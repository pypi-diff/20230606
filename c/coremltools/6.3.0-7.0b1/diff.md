# Comparing `tmp/coremltools-6.3.0.tar.gz` & `tmp/coremltools-7.0b1.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "dist/coremltools-6.3.0.tar", last modified: Wed Mar 29 23:17:30 2023, max compression
+gzip compressed data, was "dist/coremltools-7.0b1.tar", last modified: Sun Jun  4 02:56:15 2023, max compression
```

## Comparing `coremltools-6.3.0.tar` & `coremltools-7.0b1.tar`

### file list

```diff
@@ -1,463 +1,559 @@
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:30.000000 coremltools-6.3.0/
--rw-r--r--   0 nninfci    (501) staff       (20)     1488 2022-05-05 00:22:09.000000 coremltools-6.3.0/LICENSE.txt
--rw-r--r--   0 nninfci    (501) staff       (20)       17 2022-05-05 00:22:09.000000 coremltools-6.3.0/MANIFEST.in
--rw-r--r--   0 nninfci    (501) staff       (20)     2163 2023-03-29 23:17:30.000000 coremltools-6.3.0/PKG-INFO
--rw-r--r--   0 nninfci    (501) staff       (20)     3149 2023-02-23 23:27:14.000000 coremltools-6.3.0/README.md
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:29.000000 coremltools-6.3.0/coremltools/
--rw-r--r--   0 nninfci    (501) staff       (20)     4561 2023-03-29 19:25:43.000000 coremltools-6.3.0/coremltools/__init__.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:29.000000 coremltools-6.3.0/coremltools/_deps/
--rw-r--r--   0 nninfci    (501) staff       (20)     5563 2023-03-29 01:49:03.000000 coremltools-6.3.0/coremltools/_deps/__init__.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:29.000000 coremltools-6.3.0/coremltools/converters/
--rw-r--r--   0 nninfci    (501) staff       (20)      490 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/__init__.py
--rw-r--r--   0 nninfci    (501) staff       (20)    38179 2023-03-25 03:34:07.000000 coremltools-6.3.0/coremltools/converters/_converters_entry.py
--rw-r--r--   0 nninfci    (501) staff       (20)     2415 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/_profile_utils.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:29.000000 coremltools-6.3.0/coremltools/converters/libsvm/
--rw-r--r--   0 nninfci    (501) staff       (20)     3399 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/libsvm/__init__.py
--rw-r--r--   0 nninfci    (501) staff       (20)     7202 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/libsvm/_libsvm_converter.py
--rw-r--r--   0 nninfci    (501) staff       (20)      971 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/libsvm/_libsvm_util.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:29.000000 coremltools-6.3.0/coremltools/converters/mil/
--rw-r--r--   0 nninfci    (501) staff       (20)      894 2023-02-02 17:20:34.000000 coremltools-6.3.0/coremltools/converters/mil/__init__.py
--rw-r--r--   0 nninfci    (501) staff       (20)     5944 2023-02-02 17:20:34.000000 coremltools-6.3.0/coremltools/converters/mil/_deployment_compatibility.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:29.000000 coremltools-6.3.0/coremltools/converters/mil/backend/
--rw-r--r--   0 nninfci    (501) staff       (20)      218 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/backend/__init__.py
--rw-r--r--   0 nninfci    (501) staff       (20)     3868 2023-02-22 21:48:24.000000 coremltools-6.3.0/coremltools/converters/mil/backend/backend_helper.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:29.000000 coremltools-6.3.0/coremltools/converters/mil/backend/mil/
--rw-r--r--   0 nninfci    (501) staff       (20)      218 2023-03-09 05:41:10.000000 coremltools-6.3.0/coremltools/converters/mil/backend/mil/__init__.py
--rw-r--r--   0 nninfci    (501) staff       (20)    12647 2023-02-02 17:20:34.000000 coremltools-6.3.0/coremltools/converters/mil/backend/mil/helper.py
--rw-r--r--   0 nninfci    (501) staff       (20)    23014 2023-03-09 05:41:10.000000 coremltools-6.3.0/coremltools/converters/mil/backend/mil/load.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:29.000000 coremltools-6.3.0/coremltools/converters/mil/backend/mil/passes/
--rw-r--r--   0 nninfci    (501) staff       (20)      355 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/backend/mil/passes/__init__.py
--rw-r--r--   0 nninfci    (501) staff       (20)    10346 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/backend/mil/passes/adjust_io_to_supported_types.py
--rw-r--r--   0 nninfci    (501) staff       (20)     2744 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/backend/mil/passes/fuse_activation_silu.py
--rw-r--r--   0 nninfci    (501) staff       (20)     3434 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/backend/mil/passes/insert_image_preprocessing_op.py
--rw-r--r--   0 nninfci    (501) staff       (20)     1014 2023-02-22 21:48:24.000000 coremltools-6.3.0/coremltools/converters/mil/backend/mil/passes/sanitize_name_strings.py
--rw-r--r--   0 nninfci    (501) staff       (20)    31333 2023-02-02 17:20:34.000000 coremltools-6.3.0/coremltools/converters/mil/backend/mil/passes/test_passes.py
--rw-r--r--   0 nninfci    (501) staff       (20)     1265 2023-02-22 21:48:24.000000 coremltools-6.3.0/coremltools/converters/mil/backend/mil/test_helper.py
--rw-r--r--   0 nninfci    (501) staff       (20)    14116 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/backend/mil/test_model_input_params.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:29.000000 coremltools-6.3.0/coremltools/converters/mil/backend/nn/
--rw-r--r--   0 nninfci    (501) staff       (20)      218 2023-03-09 05:41:10.000000 coremltools-6.3.0/coremltools/converters/mil/backend/nn/__init__.py
--rw-r--r--   0 nninfci    (501) staff       (20)    13539 2023-03-09 05:41:10.000000 coremltools-6.3.0/coremltools/converters/mil/backend/nn/load.py
--rw-r--r--   0 nninfci    (501) staff       (20)      739 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/backend/nn/mil_to_nn_mapping_registry.py
--rw-r--r--   0 nninfci    (501) staff       (20)   129681 2023-03-29 19:25:43.000000 coremltools-6.3.0/coremltools/converters/mil/backend/nn/op_mapping.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:29.000000 coremltools-6.3.0/coremltools/converters/mil/backend/nn/passes/
--rw-r--r--   0 nninfci    (501) staff       (20)      432 2023-02-27 05:23:11.000000 coremltools-6.3.0/coremltools/converters/mil/backend/nn/passes/__init__.py
--rw-r--r--   0 nninfci    (501) staff       (20)     1698 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/backend/nn/passes/alert_return_type_cast.py
--rw-r--r--   0 nninfci    (501) staff       (20)     2528 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/backend/nn/passes/commingle_loop_vars.py
--rw-r--r--   0 nninfci    (501) staff       (20)     3705 2023-02-27 05:23:11.000000 coremltools-6.3.0/coremltools/converters/mil/backend/nn/passes/conv1d_decomposition.py
--rw-r--r--   0 nninfci    (501) staff       (20)     2153 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/backend/nn/passes/handle_return_inputs_as_outputs.py
--rw-r--r--   0 nninfci    (501) staff       (20)     2086 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/backend/nn/passes/handle_return_unused_inputs.py
--rw-r--r--   0 nninfci    (501) staff       (20)     1641 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/backend/nn/passes/handle_unused_inputs.py
--rw-r--r--   0 nninfci    (501) staff       (20)    18489 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/backend/nn/passes/mlmodel_passes.py
--rw-r--r--   0 nninfci    (501) staff       (20)    37205 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/backend/nn/passes/test_mlmodel_passes.py
--rw-r--r--   0 nninfci    (501) staff       (20)     7734 2023-02-27 05:23:11.000000 coremltools-6.3.0/coremltools/converters/mil/backend/nn/passes/test_passes.py
--rw-r--r--   0 nninfci    (501) staff       (20)      460 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/conftest.py
--rw-r--r--   0 nninfci    (501) staff       (20)    12340 2023-03-09 05:41:10.000000 coremltools-6.3.0/coremltools/converters/mil/converter.py
--rw-r--r--   0 nninfci    (501) staff       (20)     6991 2023-02-28 06:54:22.000000 coremltools-6.3.0/coremltools/converters/mil/debugging_utils.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:29.000000 coremltools-6.3.0/coremltools/converters/mil/experimental/
--rw-r--r--   0 nninfci    (501) staff       (20)      218 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/experimental/__init__.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:29.000000 coremltools-6.3.0/coremltools/converters/mil/experimental/passes/
--rw-r--r--   0 nninfci    (501) staff       (20)    31488 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/experimental/passes/README.md
--rw-r--r--   0 nninfci    (501) staff       (20)      218 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/experimental/passes/__init__.py
--rw-r--r--   0 nninfci    (501) staff       (20)     6064 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/experimental/passes/generic_conv_batchnorm_fusion.py
--rw-r--r--   0 nninfci    (501) staff       (20)    12523 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/experimental/passes/generic_conv_bias_fusion.py
--rw-r--r--   0 nninfci    (501) staff       (20)     8575 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/experimental/passes/generic_conv_scale_fusion.py
--rw-r--r--   0 nninfci    (501) staff       (20)    21031 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/experimental/passes/generic_layernorm_instancenorm_pattern_fusion.py
--rw-r--r--   0 nninfci    (501) staff       (20)     4994 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/experimental/passes/generic_linear_bias_fusion.py
--rw-r--r--   0 nninfci    (501) staff       (20)     9865 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/experimental/passes/generic_pass_infrastructure.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:29.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/
--rw-r--r--   0 nninfci    (501) staff       (20)      264 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/__init__.py
--rw-r--r--   0 nninfci    (501) staff       (20)    15826 2023-03-29 19:25:43.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/_utils.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:29.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/milproto/
--rw-r--r--   0 nninfci    (501) staff       (20)      239 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/milproto/__init__.py
--rw-r--r--   0 nninfci    (501) staff       (20)     2434 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/milproto/helper.py
--rw-r--r--   0 nninfci    (501) staff       (20)    17069 2023-02-02 17:20:34.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/milproto/load.py
--rw-r--r--   0 nninfci    (501) staff       (20)     8796 2023-03-28 07:36:50.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/milproto/test_load.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:29.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/
--rw-r--r--   0 nninfci    (501) staff       (20)      762 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/__init__.py
--rw-r--r--   0 nninfci    (501) staff       (20)    10999 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/basic_graph_ops.py
--rw-r--r--   0 nninfci    (501) staff       (20)     7497 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/convert_utils.py
--rw-r--r--   0 nninfci    (501) staff       (20)    21705 2023-03-09 05:41:10.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/converter.py
--rw-r--r--   0 nninfci    (501) staff       (20)     6464 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/dialect_ops.py
--rw-r--r--   0 nninfci    (501) staff       (20)     4544 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/dot_visitor.py
--rw-r--r--   0 nninfci    (501) staff       (20)    12848 2023-03-09 05:41:10.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/load.py
--rw-r--r--   0 nninfci    (501) staff       (20)      993 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/naming_utils.py
--rw-r--r--   0 nninfci    (501) staff       (20)   122775 2023-03-29 19:25:43.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/ops.py
--rw-r--r--   0 nninfci    (501) staff       (20)     4082 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/parse.py
--rw-r--r--   0 nninfci    (501) staff       (20)     3234 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/parsed_tf_node.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:29.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/ssa_passes/
--rw-r--r--   0 nninfci    (501) staff       (20)      300 2023-03-09 05:41:10.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/ssa_passes/__init__.py
--rw-r--r--   0 nninfci    (501) staff       (20)     4788 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/ssa_passes/backfill_make_list_elem_type.py
--rw-r--r--   0 nninfci    (501) staff       (20)     7617 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/ssa_passes/expand_tf_lstm.py
--rw-r--r--   0 nninfci    (501) staff       (20)     2071 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/ssa_passes/test_passes.py
--rw-r--r--   0 nninfci    (501) staff       (20)    12437 2023-02-22 21:48:24.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/ssa_passes/tf_lstm_to_core_lstm.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:29.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/test/
--rw-r--r--   0 nninfci    (501) staff       (20)      218 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/test/__init__.py
--rw-r--r--   0 nninfci    (501) staff       (20)     2415 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/test/test_composite_ops.py
--rw-r--r--   0 nninfci    (501) staff       (20)    11068 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/test/test_custom_ops.py
--rw-r--r--   0 nninfci    (501) staff       (20)     1463 2023-02-02 17:20:34.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/test/test_graphs.py
--rw-r--r--   0 nninfci    (501) staff       (20)    16127 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/test/test_load.py
--rw-r--r--   0 nninfci    (501) staff       (20)   251335 2023-02-28 06:54:22.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/test/test_ops.py
--rw-r--r--   0 nninfci    (501) staff       (20)     5013 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/test/test_parse.py
--rw-r--r--   0 nninfci    (501) staff       (20)     2187 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/test/test_parsed_tf_node.py
--rw-r--r--   0 nninfci    (501) staff       (20)    38934 2023-02-02 17:20:34.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/test/test_tf_conversion_api.py
--rw-r--r--   0 nninfci    (501) staff       (20)    14271 2023-02-02 17:20:34.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/test/testing_utils.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:29.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/
--rw-r--r--   0 nninfci    (501) staff       (20)      847 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/__init__.py
--rw-r--r--   0 nninfci    (501) staff       (20)     4377 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/cond_to_where.py
--rw-r--r--   0 nninfci    (501) staff       (20)     6880 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/constant_propagation.py
--rw-r--r--   0 nninfci    (501) staff       (20)     2386 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/delete_asserts.py
--rw-r--r--   0 nninfci    (501) staff       (20)     3059 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/delete_constant.py
--rw-r--r--   0 nninfci    (501) staff       (20)      669 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/delete_disconnected_nodes.py
--rw-r--r--   0 nninfci    (501) staff       (20)    19047 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/functionalize_loops.py
--rw-r--r--   0 nninfci    (501) staff       (20)     7675 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/fuse_dilation_conv.py
--rw-r--r--   0 nninfci    (501) staff       (20)     3398 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/insert_get_tuple.py
--rw-r--r--   0 nninfci    (501) staff       (20)     2966 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/quantization_pass.py
--rw-r--r--   0 nninfci    (501) staff       (20)     3649 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/tensor_array_transform.py
--rw-r--r--   0 nninfci    (501) staff       (20)     2898 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/variable_node_transform.py
--rw-r--r--   0 nninfci    (501) staff       (20)     6501 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/visitors.py
--rw-r--r--   0 nninfci    (501) staff       (20)     1769 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/tf_op_registry.py
--rw-r--r--   0 nninfci    (501) staff       (20)    21046 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/tfssa.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:29.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow2/
--rw-r--r--   0 nninfci    (501) staff       (20)      455 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow2/__init__.py
--rw-r--r--   0 nninfci    (501) staff       (20)     1540 2023-03-09 05:41:10.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow2/converter.py
--rw-r--r--   0 nninfci    (501) staff       (20)    14784 2023-03-09 05:41:10.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow2/load.py
--rw-r--r--   0 nninfci    (501) staff       (20)     8460 2023-02-02 17:20:34.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow2/ops.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:29.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow2/ssa_passes/
--rw-r--r--   0 nninfci    (501) staff       (20)      253 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow2/ssa_passes/__init__.py
--rw-r--r--   0 nninfci    (501) staff       (20)     4645 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow2/ssa_passes/remove_vacuous_cond.py
--rw-r--r--   0 nninfci    (501) staff       (20)     1850 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow2/ssa_passes/test_v2_passes.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:29.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow2/test/
--rw-r--r--   0 nninfci    (501) staff       (20)      218 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow2/test/__init__.py
--rw-r--r--   0 nninfci    (501) staff       (20)    17555 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow2/test/test_tf2_conversion_api.py
--rw-r--r--   0 nninfci    (501) staff       (20)     8379 2023-03-29 01:49:03.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow2/test/test_v2_load.py
--rw-r--r--   0 nninfci    (501) staff       (20)    25555 2023-02-02 17:20:34.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow2/test/test_v2_ops.py
--rw-r--r--   0 nninfci    (501) staff       (20)    59928 2023-02-22 21:48:24.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow2/test/test_v2_ops_tf_keras.py
--rw-r--r--   0 nninfci    (501) staff       (20)    10465 2023-02-02 17:20:34.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow2/test/testing_utils.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:29.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow2/tf_graph_pass/
--rw-r--r--   0 nninfci    (501) staff       (20)      371 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow2/tf_graph_pass/__init__.py
--rw-r--r--   0 nninfci    (501) staff       (20)    20086 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow2/tf_graph_pass/rewrite_control_flow_functions.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:29.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/torch/
--rw-r--r--   0 nninfci    (501) staff       (20)      494 2023-03-09 05:41:10.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/torch/__init__.py
--rw-r--r--   0 nninfci    (501) staff       (20)    20820 2023-03-29 19:25:43.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/torch/converter.py
--rw-r--r--   0 nninfci    (501) staff       (20)     8408 2023-03-28 22:03:59.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/torch/dialect_ops.py
--rw-r--r--   0 nninfci    (501) staff       (20)    12949 2023-02-02 17:20:34.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/torch/internal_graph.py
--rw-r--r--   0 nninfci    (501) staff       (20)     4629 2023-03-09 05:41:10.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/torch/load.py
--rw-r--r--   0 nninfci    (501) staff       (20)   194098 2023-03-29 19:25:43.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/torch/ops.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:29.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/torch/ssa_passes/
--rw-r--r--   0 nninfci    (501) staff       (20)      294 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/torch/ssa_passes/__init__.py
--rw-r--r--   0 nninfci    (501) staff       (20)     2582 2023-03-28 22:03:59.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/torch/ssa_passes/torch_tensor_assign_to_core.py
--rw-r--r--   0 nninfci    (501) staff       (20)     4525 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/torch/ssa_passes/torch_upsample_to_core_upsample.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:29.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/torch/test/
--rw-r--r--   0 nninfci    (501) staff       (20)      218 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/torch/test/__init__.py
--rw-r--r--   0 nninfci    (501) staff       (20)     1753 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/torch/test/test_api.py
--rw-r--r--   0 nninfci    (501) staff       (20)     5626 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/torch/test/test_custom_ops.py
--rw-r--r--   0 nninfci    (501) staff       (20)     1880 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/torch/test/test_examples.py
--rw-r--r--   0 nninfci    (501) staff       (20)    66729 2023-03-29 19:25:43.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/torch/test/test_internal_graph.py
--rw-r--r--   0 nninfci    (501) staff       (20)    12355 2023-02-02 17:20:34.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/torch/test/test_passes.py
--rw-r--r--   0 nninfci    (501) staff       (20)    65369 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/torch/test/test_torch_conversion_api.py
--rw-r--r--   0 nninfci    (501) staff       (20)   269720 2023-03-29 19:25:43.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/torch/test/test_torch_ops.py
--rw-r--r--   0 nninfci    (501) staff       (20)     9054 2023-02-02 17:20:34.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/torch/test/testing_utils.py
--rw-r--r--   0 nninfci    (501) staff       (20)     2276 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/torch/torch_op_registry.py
--rw-r--r--   0 nninfci    (501) staff       (20)    12932 2023-03-28 22:03:59.000000 coremltools-6.3.0/coremltools/converters/mil/frontend/torch/torchir_passes.py
--rw-r--r--   0 nninfci    (501) staff       (20)    18307 2023-02-02 17:20:34.000000 coremltools-6.3.0/coremltools/converters/mil/input_types.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:29.000000 coremltools-6.3.0/coremltools/converters/mil/mil/
--rw-r--r--   0 nninfci    (501) staff       (20)      833 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/mil/__init__.py
--rw-r--r--   0 nninfci    (501) staff       (20)    32383 2023-03-29 19:25:43.000000 coremltools-6.3.0/coremltools/converters/mil/mil/block.py
--rw-r--r--   0 nninfci    (501) staff       (20)     8906 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/mil/builder.py
--rw-r--r--   0 nninfci    (501) staff       (20)    11733 2023-02-02 17:20:34.000000 coremltools-6.3.0/coremltools/converters/mil/mil/input_type.py
--rw-r--r--   0 nninfci    (501) staff       (20)    22407 2023-03-29 19:25:43.000000 coremltools-6.3.0/coremltools/converters/mil/mil/operation.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:29.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/
--rw-r--r--   0 nninfci    (501) staff       (20)      218 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/__init__.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:29.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/
--rw-r--r--   0 nninfci    (501) staff       (20)      267 2023-02-02 17:20:34.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/__init__.py
--rw-r--r--   0 nninfci    (501) staff       (20)      354 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/_op_reqs.py
--rw-r--r--   0 nninfci    (501) staff       (20)    21615 2023-02-22 21:48:24.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/_utils.py
--rw-r--r--   0 nninfci    (501) staff       (20)    26614 2023-02-02 17:20:34.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/complex_dialect_ops.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:29.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/iOS15/
--rw-r--r--   0 nninfci    (501) staff       (20)     3183 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/iOS15/__init__.py
--rw-r--r--   0 nninfci    (501) staff       (20)    15088 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/iOS15/activation.py
--rw-r--r--   0 nninfci    (501) staff       (20)     3283 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/iOS15/classify.py
--rw-r--r--   0 nninfci    (501) staff       (20)    29194 2023-03-25 03:34:07.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/iOS15/control_flow.py
--rw-r--r--   0 nninfci    (501) staff       (20)    16798 2023-02-14 04:33:50.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/iOS15/conv.py
--rw-r--r--   0 nninfci    (501) staff       (20)    15713 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/iOS15/elementwise_binary.py
--rw-r--r--   0 nninfci    (501) staff       (20)    20155 2023-02-02 17:20:34.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/iOS15/elementwise_unary.py
--rw-r--r--   0 nninfci    (501) staff       (20)    33876 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/iOS15/image_resizing.py
--rw-r--r--   0 nninfci    (501) staff       (20)    12377 2023-03-29 19:25:43.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/iOS15/linear.py
--rw-r--r--   0 nninfci    (501) staff       (20)    12595 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/iOS15/normalization.py
--rw-r--r--   0 nninfci    (501) staff       (20)     9122 2023-02-02 17:20:34.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/iOS15/pool.py
--rw-r--r--   0 nninfci    (501) staff       (20)     9058 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/iOS15/random.py
--rw-r--r--   0 nninfci    (501) staff       (20)    20532 2023-03-29 19:25:43.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/iOS15/recurrent.py
--rw-r--r--   0 nninfci    (501) staff       (20)    15176 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/iOS15/reduction.py
--rw-r--r--   0 nninfci    (501) staff       (20)    16508 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/iOS15/scatter_gather.py
--rw-r--r--   0 nninfci    (501) staff       (20)    41580 2023-02-22 21:48:24.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/iOS15/tensor_operation.py
--rw-r--r--   0 nninfci    (501) staff       (20)    35196 2023-03-28 22:03:59.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/iOS15/tensor_transformation.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:29.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/iOS16/
--rw-r--r--   0 nninfci    (501) staff       (20)      724 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/iOS16/__init__.py
--rw-r--r--   0 nninfci    (501) staff       (20)    14272 2023-03-28 22:03:59.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/iOS16/constexpr_ops.py
--rw-r--r--   0 nninfci    (501) staff       (20)     3335 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/iOS16/image_resizing.py
--rw-r--r--   0 nninfci    (501) staff       (20)     5863 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/iOS16/scatter_gather.py
--rw-r--r--   0 nninfci    (501) staff       (20)     3930 2023-03-29 19:25:43.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/iOS16/tensor_operation.py
--rw-r--r--   0 nninfci    (501) staff       (20)     6920 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/iOS16/tensor_transformation.py
--rw-r--r--   0 nninfci    (501) staff       (20)     1245 2023-02-02 17:20:34.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/helper.py
--rw-r--r--   0 nninfci    (501) staff       (20)     8910 2023-03-16 18:42:11.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/registry.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:29.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/tests/
--rw-r--r--   0 nninfci    (501) staff       (20)      218 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/tests/__init__.py
--rw-r--r--   0 nninfci    (501) staff       (20)    35469 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/tests/test_activation.py
--rw-r--r--   0 nninfci    (501) staff       (20)     1851 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/tests/test_const.py
--rw-r--r--   0 nninfci    (501) staff       (20)    22658 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/tests/test_constexpr_ops.py
--rw-r--r--   0 nninfci    (501) staff       (20)    13602 2023-02-02 17:20:34.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/tests/test_control_flow.py
--rw-r--r--   0 nninfci    (501) staff       (20)    30760 2023-02-14 04:33:50.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/tests/test_conv.py
--rw-r--r--   0 nninfci    (501) staff       (20)    21099 2023-02-02 17:20:34.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/tests/test_elementwise_binary.py
--rw-r--r--   0 nninfci    (501) staff       (20)    24212 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/tests/test_elementwise_unary.py
--rw-r--r--   0 nninfci    (501) staff       (20)    32525 2023-02-02 17:20:34.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/tests/test_image_resizing.py
--rw-r--r--   0 nninfci    (501) staff       (20)    12430 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/tests/test_linear.py
--rw-r--r--   0 nninfci    (501) staff       (20)    25998 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/tests/test_normalization.py
--rw-r--r--   0 nninfci    (501) staff       (20)    17261 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/tests/test_pool.py
--rw-r--r--   0 nninfci    (501) staff       (20)    14861 2023-02-02 17:20:34.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/tests/test_random.py
--rw-r--r--   0 nninfci    (501) staff       (20)    25212 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/tests/test_recurrent.py
--rw-r--r--   0 nninfci    (501) staff       (20)    13720 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/tests/test_reduction.py
--rw-r--r--   0 nninfci    (501) staff       (20)    26958 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/tests/test_scatter_gather.py
--rw-r--r--   0 nninfci    (501) staff       (20)    13981 2023-03-28 22:03:59.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/tests/test_slice.py
--rw-r--r--   0 nninfci    (501) staff       (20)    54152 2023-02-22 21:48:24.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/tests/test_tensor_operation.py
--rw-r--r--   0 nninfci    (501) staff       (20)    46203 2023-03-24 00:52:25.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/tests/test_tensor_transformation.py
--rw-r--r--   0 nninfci    (501) staff       (20)     8055 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/tests/test_utils.py
--rw-r--r--   0 nninfci    (501) staff       (20)     5734 2023-02-22 21:48:24.000000 coremltools-6.3.0/coremltools/converters/mil/mil/ops/tests/testing_utils.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:29.000000 coremltools-6.3.0/coremltools/converters/mil/mil/passes/
--rw-r--r--   0 nninfci    (501) staff       (20)     1415 2023-03-09 05:41:10.000000 coremltools-6.3.0/coremltools/converters/mil/mil/passes/__init__.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:30.000000 coremltools-6.3.0/coremltools/converters/mil/mil/passes/defs/
--rw-r--r--   0 nninfci    (501) staff       (20)      218 2023-02-22 21:48:24.000000 coremltools-6.3.0/coremltools/converters/mil/mil/passes/defs/__init__.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:30.000000 coremltools-6.3.0/coremltools/converters/mil/mil/passes/defs/cleanup/
--rw-r--r--   0 nninfci    (501) staff       (20)      714 2023-02-22 21:48:24.000000 coremltools-6.3.0/coremltools/converters/mil/mil/passes/defs/cleanup/__init__.py
--rw-r--r--   0 nninfci    (501) staff       (20)     3996 2023-03-25 01:06:50.000000 coremltools-6.3.0/coremltools/converters/mil/mil/passes/defs/cleanup/const_elimination.py
--rw-r--r--   0 nninfci    (501) staff       (20)     2902 2023-03-25 01:06:50.000000 coremltools-6.3.0/coremltools/converters/mil/mil/passes/defs/cleanup/dead_code_elimination.py
--rw-r--r--   0 nninfci    (501) staff       (20)     3833 2023-02-22 21:48:24.000000 coremltools-6.3.0/coremltools/converters/mil/mil/passes/defs/cleanup/dedup_op_and_var_names.py
--rw-r--r--   0 nninfci    (501) staff       (20)     4434 2023-03-25 01:06:50.000000 coremltools-6.3.0/coremltools/converters/mil/mil/passes/defs/cleanup/fuse_reduce_mean.py
--rw-r--r--   0 nninfci    (501) staff       (20)     6930 2023-02-22 21:48:24.000000 coremltools-6.3.0/coremltools/converters/mil/mil/passes/defs/cleanup/loop_invariant_elimination.py
--rw-r--r--   0 nninfci    (501) staff       (20)     7962 2023-03-25 01:06:50.000000 coremltools-6.3.0/coremltools/converters/mil/mil/passes/defs/cleanup/noop_elimination.py
--rw-r--r--   0 nninfci    (501) staff       (20)     8399 2023-03-25 01:06:50.000000 coremltools-6.3.0/coremltools/converters/mil/mil/passes/defs/cleanup/remove_redundant_ops.py
--rw-r--r--   0 nninfci    (501) staff       (20)     3848 2023-03-25 01:06:50.000000 coremltools-6.3.0/coremltools/converters/mil/mil/passes/defs/cleanup/remove_symbolic_reshape.py
--rw-r--r--   0 nninfci    (501) staff       (20)     7620 2023-03-25 01:06:50.000000 coremltools-6.3.0/coremltools/converters/mil/mil/passes/defs/cleanup/topological_reorder.py
--rw-r--r--   0 nninfci    (501) staff       (20)    21096 2023-02-22 21:48:24.000000 coremltools-6.3.0/coremltools/converters/mil/mil/passes/defs/lower_complex_dialect_ops.py
--rw-r--r--   0 nninfci    (501) staff       (20)    24562 2023-03-25 01:06:50.000000 coremltools-6.3.0/coremltools/converters/mil/mil/passes/defs/optimize_activation.py
--rw-r--r--   0 nninfci    (501) staff       (20)    41827 2023-03-25 01:06:50.000000 coremltools-6.3.0/coremltools/converters/mil/mil/passes/defs/optimize_conv.py
--rw-r--r--   0 nninfci    (501) staff       (20)    11714 2023-03-25 01:06:50.000000 coremltools-6.3.0/coremltools/converters/mil/mil/passes/defs/optimize_elementwise_binary.py
--rw-r--r--   0 nninfci    (501) staff       (20)    11330 2023-03-25 01:06:50.000000 coremltools-6.3.0/coremltools/converters/mil/mil/passes/defs/optimize_linear.py
--rw-r--r--   0 nninfci    (501) staff       (20)    34386 2023-03-25 01:06:50.000000 coremltools-6.3.0/coremltools/converters/mil/mil/passes/defs/optimize_normalization.py
--rw-r--r--   0 nninfci    (501) staff       (20)    72694 2023-03-28 22:03:59.000000 coremltools-6.3.0/coremltools/converters/mil/mil/passes/defs/optimize_repeat_ops.py
--rw-r--r--   0 nninfci    (501) staff       (20)    29777 2023-03-28 22:03:59.000000 coremltools-6.3.0/coremltools/converters/mil/mil/passes/defs/optimize_tensor_operation.py
--rw-r--r--   0 nninfci    (501) staff       (20)    15254 2023-03-25 01:06:50.000000 coremltools-6.3.0/coremltools/converters/mil/mil/passes/defs/preprocess.py
--rw-r--r--   0 nninfci    (501) staff       (20)    32105 2023-03-28 22:03:59.000000 coremltools-6.3.0/coremltools/converters/mil/mil/passes/defs/quantization.py
--rw-r--r--   0 nninfci    (501) staff       (20)     2605 2023-03-09 05:41:10.000000 coremltools-6.3.0/coremltools/converters/mil/mil/passes/graph_pass.py
--rw-r--r--   0 nninfci    (501) staff       (20)     5761 2023-02-27 05:23:11.000000 coremltools-6.3.0/coremltools/converters/mil/mil/passes/helper.py
--rw-r--r--   0 nninfci    (501) staff       (20)    15680 2023-03-28 22:03:59.000000 coremltools-6.3.0/coremltools/converters/mil/mil/passes/pass_pipeline.py
--rw-r--r--   0 nninfci    (501) staff       (20)     2275 2023-03-09 05:41:10.000000 coremltools-6.3.0/coremltools/converters/mil/mil/passes/pass_registry.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:30.000000 coremltools-6.3.0/coremltools/converters/mil/mil/passes/tests/
--rw-r--r--   0 nninfci    (501) staff       (20)      218 2023-02-22 21:48:24.000000 coremltools-6.3.0/coremltools/converters/mil/mil/passes/tests/__init__.py
--rw-r--r--   0 nninfci    (501) staff       (20)     2082 2023-02-22 21:48:24.000000 coremltools-6.3.0/coremltools/converters/mil/mil/passes/tests/test_lower_complex_dialect_ops.py
--rw-r--r--   0 nninfci    (501) staff       (20)     5077 2023-03-09 05:41:10.000000 coremltools-6.3.0/coremltools/converters/mil/mil/passes/tests/test_pass_pipeline.py
--rw-r--r--   0 nninfci    (501) staff       (20)   271534 2023-03-28 22:03:59.000000 coremltools-6.3.0/coremltools/converters/mil/mil/passes/tests/test_passes.py
--rw-r--r--   0 nninfci    (501) staff       (20)    78845 2023-02-22 21:48:24.000000 coremltools-6.3.0/coremltools/converters/mil/mil/passes/tests/test_reduce_transposes_pass.py
--rw-r--r--   0 nninfci    (501) staff       (20)    10745 2023-02-14 04:33:50.000000 coremltools-6.3.0/coremltools/converters/mil/mil/program.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:30.000000 coremltools-6.3.0/coremltools/converters/mil/mil/tests/
--rw-r--r--   0 nninfci    (501) staff       (20)      217 2023-02-14 04:33:50.000000 coremltools-6.3.0/coremltools/converters/mil/mil/tests/__init__.py
--rw-r--r--   0 nninfci    (501) staff       (20)    15736 2023-02-22 21:48:24.000000 coremltools-6.3.0/coremltools/converters/mil/mil/tests/test_block.py
--rw-r--r--   0 nninfci    (501) staff       (20)    10605 2023-02-28 06:54:22.000000 coremltools-6.3.0/coremltools/converters/mil/mil/tests/test_debug.py
--rw-r--r--   0 nninfci    (501) staff       (20)    13429 2023-03-06 21:05:06.000000 coremltools-6.3.0/coremltools/converters/mil/mil/tests/test_programs.py
--rw-r--r--   0 nninfci    (501) staff       (20)     1085 2023-03-09 05:41:10.000000 coremltools-6.3.0/coremltools/converters/mil/mil/tests/test_types.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:30.000000 coremltools-6.3.0/coremltools/converters/mil/mil/types/
--rw-r--r--   0 nninfci    (501) staff       (20)     1703 2023-02-02 17:20:34.000000 coremltools-6.3.0/coremltools/converters/mil/mil/types/__init__.py
--rw-r--r--   0 nninfci    (501) staff       (20)     3411 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/mil/types/annotate.py
--rw-r--r--   0 nninfci    (501) staff       (20)     2123 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/mil/types/get_type_info.py
--rw-r--r--   0 nninfci    (501) staff       (20)     1468 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/mil/types/global_methods.py
--rw-r--r--   0 nninfci    (501) staff       (20)     2160 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/mil/types/symbolic.py
--rw-r--r--   0 nninfci    (501) staff       (20)     1230 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/mil/types/type_bool.py
--rw-r--r--   0 nninfci    (501) staff       (20)     5705 2023-02-02 17:20:34.000000 coremltools-6.3.0/coremltools/converters/mil/mil/types/type_complex.py
--rw-r--r--   0 nninfci    (501) staff       (20)     1665 2023-02-02 17:20:34.000000 coremltools-6.3.0/coremltools/converters/mil/mil/types/type_dict.py
--rw-r--r--   0 nninfci    (501) staff       (20)     5119 2023-03-29 19:25:43.000000 coremltools-6.3.0/coremltools/converters/mil/mil/types/type_double.py
--rw-r--r--   0 nninfci    (501) staff       (20)      370 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/mil/types/type_globals_pseudo_type.py
--rw-r--r--   0 nninfci    (501) staff       (20)     5439 2023-02-02 17:20:34.000000 coremltools-6.3.0/coremltools/converters/mil/mil/types/type_int.py
--rw-r--r--   0 nninfci    (501) staff       (20)     1974 2023-02-02 17:20:34.000000 coremltools-6.3.0/coremltools/converters/mil/mil/types/type_list.py
--rw-r--r--   0 nninfci    (501) staff       (20)    12886 2023-03-09 05:41:10.000000 coremltools-6.3.0/coremltools/converters/mil/mil/types/type_mapping.py
--rw-r--r--   0 nninfci    (501) staff       (20)     2994 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/mil/types/type_spec.py
--rw-r--r--   0 nninfci    (501) staff       (20)      641 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/mil/types/type_str.py
--rw-r--r--   0 nninfci    (501) staff       (20)     7524 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/mil/types/type_tensor.py
--rw-r--r--   0 nninfci    (501) staff       (20)     1263 2023-02-02 17:20:34.000000 coremltools-6.3.0/coremltools/converters/mil/mil/types/type_tuple.py
--rw-r--r--   0 nninfci    (501) staff       (20)      468 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/mil/types/type_unknown.py
--rw-r--r--   0 nninfci    (501) staff       (20)      352 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/mil/types/type_void.py
--rw-r--r--   0 nninfci    (501) staff       (20)    12468 2023-02-02 17:20:34.000000 coremltools-6.3.0/coremltools/converters/mil/mil/var.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:30.000000 coremltools-6.3.0/coremltools/converters/mil/mil/visitors/
--rw-r--r--   0 nninfci    (501) staff       (20)      218 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/mil/visitors/__init__.py
--rw-r--r--   0 nninfci    (501) staff       (20)     6100 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/mil/visitors/dot_visitor.py
--rw-r--r--   0 nninfci    (501) staff       (20)     6883 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/test_flexible_shape_inputs.py
--rw-r--r--   0 nninfci    (501) staff       (20)     1839 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/mil/testing_reqs.py
--rw-r--r--   0 nninfci    (501) staff       (20)    20514 2023-03-29 19:25:43.000000 coremltools-6.3.0/coremltools/converters/mil/testing_utils.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:30.000000 coremltools-6.3.0/coremltools/converters/sklearn/
--rw-r--r--   0 nninfci    (501) staff       (20)     1500 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/sklearn/_LinearSVC.py
--rw-r--r--   0 nninfci    (501) staff       (20)     1405 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/sklearn/_LinearSVR.py
--rw-r--r--   0 nninfci    (501) staff       (20)     1882 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/sklearn/_NuSVC.py
--rw-r--r--   0 nninfci    (501) staff       (20)     1458 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/sklearn/_NuSVR.py
--rw-r--r--   0 nninfci    (501) staff       (20)     4021 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/sklearn/_SVC.py
--rw-r--r--   0 nninfci    (501) staff       (20)     2372 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/sklearn/_SVR.py
--rw-r--r--   0 nninfci    (501) staff       (20)      294 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/sklearn/__init__.py
--rw-r--r--   0 nninfci    (501) staff       (20)     5912 2023-02-02 17:20:34.000000 coremltools-6.3.0/coremltools/converters/sklearn/_converter.py
--rw-r--r--   0 nninfci    (501) staff       (20)    12902 2023-02-02 17:20:34.000000 coremltools-6.3.0/coremltools/converters/sklearn/_converter_internal.py
--rw-r--r--   0 nninfci    (501) staff       (20)     1684 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/sklearn/_decision_tree_classifier.py
--rw-r--r--   0 nninfci    (501) staff       (20)     1442 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/sklearn/_decision_tree_regressor.py
--rw-r--r--   0 nninfci    (501) staff       (20)     3581 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/sklearn/_dict_vectorizer.py
--rw-r--r--   0 nninfci    (501) staff       (20)     3369 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/sklearn/_gradient_boosting_classifier.py
--rw-r--r--   0 nninfci    (501) staff       (20)     2246 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/sklearn/_gradient_boosting_regressor.py
--rw-r--r--   0 nninfci    (501) staff       (20)     3417 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/sklearn/_imputer.py
--rw-r--r--   0 nninfci    (501) staff       (20)     9525 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/sklearn/_k_neighbors_classifier.py
--rw-r--r--   0 nninfci    (501) staff       (20)     2376 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/sklearn/_linear_regression.py
--rw-r--r--   0 nninfci    (501) staff       (20)     3120 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/sklearn/_logistic_regression.py
--rw-r--r--   0 nninfci    (501) staff       (20)     2315 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/sklearn/_normalizer.py
--rw-r--r--   0 nninfci    (501) staff       (20)     9933 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/sklearn/_one_hot_encoder.py
--rw-r--r--   0 nninfci    (501) staff       (20)     1916 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/sklearn/_random_forest_classifier.py
--rw-r--r--   0 nninfci    (501) staff       (20)     1710 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/sklearn/_random_forest_regressor.py
--rw-r--r--   0 nninfci    (501) staff       (20)     1422 2023-02-02 17:20:34.000000 coremltools-6.3.0/coremltools/converters/sklearn/_ridge_regression.py
--rw-r--r--   0 nninfci    (501) staff       (20)     1032 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/sklearn/_sklearn_util.py
--rw-r--r--   0 nninfci    (501) staff       (20)     2626 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/sklearn/_standard_scaler.py
--rw-r--r--   0 nninfci    (501) staff       (20)     1210 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/sklearn/_svm_common.py
--rw-r--r--   0 nninfci    (501) staff       (20)     7783 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/sklearn/_tree_ensemble.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:30.000000 coremltools-6.3.0/coremltools/converters/xgboost/
--rw-r--r--   0 nninfci    (501) staff       (20)      243 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/xgboost/__init__.py
--rw-r--r--   0 nninfci    (501) staff       (20)     2760 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/xgboost/_tree.py
--rw-r--r--   0 nninfci    (501) staff       (20)     9537 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/converters/xgboost/_tree_ensemble.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:30.000000 coremltools-6.3.0/coremltools/models/
--rw-r--r--   0 nninfci    (501) staff       (20)     1049 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/models/__init__.py
--rw-r--r--   0 nninfci    (501) staff       (20)     1131 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/models/_deprecation.py
--rw-r--r--   0 nninfci    (501) staff       (20)    11762 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/models/_feature_management.py
--rw-r--r--   0 nninfci    (501) staff       (20)     7068 2023-03-29 19:25:43.000000 coremltools-6.3.0/coremltools/models/_interface_management.py
--rw-r--r--   0 nninfci    (501) staff       (20)     2018 2023-02-02 17:20:34.000000 coremltools-6.3.0/coremltools/models/array_feature_extractor.py
--rw-r--r--   0 nninfci    (501) staff       (20)     6761 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/models/datatypes.py
--rw-r--r--   0 nninfci    (501) staff       (20)     3718 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/models/feature_vectorizer.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:30.000000 coremltools-6.3.0/coremltools/models/ml_program/
--rw-r--r--   0 nninfci    (501) staff       (20)      247 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/models/ml_program/__init__.py
--rw-r--r--   0 nninfci    (501) staff       (20)    25126 2023-03-29 19:25:43.000000 coremltools-6.3.0/coremltools/models/ml_program/compression_utils.py
--rw-r--r--   0 nninfci    (501) staff       (20)    26036 2023-03-29 19:25:43.000000 coremltools-6.3.0/coremltools/models/model.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:30.000000 coremltools-6.3.0/coremltools/models/nearest_neighbors/
--rw-r--r--   0 nninfci    (501) staff       (20)      272 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/models/nearest_neighbors/__init__.py
--rw-r--r--   0 nninfci    (501) staff       (20)    21314 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/models/nearest_neighbors/builder.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:30.000000 coremltools-6.3.0/coremltools/models/neural_network/
--rw-r--r--   0 nninfci    (501) staff       (20)      486 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/models/neural_network/__init__.py
--rw-r--r--   0 nninfci    (501) staff       (20)   337600 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/models/neural_network/builder.py
--rw-r--r--   0 nninfci    (501) staff       (20)    27323 2023-02-02 17:20:34.000000 coremltools-6.3.0/coremltools/models/neural_network/flexible_shape_utils.py
--rw-r--r--   0 nninfci    (501) staff       (20)     8194 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/models/neural_network/optimization_utils.py
--rw-r--r--   0 nninfci    (501) staff       (20)     3748 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/models/neural_network/printer.py
--rw-r--r--   0 nninfci    (501) staff       (20)    57685 2023-02-02 17:20:34.000000 coremltools-6.3.0/coremltools/models/neural_network/quantization_utils.py
--rw-r--r--   0 nninfci    (501) staff       (20)    10768 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/models/neural_network/spec_inspection_utils.py
--rw-r--r--   0 nninfci    (501) staff       (20)     4775 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/models/neural_network/update_optimizer_utils.py
--rw-r--r--   0 nninfci    (501) staff       (20)     3967 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/models/neural_network/utils.py
--rw-r--r--   0 nninfci    (501) staff       (20)    10916 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/models/pipeline.py
--rw-r--r--   0 nninfci    (501) staff       (20)    15764 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/models/tree_ensemble.py
--rw-r--r--   0 nninfci    (501) staff       (20)    33597 2023-03-29 19:25:43.000000 coremltools-6.3.0/coremltools/models/utils.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:30.000000 coremltools-6.3.0/coremltools/proto/
--rw-r--r--   0 nninfci    (501) staff       (20)     2269 2023-02-03 02:22:08.000000 coremltools-6.3.0/coremltools/proto/ArrayFeatureExtractor_pb2.py
--rw-r--r--   0 nninfci    (501) staff       (20)     5197 2023-02-03 02:22:08.000000 coremltools-6.3.0/coremltools/proto/AudioFeaturePrint_pb2.py
--rw-r--r--   0 nninfci    (501) staff       (20)    13073 2023-02-03 02:22:08.000000 coremltools-6.3.0/coremltools/proto/BayesianProbitRegressor_pb2.py
--rw-r--r--   0 nninfci    (501) staff       (20)     5556 2023-02-03 02:22:08.000000 coremltools-6.3.0/coremltools/proto/CategoricalMapping_pb2.py
--rw-r--r--   0 nninfci    (501) staff       (20)     2940 2023-02-03 02:22:08.000000 coremltools-6.3.0/coremltools/proto/ClassConfidenceThresholding_pb2.py
--rw-r--r--   0 nninfci    (501) staff       (20)    10557 2023-02-03 02:22:08.000000 coremltools-6.3.0/coremltools/proto/CustomModel_pb2.py
--rw-r--r--   0 nninfci    (501) staff       (20)    25856 2023-02-03 02:22:08.000000 coremltools-6.3.0/coremltools/proto/DataStructures_pb2.py
--rw-r--r--   0 nninfci    (501) staff       (20)     3817 2023-02-03 02:22:08.000000 coremltools-6.3.0/coremltools/proto/DictVectorizer_pb2.py
--rw-r--r--   0 nninfci    (501) staff       (20)    38649 2023-02-03 02:22:08.000000 coremltools-6.3.0/coremltools/proto/FeatureTypes_pb2.py
--rw-r--r--   0 nninfci    (501) staff       (20)     4119 2023-02-03 02:22:08.000000 coremltools-6.3.0/coremltools/proto/FeatureVectorizer_pb2.py
--rw-r--r--   0 nninfci    (501) staff       (20)     8780 2023-02-03 02:22:08.000000 coremltools-6.3.0/coremltools/proto/GLMClassifier_pb2.py
--rw-r--r--   0 nninfci    (501) staff       (20)     5431 2023-02-03 02:22:08.000000 coremltools-6.3.0/coremltools/proto/GLMRegressor_pb2.py
--rw-r--r--   0 nninfci    (501) staff       (20)     4337 2023-02-03 02:22:08.000000 coremltools-6.3.0/coremltools/proto/Gazetteer_pb2.py
--rw-r--r--   0 nninfci    (501) staff       (20)     1655 2023-02-03 02:22:08.000000 coremltools-6.3.0/coremltools/proto/Identity_pb2.py
--rw-r--r--   0 nninfci    (501) staff       (20)     9310 2023-02-03 02:22:08.000000 coremltools-6.3.0/coremltools/proto/Imputer_pb2.py
--rw-r--r--   0 nninfci    (501) staff       (20)    11274 2023-02-03 02:22:08.000000 coremltools-6.3.0/coremltools/proto/ItemSimilarityRecommender_pb2.py
--rw-r--r--   0 nninfci    (501) staff       (20)     5073 2023-02-03 02:22:08.000000 coremltools-6.3.0/coremltools/proto/LinkedModel_pb2.py
--rw-r--r--   0 nninfci    (501) staff       (20)    83751 2023-02-03 02:22:08.000000 coremltools-6.3.0/coremltools/proto/MIL_pb2.py
--rw-r--r--   0 nninfci    (501) staff       (20)    59302 2023-02-03 02:22:08.000000 coremltools-6.3.0/coremltools/proto/Model_pb2.py
--rw-r--r--   0 nninfci    (501) staff       (20)    14471 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/proto/NamedParameters_pb2.py
--rw-r--r--   0 nninfci    (501) staff       (20)    18991 2023-02-03 02:22:08.000000 coremltools-6.3.0/coremltools/proto/NearestNeighbors_pb2.py
--rw-r--r--   0 nninfci    (501) staff       (20)   552750 2023-02-03 02:22:08.000000 coremltools-6.3.0/coremltools/proto/NeuralNetwork_pb2.py
--rw-r--r--   0 nninfci    (501) staff       (20)    10172 2023-02-03 02:22:08.000000 coremltools-6.3.0/coremltools/proto/NonMaximumSuppression_pb2.py
--rw-r--r--   0 nninfci    (501) staff       (20)     3009 2023-02-03 02:22:08.000000 coremltools-6.3.0/coremltools/proto/Normalizer_pb2.py
--rw-r--r--   0 nninfci    (501) staff       (20)     5613 2023-02-03 02:22:08.000000 coremltools-6.3.0/coremltools/proto/OneHotEncoder_pb2.py
--rw-r--r--   0 nninfci    (501) staff       (20)     8731 2023-02-03 02:22:08.000000 coremltools-6.3.0/coremltools/proto/Parameters_pb2.py
--rw-r--r--   0 nninfci    (501) staff       (20)    29440 2023-02-03 02:22:08.000000 coremltools-6.3.0/coremltools/proto/SVM_pb2.py
--rw-r--r--   0 nninfci    (501) staff       (20)     2397 2023-02-03 02:22:08.000000 coremltools-6.3.0/coremltools/proto/Scaler_pb2.py
--rw-r--r--   0 nninfci    (501) staff       (20)     4090 2023-02-03 02:22:08.000000 coremltools-6.3.0/coremltools/proto/SoundAnalysisPreprocessing_pb2.py
--rw-r--r--   0 nninfci    (501) staff       (20)     4464 2023-02-03 02:22:08.000000 coremltools-6.3.0/coremltools/proto/TextClassifier_pb2.py
--rw-r--r--   0 nninfci    (501) staff       (20)    20559 2023-02-03 02:22:08.000000 coremltools-6.3.0/coremltools/proto/TreeEnsemble_pb2.py
--rw-r--r--   0 nninfci    (501) staff       (20)     9188 2023-02-03 02:22:08.000000 coremltools-6.3.0/coremltools/proto/VisionFeaturePrint_pb2.py
--rw-r--r--   0 nninfci    (501) staff       (20)     3417 2023-02-03 02:22:08.000000 coremltools-6.3.0/coremltools/proto/WordEmbedding_pb2.py
--rw-r--r--   0 nninfci    (501) staff       (20)     6177 2023-02-03 02:22:08.000000 coremltools-6.3.0/coremltools/proto/WordTagger_pb2.py
--rw-r--r--   0 nninfci    (501) staff       (20)       44 2023-02-23 23:27:14.000000 coremltools-6.3.0/coremltools/proto/__init__.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:30.000000 coremltools-6.3.0/coremltools/test/
--rw-r--r--   0 nninfci    (501) staff       (20)      218 2022-05-05 00:22:09.000000 coremltools-6.3.0/coremltools/test/__init__.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:30.000000 coremltools-6.3.0/coremltools/test/api/
--rw-r--r--   0 nninfci    (501) staff       (20)      225 2022-05-05 00:22:09.000000 coremltools-6.3.0/coremltools/test/api/__init__.py
--rw-r--r--   0 nninfci    (501) staff       (20)    19747 2023-03-09 05:41:10.000000 coremltools-6.3.0/coremltools/test/api/test_api_examples.py
--rw-r--r--   0 nninfci    (501) staff       (20)     6967 2023-03-29 19:25:43.000000 coremltools-6.3.0/coremltools/test/api/test_api_visibilities.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:30.000000 coremltools-6.3.0/coremltools/test/blob/
--rw-r--r--   0 nninfci    (501) staff       (20)      225 2022-05-05 00:22:09.000000 coremltools-6.3.0/coremltools/test/blob/__init__.py
--rw-r--r--   0 nninfci    (501) staff       (20)     2604 2022-11-11 20:04:20.000000 coremltools-6.3.0/coremltools/test/blob/test_weights.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:30.000000 coremltools-6.3.0/coremltools/test/ml_program/
--rw-r--r--   0 nninfci    (501) staff       (20)      214 2022-05-14 03:49:29.000000 coremltools-6.3.0/coremltools/test/ml_program/__init__.py
--rw-r--r--   0 nninfci    (501) staff       (20)    20484 2023-02-28 06:54:22.000000 coremltools-6.3.0/coremltools/test/ml_program/test_compression.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:30.000000 coremltools-6.3.0/coremltools/test/modelpackage/
--rw-r--r--   0 nninfci    (501) staff       (20)      225 2022-05-05 00:22:09.000000 coremltools-6.3.0/coremltools/test/modelpackage/__init__.py
--rw-r--r--   0 nninfci    (501) staff       (20)     2137 2022-11-11 20:04:20.000000 coremltools-6.3.0/coremltools/test/modelpackage/test_mlmodel.py
--rw-r--r--   0 nninfci    (501) staff       (20)    20790 2023-03-29 19:25:43.000000 coremltools-6.3.0/coremltools/test/modelpackage/test_modelpackage.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:30.000000 coremltools-6.3.0/coremltools/test/neural_network/
--rw-r--r--   0 nninfci    (501) staff       (20)      215 2022-05-05 00:22:09.000000 coremltools-6.3.0/coremltools/test/neural_network/__init__.py
--rw-r--r--   0 nninfci    (501) staff       (20)     3321 2023-02-02 17:20:34.000000 coremltools-6.3.0/coremltools/test/neural_network/test_custom_neural_nets.py
--rw-r--r--   0 nninfci    (501) staff       (20)    22507 2023-02-02 17:20:34.000000 coremltools-6.3.0/coremltools/test/neural_network/test_model.py
--rw-r--r--   0 nninfci    (501) staff       (20)     2061 2022-11-11 20:04:20.000000 coremltools-6.3.0/coremltools/test/neural_network/test_neural_networks.py
--rw-r--r--   0 nninfci    (501) staff       (20)    24047 2022-11-11 20:04:20.000000 coremltools-6.3.0/coremltools/test/neural_network/test_nn_builder.py
--rw-r--r--   0 nninfci    (501) staff       (20)   280978 2023-02-02 17:20:34.000000 coremltools-6.3.0/coremltools/test/neural_network/test_numpy_nn_layers.py
--rw-r--r--   0 nninfci    (501) staff       (20)    18696 2022-11-11 20:04:20.000000 coremltools-6.3.0/coremltools/test/neural_network/test_quantization.py
--rw-r--r--   0 nninfci    (501) staff       (20)     1780 2022-11-11 20:04:20.000000 coremltools-6.3.0/coremltools/test/neural_network/test_simple_nn_inference.py
--rw-r--r--   0 nninfci    (501) staff       (20)    19367 2022-11-11 20:04:20.000000 coremltools-6.3.0/coremltools/test/neural_network/test_tf_numeric.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:30.000000 coremltools-6.3.0/coremltools/test/pipeline/
--rw-r--r--   0 nninfci    (501) staff       (20)      215 2022-05-05 00:22:09.000000 coremltools-6.3.0/coremltools/test/pipeline/__init__.py
--rw-r--r--   0 nninfci    (501) staff       (20)    28313 2022-11-11 20:04:20.000000 coremltools-6.3.0/coremltools/test/pipeline/test_model_updatable.py
--rw-r--r--   0 nninfci    (501) staff       (20)     9810 2023-03-29 19:25:43.000000 coremltools-6.3.0/coremltools/test/pipeline/test_pipeline.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:30.000000 coremltools-6.3.0/coremltools/test/sklearn_tests/
--rw-r--r--   0 nninfci    (501) staff       (20)      215 2022-05-05 00:22:09.000000 coremltools-6.3.0/coremltools/test/sklearn_tests/__init__.py
--rw-r--r--   0 nninfci    (501) staff       (20)    11837 2022-11-11 20:04:20.000000 coremltools-6.3.0/coremltools/test/sklearn_tests/test_NuSVC.py
--rw-r--r--   0 nninfci    (501) staff       (20)     7381 2022-11-11 20:04:20.000000 coremltools-6.3.0/coremltools/test/sklearn_tests/test_NuSVR.py
--rw-r--r--   0 nninfci    (501) staff       (20)    14243 2022-11-11 20:04:20.000000 coremltools-6.3.0/coremltools/test/sklearn_tests/test_SVC.py
--rw-r--r--   0 nninfci    (501) staff       (20)     8747 2022-11-11 20:04:20.000000 coremltools-6.3.0/coremltools/test/sklearn_tests/test_SVR.py
--rw-r--r--   0 nninfci    (501) staff       (20)     2599 2022-11-11 20:04:20.000000 coremltools-6.3.0/coremltools/test/sklearn_tests/test_categorical_imputer.py
--rw-r--r--   0 nninfci    (501) staff       (20)     3064 2022-11-11 20:04:20.000000 coremltools-6.3.0/coremltools/test/sklearn_tests/test_composite_pipelines.py
--rw-r--r--   0 nninfci    (501) staff       (20)     3358 2022-11-11 20:04:20.000000 coremltools-6.3.0/coremltools/test/sklearn_tests/test_dict_vectorizer.py
--rw-r--r--   0 nninfci    (501) staff       (20)     1031 2022-11-11 20:04:20.000000 coremltools-6.3.0/coremltools/test/sklearn_tests/test_feature_names.py
--rw-r--r--   0 nninfci    (501) staff       (20)     4400 2022-11-11 20:04:20.000000 coremltools-6.3.0/coremltools/test/sklearn_tests/test_glm_classifier.py
--rw-r--r--   0 nninfci    (501) staff       (20)     2545 2022-11-11 20:04:20.000000 coremltools-6.3.0/coremltools/test/sklearn_tests/test_imputer.py
--rw-r--r--   0 nninfci    (501) staff       (20)    14446 2022-11-11 20:04:20.000000 coremltools-6.3.0/coremltools/test/sklearn_tests/test_io_types.py
--rw-r--r--   0 nninfci    (501) staff       (20)    11433 2022-11-11 20:04:20.000000 coremltools-6.3.0/coremltools/test/sklearn_tests/test_k_neighbors_classifier.py
--rw-r--r--   0 nninfci    (501) staff       (20)     5048 2022-11-11 20:04:20.000000 coremltools-6.3.0/coremltools/test/sklearn_tests/test_linear_regression.py
--rw-r--r--   0 nninfci    (501) staff       (20)    16089 2022-11-11 20:04:20.000000 coremltools-6.3.0/coremltools/test/sklearn_tests/test_nearest_neighbors_builder.py
--rw-r--r--   0 nninfci    (501) staff       (20)     1915 2022-11-11 20:04:20.000000 coremltools-6.3.0/coremltools/test/sklearn_tests/test_normalizer.py
--rw-r--r--   0 nninfci    (501) staff       (20)    10354 2022-11-11 20:04:20.000000 coremltools-6.3.0/coremltools/test/sklearn_tests/test_one_hot_encoder.py
--rw-r--r--   0 nninfci    (501) staff       (20)     6468 2022-11-11 20:04:20.000000 coremltools-6.3.0/coremltools/test/sklearn_tests/test_random_forest_classifier.py
--rw-r--r--   0 nninfci    (501) staff       (20)     5055 2022-11-11 20:04:20.000000 coremltools-6.3.0/coremltools/test/sklearn_tests/test_random_forest_classifier_numeric.py
--rw-r--r--   0 nninfci    (501) staff       (20)     3348 2022-11-11 20:04:20.000000 coremltools-6.3.0/coremltools/test/sklearn_tests/test_random_forest_regression.py
--rw-r--r--   0 nninfci    (501) staff       (20)     3690 2022-11-11 20:04:20.000000 coremltools-6.3.0/coremltools/test/sklearn_tests/test_random_forest_regression_numeric.py
--rw-r--r--   0 nninfci    (501) staff       (20)     3884 2023-02-02 17:20:34.000000 coremltools-6.3.0/coremltools/test/sklearn_tests/test_ridge_regression.py
--rw-r--r--   0 nninfci    (501) staff       (20)     1960 2022-11-11 20:04:20.000000 coremltools-6.3.0/coremltools/test/sklearn_tests/test_standard_scalar.py
--rw-r--r--   0 nninfci    (501) staff       (20)     1876 2022-11-11 20:04:20.000000 coremltools-6.3.0/coremltools/test/sklearn_tests/test_utils.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:30.000000 coremltools-6.3.0/coremltools/test/xgboost_tests/
--rw-r--r--   0 nninfci    (501) staff       (20)      215 2022-05-05 00:22:09.000000 coremltools-6.3.0/coremltools/test/xgboost_tests/__init__.py
--rw-r--r--   0 nninfci    (501) staff       (20)    12175 2022-11-11 20:04:20.000000 coremltools-6.3.0/coremltools/test/xgboost_tests/test_boosted_trees_classifier.py
--rw-r--r--   0 nninfci    (501) staff       (20)     9737 2022-11-11 20:04:20.000000 coremltools-6.3.0/coremltools/test/xgboost_tests/test_boosted_trees_classifier_numeric.py
--rw-r--r--   0 nninfci    (501) staff       (20)     7876 2022-11-11 20:04:20.000000 coremltools-6.3.0/coremltools/test/xgboost_tests/test_boosted_trees_regression.py
--rw-r--r--   0 nninfci    (501) staff       (20)    10997 2022-11-11 20:04:20.000000 coremltools-6.3.0/coremltools/test/xgboost_tests/test_boosted_trees_regression_numeric.py
--rw-r--r--   0 nninfci    (501) staff       (20)     5295 2022-11-11 20:04:20.000000 coremltools-6.3.0/coremltools/test/xgboost_tests/test_decision_tree_classifier.py
--rw-r--r--   0 nninfci    (501) staff       (20)     5041 2022-11-11 20:04:20.000000 coremltools-6.3.0/coremltools/test/xgboost_tests/test_decision_tree_classifier_numeric.py
--rw-r--r--   0 nninfci    (501) staff       (20)     2999 2022-11-11 20:04:20.000000 coremltools-6.3.0/coremltools/test/xgboost_tests/test_decision_tree_regression.py
--rw-r--r--   0 nninfci    (501) staff       (20)     3755 2022-11-11 20:04:20.000000 coremltools-6.3.0/coremltools/test/xgboost_tests/test_decision_tree_regression_numeric.py
--rw-r--r--   0 nninfci    (501) staff       (20)      257 2023-03-29 23:02:29.000000 coremltools-6.3.0/coremltools/version.py
-drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-03-29 23:17:29.000000 coremltools-6.3.0/coremltools.egg-info/
--rw-r--r--   0 nninfci    (501) staff       (20)     2163 2023-03-29 23:17:29.000000 coremltools-6.3.0/coremltools.egg-info/PKG-INFO
--rw-r--r--   0 nninfci    (501) staff       (20)    22477 2023-03-29 23:17:29.000000 coremltools-6.3.0/coremltools.egg-info/SOURCES.txt
--rw-r--r--   0 nninfci    (501) staff       (20)        1 2023-03-29 23:17:29.000000 coremltools-6.3.0/coremltools.egg-info/dependency_links.txt
--rw-r--r--   0 nninfci    (501) staff       (20)       59 2023-03-29 23:17:29.000000 coremltools-6.3.0/coremltools.egg-info/requires.txt
--rw-r--r--   0 nninfci    (501) staff       (20)       12 2023-03-29 23:17:29.000000 coremltools-6.3.0/coremltools.egg-info/top_level.txt
--rw-r--r--   0 nninfci    (501) staff       (20)       38 2023-03-29 23:17:30.000000 coremltools-6.3.0/setup.cfg
--rwxr-xr-x   0 nninfci    (501) staff       (20)     3180 2023-03-29 19:25:43.000000 coremltools-6.3.0/setup.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/
+-rw-r--r--   0 nninfci    (501) staff       (20)     1492 2023-06-03 22:35:30.000000 coremltools-7.0b1/LICENSE.txt
+-rw-r--r--   0 nninfci    (501) staff       (20)       17 2022-05-05 00:21:59.000000 coremltools-7.0b1/MANIFEST.in
+-rw-r--r--   0 nninfci    (501) staff       (20)     1254 2023-06-03 22:35:30.000000 coremltools-7.0b1/NOTICE.txt
+-rw-r--r--   0 nninfci    (501) staff       (20)     2239 2023-06-04 02:56:15.000000 coremltools-7.0b1/PKG-INFO
+-rw-r--r--   0 nninfci    (501) staff       (20)     3149 2023-02-26 04:34:08.000000 coremltools-7.0b1/README.md
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/
+-rw-r--r--   0 nninfci    (501) staff       (20)     4681 2023-04-19 03:33:46.000000 coremltools-7.0b1/coremltools/__init__.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/_deps/
+-rw-r--r--   0 nninfci    (501) staff       (20)     5832 2023-06-03 22:35:30.000000 coremltools-7.0b1/coremltools/_deps/__init__.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/converters/
+-rw-r--r--   0 nninfci    (501) staff       (20)      490 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    40308 2023-05-25 17:55:14.000000 coremltools-7.0b1/coremltools/converters/_converters_entry.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     2415 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/_profile_utils.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/converters/libsvm/
+-rw-r--r--   0 nninfci    (501) staff       (20)     3399 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/libsvm/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     7202 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/libsvm/_libsvm_converter.py
+-rw-r--r--   0 nninfci    (501) staff       (20)      971 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/libsvm/_libsvm_util.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/converters/mil/
+-rw-r--r--   0 nninfci    (501) staff       (20)      894 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     6094 2023-04-12 05:20:09.000000 coremltools-7.0b1/coremltools/converters/mil/_deployment_compatibility.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/converters/mil/backend/
+-rw-r--r--   0 nninfci    (501) staff       (20)      218 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/backend/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     3868 2023-02-22 21:54:31.000000 coremltools-7.0b1/coremltools/converters/mil/backend/backend_helper.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/converters/mil/backend/mil/
+-rw-r--r--   0 nninfci    (501) staff       (20)      218 2023-03-13 04:45:47.000000 coremltools-7.0b1/coremltools/converters/mil/backend/mil/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    13214 2023-05-27 07:22:35.000000 coremltools-7.0b1/coremltools/converters/mil/backend/mil/helper.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    24771 2023-05-25 17:55:14.000000 coremltools-7.0b1/coremltools/converters/mil/backend/mil/load.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/converters/mil/backend/mil/passes/
+-rw-r--r--   0 nninfci    (501) staff       (20)      355 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/backend/mil/passes/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    10115 2023-05-27 07:22:35.000000 coremltools-7.0b1/coremltools/converters/mil/backend/mil/passes/adjust_io_to_supported_types.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     2744 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/backend/mil/passes/fuse_activation_silu.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     3434 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/backend/mil/passes/insert_image_preprocessing_op.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     1014 2023-02-22 21:54:31.000000 coremltools-7.0b1/coremltools/converters/mil/backend/mil/passes/sanitize_name_strings.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    33517 2023-04-22 05:09:06.000000 coremltools-7.0b1/coremltools/converters/mil/backend/mil/passes/test_passes.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     1265 2023-02-22 21:54:31.000000 coremltools-7.0b1/coremltools/converters/mil/backend/mil/test_helper.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    14116 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/backend/mil/test_model_input_params.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/converters/mil/backend/nn/
+-rw-r--r--   0 nninfci    (501) staff       (20)      218 2023-03-13 04:45:47.000000 coremltools-7.0b1/coremltools/converters/mil/backend/nn/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    13539 2023-03-13 04:45:47.000000 coremltools-7.0b1/coremltools/converters/mil/backend/nn/load.py
+-rw-r--r--   0 nninfci    (501) staff       (20)      739 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/backend/nn/mil_to_nn_mapping_registry.py
+-rw-r--r--   0 nninfci    (501) staff       (20)   129885 2023-05-25 03:33:30.000000 coremltools-7.0b1/coremltools/converters/mil/backend/nn/op_mapping.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/converters/mil/backend/nn/passes/
+-rw-r--r--   0 nninfci    (501) staff       (20)      432 2023-02-27 07:55:23.000000 coremltools-7.0b1/coremltools/converters/mil/backend/nn/passes/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     1698 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/backend/nn/passes/alert_return_type_cast.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     2528 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/backend/nn/passes/commingle_loop_vars.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     3705 2023-02-27 07:55:23.000000 coremltools-7.0b1/coremltools/converters/mil/backend/nn/passes/conv1d_decomposition.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     2153 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/backend/nn/passes/handle_return_inputs_as_outputs.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     2086 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/backend/nn/passes/handle_return_unused_inputs.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     1641 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/backend/nn/passes/handle_unused_inputs.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    18489 2023-05-25 03:33:30.000000 coremltools-7.0b1/coremltools/converters/mil/backend/nn/passes/mlmodel_passes.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    37205 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/backend/nn/passes/test_mlmodel_passes.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     7734 2023-02-27 07:55:23.000000 coremltools-7.0b1/coremltools/converters/mil/backend/nn/passes/test_passes.py
+-rw-r--r--   0 nninfci    (501) staff       (20)      460 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/conftest.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    12452 2023-05-25 17:55:14.000000 coremltools-7.0b1/coremltools/converters/mil/converter.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     6967 2023-05-25 03:33:30.000000 coremltools-7.0b1/coremltools/converters/mil/debugging_utils.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/converters/mil/experimental/
+-rw-r--r--   0 nninfci    (501) staff       (20)      218 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/experimental/__init__.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/converters/mil/experimental/passes/
+-rw-r--r--   0 nninfci    (501) staff       (20)    31488 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/experimental/passes/README.md
+-rw-r--r--   0 nninfci    (501) staff       (20)      218 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/experimental/passes/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     6064 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/experimental/passes/generic_conv_batchnorm_fusion.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    12523 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/experimental/passes/generic_conv_bias_fusion.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     8575 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/experimental/passes/generic_conv_scale_fusion.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    21031 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/experimental/passes/generic_layernorm_instancenorm_pattern_fusion.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     4994 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/experimental/passes/generic_linear_bias_fusion.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    10005 2023-05-25 07:26:59.000000 coremltools-7.0b1/coremltools/converters/mil/experimental/passes/generic_pass_infrastructure.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/
+-rw-r--r--   0 nninfci    (501) staff       (20)      264 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    15910 2023-04-19 03:33:46.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/_utils.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/milproto/
+-rw-r--r--   0 nninfci    (501) staff       (20)      239 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/milproto/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     2434 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/milproto/helper.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    17349 2023-05-19 03:34:22.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/milproto/load.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    10191 2023-05-12 03:33:31.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/milproto/test_load.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/
+-rw-r--r--   0 nninfci    (501) staff       (20)      762 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    10999 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/basic_graph_ops.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     7497 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/convert_utils.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    21705 2023-03-13 04:45:47.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/converter.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     6464 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/dialect_ops.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     4544 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/dot_visitor.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    12848 2023-03-13 04:45:47.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/load.py
+-rw-r--r--   0 nninfci    (501) staff       (20)      993 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/naming_utils.py
+-rw-r--r--   0 nninfci    (501) staff       (20)   123991 2023-06-03 03:33:56.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/ops.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     4082 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/parse.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     3234 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/parsed_tf_node.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/ssa_passes/
+-rw-r--r--   0 nninfci    (501) staff       (20)      300 2023-03-13 04:45:47.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/ssa_passes/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     4788 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/ssa_passes/backfill_make_list_elem_type.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     7617 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/ssa_passes/expand_tf_lstm.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     2071 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/ssa_passes/test_passes.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    12437 2023-02-22 21:54:31.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/ssa_passes/tf_lstm_to_core_lstm.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/test/
+-rw-r--r--   0 nninfci    (501) staff       (20)      218 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/test/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     2415 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/test/test_composite_ops.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    11068 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/test/test_custom_ops.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     1463 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/test/test_graphs.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    16127 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/test/test_load.py
+-rw-r--r--   0 nninfci    (501) staff       (20)   264008 2023-06-03 03:33:56.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/test/test_ops.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     5013 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/test/test_parse.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     2187 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/test/test_parsed_tf_node.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    40922 2023-05-25 17:55:14.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/test/test_tf_conversion_api.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    15119 2023-05-25 17:55:14.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/test/testing_utils.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/
+-rw-r--r--   0 nninfci    (501) staff       (20)      847 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     4377 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/cond_to_where.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     6880 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/constant_propagation.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     2386 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/delete_asserts.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     3059 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/delete_constant.py
+-rw-r--r--   0 nninfci    (501) staff       (20)      669 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/delete_disconnected_nodes.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    19047 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/functionalize_loops.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     7675 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/fuse_dilation_conv.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     3398 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/insert_get_tuple.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     2966 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/quantization_pass.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     3649 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/tensor_array_transform.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     2898 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/variable_node_transform.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     6425 2023-05-25 03:33:30.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/visitors.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     1769 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/tf_op_registry.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    21046 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/tfssa.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow2/
+-rw-r--r--   0 nninfci    (501) staff       (20)      455 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow2/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     1540 2023-03-13 04:45:47.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow2/converter.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    14758 2023-05-25 17:55:14.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow2/load.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     8460 2023-01-26 00:23:38.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow2/ops.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow2/ssa_passes/
+-rw-r--r--   0 nninfci    (501) staff       (20)      253 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow2/ssa_passes/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     4645 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow2/ssa_passes/remove_vacuous_cond.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     1850 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow2/ssa_passes/test_v2_passes.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow2/test/
+-rw-r--r--   0 nninfci    (501) staff       (20)      218 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow2/test/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    17464 2023-05-25 17:55:14.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow2/test/test_tf2_conversion_api.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     8392 2023-05-25 17:55:14.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow2/test/test_v2_load.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    25555 2023-01-26 00:23:38.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow2/test/test_v2_ops.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    60734 2023-05-25 17:55:14.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow2/test/test_v2_ops_tf_keras.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    10337 2023-05-25 17:55:14.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow2/test/testing_utils.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow2/tf_graph_pass/
+-rw-r--r--   0 nninfci    (501) staff       (20)      371 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow2/tf_graph_pass/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    20086 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow2/tf_graph_pass/rewrite_control_flow_functions.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/torch/
+-rw-r--r--   0 nninfci    (501) staff       (20)      534 2023-05-04 03:33:50.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/torch/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    27623 2023-04-26 03:33:32.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/torch/converter.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     8408 2023-03-31 05:11:17.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/torch/dialect_ops.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    12949 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/torch/internal_graph.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     4629 2023-03-13 04:45:47.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/torch/load.py
+-rw-r--r--   0 nninfci    (501) staff       (20)   204308 2023-06-03 03:33:56.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/torch/ops.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    11113 2023-04-26 03:33:32.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/torch/quantization_ops.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/torch/ssa_passes/
+-rw-r--r--   0 nninfci    (501) staff       (20)      294 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/torch/ssa_passes/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     2582 2023-03-31 05:11:17.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/torch/ssa_passes/torch_tensor_assign_to_core.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     4525 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/torch/ssa_passes/torch_upsample_to_core_upsample.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/torch/test/
+-rw-r--r--   0 nninfci    (501) staff       (20)      218 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/torch/test/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     1753 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/torch/test/test_api.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     5626 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/torch/test/test_custom_ops.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     1880 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/torch/test/test_examples.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    66729 2023-03-31 05:11:17.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/torch/test/test_internal_graph.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    12355 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/torch/test/test_passes.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    70726 2023-05-25 17:55:14.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/torch/test/test_torch_conversion_api.py
+-rw-r--r--   0 nninfci    (501) staff       (20)   307400 2023-06-03 03:33:56.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/torch/test/test_torch_ops.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    10824 2023-04-26 03:33:32.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/torch/test/test_torch_quantization_ops.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     9048 2023-05-12 03:33:31.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/torch/test/testing_utils.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     2276 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/torch/torch_op_registry.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    12932 2023-03-31 05:11:17.000000 coremltools-7.0b1/coremltools/converters/mil/frontend/torch/torchir_passes.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    18414 2023-05-25 17:55:14.000000 coremltools-7.0b1/coremltools/converters/mil/input_types.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/converters/mil/mil/
+-rw-r--r--   0 nninfci    (501) staff       (20)      833 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/mil/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    32464 2023-06-01 03:33:47.000000 coremltools-7.0b1/coremltools/converters/mil/mil/block.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     8906 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/mil/builder.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    11740 2023-05-25 03:33:30.000000 coremltools-7.0b1/coremltools/converters/mil/mil/input_type.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    22435 2023-04-22 05:09:06.000000 coremltools-7.0b1/coremltools/converters/mil/mil/operation.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/
+-rw-r--r--   0 nninfci    (501) staff       (20)      218 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/__init__.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/
+-rw-r--r--   0 nninfci    (501) staff       (20)      274 2023-04-12 05:20:09.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)      354 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/_op_reqs.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    22494 2023-06-03 03:33:56.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/_utils.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    30537 2023-05-25 03:33:30.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/complex_dialect_ops.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS15/
+-rw-r--r--   0 nninfci    (501) staff       (20)     3183 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS15/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    15369 2023-05-25 03:33:30.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS15/activation.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     3283 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS15/classify.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    28851 2023-06-03 03:33:56.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS15/control_flow.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    16798 2023-02-14 01:10:26.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS15/conv.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    14998 2023-06-03 03:33:56.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS15/elementwise_binary.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    20583 2023-04-22 05:09:06.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS15/elementwise_unary.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    34230 2023-05-25 03:33:30.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS15/image_resizing.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    12377 2023-03-31 05:11:17.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS15/linear.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    12595 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS15/normalization.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     9122 2023-02-03 00:46:23.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS15/pool.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     9058 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS15/random.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    21478 2023-04-07 04:05:33.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS15/recurrent.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    14774 2023-05-19 03:34:22.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS15/reduction.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    16508 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS15/scatter_gather.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    42393 2023-05-25 03:33:30.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS15/tensor_operation.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    36806 2023-04-12 05:20:09.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS15/tensor_transformation.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS16/
+-rw-r--r--   0 nninfci    (501) staff       (20)      725 2023-06-01 03:33:47.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS16/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    14437 2023-06-01 03:33:47.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS16/constexpr_ops.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     3545 2023-05-25 03:33:30.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS16/image_resizing.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     6101 2023-05-25 03:33:30.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS16/scatter_gather.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     3927 2023-05-25 03:33:30.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS16/tensor_operation.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     6962 2023-05-25 03:33:30.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS16/tensor_transformation.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS17/
+-rw-r--r--   0 nninfci    (501) staff       (20)      951 2023-05-19 03:34:22.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS17/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     9872 2023-05-25 03:33:30.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS17/activation.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     3350 2023-05-25 03:33:30.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS17/elementwise_unary.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     8618 2023-05-25 03:33:30.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS17/image_resizing.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     9750 2023-05-25 03:33:30.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS17/quantization_ops.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     4113 2023-05-25 03:33:30.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS17/reduction.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    17470 2023-05-25 03:33:30.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS17/scatter_gather.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     5751 2023-05-25 03:33:30.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS17/tensor_operation.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     4053 2023-05-25 03:33:30.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS17/tensor_transformation.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     1065 2023-04-19 03:33:46.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/helper.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     8933 2023-04-12 05:20:09.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/registry.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/tests/
+-rw-r--r--   0 nninfci    (501) staff       (20)      218 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/tests/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    42410 2023-04-19 03:33:46.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/tests/test_activation.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     1851 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/tests/test_const.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    22658 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/tests/test_constexpr_ops.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    16020 2023-06-03 03:33:56.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/tests/test_control_flow.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    30760 2023-02-14 01:10:26.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/tests/test_conv.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    21099 2022-12-22 20:15:26.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/tests/test_elementwise_binary.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    28099 2023-04-22 05:09:06.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/tests/test_elementwise_unary.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    36559 2023-05-11 21:49:53.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/tests/test_image_resizing.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    12430 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/tests/test_linear.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    26131 2023-05-25 17:55:14.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/tests/test_normalization.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    17261 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/tests/test_pool.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    17158 2023-04-12 05:20:09.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/tests/test_quantization.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    14861 2022-12-22 20:15:26.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/tests/test_random.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    27892 2023-05-25 17:55:14.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/tests/test_recurrent.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    15515 2023-05-19 03:34:22.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/tests/test_reduction.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    46996 2023-06-03 22:35:30.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/tests/test_scatter_gather.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    14399 2023-05-26 07:17:14.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/tests/test_slice.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    60065 2023-05-25 17:55:14.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/tests/test_tensor_operation.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    52757 2023-05-25 17:55:14.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/tests/test_tensor_transformation.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     8055 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/tests/test_utils.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     6513 2023-05-25 17:55:14.000000 coremltools-7.0b1/coremltools/converters/mil/mil/ops/tests/testing_utils.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/converters/mil/mil/passes/
+-rw-r--r--   0 nninfci    (501) staff       (20)     1442 2023-05-04 03:33:50.000000 coremltools-7.0b1/coremltools/converters/mil/mil/passes/__init__.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/converters/mil/mil/passes/defs/
+-rw-r--r--   0 nninfci    (501) staff       (20)      218 2023-02-22 21:54:31.000000 coremltools-7.0b1/coremltools/converters/mil/mil/passes/defs/__init__.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/converters/mil/mil/passes/defs/cleanup/
+-rw-r--r--   0 nninfci    (501) staff       (20)      767 2023-05-25 03:33:30.000000 coremltools-7.0b1/coremltools/converters/mil/mil/passes/defs/cleanup/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     5135 2023-05-26 07:17:14.000000 coremltools-7.0b1/coremltools/converters/mil/mil/passes/defs/cleanup/const_deduplication.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     4797 2023-04-20 02:26:37.000000 coremltools-7.0b1/coremltools/converters/mil/mil/passes/defs/cleanup/const_elimination.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     2902 2023-03-31 05:11:17.000000 coremltools-7.0b1/coremltools/converters/mil/mil/passes/defs/cleanup/dead_code_elimination.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     3833 2023-02-22 21:54:31.000000 coremltools-7.0b1/coremltools/converters/mil/mil/passes/defs/cleanup/dedup_op_and_var_names.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     4450 2023-04-07 04:05:33.000000 coremltools-7.0b1/coremltools/converters/mil/mil/passes/defs/cleanup/fuse_reduce_mean.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     6930 2023-02-22 21:54:31.000000 coremltools-7.0b1/coremltools/converters/mil/mil/passes/defs/cleanup/loop_invariant_elimination.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     7962 2023-03-31 05:11:17.000000 coremltools-7.0b1/coremltools/converters/mil/mil/passes/defs/cleanup/noop_elimination.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     8515 2023-04-22 05:09:06.000000 coremltools-7.0b1/coremltools/converters/mil/mil/passes/defs/cleanup/remove_redundant_ops.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     3848 2023-03-31 05:11:17.000000 coremltools-7.0b1/coremltools/converters/mil/mil/passes/defs/cleanup/remove_symbolic_reshape.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     7620 2023-03-31 05:11:18.000000 coremltools-7.0b1/coremltools/converters/mil/mil/passes/defs/cleanup/topological_reorder.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    26697 2023-05-25 03:33:30.000000 coremltools-7.0b1/coremltools/converters/mil/mil/passes/defs/lower_complex_dialect_ops.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    26258 2023-05-15 17:56:11.000000 coremltools-7.0b1/coremltools/converters/mil/mil/passes/defs/optimize_activation.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    41725 2023-05-25 03:33:30.000000 coremltools-7.0b1/coremltools/converters/mil/mil/passes/defs/optimize_conv.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    11735 2023-04-07 04:05:33.000000 coremltools-7.0b1/coremltools/converters/mil/mil/passes/defs/optimize_elementwise_binary.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    11330 2023-03-31 05:11:18.000000 coremltools-7.0b1/coremltools/converters/mil/mil/passes/defs/optimize_linear.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    34582 2023-05-25 03:33:30.000000 coremltools-7.0b1/coremltools/converters/mil/mil/passes/defs/optimize_normalization.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    23175 2023-06-01 03:33:47.000000 coremltools-7.0b1/coremltools/converters/mil/mil/passes/defs/optimize_quantization.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    72694 2023-03-31 05:11:18.000000 coremltools-7.0b1/coremltools/converters/mil/mil/passes/defs/optimize_repeat_ops.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    30535 2023-05-11 21:49:53.000000 coremltools-7.0b1/coremltools/converters/mil/mil/passes/defs/optimize_tensor_operation.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    15254 2023-03-31 05:11:18.000000 coremltools-7.0b1/coremltools/converters/mil/mil/passes/defs/preprocess.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    13281 2023-06-03 03:33:56.000000 coremltools-7.0b1/coremltools/converters/mil/mil/passes/defs/quantization.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     2384 2023-04-19 03:33:46.000000 coremltools-7.0b1/coremltools/converters/mil/mil/passes/graph_pass.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     5940 2023-04-19 03:33:46.000000 coremltools-7.0b1/coremltools/converters/mil/mil/passes/helper.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    18556 2023-06-01 03:33:47.000000 coremltools-7.0b1/coremltools/converters/mil/mil/passes/pass_pipeline.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     2275 2023-03-13 04:45:47.000000 coremltools-7.0b1/coremltools/converters/mil/mil/passes/pass_registry.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/converters/mil/mil/passes/tests/
+-rw-r--r--   0 nninfci    (501) staff       (20)      218 2023-02-22 21:54:31.000000 coremltools-7.0b1/coremltools/converters/mil/mil/passes/tests/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     3306 2023-05-25 03:33:30.000000 coremltools-7.0b1/coremltools/converters/mil/mil/passes/tests/test_lower_complex_dialect_ops.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     4996 2023-04-19 03:33:46.000000 coremltools-7.0b1/coremltools/converters/mil/mil/passes/tests/test_pass_pipeline.py
+-rw-r--r--   0 nninfci    (501) staff       (20)   267772 2023-05-26 07:17:14.000000 coremltools-7.0b1/coremltools/converters/mil/mil/passes/tests/test_passes.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    63223 2023-06-03 22:35:30.000000 coremltools-7.0b1/coremltools/converters/mil/mil/passes/tests/test_quantization_passes.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    78845 2023-02-22 21:54:31.000000 coremltools-7.0b1/coremltools/converters/mil/mil/passes/tests/test_reduce_transposes_pass.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    11212 2023-04-19 03:33:46.000000 coremltools-7.0b1/coremltools/converters/mil/mil/program.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/converters/mil/mil/tests/
+-rw-r--r--   0 nninfci    (501) staff       (20)      217 2023-02-14 01:10:26.000000 coremltools-7.0b1/coremltools/converters/mil/mil/tests/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    15736 2023-02-22 21:54:31.000000 coremltools-7.0b1/coremltools/converters/mil/mil/tests/test_block.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    10605 2023-02-28 10:17:49.000000 coremltools-7.0b1/coremltools/converters/mil/mil/tests/test_debug.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    13736 2023-05-12 03:33:31.000000 coremltools-7.0b1/coremltools/converters/mil/mil/tests/test_programs.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     1085 2023-03-09 06:42:23.000000 coremltools-7.0b1/coremltools/converters/mil/mil/tests/test_types.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/converters/mil/mil/types/
+-rw-r--r--   0 nninfci    (501) staff       (20)     1634 2023-06-03 03:33:56.000000 coremltools-7.0b1/coremltools/converters/mil/mil/types/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     3411 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/mil/types/annotate.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     2123 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/mil/types/get_type_info.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     1468 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/mil/types/global_methods.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     2160 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/mil/types/symbolic.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     1230 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/mil/types/type_bool.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     5705 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/mil/types/type_complex.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     1665 2023-02-03 00:46:23.000000 coremltools-7.0b1/coremltools/converters/mil/mil/types/type_dict.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     5119 2023-03-31 05:11:18.000000 coremltools-7.0b1/coremltools/converters/mil/mil/types/type_double.py
+-rw-r--r--   0 nninfci    (501) staff       (20)      370 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/mil/types/type_globals_pseudo_type.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     5329 2023-04-19 03:33:46.000000 coremltools-7.0b1/coremltools/converters/mil/mil/types/type_int.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     1974 2023-02-03 00:46:23.000000 coremltools-7.0b1/coremltools/converters/mil/mil/types/type_list.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    12909 2023-04-22 05:09:06.000000 coremltools-7.0b1/coremltools/converters/mil/mil/types/type_mapping.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     2994 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/mil/types/type_spec.py
+-rw-r--r--   0 nninfci    (501) staff       (20)      641 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/mil/types/type_str.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     6095 2023-06-03 03:33:56.000000 coremltools-7.0b1/coremltools/converters/mil/mil/types/type_tensor.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     1263 2023-02-03 00:46:23.000000 coremltools-7.0b1/coremltools/converters/mil/mil/types/type_tuple.py
+-rw-r--r--   0 nninfci    (501) staff       (20)      468 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/mil/types/type_unknown.py
+-rw-r--r--   0 nninfci    (501) staff       (20)      352 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/mil/types/type_void.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    12468 2023-01-26 00:23:38.000000 coremltools-7.0b1/coremltools/converters/mil/mil/var.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/converters/mil/mil/visitors/
+-rw-r--r--   0 nninfci    (501) staff       (20)      218 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/mil/visitors/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     6100 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/mil/mil/visitors/dot_visitor.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    26006 2023-05-25 17:55:14.000000 coremltools-7.0b1/coremltools/converters/mil/test_flexible_shape_inputs.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     1871 2023-05-24 05:06:52.000000 coremltools-7.0b1/coremltools/converters/mil/testing_reqs.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    21917 2023-05-25 17:55:14.000000 coremltools-7.0b1/coremltools/converters/mil/testing_utils.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/converters/sklearn/
+-rw-r--r--   0 nninfci    (501) staff       (20)     1500 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/sklearn/_LinearSVC.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     1405 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/sklearn/_LinearSVR.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     1882 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/sklearn/_NuSVC.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     1458 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/sklearn/_NuSVR.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     4021 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/sklearn/_SVC.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     2372 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/sklearn/_SVR.py
+-rw-r--r--   0 nninfci    (501) staff       (20)      294 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/sklearn/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     5912 2023-02-03 00:46:23.000000 coremltools-7.0b1/coremltools/converters/sklearn/_converter.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    12902 2023-02-03 00:46:23.000000 coremltools-7.0b1/coremltools/converters/sklearn/_converter_internal.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     1684 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/sklearn/_decision_tree_classifier.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     1442 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/sklearn/_decision_tree_regressor.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     3581 2023-05-25 03:33:30.000000 coremltools-7.0b1/coremltools/converters/sklearn/_dict_vectorizer.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     3369 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/sklearn/_gradient_boosting_classifier.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     2246 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/sklearn/_gradient_boosting_regressor.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     3417 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/sklearn/_imputer.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     9525 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/sklearn/_k_neighbors_classifier.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     2376 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/sklearn/_linear_regression.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     3120 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/sklearn/_logistic_regression.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     2315 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/sklearn/_normalizer.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     9933 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/sklearn/_one_hot_encoder.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     1916 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/sklearn/_random_forest_classifier.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     1710 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/sklearn/_random_forest_regressor.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     1422 2023-02-03 00:46:23.000000 coremltools-7.0b1/coremltools/converters/sklearn/_ridge_regression.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     1032 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/sklearn/_sklearn_util.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     2626 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/sklearn/_standard_scaler.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     1210 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/sklearn/_svm_common.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     7783 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/sklearn/_tree_ensemble.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/converters/xgboost/
+-rw-r--r--   0 nninfci    (501) staff       (20)      243 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/xgboost/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     2760 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/xgboost/_tree.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     9537 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/converters/xgboost/_tree_ensemble.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/models/
+-rw-r--r--   0 nninfci    (501) staff       (20)     1049 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/models/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     1144 2023-04-19 03:33:46.000000 coremltools-7.0b1/coremltools/models/_deprecation.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    11762 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/models/_feature_management.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     7068 2023-03-31 05:11:18.000000 coremltools-7.0b1/coremltools/models/_interface_management.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     2018 2023-02-03 00:46:23.000000 coremltools-7.0b1/coremltools/models/array_feature_extractor.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     6761 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/models/datatypes.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     3718 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/models/feature_vectorizer.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/models/ml_program/
+-rw-r--r--   0 nninfci    (501) staff       (20)      247 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/models/ml_program/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     4473 2023-04-27 02:41:28.000000 coremltools-7.0b1/coremltools/models/ml_program/compression_utils.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    28392 2023-05-25 17:55:14.000000 coremltools-7.0b1/coremltools/models/model.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/models/nearest_neighbors/
+-rw-r--r--   0 nninfci    (501) staff       (20)      272 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/models/nearest_neighbors/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    21314 2023-05-25 03:33:30.000000 coremltools-7.0b1/coremltools/models/nearest_neighbors/builder.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/models/neural_network/
+-rw-r--r--   0 nninfci    (501) staff       (20)      486 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/models/neural_network/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)   338367 2023-05-25 03:33:30.000000 coremltools-7.0b1/coremltools/models/neural_network/builder.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    27323 2023-02-03 00:46:23.000000 coremltools-7.0b1/coremltools/models/neural_network/flexible_shape_utils.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     8194 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/models/neural_network/optimization_utils.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     3748 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/models/neural_network/printer.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    58341 2023-06-03 22:35:30.000000 coremltools-7.0b1/coremltools/models/neural_network/quantization_utils.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    10772 2023-05-25 03:33:30.000000 coremltools-7.0b1/coremltools/models/neural_network/spec_inspection_utils.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     4775 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/models/neural_network/update_optimizer_utils.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     3967 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/models/neural_network/utils.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    10916 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/models/pipeline.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    15764 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/models/tree_ensemble.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    33653 2023-05-25 03:33:30.000000 coremltools-7.0b1/coremltools/models/utils.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/optimize/
+-rw-r--r--   0 nninfci    (501) staff       (20)      240 2023-04-19 03:33:46.000000 coremltools-7.0b1/coremltools/optimize/__init__.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/optimize/coreml/
+-rw-r--r--   0 nninfci    (501) staff       (20)      502 2023-04-27 02:41:28.000000 coremltools-7.0b1/coremltools/optimize/coreml/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    39395 2023-06-03 22:35:30.000000 coremltools-7.0b1/coremltools/optimize/coreml/_config.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    13232 2023-06-03 03:33:56.000000 coremltools-7.0b1/coremltools/optimize/coreml/_post_training_quantization.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    30397 2023-06-03 03:33:56.000000 coremltools-7.0b1/coremltools/optimize/coreml/_quantization_passes.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/optimize/torch/
+-rw-r--r--   0 nninfci    (501) staff       (20)      455 2023-05-17 17:04:22.000000 coremltools-7.0b1/coremltools/optimize/torch/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     1472 2023-05-17 17:04:22.000000 coremltools-7.0b1/coremltools/optimize/torch/_logging.py
+-rw-r--r--   0 nninfci    (501) staff       (20)      438 2023-05-17 17:04:22.000000 coremltools-7.0b1/coremltools/optimize/torch/_typing.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/optimize/torch/_utils/
+-rw-r--r--   0 nninfci    (501) staff       (20)      218 2023-05-17 17:04:22.000000 coremltools-7.0b1/coremltools/optimize/torch/_utils/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)      324 2023-05-17 17:04:22.000000 coremltools-7.0b1/coremltools/optimize/torch/_utils/math_utils.py
+-rw-r--r--   0 nninfci    (501) staff       (20)      355 2023-05-17 17:04:22.000000 coremltools-7.0b1/coremltools/optimize/torch/_utils/python_utils.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     2228 2023-05-17 17:04:22.000000 coremltools-7.0b1/coremltools/optimize/torch/_utils/state_dict_utils.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     3080 2023-06-03 03:33:56.000000 coremltools-7.0b1/coremltools/optimize/torch/_utils/torch_utils.py
+-rw-r--r--   0 nninfci    (501) staff       (20)      508 2023-05-17 17:04:22.000000 coremltools-7.0b1/coremltools/optimize/torch/_utils/version_utils.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     2413 2023-05-17 17:04:22.000000 coremltools-7.0b1/coremltools/optimize/torch/base_model_optimizer.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     8814 2023-06-03 22:35:30.000000 coremltools-7.0b1/coremltools/optimize/torch/optimization_config.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/optimize/torch/palettization/
+-rw-r--r--   0 nninfci    (501) staff       (20)     1116 2023-05-17 17:04:22.000000 coremltools-7.0b1/coremltools/optimize/torch/palettization/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    11467 2023-06-03 03:33:56.000000 coremltools-7.0b1/coremltools/optimize/torch/palettization/_custom_conversion.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    13026 2023-05-17 17:04:22.000000 coremltools-7.0b1/coremltools/optimize/torch/palettization/_efficient_kmeans.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     3794 2023-05-17 17:04:22.000000 coremltools-7.0b1/coremltools/optimize/torch/palettization/_fake_palettizer_tensor_hook.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     7167 2023-05-17 17:04:22.000000 coremltools-7.0b1/coremltools/optimize/torch/palettization/_partitioner.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     9938 2023-06-03 22:35:30.000000 coremltools-7.0b1/coremltools/optimize/torch/palettization/_supported_modules.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    19624 2023-06-03 22:35:30.000000 coremltools-7.0b1/coremltools/optimize/torch/palettization/fake_palettize.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    16820 2023-06-03 22:35:30.000000 coremltools-7.0b1/coremltools/optimize/torch/palettization/palettization_config.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    13047 2023-06-03 03:33:56.000000 coremltools-7.0b1/coremltools/optimize/torch/palettization/palettizer.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/optimize/torch/pruning/
+-rw-r--r--   0 nninfci    (501) staff       (20)     1775 2023-06-03 03:33:56.000000 coremltools-7.0b1/coremltools/optimize/torch/pruning/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     5129 2023-05-17 17:04:22.000000 coremltools-7.0b1/coremltools/optimize/torch/pruning/_base_pruner.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    13035 2023-06-03 22:35:30.000000 coremltools-7.0b1/coremltools/optimize/torch/pruning/_base_pruning_method.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     9509 2023-05-17 17:04:22.000000 coremltools-7.0b1/coremltools/optimize/torch/pruning/_utils.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    17728 2023-06-03 22:35:30.000000 coremltools-7.0b1/coremltools/optimize/torch/pruning/magnitude_pruner.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     5587 2023-06-03 03:33:56.000000 coremltools-7.0b1/coremltools/optimize/torch/pruning/pruning_scheduler.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/optimize/torch/quantization/
+-rw-r--r--   0 nninfci    (501) staff       (20)     1380 2023-05-17 17:04:22.000000 coremltools-7.0b1/coremltools/optimize/torch/quantization/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    23278 2023-06-03 03:33:56.000000 coremltools-7.0b1/coremltools/optimize/torch/quantization/_backend_config.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    14123 2023-06-03 03:33:56.000000 coremltools-7.0b1/coremltools/optimize/torch/quantization/_backend_config_utils.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    19603 2023-06-03 03:33:56.000000 coremltools-7.0b1/coremltools/optimize/torch/quantization/_configure.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     8734 2023-06-03 03:33:56.000000 coremltools-7.0b1/coremltools/optimize/torch/quantization/_qconfig_mapping.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     4373 2023-06-03 03:33:56.000000 coremltools-7.0b1/coremltools/optimize/torch/quantization/_utils.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/optimize/torch/quantization/modules/
+-rw-r--r--   0 nninfci    (501) staff       (20)      218 2023-05-17 17:04:22.000000 coremltools-7.0b1/coremltools/optimize/torch/quantization/modules/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     1544 2023-06-03 03:33:56.000000 coremltools-7.0b1/coremltools/optimize/torch/quantization/modules/fused_modules.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     5412 2023-06-03 03:33:56.000000 coremltools-7.0b1/coremltools/optimize/torch/quantization/modules/qat_modules.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     1757 2023-06-03 03:33:56.000000 coremltools-7.0b1/coremltools/optimize/torch/quantization/modules/quantized_modules.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    11096 2023-06-03 03:33:56.000000 coremltools-7.0b1/coremltools/optimize/torch/quantization/quantization_config.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    11379 2023-06-03 22:35:30.000000 coremltools-7.0b1/coremltools/optimize/torch/quantization/quantizer.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/proto/
+-rw-r--r--   0 nninfci    (501) staff       (20)     2269 2023-02-03 01:37:24.000000 coremltools-7.0b1/coremltools/proto/ArrayFeatureExtractor_pb2.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     5197 2023-02-03 01:37:24.000000 coremltools-7.0b1/coremltools/proto/AudioFeaturePrint_pb2.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    13073 2023-02-03 01:37:24.000000 coremltools-7.0b1/coremltools/proto/BayesianProbitRegressor_pb2.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     5556 2023-02-03 01:37:24.000000 coremltools-7.0b1/coremltools/proto/CategoricalMapping_pb2.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     2940 2023-02-03 01:37:24.000000 coremltools-7.0b1/coremltools/proto/ClassConfidenceThresholding_pb2.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    10557 2023-02-03 01:37:24.000000 coremltools-7.0b1/coremltools/proto/CustomModel_pb2.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    25856 2023-02-03 01:37:24.000000 coremltools-7.0b1/coremltools/proto/DataStructures_pb2.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     3817 2023-02-03 01:37:24.000000 coremltools-7.0b1/coremltools/proto/DictVectorizer_pb2.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    38649 2023-02-03 01:37:24.000000 coremltools-7.0b1/coremltools/proto/FeatureTypes_pb2.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     4119 2023-02-03 01:37:24.000000 coremltools-7.0b1/coremltools/proto/FeatureVectorizer_pb2.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     8780 2023-02-03 01:37:24.000000 coremltools-7.0b1/coremltools/proto/GLMClassifier_pb2.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     5431 2023-02-03 01:37:24.000000 coremltools-7.0b1/coremltools/proto/GLMRegressor_pb2.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     4337 2023-02-03 01:37:24.000000 coremltools-7.0b1/coremltools/proto/Gazetteer_pb2.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     1655 2023-02-03 01:37:24.000000 coremltools-7.0b1/coremltools/proto/Identity_pb2.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     9310 2023-02-03 01:37:24.000000 coremltools-7.0b1/coremltools/proto/Imputer_pb2.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    11274 2023-02-03 01:37:24.000000 coremltools-7.0b1/coremltools/proto/ItemSimilarityRecommender_pb2.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     5073 2023-02-03 01:37:24.000000 coremltools-7.0b1/coremltools/proto/LinkedModel_pb2.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    83751 2023-02-03 01:37:24.000000 coremltools-7.0b1/coremltools/proto/MIL_pb2.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    59302 2023-02-03 01:37:24.000000 coremltools-7.0b1/coremltools/proto/Model_pb2.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    14471 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/proto/NamedParameters_pb2.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    18991 2023-02-03 01:37:24.000000 coremltools-7.0b1/coremltools/proto/NearestNeighbors_pb2.py
+-rw-r--r--   0 nninfci    (501) staff       (20)   552750 2023-02-03 01:37:24.000000 coremltools-7.0b1/coremltools/proto/NeuralNetwork_pb2.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    10172 2023-02-03 01:37:24.000000 coremltools-7.0b1/coremltools/proto/NonMaximumSuppression_pb2.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     3009 2023-02-03 01:37:24.000000 coremltools-7.0b1/coremltools/proto/Normalizer_pb2.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     5613 2023-02-03 01:37:24.000000 coremltools-7.0b1/coremltools/proto/OneHotEncoder_pb2.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     8731 2023-02-03 01:37:24.000000 coremltools-7.0b1/coremltools/proto/Parameters_pb2.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    29440 2023-02-03 01:37:24.000000 coremltools-7.0b1/coremltools/proto/SVM_pb2.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     2397 2023-02-03 01:37:24.000000 coremltools-7.0b1/coremltools/proto/Scaler_pb2.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     4090 2023-02-03 01:37:24.000000 coremltools-7.0b1/coremltools/proto/SoundAnalysisPreprocessing_pb2.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     4464 2023-02-03 01:37:24.000000 coremltools-7.0b1/coremltools/proto/TextClassifier_pb2.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    20559 2023-02-03 01:37:24.000000 coremltools-7.0b1/coremltools/proto/TreeEnsemble_pb2.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     9023 2023-04-19 03:33:46.000000 coremltools-7.0b1/coremltools/proto/VisionFeaturePrint_pb2.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     3417 2023-02-03 01:37:24.000000 coremltools-7.0b1/coremltools/proto/WordEmbedding_pb2.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     6177 2023-02-03 01:37:24.000000 coremltools-7.0b1/coremltools/proto/WordTagger_pb2.py
+-rw-r--r--   0 nninfci    (501) staff       (20)       44 2023-02-26 04:34:08.000000 coremltools-7.0b1/coremltools/proto/__init__.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/test/
+-rw-r--r--   0 nninfci    (501) staff       (20)      218 2022-05-05 00:21:59.000000 coremltools-7.0b1/coremltools/test/__init__.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/test/api/
+-rw-r--r--   0 nninfci    (501) staff       (20)      225 2022-05-05 00:21:59.000000 coremltools-7.0b1/coremltools/test/api/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    19717 2023-04-19 03:33:46.000000 coremltools-7.0b1/coremltools/test/api/test_api_examples.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     7630 2023-05-17 17:04:22.000000 coremltools-7.0b1/coremltools/test/api/test_api_visibilities.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/test/blob/
+-rw-r--r--   0 nninfci    (501) staff       (20)      225 2022-05-05 00:21:59.000000 coremltools-7.0b1/coremltools/test/blob/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     3333 2023-05-19 03:34:22.000000 coremltools-7.0b1/coremltools/test/blob/test_weights.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/test/ml_program/
+-rw-r--r--   0 nninfci    (501) staff       (20)      214 2022-05-14 03:49:19.000000 coremltools-7.0b1/coremltools/test/ml_program/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     5777 2023-04-19 03:33:46.000000 coremltools-7.0b1/coremltools/test/ml_program/test_compression.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/test/modelpackage/
+-rw-r--r--   0 nninfci    (501) staff       (20)      225 2022-05-05 00:21:59.000000 coremltools-7.0b1/coremltools/test/modelpackage/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     2137 2022-11-12 01:18:00.000000 coremltools-7.0b1/coremltools/test/modelpackage/test_mlmodel.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    22221 2023-05-25 03:33:30.000000 coremltools-7.0b1/coremltools/test/modelpackage/test_modelpackage.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/test/neural_network/
+-rw-r--r--   0 nninfci    (501) staff       (20)      215 2022-05-05 00:21:59.000000 coremltools-7.0b1/coremltools/test/neural_network/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     3321 2023-02-03 00:46:23.000000 coremltools-7.0b1/coremltools/test/neural_network/test_custom_neural_nets.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    22507 2022-12-22 20:15:26.000000 coremltools-7.0b1/coremltools/test/neural_network/test_model.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     2061 2022-11-12 01:18:00.000000 coremltools-7.0b1/coremltools/test/neural_network/test_neural_networks.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    24047 2022-11-12 01:18:00.000000 coremltools-7.0b1/coremltools/test/neural_network/test_nn_builder.py
+-rw-r--r--   0 nninfci    (501) staff       (20)   280978 2023-02-03 00:46:23.000000 coremltools-7.0b1/coremltools/test/neural_network/test_numpy_nn_layers.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    20667 2023-06-01 03:33:47.000000 coremltools-7.0b1/coremltools/test/neural_network/test_quantization.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     1780 2022-11-12 01:18:00.000000 coremltools-7.0b1/coremltools/test/neural_network/test_simple_nn_inference.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    19367 2022-11-12 01:18:00.000000 coremltools-7.0b1/coremltools/test/neural_network/test_tf_numeric.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/test/optimize/
+-rw-r--r--   0 nninfci    (501) staff       (20)      217 2023-04-19 03:33:46.000000 coremltools-7.0b1/coremltools/test/optimize/__init__.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/test/optimize/coreml/
+-rw-r--r--   0 nninfci    (501) staff       (20)      217 2023-04-19 03:33:46.000000 coremltools-7.0b1/coremltools/test/optimize/coreml/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    87643 2023-05-12 03:33:31.000000 coremltools-7.0b1/coremltools/test/optimize/coreml/test_passes.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    36815 2023-05-25 03:33:30.000000 coremltools-7.0b1/coremltools/test/optimize/coreml/test_post_training_quantization.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/test/optimize/torch/
+-rw-r--r--   0 nninfci    (501) staff       (20)      228 2023-05-17 17:04:22.000000 coremltools-7.0b1/coremltools/test/optimize/torch/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     1506 2023-06-03 22:35:30.000000 coremltools-7.0b1/coremltools/test/optimize/torch/conftest.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/test/optimize/torch/models/
+-rw-r--r--   0 nninfci    (501) staff       (20)      218 2023-05-17 17:04:22.000000 coremltools-7.0b1/coremltools/test/optimize/torch/models/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     3770 2023-05-17 17:04:22.000000 coremltools-7.0b1/coremltools/test/optimize/torch/models/mnist.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/test/optimize/torch/palettization/
+-rw-r--r--   0 nninfci    (501) staff       (20)      218 2023-05-17 17:04:22.000000 coremltools-7.0b1/coremltools/test/optimize/torch/palettization/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     1141 2023-05-17 17:04:22.000000 coremltools-7.0b1/coremltools/test/optimize/torch/palettization/palettization_utils.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    22417 2023-06-03 03:33:56.000000 coremltools-7.0b1/coremltools/test/optimize/torch/palettization/test_palettization_api.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/test/optimize/torch/pruning/
+-rw-r--r--   0 nninfci    (501) staff       (20)      218 2023-05-17 17:04:22.000000 coremltools-7.0b1/coremltools/test/optimize/torch/pruning/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     4190 2023-05-17 17:04:22.000000 coremltools-7.0b1/coremltools/test/optimize/torch/pruning/pruning_utils.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    20070 2023-06-03 03:33:56.000000 coremltools-7.0b1/coremltools/test/optimize/torch/pruning/test_magnitude_pruner.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     3421 2023-06-03 03:33:56.000000 coremltools-7.0b1/coremltools/test/optimize/torch/pruning/test_pruning_scheduler.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/test/optimize/torch/quantization/
+-rw-r--r--   0 nninfci    (501) staff       (20)      218 2023-05-17 17:04:22.000000 coremltools-7.0b1/coremltools/test/optimize/torch/quantization/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    28114 2023-06-03 03:33:56.000000 coremltools-7.0b1/coremltools/test/optimize/torch/quantization/test_configure.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     9034 2023-06-03 03:33:56.000000 coremltools-7.0b1/coremltools/test/optimize/torch/quantization/test_quantizer.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     4180 2023-05-17 17:04:22.000000 coremltools-7.0b1/coremltools/test/optimize/torch/test_api_surface.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     1070 2023-05-17 17:04:22.000000 coremltools-7.0b1/coremltools/test/optimize/torch/test_base_optimizer.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     1565 2023-05-17 17:04:22.000000 coremltools-7.0b1/coremltools/test/optimize/torch/utils.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/test/pipeline/
+-rw-r--r--   0 nninfci    (501) staff       (20)      215 2022-05-05 00:21:59.000000 coremltools-7.0b1/coremltools/test/pipeline/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    28313 2022-11-12 01:18:00.000000 coremltools-7.0b1/coremltools/test/pipeline/test_model_updatable.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    10299 2023-05-25 03:33:30.000000 coremltools-7.0b1/coremltools/test/pipeline/test_pipeline.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/test/sklearn_tests/
+-rw-r--r--   0 nninfci    (501) staff       (20)      215 2022-05-05 00:21:59.000000 coremltools-7.0b1/coremltools/test/sklearn_tests/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    11837 2022-11-12 01:18:00.000000 coremltools-7.0b1/coremltools/test/sklearn_tests/test_NuSVC.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     7381 2022-11-12 01:18:00.000000 coremltools-7.0b1/coremltools/test/sklearn_tests/test_NuSVR.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    14243 2022-11-12 01:18:00.000000 coremltools-7.0b1/coremltools/test/sklearn_tests/test_SVC.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     8747 2022-11-12 01:18:00.000000 coremltools-7.0b1/coremltools/test/sklearn_tests/test_SVR.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     2599 2022-11-12 01:18:00.000000 coremltools-7.0b1/coremltools/test/sklearn_tests/test_categorical_imputer.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     3064 2022-11-12 01:18:00.000000 coremltools-7.0b1/coremltools/test/sklearn_tests/test_composite_pipelines.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     3358 2022-11-12 01:18:00.000000 coremltools-7.0b1/coremltools/test/sklearn_tests/test_dict_vectorizer.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     1031 2022-11-12 01:18:00.000000 coremltools-7.0b1/coremltools/test/sklearn_tests/test_feature_names.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     4400 2022-11-12 01:18:00.000000 coremltools-7.0b1/coremltools/test/sklearn_tests/test_glm_classifier.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     2545 2022-11-12 01:18:00.000000 coremltools-7.0b1/coremltools/test/sklearn_tests/test_imputer.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    14446 2022-11-12 01:18:00.000000 coremltools-7.0b1/coremltools/test/sklearn_tests/test_io_types.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    11433 2022-11-12 01:18:00.000000 coremltools-7.0b1/coremltools/test/sklearn_tests/test_k_neighbors_classifier.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     5048 2022-11-12 01:18:00.000000 coremltools-7.0b1/coremltools/test/sklearn_tests/test_linear_regression.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    16089 2022-11-12 01:18:00.000000 coremltools-7.0b1/coremltools/test/sklearn_tests/test_nearest_neighbors_builder.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     1915 2022-11-12 01:18:00.000000 coremltools-7.0b1/coremltools/test/sklearn_tests/test_normalizer.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    10354 2022-11-12 01:18:00.000000 coremltools-7.0b1/coremltools/test/sklearn_tests/test_one_hot_encoder.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     6468 2022-11-12 01:18:00.000000 coremltools-7.0b1/coremltools/test/sklearn_tests/test_random_forest_classifier.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     5055 2022-11-12 01:18:00.000000 coremltools-7.0b1/coremltools/test/sklearn_tests/test_random_forest_classifier_numeric.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     3348 2022-11-12 01:18:00.000000 coremltools-7.0b1/coremltools/test/sklearn_tests/test_random_forest_regression.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     3690 2022-11-12 01:18:00.000000 coremltools-7.0b1/coremltools/test/sklearn_tests/test_random_forest_regression_numeric.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     3884 2023-02-03 00:46:23.000000 coremltools-7.0b1/coremltools/test/sklearn_tests/test_ridge_regression.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     1960 2022-11-12 01:18:00.000000 coremltools-7.0b1/coremltools/test/sklearn_tests/test_standard_scalar.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     1876 2022-11-12 01:18:00.000000 coremltools-7.0b1/coremltools/test/sklearn_tests/test_utils.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools/test/xgboost_tests/
+-rw-r--r--   0 nninfci    (501) staff       (20)      215 2022-05-05 00:21:59.000000 coremltools-7.0b1/coremltools/test/xgboost_tests/__init__.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    12175 2022-11-12 01:18:00.000000 coremltools-7.0b1/coremltools/test/xgboost_tests/test_boosted_trees_classifier.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     9737 2022-11-12 01:18:00.000000 coremltools-7.0b1/coremltools/test/xgboost_tests/test_boosted_trees_classifier_numeric.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     7876 2022-11-12 01:18:00.000000 coremltools-7.0b1/coremltools/test/xgboost_tests/test_boosted_trees_regression.py
+-rw-r--r--   0 nninfci    (501) staff       (20)    10997 2022-11-12 01:18:00.000000 coremltools-7.0b1/coremltools/test/xgboost_tests/test_boosted_trees_regression_numeric.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     5295 2022-11-12 01:18:00.000000 coremltools-7.0b1/coremltools/test/xgboost_tests/test_decision_tree_classifier.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     5041 2022-11-12 01:18:00.000000 coremltools-7.0b1/coremltools/test/xgboost_tests/test_decision_tree_classifier_numeric.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     2999 2022-11-12 01:18:00.000000 coremltools-7.0b1/coremltools/test/xgboost_tests/test_decision_tree_regression.py
+-rw-r--r--   0 nninfci    (501) staff       (20)     3755 2022-11-12 01:18:00.000000 coremltools-7.0b1/coremltools/test/xgboost_tests/test_decision_tree_regression_numeric.py
+-rw-r--r--   0 nninfci    (501) staff       (20)      257 2023-06-03 22:35:30.000000 coremltools-7.0b1/coremltools/version.py
+drwxr-xr-x   0 nninfci    (501) staff       (20)        0 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools.egg-info/
+-rw-r--r--   0 nninfci    (501) staff       (20)     2239 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools.egg-info/PKG-INFO
+-rw-r--r--   0 nninfci    (501) staff       (20)    26949 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools.egg-info/SOURCES.txt
+-rw-r--r--   0 nninfci    (501) staff       (20)        1 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools.egg-info/dependency_links.txt
+-rw-r--r--   0 nninfci    (501) staff       (20)       78 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools.egg-info/requires.txt
+-rw-r--r--   0 nninfci    (501) staff       (20)       12 2023-06-04 02:56:15.000000 coremltools-7.0b1/coremltools.egg-info/top_level.txt
+-rw-r--r--   0 nninfci    (501) staff       (20)       38 2023-06-04 02:56:15.000000 coremltools-7.0b1/setup.cfg
+-rwxr-xr-x   0 nninfci    (501) staff       (20)     3391 2023-06-01 03:33:47.000000 coremltools-7.0b1/setup.py
```

### Comparing `coremltools-6.3.0/LICENSE.txt` & `coremltools-7.0b1/LICENSE.txt`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-Copyright (c) 2020, Apple Inc. All rights reserved.
+Copyright © 2020-2023, Apple Inc. All rights reserved.
 
 Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:  
 
 1.  Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.
 
 2.  Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.
```

#### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

### Comparing `coremltools-6.3.0/PKG-INFO` & `coremltools-7.0b1/PKG-INFO`

 * *Files 3% similar despite different names*

```diff
@@ -1,26 +1,28 @@
 Metadata-Version: 2.1
 Name: coremltools
-Version: 6.3.0
+Version: 7.0b1
 Summary: Community Tools for Core ML
 Home-page: https://github.com/apple/coremltools
 Author: Apple Inc.
 Author-email: coremltools@apple.com
 License: BSD
 Classifier: Development Status :: 5 - Production/Stable
 Classifier: Intended Audience :: Developers
 Classifier: Operating System :: MacOS :: MacOS X
 Classifier: Operating System :: POSIX :: Linux
 Classifier: Programming Language :: Python :: 3.7
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
 Classifier: Programming Language :: Python :: 3.10
+Classifier: Programming Language :: Python :: 3.11
 Classifier: Topic :: Scientific/Engineering
 Classifier: Topic :: Software Development
 License-File: LICENSE.txt
+License-File: NOTICE.txt
 
 coremltools
 ===========
 
 `Core ML <http://developer.apple.com/documentation/coreml>`_
 is an Apple framework that allows developers to easily integrate
 machine learning (ML) models into apps. Core ML is available on iOS, iPadOS,
```

### Comparing `coremltools-6.3.0/README.md` & `coremltools-7.0b1/README.md`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/__init__.py` & `coremltools-7.0b1/coremltools/__init__.py`

 * *Files 4% similar despite different names*

```diff
@@ -56,14 +56,18 @@
 
 # New versions for iOS 15.0
 _SPECIFICATION_VERSION_IOS_15 = 6
 
 # New versions for iOS 16.0
 _SPECIFICATION_VERSION_IOS_16 = 7
 
+# New versions for iOS 17.0
+_SPECIFICATION_VERSION_IOS_17 = 8
+
+
 class ComputeUnit(_Enum):
     '''
     The set of processing-unit configurations the model can use to make predictions.
     '''
     ALL = 1  # Allows the model to use all compute units available, including the neural engine
     CPU_AND_GPU = 2 # Allows the model to use both the CPU and GPU, but not the neural engine
     CPU_ONLY = 3 # Limit the model to only use the CPU
@@ -72,23 +76,24 @@
 
 # A dictionary that maps the CoreML model specification version to the MLProgram/MIL opset string
 _OPSET = {
     _SPECIFICATION_VERSION_IOS_13: "CoreML3",
     _SPECIFICATION_VERSION_IOS_14: "CoreML4",
     _SPECIFICATION_VERSION_IOS_15: "CoreML5",
     _SPECIFICATION_VERSION_IOS_16: "CoreML6",
+    _SPECIFICATION_VERSION_IOS_17: "CoreML7",
 }
 
 # Default specification version for each backend
 _LOWEST_ALLOWED_SPECIFICATION_VERSION_FOR_NEURALNETWORK = _SPECIFICATION_VERSION_IOS_13
 _LOWEST_ALLOWED_SPECIFICATION_VERSION_FOR_MILPROGRAM = _SPECIFICATION_VERSION_IOS_15
 
 
 # expose sub packages as directories
-from . import converters, models, proto
+from . import converters, models, optimize, proto
 
 # expose unified converter in coremltools package level
 from .converters import ClassifierConfig
 from .converters import ColorLayout as colorlayout
 from .converters import EnumeratedShapes, ImageType, RangeDim, Shape, TensorType, convert
 from .converters.mil._deployment_compatibility import AvailableTarget as target
 from .converters.mil.mil.passes.defs import quantization as transform
```

### Comparing `coremltools-6.3.0/coremltools/_deps/__init__.py` & `coremltools-7.0b1/coremltools/_deps/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -12,14 +12,21 @@
 import sys as _sys
 from distutils.version import StrictVersion as _StrictVersion
 
 from packaging import version
 
 from coremltools import _logger as logger
 
+_HAS_KMEANS1D = True
+try:
+    from . import kmeans1d as _kmeans1d
+except:
+    _kmeans1d = None
+    _HAS_KMEANS1D = False
+
 
 def _get_version(version):
     # matching 1.6.1, and 1.6.1rc, 1.6.1.dev
     version_regex = r"^\d+\.\d+\.\d+"
     version = _re.search(version_regex, str(version)).group(0)
     return _StrictVersion(version)
 
@@ -152,14 +159,22 @@
     import torch
     _warn_if_above_max_supported_version("Torch", torch.__version__, _TORCH_MAX_VERSION)
 except:
     _HAS_TORCH = False
 MSG_TORCH_NOT_FOUND = "PyTorch not found."
 
 
+_HAS_TORCH_VISION = True
+try:
+    import torchvision
+except:
+    _HAS_TORCH_VISION = False
+MSG_TORCH_VISION_NOT_FOUND = "TorchVision not found."
+
+
 # ---------------------------------------------------------------------------------------
 try:
     import scipy
 except:
     _HAS_SCIPY = False
 else:
     _HAS_SCIPY = True
```

### Comparing `coremltools-6.3.0/coremltools/converters/_converters_entry.py` & `coremltools-7.0b1/coremltools/converters/_converters_entry.py`

 * *Files 2% similar despite different names*

```diff
@@ -2,15 +2,15 @@
 #
 # Use of this source code is governed by a BSD-3-clause license that can be
 # found in the LICENSE.txt file or at https://opensource.org/licenses/BSD-3-Clause
 
 import collections
 import gc
 import os
-from typing import Optional, Text, Union
+from typing import List, Optional, Text, Union
 
 from coremltools import (
     _LOWEST_ALLOWED_SPECIFICATION_VERSION_FOR_MILPROGRAM,
     _LOWEST_ALLOWED_SPECIFICATION_VERSION_FOR_NEURALNETWORK,
 )
 from coremltools import ComputeUnit as _ComputeUnit
 from coremltools import __version__ as _ct_version
@@ -19,16 +19,19 @@
 from coremltools.converters.mil._deployment_compatibility import (
     AvailableTarget,
     check_deployment_compatibility,
 )
 from coremltools.converters.mil.converter import mil_convert
 from coremltools.converters.mil.input_types import (
     ClassifierConfig,
+    EnumeratedShapes,
     ImageType,
     InputType,
+    RangeDim,
+    Shape,
     TensorType,
 )
 from coremltools.converters.mil.mil import Program, types
 from coremltools.converters.mil.mil.passes.defs.quantization import ComputePrecision as precision
 from coremltools.converters.mil.mil.passes.defs.quantization import FP16ComputePrecision
 from coremltools.converters.mil.mil.passes.graph_pass import PassOption as _PassOption
 from coremltools.converters.mil.mil.passes.pass_pipeline import PassPipeline
@@ -391,24 +394,51 @@
         * To avoid fusing the ``conv`` and ``batchnorm`` ops, skip the corresponding pass
           as shown in the following example:
 
           .. sourcecode:: python
 
             pipeline = ct.PassPipeline()
             pipeline.remove_passes({"common::fuse_conv_batchnorm"})
-            ct.convert(model, pass_pipeline=pipeline)
+            mlmodel = ct.convert(model, pass_pipeline=pipeline)
 
         * To avoid folding too-large ``const`` ops that lead to a large model, set pass option
           as shown in the following example:
 
           .. sourcecode:: python
 
             pipeline = ct.PassPipeline()
             pipeline.set_options("common::const_elimination", {"skip_const_by_size": "1e6"})
-            ct.convert(model, pass_pipeline=pipeline)
+            mlmodel = ct.convert(model, pass_pipeline=pipeline)
+
+        We also provide a set of predefined pass pipelines that you can directly call.
+
+        * To avoid running all graph pass, you can use:
+
+          .. sourcecode:: python
+
+             mlmodel = ct.convert(model, pass_pipeline=ct.PassPipeline.EMPTY)
+
+        * To only run the cleanup graph passes, like constant_elimination, dead_code_elimination, etc.
+          You can use:
+
+          .. sourcecode:: python
+
+             mlmodel = ct.convert(model, pass_pipeline=ct.PassPipeline.CLEANUP)
+
+        * To convert a source model with sparse weights to a sparse format Core ML model, you can use:
+
+          .. sourcecode:: python
+
+             mlmodel = ct.convert(model, pass_pipeline=ct.PassPipeline.DEFAULT_PRUNING)
+
+        * To convert a source model with palettized weights to a compressed format Core ML model, you can use:
+
+          .. sourcecode:: python
+
+             mlmodel = ct.convert(model, pass_pipeline=ct.PassPipeline.DEFAULT_PALETTIZATION)
 
     Returns
     -------
 
     model : ``coremltools.models.MLModel`` or ``coremltools.converters.mil.Program``
         A Core ML MLModel object or MIL program object (see ``convert_to``).
 
@@ -459,17 +489,25 @@
     _check_deployment_target(minimum_deployment_target)
     outputs_as_strings, outputs_as_tensor_or_image_types = _validate_outputs_argument(outputs)
     exact_source = _determine_source(model, source,
                                      outputs_as_strings,
                                      outputs_as_tensor_or_image_types,
                                      outputs)
     exact_target = _determine_target(convert_to, minimum_deployment_target)
-    _validate_conversion_arguments(model, exact_source, inputs, outputs_as_tensor_or_image_types,
-                                   classifier_config, compute_precision,
-                                   exact_target, minimum_deployment_target)
+    _validate_conversion_arguments(
+        model,
+        exact_source,
+        exact_target,
+        inputs,
+        outputs_as_tensor_or_image_types,
+        classifier_config,
+        compute_precision,
+        exact_target,
+        minimum_deployment_target,
+    )
 
     if pass_pipeline is None:
         pass_pipeline = PassPipeline()
     if not _need_fp16_cast_pass(compute_precision, exact_target):
         pass_pipeline.remove_passes({"common::add_fp16_cast"})
     if isinstance(compute_precision, FP16ComputePrecision):
         # For backward compatibility with the `op_selector` param in FP16ComputePrecision.
@@ -500,14 +538,20 @@
         compute_units=compute_units,
         package_dir=package_dir,
         debug=debug,
         specification_version=specification_version,
         main_pipeline=pass_pipeline,
     )
 
+    if exact_target == "mlprogram" and mlmodel._input_has_infinite_upper_bound():
+        raise ValueError(
+            "For mlprogram, inputs with infinite upper_bound is not allowed. Please set upper_bound"
+            ' to a positive value in "RangeDim()" for the "inputs" param in ct.convert().'
+        )
+
     if exact_target == 'milinternal':
         return mlmodel  # Returns the MIL program
 
     if minimum_deployment_target is not None:
         check_deployment_compatibility(
             spec=mlmodel.get_spec(),
             representation=exact_target,
@@ -535,15 +579,15 @@
         compute_precision, FP16ComputePrecision
     ):
         return True
     else:
         raise ValueError(f"Invalid value of the argument 'compute_precision': {compute_precision}")
 
 
-def _set_default_specification_version(target):
+def _set_default_specification_version(target) -> Optional[AvailableTarget]:
     if target == "neuralnetwork":
         return _LOWEST_ALLOWED_SPECIFICATION_VERSION_FOR_NEURALNETWORK
     elif target == "mlprogram":
         return _LOWEST_ALLOWED_SPECIFICATION_VERSION_FOR_MILPROGRAM
     elif target in ("milinternal", "milpython"):
         return None
     else:
@@ -621,26 +665,28 @@
                     raise ValueError("Duplicate names provided in 'outputs'")
             if output_names[0] is None:
                 return None, outputs
             else:
                 return output_names, outputs
 
 
-def _validate_conversion_arguments(model,
-                                   exact_source,
-                                   inputs,
-                                   outputs,
-                                   classifier_config,
-                                   compute_precision,
-                                   convert_to,
-                                   minimum_deployment_target,
-                                   ):
+def _validate_conversion_arguments(
+    model,
+    exact_source,
+    exact_target,
+    inputs,
+    outputs,
+    classifier_config,
+    compute_precision,
+    convert_to,
+    minimum_deployment_target,
+):
     """
     Validate and process model, inputs, classifier_config based on
-    `exact_source` (which cannot be `auto`)
+    `exact_source` (which cannot be `auto`) and `exact_target`.
     """
 
     def raise_if_duplicated(input_list):
         # Detect duplicated inputs
         input_names = [t.name for t in input_list if t.name is not None]
         dups = [
             item
@@ -668,27 +714,45 @@
     flat_inputs = None
     if inputs is not None:
         if not isinstance(inputs, list):
             raise ValueError("`inputs` must be of type list")
 
         # get flattened inputs
         flat_inputs = _flatten_list(inputs)
-        for t in flat_inputs:
-            if not isinstance(t, InputType):
+        for flat_input in flat_inputs:
+            if not isinstance(flat_input, InputType):
                 raise ValueError("inputs must be a list of type ct.TensorType or ct.ImageType")
-            if t.dtype == types.fp16:
+            if flat_input.dtype == types.fp16:
                 if not (
                     minimum_deployment_target is not None
                     and minimum_deployment_target >= AvailableTarget.iOS16
                 ):
                     raise TypeError(
                         "float16 dtype for inputs is only supported for deployment "
                         "target >= iOS16/macOS13/watchOS9/tvOS16"
                     )
 
+    if exact_target == "mlprogram":
+        err_msg_infinite_bound = (
+            "For mlprogram, inputs with infinite upper_bound is not allowed. Please set upper_bound"
+            ' to a positive value in "RangeDim()" for the "inputs" param in ct.convert().'
+        )
+        if inputs is not None:
+            for flat_input in _flatten_list(inputs):
+                tensor_shapes: List[Optional[Shape]] = (
+                    flat_input.shape.shapes
+                    if isinstance(flat_input.shape, EnumeratedShapes)
+                    else [flat_input.shape]
+                )
+                for tensor_shape in tensor_shapes:
+                    if tensor_shape is not None:
+                        for shape in tensor_shape.shape:
+                            if isinstance(shape, RangeDim) and shape.upper_bound < 0:
+                                raise ValueError(err_msg_infinite_bound)
+
     if outputs is not None:
         for t in outputs:
             if t.dtype == types.fp16:
                 if not (
                     minimum_deployment_target is not None
                     and minimum_deployment_target >= AvailableTarget.iOS16
                 ):
```

### Comparing `coremltools-6.3.0/coremltools/converters/_profile_utils.py` & `coremltools-7.0b1/coremltools/converters/_profile_utils.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/libsvm/__init__.py` & `coremltools-7.0b1/coremltools/converters/libsvm/__init__.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/libsvm/_libsvm_converter.py` & `coremltools-7.0b1/coremltools/converters/libsvm/_libsvm_converter.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/libsvm/_libsvm_util.py` & `coremltools-7.0b1/coremltools/converters/libsvm/_libsvm_util.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/__init__.py` & `coremltools-7.0b1/coremltools/converters/mil/__init__.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/_deployment_compatibility.py` & `coremltools-7.0b1/coremltools/converters/mil/_deployment_compatibility.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,48 +1,55 @@
 # Copyright (c) 2021, Apple Inc. All rights reserved.
 #
 # Use of this source code is governed by a BSD-3-clause license that can be
 # found in the LICENSE.txt file or at https://opensource.org/licenses/BSD-3-Clause
 
 from enum import IntEnum
 
-from coremltools import (_SPECIFICATION_VERSION_IOS_13,
-                         _SPECIFICATION_VERSION_IOS_14,
-                         _SPECIFICATION_VERSION_IOS_15,
-                         _SPECIFICATION_VERSION_IOS_16)
+from coremltools import (
+    _SPECIFICATION_VERSION_IOS_13,
+    _SPECIFICATION_VERSION_IOS_14,
+    _SPECIFICATION_VERSION_IOS_15,
+    _SPECIFICATION_VERSION_IOS_16,
+    _SPECIFICATION_VERSION_IOS_17,
+)
 
 
 class AvailableTarget(IntEnum):
     # iOS versions
     iOS13 = _SPECIFICATION_VERSION_IOS_13
     iOS14 = _SPECIFICATION_VERSION_IOS_14
     iOS15 = _SPECIFICATION_VERSION_IOS_15
     iOS16 = _SPECIFICATION_VERSION_IOS_16
+    iOS17 = _SPECIFICATION_VERSION_IOS_17
 
     # macOS versions (aliases of iOS versions)
     macOS15 = _SPECIFICATION_VERSION_IOS_13
     macOS16 = _SPECIFICATION_VERSION_IOS_14
     macOS10_15 = _SPECIFICATION_VERSION_IOS_13
     macOS10_16 = _SPECIFICATION_VERSION_IOS_14
     macOS11 = _SPECIFICATION_VERSION_IOS_14
     macOS12 = _SPECIFICATION_VERSION_IOS_15
     macOS13 = _SPECIFICATION_VERSION_IOS_16
+    macOS14 = _SPECIFICATION_VERSION_IOS_17
 
     # watchOS versions (aliases of iOS versions)
     watchOS6 = _SPECIFICATION_VERSION_IOS_13
     watchOS7 = _SPECIFICATION_VERSION_IOS_14
     watchOS8 = _SPECIFICATION_VERSION_IOS_15
     watchOS9 = _SPECIFICATION_VERSION_IOS_16
+    watchOS10 = _SPECIFICATION_VERSION_IOS_17
 
     # tvOS versions (aliases of iOS versions)
     tvOS13 = _SPECIFICATION_VERSION_IOS_13
     tvOS14 = _SPECIFICATION_VERSION_IOS_14
     tvOS15 = _SPECIFICATION_VERSION_IOS_15
     tvOS16 = _SPECIFICATION_VERSION_IOS_16
-    
+    tvOS17 = _SPECIFICATION_VERSION_IOS_17
+
     # customized __str__
     def __str__(self):
         original_str = super().__str__()
         new_str = original_str.replace(type(self).__name__, "coremltools.target")
         return new_str
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/backend/backend_helper.py` & `coremltools-7.0b1/coremltools/converters/mil/backend/backend_helper.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/backend/mil/helper.py` & `coremltools-7.0b1/coremltools/converters/mil/backend/mil/helper.py`

 * *Files 3% similar despite different names*

```diff
@@ -173,15 +173,22 @@
     builtin_type = type_to_builtin_type(type(py_scalar))
     value_type = create_valuetype_scalar(types_to_proto_primitive(builtin_type))
     val = pm.Value(type=value_type)
     t_val = val.immediateValue.tensor
 
     # Set the tensor value
     t_field = _tensor_field_by_type(t_val, builtin_type)
-    if builtin_type in (types.fp16, types.int8, types.uint8, types.uint32):
+    if builtin_type in (
+        types.fp16,
+        types.int8,
+        types.uint8,
+        types.int16,
+        types.uint16,
+        types.uint32,
+    ):
         val.immediateValue.tensor.bytes.values = np_val_to_py_type(py_scalar)
     else:
         if builtin_type == types.str:
             py_scalar = py_scalar.encode("utf-8")
         t_field.append(np_val_to_py_type(py_scalar))
 
     return val
@@ -280,22 +287,30 @@
         return create_valuetype_dict(valuetype.T[0], valuetype.T[1])
     else:
         return create_valuetype_scalar(types_to_proto_primitive(valuetype))
 
 
 def create_file_value(output_var, blob_writer):
     if output_var.val.dtype.kind == 'f' and output_var.val.dtype.itemsize == 4:
-        offset = blob_writer.write_float_data(output_var.val.flatten())
-    elif output_var.val.dtype.kind == 'f' and output_var.val.dtype.itemsize == 2:
-        output_var_fp16_to_bytes_to_uint16 = np.frombuffer(output_var.val.flatten().tobytes(), np.uint16)
-        offset = blob_writer.write_fp16_data(output_var_fp16_to_bytes_to_uint16)
+        offset = blob_writer.write_float_data(np.ascontiguousarray(output_var.val.flatten()))
+    elif output_var.val.dtype.kind == "f" and output_var.val.dtype.itemsize == 2:
+        output_var_fp16_to_bytes_to_uint16 = np.frombuffer(
+            output_var.val.flatten().tobytes(), np.uint16
+        )
+        offset = blob_writer.write_fp16_data(
+            np.ascontiguousarray(output_var_fp16_to_bytes_to_uint16)
+        )
     elif output_var.val.dtype.kind == "u" and output_var.val.dtype.itemsize == 1:
-        offset = blob_writer.write_uint8_data(output_var.val.flatten())
+        offset = blob_writer.write_uint8_data(np.ascontiguousarray(output_var.val.flatten()))
     elif output_var.val.dtype.kind == "i" and output_var.val.dtype.itemsize == 1:
-        offset = blob_writer.write_int8_data(output_var.val.flatten())
+        offset = blob_writer.write_int8_data(np.ascontiguousarray(output_var.val.flatten()))
+    elif output_var.val.dtype.kind == "u" and output_var.val.dtype.itemsize == 2:
+        offset = blob_writer.write_uint16_data(np.ascontiguousarray(output_var.val.flatten()))
+    elif output_var.val.dtype.kind == "i" and output_var.val.dtype.itemsize == 2:
+        offset = blob_writer.write_int16_data(np.ascontiguousarray(output_var.val.flatten()))
     else:
         raise TypeError("Unsupported type, {}, for net buffer serialization.".format(output_var.val.dtype))
 
     return create_file_value_tensor(
         file_name=os.path.join(os.path.join('@model_path', _WEIGHTS_DIR_NAME), _WEIGHTS_FILE_NAME),
         offset=offset,
         dim=output_var.val.shape,
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/backend/mil/load.py` & `coremltools-7.0b1/coremltools/converters/mil/backend/mil/load.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,13 +1,14 @@
 #  Copyright (c) 2021, Apple Inc. All rights reserved.
 #
 #  Use of this source code is governed by a BSD-3-clause license that can be
 #  found in the LICENSE.txt file or at https://opensource.org/licenses/BSD-3-Clause
 
 import os
+import warnings
 
 import numpy as np
 
 from coremltools import _OPSET, _SPECIFICATION_VERSION_IOS_15
 from coremltools import _logger as logger
 from coremltools.converters.mil.backend.backend_helper import _get_probability_var_for_classifier
 from coremltools.converters.mil.backend.mil.helper import (
@@ -142,14 +143,16 @@
         attr_dict["name"] = create_scalar_value(op.name)
         attr_dict["class_name"] = create_scalar_value(class_name)
         attr_dict["input_order"] = create_list_scalarvalue(input_order, str)
         attr_dict["parameters"] = create_list_scalarvalue(parameters, str)
         attr_dict["weights"] = create_list_scalarvalue(weights, str)
         attr_dict["description"] = create_scalar_value(description)
 
+    attr_dict["name"] = create_scalar_value(op.name)
+
     return pm.Operation(
         type=op_type,
         blocks=blocks,
         inputs=inputs,
         attributes=attr_dict,
         outputs=outputs,
     )
@@ -325,16 +328,22 @@
     input_shape_map = {}
 
     for input_type in input_types:
         if isinstance(input_type, ImageType):
             image_input_names[input_type.name] = input_type
             # error checking for input(s) marked as images
             if input_type.name not in list(prog.functions["main"].inputs.keys()):
-                msg = "Provided image input '{}' is not one of the inputs of the MIL program"
-                raise ValueError(msg.format(input_type.name))
+                raise ValueError(
+                    f"Provided image input '{input_type.name}' is not one of the inputs of the MIL program"
+                )
+        if input_type.name is None:
+            raise ValueError(
+                'Fail to auto-determine the input name. Please specify the "name" '
+                'parameter when use "inputs" in ct.convert().'
+            )
         input_shape_map[input_type.name] = input_type
 
     for name, var in prog.functions["main"].inputs.items():
         input_feature_type = ft.FeatureType()
 
         # error checking for input(s) marked as images
         # an image input must be of type tensor in program proto
@@ -453,14 +462,19 @@
                 break
 
     # Create ML Model
     model = ml.Model(description=desc, specificationVersion=specification_version)
     model.mlProgram.CopyFrom(proto)
 
     # Set symbolic shapes
+    default_lower_bound = 1
+    default_upper_bound = (
+        default_lower_bound + 1 if kwargs.get("convert_to", None) == "mlprogram" else -1
+    )
+    default_bound_used = False
     for input_name in symbolic_inputs:
         input_type = input_shape_map.get(input_name, None)
 
         if isinstance(input_type, ImageType):
             if isinstance(input_type.shape, EnumeratedShapes):
                 enumerated_shapes = []
                 for s in input_type.shape.shapes:
@@ -476,21 +490,23 @@
                 img_range = NeuralNetworkImageSizeRange()
                 H = input_type.shape.shape[-2]
                 W = input_type.shape.shape[-1]
 
                 if isinstance(H, RangeDim):
                     img_range.add_height_range((H.lower_bound, H.upper_bound))
                 elif is_symbolic(H):
-                    img_range.add_height_range((1, -1))
+                    img_range.add_height_range((default_lower_bound, default_upper_bound))
+                    default_bound_used = True
                 else:
                     img_range.add_height_range((H, H))
                 if isinstance(W, RangeDim):
                     img_range.add_width_range((W.lower_bound, W.upper_bound))
                 elif is_symbolic(W):
-                    img_range.add_width_range((1, -1))
+                    img_range.add_width_range((default_lower_bound, default_upper_bound))
+                    default_bound_used = True
                 else:
                     img_range.add_width_range((W, W))
 
                 update_image_size_range(
                     model, input_name, img_range
                 )
         elif isinstance(input_type, TensorType):
@@ -502,34 +518,52 @@
                 lb = []
                 ub = []
                 for s in input_type.shape.shape:
                     if isinstance(s, RangeDim):
                         lb.append(s.lower_bound)
                         ub.append(s.upper_bound)
                     elif is_symbolic(s):
-                        lb.append(1)
-                        ub.append(-1)
+                        lb.append(default_lower_bound)
+                        ub.append(default_upper_bound)
+                        default_bound_used = True
                     else:
                         lb.append(s)
                         ub.append(s)
                 set_multiarray_ndshape_range(
                     model, input_name, lower_bounds=lb, upper_bounds=ub
                 )
         elif input_type is None:
             sym_type = prog.functions["main"].inputs[input_name].sym_type
             lb = []
             ub = []
             for s in sym_type.get_shape():
                 if is_symbolic(s):
-                    lb.append(1)
-                    ub.append(-1)
+                    lb.append(default_lower_bound)
+                    ub.append(default_upper_bound)
+                    default_bound_used = True
                 else:
                     lb.append(s)
                     ub.append(s)
             set_multiarray_ndshape_range(
                 model, input_name, lower_bounds=lb, upper_bounds=ub
             )
 
+    if default_bound_used and kwargs.get("convert_to", None) == "mlprogram":
+        warnings.warn(
+            "Some dimensions in the input shape are unknown, hence they are set to flexible ranges "
+            f"with lower bound and default value = {default_lower_bound}, and upper bound = "
+            f"{default_upper_bound}. To set different values for the default shape and upper bound, "
+            "please use the ct.RangeDim() method as described here: "
+            "https://coremltools.readme.io/docs/flexible-inputs#set-the-range-for-each-dimension.",
+            UserWarning,
+        )
+        convert_from = kwargs.get("convert_from", None)
+        if convert_from is not None and convert_from.startswith("tensorflow"):
+            warnings.warn(
+                'There is "None" dim in TF input placeholder. Please consider specifying '
+                'input shapes by using the "inputs" param in ct.convert().'
+            )
+
     # Set optional inputs
     _set_optional_inputs(model, input_types)
 
     return model
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/backend/mil/passes/adjust_io_to_supported_types.py` & `coremltools-7.0b1/coremltools/converters/mil/backend/mil/passes/adjust_io_to_supported_types.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,47 +1,48 @@
 #  Copyright (c) 2021, Apple Inc. All rights reserved.
 #
 #  Use of this source code is governed by a BSD-3-clause license that can be
 #  found in the LICENSE.txt file or at https://opensource.org/licenses/BSD-3-Clause
 
+from typing import Set
+
 from coremltools import _logger as logger
-from coremltools.converters.mil._deployment_compatibility import \
-    AvailableTarget as target
+from coremltools.converters.mil._deployment_compatibility import AvailableTarget as target
 from coremltools.converters.mil.mil import Builder as mb
 from coremltools.converters.mil.mil import types as types
 from coremltools.converters.mil.mil.passes.graph_pass import AbstractGraphPass
 from coremltools.converters.mil.mil.passes.helper import block_context_manager
 from coremltools.converters.mil.mil.passes.pass_registry import register_pass
 
 
 @register_pass(namespace="mil_backend")
 class adjust_io_to_supported_types(AbstractGraphPass):
     """
-    Converts all dtypes to types that are supported by the CoreML runtime.
-    The runtime supports only fp16, fp32, int32, str, and bool variables.
+    Converts all dtypes to types that are supported by the Core ML runtime.
+    The runtime supports fp16, fp32, int16, uint16, int32, str, and bool variables.
 
     General rules:
-        * Integer vars that are not 32 bit are replaced with int32 types.
+        * Integer vars with unsupported types are replaced with int32 types.
         * All other types not in the list of runtime supported types are replaced with the fp32 dtype.
           No casts are inserted; the previous type is replaced. The assumption is that all remaining
           types are numerical and can be reasonably replaced with 32 bit float types.
 
-    The "main" function has additional rules since its I/O is mapped to CoreML model I/O:
+    The "main" function has additional rules since its I/O is mapped to Core ML model I/O:
         * if function.opset_version <  coremltools.target.iOS16, then:
             * Fp16 I/O is replaced with fp32 I/O.
                 Casts (fp32 input -> fp16) are inserted at the beginning of the program to preserve 16 bit inputs.
                 Casts (fp16 -> fp32 output) are inserted at the end of the program to preserve 16 bit computations.
 
         * All non-integer I/O that is not fp32 is replaced with fp32 I/O.
           A cast (prev input type -> fp32) is inserted at the beginning of the program to preserve non-fp32 inputs.
           A cast (prev type -> fp32 out) is inserted at the end of the program to preserve non-fp32 computations.
           The assumption is that all remaining types are numerical and it is valid to cast them to/from fp32.
 
         * The only exception: Int64 outputs are allowed for the classifier op. This is to keep consistency with
-          the CoreML API, which uses 64 bit integers to represent classifier labels.
+          the Core ML API, which uses 64 bit integers to represent classifier labels.
 
     ------
 
     func main(bool x, int32 y, fp32 z) {
         bool  out = logical_not(x)
     } -> (out, y, z)
 
@@ -63,142 +64,156 @@
     """
 
     def apply(self, prog):
         for name, func in prog.functions.items():
             is_main_funtion = name == "main"
             _adjust_io_to_supported_types(func, is_main_funtion)
 
-__RUNTIME_SUPPORTED_TYPES = [types.fp16, types.fp32, types.int32, types.str, types.bool]
 
-#####
-# Main Function
-#####
 def _adjust_var_dtype_helper(var, dtype):
-    if (types.is_scalar(var.sym_type)):
+    if types.is_scalar(var.sym_type):
         var._sym_type = dtype
     else:
         var._sym_type = types.tensor(dtype, var.sym_type.get_shape())
 
+
+def _get_io_supported_types(opset_version: target) -> Set[type]:
+    """Get Core ML I/O supported data types based on opset version."""
+    supported_types = {types.fp32, types.int32}
+    if opset_version >= target.iOS16:
+        supported_types.add(types.fp16)
+    return supported_types
+
+
+def _get_runtime_supported_types(opset_version: target) -> Set[type]:
+    """Get Core ML Runtime supported data types based on opset version."""
+    supported_types = {types.fp16, types.fp32, types.int32, types.str, types.bool}
+    if opset_version >= target.iOS17:
+        supported_types.update({types.int16, types.uint16})
+    return supported_types
+
+
 @block_context_manager
 def _adjust_main_inputs(func):
-    first_op = func.operations[0] if len(func.operations) > 0 else None
+    """
+    Adjust the inputs in main func.
+
+    If the input's dtype is not in Core ML I/O supported types, we do following steps:
+        1. Change the input's dtype to int32 or fp32 based on original dtype.
+        2. If the original dtype is supported in Core ML Runtime, we insert a cast op to cast the
+           input from the changed dtype to the original dtype.
+    """
+    _IO_SUPPORTED_TYPES = _get_io_supported_types(func.opset_version)
+    _RUNTIME_SUPPORTED_TYPES = _get_runtime_supported_types(func.opset_version)
+
     for input_name, input_var in func.inputs.items():
-       if (types.is_tensor(input_var.sym_type) or types.is_scalar(input_var.sym_type)) \
-            and input_var.dtype != types.fp32 \
-            and input_var.dtype != types.int32:
+        if (
+            types.is_tensor(input_var.sym_type) or types.is_scalar(input_var.sym_type)
+        ) and input_var.dtype not in _IO_SUPPORTED_TYPES:
             input_dtype_str = types.builtin_to_string(input_var.dtype)
-            if types.is_int(input_var.dtype):
-                # Replace non-int32 input type with int32.
-                logger.warning("Input" + input_var.name + " is of dtype " + input_dtype_str +\
-                               ". Only integer variables of bit width 32 are supported by the CoreML runtime. " +\
-                               "This input will be assigned a dtype of int32. " +\
-                               "No cast will be inserted; the previous dtype will be replaced.")
-                _adjust_var_dtype_helper(input_var, types.int32)
-            elif input_var.dtype == types.fp64:
-                # Replace float64 input type with fp32.
-                logger.warning("Input '" + input_var.name + "' is of dtype fp64. 64 bit float inputs are " +\
-                               "not supported by ML program models. This input will be assigned a dtype " +\
-                               "of fp32. No cast will be inserted; the previous dtype will be replaced.")
-                _adjust_var_dtype_helper(input_var, types.fp32)
-            elif input_var.dtype == types.fp16 \
-                 and func.opset_version >= target.iOS16:
-                pass # do nothing, since fp16 is a valid input type for CoreML
-            else:
-                # This is some other dtype. Change the type to fp32 and add a cast.
-                # This is only a limitation of main--other functions do not represent CoreML model inputs
-                # and do not have the same limitation on input types.
-                supported_dtypes = "{int32, fp32}" if func.opset_version < target.iOS16 else \
-                                    "{int32, fp16, fp32}"
-                msg = "\nInput '{}' is of dtype {}. The " +\
-                               "CoreML runtime does not support inputs with this dtype " +\
-                               "(supported dtypes are: {}). This input will be assigned a dtype of " +\
-                               "fp32. A cast will be inserted at the beginning of the program to " +\
-                               "convert the input to the originally defined dtype.\n"
-                if input_var.dtype == types.fp16:
-                    msg += "fp16 dtype input is supported if the function.opset_version is chosen to be at least " \
-                           "iOS16/macOS13.\n"
-                logger.warning(msg.format(
-                    input_var.name,
-                    input_dtype_str,
-                    supported_dtypes))
-
+            convert_to_dtype = types.int32 if types.is_int(input_var.dtype) else types.fp32
+            convert_to_dtype_str = types.builtin_to_string(convert_to_dtype)
+            should_insert_cast = input_var.dtype in _RUNTIME_SUPPORTED_TYPES
+            _adjust_var_dtype_helper(input_var, convert_to_dtype)
+            logger.warning(
+                f"\nInput '{input_var.name}' is of dtype {input_dtype_str}. The Core ML I/O does "
+                f"not support this dtype (supported dtypes are: {_IO_SUPPORTED_TYPES}). Consider "
+                f"setting `minimum_deployment_target` to a higher IOS version for more supported "
+                f"dtypes. This input is changed to {convert_to_dtype_str}.\n"
+            )
+
+            if not should_insert_cast:
+                logger.warning(
+                    f"The original input dtype {input_dtype_str} is not supported in "
+                    f"Core ML Runtime (supported dtypes are: {_RUNTIME_SUPPORTED_TYPES}). Consider "
+                    f"setting `minimum_deployment_target` to a higher IOS version for more "
+                    f"supported dtypes. We just changed the dtype and won't insert any cast op."
+                )
+                continue
+
+            logger.warning(
+                f"Trying to insert a cast op at the beginning of the program to convert "
+                f"the input to the originally defined dtype ({input_dtype_str}).\n"
+            )
+            try:
+                first_op = func.operations[0] if len(func.operations) > 0 else None
                 casted_input_var = mb.cast(x=input_var, dtype=input_dtype_str, before_op=first_op)
-                func.replace_uses_of_var_after_op(anchor_op=casted_input_var.op, old_var=input_var, new_var=casted_input_var)
-                _adjust_var_dtype_helper(input_var, types.fp32)
+                # Use force replace as the `input_var.dtype` could be not subtype of the
+                # `convert_to_dtype`. For example, int16 cast to int32. As it's only for input
+                # dtype cast, this replace should be safe.
+                func.replace_uses_of_var_after_op(
+                    anchor_op=casted_input_var.op,
+                    old_var=input_var,
+                    new_var=casted_input_var,
+                    force_replace=True,
+                    no_check_var_types=True,
+                )
+            except Exception as e:
+                logger.warning(
+                    f"Failed to insert the cast op.\n{e}\nThe dtype of the input "
+                    f"'{input_var.name}' is changed to {convert_to_dtype_str} without "
+                    f"inserting any cast op."
+                )
+
 
 @block_context_manager
 def _adjust_main_outputs(func):
+    """Adjust the outputs in the main func to make sure they have Core ML I/O supported types."""
+    _IO_SUPPORTED_TYPES = _get_io_supported_types(func.opset_version)
+
     new_outputs = []
     for output_var in func.outputs:
         output_type = output_var.sym_type
-        if (types.is_tensor(output_type) or types.is_scalar(output_type)) \
-            and output_var.dtype != types.fp32 \
-            and output_var.dtype != types.int32 \
-            and (func.opset_version < target.iOS16 or output_var.dtype != types.fp16):
-            # since fp16 is a valid output type for coreml from ios16 spec onwards, no need to cast
+        if (
+            types.is_tensor(output_type) or types.is_scalar(output_type)
+        ) and output_var.dtype not in _IO_SUPPORTED_TYPES:
             output_dtype_str = types.builtin_to_string(output_var.dtype)
-            supported_dtypes = "{int32, fp32}" if func.opset_version < target.iOS16 else \
-                                "{int32, fp16, fp32}"
-            msg = "\nOutput '{}' is of dtype {}. The " +\
-                           "CoreML runtime does not support outputs with this dtype " +\
-                           "(supported dtypes are: {}). This output will be assigned a dtype " +\
-                           "of fp32. A cast will be inserted at the end of the program to convert" +\
-                           "the original output dtype to the dtype supported by the CoreML runtime.\n"
+            target_dtype = "int32" if types.is_int(output_var.dtype) else "fp32"
+            logger.warning(
+                f"\nOutput '{output_var.name}' is of dtype {output_dtype_str}. The "
+                f"Core ML runtime does not support outputs with this dtype (supported "
+                f"dtypes are: {_IO_SUPPORTED_TYPES}). This output will changed to "
+                f"{target_dtype} by adding a cast op at the end of the program.\n"
+            )
             if output_var.dtype == types.fp16:
-                msg += "fp16 dtype output is supported if function.opset_version is chosen to be at least " \
-                       "iOS16/macOS13.\n"
-            logger.warning(msg.format(
-                               output_var.name,
-                               output_dtype_str,
-                               supported_dtypes,
-                           ))
+                logger.warning(
+                    "fp16 dtype output is supported if function.opset_version is chosen to be at "
+                    "least iOS16/macOS13.\n"
+                )
 
             output_var_name = output_var.name
-            output_var.set_name(output_var_name + "__pre__output__fp32__cast")
-            # Convert the output to fp32, and add a cast.
-            output_var = mb.cast(x=output_var, dtype="fp32")
+            output_var.set_name(f"{output_var_name}__pre__output__{target_dtype}__cast")
+            output_var = mb.cast(x=output_var, dtype=target_dtype)
             output_var.set_name(output_var_name)
         new_outputs.append(output_var)
     func.set_outputs(new_outputs)
 
 
-#####
-# General Functions and Blocks
-#####
-def _adjust_var(var):
+def _adjust_func_inputs(func):
     """
     Changes the dtype of the provided variable according
     to the rules outlined in the top level pass comment
     (see adjust_io_to_supported_types).
     """
-    if (types.is_tensor(var.sym_type) or types.is_scalar(var.sym_type)) \
-        and var.dtype not in __RUNTIME_SUPPORTED_TYPES:
-        dtype_str = types.builtin_to_string(var.dtype)
-        if types.is_int(var.dtype):
-            # Replace non-int32 input type with int32.
-            logger.warning("Input '" + var.name + "' is of dtype " + dtype_str +\
-                           ". Only integer variables of bit width 32 are supported by the CoreML runtime. " +\
-                           "This input will be assigned a dtype of int32. " +\
-                           "No cast will be inserted; the previous dtype will be replaced.")
-            _adjust_var_dtype_helper(var, types.int32)
-        else:
-            # This is some other unsupported dtype. Change the input type to fp32.
-            logger.warning("Var " + var.name + " is of dtype " + dtype_str + ". The CoreML runtime " +\
-                           "does not support this dtype (only fp16, fp32, bool, and int32 are supported). " +\
-                           "This input will be assigned a dtype of fp32. No cast will be inserted; " +\
-                           "the previous dtype will be replaced.")
-            _adjust_var_dtype_helper(var, types.fp32)
-
+    _RUNTIME_SUPPORTED_TYPES = _get_runtime_supported_types(func.opset_version)
 
-def _adjust_func_inputs(func):
     for input_name, input_var in func.inputs.items():
-        _adjust_var(input_var)
+        if (
+            types.is_tensor(input_var.sym_type) or types.is_scalar(input_var.sym_type)
+        ) and input_var.dtype not in _RUNTIME_SUPPORTED_TYPES:
+            dtype_str = types.builtin_to_string(input_var.dtype)
+            convert_to_dtype = types.int32 if types.is_int(input_var.dtype) else types.fp32
+            convert_to_dtype_str = types.builtin_to_string(convert_to_dtype)
+            _adjust_var_dtype_helper(input_var, convert_to_dtype)
+            logger.warning(
+                f"Input '{input_var.name}' is of dtype {dtype_str}, which is not"
+                f"supported by the Core ML runtime. This input will be changed to "
+                f"{convert_to_dtype_str}. No cast will be inserted."
+            )
+
 
-#####
-# The Pass
-#####
 def _adjust_io_to_supported_types(func, is_main):
     if is_main:
         _adjust_main_inputs(func)
         _adjust_main_outputs(func)
     else:
         _adjust_func_inputs(func)
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/backend/mil/passes/fuse_activation_silu.py` & `coremltools-7.0b1/coremltools/converters/mil/backend/mil/passes/fuse_activation_silu.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/backend/mil/passes/insert_image_preprocessing_op.py` & `coremltools-7.0b1/coremltools/converters/mil/backend/mil/passes/insert_image_preprocessing_op.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/backend/mil/passes/sanitize_name_strings.py` & `coremltools-7.0b1/coremltools/converters/mil/backend/mil/passes/sanitize_name_strings.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/backend/mil/passes/test_passes.py` & `coremltools-7.0b1/coremltools/converters/mil/backend/mil/passes/test_passes.py`

 * *Files 2% similar despite different names*

```diff
@@ -5,17 +5,15 @@
 
 import copy
 import itertools
 
 import numpy as np
 import pytest
 
-# import mil internal ops to add it to the builder
 import coremltools as ct
-# Set the testing backend
 from coremltools.converters.mil._deployment_compatibility import \
     AvailableTarget as target
 from coremltools.converters.mil.mil import Builder as mb
 from coremltools.converters.mil.mil import types
 from coremltools.converters.mil.mil.passes.pass_registry import PASS_REGISTRY
 from coremltools.converters.mil.testing_utils import (
     apply_pass_and_basic_check, assert_model_is_valid, get_op_types_in_program)
@@ -189,32 +187,32 @@
             assert get_op_types_in_program(prog) == ['cast', 'relu', 'cast']
             assert inputs[0][1].dtype == types.fp32
             assert outputs[0].dtype == types.fp32
         else:
             assert get_op_types_in_program(prog) == ['relu']
             assert inputs[0][1].dtype == types.fp16
             assert block.outputs[0].dtype == types.fp16
-            
+
     def test_float16_input_output_with_opset_version_inference(self):
         """
         Input graph:
 
         main(%x: (1, 1, 4, 4, fp16)(Tensor)) {
           block0() {
             %pixel_unshuffle_0: (1, 4, 2, 2, fp16)(Tensor) = pixel_unshuffle(x=%x, downscale_factor=2, name="pixel_unshuffle_0")
           } -> (%pixel_unshuffle_0)
         }
-        
+
         This function would be inferred as an iOS16 function, and the graph pass should behave properly
         """
         @mb.program(input_specs=[mb.TensorSpec(shape=(1, 1, 4, 4), dtype=types.fp16)])
         def prog(x):
             x = mb.pixel_unshuffle(x=x, downscale_factor=np.uint32(2))
             return x
-            
+
         prev_prog, prev_block, block = apply_pass_and_basic_check(
             prog, "mil_backend::adjust_io_to_supported_types"
         )
 
         prev_inputs = list(prev_block.inputs.items())
         inputs = list(block.inputs.items())
         prev_outputs = prev_block.outputs
@@ -246,14 +244,73 @@
         )
 
         prev_inputs = list(prev_prog.functions['main'].inputs.items())
         inputs = list(prog.functions['main'].inputs.items())
         assert prev_inputs[0][1].name == inputs[0][1].name
         assert inputs[0][1].dtype == types.int32
 
+    @pytest.mark.parametrize(
+        "opset_version",
+        [None, target.iOS17],
+    )
+    def test_int16_input(self, opset_version):
+        """
+        Input graph:
+            func main(int16 x) {
+            ....
+            } -> (x)
+
+        Before IOS17, it becomes
+            func main(int32 x) {
+            ....
+            } -> (x)
+
+        In IOS17+, it becomes
+            func main(int32 x) {
+                %cast_0: (1, 1, 1, 1, int16)(Tensor) = cast(x=%x, dtype="int16", name="cast_0")
+                ....
+                %cast_1: (1, 1, 1, 1, int32)(Tensor) = cast(x=%x, dtype="int32", name="cast_1")
+            } -> (cast_1)
+        because IOS17+ supports int16 in Runtime (but doesn't support int16 for I/O).
+        """
+
+        @mb.program(
+            input_specs=[mb.TensorSpec(shape=(1, 1, 1, 1), dtype=types.int16)],
+            opset_version=opset_version,
+        )
+        def prog(x):
+            return x
+
+        prev_prog, prev_block, block = apply_pass_and_basic_check(
+            prog, "mil_backend::adjust_io_to_supported_types"
+        )
+
+        prev_inputs = list(prev_block.inputs.items())
+        inputs = list(block.inputs.items())
+        prev_outputs = prev_block.outputs
+        outputs = block.outputs
+        assert prev_inputs[0][1].dtype == types.int16
+        assert prev_outputs[0].dtype == types.int16
+        assert inputs[0][1].dtype == types.int32
+        assert outputs[0].dtype == types.int32
+        assert prev_inputs[0][1].name == inputs[0][1].name
+        assert outputs[0].name == prev_outputs[0].name
+        if opset_version and opset_version >= target.iOS17:
+            assert get_op_types_in_program(prog) == ["cast", "cast"]
+            cast_ops = [op for op in prog["main"].operations if op.op_type != "const"]
+            # The first cast is for int32 to int16.
+            assert cast_ops[0].x.dtype == types.int32
+            assert cast_ops[0].outputs[0].dtype == types.int16
+            # The second cast is for int16 to int32.
+            assert cast_ops[1].x.dtype == types.int16
+            assert cast_ops[1].outputs[0].dtype == types.int32
+        else:
+            # Before IOS17, the int16 is not supported in Runtime, so there is no cast inserted.
+            assert get_op_types_in_program(prog) == []
+
     def test_subblock(self):
         """
         Input graph:
 
         func main(float64 a, float32 b) {
             float64 out_0, float32 out_1 = while_loop(a, b,
                 (float64 a, float32 b) {
@@ -881,8 +938,7 @@
 
         assert_model_is_valid(
             program=program,
             inputs={"x": x_shape},
             backend=("mlprogram", "fp32"),
             expected_output_shapes={block.outputs[0].name: tuple(x_shape)},
         )
-
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/backend/mil/test_helper.py` & `coremltools-7.0b1/coremltools/converters/mil/backend/mil/test_helper.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/backend/mil/test_model_input_params.py` & `coremltools-7.0b1/coremltools/converters/mil/backend/mil/test_model_input_params.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/backend/nn/load.py` & `coremltools-7.0b1/coremltools/converters/mil/backend/nn/load.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/backend/nn/mil_to_nn_mapping_registry.py` & `coremltools-7.0b1/coremltools/converters/mil/backend/nn/mil_to_nn_mapping_registry.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/backend/nn/op_mapping.py` & `coremltools-7.0b1/coremltools/converters/mil/backend/nn/op_mapping.py`

 * *Files 1% similar despite different names*

```diff
@@ -1704,21 +1704,23 @@
 
     # Add expand dims for input, in
     _expand_dim(builder, input_name + "_expanded", input_name, [3, 4])
     input_name += "_expanded"
 
     if direction in {"forward", "reverse"}:
         # Expand initial_h and initial_c,
-        # from shape (B, H) to shape (1, Batch, H, 1, 1)
-        _expand_dim(builder, initial_h + "_expanded", initial_h, [0, 3, 4])
-        initial_h += "_expanded"
-        # initial_h may have the same name as initial_c (e.g., same Var).
-        # Append a different string to avoid conflict
-        _expand_dim(builder, initial_c + "_expanded2", initial_c, [0, 3, 4])
-        initial_c += "_expanded2"
+        # from shape (B, H) to shape (1, Batch, H, 1, 1).
+        # Since initial_h and initial_c may get used in multiple places,
+        # prepend input_name to avoid conflict
+        _expand_dim(builder, input_name + initial_h + "_expanded", initial_h, [0, 3, 4])
+        initial_h = input_name + initial_h + "_expanded"
+        # initial_c may have the same name as initial_h (e.g., same Var).
+        # Append a different string to initial_c to avoid conflict
+        _expand_dim(builder, input_name + initial_c + "_expanded2", initial_c, [0, 3, 4])
+        initial_c = input_name + initial_c + "_expanded2"
 
         # w_x: [H*I, H*I, H*I, H*I]
         # w_h: [H*H, H*H, H*H, H*H]
         # where format is, [input gate, forget gate, output gate, cell gate]
         w_x = _split(wt_ih, sections=4)
         w_h = _split(wt_hh, sections=4)
         # bias format: [4*H]
@@ -1763,21 +1765,21 @@
 
     elif direction == "bidirectional":
         # Expand initial_h and initial_c
         # Issue #810
         num_layer = len(builder.layers)
         initial_h_expand = initial_h + "_expanded" + "_" + str(num_layer)
         # from shape (B, 2*H) to shape (1, Batch, 2*H, 1, 1)
-        if not (initial_h_expand in set(builder.layers)):
+        if initial_h_expand not in set(builder.layers):
             _expand_dim(builder, initial_h_expand, initial_h, [0, 3, 4])
         initial_h = initial_h_expand
 
         # initial_h may have the same name as initial_c (e.g., same Var)
         initial_c_expand = initial_c + "_expanded2" + "_" + str(num_layer)
-        if not (initial_c_expand in set(builder.layers)):
+        if initial_c_expand not in set(builder.layers):
             _expand_dim(builder, initial_c_expand, initial_c, [0, 3, 4])
         initial_c = initial_c_expand
 
         initial_h_f = initial_h + "_forward"
         initial_h_r = initial_h + "_reverse"
         initial_c_f = initial_c + "_forward"
         initial_c_r = initial_c + "_reverse"
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/backend/nn/passes/alert_return_type_cast.py` & `coremltools-7.0b1/coremltools/converters/mil/backend/nn/passes/alert_return_type_cast.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/backend/nn/passes/commingle_loop_vars.py` & `coremltools-7.0b1/coremltools/converters/mil/backend/nn/passes/commingle_loop_vars.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/backend/nn/passes/conv1d_decomposition.py` & `coremltools-7.0b1/coremltools/converters/mil/backend/nn/passes/conv1d_decomposition.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/backend/nn/passes/handle_return_inputs_as_outputs.py` & `coremltools-7.0b1/coremltools/converters/mil/backend/nn/passes/handle_return_inputs_as_outputs.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/backend/nn/passes/handle_return_unused_inputs.py` & `coremltools-7.0b1/coremltools/converters/mil/backend/nn/passes/handle_return_unused_inputs.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/backend/nn/passes/handle_unused_inputs.py` & `coremltools-7.0b1/coremltools/converters/mil/backend/nn/passes/handle_unused_inputs.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/backend/nn/passes/mlmodel_passes.py` & `coremltools-7.0b1/coremltools/converters/mil/backend/nn/passes/mlmodel_passes.py`

 * *Files 0% similar despite different names*

```diff
@@ -290,15 +290,15 @@
         """
         output_to_layers: {str: layer_proto_message} : {blob name: layers that it feeds into}
         input_to_parent_layers: {str: layer_proto_message} : {blob name: parent layers that feed in}
         """
         output_to_layers = {}
         for layer in nn_layers:
             for input in layer.input:
-                if not input in output_to_layers:
+                if input not in output_to_layers:
                     output_to_layers[input] = [layer]
                 else:
                     output_to_layers[input].append(layer)
 
         input_to_parent_layers = {}
         for layer in nn_layers:
             for output in layer.output:
@@ -363,15 +363,15 @@
 
             # Get the transpose layers sequence
             layers = []
             cursor = layer
             while True:
                 if cursor.output[0] in output_to_layers:
                     layers.append(cursor)
-                if not cursor.input[0] in input_to_parent_layers:
+                if cursor.input[0] not in input_to_parent_layers:
                     break
                 cursor = input_to_parent_layers[cursor.input[0]]
                 if cursor.WhichOneof("layer") != "transpose":
                     break
                 if len(output_to_layers[cursor.output[0]]) != 1:
                     break
             layers = layers[::-1]
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/backend/nn/passes/test_mlmodel_passes.py` & `coremltools-7.0b1/coremltools/converters/mil/backend/nn/passes/test_mlmodel_passes.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/backend/nn/passes/test_passes.py` & `coremltools-7.0b1/coremltools/converters/mil/backend/nn/passes/test_passes.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/converter.py` & `coremltools-7.0b1/coremltools/converters/mil/converter.py`

 * *Files 2% similar despite different names*

```diff
@@ -11,15 +11,15 @@
 from coremltools.converters.mil import Program
 from coremltools.converters.mil.mil import Builder as mb
 from coremltools.converters.mil.mil.types.symbolic import k_num_internal_syms, k_used_symbols
 from coremltools.models import MLModel
 from coremltools.models.model import _create_mlpackage
 
 from . import ImageType, InputType
-from .mil.passes.pass_pipeline import PassPipeline, PipelineManager
+from .mil.passes.pass_pipeline import PassPipeline, PassPipelineManager
 
 
 class ConverterRegistry:
     frontends = {}
     backends = {}
     backend_alias_names = {}
 
@@ -43,17 +43,17 @@
 
     def __call__(self, model, *args, **kwargs):
         specification_version = kwargs.get("specification_version", None)
         if specification_version is not None:
             max_opset_version, op = model._get_max_opset_version_and_op()
             if max_opset_version > specification_version:
                 msg = (
-                    "Please update the minimum_deployment_target to {!s},"
-                    " since op {} is only available in opset {!s} or newer."
-                ).format(max_opset_version, op.op_type, max_opset_version)
+                    "Please update the minimum_deployment_target to coremltools.target.{},"
+                    " since op {} is only available in opset coremltools.target.{} or newer."
+                ).format(max_opset_version.name, op.op_type, max_opset_version.name)
                 raise ValueError(msg)
 
         if "inputs" in kwargs and kwargs["inputs"] is not None:
             inputs = kwargs["inputs"]
             if not isinstance(inputs, (list, tuple)):
                 raise ValueError(
                     "Type of inputs should be list or tuple, got {} instead.".format(
@@ -265,38 +265,39 @@
     frontend_converter_type = converter_registry.frontends.get(convert_from.lower())
     if not frontend_converter_type:
         raise NotImplementedError(
             f'Frontend converter "{convert_from}" not implemented, must be '
             f"one of: {list(converter_registry.frontends.keys())}"
         )
 
+    kwargs.setdefault("convert_from", convert_from)
     kwargs.setdefault("convert_to", convert_to)
 
     if main_pipeline is None:
         # If the client calls `mil_convert` directly, the `pass_pipeline` is None. To keep the
         # behaviour same as before, the quantization pass is removed in this situation.
         # TODO: rdar://106111553 ([Infra] Quantization Pass is skipped when `mil_convert` is called directly.)
         main_pipeline = PassPipeline()
         main_pipeline.remove_passes({"common::add_fp16_cast"})
     frontend_pipeline, backend_pipeline = _construct_other_pipelines(
         main_pipeline, convert_from, convert_to
     )
 
     frontend_converter = frontend_converter_type()
     prog = frontend_converter(model, **kwargs)
-    PipelineManager.apply_pipeline(prog, frontend_pipeline)
+    PassPipelineManager.apply_pipeline(prog, frontend_pipeline)
 
-    PipelineManager.apply_pipeline(prog, main_pipeline)
+    PassPipelineManager.apply_pipeline(prog, main_pipeline)
 
     prog._check_invalid_tensor_rank()
 
     if convert_to == 'milinternal':
         return None, prog
 
-    PipelineManager.apply_pipeline(prog, backend_pipeline)
+    PassPipelineManager.apply_pipeline(prog, backend_pipeline)
     backend_converter_type = converter_registry.backends.get(convert_to.lower())
     if not backend_converter_type:
         raise NotImplementedError(
             f'Backend converter "{convert_to}" not implemented, must be '
             f"one of: {list(converter_registry.backends.keys())}"
         )
     backend_converter = backend_converter_type()
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/debugging_utils.py` & `coremltools-7.0b1/coremltools/converters/mil/debugging_utils.py`

 * *Files 4% similar despite different names*

```diff
@@ -18,60 +18,61 @@
 def extract_submodel(
         model: MLModel,
         outputs: List[str],
         inputs: Optional[List[str]] = None,
         function_name: str = "main"
     ) -> MLModel:
     """
-    This utility function allows the user to extract a submodel from a Core ML model.
+    This utility function lets you extract a submodel from a Core ML model.
     
-    For the NeuralNetwork model, only in memory Core ML model can be extracted. That is to say,
-    the user should always call this function to a model directly from `ct.convert`. It is not
-    allowed to load the model from the disk, and call this API.
+    For a NeuralNetwork model, the function extracts only in-memory Core ML models.
+    You should always call this function to a model directly from ``ct.convert``. It is not
+    allowed to load the model from disk and then call this API.
     
-    For the ML program model, both cases (in memory / from disk) are supported.
+    For an ML program model, both cases (in-memory and from disk) are supported.
 
     Parameters
     ----------
     model: MLModel
         The Core ML model from which the submodel is extracted.
 
     outputs: list[str]
         A list of names of Vars, which are the outputs of the extracted submodel.
         
     inputs: list[str] (Optional)
         A list of names of Vars, which are the inputs of the extracted submodel.
-        If not provided, we use the inputs from the original model.
+        If not provided, the inputs from the original model are used.
 
     function_name: str (Optional)
-        Name of the function where the subgraph is extracted. Default "main".
+        Name of the function where the subgraph is extracted. Default ``main``.
         
     Examples
     --------
 
     NeuralNetwork:
 
         >>> from coremltools.converters.mil.debugging_utils import extract_submodel
         >>> mlmodel = ct.convert(model, convert_to="neuralnetwork")
         >>> outputs = ["output_0", "output_1"]
         >>> submodel = extract_submodel(mlmodel, outputs)
         
     ML Program:
+
         >>> from coremltools.converters.mil.debugging_utils import extract_submodel
         >>> mlmodel = ct.convert(model, convert_to="mlprogram")
         >>> outputs = ["output_0", "output_1"]
         >>>
         >>> # Directly extract model in memory
         >>> submodel = extract_submodel(mlmodel, outputs)
         >>>
         >>> # Extract model loaded from disk
         >>> mlmodel.save("model.mlpackage")
         >>> mlmodel = coremltools.model.models.MLModel("model.mlpackage")
         >>> submodel = extract_submodel(mlmodel, outputs)
-     
+
     """
     def validate_inputs(func, input_vars):
         reachable_vars = set(input_vars)
         for op in func.operations:
             if op.op_type == "const":
                 reachable_vars.add(op.outputs[0])
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/experimental/passes/README.md` & `coremltools-7.0b1/coremltools/converters/mil/experimental/passes/README.md`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/experimental/passes/generic_conv_batchnorm_fusion.py` & `coremltools-7.0b1/coremltools/converters/mil/experimental/passes/generic_conv_batchnorm_fusion.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/experimental/passes/generic_conv_bias_fusion.py` & `coremltools-7.0b1/coremltools/converters/mil/experimental/passes/generic_conv_bias_fusion.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/experimental/passes/generic_conv_scale_fusion.py` & `coremltools-7.0b1/coremltools/converters/mil/experimental/passes/generic_conv_scale_fusion.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/experimental/passes/generic_layernorm_instancenorm_pattern_fusion.py` & `coremltools-7.0b1/coremltools/converters/mil/experimental/passes/generic_layernorm_instancenorm_pattern_fusion.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/experimental/passes/generic_linear_bias_fusion.py` & `coremltools-7.0b1/coremltools/converters/mil/experimental/passes/generic_linear_bias_fusion.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/experimental/passes/generic_pass_infrastructure.py` & `coremltools-7.0b1/coremltools/converters/mil/experimental/passes/generic_pass_infrastructure.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,14 @@
 #  Copyright (c) 2020, Apple Inc. All rights reserved.
 #
 #  Use of this source code is governed by a BSD-3-clause license that can be
 #  found in the LICENSE.txt file or at https://opensource.org/licenses/BSD-3-Clause
 
 import itertools
+import warnings
 from functools import partial
 
 from coremltools.converters.mil.mil.passes.helper import block_context_manager
 
 from ...mil.passes import pass_registry
 
 # IMPORTANT: List of assumptions we are making about the problem
@@ -105,15 +106,19 @@
         # So, two identical operations will have the same ordering of outputs.
         program_child_op_list = list(program_op.outputs[i].child_ops) if pattern_op is not None else program_root_var.child_ops
         pattern_child_op_list = list(pattern_op.outputs[i].child_ops) if pattern_op is not None else pattern_root_var.child_ops
 
         # Last op in the pattern
         if len(pattern_child_op_list) == 0:
             if pattern.final_op is not None and pattern.final_op != program_op:
-                raise ValueError("User defined pattern has more than one final operation")
+                warnings.warn(
+                    "User defined pattern matched to more than one final operation. "
+                    "Skipped the pattern matching."
+                )
+                return False
             pattern.set_final_op(pattern_op.name, program_op)
             return True
 
         if len(program_child_op_list) != len(pattern_child_op_list):
             return False
 
         # Permuting the program child operations so that at least one of the permutations will be in
@@ -214,8 +219,7 @@
     pass_function = partial(fuse_all_blocks, ops_arrangement, var_constraints, transform_pattern)
 
     pass_id = namespace + "::" + pass_name
     if pass_id not in pass_registry.PASS_REGISTRY or not isinstance(pass_registry.PASS_REGISTRY[pass_id], PassContainer):
         pass_registry.PASS_REGISTRY.passes[pass_id] = PassContainer(pass_name)
 
     pass_registry.PASS_REGISTRY[pass_id].add(pass_function)
-
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/_utils.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/_utils.py`

 * *Files 2% similar despite different names*

```diff
@@ -8,29 +8,31 @@
 from coremltools.converters.mil.input_types import InputType
 from coremltools.converters.mil.mil import Builder as mb
 from coremltools.converters.mil.mil import Var, types
 from coremltools.converters.mil.mil.ops.defs._utils import parse_einsum_equation
 from coremltools.converters.mil.mil.types.symbolic import any_symbolic, is_symbolic
 
 
-def value_at(x: Var, idx: int, name=None):
+def value_at(x: Var, idx: int, name=None, before_op=None):
     """
     input x: 1D tensor (vector).
     return value at index idx. x[idx].
     Could specify the name of the returned MIL scalar tensor as well.
     """
     assert x.rank == 1
     args = {
         "x": x,
         "begin": [idx],
         "end": [0],
         "squeeze_mask": [True],
     }
     if name is not None:
         args["name"] = name
+    if before_op is not None:
+        args["before_op"] = before_op
     return mb.slice_by_index(**args)
 
 
 def _reverse_input_einsum_eq(equation: str) -> str:
     """
     Reverse the input order of the einsum eqaution
     e.g.:
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/milproto/helper.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/milproto/helper.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/milproto/load.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/milproto/load.py`

 * *Files 3% similar despite different names*

```diff
@@ -103,22 +103,26 @@
     if filename in context.blob_reader_from_filename:
         blob_reader = context.blob_reader_from_filename[filename]
     else:
         blob_reader = BlobReader(filename)
         context.blob_reader_from_filename[filename] = blob_reader
 
     if dtype == types.uint8:
-        np_value = np.array(blob_reader.read_uint8_data(offset), np.uint8)
+        np_value = blob_reader.read_uint8_data(offset)
     elif dtype == types.int8:
-        np_value = np.array(blob_reader.read_int8_data(offset), np.int8)
+        np_value = blob_reader.read_int8_data(offset)
+    elif dtype == types.uint16:
+        np_value = blob_reader.read_uint16_data(offset)
+    elif dtype == types.int16:
+        np_value = blob_reader.read_int16_data(offset)
     elif dtype == types.fp16:
-        np_value_uint16 = np.array(blob_reader.read_fp16_data(offset), np.uint16)
+        np_value_uint16 = blob_reader.read_fp16_data(offset)
         np_value = np.frombuffer(np_value_uint16.tobytes(), np.float16)
     elif dtype == types.fp32:
-        np_value = np.array(blob_reader.read_float_data(offset), np.float32)
+        np_value = blob_reader.read_float_data(offset)
     else:
         raise ValueError("Invalid dtype for blob file value type")
 
     return np_value
 
 
 def _load_value(context, value_spec):
@@ -259,17 +263,14 @@
 
     else:
         if op_type == "custom_layer":
             raise NotImplementedError(
                 "Loading Custom Layer operation not yet implemented"
             )
 
-        if op_spec.attributes:
-            raise ValueError("Attributes on operation not supported")
-
         # The conversion steps of an operation proto -> PyMIL operation are as following:
 
         # (i)   Convert the input arguments:
         #       In most of the cases, the input variable is already created beforehand, hence we can
         #       directly access and get them through the TranscriptionContext.
         #       There are cases, though, the inputs are literal value. This could happens in the classify op spec.
         #       For that case, we directly create a constant variable.
@@ -285,15 +286,20 @@
 
         # (iii) Create PyMIL operation using inputs / blocks
         #       Note that for the control flow cases, we create dummy functional inputs, and use the exisiting block to create the op.
 
         # (iv)  Set the outer_op for control flow
         #       Once the operation is created, we replace the dummy outer_op with the legit one, to make it a valid PyMIL program
 
-        inputs = {}
+        attrs = list(op_spec.attributes.items())
+        if len(attrs) > 0:
+            if len(attrs) != 1 or attrs[0][0] != "name":
+                raise ValueError("\"name\" is the only supported attribute for operation")
+        inputs = {k: _load_value(context, v) for k, v in op_spec.attributes.items()}
+
         for param_name, argument in op_spec.inputs.items():
             vars = []
             for binding in argument.arguments:
                 binding_type = binding.WhichOneof("binding")
                 if binding_type == "name":
                     vars.append(context.get_var_from_name(binding.name))
                 elif binding_type == "value":
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/milproto/test_load.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/milproto/test_load.py`

 * *Files 10% similar despite different names*

```diff
@@ -16,29 +16,32 @@
     load as milproto_to_pymil
 from coremltools.converters.mil.frontend.tensorflow.test.test_ops import \
     TestTensorArray
 from coremltools.converters.mil.frontend.tensorflow.test.testing_utils import \
     run_compare_tf
 from coremltools.converters.mil.mil.ops.tests.testing_utils import \
     compare_backend
-from coremltools.converters.mil.testing_utils import get_op_types_in_program
+from coremltools.converters.mil.testing_utils import (
+    get_op_names_in_program,
+    get_op_types_in_program
+)
 
 if _HAS_TORCH:
     import torch
     from coremltools.converters.mil.frontend.torch.test.test_torch_ops import \
         TestScriptedModels
 
 
 def get_pymil_prog_from_mlmodel(mlmodel):
     model_spec = mlmodel.get_spec()
     return milproto_to_pymil(
         model_spec=model_spec,
         specification_version=model_spec.specificationVersion,
         file_weights_dir=mlmodel.weights_dir,
-    )  
+    )
 
 def get_roundtrip_mlmodel(mlmodel):
     """
     This utility function does the following roundtrip conversion:
 
     mlprogram proto -> pymil program -> mlprogram model
     """
@@ -77,48 +80,80 @@
             x = mb.conv(x=x, weight=np.random.rand(10, 3, 2, 2), name="conv")
             x = mb.transpose(x=x, perm=[0, 3, 1, 2], name='transpose')
             x = mb.reduce_mean(x=x, axes=[2, 3], keep_dims=False, name='reduce')
             x = mb.log(x=x, name='log')
             return x
 
         # Convert it to MIL proto backed MLModel
-        mlmodel = ct.convert(prog, convert_to="mlprogram")
+        mlmodel = ct.convert(prog, convert_to="mlprogram", compute_units=ct.ComputeUnit.CPU_ONLY)
 
         # Load MLModel back to PyMIL
         loaded_pymil_prog = get_pymil_prog_from_mlmodel(mlmodel)
 
         # Assert that loaded PyMIL prog matches with defined PyMIL prog
         if get_op_types_in_program(loaded_pymil_prog) != get_op_types_in_program(prog):
             raise AssertionError("Mismatch between defined PyMIL prog and loaded PyMIL prog")
 
     def test_mil_proto_to_pymil_with_version_handling(self):
         # This test makes sure the correct version of the op is picked up during mil_proto -> pymil conversion
-        
+
         # iOS15 version program with iOS13 version topk
         @mb.program(input_specs=[mb.TensorSpec(shape=(1, 1, 4, 4))], opset_version=ct.target.iOS15)
         def prog(x):
             x = mb.topk(x=x, k=1, axis=-1, ascending=True)
             return x
 
-        iOS15_mlmodel = ct.convert(prog, convert_to="mlprogram", minimum_deployment_target=ct.target.iOS15)
+        iOS15_mlmodel = ct.convert(
+            prog,
+            convert_to="mlprogram",
+            minimum_deployment_target=ct.target.iOS15,
+            compute_units=ct.ComputeUnit.CPU_ONLY,
+        )
         iOS15_pymil_prog = get_pymil_prog_from_mlmodel(iOS15_mlmodel)
         topk_op = iOS15_pymil_prog.functions["main"].find_ops(op_type="topk")[0]
         assert not hasattr(topk_op, "sort")
 
         # iOS16 version program with iOS16 version topk
         @mb.program(input_specs=[mb.TensorSpec(shape=(1, 1, 4, 4))], opset_version=ct.target.iOS16)
         def prog(x):
             x = mb.topk(x=x, k=1, axis=-1, ascending=True)
             return x
 
-        iOS16_mlmodel = ct.convert(prog, convert_to="mlprogram", minimum_deployment_target=ct.target.iOS16)
+        iOS16_mlmodel = ct.convert(
+            prog,
+            convert_to="mlprogram",
+            minimum_deployment_target=ct.target.iOS16,
+            compute_units=ct.ComputeUnit.CPU_ONLY,
+        )
         iOS16_pymil_prog = get_pymil_prog_from_mlmodel(iOS16_mlmodel)
         topk_op = iOS16_pymil_prog.functions["main"].find_ops(op_type="topk")[0]
         assert hasattr(topk_op, "sort")
 
+    def test_mil_proto_preserving_ops_name(self):
+        # This test is checking the route source_model -> MIL -> mil_prot -> pymil is preserving the op name
+        # Define a PyMIL program
+        @mb.program(input_specs=[mb.TensorSpec(shape=(1, 3, 100, 100)), ])
+        def prog(x):
+            # MIL operation takes named inputs (instead of positional inputs).
+            # Here `name` argument is optional.
+            x = mb.relu(x=x, name='i_am_relu')
+            x = mb.conv(x=x, weight=np.random.rand(10, 3, 2, 2), name="i_am_conv")
+            x = mb.transpose(x=x, perm=[0, 3, 1, 2], name='i_am_transpose')
+            x = mb.reduce_mean(x=x, axes=[2, 3], keep_dims=False, name='i_am_reduce_mean')
+            x = mb.log(x=x, name='i_am_log')
+            return x
+
+        mlmodel = ct.convert(prog, convert_to="mlprogram", compute_units=ct.ComputeUnit.CPU_ONLY)
+        op_names = get_op_names_in_program(mlmodel._mil_program, skip_const_ops=False)
+
+        prog = get_pymil_prog_from_mlmodel(mlmodel)
+        new_op_names = get_op_names_in_program(prog, skip_const_ops=False)
+
+        assert op_names == new_op_names
+
 @pytest.mark.skipif(ct.utils._macos_version() < (12, 0), reason="mlprogram predict available only on macOS12+")
 class TestE2ENumericalCorrectness:
     @pytest.mark.skipif(not _HAS_TORCH, reason="requires torch")
     def test_elu(self):
         inputs = [ct.TensorType(name="data", shape=(2, 3, 1))]
         input_data = [torch.rand(*i.shape.to_list()) for i in inputs]
         torchmodel = torch.jit.trace(torch.nn.ELU(inplace=False), input_data)
@@ -187,13 +222,13 @@
     @pytest.mark.skipif(_HAS_TF_2, reason="Fix and re-enable this test: rdar://76293949 (TF2 unit test InvalidArgumentError)")
     def test_list(self):
         model, inputs, outputs = TestTensorArray.get_dynamic_elem_shape_model()
         input_values = [np.random.rand(2, 3)]
         input_dict = dict(zip(inputs, input_values))
         _, mlmodel, _, _ = run_compare_tf(
             model,
-            input_dict, 
+            input_dict,
             outputs,
             compute_unit=ct.ComputeUnit.CPU_ONLY,
             backend=("mlprogram", "fp16")
         )
         roundtrip_and_compare_mlmodel(mlmodel, {"Placeholder": input_values[0]})
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/__init__.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/__init__.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/basic_graph_ops.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/basic_graph_ops.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/convert_utils.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/convert_utils.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/converter.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/converter.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/dialect_ops.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/dialect_ops.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/dot_visitor.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/dot_visitor.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/load.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/load.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/naming_utils.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/naming_utils.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/ops.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/ops.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,26 +1,23 @@
 #  Copyright (c) 2020, Apple Inc. All rights reserved.
 #
 #  Use of this source code is governed by a BSD-3-clause license that can be
 #  found in the LICENSE.txt file or at https://opensource.org/licenses/BSD-3-Clause
 
 import numpy as _np
+import numpy as np
 
 from coremltools import _logger as logger
-from coremltools.converters.mil._deployment_compatibility import \
-    AvailableTarget as target
+from coremltools.converters.mil._deployment_compatibility import AvailableTarget as target
 from coremltools.converters.mil.mil import Builder as mb
 from coremltools.converters.mil.mil import types
-from coremltools.converters.mil.mil.block import \
-    is_current_opset_version_compatible_with
-from coremltools.converters.mil.mil.ops.defs._utils import (
-    broadcast_shapes, promote_input_dtypes)
+from coremltools.converters.mil.mil.block import is_current_opset_version_compatible_with
+from coremltools.converters.mil.mil.ops.defs._utils import broadcast_shapes, promote_input_dtypes
 from coremltools.converters.mil.mil.types import builtin_to_string
-from coremltools.converters.mil.mil.types.symbolic import (any_symbolic,
-                                                           is_symbolic)
+from coremltools.converters.mil.mil.types.symbolic import is_symbolic
 
 from .._utils import build_einsum_mil
 from .convert_utils import convert_graph
 from .tf_op_registry import register_tf_op
 
 
 def _adjust_min_max(min, max, num_bits=8):
@@ -581,15 +578,15 @@
         raise ValueError(
             "ExtractImagePatches only supports sizes (4D tensor) with 1s for batch and channel dimensions."
         )
     if len(sizes) != 4 or strides[0] != 1 or strides[3] != 1:
         raise ValueError(
             "ExtractImagePatches only supports strides (4D tensor) with 1s for batch and channel dimensions."
         )
-    if not padding in ["VALID", "SAME"]:
+    if padding not in ["VALID", "SAME"]:
         raise ValueError("non-supported padding for ExtractImagePatches.")
     h, w = x.shape[1], x.shape[2]
 
     # padding for SAME mode
     if padding == "SAME":
         delta_h = h % strides[1] if h % strides[1] != 0 else strides[1]
         delta_w = w % strides[2] if w % strides[2] != 0 else strides[2]
@@ -616,30 +613,40 @@
 
     boxes = _np.array(boxes, dtype=_np.float32)
     box_indices = _np.arange(batch)
     box_indices = _np.tile(box_indices, (len(boxes), 1))
     box_indices = _np.transpose(box_indices)
     box_indices = box_indices.reshape(-1, 1)
     boxes = _np.tile(boxes, (batch, 1))
-    boxes = _np.concatenate([box_indices, boxes], axis=1)
-    boxes = boxes.reshape(boxes.shape[0], 1, boxes.shape[1], 1, 1)
 
-    # use crop_and_resize
     x = _transpose_NHWC_to_NCHW(x)
-    x = mb.crop_resize(
-        x=x,
-        roi=boxes,
-        target_height=sizes[1],
-        target_width=sizes[2],
-        normalized_coordinates=False,
-        spatial_scale=1.0,
-        box_coordinate_mode="CORNERS_HEIGHT_FIRST",
-        sampling_mode="ALIGN_CORNERS",
-    )
-    x = mb.squeeze(x=x, axes=[1])
+    crop_resize_args = {
+        "x": x,
+        "target_height": sizes[1],
+        "target_width": sizes[2],
+        "normalized_coordinates": False,
+        "spatial_scale": 1.0,
+        "box_coordinate_mode": "CORNERS_HEIGHT_FIRST",
+        "sampling_mode": "ALIGN_CORNERS",
+    }
+    if not is_current_opset_version_compatible_with(target.iOS17):
+        # Before IOS17, boxes need to be shape [N,1,4,1,1] or [N,1,5,1,1].
+        boxes = _np.concatenate([box_indices, boxes], axis=1)
+        boxes = boxes.reshape(boxes.shape[0], 1, boxes.shape[1], 1, 1)
+        # Before IOS17, the input param is `roi` instead of `boxes`.
+        crop_resize_args["roi"] = boxes
+        x = mb.crop_resize(**crop_resize_args)
+        # Before IOS17, the output has an extra dim at axis 1.
+        x = mb.squeeze(x=x, axes=[1])
+    else:
+        # At this point `boxes` has shape [N, 4], which is good enough for IOS17+.
+        crop_resize_args["boxes"] = boxes
+        box_indices = np.squeeze(box_indices, axis=-1)
+        crop_resize_args["box_indices"] = box_indices
+        x = mb.crop_resize(**crop_resize_args)
     x = _transpose_NCHW_to_NHWC(x, node_name=node.name + "_transpose_to_nhwc")
     x = mb.reshape(x=x, shape=(batch, len(h_index), len(w_index), -1), name=node.name)
     context.add(node.name, x)
 
 
 @register_tf_op
 def Exp(context, node):
@@ -2253,14 +2260,15 @@
 def Gather(context, node):
     x = context[node.inputs[0]]
     indices = context[node.inputs[1]]
     axis = 0
     x = mb.gather(x=x, indices=indices, axis=axis, name=node.name)
     context.add(node.name, x)
 
+
 def _perform_gather_with_batch_dims(x, indices, batch_dims, gather_func, func_args, name):
     """
     An utility function to compute gather and gather_nd with batch_dims
     """
     # (Step 1)
     # Reshape x, indices with shape
     # x: [batch_1, ..., batch_n, *remaining_x_shape]
@@ -3007,24 +3015,26 @@
         x = mb.fill(shape=mb.shape(x=x), value=np_type(0), name=node.name)
     context.add(node.name, x)
 
 
 @register_tf_op
 def IsFinite(context, node):
     x = context[node.inputs[0]]
-    if any_symbolic(x.shape):
-        x_shape = mb.shape(x=x)
-    else:
-        x_shape = [1] if x.shape == () else x.shape
-    max_tensor = mb.fill(shape=x_shape, value=_np.finfo(_np.float32).max)
-    min_tensor = mb.fill(shape=x_shape, value=_np.finfo(_np.float32).min)
-    less_then = mb.less_equal(x=x, y=max_tensor)
-    greater_than = mb.greater_equal(x=x, y=min_tensor)
-    x = mb.logical_and(x=less_then, y=greater_than, name=node.name)
-    context.add(node.name, x)
+
+    # In floating-point arithmetic, symbolically, inf + anything = inf,
+    # so we can detect if x is finite by x + y != x
+    #
+    # To avoid false alarm, i.e. x + y = x due to rounding error for small y,
+    # here we use the fp16 max as y
+    dtype = types.nptype_from_builtin(x.sym_type.get_primitive())
+    y_add = dtype(_np.finfo(_np.float16).max)
+    x_plus = mb.add(x=x, y=y_add)
+    result = mb.not_equal(x=x, y=x_plus, name=node.name)
+
+    context.add(node.name, result)
 
 
 @register_tf_op
 def CropAndResize(context, node):
     x = context[node.inputs[0]]
     input_shape = x.shape  # (B, h_in, w_in, C)
     if len(input_shape) != 4:
@@ -3041,28 +3051,30 @@
     method = node.attr.get("method", "bilinear")
     pad_value = node.attr.get("extrapolation_value", 0.0)
 
     # CoreML index information along with boxes
     if const_box_info:
         boxes = context[node.inputs[1]].val
         box_indices = context[node.inputs[2]].val
-        box_indices = _np.expand_dims(box_indices, axis=1)
-        boxes = _np.concatenate([box_indices, boxes], axis=1)
-        # CoreML expects boxes/ROI in
-        # [N, 1, 5, 1, 1] format
-        boxes = boxes.reshape(boxes.shape[0], 1, boxes.shape[1], 1, 1)
+        if not is_current_opset_version_compatible_with(target.iOS17):
+            # Before IOS17, CoreML expects boxes/ROI in [N, 1, 5, 1, 1] shape.
+            box_indices = _np.expand_dims(box_indices, axis=1)
+            boxes = _np.concatenate([box_indices, boxes], axis=1)
+            boxes = boxes.reshape(boxes.shape[0], 1, boxes.shape[1], 1, 1)
     else:
         box_indices = context[node.inputs[2]]
         boxes = context[node.inputs[1]]
-        box_indices = mb.expand_dims(x=box_indices, axes=[1])
-        if box_indices.dtype != boxes.dtype:
-            box_indices = mb.cast(x=box_indices, dtype=types.builtin_to_string(boxes.dtype))
-        boxes = mb.concat(values=(box_indices, boxes), axis=1)
-        # TODO: Dynamic rank: Use GetShape and select indices dynamically
-        boxes = mb.reshape(x=boxes, shape=[boxes.shape[0], 1, boxes.shape[1], 1, 1])
+        if not is_current_opset_version_compatible_with(target.iOS17):
+            # Before IOS17, CoreML expects ROI in [N, 1, 5, 1, 1] shape.
+            if box_indices.dtype != boxes.dtype:
+                box_indices = mb.cast(x=box_indices, dtype=types.builtin_to_string(boxes.dtype))
+            box_indices = mb.expand_dims(x=box_indices, axes=[1])
+            boxes = mb.concat(values=(box_indices, boxes), axis=1)
+            # TODO: Dynamic rank: Use GetShape and select indices dynamically
+            boxes = mb.reshape(x=boxes, shape=[boxes.shape[0], 1, boxes.shape[1], 1, 1])
 
     # Get Height and Width of crop
     h_out, w_out = crop_size[0], crop_size[1]
 
     # TF `nearest` mode not supported
     method_map = {"bilinear": "ALIGN_CORNERS"}
     if method not in method_map:
@@ -3074,38 +3086,44 @@
     method = method_map[method]
 
     # TF input format: [B, h_in, w_in, C]
     # CoreML input format: [B, C, h_in, w_in]
     x = _transpose_NHWC_to_NCHW(x)
 
     # Crop Resize
-    args = {
+    crop_resize_args = {
         "x": x,
-        "roi": boxes,
         "target_height": h_out,
         "target_width": w_out,
         "normalized_coordinates": True,
         "spatial_scale": 1.0,
         "box_coordinate_mode": "CORNERS_HEIGHT_FIRST",
         "sampling_mode": method,
     }
     if is_current_opset_version_compatible_with(target.iOS16):
-        args["pad_value"] = pad_value
+        crop_resize_args["pad_value"] = pad_value
     else:
         if pad_value != 0.0:
-            msg = (
-                    "For iOS15 or older, only extrapolation_value=0.0 is supported or the tf CropAndResize op. "
-                    "Got {}"
-            ).format(pad_value)
-            raise ValueError(msg)
-    x = mb.crop_resize(**args)
-
-    # CoreML output format: [N, 1, C, h_out, w_out]
-    # TF output format: [N, h_out, w_out, C]
-    x = mb.squeeze(x=x, axes=[1])
+            raise ValueError(
+                f"For iOS15 or older, only extrapolation_value=0.0 is supported or the tf CropAndResize op. Got {pad_value}"
+            )
+    if not is_current_opset_version_compatible_with(target.iOS17):
+        # Before IOS17, the input param is `roi` instead of `boxes`.
+        crop_resize_args["roi"] = boxes
+    else:
+        crop_resize_args["boxes"] = boxes
+        crop_resize_args["box_indices"] = box_indices
+
+    x = mb.crop_resize(**crop_resize_args)
+
+    if not is_current_opset_version_compatible_with(target.iOS17):
+        # Before IOS17, the output has an extra dim at axis 1.
+        # CoreML output format: [N, 1, C, h_out, w_out]
+        # TF output format: [N, h_out, w_out, C]
+        x = mb.squeeze(x=x, axes=[1])
     x = _transpose_NCHW_to_NHWC(x, node.name)
     context.add(node.name, x)
 
 
 @register_tf_op
 def TensorArrayV3(context, node):
     if "infer_shape" in node.attr:
@@ -3124,15 +3142,15 @@
         init_length = size.val
         if init_length == 0:
             # Dynamic list. Use 1 as init_length
             init_length = 1
 
     builtin_dtype = node.attr["dtype"]
     dtype_str = types.builtin_to_string(builtin_dtype)
-    if elem_shape is not None and not -1 in elem_shape:
+    if elem_shape is not None and -1 not in elem_shape:
         ls = mb.make_list(
             init_length=init_length,
             dtype=dtype_str,
             elem_shape=elem_shape,
             dynamic_length=dynamic_length,
             name=node.name,
         )
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/parse.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/parse.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/parsed_tf_node.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/parsed_tf_node.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/ssa_passes/backfill_make_list_elem_type.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/ssa_passes/backfill_make_list_elem_type.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/ssa_passes/expand_tf_lstm.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/ssa_passes/expand_tf_lstm.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/ssa_passes/test_passes.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/ssa_passes/test_passes.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/ssa_passes/tf_lstm_to_core_lstm.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/ssa_passes/tf_lstm_to_core_lstm.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/test/test_composite_ops.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/test/test_composite_ops.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/test/test_custom_ops.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/test/test_custom_ops.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/test/test_graphs.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/test/test_graphs.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/test/test_load.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/test/test_load.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/test/test_ops.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/test/test_ops.py`

 * *Files 2% similar despite different names*

```diff
@@ -2,43 +2,47 @@
 #
 #  Use of this source code is governed by a BSD-3-clause license that can be
 #  found in the LICENSE.txt file or at https://opensource.org/licenses/BSD-3-Clause
 
 import itertools
 import math
 import os
+import platform
 import shutil
 import tempfile
 from distutils.version import StrictVersion
+from typing import Optional
 
 import numpy as np
 import pytest
 
 import coremltools as ct
 from coremltools import RangeDim, TensorType
 from coremltools._deps import _HAS_TF_1, _HAS_TF_2, MSG_TF1_NOT_FOUND, _get_version
 from coremltools.converters.mil.frontend.tensorflow.test.testing_utils import (
     TensorFlowBaseTest,
     freeze_g,
     layer_counts,
     load_tf_pb,
     make_tf_graph,
 )
+from coremltools.converters.mil.mil import Operation, Program, types
 from coremltools.converters.mil.testing_reqs import backends, compute_units
 from coremltools.converters.mil.testing_utils import (
     einsum_equations,
     gen_input_shapes_einsum,
     random_gen,
 )
 from coremltools.models.utils import _is_macos, _macos_version
 
 tf = pytest.importorskip("tensorflow")
 
 PREBUILT_TF1_WHEEL_VERSION = "1.15.5"
 
+
 @pytest.mark.skipif(not _HAS_TF_1, reason=MSG_TF1_NOT_FOUND)
 class TestContribResampler(TensorFlowBaseTest):
     @pytest.mark.parametrize(
         "compute_unit, backend, data_warp_shapes",
         itertools.product(
             compute_units,
             backends,
@@ -247,400 +251,395 @@
             input_dict,
             outputs,
             compute_unit=compute_unit,
             backend=backend,
         )
 
 
-class TestActivationElu(TensorFlowBaseTest):
+class TestActivation(TensorFlowBaseTest):
+    @staticmethod
+    def run_compare_tf(model, input_dict, outputs, target_op: Optional[str] = None, **kwargs):
+        """Override compare method for Activation ops tests, as we want to verify the mixed
+        precision support for alpha/beta in IOS17 Activation Ops."""
+        results = TensorFlowBaseTest.run_compare_tf(model, input_dict, outputs, **kwargs)
+
+        if target_op and kwargs.get("backend", (None, None))[1] == "fp16":
+            prog: Program = results[1]._mil_program
+            activation_op: Operation = prog.find_ops(op_type=target_op, exactly_one=True)[0]
+            assert activation_op.x.dtype == types.fp16
+
+            # Before IOS17, both alpha and input/output are converted to fp16.
+            # After IOS17, alpha is kept as fp32 because it supports mixed precision.
+            expected_alpha_beta_dtype = types.fp16
+            if kwargs.get("minimum_deployment_target", None) == ct.target.iOS17:
+                expected_alpha_beta_dtype = types.fp32
+            if hasattr(activation_op, "alpha"):
+                assert activation_op.alpha.dtype == expected_alpha_beta_dtype
+            if hasattr(activation_op, "beta"):
+                assert activation_op.beta.dtype == expected_alpha_beta_dtype
+
+        return results
+
     @pytest.mark.parametrize(
-        "compute_unit, backend, rank",
+        "compute_unit, backend, rank, minimum_deployment_target",
         itertools.product(
             compute_units,
             backends,
-            [rank for rank in range(1, 6)]
+            [rank for rank in range(1, 6)],
+            [None, ct.target.iOS17],
         ),
     )
-    def test(self, compute_unit, backend, rank):
+    def test_elu(self, compute_unit, backend, rank, minimum_deployment_target):
         input_shape = np.random.randint(low=1, high=4, size=rank)
 
         @make_tf_graph([input_shape])
         def build_model(x):
             return tf.nn.elu(x)
 
         model, inputs, outputs = build_model
 
         input_values = [random_gen(input_shape, -1, 1)]
         input_dict = dict(zip(inputs, input_values))
-        TensorFlowBaseTest.run_compare_tf(
+        self.run_compare_tf(
             model,
             input_dict,
             outputs,
             compute_unit=compute_unit,
             backend=backend,
+            minimum_deployment_target=minimum_deployment_target,
+            target_op="elu",
         )
 
-
-class TestAddN(TensorFlowBaseTest):
     @pytest.mark.parametrize(
-        "compute_unit, backend, rank, num_inputs",
+        "compute_unit, backend, rank, minimum_deployment_target",
         itertools.product(
             compute_units,
             backends,
-            list(range(6)),
-            [1, 3, 9],
+            [rank for rank in range(1, 6)],
+            [None, ct.target.iOS17],
         ),
     )
-    def test(self, compute_unit, backend, rank, num_inputs):
-        if rank == 0:
-            pytest.skip('Rank 0 not supported by CoreML runtime')
-
+    def test_leaky_relu(self, compute_unit, backend, rank, minimum_deployment_target):
         input_shape = np.random.randint(low=1, high=4, size=rank)
-        input_shapes = [input_shape[:] for _ in range(num_inputs)]
 
-        @make_tf_graph(input_shapes)
-        def build_model(*inputs):
-            return tf.raw_ops.AddN(inputs=inputs)
+        @make_tf_graph([input_shape])
+        def build_model(x):
+            return tf.nn.leaky_relu(x, 0.2)
 
         model, inputs, outputs = build_model
-        input_values = [random_gen(shape, -1, 1) for shape in input_shapes]
+
+        input_values = [random_gen(input_shape, -1, 1)]
         input_dict = dict(zip(inputs, input_values))
-        TensorFlowBaseTest.run_compare_tf(
+        self.run_compare_tf(
             model,
             input_dict,
             outputs,
             compute_unit=compute_unit,
             backend=backend,
+            minimum_deployment_target=minimum_deployment_target,
+            target_op="leaky_relu",
         )
 
-
-class TestAddOrdering(TensorFlowBaseTest):
     @pytest.mark.parametrize(
-        "compute_unit, backend",
-        itertools.product(compute_units, backends),
+        "compute_unit, backend, rank",
+        itertools.product(compute_units, backends, [rank for rank in range(1, 6)]),
     )
-    def test(self, compute_unit, backend):
-        @make_tf_graph([(2, 3, 4), (2, 3, 4)])
-        def build_model(x, y):
-            return tf.math.add(x, y)
+    def test_relu(self, compute_unit, backend, rank):
+        input_shape = np.random.randint(low=1, high=4, size=rank)
+
+        @make_tf_graph([input_shape])
+        def build_model(x):
+            return tf.nn.relu(x)
 
         model, inputs, outputs = build_model
-        input_values = [random_gen((2, 3, 4), -1, 1)] * 2
-        input_dict = dict(zip(inputs, input_values))
 
-        spec, _, _, _, _, _ = TensorFlowBaseTest.run_compare_tf(
+        input_values = [random_gen(input_shape, -10.0, 10)]
+        input_dict = dict(zip(inputs, input_values))
+        self.run_compare_tf(
             model,
             input_dict,
             outputs,
             compute_unit=compute_unit,
             backend=backend,
         )
 
-        if backend[0] == "neuralnetwork":
-            nn_spec = spec.neuralNetwork
-            if _HAS_TF_1:
-                input_names = ["Placeholder", "Placeholder_1"]
-            elif _HAS_TF_2:
-                input_names = ["args_0", "args_1"]
-
-            assert nn_spec.layers[0].input[0] == input_names[0]
-            assert nn_spec.layers[0].input[1] == input_names[1]
-
-
-class TestActivationLeakyReLU(TensorFlowBaseTest):
     @pytest.mark.parametrize(
         "compute_unit, backend, rank",
-        itertools.product(
-            compute_units,
-            backends,
-            [rank for rank in range(1, 6)]
-        ),
+        itertools.product(compute_units, backends, [rank for rank in range(1, 6)]),
     )
-    def test(self, compute_unit, backend, rank):
+    def test_relu6(self, compute_unit, backend, rank):
         input_shape = np.random.randint(low=1, high=4, size=rank)
 
         @make_tf_graph([input_shape])
         def build_model(x):
-            return tf.nn.leaky_relu(x, 0.2)
+            return tf.nn.relu6(x)
 
         model, inputs, outputs = build_model
 
         input_values = [random_gen(input_shape, -1, 1)]
         input_dict = dict(zip(inputs, input_values))
-        TensorFlowBaseTest.run_compare_tf(
+        self.run_compare_tf(
             model,
             input_dict,
             outputs,
             compute_unit=compute_unit,
             backend=backend,
         )
 
-
-class TestActivationReLU(TensorFlowBaseTest):
     @pytest.mark.parametrize(
         "compute_unit, backend, rank",
-        itertools.product(
-            compute_units,
-            backends,
-            [rank for rank in range(1, 6)]
-        ),
+        itertools.product(compute_units, backends, [rank for rank in range(1, 6)]),
     )
-    def test(self, compute_unit, backend, rank):
+    def test_sigmoid(self, compute_unit, backend, rank):
         input_shape = np.random.randint(low=1, high=4, size=rank)
 
         @make_tf_graph([input_shape])
         def build_model(x):
-            return tf.nn.relu(x)
+            return tf.math.sigmoid(x)
 
         model, inputs, outputs = build_model
 
-        input_values = [random_gen(input_shape, -10.0, 10)]
+        input_values = [random_gen(input_shape, -1, 1)]
         input_dict = dict(zip(inputs, input_values))
-        TensorFlowBaseTest.run_compare_tf(
+        self.run_compare_tf(
             model,
             input_dict,
             outputs,
             compute_unit=compute_unit,
             backend=backend,
         )
 
-
-class TestActivationReLU6(TensorFlowBaseTest):
     @pytest.mark.parametrize(
         "compute_unit, backend, rank",
-        itertools.product(
-            compute_units,
-            backends,
-            [rank for rank in range(1, 6)]
-        ),
+        itertools.product(compute_units, backends, [rank for rank in range(1, 6)]),
     )
-    def test(self, compute_unit, backend, rank):
+    def test_softplus(self, compute_unit, backend, rank):
         input_shape = np.random.randint(low=1, high=4, size=rank)
 
         @make_tf_graph([input_shape])
         def build_model(x):
-            return tf.nn.relu6(x)
+            return tf.math.softplus(x)
 
         model, inputs, outputs = build_model
 
         input_values = [random_gen(input_shape, -1, 1)]
         input_dict = dict(zip(inputs, input_values))
-        TensorFlowBaseTest.run_compare_tf(
+        self.run_compare_tf(
             model,
             input_dict,
             outputs,
             compute_unit=compute_unit,
             backend=backend,
         )
 
-
-class TestGelu(TensorFlowBaseTest):
     @pytest.mark.parametrize(
-        "compute_unit, backend, rank, mode",
+        "compute_unit, backend, rank_and_axes",
         itertools.product(
             compute_units,
             backends,
-            [rank for rank in range(2, 3)],
-            ("tanh_approx", "exact_1", "exact_2", "exact_3")
+            [(rank, axis) for rank in range(1, 6) for axis in range(-1, rank)],
         ),
     )
-    def test(self, compute_unit, backend, rank, mode):
+    def test_softmax(self, compute_unit, backend, rank_and_axes):
+        rank, axis = rank_and_axes
         input_shape = np.random.randint(low=1, high=4, size=rank)
 
         @make_tf_graph([input_shape])
-        def build_model_tanh_approx(x):
-            a = 0.5 * (
-                1.0 + tf.tanh((math.sqrt(2 / math.pi) * (x + 0.044715 * tf.pow(x, 3))))
-            )
-            return a * x
-
-        @make_tf_graph([input_shape])
-        def build_model_exact_1(x):
-            return x * (0.5 * (1.0 + tf.math.erf(x / tf.math.sqrt(2.0))))
-
-        @make_tf_graph([input_shape])
-        def build_model_exact_2(x):
-            return 0.5 * (x * (1.0 + tf.math.erf(x / tf.math.sqrt(2.0))))
-
-        @make_tf_graph([input_shape])
-        def build_model_exact_3(x):
-            return (x * 0.5) * (1.0 + tf.math.erf(x / tf.math.sqrt(2.0)))
-
-        if mode == "tanh_approx":
-            build_model = build_model_tanh_approx
-        elif mode == "exact_1":
-            build_model = build_model_exact_1
-        elif mode == "exact_2":
-            build_model = build_model_exact_2
-        elif mode == "exact_3":
-            build_model = build_model_exact_3
-        else:
-            raise ValueError("Unexpected mode for Gelu layer")
+        def build_model(x):
+            return tf.nn.softmax(x, axis=axis)
 
         model, inputs, outputs = build_model
 
-        input_values = [random_gen(input_shape, -5, 5)]
+        input_values = [random_gen(input_shape, -1, 1)]
         input_dict = dict(zip(inputs, input_values))
-        spec, mlmodel, _, _, _, _ = TensorFlowBaseTest.run_compare_tf(
+        self.run_compare_tf(
             model,
             input_dict,
             outputs,
             compute_unit=compute_unit,
             backend=backend,
         )
-        assert TestGelu._op_count_in_mil_program(mlmodel, "gelu") == 1
-        assert TestGelu._op_count_in_mil_program(mlmodel, "erf") == 0
-        assert TestGelu._op_count_in_mil_program(mlmodel, "pow") == 0
-        assert TestGelu._op_count_in_mil_program(mlmodel, "tanh") == 0
 
-
-class TestActivationSigmoid(TensorFlowBaseTest):
     @pytest.mark.parametrize(
         "compute_unit, backend, rank",
-        itertools.product(
-            compute_units,
-            backends,
-            [rank for rank in range(1, 6)]
-        ),
+        itertools.product(compute_units, backends, [rank for rank in range(1, 6)]),
     )
-    def test(self, compute_unit, backend, rank):
+    def test_softsign(self, compute_unit, backend, rank):
         input_shape = np.random.randint(low=1, high=4, size=rank)
 
         @make_tf_graph([input_shape])
         def build_model(x):
-            return tf.math.sigmoid(x)
+            return tf.math.softsign(x)
 
         model, inputs, outputs = build_model
 
         input_values = [random_gen(input_shape, -1, 1)]
         input_dict = dict(zip(inputs, input_values))
-        TensorFlowBaseTest.run_compare_tf(
+        self.run_compare_tf(
             model,
             input_dict,
             outputs,
             compute_unit=compute_unit,
             backend=backend,
         )
 
-
-class TestActivationSoftPlus(TensorFlowBaseTest):
     @pytest.mark.parametrize(
-        "compute_unit, backend, rank",
+        "compute_unit, backend, rank, minimum_deployment_target",
         itertools.product(
             compute_units,
             backends,
-            [rank for rank in range(1, 6)]
+            [rank for rank in range(1, 6)],
+            [None, ct.target.iOS17],
         ),
     )
-    def test(self, compute_unit, backend, rank):
+    def test_selu(self, compute_unit, backend, rank, minimum_deployment_target):
         input_shape = np.random.randint(low=1, high=4, size=rank)
 
         @make_tf_graph([input_shape])
         def build_model(x):
-            return tf.math.softplus(x)
+            return tf.nn.selu(x)
 
         model, inputs, outputs = build_model
 
-        input_values = [random_gen(input_shape, -1, 1)]
+        input_values = [random_gen(input_shape, -1.0, 1.0)]
         input_dict = dict(zip(inputs, input_values))
-        TensorFlowBaseTest.run_compare_tf(
+        self.run_compare_tf(
             model,
             input_dict,
             outputs,
             compute_unit=compute_unit,
             backend=backend,
+            minimum_deployment_target=minimum_deployment_target,
+            target_op="elu",
         )
 
 
-class TestActivationSoftmax(TensorFlowBaseTest):
+class TestAddN(TensorFlowBaseTest):
     @pytest.mark.parametrize(
-        "compute_unit, backend, rank_and_axes",
+        "compute_unit, backend, rank, num_inputs",
         itertools.product(
             compute_units,
             backends,
-            [(rank, axis) for rank in range(1, 6) for axis in range(-1, rank)],
+            list(range(6)),
+            [1, 3, 9],
         ),
     )
-    def test(self, compute_unit, backend, rank_and_axes):
-        rank, axis = rank_and_axes
+    def test(self, compute_unit, backend, rank, num_inputs):
+        if rank == 0:
+            pytest.skip('Rank 0 not supported by CoreML runtime')
+
         input_shape = np.random.randint(low=1, high=4, size=rank)
+        input_shapes = [input_shape[:] for _ in range(num_inputs)]
 
-        @make_tf_graph([input_shape])
-        def build_model(x):
-            return tf.nn.softmax(x, axis=axis)
+        @make_tf_graph(input_shapes)
+        def build_model(*inputs):
+            return tf.raw_ops.AddN(inputs=inputs)
 
         model, inputs, outputs = build_model
-
-        input_values = [random_gen(input_shape, -1, 1)]
+        input_values = [random_gen(shape, -1, 1) for shape in input_shapes]
         input_dict = dict(zip(inputs, input_values))
         TensorFlowBaseTest.run_compare_tf(
             model,
             input_dict,
             outputs,
             compute_unit=compute_unit,
             backend=backend,
         )
 
 
-class TestActivationSoftSign(TensorFlowBaseTest):
+class TestAddOrdering(TensorFlowBaseTest):
     @pytest.mark.parametrize(
-        "compute_unit, backend, rank",
-        itertools.product(
-            compute_units,
-            backends,
-            [rank for rank in range(1, 6)]
-        ),
+        "compute_unit, backend",
+        itertools.product(compute_units, backends),
     )
-    def test(self, compute_unit, backend, rank):
-        input_shape = np.random.randint(low=1, high=4, size=rank)
-
-        @make_tf_graph([input_shape])
-        def build_model(x):
-            return tf.math.softsign(x)
+    def test(self, compute_unit, backend):
+        @make_tf_graph([(2, 3, 4), (2, 3, 4)])
+        def build_model(x, y):
+            return tf.math.add(x, y)
 
         model, inputs, outputs = build_model
-
-        input_values = [random_gen(input_shape, -1, 1)]
+        input_values = [random_gen((2, 3, 4), -1, 1)] * 2
         input_dict = dict(zip(inputs, input_values))
-        TensorFlowBaseTest.run_compare_tf(
+
+        spec, _, _, _, _, _ = TensorFlowBaseTest.run_compare_tf(
             model,
             input_dict,
             outputs,
             compute_unit=compute_unit,
             backend=backend,
         )
 
+        if backend[0] == "neuralnetwork":
+            nn_spec = spec.neuralNetwork
+            if _HAS_TF_1:
+                input_names = ["Placeholder", "Placeholder_1"]
+            elif _HAS_TF_2:
+                input_names = ["args_0", "args_1"]
+
+            assert nn_spec.layers[0].input[0] == input_names[0]
+            assert nn_spec.layers[0].input[1] == input_names[1]
 
-class TestActivationSelu(TensorFlowBaseTest):
+class TestGelu(TensorFlowBaseTest):
     @pytest.mark.parametrize(
-        "compute_unit, backend, rank",
+        "compute_unit, backend, rank, mode",
         itertools.product(
             compute_units,
             backends,
-            [rank for rank in range(1, 6)]
+            [rank for rank in range(2, 3)],
+            ("tanh_approx", "exact_1", "exact_2", "exact_3")
         ),
     )
-    def test(self, compute_unit, backend, rank):
+    def test(self, compute_unit, backend, rank, mode):
         input_shape = np.random.randint(low=1, high=4, size=rank)
 
         @make_tf_graph([input_shape])
-        def build_model(x):
-            return tf.nn.selu(x)
+        def build_model_tanh_approx(x):
+            a = 0.5 * (
+                1.0 + tf.tanh((math.sqrt(2 / math.pi) * (x + 0.044715 * tf.pow(x, 3))))
+            )
+            return a * x
+
+        @make_tf_graph([input_shape])
+        def build_model_exact_1(x):
+            return x * (0.5 * (1.0 + tf.math.erf(x / tf.math.sqrt(2.0))))
+
+        @make_tf_graph([input_shape])
+        def build_model_exact_2(x):
+            return 0.5 * (x * (1.0 + tf.math.erf(x / tf.math.sqrt(2.0))))
+
+        @make_tf_graph([input_shape])
+        def build_model_exact_3(x):
+            return (x * 0.5) * (1.0 + tf.math.erf(x / tf.math.sqrt(2.0)))
+
+        if mode == "tanh_approx":
+            build_model = build_model_tanh_approx
+        elif mode == "exact_1":
+            build_model = build_model_exact_1
+        elif mode == "exact_2":
+            build_model = build_model_exact_2
+        elif mode == "exact_3":
+            build_model = build_model_exact_3
+        else:
+            raise ValueError("Unexpected mode for Gelu layer")
 
         model, inputs, outputs = build_model
 
-        input_values = [random_gen(input_shape, -1.0, 1.0)]
+        input_values = [random_gen(input_shape, -5, 5)]
         input_dict = dict(zip(inputs, input_values))
-        TensorFlowBaseTest.run_compare_tf(
+        spec, mlmodel, _, _, _, _ = TensorFlowBaseTest.run_compare_tf(
             model,
             input_dict,
             outputs,
             compute_unit=compute_unit,
             backend=backend,
         )
+        assert TestGelu._op_count_in_mil_program(mlmodel, "gelu") == 1
+        assert TestGelu._op_count_in_mil_program(mlmodel, "erf") == 0
+        assert TestGelu._op_count_in_mil_program(mlmodel, "pow") == 0
+        assert TestGelu._op_count_in_mil_program(mlmodel, "tanh") == 0
 
 
 class Testlog1p(TensorFlowBaseTest):
     @pytest.mark.parametrize(
         "compute_unit, backend, rank",
         itertools.product(
             compute_units,
@@ -2206,15 +2205,15 @@
             compute_units,
             backends,
             einsum_equations,
             [False, True],
         )
     )
     def test(self, compute_unit, backend, equation, reverse_input_order):
-        input_shapes, _ = gen_input_shapes_einsum(equation, False)
+        input_shapes, _ = gen_input_shapes_einsum(equation, False, backend)
         if _HAS_TF_1:
             if len(set(input_shapes[0])) < len(input_shapes[0]) or len(set(input_shapes[1])) < len(input_shapes[1]):
                 pytest.skip("tf1 does not support diagonal cases")
 
         if reverse_input_order:
             input_output_strings = equation.split('->')
             input_strings = input_output_strings[0].split(',')
@@ -2602,50 +2601,46 @@
         # also check if the scale factor are integers
         if backend[0] == 'neuralnetwork':
             for layer in spec.neuralNetwork.layers:
                 if layer.WhichOneof('layer') == "upsample":
                     assert len(layer.upsample.fractionalScalingFactor) == 0
 
     @pytest.mark.parametrize(
-        "compute_unit, backend, input_shape, num_of_crops, crop_size, method, dynamic, extrapolation_value",
+        "compute_unit, backend, input_shape, num_of_crops, crop_size, method, dynamic, "
+        "extrapolation_value, minimum_deployment_target",
         itertools.product(
             compute_units,
             backends,
             [(1, 64, 64, 1)],
             [1, 3, 5],
             [(2, 2), (1, 1), (4, 4), (128, 128)],
             ["bilinear"],
             [False, True],
             [0.0, 1.0],
+            [None, ct.target.iOS17],
         ),
     )
     def test_crop_and_resize(
         self,
         compute_unit,
         backend,
         input_shape,
         num_of_crops,
         crop_size,
         method,
         dynamic,
         extrapolation_value,
+        minimum_deployment_target,
     ):
-        if backend[0] == "mlprogram" and compute_unit != ct.ComputeUnit.CPU_ONLY and crop_size == (1, 1):
-            # in this case, there is a numerical mismatch on the GPU MIL backend. The GPU runtime tests are
-            # tracked seprately.
-            return
-
         if extrapolation_value != 0.0:
-            if backend[0] == "neuralnetwork":
-                pytest.xfail("pad_value not availabe in neural network backend.")
-            if ct.utils._macos_version() < (13, 0):
-                pytest.skip("pad_value not supported in macOS12 or older.")
-            minimum_deployment_target = ct.target.iOS16
-        else:
-            minimum_deployment_target = None
+            if minimum_deployment_target is None or minimum_deployment_target < ct.target.iOS16:
+                pytest.skip(
+                    "extrapolation_value (corresponds to `pad_value` in MIL crop_resize op) only "
+                    "supported in IOS16+."
+                )
 
         # rdar://98749492 (crop_resize is unstable for cropping out of bound setting in fp16)
         if backend[0] == "mlprogram":
             backend = ("mlprogram", "fp32")
 
         # TODO(rdar://98749492): Once resolved, set crop_bias = 0.5 in order to test the crop outside the image
         crop_bias = 0.0
@@ -2702,27 +2697,36 @@
                 backend=backend,
                 minimum_deployment_target=minimum_deployment_target,
             )
 
         test_dynamic() if dynamic else test_static()
 
     @pytest.mark.parametrize(
-        "compute_unit, backend, width, height, strides, sizes, padding,",
+        "compute_unit, backend, width, height, strides, sizes, padding, minimum_deployment_target",
         itertools.product(
             compute_units,
             backends,
             [1, 3, 5],
             [2, 7, 12],
             [(1, 1), (2, 1), (3, 5)],
             [(1, 1), (1, 2), (5, 4)],
             ["VALID", "SAME"],
+            [None, ct.target.iOS17],
         ),
     )
     def test_extract_patches(
-        self, compute_unit, backend, width, height, strides, sizes, padding
+        self,
+        compute_unit,
+        backend,
+        width,
+        height,
+        strides,
+        sizes,
+        padding,
+        minimum_deployment_target,
     ):
         # TODO: theoritically, the current extractpatches code handle batch size rather than 1,
         # but there seems to have a bug in crop_resize when using GPU and batch_size > 1.
         # We should test batch_size > 1 after the issue is fixed.
         # <rdar://problem/61602238>
         input = np.random.rand(1, height, width, 128).astype(np.float32)
         if padding == "VALID":
@@ -2746,14 +2750,15 @@
         input_dict = dict(zip(inputs, input_values))
         TensorFlowBaseTest.run_compare_tf(
             model,
             input_dict,
             outputs,
             compute_unit=compute_unit,
             backend=backend,
+            minimum_deployment_target=minimum_deployment_target,
         )
 
 
 class TestLinear(TensorFlowBaseTest):
     @pytest.mark.parametrize(
         "compute_unit, backend, dim, transpose_a, transpose_b, use_constant",
         itertools.product(
@@ -2959,14 +2964,19 @@
         itertools.product(
             compute_units,
             backends,
             [1e-1, 1e-10]
         ),
     )
     def test_fused_batch_norm(self, compute_unit, backend, epsilon):
+        if backend[0] == "neuralnetwork" and epsilon == 1e-10 and platform.machine() == "x86_64":
+            pytest.xfail(
+                "rdar://108739991 ([CI][TF] re-enable batch norm unittest failing in Intel machines)"
+            )
+
         # TensorFlow's FusedBatchNorm is only for 4D inputs
         input_shape = np.random.randint(low=1, high=4, size=4)
         attr_shape = [list(input_shape)[-1]]
 
         m = random_gen(shape=attr_shape, rand_min=-1.0, rand_max=1.0)
         v = random_gen(shape=attr_shape, rand_min=0.0, rand_max=10.0)
         o = random_gen(shape=attr_shape, rand_min=1.0, rand_max=10.0)
@@ -3662,14 +3672,15 @@
         if tf_op in {tf.math.argmax}:
             test_tf_argmax()
         elif tf_op in {tf.math.argmin}:
             test_tf_argmin()
         else:
             test_tf_reduction()
 
+
 class TestGather(TensorFlowBaseTest):
     @pytest.mark.parametrize(
         "compute_unit, backend, rankX_rankIndices_axis, mode",
         itertools.product(
             compute_units,
             backends,
             [
@@ -3716,14 +3727,65 @@
             input_dict,
             outputs,
             compute_unit=compute_unit,
             backend=backend,
         )
 
     @pytest.mark.parametrize(
+        "compute_unit, backend, mode",
+        itertools.product(
+            compute_units,
+            backends,
+            ["Gather", "GatherV2", "gather"],
+        ),
+    )
+    def test_gather_invalid_indices(self, compute_unit, backend, mode):
+        """
+        This test is to verify that TensorFlow Gather op doesn't allow negative nor out-of-range
+        indices, so don't need mb.select for IOS17 mb.gather when lowering TensorFlow gather op.
+        Use TensorFlowBaseTest.run_compare_tf to make this test compatible with both TF1 and TF2.
+        """
+
+        @make_tf_graph([[4, tf.int32]])
+        def build_model(indices):
+            params = tf.constant([0.0, 1.0, 2.0, 3.0, 4.0, 5.0])
+            if mode == "Gather":
+                res = tf.raw_ops.Gather(params=params, indices=indices)
+            elif mode == "GatherV2":
+                res = tf.raw_ops.GatherV2(params=params, indices=indices, axis=0)
+            elif mode == "gather":
+                res = tf.gather(params, indices)
+            else:
+                raise ValueError(f"Unsupported mode: {mode}")
+            return res
+
+        model, inputs, outputs = build_model
+
+        with pytest.raises(tf.errors.InvalidArgumentError, match="-1 is not in \[0, 6\)"):
+            # Negative indices will error out.
+            input_dict = dict(zip(inputs, [np.array([2, 0, -1, 5], dtype=np.int32)]))
+            TensorFlowBaseTest.run_compare_tf(
+                model,
+                input_dict,
+                outputs,
+                compute_unit=compute_unit,
+                backend=backend,
+            )
+        with pytest.raises(tf.errors.InvalidArgumentError, match="6 is not in \[0, 6\)"):
+            # Out-of-range indices will error out.
+            input_dict = dict(zip(inputs, [np.array([2, 0, 1, 6], dtype=np.int32)]))
+            TensorFlowBaseTest.run_compare_tf(
+                model,
+                input_dict,
+                outputs,
+                compute_unit=compute_unit,
+                backend=backend,
+            )
+
+    @pytest.mark.parametrize(
         "compute_unit, backend, rankX_rankIndices_axis_batchdims, mode",
         itertools.product(
             compute_units,
             backends,
             [
                 (2, 2, 1, 0),
                 (3, 2, 1, 1),
@@ -3867,29 +3929,76 @@
             input_dict,
             outputs,
             compute_unit=compute_unit,
             backend=backend,
             minimum_deployment_target=ct.target.iOS16 if backend[0] == "mlprogram" else None
         )
 
+    @pytest.mark.parametrize(
+        "compute_unit, backend",
+        itertools.product(
+            compute_units,
+            backends,
+        ),
+    )
+    def test_gather_nd_invalid_indices(self, compute_unit, backend):
+        """
+        This test is to verify that TensorFlow GatherNd op doesn't allow negative nor out-of-range
+        indices, so don't need mb.select for IOS17 mb.gather when lowering TensorFlow GatherNd op.
+        Use TensorFlowBaseTest.run_compare_tf to make this test compatible with both TF1 and TF2.
+        """
+
+        @make_tf_graph([[2, 2, tf.int32]])
+        def build_model(indices):
+            params = tf.constant([[0.0, 1.0], [2.0, 3.0]])
+            return tf.gather_nd(params, indices)
+
+        model, inputs, outputs = build_model
+
+        with pytest.raises(
+            tf.errors.InvalidArgumentError,
+            match="\[1, -1\] does not index into param shape \[2,2\]",
+        ):
+            # Negative indices will error out.
+            input_dict = dict(zip(inputs, [np.array([[0, 0], [1, -1]], dtype=np.int32)]))
+            TensorFlowBaseTest.run_compare_tf(
+                model,
+                input_dict,
+                outputs,
+                compute_unit=compute_unit,
+                backend=backend,
+            )
+        with pytest.raises(
+            tf.errors.InvalidArgumentError, match="\[2, 0\] does not index into param shape \[2,2\]"
+        ):
+            # Out-of-range indices will error out.
+            input_dict = dict(zip(inputs, [np.array([[2, 0], [1, 1]], dtype=np.int32)]))
+            TensorFlowBaseTest.run_compare_tf(
+                model,
+                input_dict,
+                outputs,
+                compute_unit=compute_unit,
+                backend=backend,
+            )
+
 
 class TestScatter(TensorFlowBaseTest):
     @pytest.mark.parametrize(
-        "compute_unit, backend, data_rank, indices_rank",
+        "compute_unit, backend, data_rank, indices_rank, minimum_deployment_target",
         itertools.product(
             compute_units,
             backends,
             list(range(1, 4)),
             list(range(2, 4)),
+            [None, ct.target.iOS17],
         ),
     )
     def test_scatter_nd_with_zeros(
-        self, compute_unit, backend, data_rank, indices_rank
+        self, compute_unit, backend, data_rank, indices_rank, minimum_deployment_target
     ):
-
         shape = np.random.randint(low=2, high=4, size=data_rank).astype(np.int32)
         indices_shape = np.random.randint(low=2, high=4, size=indices_rank)
         indices_shape[-1] = np.random.randint(low=1, high=data_rank + 1)
         updates_shape = list(indices_shape[:-1]) + list(shape[indices_shape[-1] :])
 
         updates = np.random.rand(*updates_shape).astype(np.int32)
         indices_list = []
@@ -3910,31 +4019,87 @@
         input_dict = dict(zip(inputs, input_values))
         TensorFlowBaseTest.run_compare_tf(
             model,
             input_dict,
             outputs,
             compute_unit=compute_unit,
             backend=backend,
+            minimum_deployment_target=minimum_deployment_target,
         )
 
+    @pytest.mark.parametrize(
+        "compute_unit, backend",
+        itertools.product(
+            compute_units,
+            backends,
+        ),
+    )
+    def test_scatter_nd_with_invalid_indices(self, compute_unit, backend):
+        shape = np.random.randint(low=2, high=4, size=3).astype(np.int32)
+        indices_shape = np.random.randint(low=2, high=4, size=3)
+        indices_shape[-1] = np.random.randint(low=1, high=4)
+        updates_shape = list(indices_shape[:-1]) + list(shape[indices_shape[-1] :])
+
+        updates = np.random.rand(*updates_shape).astype(np.int32)
+        neg_indices_list = []
+        for i in range(indices_shape[-1]):
+            neg_indices_list.append(np.random.randint(-shape[i], 0, size=indices_shape[:-1]))
+        indices = np.stack(neg_indices_list, axis=-1).astype(np.int32)
+
+        @make_tf_graph(
+            [list(indices.shape) + [tf.int32], updates_shape + [tf.int32], [3, tf.int32]]
+        )
+        def build_model(indices, updates, shape):
+            return tf.raw_ops.ScatterNd(indices=indices, updates=updates, shape=shape)
+
+        model, inputs, outputs = build_model
+
+        # TensorFlow ScatterNd doesn't support negative indices.
+        with pytest.raises(tf.errors.InvalidArgumentError, match="does not index into shape"):
+            TensorFlowBaseTest.run_compare_tf(
+                model,
+                dict(zip(inputs, [indices, updates, shape])),
+                outputs,
+                compute_unit=compute_unit,
+                backend=backend,
+            )
+
+        out_of_range_indices_list = []
+        for i in range(indices_shape[-1]):
+            out_of_range_indices_list.append(
+                np.random.randint(shape[i], shape[i] * 2, size=indices_shape[:-1])
+            )
+        indices = np.stack(out_of_range_indices_list, axis=-1).astype(np.int32)
+
+        # TensorFlow ScatterNd doesn't support out of range indices.
+        with pytest.raises(tf.errors.InvalidArgumentError, match="does not index into shape"):
+            TensorFlowBaseTest.run_compare_tf(
+                model,
+                dict(zip(inputs, [indices, updates, shape])),
+                outputs,
+                compute_unit=compute_unit,
+                backend=backend,
+            )
+
 
 class TestTensorScatterAdd(TensorFlowBaseTest):
     @pytest.mark.parametrize(
-        "compute_unit, backend, tensor_rank, indices_rank",
+        "compute_unit, backend, tensor_rank, indices_rank, minimum_deployment_target",
         itertools.product(
             compute_units,
             backends,
             # updates_rank = indices_rank - 1 + tensor_rank - indices_shape[-1] <= tensor_rank + indices_rank - 2
             # and Core ML only supports updates_rank < 6,
             # so we constrain tensor_rank + indices_rank - 2 < 6
             [tensor_rank for tensor_rank in range(1, 5)],
-            [indices_rank for indices_rank in range(2, 4)]
+            [indices_rank for indices_rank in range(2, 4)],
+            [None, ct.target.iOS17],
         ),
     )
-    def test(self, compute_unit, backend, tensor_rank, indices_rank):
+    def test_scatter_add(self, compute_unit, backend, tensor_rank, indices_rank, minimum_deployment_target):
         # To avoid indexing out of bound:
         #     tensor size for each dimension >= MIN_TENSOR_SIZE
         #     index for each dimension < MIN_TENSOR_SIZE
         MIN_TENSOR_SIZE = 3
 
         tensor_shape = np.random.randint(low=MIN_TENSOR_SIZE, high=9, size=tensor_rank)
         # indices shape constraint: 0 < indices_shape[-1] <= tensor_rank
@@ -3964,28 +4129,97 @@
         input_dict = dict(zip(inputs, input_values))
         TensorFlowBaseTest.run_compare_tf(
             model,
             input_dict,
             outputs,
             compute_unit=compute_unit,
             backend=backend,
+            minimum_deployment_target=minimum_deployment_target,
         )
 
+    @pytest.mark.parametrize(
+        "compute_unit, backend",
+        itertools.product(
+            compute_units,
+            backends,
+        ),
+    )
+    def test_scatter_add_invalid_indices(self, compute_unit, backend):
+        # To avoid indexing out of bound:
+        #     tensor size for each dimension >= MIN_TENSOR_SIZE
+        #     index for each dimension < MIN_TENSOR_SIZE
+        MIN_TENSOR_SIZE = 3
+
+        tensor_rank = 3
+        indices_rank = 3
+        tensor_shape = np.random.randint(low=MIN_TENSOR_SIZE, high=9, size=tensor_rank)
+        # indices shape constraint: 0 < indices_shape[-1] <= tensor_rank
+        indices_shape = np.random.randint(low=1, high=tensor_rank + 1, size=indices_rank)
+
+        updates_shape = []
+        for i in range(indices_rank - 1):
+            updates_shape.append(indices_shape[i])
+        for i in range(indices_shape[-1], tensor_rank):
+            updates_shape.append(tensor_shape[i])
+        updates_shape = np.array(updates_shape)
+
+        @make_tf_graph([tensor_shape, list(indices_shape) + [tf.int32], updates_shape])
+        def build_model(tensor, indices, updates):
+            return tf.tensor_scatter_nd_add(tensor, indices, updates)
+
+        model, inputs, outputs = build_model
+
+        # TensorFlow tensor_scatter_nd_add doesn't support negative indices.
+        neg_indices = random_gen(indices_shape, rand_min=-3, rand_max=-1, dtype=np.int32)
+        input_values = [
+            random_gen(tensor_shape, rand_min=-1.0, rand_max=1.0),
+            neg_indices,
+            random_gen(updates_shape, rand_min=-1.0, rand_max=1.0),
+        ]
+        with pytest.raises(tf.errors.InvalidArgumentError, match="does not index into shape"):
+            TensorFlowBaseTest.run_compare_tf(
+                model,
+                dict(zip(inputs, input_values)),
+                outputs,
+                compute_unit=compute_unit,
+                backend=backend,
+            )
+
+        # TensorFlow tensor_scatter_nd_add doesn't support out of range indices.
+        out_of_range_indices = random_gen(indices_shape, rand_min=10, rand_max=20, dtype=np.int32)
+        input_values = [
+            random_gen(tensor_shape, rand_min=-1.0, rand_max=1.0),
+            out_of_range_indices,
+            random_gen(updates_shape, rand_min=-1.0, rand_max=1.0),
+        ]
+        with pytest.raises(tf.errors.InvalidArgumentError, match="does not index into shape"):
+            TensorFlowBaseTest.run_compare_tf(
+                model,
+                dict(zip(inputs, input_values)),
+                outputs,
+                compute_unit=compute_unit,
+                backend=backend,
+            )
+
 
 class TestSliceByIndex(TensorFlowBaseTest):
     @pytest.mark.parametrize(
         "compute_unit, backend, rank, masking_type",
         itertools.product(
             compute_units,
             backends,
             [rank for rank in range(1, 5)],
             ["none", "positive_mask", "negative_mask"]
         ),
     )
     def test_slice_by_index_simple(self, compute_unit, backend, rank, masking_type):
+        if backend[0] == "mlprogram":
+            pytest.xfail(
+                "rdar://109854221 ([Bug][Regression] slice_by_index is throwing expection through E5ML - Follow up radar)"
+            )
         input_shape = np.random.randint(low=2, high=4, size=rank)
         begin_val = np.array(
             [
                 np.random.randint(low=-input_shape[i], high=input_shape[i])
                 for i in range(rank)
             ]
         ).astype(np.int32)
@@ -4694,14 +4928,19 @@
             )
         if num_boxes >= 1000 and backend == ("mlprogram", "fp16"):
             pytest.xfail(
                 "rdar://103891349 ([TensorFlow] [PyTorch] NMS discrepancy in Fp16 when "
                 "number of boxes is large)"
             )
 
+        if backend[0] == "mlprogram":
+            # force we are using fp16 for mlprogram, until this radar is fix:
+            # rdar://109871491 ([Bug][CI][Regression] Numerical regression on E5ML for nms layers)
+            backend = ("mlprogram", "fp32")
+
         boxes_val = random_gen(shape=(num_boxes, 4), rand_min=0, rand_max=32)
         # When the input score is too close, the returned index order is not guaranteed.
         # So instead of generating random scores by rand, use shuffle.
         scores_val = np.arange(num_boxes).astype(np.float32)
         np.random.shuffle(scores_val)
 
         @make_tf_graph([boxes_val.shape, scores_val.shape])
@@ -5115,14 +5354,40 @@
             model,
             input_dict,
             outputs,
             compute_unit=compute_unit,
             backend=backend,
         )
 
+    @pytest.mark.parametrize(
+        "compute_unit, backend",
+        itertools.product(compute_units, backends),
+    )
+    def test_tile_invalid(self, compute_unit, backend):
+        """TF doesn't support tile where `multiples` have different length than x's rank."""
+        x_shape = (2, 3, 4)
+
+        with pytest.raises(ValueError, match="Shape must be rank 3 but is rank 2"):
+
+            @make_tf_graph([x_shape])
+            def build_model(x):
+                return tf.tile(x, multiples=[1, 2])
+
+            model, inputs, outputs = build_model
+            input_values = [random_gen(x_shape)]
+            input_dict = dict(zip(inputs, input_values))
+            TensorFlowBaseTest.run_compare_tf(
+                model,
+                input_dict,
+                outputs,
+                compute_unit=compute_unit,
+                backend=backend,
+            )
+
+
 class TestDynamicTile(TensorFlowBaseTest):
     @pytest.mark.parametrize(
         "compute_unit, backend, rank",
         itertools.product(compute_units, backends, [1, 2, 3, 4, 5]),
     )
     def test_tile(self, compute_unit, backend, rank):
         x_shape = np.random.randint(low=2, high=4, size=rank)
@@ -5564,19 +5829,21 @@
             model,
             input_dict,
             outputs,
             compute_unit=compute_unit,
             backend=backend,
         )
 
+
 class TestReshape(TensorFlowBaseTest):
     @pytest.mark.parametrize(
-        "compute_unit, backend", itertools.product(compute_units, backends,)
+        "compute_unit, backend, minimum_deployment_target",
+        itertools.product(compute_units, backends, [None, ct.target.iOS17]),
     )
-    def test_flatten(self, compute_unit, backend):
+    def test_flatten(self, compute_unit, backend, minimum_deployment_target):
         shapes = [[2, 2], [3, 2, 1, 2], [2, 1, 4, 3]]
 
         for input_shape in shapes:
 
             @make_tf_graph([input_shape])
             def build_model(x):
                 return tf.keras.backend.flatten(x)
@@ -5587,59 +5854,63 @@
             input_dict = dict(zip(inputs, input_values))
             TensorFlowBaseTest.run_compare_tf(
                 model,
                 input_dict,
                 outputs,
                 compute_unit=compute_unit,
                 backend=backend,
+                minimum_deployment_target=minimum_deployment_target,
             )
 
     @pytest.mark.parametrize(
-        "compute_unit, backend, input_shape",
+        "compute_unit, backend, input_shape, minimum_deployment_target",
         itertools.product(
             compute_units,
             backends,
             [
                 ([10, 10], [5, 20]),
                 ([3, 4, 5, 6], [4, 5, 3, 6]),
                 ([4, 4, 5, 6], [2, 2, -1]),
             ],
+            [None, ct.target.iOS17],
         ),
     )
-    def test_reshape_static(self, compute_unit, backend, input_shape):
+    def test_reshape_static(self, compute_unit, backend, input_shape, minimum_deployment_target):
         @make_tf_graph([input_shape[0]])
         def build_model(x):
             return tf.reshape(x, shape=input_shape[1])
 
         model, inputs, outputs = build_model
 
         input_values = [np.random.rand(*input_shape[0]).astype(np.float32)]
         input_dict = dict(zip(inputs, input_values))
         TensorFlowBaseTest.run_compare_tf(
             model,
             input_dict,
             outputs,
             compute_unit=compute_unit,
             backend=backend,
+            minimum_deployment_target=minimum_deployment_target,
         )
 
     @pytest.mark.parametrize(
-        "compute_unit, backend, input_shape",
+        "compute_unit, backend, input_shape, minimum_deployment_target",
         itertools.product(
             compute_units,
             backends,
             [
                 ([10, 10], [5, 20]),
                 ([3, 4, 5, 6], [4, 5, 3, 6]),
                 ([4, 4, 5, 6], [2, 2, -1]),
                 ([2, 3, 5, 3], [2, -1]),
             ],
+            [None, ct.target.iOS17],
         ),
     )
-    def test_reshape_dynamic(self, compute_unit, backend, input_shape):
+    def test_reshape_dynamic(self, compute_unit, backend, input_shape, minimum_deployment_target):
         @make_tf_graph([input_shape[0], (len(input_shape[1]), tf.int32)])
         def build_model(x, y):
             return tf.reshape(x, shape=y)
 
         model, inputs, outputs = build_model
 
         input_values = [
@@ -5652,22 +5923,20 @@
             input_dict,
             outputs,
             compute_unit=compute_unit,
             backend=backend,
         )
 
     @pytest.mark.parametrize(
-        "compute_unit, backend, shape",
+        "compute_unit, backend, shape, minimum_deployment_target",
         itertools.product(
-            compute_units,
-            backends,
-            [[1], [1, 1], [1, 1, -1], []],
+            compute_units, backends, [[1], [1, 1], [1, 1, -1], []], [None, ct.target.iOS17]
         ),
     )
-    def test_reshape_scalar(self, compute_unit, backend, shape):
+    def test_reshape_scalar(self, compute_unit, backend, shape, minimum_deployment_target):
         pytest.skip('Rank 0 not supported by CoreML runtime')
 
         input_shape = ()
 
         @make_tf_graph([input_shape])
         def build_model(x):
             return tf.raw_ops.Reshape(tensor=x, shape=shape)
@@ -5678,16 +5947,18 @@
         input_dict = dict(zip(inputs, input_values))
         TensorFlowBaseTest.run_compare_tf(
             model,
             input_dict,
             outputs,
             compute_unit=compute_unit,
             backend=backend,
+            minimum_deployment_target=minimum_deployment_target,
         )
 
+
 class TestShape(TensorFlowBaseTest):
     @pytest.mark.parametrize(
         "compute_unit, backend, rank",
         itertools.product(
             compute_units,
             backends,
             [rank for rank in range(1, 6)],
@@ -6281,15 +6552,20 @@
         model, inputs, outputs = build_model
         input_values = [random_gen(input_shape)]
         input_dict = dict(zip(inputs, input_values))
 
         # Before rdar://93071454 (batch_to_space is error out in espresso for dynamic inputs cormel model) is fixed,
         # we need to specify the default shape for the dynamic model by setting inputs_for_conversion
         if dynamic:
-            shape = tuple([RangeDim(default=dim) for dim in input_shape])
+            shape = tuple(
+                [
+                    RangeDim(default=dim, upper_bound=dim if backend[0] == "mlprogram" else -1)
+                    for dim in input_shape
+                ]
+            )
             inputs_for_conversion = [TensorType(shape=shape, dtype=np.float32)]
         else:
             inputs_for_conversion = None
 
         TensorFlowBaseTest.run_compare_tf(
             model,
             input_dict,
@@ -6326,15 +6602,20 @@
             return tf.raw_ops.BatchToSpaceND(
                 input=x, block_shape=block_shape, crops=crops
             )
 
         # Before rdar://93071454 (batch_to_space is error out in espresso for dynamic inputs cormel model) is fixed,
         # we need to specify the default shape for the dynamic model by setting inputs_for_conversion
         if dynamic:
-            shape = tuple([RangeDim(default=dim) for dim in input_shape])
+            shape = tuple(
+                [
+                    RangeDim(default=dim, upper_bound=dim if backend[0] == "mlprogram" else -1)
+                    for dim in input_shape
+                ]
+            )
             inputs_for_conversion = [TensorType(shape=shape, dtype=np.float32)]
         else:
                         inputs_for_conversion = None
 
         model, inputs, outputs = build_model
         input_values = [random_gen(input_shape)]
         input_dict = dict(zip(inputs, input_values))
@@ -6765,25 +7046,17 @@
             backend=backend,
         )
 
 
 class TestIsFinite(TensorFlowBaseTest):
     @pytest.mark.parametrize(
         "compute_unit, backend, rank, dynamic",
-        itertools.product(
-            compute_units,
-            backends,
-            [rank for rank in range(5)],
-            [True, False]
-        ),
+        itertools.product(compute_units, backends, [rank for rank in range(1, 5)], [True, False]),
     )
     def test(self, compute_unit, backend, rank, dynamic):
-        if rank == 0:
-            pytest.skip('Rank 0 not supported by CoreML runtime')
-
         def _generate_num_with_inf(input_shape):
             res = random_gen(input_shape, rand_min=-1, rand_max=1)
             random_map = np.random.choice([np.inf, -np.inf, 0], size=input_shape)
             if len(input_shape) == 0:
                 return random_map.astype(np.float32)
             res[np.where(random_map == np.inf)] = np.inf
             res[np.where(random_map == -np.inf)] = -np.inf
@@ -6881,23 +7154,24 @@
             compute_unit=compute_unit,
             backend=backend
         )
 
 
 class TestClipByValue(TensorFlowBaseTest):
     @pytest.mark.parametrize(
-        'compute_unit, backend, rank, min_and_max',
-         itertools.product(
-             compute_units,
-             backends,
-             [rank for rank in range(5)],
-             [(-1, 1), (-1, -1), (1, 2), (-3, -2)],
-         ),
+        "compute_unit, backend, rank, min_and_max, minimum_deployment_target",
+        itertools.product(
+            compute_units,
+            backends,
+            [rank for rank in range(5)],
+            [(-1, 1), (-1, -1), (1, 2), (-3, -2)],
+            [None, ct.target.iOS17],
+        ),
     )
-    def test(self, compute_unit, backend, rank, min_and_max):
+    def test(self, compute_unit, backend, rank, min_and_max, minimum_deployment_target):
         if rank == 0:
             pytest.skip('Rank 0 not supported by CoreML runtime')
 
         input_shape = np.random.randint(low=2, high=4, size=rank)
         min_val, max_val = min_and_max
         input_value = random_gen(input_shape, rand_min=min_val-1, rand_max=max_val+1)
 
@@ -6909,15 +7183,16 @@
         input_values = [input_value]
         input_dict = dict(zip(inputs, input_values))
         TensorFlowBaseTest.run_compare_tf(
             model,
             input_dict,
             outputs,
             compute_unit=compute_unit,
-            backend=backend
+            backend=backend,
+            minimum_deployment_target=minimum_deployment_target,
         )
 
 
 class TestSize(TensorFlowBaseTest):
     @pytest.mark.parametrize(
         'compute_unit, backend, rank, dynamic',
          itertools.product(
@@ -6950,19 +7225,15 @@
             def build_model(x):
                 return tf.raw_ops.Size(input=x)
 
             model, inputs, outputs = build_model
             input_values = [input_value]
         input_dict = dict(zip(inputs, input_values))
         TensorFlowBaseTest.run_compare_tf(
-            model,
-            input_dict,
-            outputs,
-            compute_unit=compute_unit,
-            backend=backend
+            model, input_dict, outputs, compute_unit=compute_unit, backend=backend
         )
 
 class TestAudioSpectrogram(TensorFlowBaseTest):
     @pytest.mark.parametrize(
         "compute_unit, backend, params, magnitude_squared",
         itertools.product(
             compute_units,
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/test/test_parse.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/test/test_parse.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/test/test_parsed_tf_node.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/test/test_parsed_tf_node.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/test/test_tf_conversion_api.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/test/test_tf_conversion_api.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,25 +1,34 @@
 #  Copyright (c) 2022, Apple Inc. All rights reserved.
 #
 #  Use of this source code is governed by a BSD-3-clause license that can be
 #  found in the LICENSE.txt file or at https://opensource.org/licenses/BSD-3-Clause
 
+import itertools
 import os
 import tempfile
 
 import numpy as np
 import pytest
 
 import coremltools as ct
 from coremltools._deps import _HAS_TF_1, _HAS_TF_2, MSG_TF1_NOT_FOUND
+from coremltools.converters.mil.testing_reqs import backends, compute_units
 from coremltools.converters.mil.testing_utils import (
-    assert_cast_ops_count, assert_input_dtype, assert_ops_in_mil_program,
-    assert_output_dtype, assert_prog_input_type, assert_prog_output_type,
-    assert_spec_input_image_type, assert_spec_output_image_type,
-    get_op_types_in_program, verify_prediction)
+    assert_cast_ops_count,
+    assert_input_dtype,
+    assert_ops_in_mil_program,
+    assert_output_dtype,
+    assert_prog_input_type,
+    assert_prog_output_type,
+    assert_spec_input_image_type,
+    assert_spec_output_image_type,
+    get_op_types_in_program,
+    verify_prediction,
+)
 from coremltools.proto import FeatureTypes_pb2 as ft
 from coremltools.test.api.test_api_examples import TestInputs as _TestInputs
 
 tf = pytest.importorskip("tensorflow")
 
 #################################################################################
 # Note: all tests are also used as examples in https://coremltools.readme.io/docs
@@ -242,14 +251,61 @@
                 graph,
                 inputs=[ct.TensorType(shape=(1, 2, 3), name="wrong_input")]
             )
         expected_error = "Multiple inputs are found in graph, but no input name was provided"
         expected_error = "Input ({}) provided is not found in given tensorflow graph. Placeholders in graph are: {}".format("wrong_input", ["input", "input_1"])
         assert expected_error == str(e.value)
 
+    @pytest.mark.parametrize(
+        "backend, compute_unit",
+        itertools.product(
+            backends,
+            compute_units,
+        ),
+    )
+    def test_input_dynamic_without_inputs_param(self, backend, compute_unit):
+        """The `inputs` param is not provided for a dynamic input (shape has `None`)."""
+        with tf.Graph().as_default() as graph:
+            x = tf.placeholder(tf.float32, shape=(None, None, 3), name="input")
+            x1 = tf.placeholder(tf.float32, shape=(1, 2, 3), name="input_1")
+            y = tf.nn.relu(x, name="output")
+            y1 = tf.nn.relu(x1, name="output_1")
+
+        convert_to = backend[0]
+        if convert_to == "mlprogram":
+            with pytest.warns(
+                UserWarning,
+                match="Some dimensions in the input shape are unknown, hence they are set to "
+                "flexible ranges with lower bound and default value = 1, and upper bound = 2. "
+                "To set different values for the default shape and upper bound, please use "
+                "the ct.RangeDim.*",
+            ):
+                mlmodel = ct.convert(
+                    graph,
+                    convert_to=convert_to,
+                    compute_units=compute_unit,
+                )
+        else:
+            mlmodel = ct.convert(
+                graph,
+                convert_to=convert_to,
+                compute_units=compute_unit,
+            )
+
+        spec = mlmodel.get_spec()
+        assert list(spec.description.input[0].type.multiArrayType.shape) == [1, 1, 3]
+        assert (
+            spec.description.input[0].type.multiArrayType.shapeRange.sizeRanges[1].lowerBound == 1
+        )
+        assert (
+            spec.description.input[0].type.multiArrayType.shapeRange.sizeRanges[1].upperBound == -1
+            if convert_to == "neuralnetwork"
+            else 2
+        )
+
     @staticmethod
     @pytest.mark.skipif(not ct.utils._is_macos(), reason="test needs predictions")
     def test_tf_predict_input():
         TestTf1Inputs._test_variant_input_type_prediction(tf.convert_to_tensor)
 
 @pytest.fixture
 def int32_input_model():
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/test/testing_utils.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/test/testing_utils.py`

 * *Files 2% similar despite different names*

```diff
@@ -8,16 +8,19 @@
 
 import numpy as np
 import pytest
 
 import coremltools.models.utils as coremltoolsutils
 from coremltools._deps import _HAS_TF_2
 from coremltools.converters.mil.testing_reqs import ct
-from coremltools.converters.mil.testing_utils import (compare_backend,
-                                                      ct_convert)
+from coremltools.converters.mil.testing_utils import (
+    compare_backend,
+    ct_convert,
+    validate_minimum_deployment_target,
+)
 
 tf = pytest.importorskip("tensorflow", minversion="1.15.0")
 
 from tensorflow.python.framework import dtypes
 from tensorflow.python.keras.saving import saving_utils as _saving_utils
 from tensorflow.python.tools.freeze_graph import freeze_graph as freeze_g
 
@@ -143,19 +146,39 @@
     if not isinstance(output_nodes, list):
         output_nodes = [output_nodes]
 
     # Convert TF graph.
     input_names = get_tf_node_names(list(feed_dict.keys()), mode="inputs")
     output_names = get_tf_node_names(output_nodes, mode="outputs")
     input_values = {name: val for name, val in zip(input_names, feed_dict.values())}
-        
-    inputs = inputs_for_conversion if inputs_for_conversion is not None else None
+
+    if inputs_for_conversion is None and backend[0] == "mlprogram":
+        # As mlprogram by default use a small upper-bound for dynamic shapes, set a larger one here
+        # to avoid test failures.
+        has_dynamic_shape = False
+        input_types = []
+        for input_placeholder in list(feed_dict.keys()):
+            input_shape = [
+                ct.RangeDim(upper_bound=64) if dim.value is None else dim.value
+                for dim in input_placeholder.shape
+            ]
+            input_types.append(
+                ct.TensorType(name=input_placeholder.name.split(":")[0], shape=input_shape)
+            )
+            if any([dim.value is None for dim in input_placeholder.shape]):
+                has_dynamic_shape = True
+        if has_dynamic_shape:
+            inputs_for_conversion = input_types
 
     mlmodel = ct_convert(
-        graph, inputs=inputs, outputs=output_names, source=frontend, convert_to=backend,
+        graph,
+        inputs=inputs_for_conversion,
+        outputs=output_names,
+        source=frontend,
+        convert_to=backend,
         compute_units=compute_unit,
         minimum_deployment_target=minimum_deployment_target,
     )
 
     return mlmodel, input_values, output_names, output_nodes
 
 
@@ -283,21 +306,21 @@
     for k, v in input_key_values.items():
         if isinstance(v, np.ndarray) and issubclass(v.dtype.type, np.integer):
             input_key_values[k] = v.astype(float) # Core ML only accepts floats
 
     pred = None
     if not coremltoolsutils._has_custom_layer(mlmodel._spec):
         pred = compare_backend(
-                mlmodel,
-                input_key_values,
-                expected_outputs,
-                atol=atol,
-                rtol=rtol,
-                also_compare_shapes=True,
-                dtype=backend[1],
+            mlmodel,
+            input_key_values,
+            expected_outputs,
+            atol=atol,
+            rtol=rtol,
+            also_compare_shapes=True,
+            dtype=backend[1],
         )
     else:
         print('Skipping model prediction as it has a custom nn layer!')
     return mlmodel._spec, mlmodel, input_key_values, pred
 
 
 def layer_counts(spec, layer_type):
@@ -330,44 +353,44 @@
     def run_compare_tf(graph, feed_dict, output_nodes,
                        inputs_for_conversion=None,
                        compute_unit=ct.ComputeUnit.CPU_ONLY,
                        frontend_only=False, frontend="tensorflow",
                        backend=("neuralnetwork", "fp32"), atol=1e-04, rtol=1e-05,
                        freeze_graph=False, tf_outputs=None,
                        minimum_deployment_target=None):
+        if minimum_deployment_target is not None:
+            validate_minimum_deployment_target(minimum_deployment_target, backend)
 
         res = run_compare_tf(graph,
                              feed_dict,
                              output_nodes,
                              inputs_for_conversion=inputs_for_conversion,
                              compute_unit=compute_unit,
                              frontend_only=frontend_only,
                              frontend=frontend,
                              backend=backend, atol=atol,
                              rtol=rtol,
                              freeze_graph=freeze_graph,
                              tf_outputs=tf_outputs,
                              minimum_deployment_target=minimum_deployment_target
         )
-        
+
         alist = []
         if res is not None:
             alist = list(res)
         alist.append(TensorFlowBaseTest.testclassname)
         alist.append(TensorFlowBaseTest.testmodelname)
 
         return tuple(alist)
 
     @staticmethod
     def _op_count_in_mil_program(mlmodel, op_type):
         prog = mlmodel._mil_program
         return len(prog.find_ops(op_type=op_type))
-        
-        
+
+
 if _HAS_TF_2:
     from coremltools.converters.mil.frontend.tensorflow2.test.testing_utils import (
         TensorFlow2BaseTest, make_tf2_graph)
-    from coremltools.converters.mil.frontend.tensorflow.test.testing_utils import \
-        TensorFlowBaseTest
+    from coremltools.converters.mil.frontend.tensorflow.test.testing_utils import TensorFlowBaseTest
     TensorFlowBaseTest.run_compare_tf = TensorFlow2BaseTest.run_compare_tf2
     make_tf_graph = make_tf2_graph
-
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/__init__.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/__init__.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/cond_to_where.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/cond_to_where.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/constant_propagation.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/constant_propagation.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/delete_asserts.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/delete_asserts.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/delete_constant.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/delete_constant.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/delete_disconnected_nodes.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/delete_disconnected_nodes.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/functionalize_loops.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/functionalize_loops.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/fuse_dilation_conv.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/fuse_dilation_conv.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/insert_get_tuple.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/insert_get_tuple.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/quantization_pass.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/quantization_pass.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/tensor_array_transform.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/tensor_array_transform.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/variable_node_transform.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/variable_node_transform.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/visitors.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/visitors.py`

 * *Files 2% similar despite different names*

```diff
@@ -186,17 +186,17 @@
 
         # add self to memo first otherwise cycles will not terminate
         self.memo[node.name] = None
         reachable = None
         all_unreachable = True
         for i in node.outputs + node.control_outputs:
             visit_result = self.visit_impl(g, g[i])
-            if visit_result == True:  # pylint: disable=singleton-comparison
+            if visit_result is True:
                 reachable = True
-            if visit_result != False:  # pylint: disable=singleton-comparison
+            if visit_result is not False:
                 all_unreachable = False
 
         if reachable:
             self.memo[node.name] = reachable
         elif all_unreachable:
             self.memo[node.name] = False
         else:
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/tf_op_registry.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/tf_op_registry.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow/tfssa.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow/tfssa.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow2/converter.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow2/converter.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow2/load.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow2/load.py`

 * *Files 2% similar despite different names*

```diff
@@ -86,47 +86,46 @@
             rewrite_control_flow_functions,
             flatten_sub_graph_namespaces,
             remove_variable_nodes,
             fuse_dilation_conv,
         ]
 
     def _get_concrete_functions_and_graph_def(self):
-        msg = (
-            "Expected model format: [SavedModel | [concrete_function] | "
-            "tf.keras.Model | .h5 | GraphDef], got {}"
-        )
-        if (
-            isinstance(self.model, list)
-            or isinstance(self.model, _tf.keras.Model)
-            or isinstance(self.model, str)
-            or isinstance(self.model, _tf.compat.v1.GraphDef)
-        ):
-            cfs = []
-            if isinstance(self.model, list):
-                cfs = self.model
-            if isinstance(self.model, _tf.keras.Model):
-                cfs = self._concrete_fn_from_tf_keras_or_h5(self.model)
-            elif isinstance(self.model, _tf.compat.v1.GraphDef):
-                return None, self.model
-            elif isinstance(self.model, str):
-                if not _os_path.exists(self.model):
-                    raise ValueError(
-                        'Input model "{}" does not exist'.format(self.model)
-                    )
-                elif _os_path.isfile(self.model) \
-                     and (self.model.endswith(".h5") or self.model.endswith(".hdf5")):
-                    cfs = self._concrete_fn_from_tf_keras_or_h5(self.model)
-                elif _os_path.isdir(self.model):
-                    saved_model = _tf.saved_model.load(self.model)
-                    sv = saved_model.signatures.values()
-                    cfs = sv if isinstance(sv, list) else list(sv)
-                else:
-                    raise NotImplementedError(msg.format(self.model))
-        else:
-            raise NotImplementedError(msg.format(self.model))
+        if not isinstance(self.model, (list, str, _tf.keras.Model, _tf.compat.v1.GraphDef)):
+            raise NotImplementedError(
+                f"Expected model format: [SavedModel | concrete_function | "
+                f"tf.keras.Model | .h5 | GraphDef], got {self.model}"
+            )
+
+        cfs = []
+        if isinstance(self.model, list):
+            cfs = self.model
+        if isinstance(self.model, _tf.keras.Model):
+            cfs = self._concrete_fn_from_tf_keras(self.model)
+        elif isinstance(self.model, _tf.compat.v1.GraphDef):
+            return None, self.model
+        elif isinstance(self.model, str):
+            if not _os_path.exists(self.model):
+                raise ValueError(f'Input model "{self.model}" does not exist')
+            elif _os_path.isfile(self.model) and (
+                self.model.endswith(".h5") or self.model.endswith(".hdf5")
+            ):
+                # Keep a reference to loaded model, or it errors out due to variables deletion, see
+                # https://github.com/tensorflow/tensorflow/issues/37615#issuecomment-1552237114.
+                keras_model = _tf.keras.models.load_model(self.model)
+                cfs = self._concrete_fn_from_tf_keras(keras_model)
+            elif _os_path.isdir(self.model):
+                saved_model = _tf.saved_model.load(self.model)
+                sv = saved_model.signatures.values()
+                cfs = sv if isinstance(sv, list) else list(sv)
+            else:
+                raise ValueError(
+                    f"Input model path should be .h5/.hdf5 file or a directory, but "
+                    f"got {self.model}"
+                )
 
         graph_def = self._graph_def_from_concrete_fn(cfs)
 
         return cfs, graph_def
 
     def _graph_def_from_model(self, output_names=None):
         """Overwrites TFLoader._graph_def_from_model()"""
@@ -307,17 +306,15 @@
                 # ret is a mapping from the output arg names from `signature` to the
                 # outputs from `node_def` that should be returned by the function.
                 graph_ret.update({name: sg_def.ret})
 
         return graph_dict, graph_inputs, graph_outputs, graph_ret
 
     @staticmethod
-    def _concrete_fn_from_tf_keras_or_h5(keras_model):
-        if not isinstance(keras_model, _tf.keras.Model):
-            keras_model = _tf.keras.models.load_model(keras_model)
+    def _concrete_fn_from_tf_keras(keras_model: _tf.keras.Model):
         input_signature = _saving_utils.model_input_signature(
             keras_model, keep_original_batch_size=True
         )
         fn = _saving_utils.trace_model_call(keras_model, input_signature)
         return [fn.get_concrete_function()]
 
     def _graph_def_from_concrete_fn(self, cfs):
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow2/ops.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow2/ops.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow2/ssa_passes/remove_vacuous_cond.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow2/ssa_passes/remove_vacuous_cond.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow2/ssa_passes/test_v2_passes.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow2/ssa_passes/test_v2_passes.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow2/test/test_tf2_conversion_api.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow2/test/test_tf2_conversion_api.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,24 +1,20 @@
 #  Copyright (c) 2020, Apple Inc. All rights reserved.
 #
 #  Use of this source code is governed by a BSD-3-clause license that can be
 #  found in the LICENSE.txt file or at https://opensource.org/licenses/BSD-3-Clause
 
 import os
 import platform
-import urllib
-from io import BytesIO
 from os import chdir, getcwd
 from shutil import rmtree
 from tempfile import mkdtemp
 
 import numpy as np
 import pytest
-import requests
-from PIL import Image
 
 import coremltools as ct
 from coremltools.converters.mil.mil import types
 
 tf = pytest.importorskip("tensorflow", minversion="2.1.0")
 
 import tensorflow as tf
@@ -137,20 +133,20 @@
         # write a toy SavedModel directory
         tf_keras_model.save("./saved_model", save_format="tf")
 
     def teardown_class(self):
         chdir(self._cwd)
         if os.path.exists(self._temp_dir):
             rmtree(self._temp_dir)
-    
+
     @staticmethod
     def test_convert_tf_keras_h5_file():
         if platform.machine() == "arm64":
             pytest.xfail("rdar://101162740 ([CI] [TF] The tf_keras_h5_file API testing is failing on M1 with new OS)")
-            
+
         for file_extension in ("h5", "hdf5"):
             x = tf.keras.Input(shape=(32,), name="input")
             y = tf.keras.layers.Dense(16, activation="softmax")(x)
             keras_model = tf.keras.Model(x, y)
             temp_dir = mkdtemp()
             save_dir = str(temp_dir)
             path = os.path.join(save_dir, "tf_keras_model." + file_extension)
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow2/test/test_v2_load.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow2/test/test_v2_load.py`

 * *Files 4% similar despite different names*

```diff
@@ -66,15 +66,15 @@
         mlmodel = converter.convert(
             self.model_path_h5,
             inputs=[TensorType(input_names[0], (3, 4, 5))],
             outputs=["Identity"],
             source=frontend,
         )
         assert mlmodel is not None
-        
+
     def test_keras_hdf5_file(self):
         keras_model = tf.keras.Sequential(
             [tf.keras.layers.ReLU(input_shape=(4, 5), batch_size=3)]
         )
         input_names, output_names = get_tf_keras_io_names(keras_model)
         keras_model.save(self.model_path_h5, save_format="h5")
         mlmodel = converter.convert(
@@ -129,15 +129,15 @@
 
         model = build_model()
         concrete_func = model.__call__.get_concrete_function()
         mlmodel = converter.convert(
             [concrete_func], outputs=["Identity"], source=frontend
         )
         assert mlmodel is not None
-    
+
     def test_graphdef_from_tf_function(self):
         class build_model(tf.Module):
             def __init__(self):
                 self.dense = tf.keras.layers.Dense(256, activation="relu")
 
             input_signature = [
                 tf.TensorSpec(name="input", shape=(
@@ -173,39 +173,39 @@
         )
         metadata_keys = mlmodel.get_spec().description.metadata.userDefined
         assert "com.github.apple.coremltools.version" in metadata_keys
         assert "com.github.apple.coremltools.source" in metadata_keys
         assert "tensorflow==2." in metadata_keys["com.github.apple.coremltools.source"]
 
     def test_invalid_format_none(self):
-        with pytest.raises(NotImplementedError) as e:
+        with pytest.raises(NotImplementedError, match="Expected model format: .* .h5"):
             converter.convert(None, source=frontend)
-        e.match(r"Expected model format: .* .h5")
 
     def test_invalid_format_invalid_extension(self):
-        _, invalid_filename = tempfile.mkstemp(
-            suffix=".invalid", prefix=self.saved_model_dir
-        )
-        with pytest.raises(NotImplementedError) as e:
+        _, invalid_filename = tempfile.mkstemp(suffix=".invalid", prefix=self.saved_model_dir)
+        with pytest.raises(
+            ValueError,
+            match="Input model path should be .h5/.hdf5 file or a directory, but got .*.invalid",
+        ):
             converter.convert(invalid_filename, source=frontend)
-        e.match(r"Expected model format: .* .h5")
 
     def test_invalid_format_multiple_concrete_functions(self):
         class build_model(tf.Module):
             @tf.function(
                 input_signature=[tf.TensorSpec(shape=[3, 4, 5], dtype=tf.float32)]
             )
             def __call__(self, x):
                 return tf.nn.relu(x)
 
         model = build_model()
         cf = model.__call__.get_concrete_function()
-        with pytest.raises(NotImplementedError) as e:
+        with pytest.raises(
+            NotImplementedError, match="Only a single concrete function is supported"
+        ):
             converter.convert([cf, cf, cf], source=frontend)
-        e.match(r"Only a single concrete function is supported")
 
     def test_invalid_converter_type(self):
         keras_model = tf.keras.Sequential(
             [tf.keras.layers.ReLU(input_shape=(4, 5), batch_size=3)]
         )
         with pytest.raises(ValueError) as e:
             converter.convert(keras_model, source="invalid")
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow2/test/test_v2_ops.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow2/test/test_v2_ops.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow2/test/test_v2_ops_tf_keras.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow2/test/test_v2_ops_tf_keras.py`

 * *Files 1% similar despite different names*

```diff
@@ -523,14 +523,19 @@
             activation="relu"
         )(input_layer)
         output_layer = GlobalMaxPooling2D()(layer)
         model = Model(inputs=[input_layer], outputs=[output_layer])
         TensorFlowBaseTest.run_compare_tf_keras(
             model,
             [random_gen((1, 80, 40, 1), rand_min=-10, rand_max=10)],
+            inputs_for_conversion=[
+                ct.TensorType(
+                    shape=(1, ct.RangeDim(upper_bound=80), ct.RangeDim(upper_bound=80), 1)
+                )
+            ],
             compute_unit=compute_unit,
             backend=backend,
         )
 
 
     @pytest.mark.parametrize(
         ",".join(
@@ -1034,28 +1039,34 @@
             [1e-2, 1e-10],
             [True, False],
         ),
     )
     def test_layer_normalization(self, compute_unit, backend, rank, axis, epsilon, dynamic):
         shape = np.random.randint(low=2, high=4, size=rank)
         keras_shape = shape.tolist()
+        inputs_for_conversion = None
 
         if dynamic:
             keras_shape[0] = None
+            if backend[0] == "mlprogram":
+                inputs_for_conversion = [
+                    ct.TensorType(shape=[ct.RangeDim(upper_bound=4)] + keras_shape[1:])
+                ]
 
         model = tf.keras.Sequential(
             [
                 tf.keras.layers.LayerNormalization(
                     batch_input_shape=keras_shape, axis=axis, epsilon=epsilon, trainable=False
                 )
             ]
         )
         TensorFlowBaseTest.run_compare_tf_keras(
             model,
             [random_gen(shape, rand_min=-100, rand_max=100)],
+            inputs_for_conversion=inputs_for_conversion,
             compute_unit=compute_unit,
             backend=backend,
         )
 
 
     @pytest.mark.parametrize(
         "compute_unit, backend, rank, groups, axis, epsilon, center, scale",
@@ -1686,24 +1697,32 @@
             if dynamic:
                 keras_shape[1] = keras_shape[2] = None
             upsample_factor = (upsample_factor[1], upsample_factor[2])
         elif op == tf.keras.layers.UpSampling3D:
             kwargs = {"data_format": data_format}
             shape = np.random.randint(low=2, high=4, size=5)
             keras_shape = np.copy(shape).tolist()
-            # not support upsampling3D with dynamic input shape, since 6D tensors are produced in that case
             if dynamic:
-                return
+                pytest.skip(
+                    "upsampling3D with dynamic input shape is not supported, since 6D tensors are produced in that case"
+                )
+
+        inputs_for_conversion = None
+        if backend[0] == "mlprogram" and dynamic:
+            inputs_for_conversion = [
+                ct.TensorType(shape=[dim or ct.RangeDim(upper_bound=10) for dim in keras_shape])
+            ]
 
         model = tf.keras.Sequential(
             [op(batch_input_shape=keras_shape, size=upsample_factor, **kwargs)]
         )
         spec = TensorFlowBaseTest.run_compare_tf_keras(
             model,
             [random_gen(shape, rand_min=-10, rand_max=10)],
+            inputs_for_conversion=inputs_for_conversion,
             compute_unit=compute_unit,
             backend=backend,
         )[0]
         # also check if the scale factor are integers
         if backend[0] == 'neuralnetwork':
             for layer in spec.neuralNetwork.layers:
                 if layer.WhichOneof('layer') == "upsample":
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow2/test/testing_utils.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow2/test/testing_utils.py`

 * *Files 2% similar despite different names*

```diff
@@ -9,18 +9,23 @@
 
 tf = pytest.importorskip("tensorflow", minversion="2.1.0")
 from tensorflow.python.framework import dtypes
 
 import coremltools as ct
 import coremltools.models.utils as coremltoolsutils
 from coremltools.converters.mil.frontend.tensorflow.test.testing_utils import (
-    TensorFlowBaseTest, get_tf_node_names)
+    TensorFlowBaseTest,
+    get_tf_node_names,
+)
 from coremltools.converters.mil.input_types import RangeDim, TensorType
-from coremltools.converters.mil.testing_utils import (compare_backend,
-                                                      ct_convert)
+from coremltools.converters.mil.testing_utils import (
+    compare_backend,
+    ct_convert,
+    validate_minimum_deployment_target,
+)
 from coremltools.models.utils import _macos_version
 
 
 def make_tf2_graph(input_types):
     """
     Decorator to help construct TensorFlow 2.x model.
 
@@ -100,40 +105,44 @@
     atol: float
         The absolute tolerance parameter.
     rtol: float
         The relative tolerance parameter.
     minimum_deployment_target: coremltools.target enumeration
         The spec version for the mlmodel
     """
+    # Infinite upper-bound not allowed in mlprogram.
+    symbolic_upper_bound = 20 if backend[0] == "mlprogram" else -1
+
     inputs = []
     if inputs_for_conversion is None:
         cf_inputs = [t for t in model[0].inputs if t.dtype != dtypes.resource]
         for t in cf_inputs:
             name = get_tf_node_names(t.name)[0]
-            shape = [RangeDim() if s is None or s == -1 else s \
-                    for s in list(t.get_shape())]
-            inputs.append(TensorType(name=name, shape=shape,
-                                     dtype=t.dtype.as_numpy_dtype))
+            shape = [
+                RangeDim(upper_bound=symbolic_upper_bound) if s is None or s == -1 else s
+                for s in list(t.get_shape())
+            ]
+            inputs.append(TensorType(name=name, shape=shape, dtype=t.dtype.as_numpy_dtype))
     else:
         inputs = inputs_for_conversion
-        
+
     outputs = []
     for t in output_names:
         name = get_tf_node_names(t)[0]
         outputs.append(name)
 
     # get TensorFlow 2.x output as reference and run comparison
     tf_input_values = [tf.constant(t) for t in input_dict.values()]
     tf_outputs = model[0](*tf_input_values)
     if isinstance(tf_outputs, (tuple, list)):
         ref = [t.numpy() for t in tf_outputs]
     else:
         ref = [tf_outputs.numpy()]
     expected_outputs = {n: v for n, v in zip(outputs, ref)}
-    
+
     mlmodel = ct_convert(
         model,
         source=frontend,
         inputs=inputs,
         outputs=outputs,
         convert_to=backend,
         debug=debug,
@@ -148,21 +157,21 @@
     if frontend_only or _macos_version() < (10, 13) \
        or (mlmodel.is_package and _macos_version() < (12, 0)):
         return mlmodel._spec, mlmodel, input_dict, None
 
     pred = None
     if not coremltoolsutils._has_custom_layer(mlmodel._spec):
         pred = compare_backend(
-                mlmodel,
-                input_dict,
-                expected_outputs,
-                atol=atol,
-                rtol=rtol,
-                also_compare_shapes=True,
-                dtype=backend[1],
+            mlmodel,
+            input_dict,
+            expected_outputs,
+            atol=atol,
+            rtol=rtol,
+            also_compare_shapes=True,
+            dtype=backend[1],
         )
     else:
         print('Skipping model prediction as it has a custom nn layer!')
     return mlmodel._spec, mlmodel, input_dict, pred
 
 
 def run_compare_tf_keras(
@@ -217,54 +226,61 @@
     if frontend_only or _macos_version() < (10, 13) \
        or (mlmodel.is_package and _macos_version() < (12, 0)):
         return proto, mlmodel, input_key_values, None
 
     pred = None
     if not coremltoolsutils._has_custom_layer(proto):
         pred = compare_backend(
-                mlmodel,
-                input_key_values,
-                expected_outputs,
-                atol=atol,
-                rtol=rtol,
-                also_compare_shapes=True,
-                dtype=backend[1]
+            mlmodel,
+            input_key_values,
+            expected_outputs,
+            atol=atol,
+            rtol=rtol,
+            also_compare_shapes=True,
+            dtype=backend[1],
         )
     else:
         print('Skipping model prediction as it has a custom nn layer!')
     return proto, mlmodel, input_key_values, pred
 
 
 class TensorFlow2BaseTest(TensorFlowBaseTest):
 
     @staticmethod
-    def run_compare_tf2(model,
-                        input_dict,
-                        output_names,
-                        inputs_for_conversion=None,
-                        compute_unit=ct.ComputeUnit.CPU_ONLY,
-                        frontend_only=False,
-                        frontend="tensorflow",
-                        backend=("neuralnetwork", "fp32"),
-                        debug=False,
-                        atol=1e-04,
-                        rtol=1e-05,
-                        minimum_deployment_target=None,):
-        res = run_compare_tf2(model,
-                              input_dict,
-                              output_names,
-                              inputs_for_conversion=inputs_for_conversion,
-                              compute_unit=compute_unit,
-                              frontend_only=frontend_only,
-                              frontend=frontend,
-                              backend=backend,
-                              debug=debug,
-                              atol=atol,
-                              rtol=rtol,
-                              minimum_deployment_target=minimum_deployment_target,)
+    def run_compare_tf2(
+        model,
+        input_dict,
+        output_names,
+        inputs_for_conversion=None,
+        compute_unit=ct.ComputeUnit.CPU_ONLY,
+        frontend_only=False,
+        frontend="tensorflow",
+        backend=("neuralnetwork", "fp32"),
+        debug=False,
+        atol=1e-04,
+        rtol=1e-05,
+        minimum_deployment_target=None,
+    ):
+        if minimum_deployment_target is not None:
+            validate_minimum_deployment_target(minimum_deployment_target, backend)
+
+        res = run_compare_tf2(
+            model,
+            input_dict,
+            output_names,
+            inputs_for_conversion=inputs_for_conversion,
+            compute_unit=compute_unit,
+            frontend_only=frontend_only,
+            frontend=frontend,
+            backend=backend,
+            debug=debug,
+            atol=atol,
+            rtol=rtol,
+            minimum_deployment_target=minimum_deployment_target,
+        )
         alist = list(res)
         alist.append(TensorFlow2BaseTest.testclassname)
         alist.append(TensorFlow2BaseTest.testmodelname)
         return tuple(alist)
 
     @staticmethod
     def run_compare_tf_keras(
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/tensorflow2/tf_graph_pass/rewrite_control_flow_functions.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/tensorflow2/tf_graph_pass/rewrite_control_flow_functions.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/torch/converter.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/torch/converter.py`

 * *Files 21% similar despite different names*

```diff
@@ -10,14 +10,15 @@
 
 from coremltools import _logger as logger
 from coremltools._deps import version_lt
 from coremltools.converters.mil._deployment_compatibility import AvailableTarget as _target
 from coremltools.converters.mil.input_types import ImageType
 from coremltools.converters.mil.mil import Builder as mb
 from coremltools.converters.mil.mil import Function, Program, types
+from coremltools.converters.mil.mil.types import is_float
 
 from .._utils import get_output_names
 from .internal_graph import InternalTorchIRGraph, InternalTorchIRNode
 from .ops import convert_nodes
 from .torch_op_registry import _TORCH_OPS_REGISTRY
 from .torchir_passes import (
     flatten_graph_input_values,
@@ -36,60 +37,205 @@
     torch.int64: types.int32,
 }
 
 
 mil_to_torch_types = {v: k for k, v in torch_to_mil_types.items()}
 
 
+class QuantizationContext:
+    """
+    Utilities to manage information pertaining to quantization of tensors in a PyTorch graph.
+    """
+
+    def __init__(self, context):
+        self._context = context
+
+        # Maps var name to tuple of (torch dtype, scale, zero_point)
+        # zero_point is in a NumPy dtype corresponding to torch one (for e.g. np.uint8 for torch.quint8).
+        self._quant_param_map = {}
+        # In MIL Programs, if a MIL op doesn't support quantized I/O but the PyTorch ops do,
+        # we just use floating-point tensors after dequantization. This means that information about
+        # what dtype (int8/uint8) quantized tensors had in the PyTorch graph is not carried into
+        # in the MIL graph.
+        # To simplify, we only support a single dtype for activation quantizations throughout the
+        # incoming graph.
+        # The other option is to remember dtypes across ops, including MIL ones that don't support
+        # quantized I/O. We will need to be careful about edge cases like conflicting dtypes, etc.
+        self._quant_dtype = None
+
+    def add_quantization_info(self, name, torch_dtype, scale, zero_point, axis=None):
+        """
+        Stores the quantization parameters (torch dtype, scale, zero_point) corresponding to a named
+        var in the graph.
+        zero_point should be in a NumPy dtype corresponding to torch one (for e.g. np.uint8 for torch.quint8).
+        """
+        self._quant_param_map[name] = (torch_dtype, scale, zero_point, axis)
+
+    def get_quantization_info(self, name):
+        """
+        Retrieves the information added via add_quantization_info, if applicable.
+        Returns None if quantization parameters could not be found.
+        """
+        if name not in self._quant_param_map:
+            return None
+        return self._quant_param_map[name]
+
+    def maybe_handle_quantized_inputs(self, node: InternalTorchIRNode):
+        """
+        If a node's op doesn't support quantized inputs but gets one, this will wire it to
+        receive a dequantized version of it.
+        """
+
+        op_type = node.kind
+        if op_type in {"quantize_per_tensor", "dequantize"} or "quantized::" in op_type:
+            # Op can handle quantized inputs. Nothing to do here.
+            return
+
+        for input_name in node.inputs:
+            if self.get_quantization_info(input_name) is None:
+                # Not a quantized tensor
+                continue
+
+            # We need a dequantized version of the input to feed to the op.
+            dequantized_var, _ = self.get_dequantized_var(input_name)
+            node.replace_name(input_name, dequantized_var.name)
+
+    def get_quantized_per_tensor(self, name, torch_dtype, scale, zero_point, quantized_name):
+        """
+        Quantizes the provided named var as per quantization params.
+        zero_point will be cast to the appropriate dtype based on torch_dtype.
+        """
+        if self._quant_dtype is None:
+            self._quant_dtype = torch_dtype
+        elif self._quant_dtype != torch_dtype:
+            raise NotImplementedError(
+                "Currently we only support a single activation dtype throughout the model"
+            )
+
+        if torch_dtype == torch.quint8:
+            zero_point = np.uint8(zero_point)
+            output_dtype = "uint8"
+        elif torch_dtype == torch.qint8:
+            zero_point = np.int8(zero_point)
+            output_dtype = "int8"
+        else:
+            raise ValueError(f"Invalid torch dtype for quantization: {torch_dtype}")
+        if np.isscalar(zero_point):
+            # MIL allows skipping zero_point if its zero.
+            if zero_point == 0:
+                zero_point = None
+            # TODO (rdar://107718371): skip 128 for uint8 by switching to int8
+
+        result = mb.quantize(
+            input=self._context[name], zero_point=zero_point, scale=scale, output_dtype=output_dtype
+        )
+        self._context.add(result, quantized_name)
+        self._context.quant_context.add_quantization_info(
+            quantized_name, torch_dtype, scale, zero_point
+        )
+        return result
+
+    def get_dequantized_var(self, name: str, dequantized_name: str = None):
+        """
+        Returns dequantized var & torch dtype corresponding to the named var.
+        """
+
+        original_var = self._context[name]
+        if is_float(original_var.dtype):
+            # Input doesn't need dequantization.
+            # This might happen if in the PyTorch graph the upstream nodes supported quantized inputs,
+            # but MIL does not. In that case, we already dequantized the vars before feeding them to
+            # the MIL op.
+            if dequantized_name is not None:
+                self._context.add(original_var, dequantized_name)
+            if self._quant_dtype is None:
+                raise AssertionError("Trying to dequantize without quantization info")
+            return original_var, self._quant_dtype
+
+        quant_params = self.get_quantization_info(name)
+        if quant_params is None:
+            raise ValueError(
+                f"Could not find quantization parameters for quantized var {original_var.name}"
+            )
+        torch_dtype, scale, zero_point, axis = quant_params
+
+        # We add a new var corresponding to each dequantized value.
+        # This ensures the atomicity of quantized op patterns in MIL.
+        dequantized_var = mb.dequantize(
+            input=original_var, scale=scale, zero_point=zero_point, axis=axis
+        )
+        if dequantized_name is not None:
+            dequantized_var_name = dequantized_name
+        else:
+            dequantized_var_name = dequantized_var.name
+        self._context.add(dequantized_var, dequantized_var_name)
+
+        return dequantized_var, torch_dtype
+
+
 class TranscriptionContext:
     """
     Maintains a map from torch operations to their MIL values
     while building the graph. Can be used to process subgraphs recursively
     by pushing new context when stepping into a subgraph and popping that
     context when stepping out.
     """
 
     def __init__(self, name=None):
         self.name = name if name else ""
         self._current_graph = [{}]
+        self._torch_graph = None
+        self._quant_context = QuantizationContext(self)
+
+    @property
+    def torch_graph(self):
+        if self._torch_graph is None:
+            raise ValueError("InternalTorchIRGraph not set yet on context")
+        return self._torch_graph
+
+    @property
+    def quant_context(self):
+        return self._quant_context
+
+    @torch_graph.setter
+    def torch_graph(self, graph: InternalTorchIRGraph):
+        self._torch_graph = graph
 
     def prepare_for_conversion(self, node: InternalTorchIRNode):
         """
         Perform any preparation necessary before node-specific frontend conversion
         is invoked.
         """
-        pass
+        self.quant_context.maybe_handle_quantized_inputs(node)
 
     def add(self, ssa_var, torch_name=None):
         """
         Arguments:
             ssa_var: Variable to add to the graph being constructed.
             torch_name: Optional unique string identifier of the operation. If
                 omitted, it will use @ssa_var.name.
         """
         if torch_name is None:
             torch_name = ssa_var.name
         if torch_name in self._current_graph[-1]:
-            print("Torch var {} is added again.".format(torch_name))
+            print(f"Torch var {torch_name} is added again.")
             return
         self._current_graph[-1][torch_name] = ssa_var
 
     def __getitem__(self, torch_name):
         """
         Lookup a name in the context. Note that since nested blocks must be
         able to access anything that was defined before them, we have to
         search all contexts for a name, starting with the most local scope.
         """
         for idx in reversed(range(len(self._current_graph))):
             current_graph = self._current_graph[idx]
             if torch_name in current_graph:
                 return self._current_graph[idx][torch_name]
-        raise ValueError(
-            "Torch var {} not found in context {}".format(torch_name, self.name)
-        )
+        raise ValueError(f"Torch var {torch_name} not found in context {self.name}")
 
     def __contains__(self, torch_name):
         """Returns whether or not the torch var exist in context."""
         return torch_name in self._current_graph[-1]
 
     def push(self, inputs=None):
         """
@@ -117,15 +263,15 @@
             for k, v in current_graph.items():
                 if hasattr(v, "shape_str"):
                     shape_str = v.shape_str()
                 elif hasattr(v, "sym_shape"):
                     shape_str = v.sym_shape()
                 else:
                     shape_str = "None"
-                __str += "%{} : {}\n".format(k, shape_str)
+                __str += f"%{k} : {shape_str}\n"
             _str += __str + "\n"
         return _str
 
     def __repr__(self):
         return str(self)
 
 
@@ -170,14 +316,15 @@
         self.opset_version = _target(opset_version) if opset_version is not None else None
         self.context = TranscriptionContext()
         raw_graph, params_dict = self._expand_and_optimize_ir(self.torchscript)
         self.params_dict = params_dict
         self.graph = InternalTorchIRGraph(
             raw_graph, params_dict, self.inputs, cut_at_symbols
         )
+        self.context.torch_graph = self.graph
 
         # TODO (rdar://106161395): Register Torch IR passes and unify them into the pass pipeline.
         # Apply Torch IR passes
         passes = [
             transform_inplace_ops,
             flatten_graph_input_values,
             flatten_graph_output_values,
@@ -227,16 +374,24 @@
         Returns the set of ops in @self.graph that are implemented, and
         the set for which no conversion function is registered.
         """
         return TorchConverter._check_ops(self.graph)
 
     def convert_const(self):
         for name, val in self.graph.params.items():
-            if not isinstance(val, np.ndarray):
-                raise ValueError("unsupported class for {} in PyTorch graph: {}".format(name, type(val)))
+            if isinstance(val, torch._C.ScriptObject):
+                logger.info(f"Encountered constant {name} of type _torch._C.ScriptObject")
+                continue
+            elif not isinstance(val, np.ndarray):
+                raise ValueError(f"unsupported class for {name} in PyTorch graph: {type(val)}")
+            # TODO (rdar://107718371): support uint8 quantization
+            # Some torch models store indices with uint8, which are unrelated to quantization and
+            # need to be cast to int32 since Core ML does not support int8.
+            # We need a way to distinguish whether an uint8 is quantization (so should be kept)
+            # or not (so should be cast to int32).
             if val.dtype == np.uint8:
                 val = val.astype(np.int32)
             const = mb.const(val=val, name=name)
             self.context.add(const)
 
     def convert(self):
         logger.info("Converting graph.")
@@ -285,26 +440,23 @@
 
             graph_outputs = [self.context[name] for name in self.graph.outputs]
 
             # An output can be None when it's a None constant, which happens
             # in Fairseq MT.
             for g in graph_outputs:
                 if g is None:
-                    msg = "Droping output {} which is None"
-                    logger.warning(msg.format(g))
+                    logger.warning(f"Droping output {g} which is None")
             graph_outputs = [g for g in graph_outputs if g is not None]
 
             # Output renaming occurs
             if self.outputs is not None:
                 if len(self.outputs) != len(graph_outputs):
-                    msg = "Number of outputs provided, {}, do not match the number of outputs detected in the model, {}."
-                    raise ValueError(msg.format(
-                        len(self.outputs),
-                        len(graph_outputs),
-                    ))
+                    raise ValueError(
+                        f"Number of outputs provided, {len(self.outputs)}, do not match the number of outputs detected in the model, {len(graph_outputs)}."
+                    )
             if self.output_names:
                 for index, var in enumerate(graph_outputs):
                     if self.output_names[index] is not None:
                         output_rename = self.output_names[index]
                         var.name = output_rename
 
             ssa_func.set_outputs(graph_outputs)
@@ -380,15 +532,15 @@
         params_dict = {}
         state_dict = torchscript.state_dict(keep_vars=True)
 
         def _check_is_tensor(node, module):
             if not isinstance(module, torch.Tensor):
                 return False
             if str(node.output().type()) not in ("Tensor", "Optional[Tensor]"):
-                raise TypeError("Type \"{}\" not supported".format(node.output().type()))
+                raise TypeError(f'Type "{node.output().type()}" not supported')
             return True
 
         def _check_is_quantized_tensor(node, module):
             if not isinstance(module, torch._C.ScriptObject):
                 return False
             # We only support ScriptObjects that correspond to quantized packed params.
             assert "PackedParams" in node.output().type().name()
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/torch/dialect_ops.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/torch/dialect_ops.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/torch/internal_graph.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/torch/internal_graph.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/torch/load.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/torch/load.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/torch/ops.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/torch/ops.py`

 * *Files 2% similar despite different names*

```diff
@@ -10,12123 +10,12761 @@
 00000090: 6e20 7468 6520 4c49 4345 4e53 452e 7478  n the LICENSE.tx
 000000a0: 7420 6669 6c65 206f 7220 6174 2068 7474  t file or at htt
 000000b0: 7073 3a2f 2f6f 7065 6e73 6f75 7263 652e  ps://opensource.
 000000c0: 6f72 672f 6c69 6365 6e73 6573 2f42 5344  org/licenses/BSD
 000000d0: 2d33 2d43 6c61 7573 650a 0a69 6d70 6f72  -3-Clause..impor
 000000e0: 7420 6275 696c 7469 6e73 0a69 6d70 6f72  t builtins.impor
 000000f0: 7420 6d61 7468 2061 7320 5f6d 6174 680a  t math as _math.
-00000100: 696d 706f 7274 206e 756d 6265 7273 0a66  import numbers.f
-00000110: 726f 6d20 636f 6c6c 6563 7469 6f6e 732e  rom collections.
-00000120: 6162 6320 696d 706f 7274 2049 7465 7261  abc import Itera
-00000130: 626c 650a 6672 6f6d 2074 7970 696e 6720  ble.from typing 
-00000140: 696d 706f 7274 204c 6973 742c 204f 7074  import List, Opt
-00000150: 696f 6e61 6c0a 0a69 6d70 6f72 7420 6e75  ional..import nu
-00000160: 6d70 7920 6173 205f 6e70 0a69 6d70 6f72  mpy as _np.impor
-00000170: 7420 746f 7263 680a 6672 6f6d 2074 7164  t torch.from tqd
-00000180: 6d20 696d 706f 7274 2074 7164 6d20 6173  m import tqdm as
-00000190: 205f 7471 646d 0a0a 6672 6f6d 2063 6f72   _tqdm..from cor
-000001a0: 656d 6c74 6f6f 6c73 2069 6d70 6f72 7420  emltools import 
-000001b0: 5f6c 6f67 6765 7220 6173 206c 6f67 6765  _logger as logge
-000001c0: 720a 6672 6f6d 2063 6f72 656d 6c74 6f6f  r.from coremltoo
-000001d0: 6c73 2e63 6f6e 7665 7274 6572 732e 6d69  ls.converters.mi
-000001e0: 6c2e 5f64 6570 6c6f 796d 656e 745f 636f  l._deployment_co
-000001f0: 6d70 6174 6962 696c 6974 7920 696d 706f  mpatibility impo
-00000200: 7274 2028 0a20 2020 2041 7661 696c 6162  rt (.    Availab
-00000210: 6c65 5461 7267 6574 2061 7320 7461 7267  leTarget as targ
-00000220: 6574 2c0a 290a 6672 6f6d 2063 6f72 656d  et,.).from corem
-00000230: 6c74 6f6f 6c73 2e63 6f6e 7665 7274 6572  ltools.converter
-00000240: 732e 6d69 6c2e 6d69 6c20 696d 706f 7274  s.mil.mil import
-00000250: 2042 7569 6c64 6572 2061 7320 6d62 0a66   Builder as mb.f
-00000260: 726f 6d20 636f 7265 6d6c 746f 6f6c 732e  rom coremltools.
-00000270: 636f 6e76 6572 7465 7273 2e6d 696c 2e6d  converters.mil.m
-00000280: 696c 2069 6d70 6f72 7420 5379 6d62 6f6c  il import Symbol
-00000290: 2c20 7479 7065 730a 6672 6f6d 2063 6f72  , types.from cor
-000002a0: 656d 6c74 6f6f 6c73 2e63 6f6e 7665 7274  emltools.convert
-000002b0: 6572 732e 6d69 6c2e 6d69 6c2e 626c 6f63  ers.mil.mil.bloc
-000002c0: 6b20 696d 706f 7274 2028 0a20 2020 2069  k import (.    i
-000002d0: 735f 6375 7272 656e 745f 6f70 7365 745f  s_current_opset_
-000002e0: 7665 7273 696f 6e5f 636f 6d70 6174 6962  version_compatib
-000002f0: 6c65 5f77 6974 682c 0a29 0a66 726f 6d20  le_with,.).from 
-00000300: 636f 7265 6d6c 746f 6f6c 732e 636f 6e76  coremltools.conv
-00000310: 6572 7465 7273 2e6d 696c 2e6d 696c 2e6f  erters.mil.mil.o
-00000320: 7073 2e64 6566 732e 5f75 7469 6c73 2069  ps.defs._utils i
-00000330: 6d70 6f72 7420 280a 2020 2020 4d41 585f  mport (.    MAX_
-00000340: 5349 5a45 5f43 4f4e 5354 414e 545f 464f  SIZE_CONSTANT_FO
-00000350: 4c44 494e 472c 2070 726f 6d6f 7465 5f69  LDING, promote_i
-00000360: 6e70 7574 5f64 7479 7065 732c 0a20 2020  nput_dtypes,.   
-00000370: 2073 6f6c 7665 5f73 6c69 6365 5f62 795f   solve_slice_by_
-00000380: 696e 6465 785f 7368 6170 6529 0a66 726f  index_shape).fro
-00000390: 6d20 636f 7265 6d6c 746f 6f6c 732e 636f  m coremltools.co
-000003a0: 6e76 6572 7465 7273 2e6d 696c 2e6d 696c  nverters.mil.mil
-000003b0: 2e74 7970 6573 2069 6d70 6f72 7420 6973  .types import is
-000003c0: 5f62 6f6f 6c2c 206e 7074 7970 655f 6672  _bool, nptype_fr
-000003d0: 6f6d 5f62 7569 6c74 696e 0a66 726f 6d20  om_builtin.from 
-000003e0: 636f 7265 6d6c 746f 6f6c 732e 636f 6e76  coremltools.conv
-000003f0: 6572 7465 7273 2e6d 696c 2e6d 696c 2e74  erters.mil.mil.t
-00000400: 7970 6573 2e73 796d 626f 6c69 6320 696d  ypes.symbolic im
-00000410: 706f 7274 2028 0a20 2020 2061 6e79 5f73  port (.    any_s
-00000420: 796d 626f 6c69 632c 0a20 2020 2069 735f  ymbolic,.    is_
-00000430: 7379 6d62 6f6c 6963 2c0a 290a 6672 6f6d  symbolic,.).from
-00000440: 2063 6f72 656d 6c74 6f6f 6c73 2e63 6f6e   coremltools.con
-00000450: 7665 7274 6572 732e 6d69 6c2e 6d69 6c2e  verters.mil.mil.
-00000460: 7661 7220 696d 706f 7274 204c 6973 7456  var import ListV
-00000470: 6172 2c20 5661 720a 0a66 726f 6d20 2e2e  ar, Var..from ..
-00000480: 5f75 7469 6c73 2069 6d70 6f72 7420 7661  _utils import va
-00000490: 6c75 655f 6174 2c20 6275 696c 645f 6569  lue_at, build_ei
-000004a0: 6e73 756d 5f6d 696c 0a66 726f 6d20 2e74  nsum_mil.from .t
-000004b0: 6f72 6368 5f6f 705f 7265 6769 7374 7279  orch_op_registry
-000004c0: 2069 6d70 6f72 7420 5f54 4f52 4348 5f4f   import _TORCH_O
-000004d0: 5053 5f52 4547 4953 5452 592c 2072 6567  PS_REGISTRY, reg
-000004e0: 6973 7465 725f 746f 7263 685f 6f70 0a0a  ister_torch_op..
-000004f0: 2320 5468 6520 7079 746f 7263 6820 6172  # The pytorch ar
-00000500: 6773 2066 6f72 206d 616e 7920 6f66 2074  gs for many of t
-00000510: 6865 2062 656c 6f77 206f 7073 2077 6572  he below ops wer
-00000520: 6520 736f 7572 6365 6420 6672 6f6d 0a23  e sourced from.#
-00000530: 2068 7474 7073 3a2f 2f67 6974 6875 622e   https://github.
-00000540: 636f 6d2f 7079 746f 7263 682f 7079 746f  com/pytorch/pyto
-00000550: 7263 682f 626c 6f62 2f64 3937 3130 3037  rch/blob/d971007
-00000560: 6332 3931 6330 6561 6431 3030 3364 3132  c291c0ead1003d12
-00000570: 6364 3535 3364 3138 6464 6235 3832 3230  cd553d18ddb58220
-00000580: 372f 746f 7263 682f 6373 7263 2f6a 6974  7/torch/csrc/jit
-00000590: 2f6d 6f62 696c 652f 7265 6769 7374 6572  /mobile/register
-000005a0: 5f6d 6f62 696c 655f 6f70 732e 6370 7023  _mobile_ops.cpp#
-000005b0: 4c32 3136 0a0a 0a23 204d 6178 2069 6e74  L216...# Max int
-000005c0: 3634 2076 616c 7565 2e20 5573 6564 2061  64 value. Used a
-000005d0: 7320 6120 6465 6661 756c 7420 7661 6c75  s a default valu
-000005e0: 6520 696e 206d 616e 7920 5079 546f 7263  e in many PyTorc
-000005f0: 6820 6675 6e63 7469 6f6e 732e 0a50 5954  h functions..PYT
-00000600: 4f52 4348 5f44 4546 4155 4c54 5f56 414c  ORCH_DEFAULT_VAL
-00000610: 5545 203d 2032 2a2a 3633 202d 2031 0a0a  UE = 2**63 - 1..
-00000620: 5641 4c55 455f 434c 4f53 455f 544f 5f49  VALUE_CLOSE_TO_I
-00000630: 4e46 494e 4954 5920 3d20 3165 2b33 380a  NFINITY = 1e+38.
-00000640: 0a0a 6465 6620 5f61 6c6c 5f6f 7574 7075  ..def _all_outpu
-00000650: 7473 5f70 7265 7365 6e74 2863 6f6e 7465  ts_present(conte
-00000660: 7874 2c20 6772 6170 6829 3a0a 2020 2020  xt, graph):.    
-00000670: 2222 220a 2020 2020 5265 7475 726e 7320  """.    Returns 
-00000680: 7472 7565 2069 6620 616c 6c20 7468 6520  true if all the 
-00000690: 7379 6d62 6f6c 7320 696e 2074 6865 2067  symbols in the g
-000006a0: 7261 7068 2773 206f 7574 7075 7420 6c69  raph's output li
-000006b0: 7374 2061 7265 0a20 2020 2070 7265 7365  st are.    prese
-000006c0: 6e74 2069 6e20 636f 6e74 6578 742e 0a20  nt in context.. 
-000006d0: 2020 2022 2222 0a20 2020 2066 6f72 206f     """.    for o
-000006e0: 7574 7020 696e 2067 7261 7068 2e6f 7574  utp in graph.out
-000006f0: 7075 7473 3a0a 2020 2020 2020 2020 7472  puts:.        tr
-00000700: 793a 0a20 2020 2020 2020 2020 2020 2063  y:.            c
-00000710: 6f6e 7465 7874 5b6f 7574 705d 0a20 2020  ontext[outp].   
-00000720: 2020 2020 2065 7863 6570 7420 5661 6c75       except Valu
-00000730: 6545 7272 6f72 3a0a 2020 2020 2020 2020  eError:.        
-00000740: 2020 2020 7265 7475 726e 2046 616c 7365      return False
-00000750: 0a20 2020 2072 6574 7572 6e20 5472 7565  .    return True
-00000760: 0a0a 0a64 6566 2063 6f6e 7665 7274 5f6e  ...def convert_n
-00000770: 6f64 6573 2863 6f6e 7465 7874 2c20 6772  odes(context, gr
-00000780: 6170 6829 3a0a 2020 2020 2222 220a 2020  aph):.    """.  
-00000790: 2020 4974 6572 6174 6520 6f76 6572 2074    Iterate over t
-000007a0: 6865 206e 6f64 6573 206f 6620 6120 6772  he nodes of a gr
-000007b0: 6170 6820 6f72 2062 6c6f 636b 2061 6e64  aph or block and
-000007c0: 2063 6f6e 7665 7274 2074 6f20 4d49 4c2e   convert to MIL.
-000007d0: 0a0a 2020 2020 4172 6775 6d65 6e74 733a  ..    Arguments:
-000007e0: 0a20 2020 2020 2020 2063 6f6e 7465 7874  .        context
-000007f0: 3a20 4120 5472 616e 7363 7269 7074 696f  : A Transcriptio
-00000800: 6e43 6f6e 7465 7874 206f 626a 6563 7420  nContext object 
-00000810: 746f 2070 756c 6c20 6e6f 6465 2069 6e70  to pull node inp
-00000820: 7574 7320 616e 640a 2020 2020 2020 2020  uts and.        
-00000830: 2020 2020 6173 7369 676e 206e 6f64 6520      assign node 
-00000840: 6f75 7470 7574 732e 0a20 2020 2020 2020  outputs..       
-00000850: 2067 7261 7068 3a20 416e 2049 6e74 6572   graph: An Inter
-00000860: 6e61 6c54 6f72 6368 4952 4772 6170 6820  nalTorchIRGraph 
-00000870: 6f72 2049 6e74 6572 6e61 6c54 6f72 6368  or InternalTorch
-00000880: 4952 426c 6f63 6b20 6f62 6a65 6374 2e0a  IRBlock object..
-00000890: 2020 2020 2222 220a 2020 2020 666f 7220      """.    for 
-000008a0: 6e6f 6465 2069 6e20 5f74 7164 6d28 6772  node in _tqdm(gr
-000008b0: 6170 682e 6e6f 6465 732c 2064 6573 633d  aph.nodes, desc=
-000008c0: 2243 6f6e 7665 7274 696e 6720 5079 546f  "Converting PyTo
-000008d0: 7263 6820 4672 6f6e 7465 6e64 203d 3d3e  rch Frontend ==>
-000008e0: 204d 494c 204f 7073 222c 2075 6e69 743d   MIL Ops", unit=
-000008f0: 2220 6f70 7322 293a 0a20 2020 2020 2020  " ops"):.       
-00000900: 206f 705f 6c6f 6f6b 7570 203d 206e 6f64   op_lookup = nod
-00000910: 652e 6b69 6e64 0a20 2020 2020 2020 2069  e.kind.        i
-00000920: 6620 6f70 5f6c 6f6f 6b75 702e 7374 6172  f op_lookup.star
-00000930: 7473 7769 7468 2822 5f5f 2229 2061 6e64  tswith("__") and
-00000940: 206f 705f 6c6f 6f6b 7570 2e65 6e64 7377   op_lookup.endsw
-00000950: 6974 6828 225f 5f22 293a 0a20 2020 2020  ith("__"):.     
-00000960: 2020 2020 2020 2023 2053 6f6d 6520 6f70         # Some op
-00000970: 7320 6d61 7920 6861 7665 2064 6f75 626c  s may have doubl
-00000980: 6520 756e 6465 7273 636f 7265 2c20 7375  e underscore, su
-00000990: 6368 2061 7320 605f 5f61 6e64 5f5f 602e  ch as `__and__`.
-000009a0: 0a20 2020 2020 2020 2020 2020 206f 705f  .            op_
-000009b0: 6c6f 6f6b 7570 203d 206f 705f 6c6f 6f6b  lookup = op_look
-000009c0: 7570 5b32 3a2d 325d 0a20 2020 2020 2020  up[2:-2].       
-000009d0: 2065 6c69 6620 6f70 5f6c 6f6f 6b75 702e   elif op_lookup.
-000009e0: 656e 6473 7769 7468 2822 5f22 293a 0a20  endswith("_"):. 
-000009f0: 2020 2020 2020 2020 2020 2023 2054 6869             # Thi
-00000a00: 7320 6973 2061 6e20 2269 6e20 706c 6163  s is an "in plac
-00000a10: 6522 206f 702e 0a20 2020 2020 2020 2020  e" op..         
-00000a20: 2020 2023 204c 6f6f 6b20 7570 2074 6865     # Look up the
-00000a30: 2073 7461 6e64 6172 6420 6f70 2069 6e73   standard op ins
-00000a40: 7465 6164 2062 7920 7265 6d6f 7669 6e67  tead by removing
-00000a50: 2075 6e64 6572 7363 6f72 652e 0a20 2020   underscore..   
-00000a60: 2020 2020 2020 2020 206f 705f 6c6f 6f6b           op_look
-00000a70: 7570 203d 206f 705f 6c6f 6f6b 7570 5b3a  up = op_lookup[:
-00000a80: 2d31 5d0a 2020 2020 2020 2020 6164 645f  -1].        add_
-00000a90: 6f70 203d 205f 544f 5243 485f 4f50 535f  op = _TORCH_OPS_
-00000aa0: 5245 4749 5354 5259 2e67 6574 286f 705f  REGISTRY.get(op_
-00000ab0: 6c6f 6f6b 7570 2c20 4e6f 6e65 290a 0a20  lookup, None).. 
-00000ac0: 2020 2020 2020 206c 6f67 6765 722e 696e         logger.in
-00000ad0: 666f 2822 436f 6e76 6572 7469 6e67 206f  fo("Converting o
-00000ae0: 7020 7b7d 203a 207b 7d22 2e66 6f72 6d61  p {} : {}".forma
-00000af0: 7428 6e6f 6465 2e6e 616d 652c 206e 6f64  t(node.name, nod
-00000b00: 652e 6b69 6e64 2929 0a20 2020 2020 2020  e.kind)).       
-00000b10: 2069 6620 6164 645f 6f70 2069 7320 4e6f   if add_op is No
-00000b20: 6e65 3a0a 2020 2020 2020 2020 2020 2020  ne:.            
-00000b30: 7261 6973 6520 5275 6e74 696d 6545 7272  raise RuntimeErr
-00000b40: 6f72 280a 2020 2020 2020 2020 2020 2020  or(.            
-00000b50: 2020 2020 2250 7954 6f72 6368 2063 6f6e      "PyTorch con
-00000b60: 7665 7274 2066 756e 6374 696f 6e20 666f  vert function fo
-00000b70: 7220 6f70 2027 7b7d 2720 6e6f 7420 696d  r op '{}' not im
-00000b80: 706c 656d 656e 7465 642e 222e 666f 726d  plemented.".form
-00000b90: 6174 286e 6f64 652e 6b69 6e64 290a 2020  at(node.kind).  
-00000ba0: 2020 2020 2020 2020 2020 290a 0a20 2020            )..   
-00000bb0: 2020 2020 2063 6f6e 7465 7874 2e70 7265       context.pre
-00000bc0: 7061 7265 5f66 6f72 5f63 6f6e 7665 7273  pare_for_convers
-00000bd0: 696f 6e28 6e6f 6465 290a 2020 2020 2020  ion(node).      
-00000be0: 2020 6164 645f 6f70 2863 6f6e 7465 7874    add_op(context
-00000bf0: 2c20 6e6f 6465 290a 0a20 2020 2020 2020  , node)..       
-00000c00: 2023 2057 6527 7665 2067 656e 6572 6174   # We've generat
-00000c10: 6564 2061 6c6c 2074 6865 206f 7574 7075  ed all the outpu
-00000c20: 7473 2074 6865 2067 7261 7068 206e 6565  ts the graph nee
-00000c30: 6473 2c20 7465 726d 696e 6174 6520 636f  ds, terminate co
-00000c40: 6e76 6572 7369 6f6e 2e0a 2020 2020 2020  nversion..      
-00000c50: 2020 6966 205f 616c 6c5f 6f75 7470 7574    if _all_output
-00000c60: 735f 7072 6573 656e 7428 636f 6e74 6578  s_present(contex
-00000c70: 742c 2067 7261 7068 293a 0a20 2020 2020  t, graph):.     
-00000c80: 2020 2020 2020 2062 7265 616b 0a0a 0a64         break...d
-00000c90: 6566 2063 6f6e 7665 7274 5f62 6c6f 636b  ef convert_block
-00000ca0: 2863 6f6e 7465 7874 2c20 626c 6f63 6b2c  (context, block,
-00000cb0: 2069 6e70 7574 7329 3a0a 2020 2020 2222   inputs):.    ""
-00000cc0: 2243 6f6e 7665 7274 2061 2062 6c6f 636b  "Convert a block
-00000cd0: 2028 7375 622d 6772 6170 6829 2074 6f20   (sub-graph) to 
-00000ce0: 4d49 4c2e 2043 6f6e 7665 7273 696f 6e20  MIL. Conversion 
-00000cf0: 6861 7070 656e 7320 7769 7468 696e 2061  happens within a
-00000d00: 206e 6577 0a20 2020 2020 2020 2063 6f6e   new.        con
-00000d10: 7465 7874 2066 7261 6d65 2e0a 0a20 2020  text frame...   
-00000d20: 2020 2020 2041 7267 756d 656e 7473 3a0a       Arguments:.
-00000d30: 2020 2020 2020 2020 2020 2020 636f 6e74              cont
-00000d40: 6578 743a 2041 2054 7261 6e73 6372 6970  ext: A Transcrip
-00000d50: 7469 6f6e 436f 6e74 6578 7420 6f62 6a65  tionContext obje
-00000d60: 6374 2074 6f20 7075 6c6c 206e 6f64 6520  ct to pull node 
-00000d70: 696e 7075 7473 2061 6e64 0a20 2020 2020  inputs and.     
-00000d80: 2020 2020 2020 2020 2020 2061 7373 6967             assig
-00000d90: 6e20 6e6f 6465 206f 7574 7075 7473 2e0a  n node outputs..
-00000da0: 2020 2020 2020 2020 2020 2020 626c 6f63              bloc
-00000db0: 6b3a 2041 6e20 496e 7465 726e 616c 546f  k: An InternalTo
-00000dc0: 7263 6849 5242 6c6f 636b 206f 626a 6563  rchIRBlock objec
-00000dd0: 742e 0a20 2020 2020 2020 2020 2020 2069  t..            i
-00000de0: 6e70 7574 733a 204c 6973 7420 6f66 2056  nputs: List of V
-00000df0: 6172 7320 6672 6f6d 2074 6865 206f 7574  ars from the out
-00000e00: 6572 2063 6f6e 7465 7874 2074 6861 7420  er context that 
-00000e10: 6d61 7020 746f 2074 6865 2062 6c6f 636b  map to the block
-00000e20: 2773 0a20 2020 2020 2020 2020 2020 2020  's.             
-00000e30: 2020 2065 7870 6563 7465 6420 696e 7075     expected inpu
-00000e40: 7473 2e20 5468 6520 6e75 6d62 6572 206f  ts. The number o
-00000e50: 6620 696e 7075 7473 2070 726f 7669 6465  f inputs provide
-00000e60: 6420 6d75 7374 206d 6174 6368 2074 6865  d must match the
-00000e70: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00000e80: 206e 756d 6265 7220 6578 7065 6374 6564   number expected
-00000e90: 2062 7920 7468 6520 626c 6f63 6b2e 0a20   by the block.. 
-00000ea0: 2020 2022 2222 0a0a 2020 2020 6173 7365     """..    asse
-00000eb0: 7274 206c 656e 2862 6c6f 636b 2e69 6e70  rt len(block.inp
-00000ec0: 7574 7329 203d 3d20 6c65 6e28 696e 7075  uts) == len(inpu
-00000ed0: 7473 290a 0a20 2020 2023 2053 7461 7274  ts)..    # Start
-00000ee0: 2061 206e 6577 2063 6f6e 7465 7874 2066   a new context f
-00000ef0: 7261 6d65 2e0a 2020 2020 636f 6e74 6578  rame..    contex
-00000f00: 742e 7075 7368 2828 626c 6f63 6b2e 696e  t.push((block.in
-00000f10: 7075 7473 2c20 696e 7075 7473 2929 0a0a  puts, inputs))..
-00000f20: 2020 2020 2320 4164 6420 7468 6520 626c      # Add the bl
-00000f30: 6f63 6b20 6f70 732e 0a20 2020 2063 6f6e  ock ops..    con
-00000f40: 7665 7274 5f6e 6f64 6573 2863 6f6e 7465  vert_nodes(conte
-00000f50: 7874 2c20 626c 6f63 6b29 0a0a 2020 2020  xt, block)..    
-00000f60: 2320 436f 6c6c 6563 7420 7468 6520 626c  # Collect the bl
-00000f70: 6f63 6b20 6f75 7470 7574 732e 0a20 2020  ock outputs..   
-00000f80: 206f 7574 7075 7473 203d 205b 636f 6e74   outputs = [cont
-00000f90: 6578 745b 6f75 7470 5d20 666f 7220 6f75  ext[outp] for ou
-00000fa0: 7470 2069 6e20 626c 6f63 6b2e 6f75 7470  tp in block.outp
-00000fb0: 7574 735d 0a0a 2020 2020 2320 5265 7475  uts]..    # Retu
-00000fc0: 726e 2074 6f20 7468 6520 7072 6576 696f  rn to the previo
-00000fd0: 7573 2063 6f6e 7465 7874 2066 7261 6d65  us context frame
-00000fe0: 2e0a 2020 2020 636f 6e74 6578 742e 706f  ..    context.po
-00000ff0: 7028 290a 2020 2020 7265 7475 726e 206f  p().    return o
-00001000: 7574 7075 7473 0a0a 0a23 2053 6f6d 6520  utputs...# Some 
-00001010: 6f70 7320 7769 6c6c 2072 6563 6569 7665  ops will receive
-00001020: 2061 2064 7479 7065 2069 6e70 7574 2061   a dtype input a
-00001030: 7320 616e 2069 6e74 6567 6572 0a23 2077  s an integer.# w
-00001040: 6869 6368 206d 6170 7320 746f 2061 2074  hich maps to a t
-00001050: 6f72 6368 2064 7479 7065 2e20 5468 6520  orch dtype. The 
-00001060: 6265 6c6f 7720 6d61 7070 696e 6720 7761  below mapping wa
-00001070: 7320 666f 756e 6420 6279 0a23 2063 6f6e  s found by.# con
-00001080: 7665 7274 696e 6720 7465 7374 206d 6f64  verting test mod
-00001090: 656c 7320 7769 7468 2064 6966 6665 7265  els with differe
-000010a0: 6e74 2064 7479 7065 7320 7061 7373 6564  nt dtypes passed
-000010b0: 2074 6f20 6f6e 6573 2e0a 4e55 4d5f 544f   to ones..NUM_TO
-000010c0: 5f54 4f52 4348 5f44 5459 5045 203d 207b  _TORCH_DTYPE = {
-000010d0: 0a20 2020 2030 3a20 746f 7263 682e 7569  .    0: torch.ui
-000010e0: 6e74 382c 0a20 2020 2031 3a20 746f 7263  nt8,.    1: torc
-000010f0: 682e 696e 7438 2c0a 2020 2020 323a 2074  h.int8,.    2: t
-00001100: 6f72 6368 2e69 6e74 3136 2c0a 2020 2020  orch.int16,.    
-00001110: 333a 2074 6f72 6368 2e69 6e74 3332 2c0a  3: torch.int32,.
-00001120: 2020 2020 343a 2074 6f72 6368 2e69 6e74      4: torch.int
-00001130: 3332 2c0a 2020 2020 353a 2074 6f72 6368  32,.    5: torch
-00001140: 2e66 6c6f 6174 3136 2c0a 2020 2020 363a  .float16,.    6:
-00001150: 2074 6f72 6368 2e66 6c6f 6174 3332 2c0a   torch.float32,.
-00001160: 2020 2020 373a 2074 6f72 6368 2e66 6c6f      7: torch.flo
-00001170: 6174 3332 2c0a 2020 2020 3131 3a20 746f  at32,.    11: to
-00001180: 7263 682e 626f 6f6c 2c0a 2020 2020 3132  rch.bool,.    12
-00001190: 3a20 746f 7263 682e 7169 6e74 382c 0a20  : torch.qint8,. 
-000011a0: 2020 2031 333a 2074 6f72 6368 2e71 7569     13: torch.qui
-000011b0: 6e74 382c 0a7d 0a0a 4e55 4d50 595f 4454  nt8,.}..NUMPY_DT
-000011c0: 5950 455f 544f 5f54 4f52 4348 5f4e 554d  YPE_TO_TORCH_NUM
-000011d0: 203d 207b 0a20 2020 205f 6e70 2e75 696e   = {.    _np.uin
-000011e0: 7438 3a20 302c 0a20 2020 205f 6e70 2e69  t8: 0,.    _np.i
-000011f0: 6e74 383a 2031 2c0a 2020 2020 5f6e 702e  nt8: 1,.    _np.
-00001200: 696e 7431 363a 2032 2c0a 2020 2020 5f6e  int16: 2,.    _n
-00001210: 702e 696e 7433 323a 2033 2c0a 2020 2020  p.int32: 3,.    
-00001220: 5f6e 702e 696e 7436 343a 2034 2c0a 2020  _np.int64: 4,.  
-00001230: 2020 5f6e 702e 666c 6f61 7431 363a 2035    _np.float16: 5
-00001240: 2c0a 2020 2020 5f6e 702e 666c 6f61 7433  ,.    _np.float3
-00001250: 323a 2036 2c0a 2020 2020 5f6e 702e 666c  2: 6,.    _np.fl
-00001260: 6f61 7436 343a 2037 2c0a 2020 2020 626f  oat64: 7,.    bo
-00001270: 6f6c 3a20 3131 2c0a 7d0a 0a4e 554d 5f54  ol: 11,.}..NUM_T
-00001280: 4f5f 4e55 4d50 595f 4454 5950 4520 3d20  O_NUMPY_DTYPE = 
-00001290: 7b0a 2020 2020 303a 205f 6e70 2e75 696e  {.    0: _np.uin
-000012a0: 7438 2c0a 2020 2020 313a 205f 6e70 2e69  t8,.    1: _np.i
-000012b0: 6e74 382c 0a20 2020 2032 3a20 5f6e 702e  nt8,.    2: _np.
-000012c0: 696e 7431 362c 0a20 2020 2033 3a20 5f6e  int16,.    3: _n
-000012d0: 702e 696e 7433 322c 0a20 2020 2034 3a20  p.int32,.    4: 
-000012e0: 5f6e 702e 696e 7433 322c 0a20 2020 2035  _np.int32,.    5
-000012f0: 3a20 5f6e 702e 666c 6f61 7431 362c 0a20  : _np.float16,. 
-00001300: 2020 2036 3a20 5f6e 702e 666c 6f61 7433     6: _np.float3
-00001310: 322c 0a20 2020 2037 3a20 5f6e 702e 666c  2,.    7: _np.fl
-00001320: 6f61 7433 322c 0a20 2020 2031 313a 2062  oat32,.    11: b
-00001330: 6f6f 6c2c 0a7d 0a0a 4e55 4d5f 544f 5f44  ool,.}..NUM_TO_D
-00001340: 5459 5045 5f53 5452 494e 4720 3d20 7b0a  TYPE_STRING = {.
-00001350: 2020 2020 333a 2022 696e 7433 3222 2c0a      3: "int32",.
-00001360: 2020 2020 343a 2022 696e 7433 3222 2c0a      4: "int32",.
-00001370: 2020 2020 353a 2022 6670 3136 222c 0a20      5: "fp16",. 
-00001380: 2020 2036 3a20 2266 7033 3222 2c0a 2020     6: "fp32",.  
-00001390: 2020 373a 2022 6670 3332 222c 0a20 2020    7: "fp32",.   
-000013a0: 2031 313a 2022 626f 6f6c 222c 0a7d 0a0a   11: "bool",.}..
-000013b0: 5459 5045 5f54 4f5f 4454 5950 455f 5354  TYPE_TO_DTYPE_ST
-000013c0: 5249 4e47 203d 207b 0a20 2020 2074 7970  RING = {.    typ
-000013d0: 6573 2e62 6f6f 6c3a 2022 626f 6f6c 222c  es.bool: "bool",
-000013e0: 0a20 2020 2074 7970 6573 2e66 7031 363a  .    types.fp16:
-000013f0: 2022 6670 3136 222c 0a20 2020 2074 7970   "fp16",.    typ
-00001400: 6573 2e66 7033 323a 2022 6670 3332 222c  es.fp32: "fp32",
-00001410: 0a20 2020 2074 7970 6573 2e69 6e74 3332  .    types.int32
-00001420: 3a20 2269 6e74 3332 222c 0a7d 0a0a 0a64  : "int32",.}...d
-00001430: 6566 205f 6765 745f 696e 7075 7473 2863  ef _get_inputs(c
-00001440: 6f6e 7465 7874 2c20 6e6f 6465 2c20 6578  ontext, node, ex
-00001450: 7065 6374 6564 3d4e 6f6e 652c 206d 696e  pected=None, min
-00001460: 5f65 7870 6563 7465 643d 4e6f 6e65 2920  _expected=None) 
-00001470: 2d3e 204c 6973 745b 5661 725d 3a0a 2020  -> List[Var]:.  
-00001480: 2020 2222 220a 2020 2020 4c6f 6f6b 2075    """.    Look u
-00001490: 7020 6120 6e6f 6465 2773 2069 6e70 7574  p a node's input
-000014a0: 7320 696e 2040 636f 6e74 6578 7420 616e  s in @context an
-000014b0: 6420 7265 7475 726e 2074 6865 6d20 6173  d return them as
-000014c0: 2061 206c 6973 742e 2049 660a 2020 2020   a list. If.    
-000014d0: 4065 7870 6563 7465 6420 6973 206e 6f74  @expected is not
-000014e0: 204e 6f6e 652c 2061 6c73 6f20 7665 7269   None, also veri
-000014f0: 6669 6573 2074 6865 206e 756d 6265 7220  fies the number 
-00001500: 6f66 2069 6e70 7574 7320 6d61 7463 6865  of inputs matche
-00001510: 7320 7468 650a 2020 2020 7661 6c75 6520  s the.    value 
-00001520: 6f66 2040 6578 7065 6374 6564 2e0a 2020  of @expected..  
-00001530: 2020 2222 220a 2020 2020 696e 7075 7473    """.    inputs
-00001540: 203d 205b 636f 6e74 6578 745b 6e61 6d65   = [context[name
-00001550: 5d20 666f 7220 6e61 6d65 2069 6e20 6e6f  ] for name in no
-00001560: 6465 2e69 6e70 7574 735d 0a20 2020 2069  de.inputs].    i
-00001570: 6620 6578 7065 6374 6564 2069 7320 6e6f  f expected is no
-00001580: 7420 4e6f 6e65 3a0a 2020 2020 2020 2020  t None:.        
-00001590: 6578 7065 6374 6564 203d 205b 6578 7065  expected = [expe
-000015a0: 6374 6564 5d20 6966 206e 6f74 2069 7369  cted] if not isi
-000015b0: 6e73 7461 6e63 6528 6578 7065 6374 6564  nstance(expected
-000015c0: 2c20 286c 6973 742c 2074 7570 6c65 2929  , (list, tuple))
-000015d0: 2065 6c73 6520 6578 7065 6374 6564 0a0a   else expected..
-000015e0: 2020 2020 2020 2020 6966 206c 656e 2869          if len(i
-000015f0: 6e70 7574 7329 206e 6f74 2069 6e20 6578  nputs) not in ex
-00001600: 7065 6374 6564 3a0a 2020 2020 2020 2020  pected:.        
-00001610: 2020 2020 7261 6973 6520 5661 6c75 6545      raise ValueE
-00001620: 7272 6f72 280a 2020 2020 2020 2020 2020  rror(.          
-00001630: 2020 2020 2020 226e 6f64 6520 7b7d 2028        "node {} (
-00001640: 7b7d 2920 676f 7420 7b7d 2069 6e70 7574  {}) got {} input
-00001650: 2873 292c 2065 7870 6563 7465 6420 7b7d  (s), expected {}
-00001660: 222e 666f 726d 6174 280a 2020 2020 2020  ".format(.      
-00001670: 2020 2020 2020 2020 2020 2020 2020 6e6f                no
-00001680: 6465 2e6e 616d 652c 206e 6f64 652e 6b69  de.name, node.ki
-00001690: 6e64 2c20 6c65 6e28 696e 7075 7473 292c  nd, len(inputs),
-000016a0: 2065 7870 6563 7465 640a 2020 2020 2020   expected.      
-000016b0: 2020 2020 2020 2020 2020 290a 2020 2020            ).    
-000016c0: 2020 2020 2020 2020 290a 2020 2020 6966          ).    if
-000016d0: 206d 696e 5f65 7870 6563 7465 6420 6973   min_expected is
-000016e0: 206e 6f74 204e 6f6e 653a 0a20 2020 2020   not None:.     
-000016f0: 2020 2069 6620 6c65 6e28 696e 7075 7473     if len(inputs
-00001700: 2920 3c20 6d69 6e5f 6578 7065 6374 6564  ) < min_expected
-00001710: 3a0a 2020 2020 2020 2020 2020 2020 7261  :.            ra
-00001720: 6973 6520 5661 6c75 6545 7272 6f72 280a  ise ValueError(.
-00001730: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001740: 226e 6f64 6520 7b7d 2028 7b7d 2920 676f  "node {} ({}) go
-00001750: 7420 7b7d 2069 6e70 7574 2873 292c 2065  t {} input(s), e
-00001760: 7870 6563 7465 6420 6d69 6e69 6d75 6d20  xpected minimum 
-00001770: 7b7d 2069 6e70 7574 7322 2e66 6f72 6d61  {} inputs".forma
-00001780: 7428 0a20 2020 2020 2020 2020 2020 2020  t(.             
-00001790: 2020 2020 2020 206e 6f64 652e 6e61 6d65         node.name
-000017a0: 2c20 6e6f 6465 2e6b 696e 642c 206c 656e  , node.kind, len
-000017b0: 2869 6e70 7574 7329 2c20 6d69 6e5f 6578  (inputs), min_ex
-000017c0: 7065 6374 6564 0a20 2020 2020 2020 2020  pected.         
-000017d0: 2020 2020 2020 2029 0a20 2020 2020 2020         ).       
-000017e0: 2020 2020 2029 0a0a 2020 2020 7265 7475       )..    retu
-000017f0: 726e 2069 6e70 7574 730a 0a0a 6465 6620  rn inputs...def 
-00001800: 5f6c 6973 745f 7365 6c65 6374 2873 6861  _list_select(sha
-00001810: 7065 5f76 6172 2c20 696e 6465 7829 3a0a  pe_var, index):.
-00001820: 2020 2020 2222 220a 2020 2020 536f 6d65      """.    Some
-00001830: 7469 6d65 7320 7765 206e 6565 6420 746f  times we need to
-00001840: 2073 656c 6563 7420 6120 7370 6563 6966   select a specif
-00001850: 6963 2069 7465 6d20 6672 6f6d 2061 206c  ic item from a l
-00001860: 6973 742e 2049 6620 7468 6174 2069 7465  ist. If that ite
-00001870: 6d0a 2020 2020 6973 206b 6e6f 776e 2061  m.    is known a
-00001880: 7420 636f 6d70 696c 6520 7469 6d65 2c20  t compile time, 
-00001890: 6578 7472 6163 7420 6974 2061 7320 6120  extract it as a 
-000018a0: 636f 6e73 742e 204f 7468 6572 7769 7365  const. Otherwise
-000018b0: 2c20 6966 2069 7427 730a 2020 2020 7379  , if it's.    sy
-000018c0: 6d62 6f6c 6963 2c20 7573 6520 6761 7468  mbolic, use gath
-000018d0: 6572 2e0a 2020 2020 2222 220a 2020 2020  er..    """.    
-000018e0: 6966 2073 6861 7065 5f76 6172 2e63 616e  if shape_var.can
-000018f0: 5f62 655f 666f 6c64 6564 5f74 6f5f 636f  _be_folded_to_co
-00001900: 6e73 7428 293a 0a20 2020 2020 2020 2072  nst():.        r
-00001910: 6573 203d 206d 622e 636f 6e73 7428 7661  es = mb.const(va
-00001920: 6c3d 7368 6170 655f 7661 722e 7661 6c5b  l=shape_var.val[
-00001930: 696e 6465 785d 290a 2020 2020 656c 7365  index]).    else
-00001940: 3a0a 2020 2020 2020 2020 7265 7320 3d20  :.        res = 
-00001950: 6d62 2e67 6174 6865 7228 783d 7368 6170  mb.gather(x=shap
-00001960: 655f 7661 722c 2069 6e64 6963 6573 3d69  e_var, indices=i
-00001970: 6e64 6578 290a 2020 2020 7265 7475 726e  ndex).    return
-00001980: 2072 6573 0a0a 0a64 6566 205f 636f 6e73   res...def _cons
-00001990: 7472 7563 745f 636f 6e73 7461 6e74 2876  truct_constant(v
-000019a0: 616c 2c20 6e61 6d65 293a 0a20 2020 2023  al, name):.    #
-000019b0: 2043 6f6e 7665 7274 6572 2063 616e 6e6f   Converter canno
-000019c0: 7420 6861 6e64 6c65 2074 6f72 6368 2074  t handle torch t
-000019d0: 656e 736f 7273 2e0a 2020 2020 6966 2069  ensors..    if i
-000019e0: 7369 6e73 7461 6e63 6528 7661 6c2c 2074  sinstance(val, t
-000019f0: 6f72 6368 2e54 656e 736f 7229 3a0a 2020  orch.Tensor):.  
-00001a00: 2020 2020 2020 7661 6c20 3d20 7661 6c2e        val = val.
-00001a10: 6370 7528 292e 6e75 6d70 7928 290a 0a20  cpu().numpy().. 
-00001a20: 2020 2023 204d 494c 2063 6173 7473 2069     # MIL casts i
-00001a30: 6e74 7320 746f 2069 6e74 3332 2c20 7768  nts to int32, wh
-00001a40: 6963 6820 6361 6e27 7420 7265 7072 6573  ich can't repres
-00001a50: 656e 7420 5079 546f 7263 6827 7320 6465  ent PyTorch's de
-00001a60: 6661 756c 7420 7661 6c75 652e 0a20 2020  fault value..   
-00001a70: 2023 2053 6f20 7765 2069 6e73 7465 6164   # So we instead
-00001a80: 2072 6570 7265 7365 6e74 2069 7420 7769   represent it wi
-00001a90: 7468 204e 6f6e 652c 2061 6e64 2061 6e79  th None, and any
-00001aa0: 206f 7073 2074 6861 7420 6d69 6768 7420   ops that might 
-00001ab0: 6765 7420 7468 650a 2020 2020 2320 7661  get the.    # va
-00001ac0: 6c75 6520 7769 6c6c 2063 6865 636b 2066  lue will check f
-00001ad0: 6f72 204e 6f6e 6520 696e 7374 6561 642e  or None instead.
-00001ae0: 0a20 2020 2069 6620 6973 696e 7374 616e  .    if isinstan
-00001af0: 6365 2876 616c 2c20 696e 7429 2061 6e64  ce(val, int) and
-00001b00: 2076 616c 203d 3d20 5059 544f 5243 485f   val == PYTORCH_
-00001b10: 4445 4641 554c 545f 5641 4c55 453a 0a20  DEFAULT_VALUE:. 
-00001b20: 2020 2020 2020 2076 616c 203d 204e 6f6e         val = Non
-00001b30: 650a 0a20 2020 2023 2050 7974 6f72 6368  e..    # Pytorch
-00001b40: 2075 7365 7320 696e 660a 2020 2020 6966   uses inf.    if
-00001b50: 2076 616c 2069 7320 6e6f 7420 4e6f 6e65   val is not None
-00001b60: 2061 6e64 2069 7369 6e73 7461 6e63 6528   and isinstance(
-00001b70: 7661 6c2c 206e 756d 6265 7273 2e4e 756d  val, numbers.Num
-00001b80: 6265 7229 2061 6e64 205f 6e70 2e69 7369  ber) and _np.isi
-00001b90: 6e66 2876 616c 293a 0a20 2020 2020 2020  nf(val):.       
-00001ba0: 2069 6620 7661 6c20 3c20 303a 2020 2320   if val < 0:  # 
-00001bb0: 6e65 6720 696e 660a 2020 2020 2020 2020  neg inf.        
-00001bc0: 2020 2020 2320 6d6f 7374 206e 6567 6174      # most negat
-00001bd0: 6976 6520 6e75 6d62 6572 2069 6e20 6670  ive number in fp
-00001be0: 3332 0a20 2020 2020 2020 2020 2020 2076  32.            v
-00001bf0: 616c 203d 202d 332e 3465 2b33 380a 2020  al = -3.4e+38.  
-00001c00: 2020 2020 2020 656c 7365 3a20 2023 2070        else:  # p
-00001c10: 6f73 6974 6976 6520 696e 660a 2020 2020  ositive inf.    
-00001c20: 2020 2020 2020 2020 7661 6c20 3d20 332e          val = 3.
-00001c30: 3465 2b33 380a 2020 2020 6966 2076 616c  4e+38.    if val
-00001c40: 2069 7320 4e6f 6e65 3a0a 2020 2020 2020   is None:.      
-00001c50: 2020 7265 7475 726e 204e 6f6e 650a 2020    return None.  
-00001c60: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
-00001c70: 7265 7475 726e 206d 622e 636f 6e73 7428  return mb.const(
-00001c80: 7661 6c3d 7661 6c2c 206e 616d 653d 6e61  val=val, name=na
-00001c90: 6d65 290a 0a0a 4072 6567 6973 7465 725f  me)...@register_
-00001ca0: 746f 7263 685f 6f70 0a64 6566 2061 6666  torch_op.def aff
-00001cb0: 696e 655f 6772 6964 5f67 656e 6572 6174  ine_grid_generat
-00001cc0: 6f72 2863 6f6e 7465 7874 2c20 6e6f 6465  or(context, node
-00001cd0: 293a 0a20 2020 2023 2072 6461 723a 2f2f  ):.    # rdar://
-00001ce0: 3733 3136 3533 3836 2028 496d 7072 6f76  73165386 (Improv
-00001cf0: 6520 6572 726f 7220 6861 6e64 6c69 6e67  e error handling
-00001d00: 206f 6620 636f 7265 6d6c 746f 6f6c 7320   of coremltools 
-00001d10: 2261 6666 696e 6522 206f 7020 5079 546f  "affine" op PyTo
-00001d20: 7263 6820 636f 6e76 6572 7369 6f6e 2e29  rch conversion.)
-00001d30: 0a0a 2020 2020 6166 6669 6e65 5f6f 705f  ..    affine_op_
-00001d40: 6e61 6d65 203d 206e 6f64 652e 6e61 6d65  name = node.name
-00001d50: 0a20 2020 2074 6865 7461 2c20 7369 7a65  .    theta, size
-00001d60: 2c20 616c 6967 6e5f 636f 726e 6572 7320  , align_corners 
-00001d70: 3d20 5f67 6574 5f69 6e70 7574 7328 636f  = _get_inputs(co
-00001d80: 6e74 6578 742c 206e 6f64 652c 2065 7870  ntext, node, exp
-00001d90: 6563 7465 643d 3329 0a0a 2020 2020 2320  ected=3)..    # 
-00001da0: 6e6f 7465 3a20 6f6e 6c79 2061 6464 2063  note: only add c
-00001db0: 6f6e 7374 7320 6865 7265 2061 7320 5079  onsts here as Py
-00001dc0: 546f 7263 6820 7573 6573 2061 6666 696e  Torch uses affin
-00001dd0: 655f 6772 6964 202b 2067 7269 645f 7361  e_grid + grid_sa
-00001de0: 6d70 6c65 7220 746f 6765 7468 6572 0a20  mpler together. 
-00001df0: 2020 2069 735f 7468 6574 615f 636f 6e73     is_theta_cons
-00001e00: 7420 3d20 7468 6574 612e 7661 6c20 6973  t = theta.val is
-00001e10: 206e 6f74 204e 6f6e 650a 2020 2020 6966   not None.    if
-00001e20: 2069 735f 7468 6574 615f 636f 6e73 743a   is_theta_const:
-00001e30: 0a20 2020 2020 2020 2063 6f6e 7465 7874  .        context
-00001e40: 2e61 6464 286d 622e 636f 6e73 7428 7661  .add(mb.const(va
-00001e50: 6c3d 7468 6574 612e 7661 6c2c 206e 616d  l=theta.val, nam
-00001e60: 653d 227b 7d5f 7468 6574 6122 2e66 6f72  e="{}_theta".for
-00001e70: 6d61 7428 6166 6669 6e65 5f6f 705f 6e61  mat(affine_op_na
-00001e80: 6d65 2929 290a 2020 2020 656c 7365 3a20  me))).    else: 
-00001e90: 2023 2074 6865 7461 2069 7320 6479 6e61   # theta is dyna
-00001ea0: 6d69 6320 696e 7075 742c 206b 6565 7020  mic input, keep 
-00001eb0: 7472 6163 6b20 6f66 2069 7427 7320 6e61  track of it's na
-00001ec0: 6d65 0a20 2020 2020 2020 2063 6f6e 7465  me.        conte
-00001ed0: 7874 2e61 6464 286d 622e 636f 6e73 7428  xt.add(mb.const(
-00001ee0: 7661 6c3d 7468 6574 612e 6e61 6d65 2c20  val=theta.name, 
-00001ef0: 6e61 6d65 3d22 7b7d 5f74 6865 7461 222e  name="{}_theta".
-00001f00: 666f 726d 6174 2861 6666 696e 655f 6f70  format(affine_op
-00001f10: 5f6e 616d 6529 2929 0a0a 2020 2020 636f  _name)))..    co
-00001f20: 6e74 6578 742e 6164 6428 6d62 2e63 6f6e  ntext.add(mb.con
-00001f30: 7374 2876 616c 3d73 697a 652e 7661 6c2c  st(val=size.val,
-00001f40: 206e 616d 653d 227b 7d5f 7369 7a65 222e   name="{}_size".
-00001f50: 666f 726d 6174 2861 6666 696e 655f 6f70  format(affine_op
-00001f60: 5f6e 616d 6529 2929 0a20 2020 2063 6f6e  _name))).    con
-00001f70: 7465 7874 2e61 6464 286d 622e 636f 6e73  text.add(mb.cons
-00001f80: 7428 7661 6c3d 616c 6967 6e5f 636f 726e  t(val=align_corn
-00001f90: 6572 732e 7661 6c2c 206e 616d 653d 227b  ers.val, name="{
-00001fa0: 7d5f 616c 6967 6e5f 636f 726e 6572 7322  }_align_corners"
-00001fb0: 2e66 6f72 6d61 7428 6166 6669 6e65 5f6f  .format(affine_o
-00001fc0: 705f 6e61 6d65 2929 290a 0a0a 4072 6567  p_name)))...@reg
-00001fd0: 6973 7465 725f 746f 7263 685f 6f70 0a64  ister_torch_op.d
-00001fe0: 6566 2067 7269 645f 7361 6d70 6c65 7228  ef grid_sampler(
-00001ff0: 636f 6e74 6578 742c 206e 6f64 6529 3a0a  context, node):.
-00002000: 2020 2020 6166 6669 6e65 5f6f 705f 6e61      affine_op_na
-00002010: 6d65 203d 206e 6f64 652e 696e 7075 7473  me = node.inputs
-00002020: 5b31 5d0a 2020 2020 2320 6874 7470 733a  [1].    # https:
-00002030: 2f2f 6769 7468 7562 2e63 6f6d 2f70 7974  //github.com/pyt
-00002040: 6f72 6368 2f70 7974 6f72 6368 2f62 6c6f  orch/pytorch/blo
-00002050: 622f 3030 6434 3332 6131 6564 3137 3965  b/00d432a1ed179e
-00002060: 6666 3532 6139 6438 3661 3036 3330 6636  ff52a9d86a0630f6
-00002070: 3233 6266 3230 6133 3761 2f61 7465 6e2f  23bf20a37a/aten/
-00002080: 7372 632f 4154 656e 2f6e 6174 6976 652f  src/ATen/native/
-00002090: 4772 6964 5361 6d70 6c65 722e 6823 4c31  GridSampler.h#L1
-000020a0: 302d 4c31 310a 2020 2020 6d5f 6d6f 6465  0-L11.    m_mode
-000020b0: 203d 207b 303a 2022 6269 6c69 6e65 6172   = {0: "bilinear
-000020c0: 222c 2031 3a20 226e 6561 7265 7374 227d  ", 1: "nearest"}
-000020d0: 0a20 2020 206d 5f70 6164 6469 6e67 5f6d  .    m_padding_m
-000020e0: 6f64 6520 3d20 7b30 3a20 2263 6f6e 7374  ode = {0: "const
-000020f0: 616e 7422 2c20 313a 2022 626f 7264 6572  ant", 1: "border
-00002100: 222c 2032 3a20 2272 6566 6c65 6374 696f  ", 2: "reflectio
-00002110: 6e22 7d0a 0a20 2020 2023 2061 6464 2060  n"}..    # add `
-00002120: 7265 7361 6d70 6c65 6020 6966 2067 7269  resample` if gri
-00002130: 642f 636f 6f72 6469 6e61 7465 7320 6973  d/coordinates is
-00002140: 2069 6e20 696e 7075 742c 206f 7468 6572   in input, other
-00002150: 7769 7365 2c0a 2020 2020 2320 6164 6420  wise,.    # add 
-00002160: 6061 6666 696e 6560 2074 6f20 6765 6e65  `affine` to gene
-00002170: 7261 7465 2067 7269 6420 6672 6f6d 2060  rate grid from `
-00002180: 6166 6669 6e65 5f67 7269 645f 6765 6e65  affine_grid_gene
-00002190: 7261 746f 7260 2e0a 2020 2020 6966 2061  rator`..    if a
-000021a0: 6666 696e 655f 6f70 5f6e 616d 6520 696e  ffine_op_name in
-000021b0: 2063 6f6e 7465 7874 3a20 2023 2061 6464   context:  # add
-000021c0: 2060 7265 7361 6d70 6c65 6020 6f70 0a20   `resample` op. 
-000021d0: 2020 2020 2020 2069 6e70 7574 7320 3d20         inputs = 
-000021e0: 5f67 6574 5f69 6e70 7574 7328 636f 6e74  _get_inputs(cont
-000021f0: 6578 742c 206e 6f64 652c 2065 7870 6563  ext, node, expec
-00002200: 7465 643d 3529 0a20 2020 2020 2020 2073  ted=5).        s
-00002210: 616d 706c 696e 675f 6d6f 6465 203d 206d  ampling_mode = m
-00002220: 5f6d 6f64 655b 696e 7075 7473 5b32 5d2e  _mode[inputs[2].
-00002230: 7661 6c5d 0a20 2020 2020 2020 2070 6164  val].        pad
-00002240: 6469 6e67 5f6d 6f64 6520 3d20 6d5f 7061  ding_mode = m_pa
-00002250: 6464 696e 675f 6d6f 6465 5b69 6e70 7574  dding_mode[input
-00002260: 735b 335d 2e76 616c 5d0a 2020 2020 2020  s[3].val].      
-00002270: 2020 616c 6967 6e5f 636f 726e 6572 7320    align_corners 
-00002280: 3d20 696e 7075 7473 5b34 5d2e 7661 6c0a  = inputs[4].val.
-00002290: 0a20 2020 2020 2020 2023 2057 6865 6e20  .        # When 
-000022a0: 616c 6967 6e5f 636f 726e 6572 733d 4661  align_corners=Fa
-000022b0: 6c73 652c 2070 6164 6469 6e67 5f6d 6f64  lse, padding_mod
-000022c0: 6520 6973 2063 6f72 7265 7370 6f6e 6469  e is correspondi
-000022d0: 6e67 2074 6f20 436f 7265 204d 4c27 7320  ng to Core ML's 
-000022e0: 7379 6d6d 6574 7269 630a 2020 2020 2020  symmetric.      
-000022f0: 2020 6966 2070 6164 6469 6e67 5f6d 6f64    if padding_mod
-00002300: 6520 3d3d 2022 7265 666c 6563 7469 6f6e  e == "reflection
-00002310: 2220 616e 6420 616c 6967 6e5f 636f 726e  " and align_corn
-00002320: 6572 7320 6973 2046 616c 7365 3a0a 2020  ers is False:.  
-00002330: 2020 2020 2020 2020 2020 7061 6464 696e            paddin
-00002340: 675f 6d6f 6465 203d 2022 7379 6d6d 6574  g_mode = "symmet
-00002350: 7269 6322 0a0a 2020 2020 2020 2020 7820  ric"..        x 
-00002360: 3d20 6d62 2e72 6573 616d 706c 6528 0a20  = mb.resample(. 
-00002370: 2020 2020 2020 2020 2020 2078 3d69 6e70             x=inp
-00002380: 7574 735b 305d 2c0a 2020 2020 2020 2020  uts[0],.        
-00002390: 2020 2020 636f 6f72 6469 6e61 7465 733d      coordinates=
-000023a0: 696e 7075 7473 5b31 5d2c 0a20 2020 2020  inputs[1],.     
-000023b0: 2020 2020 2020 2073 616d 706c 696e 675f         sampling_
-000023c0: 6d6f 6465 3d73 616d 706c 696e 675f 6d6f  mode=sampling_mo
-000023d0: 6465 2c0a 2020 2020 2020 2020 2020 2020  de,.            
-000023e0: 7061 6464 696e 675f 6d6f 6465 3d70 6164  padding_mode=pad
-000023f0: 6469 6e67 5f6d 6f64 652c 0a20 2020 2020  ding_mode,.     
-00002400: 2020 2020 2020 2070 6164 6469 6e67 5f76         padding_v
-00002410: 616c 7565 3d30 2e30 2c0a 2020 2020 2020  alue=0.0,.      
-00002420: 2020 2020 2020 636f 6f72 6469 6e61 7465        coordinate
-00002430: 735f 6d6f 6465 3d22 6e6f 726d 616c 697a  s_mode="normaliz
-00002440: 6564 5f6d 696e 7573 5f6f 6e65 5f74 6f5f  ed_minus_one_to_
-00002450: 6f6e 6522 2c0a 2020 2020 2020 2020 2020  one",.          
-00002460: 2020 616c 6967 6e5f 636f 726e 6572 733d    align_corners=
-00002470: 616c 6967 6e5f 636f 726e 6572 732c 0a20  align_corners,. 
-00002480: 2020 2020 2020 2020 2020 206e 616d 653d             name=
-00002490: 6e6f 6465 2e6e 616d 652c 0a20 2020 2020  node.name,.     
-000024a0: 2020 2029 0a20 2020 2020 2020 2063 6f6e     ).        con
-000024b0: 7465 7874 2e61 6464 2878 290a 2020 2020  text.add(x).    
-000024c0: 656c 7365 3a20 2023 2061 6464 2060 6166  else:  # add `af
-000024d0: 6669 6e65 6020 6f70 2069 6e73 7465 6164  fine` op instead
-000024e0: 0a20 2020 2020 2020 2078 203d 2063 6f6e  .        x = con
-000024f0: 7465 7874 5b6e 6f64 652e 696e 7075 7473  text[node.inputs
-00002500: 5b30 5d5d 0a20 2020 2020 2020 2023 2069  [0]].        # i
-00002510: 6e70 7574 7320 6672 6f6d 2060 6166 6669  nputs from `affi
-00002520: 6e65 5f67 7269 645f 6765 6e65 7261 746f  ne_grid_generato
-00002530: 7260 0a20 2020 2020 2020 2061 6666 696e  r`.        affin
-00002540: 655f 7468 6574 6120 3d20 636f 6e74 6578  e_theta = contex
-00002550: 745b 227b 7d5f 7468 6574 6122 2e66 6f72  t["{}_theta".for
-00002560: 6d61 7428 6166 6669 6e65 5f6f 705f 6e61  mat(affine_op_na
-00002570: 6d65 295d 0a20 2020 2020 2020 2061 6666  me)].        aff
-00002580: 696e 655f 7369 7a65 203d 2063 6f6e 7465  ine_size = conte
-00002590: 7874 5b22 7b7d 5f73 697a 6522 2e66 6f72  xt["{}_size".for
-000025a0: 6d61 7428 6166 6669 6e65 5f6f 705f 6e61  mat(affine_op_na
-000025b0: 6d65 295d 0a20 2020 2020 2020 2061 6666  me)].        aff
-000025c0: 696e 655f 616c 6967 6e5f 636f 726e 6572  ine_align_corner
-000025d0: 7320 3d20 636f 6e74 6578 745b 227b 7d5f  s = context["{}_
-000025e0: 616c 6967 6e5f 636f 726e 6572 7322 2e66  align_corners".f
-000025f0: 6f72 6d61 7428 6166 6669 6e65 5f6f 705f  ormat(affine_op_
-00002600: 6e61 6d65 295d 0a0a 2020 2020 2020 2020  name)]..        
-00002610: 2320 6166 6669 6e65 5f74 6865 7461 2e76  # affine_theta.v
-00002620: 616c 2069 7320 6569 7468 6572 206e 616d  al is either nam
-00002630: 6520 7374 7269 6e67 2028 6479 6e61 6d69  e string (dynami
-00002640: 6320 696e 7075 7429 206f 7220 6e70 2e6e  c input) or np.n
-00002650: 6461 7272 6179 2028 7374 6174 6963 2076  darray (static v
-00002660: 616c 7565 7329 0a20 2020 2020 2020 2023  alues).        #
-00002670: 2073 6565 2060 6166 6669 6e65 5f67 7269   see `affine_gri
-00002680: 645f 6765 6e65 7261 746f 7260 2066 6f72  d_generator` for
-00002690: 2064 6574 6169 6c73 2e0a 2020 2020 2020   details..      
-000026a0: 2020 6973 5f74 6865 7461 5f63 6f6e 7374    is_theta_const
-000026b0: 203d 206e 6f74 2069 7369 6e73 7461 6e63   = not isinstanc
-000026c0: 6528 6166 6669 6e65 5f74 6865 7461 2e76  e(affine_theta.v
-000026d0: 616c 2c20 7374 7229 0a20 2020 2020 2020  al, str).       
-000026e0: 2069 6620 6973 5f74 6865 7461 5f63 6f6e   if is_theta_con
-000026f0: 7374 3a0a 2020 2020 2020 2020 2020 2020  st:.            
-00002700: 7472 616e 7366 6f72 6d5f 6d61 7472 6978  transform_matrix
-00002710: 203d 205f 6e70 2e72 6573 6861 7065 2861   = _np.reshape(a
-00002720: 6666 696e 655f 7468 6574 612e 7661 6c2c  ffine_theta.val,
-00002730: 2028 6166 6669 6e65 5f74 6865 7461 2e73   (affine_theta.s
-00002740: 6861 7065 5b30 5d2c 2036 2929 0a20 2020  hape[0], 6)).   
-00002750: 2020 2020 2065 6c73 653a 2020 2320 7468       else:  # th
-00002760: 6574 6120 6973 2064 796e 616d 6963 2069  eta is dynamic i
-00002770: 6e70 7574 2c20 6164 6420 6072 6573 6861  nput, add `resha
-00002780: 7065 6020 6f70 2074 6f20 5079 4d49 4c0a  pe` op to PyMIL.
-00002790: 2020 2020 2020 2020 2020 2020 7472 616e              tran
-000027a0: 7366 6f72 6d5f 6d61 7472 6978 203d 206d  sform_matrix = m
-000027b0: 622e 7265 7368 6170 6528 0a20 2020 2020  b.reshape(.     
-000027c0: 2020 2020 2020 2020 2020 2078 3d63 6f6e             x=con
-000027d0: 7465 7874 5b61 6666 696e 655f 7468 6574  text[affine_thet
-000027e0: 612e 7661 6c5d 2c0a 2020 2020 2020 2020  a.val],.        
-000027f0: 2020 2020 2020 2020 7368 6170 653d 282d          shape=(-
-00002800: 312c 2036 292c 0a20 2020 2020 2020 2020  1, 6),.         
-00002810: 2020 2020 2020 206e 616d 653d 6e6f 6465         name=node
-00002820: 2e6e 616d 6520 2b20 225f 7468 6574 615f  .name + "_theta_
-00002830: 7265 7368 6170 6522 2c0a 2020 2020 2020  reshape",.      
-00002840: 2020 2020 2020 290a 0a20 2020 2020 2020        )..       
-00002850: 2023 2069 6e70 7574 7320 6672 6f6d 2060   # inputs from `
-00002860: 6772 6964 5f73 616d 706c 6572 600a 2020  grid_sampler`.  
-00002870: 2020 2020 2020 7361 6d70 6c69 6e67 5f6d        sampling_m
-00002880: 6f64 6520 3d20 6d5f 6d6f 6465 5b63 6f6e  ode = m_mode[con
-00002890: 7465 7874 5b6e 6f64 652e 696e 7075 7473  text[node.inputs
-000028a0: 5b32 5d5d 2e76 616c 5d0a 2020 2020 2020  [2]].val].      
-000028b0: 2020 7061 6464 696e 675f 6d6f 6465 203d    padding_mode =
-000028c0: 206d 5f70 6164 6469 6e67 5f6d 6f64 655b   m_padding_mode[
-000028d0: 636f 6e74 6578 745b 6e6f 6465 2e69 6e70  context[node.inp
-000028e0: 7574 735b 335d 5d2e 7661 6c5d 0a20 2020  uts[3]].val].   
-000028f0: 2020 2020 2061 6c69 676e 5f63 6f72 6e65       align_corne
-00002900: 7273 203d 2063 6f6e 7465 7874 5b6e 6f64  rs = context[nod
-00002910: 652e 696e 7075 7473 5b34 5d5d 2e76 616c  e.inputs[4]].val
-00002920: 0a0a 2020 2020 2020 2020 6966 2073 616d  ..        if sam
-00002930: 706c 696e 675f 6d6f 6465 2021 3d20 2262  pling_mode != "b
-00002940: 696c 696e 6561 7222 3a0a 2020 2020 2020  ilinear":.      
-00002950: 2020 2020 2020 7261 6973 6520 4e6f 7449        raise NotI
-00002960: 6d70 6c65 6d65 6e74 6564 4572 726f 7228  mplementedError(
-00002970: 2227 7361 6d70 6c69 6e67 5f6d 6f64 6527  "'sampling_mode'
-00002980: 206e 6f74 2073 7570 706f 7274 6564 2e22   not supported."
-00002990: 290a 0a20 2020 2020 2020 2069 6620 7061  )..        if pa
-000029a0: 6464 696e 675f 6d6f 6465 2021 3d20 2263  dding_mode != "c
-000029b0: 6f6e 7374 616e 7422 3a0a 2020 2020 2020  onstant":.      
-000029c0: 2020 2020 2020 7261 6973 6520 4e6f 7449        raise NotI
-000029d0: 6d70 6c65 6d65 6e74 6564 4572 726f 7228  mplementedError(
-000029e0: 2227 7061 6464 696e 675f 6d6f 6465 2720  "'padding_mode' 
-000029f0: 6e6f 7420 7375 7070 6f72 7465 642e 2229  not supported.")
-00002a00: 0a0a 2020 2020 2020 2020 6966 2061 6666  ..        if aff
-00002a10: 696e 655f 616c 6967 6e5f 636f 726e 6572  ine_align_corner
-00002a20: 732e 7661 6c20 213d 2061 6c69 676e 5f63  s.val != align_c
-00002a30: 6f72 6e65 7273 3a0a 2020 2020 2020 2020  orners:.        
-00002a40: 2020 2020 7261 6973 6520 5661 6c75 6545      raise ValueE
-00002a50: 7272 6f72 280a 2020 2020 2020 2020 2020  rror(.          
-00002a60: 2020 2020 2020 224f 7020 2761 6666 696e        "Op 'affin
-00002a70: 655f 6772 6964 5f67 656e 6572 6174 6f72  e_grid_generator
-00002a80: 2720 616e 6420 2767 7269 645f 7361 6d70  ' and 'grid_samp
-00002a90: 6c65 7227 206d 7573 7420 6167 7265 6520  ler' must agree 
-00002aa0: 6f6e 2027 616c 6967 6e5f 636f 726e 6572  on 'align_corner
-00002ab0: 7327 2e22 0a20 2020 2020 2020 2020 2020  s'.".           
-00002ac0: 2029 0a0a 2020 2020 2020 2020 7820 3d20   )..        x = 
-00002ad0: 6d62 2e61 6666 696e 6528 0a20 2020 2020  mb.affine(.     
-00002ae0: 2020 2020 2020 2078 3d78 2c0a 2020 2020         x=x,.    
-00002af0: 2020 2020 2020 2020 7472 616e 7366 6f72          transfor
-00002b00: 6d5f 6d61 7472 6978 3d74 7261 6e73 666f  m_matrix=transfo
-00002b10: 726d 5f6d 6174 7269 782c 0a20 2020 2020  rm_matrix,.     
-00002b20: 2020 2020 2020 206f 7574 7075 745f 6865         output_he
-00002b30: 6967 6874 3d61 6666 696e 655f 7369 7a65  ight=affine_size
-00002b40: 2e76 616c 5b32 5d2c 0a20 2020 2020 2020  .val[2],.       
-00002b50: 2020 2020 206f 7574 7075 745f 7769 6474       output_widt
-00002b60: 683d 6166 6669 6e65 5f73 697a 652e 7661  h=affine_size.va
-00002b70: 6c5b 335d 2c0a 2020 2020 2020 2020 2020  l[3],.          
-00002b80: 2020 7361 6d70 6c69 6e67 5f6d 6f64 653d    sampling_mode=
-00002b90: 7361 6d70 6c69 6e67 5f6d 6f64 652c 0a20  sampling_mode,. 
-00002ba0: 2020 2020 2020 2020 2020 2070 6164 6469             paddi
-00002bb0: 6e67 5f6d 6f64 653d 7061 6464 696e 675f  ng_mode=padding_
-00002bc0: 6d6f 6465 2c0a 2020 2020 2020 2020 2020  mode,.          
-00002bd0: 2020 7061 6464 696e 675f 7661 6c75 653d    padding_value=
-00002be0: 302e 302c 0a20 2020 2020 2020 2020 2020  0.0,.           
-00002bf0: 2063 6f6f 7264 696e 6174 6573 5f6d 6f64   coordinates_mod
-00002c00: 653d 226e 6f72 6d61 6c69 7a65 645f 6d69  e="normalized_mi
-00002c10: 6e75 735f 6f6e 655f 746f 5f6f 6e65 222c  nus_one_to_one",
-00002c20: 0a20 2020 2020 2020 2020 2020 2061 6c69  .            ali
-00002c30: 676e 5f63 6f72 6e65 7273 3d61 6c69 676e  gn_corners=align
-00002c40: 5f63 6f72 6e65 7273 2c0a 2020 2020 2020  _corners,.      
-00002c50: 2020 2020 2020 6e61 6d65 3d6e 6f64 652e        name=node.
-00002c60: 6e61 6d65 2c0a 2020 2020 2020 2020 290a  name,.        ).
-00002c70: 2020 2020 2020 2020 636f 6e74 6578 742e          context.
-00002c80: 6164 6428 7829 0a0a 0a40 7265 6769 7374  add(x)...@regist
-00002c90: 6572 5f74 6f72 6368 5f6f 700a 6465 6620  er_torch_op.def 
-00002ca0: 7369 6c75 2863 6f6e 7465 7874 2c20 6e6f  silu(context, no
-00002cb0: 6465 293a 0a20 2020 2069 6e70 7574 7320  de):.    inputs 
-00002cc0: 3d20 5f67 6574 5f69 6e70 7574 7328 636f  = _get_inputs(co
-00002cd0: 6e74 6578 742c 206e 6f64 652c 2065 7870  ntext, node, exp
-00002ce0: 6563 7465 643d 3129 0a20 2020 2078 203d  ected=1).    x =
-00002cf0: 206d 622e 7369 6c75 2878 3d69 6e70 7574   mb.silu(x=input
-00002d00: 735b 305d 2c20 6e61 6d65 3d6e 6f64 652e  s[0], name=node.
-00002d10: 6e61 6d65 290a 2020 2020 636f 6e74 6578  name).    contex
-00002d20: 742e 6164 6428 7829 0a0a 0a40 7265 6769  t.add(x)...@regi
-00002d30: 7374 6572 5f74 6f72 6368 5f6f 700a 6465  ster_torch_op.de
-00002d40: 6620 636f 6e73 7461 6e74 2863 6f6e 7465  f constant(conte
-00002d50: 7874 2c20 6e6f 6465 293a 0a20 2020 2061  xt, node):.    a
-00002d60: 7373 6572 7420 6c65 6e28 6e6f 6465 2e69  ssert len(node.i
-00002d70: 6e70 7574 7329 203d 3d20 300a 2020 2020  nputs) == 0.    
-00002d80: 6173 7365 7274 206c 656e 286e 6f64 652e  assert len(node.
-00002d90: 6f75 7470 7574 7329 203d 3d20 310a 0a20  outputs) == 1.. 
-00002da0: 2020 206e 616d 6520 3d20 6e6f 6465 2e6e     name = node.n
-00002db0: 616d 650a 2020 2020 7661 6c20 3d20 6e6f  ame.    val = no
-00002dc0: 6465 2e61 7474 725b 2276 616c 7565 225d  de.attr["value"]
-00002dd0: 0a0a 2020 2020 636f 6e73 7420 3d20 5f63  ..    const = _c
-00002de0: 6f6e 7374 7275 6374 5f63 6f6e 7374 616e  onstruct_constan
-00002df0: 7428 7661 6c2c 206e 616d 6529 0a20 2020  t(val, name).   
-00002e00: 2063 6f6e 7465 7874 2e61 6464 2863 6f6e   context.add(con
-00002e10: 7374 2c20 746f 7263 685f 6e61 6d65 3d6e  st, torch_name=n
-00002e20: 616d 6529 0a0a 0a40 7265 6769 7374 6572  ame)...@register
-00002e30: 5f74 6f72 6368 5f6f 700a 6465 6620 636f  _torch_op.def co
-00002e40: 7369 6e65 5f73 696d 696c 6172 6974 7928  sine_similarity(
-00002e50: 636f 6e74 6578 742c 206e 6f64 6529 3a0a  context, node):.
-00002e60: 2020 2020 696e 7075 7473 203d 205f 6765      inputs = _ge
-00002e70: 745f 696e 7075 7473 2863 6f6e 7465 7874  t_inputs(context
-00002e80: 2c20 6e6f 6465 2c20 6578 7065 6374 6564  , node, expected
-00002e90: 3d34 290a 2020 2020 6469 6d20 3d20 696e  =4).    dim = in
-00002ea0: 7075 7473 5b2d 325d 2e76 616c 0a20 2020  puts[-2].val.   
-00002eb0: 2065 7073 203d 2069 6e70 7574 735b 2d31   eps = inputs[-1
-00002ec0: 5d2e 7661 6c0a 2020 2020 7879 203d 206d  ].val.    xy = m
-00002ed0: 622e 6d75 6c28 783d 696e 7075 7473 5b30  b.mul(x=inputs[0
-00002ee0: 5d2c 2079 3d69 6e70 7574 735b 315d 290a  ], y=inputs[1]).
-00002ef0: 2020 2020 7375 6d5f 7879 203d 206d 622e      sum_xy = mb.
-00002f00: 7265 6475 6365 5f73 756d 2878 3d78 792c  reduce_sum(x=xy,
-00002f10: 2061 7865 733d 5b64 696d 5d29 0a0a 2020   axes=[dim])..  
-00002f20: 2020 7878 203d 206d 622e 6d75 6c28 783d    xx = mb.mul(x=
-00002f30: 696e 7075 7473 5b30 5d2c 2079 3d69 6e70  inputs[0], y=inp
-00002f40: 7574 735b 305d 290a 2020 2020 7375 6d5f  uts[0]).    sum_
-00002f50: 7878 203d 206d 622e 7265 6475 6365 5f73  xx = mb.reduce_s
-00002f60: 756d 2878 3d78 782c 2061 7865 733d 5b64  um(x=xx, axes=[d
-00002f70: 696d 5d29 0a20 2020 2079 7920 3d20 6d62  im]).    yy = mb
-00002f80: 2e6d 756c 2878 3d69 6e70 7574 735b 315d  .mul(x=inputs[1]
-00002f90: 2c20 793d 696e 7075 7473 5b31 5d29 0a20  , y=inputs[1]). 
-00002fa0: 2020 2073 756d 5f79 7920 3d20 6d62 2e72     sum_yy = mb.r
-00002fb0: 6564 7563 655f 7375 6d28 783d 7979 2c20  educe_sum(x=yy, 
-00002fc0: 6178 6573 3d5b 6469 6d5d 290a 0a20 2020  axes=[dim])..   
-00002fd0: 206d 756c 5f73 756d 5f78 7920 3d20 6d62   mul_sum_xy = mb
-00002fe0: 2e6d 756c 2878 3d73 756d 5f78 782c 2079  .mul(x=sum_xx, y
-00002ff0: 3d73 756d 5f79 7929 0a20 2020 2064 6976  =sum_yy).    div
-00003000: 5f31 3220 3d20 6d62 2e6d 6178 696d 756d  _12 = mb.maximum
-00003010: 2878 3d6d 756c 5f73 756d 5f78 792c 2079  (x=mul_sum_xy, y
-00003020: 3d65 7073 202a 2065 7073 290a 2020 2020  =eps * eps).    
-00003030: 6469 765f 7371 7274 203d 206d 622e 7371  div_sqrt = mb.sq
-00003040: 7274 2878 3d64 6976 5f31 3229 0a0a 2020  rt(x=div_12)..  
-00003050: 2020 6373 203d 206d 622e 7265 616c 5f64    cs = mb.real_d
-00003060: 6976 2878 3d73 756d 5f78 792c 2079 3d64  iv(x=sum_xy, y=d
-00003070: 6976 5f73 7172 742c 206e 616d 653d 6e6f  iv_sqrt, name=no
-00003080: 6465 2e6e 616d 6529 0a20 2020 2063 6f6e  de.name).    con
-00003090: 7465 7874 2e61 6464 2863 7329 0a0a 0a40  text.add(cs)...@
-000030a0: 7265 6769 7374 6572 5f74 6f72 6368 5f6f  register_torch_o
-000030b0: 700a 6465 6620 7365 6c75 2863 6f6e 7465  p.def selu(conte
-000030c0: 7874 2c20 6e6f 6465 293a 0a20 2020 2041  xt, node):.    A
-000030d0: 4c50 4841 203d 2031 2e36 3733 3236 3332  LPHA = 1.6732632
-000030e0: 3432 3335 3433 3737 320a 2020 2020 5343  423543772.    SC
-000030f0: 414c 4520 3d20 312e 3035 3037 3030 3938  ALE = 1.05070098
-00003100: 3733 3535 3438 3035 0a0a 2020 2020 7820  73554805..    x 
-00003110: 3d20 5f67 6574 5f69 6e70 7574 7328 636f  = _get_inputs(co
-00003120: 6e74 6578 742c 206e 6f64 652c 2065 7870  ntext, node, exp
-00003130: 6563 7465 643d 3129 5b30 5d0a 2020 2020  ected=1)[0].    
-00003140: 7820 3d20 6d62 2e65 6c75 2878 3d78 2c20  x = mb.elu(x=x, 
-00003150: 616c 7068 613d 414c 5048 4129 0a20 2020  alpha=ALPHA).   
-00003160: 2078 203d 206d 622e 6d75 6c28 783d 782c   x = mb.mul(x=x,
-00003170: 2079 3d53 4341 4c45 2c20 6e61 6d65 3d6e   y=SCALE, name=n
-00003180: 6f64 652e 6e61 6d65 290a 2020 2020 636f  ode.name).    co
-00003190: 6e74 6578 742e 6164 6428 7829 0a0a 0a40  ntext.add(x)...@
-000031a0: 7265 6769 7374 6572 5f74 6f72 6368 5f6f  register_torch_o
-000031b0: 700a 6465 6620 646f 7428 636f 6e74 6578  p.def dot(contex
-000031c0: 742c 206e 6f64 6529 3a0a 2020 2020 696e  t, node):.    in
-000031d0: 7075 7473 203d 205f 6765 745f 696e 7075  puts = _get_inpu
-000031e0: 7473 2863 6f6e 7465 7874 2c20 6e6f 6465  ts(context, node
-000031f0: 2c20 6578 7065 6374 6564 3d32 290a 2020  , expected=2).  
-00003200: 2020 7879 203d 206d 622e 6d75 6c28 783d    xy = mb.mul(x=
-00003210: 696e 7075 7473 5b30 5d2c 2079 3d69 6e70  inputs[0], y=inp
-00003220: 7574 735b 315d 290a 2020 2020 7375 6d5f  uts[1]).    sum_
-00003230: 7879 203d 206d 622e 7265 6475 6365 5f73  xy = mb.reduce_s
-00003240: 756d 2878 3d78 792c 2061 7865 733d 5b30  um(x=xy, axes=[0
-00003250: 5d29 0a20 2020 2063 6f6e 7465 7874 2e61  ]).    context.a
-00003260: 6464 2873 756d 5f78 792c 206e 6f64 652e  dd(sum_xy, node.
-00003270: 6e61 6d65 290a 0a0a 4072 6567 6973 7465  name)...@registe
-00003280: 725f 746f 7263 685f 6f70 0a64 6566 206d  r_torch_op.def m
-00003290: 7628 636f 6e74 6578 742c 206e 6f64 6529  v(context, node)
-000032a0: 3a0a 2020 2020 696e 7075 7473 203d 205f  :.    inputs = _
-000032b0: 6765 745f 696e 7075 7473 2863 6f6e 7465  get_inputs(conte
-000032c0: 7874 2c20 6e6f 6465 2c20 6578 7065 6374  xt, node, expect
-000032d0: 6564 3d32 290a 2020 2020 6578 7061 6e64  ed=2).    expand
-000032e0: 203d 206d 622e 6578 7061 6e64 5f64 696d   = mb.expand_dim
-000032f0: 7328 783d 696e 7075 7473 5b31 5d2c 2061  s(x=inputs[1], a
-00003300: 7865 733d 5b2d 315d 2c20 6e61 6d65 3d6e  xes=[-1], name=n
-00003310: 6f64 652e 6e61 6d65 202b 2022 5f65 7870  ode.name + "_exp
-00003320: 616e 6465 6422 290a 2020 2020 6d76 203d  anded").    mv =
-00003330: 206d 622e 6d61 746d 756c 2878 3d69 6e70   mb.matmul(x=inp
-00003340: 7574 735b 305d 2c20 793d 6578 7061 6e64  uts[0], y=expand
-00003350: 2c20 6e61 6d65 3d6e 6f64 652e 6e61 6d65  , name=node.name
-00003360: 202b 2022 5f6d 7622 290a 2020 2020 7265   + "_mv").    re
-00003370: 7320 3d20 6d62 2e73 7175 6565 7a65 2878  s = mb.squeeze(x
-00003380: 3d6d 762c 2061 7865 733d 5b2d 315d 2c20  =mv, axes=[-1], 
-00003390: 6e61 6d65 3d6e 6f64 652e 6e61 6d65 290a  name=node.name).
-000033a0: 2020 2020 636f 6e74 6578 742e 6164 6428      context.add(
-000033b0: 7265 7329 0a0a 0a40 7265 6769 7374 6572  res)...@register
-000033c0: 5f74 6f72 6368 5f6f 700a 6465 6620 6f75  _torch_op.def ou
-000033d0: 7465 7228 636f 6e74 6578 742c 206e 6f64  ter(context, nod
-000033e0: 6529 3a0a 2020 2020 696e 7075 7473 203d  e):.    inputs =
-000033f0: 205f 6765 745f 696e 7075 7473 2863 6f6e   _get_inputs(con
-00003400: 7465 7874 2c20 6e6f 6465 2c20 6578 7065  text, node, expe
-00003410: 6374 6564 3d32 290a 2020 2020 7820 3d20  cted=2).    x = 
-00003420: 6d62 2e72 6573 6861 7065 2878 3d69 6e70  mb.reshape(x=inp
-00003430: 7574 735b 305d 2c20 7368 6170 653d 5b2d  uts[0], shape=[-
-00003440: 312c 2031 5d29 0a20 2020 2079 203d 206d  1, 1]).    y = m
-00003450: 622e 7265 7368 6170 6528 783d 696e 7075  b.reshape(x=inpu
-00003460: 7473 5b31 5d2c 2073 6861 7065 3d5b 312c  ts[1], shape=[1,
-00003470: 202d 315d 290a 2020 2020 7265 7320 3d20   -1]).    res = 
-00003480: 6d62 2e6d 6174 6d75 6c28 783d 782c 2079  mb.matmul(x=x, y
-00003490: 3d79 2c20 6e61 6d65 3d6e 6f64 652e 6e61  =y, name=node.na
-000034a0: 6d65 290a 2020 2020 636f 6e74 6578 742e  me).    context.
-000034b0: 6164 6428 7265 7329 0a0a 0a40 7265 6769  add(res)...@regi
-000034c0: 7374 6572 5f74 6f72 6368 5f6f 700a 6465  ster_torch_op.de
-000034d0: 6620 6372 6f73 7328 636f 6e74 6578 742c  f cross(context,
-000034e0: 206e 6f64 6529 3a0a 2020 2020 696e 7075   node):.    inpu
-000034f0: 7473 203d 205f 6765 745f 696e 7075 7473  ts = _get_inputs
-00003500: 2863 6f6e 7465 7874 2c20 6e6f 6465 2c20  (context, node, 
-00003510: 6578 7065 6374 6564 3d33 290a 2020 2020  expected=3).    
-00003520: 7820 3d20 696e 7075 7473 5b30 5d0a 2020  x = inputs[0].  
-00003530: 2020 7920 3d20 696e 7075 7473 5b31 5d0a    y = inputs[1].
-00003540: 2020 2020 6469 6d20 3d20 696e 7075 7473      dim = inputs
-00003550: 5b32 5d0a 0a20 2020 2078 3120 3d20 6d62  [2]..    x1 = mb
-00003560: 2e67 6174 6865 7228 783d 782c 2069 6e64  .gather(x=x, ind
-00003570: 6963 6573 3d5b 312c 2032 2c20 305d 2c20  ices=[1, 2, 0], 
-00003580: 6178 6973 3d64 696d 2c20 6e61 6d65 3d22  axis=dim, name="
-00003590: 7831 2229 0a20 2020 2078 3220 3d20 6d62  x1").    x2 = mb
-000035a0: 2e67 6174 6865 7228 783d 782c 2069 6e64  .gather(x=x, ind
-000035b0: 6963 6573 3d5b 322c 2030 2c20 315d 2c20  ices=[2, 0, 1], 
-000035c0: 6178 6973 3d64 696d 2c20 6e61 6d65 3d22  axis=dim, name="
-000035d0: 7832 2229 0a20 2020 2079 3120 3d20 6d62  x2").    y1 = mb
-000035e0: 2e67 6174 6865 7228 783d 792c 2069 6e64  .gather(x=y, ind
-000035f0: 6963 6573 3d5b 312c 2032 2c20 305d 2c20  ices=[1, 2, 0], 
-00003600: 6178 6973 3d64 696d 2c20 6e61 6d65 3d22  axis=dim, name="
-00003610: 7931 2229 0a20 2020 2079 3220 3d20 6d62  y1").    y2 = mb
-00003620: 2e67 6174 6865 7228 783d 792c 2069 6e64  .gather(x=y, ind
-00003630: 6963 6573 3d5b 322c 2030 2c20 315d 2c20  ices=[2, 0, 1], 
-00003640: 6178 6973 3d64 696d 2c20 6e61 6d65 3d22  axis=dim, name="
-00003650: 7932 2229 0a20 2020 206d 3120 3d20 6d62  y2").    m1 = mb
-00003660: 2e6d 756c 2878 3d78 312c 2079 3d79 3229  .mul(x=x1, y=y2)
-00003670: 0a20 2020 206d 3220 3d20 6d62 2e6d 756c  .    m2 = mb.mul
-00003680: 2878 3d78 322c 2079 3d79 3129 0a20 2020  (x=x2, y=y1).   
-00003690: 207a 203d 206d 622e 7375 6228 783d 6d31   z = mb.sub(x=m1
-000036a0: 2c20 793d 6d32 2c20 6e61 6d65 3d6e 6f64  , y=m2, name=nod
-000036b0: 652e 6e61 6d65 290a 2020 2020 636f 6e74  e.name).    cont
-000036c0: 6578 742e 6164 6428 7a29 0a0a 0a40 7265  ext.add(z)...@re
-000036d0: 6769 7374 6572 5f74 6f72 6368 5f6f 700a  gister_torch_op.
-000036e0: 6465 6620 6672 6f62 656e 6975 735f 6e6f  def frobenius_no
-000036f0: 726d 2863 6f6e 7465 7874 2c20 6e6f 6465  rm(context, node
-00003700: 293a 0a20 2020 2078 2c20 6469 6d2c 206b  ):.    x, dim, k
-00003710: 6565 705f 6469 6d73 203d 205f 6765 745f  eep_dims = _get_
-00003720: 696e 7075 7473 2863 6f6e 7465 7874 2c20  inputs(context, 
-00003730: 6e6f 6465 2c20 6578 7065 6374 6564 3d33  node, expected=3
-00003740: 290a 2020 2020 7265 7375 6c74 203d 206d  ).    result = m
-00003750: 622e 7265 6475 6365 5f6c 325f 6e6f 726d  b.reduce_l2_norm
-00003760: 2878 3d78 2c20 6178 6573 3d64 696d 2c20  (x=x, axes=dim, 
-00003770: 6b65 6570 5f64 696d 733d 6b65 6570 5f64  keep_dims=keep_d
-00003780: 696d 732c 206e 616d 653d 6e6f 6465 2e6e  ims, name=node.n
-00003790: 616d 6529 0a20 2020 2063 6f6e 7465 7874  ame).    context
-000037a0: 2e61 6464 2872 6573 756c 7429 0a0a 0a40  .add(result)...@
-000037b0: 7265 6769 7374 6572 5f74 6f72 6368 5f6f  register_torch_o
-000037c0: 700a 6465 6620 6e6f 726d 2863 6f6e 7465  p.def norm(conte
-000037d0: 7874 2c20 6e6f 6465 293a 0a20 2020 2078  xt, node):.    x
-000037e0: 2c20 6e75 6d2c 2064 696d 2c20 6b65 6570  , num, dim, keep
-000037f0: 5f64 696d 7320 3d20 5f67 6574 5f69 6e70  _dims = _get_inp
-00003800: 7574 7328 636f 6e74 6578 742c 206e 6f64  uts(context, nod
-00003810: 652c 2065 7870 6563 7465 643d 3429 0a20  e, expected=4). 
-00003820: 2020 2061 7373 6572 7420 7820 6973 206e     assert x is n
-00003830: 6f74 204e 6f6e 6520 616e 6420 6b65 6570  ot None and keep
-00003840: 5f64 696d 7320 6973 206e 6f74 204e 6f6e  _dims is not Non
-00003850: 6520 616e 6420 6e75 6d20 6973 206e 6f74  e and num is not
-00003860: 204e 6f6e 6520 616e 6420 6469 6d20 6973   None and dim is
-00003870: 206e 6f74 204e 6f6e 650a 2020 2020 7465   not None.    te
-00003880: 6d70 203d 205f 7665 6374 6f72 5f6e 6f72  mp = _vector_nor
-00003890: 6d28 783d 782c 206f 7264 6572 3d6e 756d  m(x=x, order=num
-000038a0: 2c20 6469 6d3d 6469 6d2c 206b 6565 705f  , dim=dim, keep_
-000038b0: 6469 6d73 3d6b 6565 705f 6469 6d73 2c20  dims=keep_dims, 
-000038c0: 6e61 6d65 3d6e 6f64 652e 6e61 6d65 290a  name=node.name).
-000038d0: 2020 2020 636f 6e74 6578 742e 6164 6428      context.add(
-000038e0: 7465 6d70 290a 0a0a 6465 6620 5f76 6563  temp)...def _vec
-000038f0: 746f 725f 6e6f 726d 2878 2c20 6f72 6465  tor_norm(x, orde
-00003900: 722c 2064 696d 2c20 6b65 6570 5f64 696d  r, dim, keep_dim
-00003910: 732c 206e 616d 6529 3a0a 2020 2020 6966  s, name):.    if
-00003920: 206f 7264 6572 2e76 616c 203d 3d20 303a   order.val == 0:
-00003930: 0a20 2020 2020 2020 2023 2073 756d 2878  .        # sum(x
-00003940: 213d 3029 0a20 2020 2020 2020 2078 203d  !=0).        x =
-00003950: 206d 622e 6361 7374 2878 3d78 2c20 6474   mb.cast(x=x, dt
-00003960: 7970 653d 2266 7033 3222 290a 2020 2020  ype="fp32").    
-00003970: 2020 2020 7465 6d70 203d 206d 622e 6e6f      temp = mb.no
-00003980: 745f 6571 7561 6c28 783d 782c 2079 3d30  t_equal(x=x, y=0
-00003990: 2e29 0a20 2020 2020 2020 2074 656d 7020  .).        temp 
-000039a0: 3d20 6d62 2e63 6173 7428 783d 7465 6d70  = mb.cast(x=temp
-000039b0: 2c20 6474 7970 653d 2769 6e74 3332 2729  , dtype='int32')
-000039c0: 0a20 2020 2020 2020 2074 656d 7020 3d20  .        temp = 
-000039d0: 6d62 2e72 6564 7563 655f 7375 6d28 783d  mb.reduce_sum(x=
-000039e0: 7465 6d70 2c20 6178 6573 3d64 696d 2c20  temp, axes=dim, 
-000039f0: 6b65 6570 5f64 696d 733d 6b65 6570 5f64  keep_dims=keep_d
-00003a00: 696d 732c 206e 616d 653d 6e61 6d65 290a  ims, name=name).
-00003a10: 2020 2020 656c 6966 206f 7264 6572 2e76      elif order.v
-00003a20: 616c 203e 2056 414c 5545 5f43 4c4f 5345  al > VALUE_CLOSE
-00003a30: 5f54 4f5f 494e 4649 4e49 5459 3a0a 2020  _TO_INFINITY:.  
-00003a40: 2020 2020 2020 2320 6d61 7828 6162 7328        # max(abs(
-00003a50: 7829 290a 2020 2020 2020 2020 7465 6d70  x)).        temp
-00003a60: 203d 206d 622e 6162 7328 783d 7829 0a20   = mb.abs(x=x). 
-00003a70: 2020 2020 2020 2074 656d 7020 3d20 6d62         temp = mb
-00003a80: 2e72 6564 7563 655f 6d61 7828 783d 7465  .reduce_max(x=te
-00003a90: 6d70 2c20 6178 6573 3d64 696d 2c20 6b65  mp, axes=dim, ke
-00003aa0: 6570 5f64 696d 733d 6b65 6570 5f64 696d  ep_dims=keep_dim
-00003ab0: 732c 206e 616d 653d 6e61 6d65 290a 2020  s, name=name).  
-00003ac0: 2020 656c 6966 206f 7264 6572 2e76 616c    elif order.val
-00003ad0: 203c 202d 5641 4c55 455f 434c 4f53 455f   < -VALUE_CLOSE_
-00003ae0: 544f 5f49 4e46 494e 4954 593a 0a20 2020  TO_INFINITY:.   
-00003af0: 2020 2020 2023 206d 696e 2861 6273 2878       # min(abs(x
-00003b00: 2929 0a20 2020 2020 2020 2074 656d 7020  )).        temp 
-00003b10: 3d20 6d62 2e61 6273 2878 3d78 290a 2020  = mb.abs(x=x).  
-00003b20: 2020 2020 2020 7465 6d70 203d 206d 622e        temp = mb.
-00003b30: 7265 6475 6365 5f6d 696e 2878 3d74 656d  reduce_min(x=tem
-00003b40: 702c 2061 7865 733d 6469 6d2c 206b 6565  p, axes=dim, kee
-00003b50: 705f 6469 6d73 3d6b 6565 705f 6469 6d73  p_dims=keep_dims
-00003b60: 2c20 6e61 6d65 3d6e 616d 6529 0a20 2020  , name=name).   
-00003b70: 2065 6c73 653a 0a20 2020 2020 2020 2023   else:.        #
-00003b80: 2073 756d 2861 6273 2878 295e 7b6f 7264   sum(abs(x)^{ord
-00003b90: 6572 7d29 5e7b 2831 202f 206f 7264 6572  er})^{(1 / order
-00003ba0: 297d 0a20 2020 2020 2020 2074 656d 7020  )}.        temp 
-00003bb0: 3d20 6d62 2e61 6273 2878 3d78 290a 2020  = mb.abs(x=x).  
-00003bc0: 2020 2020 2020 782c 2079 203d 2070 726f        x, y = pro
-00003bd0: 6d6f 7465 5f69 6e70 7574 5f64 7479 7065  mote_input_dtype
-00003be0: 7328 5b74 656d 702c 206f 7264 6572 2e76  s([temp, order.v
-00003bf0: 616c 5d29 0a20 2020 2020 2020 2074 656d  al]).        tem
-00003c00: 7020 3d20 6d62 2e70 6f77 2878 3d78 2c20  p = mb.pow(x=x, 
-00003c10: 793d 7929 0a20 2020 2020 2020 2074 656d  y=y).        tem
-00003c20: 7020 3d20 6d62 2e72 6564 7563 655f 7375  p = mb.reduce_su
-00003c30: 6d28 783d 7465 6d70 2c20 6178 6573 3d64  m(x=temp, axes=d
-00003c40: 696d 2c20 6b65 6570 5f64 696d 733d 6b65  im, keep_dims=ke
-00003c50: 6570 5f64 696d 7329 0a20 2020 2020 2020  ep_dims).       
-00003c60: 2074 656d 7020 3d20 6d62 2e70 6f77 2878   temp = mb.pow(x
-00003c70: 3d74 656d 702c 2079 3d31 2e30 202f 206f  =temp, y=1.0 / o
-00003c80: 7264 6572 2e76 616c 2c20 6e61 6d65 3d6e  rder.val, name=n
-00003c90: 616d 6529 0a20 2020 2072 6574 7572 6e20  ame).    return 
-00003ca0: 7465 6d70 0a0a 4072 6567 6973 7465 725f  temp..@register_
-00003cb0: 746f 7263 685f 6f70 0a64 6566 205f 7765  torch_op.def _we
-00003cc0: 6967 6874 5f6e 6f72 6d28 636f 6e74 6578  ight_norm(contex
-00003cd0: 742c 206e 6f64 6529 3a0a 2020 2020 762c  t, node):.    v,
-00003ce0: 2067 2c20 6469 6d20 3d20 5f67 6574 5f69   g, dim = _get_i
-00003cf0: 6e70 7574 7328 636f 6e74 6578 742c 206e  nputs(context, n
-00003d00: 6f64 652c 2065 7870 6563 7465 643d 3329  ode, expected=3)
-00003d10: 0a0a 2020 2020 2320 4465 7465 726d 696e  ..    # Determin
-00003d20: 6520 6178 6573 2066 6f72 204c 3220 6e6f  e axes for L2 no
-00003d30: 726d 0a20 2020 2069 6620 6469 6d2e 7661  rm.    if dim.va
-00003d40: 6c20 3d3d 202d 313a 0a20 2020 2020 2020  l == -1:.       
-00003d50: 2061 7865 7320 3d20 4e6f 6e65 0a20 2020   axes = None.   
-00003d60: 2065 6c73 653a 0a20 2020 2020 2020 2061   else:.        a
-00003d70: 7865 7320 3d20 6c69 7374 2872 616e 6765  xes = list(range
-00003d80: 2876 2e72 616e 6b29 290a 2020 2020 2020  (v.rank)).      
-00003d90: 2020 6469 6d20 3d20 6469 6d2e 7661 6c0a    dim = dim.val.
-00003da0: 2020 2020 2020 2020 6966 2064 696d 203e          if dim >
-00003db0: 3d20 303a 0a20 2020 2020 2020 2020 2020  = 0:.           
-00003dc0: 2061 7865 732e 7265 6d6f 7665 2864 696d   axes.remove(dim
-00003dd0: 290a 2020 2020 2020 2020 656c 7365 3a0a  ).        else:.
-00003de0: 2020 2020 2020 2020 2020 2020 6178 6573              axes
-00003df0: 2e72 656d 6f76 6528 762e 7261 6e6b 202b  .remove(v.rank +
-00003e00: 2064 696d 290a 0a20 2020 2023 2043 616c   dim)..    # Cal
-00003e10: 6375 6c61 7465 204c 3220 6e6f 726d 206f  culate L2 norm o
-00003e20: 6620 760a 2020 2020 7465 6d70 203d 206d  f v.    temp = m
-00003e30: 622e 706f 7728 783d 762c 2079 3d32 2e29  b.pow(x=v, y=2.)
-00003e40: 0a20 2020 2074 656d 7020 3d20 6d62 2e72  .    temp = mb.r
-00003e50: 6564 7563 655f 7375 6d28 783d 7465 6d70  educe_sum(x=temp
-00003e60: 2c20 6178 6573 3d61 7865 732c 206b 6565  , axes=axes, kee
-00003e70: 705f 6469 6d73 3d54 7275 6529 0a20 2020  p_dims=True).   
-00003e80: 206e 6f72 6d20 3d20 6d62 2e70 6f77 2878   norm = mb.pow(x
-00003e90: 3d74 656d 702c 2079 3d31 2e2f 3229 0a0a  =temp, y=1./2)..
-00003ea0: 2020 2020 696e 7665 7273 655f 6e6f 726d      inverse_norm
-00003eb0: 203d 206d 622e 696e 7665 7273 6528 783d   = mb.inverse(x=
-00003ec0: 6e6f 726d 290a 2020 2020 6469 7265 6374  norm).    direct
-00003ed0: 696f 6e20 3d20 6d62 2e6d 756c 2878 3d76  ion = mb.mul(x=v
-00003ee0: 2c20 793d 696e 7665 7273 655f 6e6f 726d  , y=inverse_norm
-00003ef0: 290a 2020 2020 7265 7375 6c74 203d 206d  ).    result = m
-00003f00: 622e 6d75 6c28 783d 672c 2079 3d64 6972  b.mul(x=g, y=dir
-00003f10: 6563 7469 6f6e 2c20 6e61 6d65 3d6e 6f64  ection, name=nod
-00003f20: 652e 6e61 6d65 290a 2020 2020 636f 6e74  e.name).    cont
-00003f30: 6578 742e 6164 6428 7265 7375 6c74 290a  ext.add(result).
-00003f40: 0a0a 0a64 6566 205f 6d61 7472 6978 5f6e  ...def _matrix_n
-00003f50: 6f72 6d28 782c 206f 7264 6572 2c20 6469  orm(x, order, di
-00003f60: 6d2c 206b 6565 705f 6469 6d73 2c20 6e61  m, keep_dims, na
-00003f70: 6d65 293a 0a20 2020 2069 6620 6f72 6465  me):.    if orde
-00003f80: 722e 7661 6c20 3d3d 2031 3a0a 2020 2020  r.val == 1:.    
-00003f90: 2020 2020 2320 6d69 6e28 7375 6d28 6162      # min(sum(ab
-00003fa0: 7328 7829 2c20 6469 6d3d 3029 290a 2020  s(x), dim=0)).  
-00003fb0: 2020 2020 2020 7465 6d70 203d 206d 622e        temp = mb.
-00003fc0: 6162 7328 783d 7829 0a20 2020 2020 2020  abs(x=x).       
-00003fd0: 2074 656d 7020 3d20 6d62 2e72 6564 7563   temp = mb.reduc
-00003fe0: 655f 7375 6d28 783d 7465 6d70 2c20 6178  e_sum(x=temp, ax
-00003ff0: 6573 3d5b 6469 6d5b 305d 5d2c 206b 6565  es=[dim[0]], kee
-00004000: 705f 6469 6d73 3d54 7275 6529 0a20 2020  p_dims=True).   
-00004010: 2020 2020 2074 656d 7020 3d20 6d62 2e72       temp = mb.r
-00004020: 6564 7563 655f 6d61 7828 783d 7465 6d70  educe_max(x=temp
-00004030: 2c20 6178 6573 3d64 696d 2c20 6b65 6570  , axes=dim, keep
-00004040: 5f64 696d 733d 6b65 6570 5f64 696d 732c  _dims=keep_dims,
-00004050: 206e 616d 653d 6e61 6d65 290a 2020 2020   name=name).    
-00004060: 656c 6966 206f 7264 6572 2e76 616c 203d  elif order.val =
-00004070: 3d20 2d31 3a0a 2020 2020 2020 2020 2320  = -1:.        # 
-00004080: 6d69 6e28 7375 6d28 6162 7328 7829 2c20  min(sum(abs(x), 
-00004090: 6469 6d3d 3029 290a 2020 2020 2020 2020  dim=0)).        
-000040a0: 7465 6d70 203d 206d 622e 6162 7328 783d  temp = mb.abs(x=
-000040b0: 7829 0a20 2020 2020 2020 2074 656d 7020  x).        temp 
-000040c0: 3d20 6d62 2e72 6564 7563 655f 7375 6d28  = mb.reduce_sum(
-000040d0: 783d 7465 6d70 2c20 6178 6573 3d5b 6469  x=temp, axes=[di
-000040e0: 6d5b 305d 5d2c 206b 6565 705f 6469 6d73  m[0]], keep_dims
-000040f0: 3d54 7275 6529 0a20 2020 2020 2020 2074  =True).        t
-00004100: 656d 7020 3d20 6d62 2e72 6564 7563 655f  emp = mb.reduce_
-00004110: 6d69 6e28 783d 7465 6d70 2c20 6178 6573  min(x=temp, axes
-00004120: 3d64 696d 2c20 6b65 6570 5f64 696d 733d  =dim, keep_dims=
-00004130: 6b65 6570 5f64 696d 732c 206e 616d 653d  keep_dims, name=
-00004140: 6e61 6d65 290a 2020 2020 656c 6966 206f  name).    elif o
-00004150: 7264 6572 2e76 616c 203d 3d20 2266 726f  rder.val == "fro
-00004160: 223a 0a20 2020 2020 2020 2023 2073 756d  ":.        # sum
-00004170: 2878 2a2a 3229 2a2a 312f 320a 2020 2020  (x**2)**1/2.    
-00004180: 2020 2020 7465 6d70 203d 206d 622e 7265      temp = mb.re
-00004190: 6475 6365 5f6c 325f 6e6f 726d 2878 3d78  duce_l2_norm(x=x
-000041a0: 2c20 6178 6573 3d64 696d 2c20 6b65 6570  , axes=dim, keep
-000041b0: 5f64 696d 733d 6b65 6570 5f64 696d 732c  _dims=keep_dims,
-000041c0: 206e 616d 653d 6e61 6d65 290a 2020 2020   name=name).    
-000041d0: 656c 6966 206f 7264 6572 2e76 616c 203e  elif order.val >
-000041e0: 2056 414c 5545 5f43 4c4f 5345 5f54 4f5f   VALUE_CLOSE_TO_
-000041f0: 494e 4649 4e49 5459 3a0a 2020 2020 2020  INFINITY:.      
-00004200: 2020 2320 6d61 7828 7375 6d28 6162 7328    # max(sum(abs(
-00004210: 7829 2c20 6469 6d3d 3129 290a 2020 2020  x), dim=1)).    
-00004220: 2020 2020 7465 6d70 203d 206d 622e 6162      temp = mb.ab
-00004230: 7328 783d 7829 0a20 2020 2020 2020 2074  s(x=x).        t
-00004240: 656d 7020 3d20 6d62 2e72 6564 7563 655f  emp = mb.reduce_
-00004250: 7375 6d28 783d 7465 6d70 2c20 6178 6573  sum(x=temp, axes
-00004260: 3d5b 6469 6d5b 315d 5d2c 206b 6565 705f  =[dim[1]], keep_
-00004270: 6469 6d73 3d54 7275 6529 0a20 2020 2020  dims=True).     
-00004280: 2020 2074 656d 7020 3d20 6d62 2e72 6564     temp = mb.red
-00004290: 7563 655f 6d61 7828 783d 7465 6d70 2c20  uce_max(x=temp, 
-000042a0: 6178 6573 3d64 696d 2c20 6b65 6570 5f64  axes=dim, keep_d
-000042b0: 696d 733d 6b65 6570 5f64 696d 732c 206e  ims=keep_dims, n
-000042c0: 616d 653d 6e61 6d65 290a 2020 2020 656c  ame=name).    el
-000042d0: 6966 206f 7264 6572 2e76 616c 203c 202d  if order.val < -
-000042e0: 5641 4c55 455f 434c 4f53 455f 544f 5f49  VALUE_CLOSE_TO_I
-000042f0: 4e46 494e 4954 593a 0a20 2020 2020 2020  NFINITY:.       
-00004300: 2023 206d 696e 2873 756d 2861 6273 2878   # min(sum(abs(x
-00004310: 292c 2064 696d 3d31 2929 0a20 2020 2020  ), dim=1)).     
-00004320: 2020 2074 656d 7020 3d20 6d62 2e61 6273     temp = mb.abs
-00004330: 2878 3d78 290a 2020 2020 2020 2020 7465  (x=x).        te
-00004340: 6d70 203d 206d 622e 7265 6475 6365 5f73  mp = mb.reduce_s
-00004350: 756d 2878 3d74 656d 702c 2061 7865 733d  um(x=temp, axes=
-00004360: 5b64 696d 5b31 5d5d 2c20 6b65 6570 5f64  [dim[1]], keep_d
-00004370: 696d 733d 5472 7565 290a 2020 2020 2020  ims=True).      
-00004380: 2020 7465 6d70 203d 206d 622e 7265 6475    temp = mb.redu
-00004390: 6365 5f6d 696e 2878 3d74 656d 702c 2061  ce_min(x=temp, a
-000043a0: 7865 733d 6469 6d2c 206b 6565 705f 6469  xes=dim, keep_di
-000043b0: 6d73 3d6b 6565 705f 6469 6d73 2c20 6e61  ms=keep_dims, na
-000043c0: 6d65 3d6e 616d 6529 0a20 2020 2065 6c73  me=name).    els
-000043d0: 653a 0a20 2020 2020 2020 2072 6169 7365  e:.        raise
-000043e0: 2052 756e 7469 6d65 4572 726f 7228 224d   RuntimeError("M
-000043f0: 6174 7269 7820 6e6f 726d 2069 7320 6e6f  atrix norm is no
-00004400: 7420 6465 6669 6e65 6420 666f 7220 7468  t defined for th
-00004410: 6520 6375 7272 656e 7420 696e 7075 7473  e current inputs
-00004420: 2229 0a20 2020 2072 6574 7572 6e20 7465  ").    return te
-00004430: 6d70 0a0a 0a40 7265 6769 7374 6572 5f74  mp...@register_t
-00004440: 6f72 6368 5f6f 700a 6465 6620 6c69 6e61  orch_op.def lina
-00004450: 6c67 5f76 6563 746f 725f 6e6f 726d 2863  lg_vector_norm(c
-00004460: 6f6e 7465 7874 2c20 6e6f 6465 293a 0a20  ontext, node):. 
-00004470: 2020 2078 2c20 6f72 6465 722c 2064 696d     x, order, dim
-00004480: 2c20 6b65 6570 5f64 696d 732c 205f 203d  , keep_dims, _ =
-00004490: 205f 6765 745f 696e 7075 7473 2863 6f6e   _get_inputs(con
-000044a0: 7465 7874 2c20 6e6f 6465 2c20 6578 7065  text, node, expe
-000044b0: 6374 6564 3d35 290a 2020 2020 6173 7365  cted=5).    asse
-000044c0: 7274 2078 2069 7320 6e6f 7420 4e6f 6e65  rt x is not None
-000044d0: 2061 6e64 206b 6565 705f 6469 6d73 2069   and keep_dims i
-000044e0: 7320 6e6f 7420 4e6f 6e65 2061 6e64 206f  s not None and o
-000044f0: 7264 6572 2069 7320 6e6f 7420 4e6f 6e65  rder is not None
-00004500: 0a20 2020 2074 656d 7020 3d20 5f76 6563  .    temp = _vec
-00004510: 746f 725f 6e6f 726d 2878 3d78 2c20 6f72  tor_norm(x=x, or
-00004520: 6465 723d 6f72 6465 722c 2064 696d 3d64  der=order, dim=d
-00004530: 696d 2c20 6b65 6570 5f64 696d 733d 6b65  im, keep_dims=ke
-00004540: 6570 5f64 696d 732c 206e 616d 653d 6e6f  ep_dims, name=no
-00004550: 6465 2e6e 616d 6529 0a20 2020 2063 6f6e  de.name).    con
-00004560: 7465 7874 2e61 6464 2874 656d 7029 0a0a  text.add(temp)..
-00004570: 0a40 7265 6769 7374 6572 5f74 6f72 6368  .@register_torch
-00004580: 5f6f 700a 6465 6620 6c69 6e61 6c67 5f6d  _op.def linalg_m
-00004590: 6174 7269 785f 6e6f 726d 2863 6f6e 7465  atrix_norm(conte
-000045a0: 7874 2c20 6e6f 6465 293a 0a20 2020 2078  xt, node):.    x
-000045b0: 2c20 6f72 6465 722c 2064 696d 2c20 6b65  , order, dim, ke
-000045c0: 6570 5f64 696d 732c 205f 203d 205f 6765  ep_dims, _ = _ge
-000045d0: 745f 696e 7075 7473 2863 6f6e 7465 7874  t_inputs(context
-000045e0: 2c20 6e6f 6465 2c20 6578 7065 6374 6564  , node, expected
-000045f0: 3d35 290a 2020 2020 6173 7365 7274 2078  =5).    assert x
-00004600: 2069 7320 6e6f 7420 4e6f 6e65 2061 6e64   is not None and
-00004610: 206b 6565 705f 6469 6d73 2069 7320 6e6f   keep_dims is no
-00004620: 7420 4e6f 6e65 2061 6e64 206f 7264 6572  t None and order
-00004630: 2069 7320 6e6f 7420 4e6f 6e65 2061 6e64   is not None and
-00004640: 2064 696d 2069 7320 6e6f 7420 4e6f 6e65   dim is not None
-00004650: 0a20 2020 2061 7373 6572 7420 6c65 6e28  .    assert len(
-00004660: 6469 6d2e 7661 6c29 203d 3d20 320a 2020  dim.val) == 2.  
-00004670: 2020 7465 6d70 203d 205f 6d61 7472 6978    temp = _matrix
-00004680: 5f6e 6f72 6d28 783d 782c 206f 7264 6572  _norm(x=x, order
-00004690: 3d6f 7264 6572 2c20 6469 6d3d 6469 6d2e  =order, dim=dim.
-000046a0: 7661 6c2c 206b 6565 705f 6469 6d73 3d6b  val, keep_dims=k
-000046b0: 6565 705f 6469 6d73 2c20 6e61 6d65 3d6e  eep_dims, name=n
-000046c0: 6f64 652e 6e61 6d65 290a 2020 2020 636f  ode.name).    co
-000046d0: 6e74 6578 742e 6164 6428 7465 6d70 290a  ntext.add(temp).
-000046e0: 0a0a 4072 6567 6973 7465 725f 746f 7263  ..@register_torc
-000046f0: 685f 6f70 0a64 6566 206c 696e 616c 675f  h_op.def linalg_
-00004700: 6e6f 726d 2863 6f6e 7465 7874 2c20 6e6f  norm(context, no
-00004710: 6465 293a 0a20 2020 2078 2c20 6f72 6465  de):.    x, orde
-00004720: 722c 2064 696d 2c20 6b65 6570 5f64 696d  r, dim, keep_dim
-00004730: 732c 205f 203d 205f 6765 745f 696e 7075  s, _ = _get_inpu
-00004740: 7473 2863 6f6e 7465 7874 2c20 6e6f 6465  ts(context, node
-00004750: 2c20 6578 7065 6374 6564 3d35 290a 2020  , expected=5).  
-00004760: 2020 6173 7365 7274 2078 2069 7320 6e6f    assert x is no
-00004770: 7420 4e6f 6e65 2061 6e64 206b 6565 705f  t None and keep_
-00004780: 6469 6d73 2069 7320 6e6f 7420 4e6f 6e65  dims is not None
-00004790: 0a20 2020 2069 6620 6469 6d20 6973 204e  .    if dim is N
-000047a0: 6f6e 653a 0a20 2020 2020 2020 2064 696d  one:.        dim
-000047b0: 203d 205f 6e70 2e61 7261 6e67 6528 782e   = _np.arange(x.
-000047c0: 7261 6e6b 290a 2020 2020 656c 7365 3a0a  rank).    else:.
-000047d0: 2020 2020 2020 2020 6469 6d20 3d20 6469          dim = di
-000047e0: 6d2e 7661 6c0a 2020 2020 6966 206f 7264  m.val.    if ord
-000047f0: 6572 2069 7320 4e6f 6e65 3a0a 2020 2020  er is None:.    
-00004800: 2020 2020 7465 6d70 203d 206d 622e 7265      temp = mb.re
-00004810: 6475 6365 5f6c 325f 6e6f 726d 2878 3d78  duce_l2_norm(x=x
-00004820: 2c20 6178 6573 3d64 696d 2c20 6b65 6570  , axes=dim, keep
-00004830: 5f64 696d 733d 6b65 6570 5f64 696d 732c  _dims=keep_dims,
-00004840: 206e 616d 653d 6e6f 6465 2e6e 616d 6529   name=node.name)
-00004850: 0a20 2020 2065 6c69 6620 6c65 6e28 6469  .    elif len(di
-00004860: 6d29 203d 3d20 323a 0a20 2020 2020 2020  m) == 2:.       
-00004870: 2074 656d 7020 3d20 5f6d 6174 7269 785f   temp = _matrix_
-00004880: 6e6f 726d 280a 2020 2020 2020 2020 2020  norm(.          
-00004890: 2020 783d 782c 206f 7264 6572 3d6f 7264    x=x, order=ord
-000048a0: 6572 2c20 6469 6d3d 6469 6d2c 206b 6565  er, dim=dim, kee
-000048b0: 705f 6469 6d73 3d6b 6565 705f 6469 6d73  p_dims=keep_dims
-000048c0: 2c20 6e61 6d65 3d6e 6f64 652e 6e61 6d65  , name=node.name
-000048d0: 0a20 2020 2020 2020 2029 0a20 2020 2065  .        ).    e
-000048e0: 6c73 653a 0a20 2020 2020 2020 2074 656d  lse:.        tem
-000048f0: 7020 3d20 5f76 6563 746f 725f 6e6f 726d  p = _vector_norm
-00004900: 2878 3d78 2c20 6f72 6465 723d 6f72 6465  (x=x, order=orde
-00004910: 722c 2064 696d 3d64 696d 2c20 6b65 6570  r, dim=dim, keep
-00004920: 5f64 696d 733d 6b65 6570 5f64 696d 732c  _dims=keep_dims,
-00004930: 206e 616d 653d 6e6f 6465 2e6e 616d 6529   name=node.name)
-00004940: 0a20 2020 2063 6f6e 7465 7874 2e61 6464  .    context.add
-00004950: 2874 656d 7029 0a0a 0a40 7265 6769 7374  (temp)...@regist
-00004960: 6572 5f74 6f72 6368 5f6f 700a 6465 6620  er_torch_op.def 
-00004970: 6861 7264 7377 6973 6828 636f 6e74 6578  hardswish(contex
-00004980: 742c 206e 6f64 6529 3a0a 2020 2020 696e  t, node):.    in
-00004990: 7075 7473 203d 205f 6765 745f 696e 7075  puts = _get_inpu
-000049a0: 7473 2863 6f6e 7465 7874 2c20 6e6f 6465  ts(context, node
-000049b0: 2c20 6578 7065 6374 6564 3d31 290a 2020  , expected=1).  
-000049c0: 2020 7820 3d20 696e 7075 7473 5b30 5d0a    x = inputs[0].
-000049d0: 0a20 2020 2077 203d 206d 622e 7468 7265  .    w = mb.thre
-000049e0: 7368 6f6c 6465 645f 7265 6c75 2878 3d78  sholded_relu(x=x
-000049f0: 2c20 616c 7068 613d 2d33 2e30 290a 2020  , alpha=-3.0).  
-00004a00: 2020 7920 3d20 6d62 2e73 6967 6d6f 6964    y = mb.sigmoid
-00004a10: 5f68 6172 6428 0a20 2020 2020 2020 2078  _hard(.        x
-00004a20: 3d77 2c20 616c 7068 613d 312e 3020 2f20  =w, alpha=1.0 / 
-00004a30: 362c 2062 6574 613d 302e 350a 2020 2020  6, beta=0.5.    
-00004a40: 2920 2023 2060 6079 203d 206d 696e 286d  )  # ``y = min(m
-00004a50: 6178 2861 6c70 6861 202a 2078 202b 2062  ax(alpha * x + b
-00004a60: 6574 612c 202d 3129 2c20 3129 0a20 2020  eta, -1), 1).   
-00004a70: 2072 6573 756c 7420 3d20 6d62 2e6d 756c   result = mb.mul
-00004a80: 2878 3d77 2c20 793d 792c 206e 616d 653d  (x=w, y=y, name=
-00004a90: 6e6f 6465 2e6e 616d 6529 0a0a 2020 2020  node.name)..    
-00004aa0: 636f 6e74 6578 742e 6164 6428 7265 7375  context.add(resu
-00004ab0: 6c74 290a 0a0a 4072 6567 6973 7465 725f  lt)...@register_
-00004ac0: 746f 7263 685f 6f70 0a64 6566 2072 6573  torch_op.def res
-00004ad0: 6861 7065 5f61 7328 636f 6e74 6578 742c  hape_as(context,
-00004ae0: 206e 6f64 6529 3a0a 2020 2020 696e 7075   node):.    inpu
-00004af0: 7473 203d 205f 6765 745f 696e 7075 7473  ts = _get_inputs
-00004b00: 2863 6f6e 7465 7874 2c20 6e6f 6465 2c20  (context, node, 
-00004b10: 6578 7065 6374 6564 3d32 290a 2020 2020  expected=2).    
-00004b20: 7820 3d20 696e 7075 7473 5b30 5d0a 2020  x = inputs[0].  
-00004b30: 2020 7265 6620 3d20 696e 7075 7473 5b31    ref = inputs[1
-00004b40: 5d0a 2020 2020 7368 6170 6520 3d20 6d62  ].    shape = mb
-00004b50: 2e73 6861 7065 2878 3d72 6566 290a 2020  .shape(x=ref).  
-00004b60: 2020 7265 7375 6c74 203d 206d 622e 7265    result = mb.re
-00004b70: 7368 6170 6528 783d 782c 2073 6861 7065  shape(x=x, shape
-00004b80: 3d73 6861 7065 2c20 6e61 6d65 3d6e 6f64  =shape, name=nod
-00004b90: 652e 6e61 6d65 290a 2020 2020 636f 6e74  e.name).    cont
-00004ba0: 6578 742e 6164 6428 7265 7375 6c74 290a  ext.add(result).
-00004bb0: 0a0a 6465 6620 5f61 7272 6179 5f63 6f6e  ..def _array_con
-00004bc0: 7374 7275 6374 2863 6f6e 7465 7874 2c20  struct(context, 
-00004bd0: 6e6f 6465 2c20 6172 7261 795f 7479 7065  node, array_type
-00004be0: 293a 0a20 2020 2061 7373 6572 7420 6c65  ):.    assert le
-00004bf0: 6e28 6e6f 6465 2e6f 7574 7075 7473 2920  n(node.outputs) 
-00004c00: 3d3d 2031 0a20 2020 2069 6e70 7574 7320  == 1.    inputs 
-00004c10: 3d20 5f67 6574 5f69 6e70 7574 7328 636f  = _get_inputs(co
-00004c20: 6e74 6578 742c 206e 6f64 6529 0a20 2020  ntext, node).   
-00004c30: 2073 6361 6c61 725f 696e 7075 7473 203d   scalar_inputs =
-00004c40: 205b 0a20 2020 2020 2020 2069 6e70 0a20   [.        inp. 
-00004c50: 2020 2020 2020 2066 6f72 2069 6e70 2069         for inp i
-00004c60: 6e20 696e 7075 7473 0a20 2020 2020 2020  n inputs.       
-00004c70: 2069 6620 6973 696e 7374 616e 6365 2869   if isinstance(i
-00004c80: 6e70 2c20 5661 7229 2061 6e64 2069 6e70  np, Var) and inp
-00004c90: 2e63 616e 5f62 655f 666f 6c64 6564 5f74  .can_be_folded_t
-00004ca0: 6f5f 636f 6e73 7428 2920 616e 6420 6c65  o_const() and le
-00004cb0: 6e28 696e 702e 7368 6170 6529 203d 3d20  n(inp.shape) == 
-00004cc0: 300a 2020 2020 5d0a 0a20 2020 2069 6620  0.    ]..    if 
-00004cd0: 6c65 6e28 7363 616c 6172 5f69 6e70 7574  len(scalar_input
-00004ce0: 7329 203d 3d20 6c65 6e28 696e 7075 7473  s) == len(inputs
-00004cf0: 293a 0a20 2020 2020 2020 2023 2041 6c6c  ):.        # All
-00004d00: 2074 6865 206c 6973 7420 6974 656d 7320   the list items 
-00004d10: 6172 6520 636f 6d70 696c 652d 7469 6d65  are compile-time
-00004d20: 2073 6361 6c61 7220 636f 6e73 7461 6e74   scalar constant
-00004d30: 732c 2073 6f20 6c65 7427 7320 6372 6561  s, so let's crea
-00004d40: 7465 0a20 2020 2020 2020 2023 2061 206e  te.        # a n
-00004d50: 6577 2063 6f6e 7374 2074 6861 7420 636f  ew const that co
-00004d60: 6e63 6174 656e 6174 6573 2074 6865 6d2e  ncatenates them.
-00004d70: 0a20 2020 2020 2020 2076 616c 203d 2061  .        val = a
-00004d80: 7272 6179 5f74 7970 6528 5b69 6e70 2e76  rray_type([inp.v
-00004d90: 616c 2066 6f72 2069 6e70 2069 6e20 696e  al for inp in in
-00004da0: 7075 7473 5d29 0a20 2020 2020 2020 2063  puts]).        c
-00004db0: 6f6e 7374 203d 206d 622e 636f 6e73 7428  onst = mb.const(
-00004dc0: 7661 6c3d 7661 6c2c 206e 616d 653d 6e6f  val=val, name=no
-00004dd0: 6465 2e6e 616d 6529 0a20 2020 2020 2020  de.name).       
-00004de0: 2063 6f6e 7465 7874 2e61 6464 2863 6f6e   context.add(con
-00004df0: 7374 290a 2020 2020 656c 7365 3a0a 2020  st).    else:.  
-00004e00: 2020 2020 2020 2320 4966 2061 7420 6c65        # If at le
-00004e10: 6173 7420 6f6e 6520 696e 7075 7420 746f  ast one input to
-00004e20: 2074 6865 2063 6f6e 7374 7275 6374 206f   the construct o
-00004e30: 7020 6973 206e 6f6e 2d63 6f6e 7374 2c20  p is non-const, 
-00004e40: 636f 6c6c 6563 740a 2020 2020 2020 2020  collect.        
-00004e50: 2320 7468 6520 696e 7075 7473 2061 6e64  # the inputs and
-00004e60: 2061 6464 2074 6865 6d20 6469 7265 6374   add them direct
-00004e70: 6c79 2074 6f20 7468 6520 636f 6e74 6578  ly to the contex
-00004e80: 742e 204f 7073 2074 6861 7420 7573 6520  t. Ops that use 
-00004e90: 7468 6973 0a20 2020 2020 2020 2023 206e  this.        # n
-00004ea0: 6f64 6527 7320 6f75 7470 7574 2077 696c  ode's output wil
-00004eb0: 6c20 7461 6b65 2074 6865 206c 6973 7420  l take the list 
-00004ec0: 6469 7265 6374 6c79 2061 7320 696e 7075  directly as inpu
-00004ed0: 742e 0a20 2020 2020 2020 2063 6f6e 7465  t..        conte
-00004ee0: 7874 2e61 6464 2861 7272 6179 5f74 7970  xt.add(array_typ
-00004ef0: 6528 696e 7075 7473 292c 206e 6f64 652e  e(inputs), node.
-00004f00: 6e61 6d65 290a 0a0a 4072 6567 6973 7465  name)...@registe
-00004f10: 725f 746f 7263 685f 6f70 0a64 6566 2074  r_torch_op.def t
-00004f20: 7570 6c65 636f 6e73 7472 7563 7428 636f  upleconstruct(co
-00004f30: 6e74 6578 742c 206e 6f64 6529 3a0a 2020  ntext, node):.  
-00004f40: 2020 5f61 7272 6179 5f63 6f6e 7374 7275    _array_constru
-00004f50: 6374 2863 6f6e 7465 7874 2c20 6e6f 6465  ct(context, node
-00004f60: 2c20 6172 7261 795f 7479 7065 3d74 7570  , array_type=tup
-00004f70: 6c65 290a 0a0a 4072 6567 6973 7465 725f  le)...@register_
-00004f80: 746f 7263 685f 6f70 0a64 6566 206c 6973  torch_op.def lis
-00004f90: 7463 6f6e 7374 7275 6374 2863 6f6e 7465  tconstruct(conte
-00004fa0: 7874 2c20 6e6f 6465 293a 0a20 2020 205f  xt, node):.    _
-00004fb0: 6172 7261 795f 636f 6e73 7472 7563 7428  array_construct(
-00004fc0: 636f 6e74 6578 742c 206e 6f64 652c 2061  context, node, a
-00004fd0: 7272 6179 5f74 7970 653d 6c69 7374 290a  rray_type=list).
-00004fe0: 0a0a 4072 6567 6973 7465 725f 746f 7263  ..@register_torc
-00004ff0: 685f 6f70 0a64 6566 2065 7128 636f 6e74  h_op.def eq(cont
-00005000: 6578 742c 206e 6f64 6529 3a0a 2020 2020  ext, node):.    
-00005010: 696e 7075 7473 203d 205f 6765 745f 696e  inputs = _get_in
-00005020: 7075 7473 2863 6f6e 7465 7874 2c20 6e6f  puts(context, no
-00005030: 6465 2c20 6578 7065 6374 6564 3d32 290a  de, expected=2).
-00005040: 2020 2020 7820 3d20 696e 7075 7473 5b30      x = inputs[0
-00005050: 5d0a 2020 2020 7920 3d20 696e 7075 7473  ].    y = inputs
-00005060: 5b31 5d0a 2020 2020 6966 2069 735f 626f  [1].    if is_bo
-00005070: 6f6c 2878 2e64 7479 7065 293a 0a20 2020  ol(x.dtype):.   
-00005080: 2020 2020 2078 203d 206d 622e 6361 7374       x = mb.cast
-00005090: 2878 3d78 2c20 6474 7970 653d 2769 6e74  (x=x, dtype='int
-000050a0: 3332 2729 0a20 2020 2069 6620 6973 5f62  32').    if is_b
-000050b0: 6f6f 6c28 792e 6474 7970 6529 3a0a 2020  ool(y.dtype):.  
-000050c0: 2020 2020 2020 7920 3d20 6d62 2e63 6173        y = mb.cas
-000050d0: 7428 783d 792c 2064 7479 7065 3d27 696e  t(x=y, dtype='in
-000050e0: 7433 3227 290a 2020 2020 782c 2079 203d  t32').    x, y =
-000050f0: 2070 726f 6d6f 7465 5f69 6e70 7574 5f64   promote_input_d
-00005100: 7479 7065 7328 5b78 2c20 795d 290a 2020  types([x, y]).  
-00005110: 2020 6571 7561 6c5f 746f 203d 206d 622e    equal_to = mb.
-00005120: 6571 7561 6c28 783d 782c 2079 3d79 2c20  equal(x=x, y=y, 
-00005130: 6e61 6d65 3d6e 6f64 652e 6e61 6d65 290a  name=node.name).
-00005140: 2020 2020 636f 6e74 6578 742e 6164 6428      context.add(
-00005150: 6571 7561 6c5f 746f 290a 0a0a 4072 6567  equal_to)...@reg
-00005160: 6973 7465 725f 746f 7263 685f 6f70 0a64  ister_torch_op.d
-00005170: 6566 206e 6528 636f 6e74 6578 742c 206e  ef ne(context, n
-00005180: 6f64 6529 3a0a 2020 2020 696e 7075 7473  ode):.    inputs
-00005190: 203d 205f 6765 745f 696e 7075 7473 2863   = _get_inputs(c
-000051a0: 6f6e 7465 7874 2c20 6e6f 6465 2c20 6578  ontext, node, ex
-000051b0: 7065 6374 6564 3d32 290a 2020 2020 7820  pected=2).    x 
-000051c0: 3d20 696e 7075 7473 5b30 5d0a 2020 2020  = inputs[0].    
-000051d0: 7920 3d20 696e 7075 7473 5b31 5d0a 2020  y = inputs[1].  
-000051e0: 2020 6966 2069 735f 626f 6f6c 2878 2e64    if is_bool(x.d
-000051f0: 7479 7065 293a 0a20 2020 2020 2020 2078  type):.        x
-00005200: 203d 206d 622e 6361 7374 2878 3d78 2c20   = mb.cast(x=x, 
-00005210: 6474 7970 653d 2769 6e74 3332 2729 0a20  dtype='int32'). 
-00005220: 2020 2069 6620 6973 5f62 6f6f 6c28 792e     if is_bool(y.
-00005230: 6474 7970 6529 3a0a 2020 2020 2020 2020  dtype):.        
-00005240: 7920 3d20 6d62 2e63 6173 7428 783d 792c  y = mb.cast(x=y,
-00005250: 2064 7479 7065 3d27 696e 7433 3227 290a   dtype='int32').
-00005260: 2020 2020 782c 2079 203d 2070 726f 6d6f      x, y = promo
-00005270: 7465 5f69 6e70 7574 5f64 7479 7065 7328  te_input_dtypes(
-00005280: 5b78 2c20 795d 290a 2020 2020 6571 7561  [x, y]).    equa
-00005290: 6c5f 746f 203d 206d 622e 6e6f 745f 6571  l_to = mb.not_eq
-000052a0: 7561 6c28 783d 782c 2079 3d79 2c20 6e61  ual(x=x, y=y, na
-000052b0: 6d65 3d6e 6f64 652e 6e61 6d65 290a 2020  me=node.name).  
-000052c0: 2020 636f 6e74 6578 742e 6164 6428 6571    context.add(eq
-000052d0: 7561 6c5f 746f 290a 0a0a 4072 6567 6973  ual_to)...@regis
-000052e0: 7465 725f 746f 7263 685f 6f70 0a64 6566  ter_torch_op.def
-000052f0: 206c 6528 636f 6e74 6578 742c 206e 6f64   le(context, nod
-00005300: 6529 3a0a 2020 2020 696e 7075 7473 203d  e):.    inputs =
-00005310: 205f 6765 745f 696e 7075 7473 2863 6f6e   _get_inputs(con
-00005320: 7465 7874 2c20 6e6f 6465 2c20 6578 7065  text, node, expe
-00005330: 6374 6564 3d32 290a 2020 2020 782c 2079  cted=2).    x, y
-00005340: 203d 2070 726f 6d6f 7465 5f69 6e70 7574   = promote_input
-00005350: 5f64 7479 7065 7328 696e 7075 7473 290a  _dtypes(inputs).
-00005360: 2020 2020 6c65 7373 5f65 7175 616c 203d      less_equal =
-00005370: 206d 622e 6c65 7373 5f65 7175 616c 2878   mb.less_equal(x
-00005380: 3d78 2c20 793d 792c 206e 616d 653d 6e6f  =x, y=y, name=no
-00005390: 6465 2e6e 616d 6529 0a20 2020 2063 6f6e  de.name).    con
-000053a0: 7465 7874 2e61 6464 286c 6573 735f 6571  text.add(less_eq
-000053b0: 7561 6c29 0a0a 0a40 7265 6769 7374 6572  ual)...@register
-000053c0: 5f74 6f72 6368 5f6f 700a 6465 6620 6c74  _torch_op.def lt
-000053d0: 2863 6f6e 7465 7874 2c20 6e6f 6465 293a  (context, node):
-000053e0: 0a20 2020 2069 6e70 7574 7320 3d20 5f67  .    inputs = _g
-000053f0: 6574 5f69 6e70 7574 7328 636f 6e74 6578  et_inputs(contex
-00005400: 742c 206e 6f64 652c 2065 7870 6563 7465  t, node, expecte
-00005410: 643d 3229 0a20 2020 2078 2c20 7920 3d20  d=2).    x, y = 
-00005420: 7072 6f6d 6f74 655f 696e 7075 745f 6474  promote_input_dt
-00005430: 7970 6573 2869 6e70 7574 7329 0a20 2020  ypes(inputs).   
-00005440: 206c 6573 7320 3d20 6d62 2e6c 6573 7328   less = mb.less(
-00005450: 783d 782c 2079 3d79 2c20 6e61 6d65 3d6e  x=x, y=y, name=n
-00005460: 6f64 652e 6e61 6d65 290a 2020 2020 636f  ode.name).    co
-00005470: 6e74 6578 742e 6164 6428 6c65 7373 290a  ntext.add(less).
-00005480: 0a0a 4072 6567 6973 7465 725f 746f 7263  ..@register_torc
-00005490: 685f 6f70 0a64 6566 2067 6528 636f 6e74  h_op.def ge(cont
-000054a0: 6578 742c 206e 6f64 6529 3a0a 2020 2020  ext, node):.    
-000054b0: 696e 7075 7473 203d 205f 6765 745f 696e  inputs = _get_in
-000054c0: 7075 7473 2863 6f6e 7465 7874 2c20 6e6f  puts(context, no
-000054d0: 6465 2c20 6578 7065 6374 6564 3d32 290a  de, expected=2).
-000054e0: 2020 2020 782c 2079 203d 2070 726f 6d6f      x, y = promo
-000054f0: 7465 5f69 6e70 7574 5f64 7479 7065 7328  te_input_dtypes(
-00005500: 696e 7075 7473 290a 2020 2020 6772 6561  inputs).    grea
-00005510: 7465 725f 6571 7561 6c20 3d20 6d62 2e67  ter_equal = mb.g
-00005520: 7265 6174 6572 5f65 7175 616c 2878 3d78  reater_equal(x=x
-00005530: 2c20 793d 792c 206e 616d 653d 6e6f 6465  , y=y, name=node
-00005540: 2e6e 616d 6529 0a20 2020 2063 6f6e 7465  .name).    conte
-00005550: 7874 2e61 6464 2867 7265 6174 6572 5f65  xt.add(greater_e
-00005560: 7175 616c 290a 0a0a 4072 6567 6973 7465  qual)...@registe
-00005570: 725f 746f 7263 685f 6f70 0a64 6566 2067  r_torch_op.def g
-00005580: 7428 636f 6e74 6578 742c 206e 6f64 6529  t(context, node)
-00005590: 3a0a 2020 2020 696e 7075 7473 203d 205f  :.    inputs = _
-000055a0: 6765 745f 696e 7075 7473 2863 6f6e 7465  get_inputs(conte
-000055b0: 7874 2c20 6e6f 6465 2c20 6578 7065 6374  xt, node, expect
-000055c0: 6564 3d32 290a 2020 2020 782c 2079 203d  ed=2).    x, y =
-000055d0: 2070 726f 6d6f 7465 5f69 6e70 7574 5f64   promote_input_d
-000055e0: 7479 7065 7328 696e 7075 7473 5b3a 325d  types(inputs[:2]
-000055f0: 290a 2020 2020 6772 6561 7465 7220 3d20  ).    greater = 
-00005600: 6d62 2e67 7265 6174 6572 2878 3d78 2c20  mb.greater(x=x, 
-00005610: 793d 792c 206e 616d 653d 6e6f 6465 2e6e  y=y, name=node.n
-00005620: 616d 6529 0a20 2020 2063 6f6e 7465 7874  ame).    context
-00005630: 2e61 6464 2867 7265 6174 6572 290a 0a0a  .add(greater)...
-00005640: 4072 6567 6973 7465 725f 746f 7263 685f  @register_torch_
-00005650: 6f70 2874 6f72 6368 5f61 6c69 6173 3d5b  op(torch_alias=[
-00005660: 2274 225d 290a 6465 6620 7472 616e 7370  "t"]).def transp
-00005670: 6f73 6528 636f 6e74 6578 742c 206e 6f64  ose(context, nod
-00005680: 6529 3a0a 2020 2020 6173 7365 7274 206c  e):.    assert l
-00005690: 656e 286e 6f64 652e 6f75 7470 7574 7329  en(node.outputs)
-000056a0: 203d 3d20 310a 2020 2020 696e 7075 7473   == 1.    inputs
-000056b0: 203d 205f 6765 745f 696e 7075 7473 2863   = _get_inputs(c
-000056c0: 6f6e 7465 7874 2c20 6e6f 6465 290a 2020  ontext, node).  
-000056d0: 2020 7820 3d20 696e 7075 7473 5b30 5d0a    x = inputs[0].
-000056e0: 0a20 2020 2069 6620 6c65 6e28 6e6f 6465  .    if len(node
-000056f0: 2e69 6e70 7574 7329 203d 3d20 313a 0a20  .inputs) == 1:. 
-00005700: 2020 2020 2020 2023 2050 7954 6f72 6368         # PyTorch
-00005710: 2068 6173 2073 6576 6572 616c 2074 7261   has several tra
-00005720: 6e73 706f 7365 206f 7073 2074 6861 7420  nspose ops that 
-00005730: 6361 6e20 6265 2065 6d69 7474 6564 2e20  can be emitted. 
-00005740: 5468 6973 206f 6e65 2069 7320 6f6e 6c79  This one is only
-00005750: 0a20 2020 2020 2020 2023 2065 6d69 7474  .        # emitt
-00005760: 6564 2077 6865 6e20 2e74 2829 2069 7320  ed when .t() is 
-00005770: 6361 6c6c 6564 206f 6e20 6120 7465 6e73  called on a tens
-00005780: 6f72 2c20 7768 6963 6820 6d65 616e 7320  or, which means 
-00005790: 6974 2063 616e 206f 6e6c 7920 6265 0a20  it can only be. 
-000057a0: 2020 2020 2020 2023 2063 616c 6c65 6420         # called 
-000057b0: 6f6e 2061 206d 6174 7269 782e 0a20 2020  on a matrix..   
-000057c0: 2020 2020 2069 6620 6c65 6e28 782e 7368       if len(x.sh
-000057d0: 6170 6529 203e 2032 3a0a 2020 2020 2020  ape) > 2:.      
-000057e0: 2020 2020 2020 7261 6973 6520 5661 6c75        raise Valu
-000057f0: 6545 7272 6f72 2822 7472 616e 7370 6f73  eError("transpos
-00005800: 6520 7769 7468 6f75 7420 6469 6d73 2066  e without dims f
-00005810: 6f72 2072 616e 6b20 3e20 3220 6973 2075  or rank > 2 is u
-00005820: 6e73 7570 706f 7274 6564 2229 0a20 2020  nsupported").   
-00005830: 2020 2020 2072 6573 203d 206d 622e 7472       res = mb.tr
-00005840: 616e 7370 6f73 6528 783d 782c 2070 6572  anspose(x=x, per
-00005850: 6d3d 5b31 2c20 305d 2c20 6e61 6d65 3d6e  m=[1, 0], name=n
-00005860: 6f64 652e 6e61 6d65 290a 2020 2020 656c  ode.name).    el
-00005870: 7365 3a0a 2020 2020 2020 2020 6173 7365  se:.        asse
-00005880: 7274 206c 656e 2869 6e70 7574 7329 203d  rt len(inputs) =
-00005890: 3d20 330a 2020 2020 2020 2020 6178 3020  = 3.        ax0 
-000058a0: 3d20 696e 7075 7473 5b31 5d2e 7661 6c0a  = inputs[1].val.
-000058b0: 2020 2020 2020 2020 6178 3120 3d20 696e          ax1 = in
-000058c0: 7075 7473 5b32 5d2e 7661 6c0a 0a20 2020  puts[2].val..   
-000058d0: 2020 2020 2070 6572 6d20 3d20 6c69 7374       perm = list
-000058e0: 2872 616e 6765 286c 656e 2878 2e73 6861  (range(len(x.sha
-000058f0: 7065 2929 290a 2020 2020 2020 2020 7065  pe))).        pe
-00005900: 726d 5b61 7830 5d20 3d20 6178 310a 2020  rm[ax0] = ax1.  
-00005910: 2020 2020 2020 7065 726d 5b61 7831 5d20        perm[ax1] 
-00005920: 3d20 6178 300a 0a20 2020 2020 2020 2072  = ax0..        r
-00005930: 6573 203d 206d 622e 7472 616e 7370 6f73  es = mb.transpos
-00005940: 6528 783d 782c 2070 6572 6d3d 7065 726d  e(x=x, perm=perm
-00005950: 2c20 6e61 6d65 3d6e 6f64 652e 6e61 6d65  , name=node.name
-00005960: 290a 2020 2020 636f 6e74 6578 742e 6164  ).    context.ad
-00005970: 6428 7265 7329 0a0a 0a40 7265 6769 7374  d(res)...@regist
-00005980: 6572 5f74 6f72 6368 5f6f 700a 6465 6620  er_torch_op.def 
-00005990: 7065 726d 7574 6528 636f 6e74 6578 742c  permute(context,
-000059a0: 206e 6f64 6529 3a0a 2020 2020 696e 7075   node):.    inpu
-000059b0: 7473 203d 205f 6765 745f 696e 7075 7473  ts = _get_inputs
-000059c0: 2863 6f6e 7465 7874 2c20 6e6f 6465 2c20  (context, node, 
-000059d0: 6578 7065 6374 6564 3d32 290a 2020 2020  expected=2).    
-000059e0: 7065 726d 203d 206d 622e 7472 616e 7370  perm = mb.transp
-000059f0: 6f73 6528 783d 696e 7075 7473 5b30 5d2c  ose(x=inputs[0],
-00005a00: 2070 6572 6d3d 696e 7075 7473 5b31 5d2c   perm=inputs[1],
-00005a10: 206e 616d 653d 6e6f 6465 2e6e 616d 6529   name=node.name)
-00005a20: 0a20 2020 2063 6f6e 7465 7874 2e61 6464  .    context.add
-00005a30: 2870 6572 6d29 0a0a 0a40 7265 6769 7374  (perm)...@regist
-00005a40: 6572 5f74 6f72 6368 5f6f 700a 6465 6620  er_torch_op.def 
-00005a50: 6672 6163 2863 6f6e 7465 7874 2c20 6e6f  frac(context, no
-00005a60: 6465 293a 0a20 2020 2023 2046 7261 6328  de):.    # Frac(
-00005a70: 7829 203d 2078 202d 2066 6c6f 6f72 2861  x) = x - floor(a
-00005a80: 6273 2878 2929 202a 2073 6967 6e28 7829  bs(x)) * sign(x)
-00005a90: 0a0a 2020 2020 7820 3d20 5f67 6574 5f69  ..    x = _get_i
-00005aa0: 6e70 7574 7328 636f 6e74 6578 742c 206e  nputs(context, n
-00005ab0: 6f64 652c 2065 7870 6563 7465 643d 3129  ode, expected=1)
-00005ac0: 5b30 5d0a 2020 2020 666c 6f6f 725f 6162  [0].    floor_ab
-00005ad0: 7320 3d20 6d62 2e66 6c6f 6f72 2878 3d6d  s = mb.floor(x=m
-00005ae0: 622e 6162 7328 783d 7829 290a 2020 2020  b.abs(x=x)).    
-00005af0: 7369 676e 5f61 6273 5f66 6c6f 6f72 203d  sign_abs_floor =
-00005b00: 206d 622e 6d75 6c28 783d 666c 6f6f 725f   mb.mul(x=floor_
-00005b10: 6162 732c 2079 3d6d 622e 7369 676e 2878  abs, y=mb.sign(x
-00005b20: 3d78 2929 0a20 2020 2072 6573 203d 206d  =x)).    res = m
-00005b30: 622e 7375 6228 783d 782c 2079 3d73 6967  b.sub(x=x, y=sig
-00005b40: 6e5f 6162 735f 666c 6f6f 7229 0a20 2020  n_abs_floor).   
-00005b50: 2063 6f6e 7465 7874 2e61 6464 2872 6573   context.add(res
-00005b60: 2c20 746f 7263 685f 6e61 6d65 3d6e 6f64  , torch_name=nod
-00005b70: 652e 6e61 6d65 290a 0a0a 4072 6567 6973  e.name)...@regis
-00005b80: 7465 725f 746f 7263 685f 6f70 0a64 6566  ter_torch_op.def
-00005b90: 2070 6978 656c 5f73 6875 6666 6c65 2863   pixel_shuffle(c
-00005ba0: 6f6e 7465 7874 2c20 6e6f 6465 293a 0a20  ontext, node):. 
-00005bb0: 2020 2069 6e70 7574 7320 3d20 5f67 6574     inputs = _get
-00005bc0: 5f69 6e70 7574 7328 636f 6e74 6578 742c  _inputs(context,
-00005bd0: 206e 6f64 652c 2065 7870 6563 7465 643d   node, expected=
-00005be0: 3229 0a20 2020 2070 6572 6d20 3d20 6d62  2).    perm = mb
-00005bf0: 2e70 6978 656c 5f73 6875 6666 6c65 2878  .pixel_shuffle(x
-00005c00: 3d69 6e70 7574 735b 305d 2c20 7570 7363  =inputs[0], upsc
-00005c10: 616c 655f 6661 6374 6f72 3d69 6e70 7574  ale_factor=input
-00005c20: 735b 315d 2c20 6e61 6d65 3d6e 6f64 652e  s[1], name=node.
-00005c30: 6e61 6d65 290a 2020 2020 636f 6e74 6578  name).    contex
-00005c40: 742e 6164 6428 7065 726d 290a 0a0a 4072  t.add(perm)...@r
-00005c50: 6567 6973 7465 725f 746f 7263 685f 6f70  egister_torch_op
-00005c60: 0a64 6566 2070 6978 656c 5f75 6e73 6875  .def pixel_unshu
-00005c70: 6666 6c65 2863 6f6e 7465 7874 2c20 6e6f  ffle(context, no
-00005c80: 6465 293a 0a20 2020 2069 6e70 7574 7320  de):.    inputs 
-00005c90: 3d20 5f67 6574 5f69 6e70 7574 7328 636f  = _get_inputs(co
-00005ca0: 6e74 6578 742c 206e 6f64 652c 2065 7870  ntext, node, exp
-00005cb0: 6563 7465 643d 3229 0a20 2020 2064 6f77  ected=2).    dow
-00005cc0: 6e73 6361 6c65 5f66 6163 746f 7220 3d20  nscale_factor = 
-00005cd0: 5f6e 702e 7569 6e74 3332 2869 6e70 7574  _np.uint32(input
-00005ce0: 735b 315d 2e76 616c 290a 2020 2020 7065  s[1].val).    pe
-00005cf0: 726d 203d 206d 622e 7069 7865 6c5f 756e  rm = mb.pixel_un
-00005d00: 7368 7566 666c 6528 783d 696e 7075 7473  shuffle(x=inputs
-00005d10: 5b30 5d2c 2064 6f77 6e73 6361 6c65 5f66  [0], downscale_f
-00005d20: 6163 746f 723d 646f 776e 7363 616c 655f  actor=downscale_
-00005d30: 6661 6374 6f72 2c20 6e61 6d65 3d6e 6f64  factor, name=nod
-00005d40: 652e 6e61 6d65 290a 2020 2020 636f 6e74  e.name).    cont
-00005d50: 6578 742e 6164 6428 7065 726d 290a 0a0a  ext.add(perm)...
-00005d60: 4072 6567 6973 7465 725f 746f 7263 685f  @register_torch_
-00005d70: 6f70 2874 6f72 6368 5f61 6c69 6173 3d5b  op(torch_alias=[
-00005d80: 2262 6d6d 225d 290a 6465 6620 6d61 746d  "bmm"]).def matm
-00005d90: 756c 2863 6f6e 7465 7874 2c20 6e6f 6465  ul(context, node
-00005da0: 293a 0a20 2020 2069 6e70 7574 7320 3d20  ):.    inputs = 
-00005db0: 5f67 6574 5f69 6e70 7574 7328 636f 6e74  _get_inputs(cont
-00005dc0: 6578 742c 206e 6f64 652c 2065 7870 6563  ext, node, expec
-00005dd0: 7465 643d 3229 0a20 2020 2069 6620 696e  ted=2).    if in
-00005de0: 7075 7473 5b31 5d2e 7661 6c20 6973 206e  puts[1].val is n
-00005df0: 6f74 204e 6f6e 6520 616e 6420 5c0a 2020  ot None and \.  
-00005e00: 2020 2020 2020 2020 2020 6c65 6e28 696e            len(in
-00005e10: 7075 7473 5b31 5d2e 7368 6170 6529 203d  puts[1].shape) =
-00005e20: 3d20 3220 616e 6420 6c65 6e28 696e 7075  = 2 and len(inpu
-00005e30: 7473 5b30 5d2e 7368 6170 6529 203c 3d20  ts[0].shape) <= 
-00005e40: 333a 0a20 2020 2020 2020 2072 6573 203d  3:.        res =
-00005e50: 206d 622e 6c69 6e65 6172 2878 3d69 6e70   mb.linear(x=inp
-00005e60: 7574 735b 305d 2c20 7765 6967 6874 3d5f  uts[0], weight=_
-00005e70: 6e70 2e74 7261 6e73 706f 7365 2869 6e70  np.transpose(inp
-00005e80: 7574 735b 315d 2e76 616c 292c 206e 616d  uts[1].val), nam
-00005e90: 653d 6e6f 6465 2e6e 616d 6529 0a20 2020  e=node.name).   
-00005ea0: 2065 6c73 653a 0a20 2020 2020 2020 2072   else:.        r
-00005eb0: 6573 203d 206d 622e 6d61 746d 756c 2878  es = mb.matmul(x
-00005ec0: 3d69 6e70 7574 735b 305d 2c20 793d 696e  =inputs[0], y=in
-00005ed0: 7075 7473 5b31 5d2c 206e 616d 653d 6e6f  puts[1], name=no
-00005ee0: 6465 2e6e 616d 6529 0a20 2020 2063 6f6e  de.name).    con
-00005ef0: 7465 7874 2e61 6464 2872 6573 290a 0a0a  text.add(res)...
-00005f00: 4072 6567 6973 7465 725f 746f 7263 685f  @register_torch_
-00005f10: 6f70 0a64 6566 2061 6464 2863 6f6e 7465  op.def add(conte
-00005f20: 7874 2c20 6e6f 6465 293a 0a20 2020 2061  xt, node):.    a
-00005f30: 6464 5f69 6e70 7574 7320 3d20 5f67 6574  dd_inputs = _get
-00005f40: 5f69 6e70 7574 7328 636f 6e74 6578 742c  _inputs(context,
-00005f50: 206e 6f64 6529 0a20 2020 2061 7373 6572   node).    asser
-00005f60: 7420 6c65 6e28 6e6f 6465 2e6f 7574 7075  t len(node.outpu
-00005f70: 7473 2920 3d3d 2031 0a0a 2020 2020 2320  ts) == 1..    # 
-00005f80: 544f 444f 2028 7362 6572 6172 6469 293a  TODO (sberardi):
-00005f90: 2033 7264 2070 6172 616d 2074 6f20 6174   3rd param to at
-00005fa0: 656e 3a3a 6164 6420 6973 2061 2073 6361  en::add is a sca
-00005fb0: 6c65 2066 6163 746f 722c 206e 6565 6420  le factor, need 
-00005fc0: 746f 2068 616e 646c 6520 7468 6174 2e0a  to handle that..
-00005fd0: 2020 2020 2320 6f75 743d 696e 7075 742b      # out=input+
-00005fe0: 616c 7068 6120 7820 6f74 6865 720a 2020  alpha x other.  
-00005ff0: 2020 2320 7264 6172 3a2f 2f36 3031 3735    # rdar://60175
-00006000: 3733 360a 2020 2020 6966 206c 656e 2861  736.    if len(a
-00006010: 6464 5f69 6e70 7574 7329 203e 2032 2061  dd_inputs) > 2 a
-00006020: 6e64 2061 6464 5f69 6e70 7574 735b 325d  nd add_inputs[2]
-00006030: 2e76 616c 2021 3d20 313a 0a20 2020 2020  .val != 1:.     
-00006040: 2020 2072 6169 7365 2056 616c 7565 4572     raise ValueEr
-00006050: 726f 7228 2241 4444 2064 6f65 7320 6e6f  ror("ADD does no
-00006060: 7420 7375 7070 6f72 7420 7363 616c 6520  t support scale 
-00006070: 6661 6374 6f72 2070 6172 616d 2229 0a20  factor param"). 
-00006080: 2020 2078 2c20 7920 3d20 7072 6f6d 6f74     x, y = promot
-00006090: 655f 696e 7075 745f 6474 7970 6573 2861  e_input_dtypes(a
-000060a0: 6464 5f69 6e70 7574 735b 3a32 5d29 0a20  dd_inputs[:2]). 
-000060b0: 2020 2061 6464 5f6e 6f64 6520 3d20 6d62     add_node = mb
-000060c0: 2e61 6464 2878 3d78 2c20 793d 792c 206e  .add(x=x, y=y, n
-000060d0: 616d 653d 6e6f 6465 2e6e 616d 6529 0a20  ame=node.name). 
-000060e0: 2020 2063 6f6e 7465 7874 2e61 6464 2861     context.add(a
-000060f0: 6464 5f6e 6f64 6529 0a0a 0a40 7265 6769  dd_node)...@regi
-00006100: 7374 6572 5f74 6f72 6368 5f6f 700a 6465  ster_torch_op.de
-00006110: 6620 6375 6d73 756d 2863 6f6e 7465 7874  f cumsum(context
-00006120: 2c20 6e6f 6465 293a 0a20 2020 2069 6e70  , node):.    inp
-00006130: 7574 7320 3d20 5f67 6574 5f69 6e70 7574  uts = _get_input
-00006140: 7328 636f 6e74 6578 742c 206e 6f64 652c  s(context, node,
-00006150: 2065 7870 6563 7465 643d 3329 0a20 2020   expected=3).   
-00006160: 2078 203d 2069 6e70 7574 735b 305d 0a20   x = inputs[0]. 
-00006170: 2020 2069 6620 6973 5f62 6f6f 6c28 782e     if is_bool(x.
-00006180: 6474 7970 6529 3a0a 2020 2020 2020 2020  dtype):.        
-00006190: 7820 3d20 6d62 2e63 6173 7428 783d 782c  x = mb.cast(x=x,
-000061a0: 2064 7479 7065 3d27 696e 7433 3227 290a   dtype='int32').
-000061b0: 2020 2020 7265 7320 3d20 6d62 2e63 756d      res = mb.cum
-000061c0: 7375 6d28 783d 782c 2061 7869 733d 696e  sum(x=x, axis=in
-000061d0: 7075 7473 5b31 5d2c 206e 616d 653d 6e6f  puts[1], name=no
-000061e0: 6465 2e6e 616d 6529 0a20 2020 2063 6f6e  de.name).    con
-000061f0: 7465 7874 2e61 6464 2872 6573 290a 0a0a  text.add(res)...
-00006200: 4072 6567 6973 7465 725f 746f 7263 685f  @register_torch_
-00006210: 6f70 0a64 6566 2061 6464 6d6d 2863 6f6e  op.def addmm(con
-00006220: 7465 7874 2c20 6e6f 6465 293a 0a20 2020  text, node):.   
-00006230: 2023 2061 6464 6d6d 2854 656e 736f 7220   # addmm(Tensor 
-00006240: 696e 7075 742c 2054 656e 736f 7220 6d61  input, Tensor ma
-00006250: 7431 2c20 5465 6e73 6f72 206d 6174 322c  t1, Tensor mat2,
-00006260: 2053 6361 6c61 7220 6265 7461 3d31 2c20   Scalar beta=1, 
-00006270: 5363 616c 6172 2061 6c70 6861 3d31 290a  Scalar alpha=1).
-00006280: 2020 2020 2320 6f75 7470 7574 203d 2062      # output = b
-00006290: 6574 6120 2a20 696e 7075 7420 2b20 616c  eta * input + al
-000062a0: 7068 6120 2a20 6d61 7431 202a 206d 6174  pha * mat1 * mat
-000062b0: 320a 0a20 2020 2061 7373 6572 7420 6c65  2..    assert le
-000062c0: 6e28 6e6f 6465 2e6f 7574 7075 7473 2920  n(node.outputs) 
-000062d0: 3d3d 2031 0a20 2020 2069 6e70 7574 7320  == 1.    inputs 
-000062e0: 3d20 5f67 6574 5f69 6e70 7574 7328 636f  = _get_inputs(co
-000062f0: 6e74 6578 742c 206e 6f64 652c 2065 7870  ntext, node, exp
-00006300: 6563 7465 643d 3529 0a20 2020 2062 6961  ected=5).    bia
-00006310: 7320 3d20 696e 7075 7473 5b30 5d0a 2020  s = inputs[0].  
-00006320: 2020 6d61 7431 203d 2069 6e70 7574 735b    mat1 = inputs[
-00006330: 315d 0a20 2020 206d 6174 3220 3d20 696e  1].    mat2 = in
-00006340: 7075 7473 5b32 5d0a 2020 2020 6265 7461  puts[2].    beta
-00006350: 203d 2069 6e70 7574 735b 335d 0a20 2020   = inputs[3].   
-00006360: 2061 6c70 6861 203d 2069 6e70 7574 735b   alpha = inputs[
-00006370: 345d 0a0a 2020 2020 6966 2062 6574 612e  4]..    if beta.
-00006380: 7661 6c20 213d 2031 2e30 3a0a 2020 2020  val != 1.0:.    
-00006390: 2020 2020 2320 4170 706c 7920 7363 616c      # Apply scal
-000063a0: 696e 6720 6661 6374 6f72 2062 6574 6120  ing factor beta 
-000063b0: 746f 2074 6865 2062 6961 732e 0a20 2020  to the bias..   
-000063c0: 2020 2020 2062 6961 7320 3d20 6d62 2e6d       bias = mb.m
-000063d0: 756c 2878 3d62 6574 612c 2079 3d62 6961  ul(x=beta, y=bia
-000063e0: 732c 206e 616d 653d 6269 6173 2e6e 616d  s, name=bias.nam
-000063f0: 6520 2b20 225f 7363 616c 6564 2229 0a20  e + "_scaled"). 
-00006400: 2020 2020 2020 2063 6f6e 7465 7874 2e61         context.a
-00006410: 6464 2862 6961 7329 0a0a 2020 2020 6966  dd(bias)..    if
-00006420: 2061 6c70 6861 2e76 616c 2021 3d20 312e   alpha.val != 1.
-00006430: 303a 0a20 2020 2020 2020 2023 2041 7070  0:.        # App
-00006440: 6c79 2073 6361 6c69 6e67 2066 6163 746f  ly scaling facto
-00006450: 7220 616c 7068 6120 746f 2074 6865 2069  r alpha to the i
-00006460: 6e70 7574 2e0a 2020 2020 2020 2020 6d61  nput..        ma
-00006470: 7431 203d 206d 622e 6d75 6c28 783d 616c  t1 = mb.mul(x=al
-00006480: 7068 612c 2079 3d6d 6174 312c 206e 616d  pha, y=mat1, nam
-00006490: 653d 6d61 7431 2e6e 616d 6520 2b20 225f  e=mat1.name + "_
-000064a0: 7363 616c 6564 2229 0a20 2020 2020 2020  scaled").       
-000064b0: 2063 6f6e 7465 7874 2e61 6464 286d 6174   context.add(mat
-000064c0: 3129 0a0a 2020 2020 2320 4d49 4c20 6c69  1)..    # MIL li
-000064d0: 6e65 6172 2077 696c 6c20 7472 616e 7370  near will transp
-000064e0: 6f73 6520 6d61 7432 2c20 6275 7420 6164  ose mat2, but ad
-000064f0: 646d 6d20 6578 7065 6374 7320 7468 6174  dmm expects that
-00006500: 206d 6174 3120 616e 6420 6d61 7432 0a20   mat1 and mat2. 
-00006510: 2020 2023 2063 616e 206d 756c 7469 706c     # can multipl
-00006520: 7920 6173 2069 732e 2053 6f20 7765 2061  y as is. So we a
-00006530: 6464 2061 2074 7261 6e70 6f73 652e 0a20  dd a tranpose.. 
-00006540: 2020 206d 6174 3220 3d20 6d62 2e74 7261     mat2 = mb.tra
-00006550: 6e73 706f 7365 2878 3d6d 6174 322c 2070  nspose(x=mat2, p
-00006560: 6572 6d3d 5b31 2c20 305d 2c20 6e61 6d65  erm=[1, 0], name
-00006570: 3d6d 6174 322e 6e61 6d65 202b 2022 5f74  =mat2.name + "_t
-00006580: 7261 6e73 706f 7365 6422 290a 2020 2020  ransposed").    
-00006590: 636f 6e74 6578 742e 6164 6428 6d61 7432  context.add(mat2
-000065a0: 290a 0a20 2020 2061 6464 6d6d 5f6e 6f64  )..    addmm_nod
-000065b0: 6520 3d20 6d62 2e6c 696e 6561 7228 783d  e = mb.linear(x=
-000065c0: 6d61 7431 2c20 7765 6967 6874 3d6d 6174  mat1, weight=mat
-000065d0: 322c 2062 6961 733d 6269 6173 2c20 6e61  2, bias=bias, na
-000065e0: 6d65 3d6e 6f64 652e 6e61 6d65 290a 2020  me=node.name).  
-000065f0: 2020 636f 6e74 6578 742e 6164 6428 6164    context.add(ad
-00006600: 646d 6d5f 6e6f 6465 290a 0a0a 4072 6567  dmm_node)...@reg
-00006610: 6973 7465 725f 746f 7263 685f 6f70 0a64  ister_torch_op.d
-00006620: 6566 206c 696e 6561 7228 636f 6e74 6578  ef linear(contex
-00006630: 742c 206e 6f64 6529 3a0a 2020 2020 696e  t, node):.    in
-00006640: 7075 7473 203d 205f 6765 745f 696e 7075  puts = _get_inpu
-00006650: 7473 2863 6f6e 7465 7874 2c20 6e6f 6465  ts(context, node
-00006660: 2c20 6578 7065 6374 6564 3d5b 322c 2033  , expected=[2, 3
-00006670: 5d29 0a20 2020 2078 203d 2069 6e70 7574  ]).    x = input
-00006680: 735b 305d 0a20 2020 2057 203d 2069 6e70  s[0].    W = inp
-00006690: 7574 735b 315d 0a20 2020 2062 6961 7320  uts[1].    bias 
-000066a0: 3d20 696e 7075 7473 5b32 5d20 6966 206c  = inputs[2] if l
-000066b0: 656e 286e 6f64 652e 696e 7075 7473 2920  en(node.inputs) 
-000066c0: 3d3d 2033 2065 6c73 6520 4e6f 6e65 0a20  == 3 else None. 
-000066d0: 2020 2072 6573 203d 206d 622e 6c69 6e65     res = mb.line
-000066e0: 6172 2878 3d78 2c20 7765 6967 6874 3d57  ar(x=x, weight=W
-000066f0: 2c20 6269 6173 3d62 6961 732c 206e 616d  , bias=bias, nam
-00006700: 653d 6e6f 6465 2e6e 616d 6529 0a20 2020  e=node.name).   
-00006710: 2063 6f6e 7465 7874 2e61 6464 2872 6573   context.add(res
-00006720: 290a 0a0a 4072 6567 6973 7465 725f 746f  )...@register_to
-00006730: 7263 685f 6f70 2874 6f72 6368 5f61 6c69  rch_op(torch_ali
-00006740: 6173 3d5b 2263 6f6e 7632 6422 5d29 0a64  as=["conv2d"]).d
-00006750: 6566 205f 636f 6e76 6f6c 7574 696f 6e28  ef _convolution(
-00006760: 636f 6e74 6578 742c 206e 6f64 6529 3a0a  context, node):.
-00006770: 2020 2020 696e 7075 7473 203d 205f 6765      inputs = _ge
-00006780: 745f 696e 7075 7473 2863 6f6e 7465 7874  t_inputs(context
-00006790: 2c20 6e6f 6465 290a 0a20 2020 2078 203d  , node)..    x =
-000067a0: 2069 6e70 7574 735b 305d 0a20 2020 2023   inputs[0].    #
-000067b0: 2050 7954 6f72 6368 2061 6e64 204d 494c   PyTorch and MIL
-000067c0: 2068 6173 2073 616d 6520 7765 6967 6874   has same weight
-000067d0: 206c 6179 6f75 740a 2020 2020 2320 436f   layout.    # Co
-000067e0: 6e76 3a20 5b43 6f75 742c 2043 696e 2c20  nv: [Cout, Cin, 
-000067f0: 2a44 5d0a 2020 2020 2320 436f 6e76 5472  *D].    # ConvTr
-00006800: 616e 7370 6f73 653a 205b 4369 6e2c 2043  anspose: [Cin, C
-00006810: 6f75 742c 202a 445d 0a20 2020 2077 6569  out, *D].    wei
-00006820: 6768 7420 3d20 696e 7075 7473 5b31 5d0a  ght = inputs[1].
-00006830: 2020 2020 6269 6173 203d 2069 6e70 7574      bias = input
-00006840: 735b 325d 0a20 2020 2073 7472 6964 6573  s[2].    strides
-00006850: 203d 2069 6e70 7574 735b 335d 0a0a 2020   = inputs[3]..  
-00006860: 2020 782c 2077 6569 6768 7420 3d20 7072    x, weight = pr
-00006870: 6f6d 6f74 655f 696e 7075 745f 6474 7970  omote_input_dtyp
-00006880: 6573 285b 782c 2077 6569 6768 745d 290a  es([x, weight]).
-00006890: 0a20 2020 2023 2045 7870 616e 6420 7061  .    # Expand pa
-000068a0: 6464 696e 672e 2054 6f72 6368 2061 6363  dding. Torch acc
-000068b0: 6570 7473 2065 6974 6865 7220 616e 2069  epts either an i
-000068c0: 6e74 2028 666f 7220 616c 6c20 6469 6d65  nt (for all dime
-000068d0: 6e73 696f 6e73 2920 6f72 2061 6e20 6e2d  nsions) or an n-
-000068e0: 7475 706c 6520 6f66 2069 6e74 7320 286f  tuple of ints (o
-000068f0: 6e65 2070 6572 2064 696d 656e 7369 6f6e  ne per dimension
-00006900: 292c 2062 7574 0a20 2020 2023 2077 6520  ), but.    # we 
-00006910: 7265 7175 6972 6520 6120 2832 202a 206e  require a (2 * n
-00006920: 292d 7475 706c 652c 2077 6865 7265 206e  )-tuple, where n
-00006930: 2069 7320 7468 6520 6e75 6d62 6572 206f   is the number o
-00006940: 6620 7370 6174 6961 6c20 6469 6d65 6e73  f spatial dimens
-00006950: 696f 6e73 2c20 7374 6172 7420 616e 6420  ions, start and 
-00006960: 656e 6420 666f 7220 6561 6368 2073 7061  end for each spa
-00006970: 7469 616c 2064 696d 656e 7369 6f6e 0a20  tial dimension. 
-00006980: 2020 2070 6164 203d 2069 6e70 7574 735b     pad = inputs[
-00006990: 345d 2e76 616c 0a0a 2020 2020 6966 206c  4].val..    if l
-000069a0: 656e 2877 6569 6768 742e 7368 6170 6529  en(weight.shape)
-000069b0: 2069 6e20 2833 2c20 3429 3a0a 2020 2020   in (3, 4):.    
-000069c0: 2020 2020 2320 3144 2061 6e64 2032 443a      # 1D and 2D:
-000069d0: 204e 6565 6420 746f 2065 7870 6c69 6369   Need to explici
-000069e0: 746c 7920 7374 6174 6520 4c2d 522c 2054  tly state L-R, T
-000069f0: 2d42 2070 6164 0a20 2020 2020 2020 2070  -B pad.        p
-00006a00: 6164 203d 205f 6e70 2e72 6570 6561 7428  ad = _np.repeat(
-00006a10: 7061 642c 2032 290a 2020 2020 656c 6966  pad, 2).    elif
-00006a20: 206c 656e 2877 6569 6768 742e 7368 6170   len(weight.shap
-00006a30: 6529 203d 3d20 353a 0a20 2020 2020 2020  e) == 5:.       
-00006a40: 2023 2033 443a 204e 6565 6420 746f 2065   # 3D: Need to e
-00006a50: 7870 6c69 6369 746c 7920 7374 6174 6520  xplicitly state 
-00006a60: 462d 426b 2c20 4c2d 522c 2054 2d42 2070  F-Bk, L-R, T-B p
-00006a70: 6164 0a20 2020 2020 2020 2069 6620 7479  ad.        if ty
-00006a80: 7065 2870 6164 2920 3d3d 2069 6e74 3a0a  pe(pad) == int:.
-00006a90: 2020 2020 2020 2020 2020 2020 7061 6420              pad 
-00006aa0: 3d20 5f6e 702e 7265 7065 6174 2870 6164  = _np.repeat(pad
-00006ab0: 2c20 3629 0a20 2020 2020 2020 2065 6c69  , 6).        eli
-00006ac0: 6620 6c65 6e28 7061 6429 203d 3d20 333a  f len(pad) == 3:
-00006ad0: 0a20 2020 2020 2020 2020 2020 2070 6164  .            pad
-00006ae0: 203d 205f 6e70 2e72 6570 6561 7428 7061   = _np.repeat(pa
-00006af0: 642c 2032 290a 2020 2020 656c 7365 3a0a  d, 2).    else:.
-00006b00: 2020 2020 2020 2020 7261 6973 6520 5661          raise Va
-00006b10: 6c75 6545 7272 6f72 280a 2020 2020 2020  lueError(.      
-00006b20: 2020 2020 2020 2249 6e76 616c 6964 2077        "Invalid w
-00006b30: 6569 6768 7420 6469 6d65 6e73 696f 6e2e  eight dimension.
-00006b40: 204d 7573 7420 6265 2033 2c20 342c 206f   Must be 3, 4, o
-00006b50: 7220 3520 666f 7220 3144 2c20 3244 2c20  r 5 for 1D, 2D, 
-00006b60: 6f72 2033 4420 636f 6e76 6f6c 7574 696f  or 3D convolutio
-00006b70: 6e2c 2072 6573 7065 6374 6976 656c 792e  n, respectively.
-00006b80: 220a 2020 2020 2020 2020 290a 0a20 2020  ".        )..   
-00006b90: 2064 696c 6174 696f 6e73 203d 2069 6e70   dilations = inp
-00006ba0: 7574 735b 355d 0a20 2020 206f 7574 5f70  uts[5].    out_p
-00006bb0: 6164 203d 204e 6f6e 650a 2020 2020 6966  ad = None.    if
-00006bc0: 206c 656e 2869 6e70 7574 7329 203e 3d20   len(inputs) >= 
-00006bd0: 3132 3a0a 2020 2020 2020 2020 7472 616e  12:.        tran
-00006be0: 7370 6f73 6564 203d 2069 6e70 7574 735b  sposed = inputs[
-00006bf0: 365d 2e76 616c 0a20 2020 2020 2020 206f  6].val.        o
-00006c00: 7574 5f70 6164 203d 2069 6e70 7574 735b  ut_pad = inputs[
-00006c10: 375d 2e76 616c 0a20 2020 2020 2020 2067  7].val.        g
-00006c20: 726f 7570 203d 2069 6e70 7574 735b 385d  roup = inputs[8]
-00006c30: 0a20 2020 2065 6c69 6620 6c65 6e28 696e  .    elif len(in
-00006c40: 7075 7473 2920 3d3d 2037 3a0a 2020 2020  puts) == 7:.    
-00006c50: 2020 2020 7472 616e 7370 6f73 6564 203d      transposed =
-00006c60: 2046 616c 7365 0a20 2020 2020 2020 2067   False.        g
-00006c70: 726f 7570 203d 2069 6e70 7574 735b 365d  roup = inputs[6]
-00006c80: 0a20 2020 2065 6c73 653a 0a20 2020 2020  .    else:.     
-00006c90: 2020 2072 6169 7365 2056 616c 7565 4572     raise ValueEr
-00006ca0: 726f 7228 0a20 2020 2020 2020 2020 2020  ror(.           
-00006cb0: 2022 756e 6578 7065 6374 6564 206e 756d   "unexpected num
-00006cc0: 6265 7220 6f66 2069 6e70 7574 7320 666f  ber of inputs fo
-00006cd0: 7220 6e6f 6465 207b 7d20 287b 7d29 3a20  r node {} ({}): 
-00006ce0: 7b7d 222e 666f 726d 6174 280a 2020 2020  {}".format(.    
-00006cf0: 2020 2020 2020 2020 2020 2020 6e6f 6465              node
-00006d00: 2e6e 616d 652c 206e 6f64 652e 6b69 6e64  .name, node.kind
-00006d10: 2c20 6c65 6e28 696e 7075 7473 290a 2020  , len(inputs).  
-00006d20: 2020 2020 2020 2020 2020 290a 2020 2020            ).    
-00006d30: 2020 2020 290a 0a20 2020 206b 7761 7267      )..    kwarg
-00006d40: 7320 3d20 7b0a 2020 2020 2020 2020 2278  s = {.        "x
-00006d50: 223a 2078 2c0a 2020 2020 2020 2020 2277  ": x,.        "w
-00006d60: 6569 6768 7422 3a20 7765 6967 6874 2c0a  eight": weight,.
-00006d70: 2020 2020 2020 2020 2273 7472 6964 6573          "strides
-00006d80: 223a 2073 7472 6964 6573 2c0a 2020 2020  ": strides,.    
-00006d90: 2020 2020 2270 6164 5f74 7970 6522 3a20      "pad_type": 
-00006da0: 2263 7573 746f 6d22 2c0a 2020 2020 2020  "custom",.      
-00006db0: 2020 2270 6164 223a 2070 6164 2c0a 2020    "pad": pad,.  
-00006dc0: 2020 2020 2020 2264 696c 6174 696f 6e73        "dilations
-00006dd0: 223a 2064 696c 6174 696f 6e73 2c0a 2020  ": dilations,.  
-00006de0: 2020 2020 2020 2267 726f 7570 7322 3a20        "groups": 
-00006df0: 6772 6f75 702c 0a20 2020 2020 2020 2022  group,.        "
-00006e00: 6e61 6d65 223a 206e 6f64 652e 6e61 6d65  name": node.name
-00006e10: 2c0a 2020 2020 7d0a 2020 2020 2320 4269  ,.    }.    # Bi
-00006e20: 6173 2069 7320 6f70 7469 6f6e 616c 2069  as is optional i
-00006e30: 6e20 5079 546f 7263 6827 7320 636f 6e76  n PyTorch's conv
-00006e40: 6f6c 7574 696f 6e2e 0a20 2020 2069 6620  olution..    if 
-00006e50: 6269 6173 2069 7320 6e6f 7420 4e6f 6e65  bias is not None
-00006e60: 3a0a 2020 2020 2020 2020 6b77 6172 6773  :.        kwargs
-00006e70: 5b22 6269 6173 225d 203d 2062 6961 730a  ["bias"] = bias.
-00006e80: 0a20 2020 2069 6620 7472 616e 7370 6f73  .    if transpos
-00006e90: 6564 2069 7320 5472 7565 3a0a 2020 2020  ed is True:.    
-00006ea0: 2020 2020 2320 5472 616e 7370 6f73 6564      # Transposed
-00006eb0: 2063 6f6e 766f 6c75 7469 6f6e 0a20 2020   convolution.   
-00006ec0: 2020 2020 2023 2048 616e 646c 6520 6f75       # Handle ou
-00006ed0: 7470 7574 5f70 6164 6469 6e67 2075 7369  tput_padding usi
-00006ee0: 6e67 2070 7265 2d70 6164 206f 7220 706f  ng pre-pad or po
-00006ef0: 7374 2d63 726f 700a 2020 2020 2020 2020  st-crop.        
-00006f00: 7072 655f 7061 6420 3d20 5b30 5d20 2a20  pre_pad = [0] * 
-00006f10: 6c65 6e28 7061 6429 0a20 2020 2020 2020  len(pad).       
-00006f20: 2070 6f73 745f 6372 6f70 203d 205b 305d   post_crop = [0]
-00006f30: 202a 206c 656e 2870 6164 290a 0a20 2020   * len(pad)..   
-00006f40: 2020 2020 2069 6620 6f75 745f 7061 6420       if out_pad 
-00006f50: 6973 206e 6f74 204e 6f6e 6520 616e 6420  is not None and 
-00006f60: 616e 7928 6f75 745f 7061 6429 3a0a 2020  any(out_pad):.  
-00006f70: 2020 2020 2020 2020 2020 6f75 7470 7574            output
-00006f80: 5f70 6164 6469 6e67 203d 205b 305d 202a  _padding = [0] *
-00006f90: 206c 656e 2870 6164 290a 2020 2020 2020   len(pad).      
-00006fa0: 2020 2020 2020 2320 6f75 7470 7574 2070        # output p
-00006fb0: 6164 6469 6e67 2061 6464 7320 6164 6469  adding adds addi
-00006fc0: 7469 6f6e 616c 2070 6164 6469 6e67 206f  tional padding o
-00006fd0: 6e20 6f6e 6520 6f66 2074 6865 2073 6964  n one of the sid
-00006fe0: 6520 6f66 2064 696d 656e 7369 6f6e 0a20  e of dimension. 
-00006ff0: 2020 2020 2020 2020 2020 2023 2069 2e65             # i.e
-00007000: 2e20 626f 7474 6f6d 2066 726f 6d20 746f  . bottom from to
-00007010: 702d 626f 7474 6f6d 2c0a 2020 2020 2020  p-bottom,.      
-00007020: 2020 2020 2020 2320 2020 2020 2072 6967        #      rig
-00007030: 6874 2020 6672 6f6d 206c 6566 742d 7269  ht  from left-ri
-00007040: 6768 740a 2020 2020 2020 2020 2020 2020  ght.            
-00007050: 2320 2020 2020 2062 6163 6b20 2020 6672  #      back   fr
-00007060: 6f6d 2066 726f 6e74 2d62 6163 6b0a 2020  om front-back.  
-00007070: 2020 2020 2020 2020 2020 2320 436f 7265            # Core
-00007080: 204d 4c20 7061 6464 696e 6720 7374 7275   ML padding stru
-00007090: 6374 7572 6520 6973 2073 696d 696c 6172  cture is similar
-000070a0: 205b 746f 702c 2062 6f74 746f 6d2c 206c   [top, bottom, l
-000070b0: 6566 742c 2072 6967 6874 5d0a 2020 2020  eft, right].    
-000070c0: 2020 2020 2020 2020 2320 6d61 7070 696e          # mappin
-000070d0: 6720 6f75 7470 7574 5f70 6164 6469 6e67  g output_padding
-000070e0: 2074 6f20 7369 6d70 6c69 6679 2066 7572   to simplify fur
-000070f0: 7468 6572 2070 726f 6365 7373 696e 6721  ther processing!
-00007100: 0a20 2020 2020 2020 2020 2020 2023 0a20  .            #. 
-00007110: 2020 2020 2020 2020 2020 2023 2046 6f72             # For
-00007120: 2043 6f6e 7654 7261 6e73 706f 7365 3264   ConvTranspose2d
-00007130: 3a20 5b62 6f74 746f 6d2c 2072 6967 6874  : [bottom, right
-00007140: 5d20 2d3e 205b 302c 2062 2c20 302c 2072  ] -> [0, b, 0, r
-00007150: 5d0a 2020 2020 2020 2020 2020 2020 6f75  ].            ou
-00007160: 7470 7574 5f70 6164 6469 6e67 203d 205b  tput_padding = [
-00007170: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00007180: 2030 2069 6620 6920 2520 3220 3d3d 2030   0 if i % 2 == 0
-00007190: 2065 6c73 6520 6f75 745f 7061 645b 6920   else out_pad[i 
-000071a0: 2f2f 2032 5d20 666f 7220 6920 696e 2072  // 2] for i in r
-000071b0: 616e 6765 286c 656e 2870 6164 2929 0a20  ange(len(pad)). 
-000071c0: 2020 2020 2020 2020 2020 205d 0a20 2020             ].   
-000071d0: 2020 2020 2020 2020 2069 6620 7375 6d28           if sum(
-000071e0: 7061 6429 203d 3d20 3020 616e 6420 616e  pad) == 0 and an
-000071f0: 7928 6f75 7470 7574 5f70 6164 6469 6e67  y(output_padding
-00007200: 293a 0a20 2020 2020 2020 2020 2020 2020  ):.             
-00007210: 2020 2072 6169 7365 2056 616c 7565 4572     raise ValueEr
-00007220: 726f 7228 0a20 2020 2020 2020 2020 2020  ror(.           
-00007230: 2020 2020 2020 2020 2022 436f 6e76 5472           "ConvTr
-00007240: 616e 7370 6f73 6520 636f 6e66 6967 7572  anspose configur
-00007250: 6174 696f 6e20 6f66 2070 6164 6469 6e67  ation of padding
-00007260: 3d30 2061 6e64 206f 7574 7075 745f 7061  =0 and output_pa
-00007270: 6464 696e 6720 3e20 3020 6e6f 7420 7375  dding > 0 not su
-00007280: 7070 6f72 7465 6421 220a 2020 2020 2020  pported!".      
-00007290: 2020 2020 2020 2020 2020 290a 2020 2020            ).    
-000072a0: 2020 2020 2020 2020 706f 7374 5f63 726f          post_cro
-000072b0: 7020 3d20 7061 642e 636f 7079 2829 0a20  p = pad.copy(). 
-000072c0: 2020 2020 2020 2020 2020 2070 6164 202a             pad *
-000072d0: 3d20 300a 2020 2020 2020 2020 2020 2020  = 0.            
-000072e0: 666f 7220 6920 696e 2072 616e 6765 2830  for i in range(0
-000072f0: 2c20 6c65 6e28 7061 6429 293a 0a20 2020  , len(pad)):.   
-00007300: 2020 2020 2020 2020 2020 2020 2069 6620               if 
-00007310: 706f 7374 5f63 726f 705b 695d 203e 3d20  post_crop[i] >= 
-00007320: 6f75 7470 7574 5f70 6164 6469 6e67 5b69  output_padding[i
-00007330: 5d3a 0a20 2020 2020 2020 2020 2020 2020  ]:.             
-00007340: 2020 2020 2020 2070 6f73 745f 6372 6f70         post_crop
-00007350: 5b69 5d20 2d3d 206f 7574 7075 745f 7061  [i] -= output_pa
-00007360: 6464 696e 675b 695d 0a20 2020 2020 2020  dding[i].       
-00007370: 2020 2020 2020 2020 2065 6c73 653a 0a20           else:. 
-00007380: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007390: 2020 2070 7265 5f70 6164 5b69 5d20 3d20     pre_pad[i] = 
-000073a0: 6f75 7470 7574 5f70 6164 6469 6e67 5b69  output_padding[i
-000073b0: 5d20 2d20 706f 7374 5f63 726f 705b 695d  ] - post_crop[i]
-000073c0: 0a20 2020 2020 2020 2020 2020 206b 7761  .            kwa
-000073d0: 7267 735b 2270 6164 225d 203d 2070 7265  rgs["pad"] = pre
-000073e0: 5f70 6164 0a20 2020 2020 2020 2020 2020  _pad.           
-000073f0: 2069 6620 616e 7928 7072 655f 7061 6429   if any(pre_pad)
-00007400: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00007410: 2020 2320 436f 6e73 7461 6e74 2070 6164    # Constant pad
-00007420: 2072 6571 7569 7265 7320 7061 6420 746f   requires pad to
-00007430: 2062 6520 6f66 206c 656e 6774 6820 322a   be of length 2*
-00007440: 696e 7075 745f 7261 6e6b 0a20 2020 2020  input_rank.     
-00007450: 2020 2020 2020 2020 2020 2070 7265 5f70             pre_p
-00007460: 6164 203d 205b 305d 202a 2032 202a 2028  ad = [0] * 2 * (
-00007470: 6c65 6e28 782e 7368 6170 6529 202d 2032  len(x.shape) - 2
-00007480: 2920 2b20 7072 655f 7061 640a 2020 2020  ) + pre_pad.    
-00007490: 2020 2020 2020 2020 2020 2020 7820 3d20              x = 
-000074a0: 6d62 2e70 6164 2878 3d78 2c20 7061 643d  mb.pad(x=x, pad=
-000074b0: 7072 655f 7061 6429 0a20 2020 2020 2020  pre_pad).       
-000074c0: 2020 2020 2020 2020 206b 7761 7267 735b           kwargs[
-000074d0: 2278 225d 203d 2078 0a20 2020 2020 2020  "x"] = x.       
-000074e0: 2020 2020 2069 6620 616e 7928 706f 7374       if any(post
-000074f0: 5f63 726f 7029 3a0a 2020 2020 2020 2020  _crop):.        
-00007500: 2020 2020 2020 2020 6465 6c20 6b77 6172          del kwar
-00007510: 6773 5b22 6e61 6d65 225d 0a0a 2020 2020  gs["name"]..    
-00007520: 2020 2020 636f 6e76 203d 206d 622e 636f      conv = mb.co
-00007530: 6e76 5f74 7261 6e73 706f 7365 282a 2a6b  nv_transpose(**k
-00007540: 7761 7267 7329 0a20 2020 2020 2020 2069  wargs).        i
-00007550: 6620 616e 7928 706f 7374 5f63 726f 7029  f any(post_crop)
-00007560: 3a0a 2020 2020 2020 2020 2020 2020 2320  :.            # 
-00007570: 544f 444f 3a20 7264 6172 3a2f 2f36 3535  TODO: rdar://655
-00007580: 3735 3832 3620 2850 7954 6f72 6368 2063  75826 (PyTorch c
-00007590: 6f6e 7665 7274 6572 3a20 6f75 7470 7574  onverter: output
-000075a0: 5f70 6164 6469 6e67 206d 6170 7069 6e67  _padding mapping
-000075b0: 2074 6f20 736c 6963 650a 2020 2020 2020   to slice.      
-000075c0: 2020 2020 2020 2320 696e 7374 6561 6420        # instead 
-000075d0: 6f66 2063 726f 7020 6c61 7965 7220 666f  of crop layer fo
-000075e0: 7220 3120 616e 6420 3344 2043 6f6e 7654  r 1 and 3D ConvT
-000075f0: 7261 6e73 706f 7365 290a 2020 2020 2020  ranspose).      
-00007600: 2020 2020 2020 6966 206c 656e 2870 6f73        if len(pos
-00007610: 745f 6372 6f70 2920 3d3d 2032 2061 6e64  t_crop) == 2 and
-00007620: 2063 6f6e 762e 7261 6e6b 203d 3d20 333a   conv.rank == 3:
-00007630: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00007640: 2023 204e 756d 6265 7220 6f66 2065 6c65   # Number of ele
-00007650: 6d65 6e74 7320 746f 2063 726f 7020 6672  ments to crop fr
-00007660: 6f6d 2072 6967 6874 203d 2070 6f73 745f  om right = post_
-00007670: 6372 6f70 5b2d 315d 2e0a 2020 2020 2020  crop[-1]..      
-00007680: 2020 2020 2020 2020 2020 2320 5369 6e63            # Sinc
-00007690: 6520 736c 6963 696e 6720 7375 7070 6f72  e slicing suppor
-000076a0: 7473 206e 6567 6174 6976 6520 696e 6465  ts negative inde
-000076b0: 7869 6e67 2c20 656e 645f 6964 203d 202d  xing, end_id = -
-000076c0: 3120 2a20 706f 7374 5f63 726f 705b 2d31  1 * post_crop[-1
-000076d0: 5d0a 2020 2020 2020 2020 2020 2020 2020  ].              
-000076e0: 2020 636f 6e76 203d 206d 622e 736c 6963    conv = mb.slic
-000076f0: 655f 6279 5f69 6e64 6578 280a 2020 2020  e_by_index(.    
-00007700: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007710: 783d 636f 6e76 2c0a 2020 2020 2020 2020  x=conv,.        
-00007720: 2020 2020 2020 2020 2020 2020 6265 6769              begi
-00007730: 6e3d 5b30 2c20 302c 2070 6f73 745f 6372  n=[0, 0, post_cr
-00007740: 6f70 5b30 5d5d 2c0a 2020 2020 2020 2020  op[0]],.        
-00007750: 2020 2020 2020 2020 2020 2020 656e 643d              end=
-00007760: 5b30 2c20 302c 202d 3120 2a20 706f 7374  [0, 0, -1 * post
-00007770: 5f63 726f 705b 2d31 5d5d 2c0a 2020 2020  _crop[-1]],.    
-00007780: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007790: 6265 6769 6e5f 6d61 736b 3d5b 5472 7565  begin_mask=[True
-000077a0: 2c20 5472 7565 2c20 4661 6c73 655d 2c0a  , True, False],.
-000077b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000077c0: 2020 2020 656e 645f 6d61 736b 3d5b 5472      end_mask=[Tr
-000077d0: 7565 2c20 5472 7565 2c20 4661 6c73 655d  ue, True, False]
-000077e0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-000077f0: 2020 2020 2020 6e61 6d65 3d6e 6f64 652e        name=node.
-00007800: 6e61 6d65 2c0a 2020 2020 2020 2020 2020  name,.          
-00007810: 2020 2020 2020 290a 2020 2020 2020 2020        ).        
-00007820: 2020 2020 656c 6966 206c 656e 2870 6f73      elif len(pos
-00007830: 745f 6372 6f70 2920 3d3d 2034 2061 6e64  t_crop) == 4 and
-00007840: 2063 6f6e 762e 7261 6e6b 203d 3d20 343a   conv.rank == 4:
-00007850: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00007860: 2063 6f6e 7620 3d20 6d62 2e63 726f 7028   conv = mb.crop(
-00007870: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00007880: 2020 2020 2078 3d63 6f6e 762c 0a20 2020       x=conv,.   
-00007890: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000078a0: 2063 726f 705f 6865 6967 6874 3d70 6f73   crop_height=pos
-000078b0: 745f 6372 6f70 5b3a 325d 2c0a 2020 2020  t_crop[:2],.    
-000078c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000078d0: 6372 6f70 5f77 6964 7468 3d70 6f73 745f  crop_width=post_
-000078e0: 6372 6f70 5b32 3a34 5d2c 0a20 2020 2020  crop[2:4],.     
-000078f0: 2020 2020 2020 2020 2020 2020 2020 206e                 n
-00007900: 616d 653d 6e6f 6465 2e6e 616d 652c 0a20  ame=node.name,. 
-00007910: 2020 2020 2020 2020 2020 2020 2020 2029                 )
-00007920: 0a20 2020 2020 2020 2020 2020 2065 6c73  .            els
-00007930: 653a 0a20 2020 2020 2020 2020 2020 2020  e:.             
-00007940: 2020 2072 6169 7365 2056 616c 7565 4572     raise ValueEr
-00007950: 726f 7228 0a20 2020 2020 2020 2020 2020  ror(.           
-00007960: 2020 2020 2020 2020 2022 6f75 7470 7574           "output
-00007970: 5f70 6164 6469 6e67 2069 7320 7375 7070  _padding is supp
-00007980: 6f72 7465 6420 6f6e 6c79 2066 6f72 2043  orted only for C
-00007990: 6f6e 7654 7261 6e73 706f 7365 3144 206f  onvTranspose1D o
-000079a0: 7220 436f 6e76 5472 616e 7370 6f73 6532  r ConvTranspose2
-000079b0: 4421 220a 2020 2020 2020 2020 2020 2020  D!".            
-000079c0: 2020 2020 290a 2020 2020 656c 7365 3a0a      ).    else:.
-000079d0: 2020 2020 2020 2020 2320 4e6f 726d 616c          # Normal
-000079e0: 2063 6f6e 766f 6c75 7469 6f6e 0a20 2020   convolution.   
-000079f0: 2020 2020 2063 6f6e 7620 3d20 6d62 2e63       conv = mb.c
-00007a00: 6f6e 7628 2a2a 6b77 6172 6773 290a 2020  onv(**kwargs).  
-00007a10: 2020 636f 6e74 6578 742e 6164 6428 636f    context.add(co
-00007a20: 6e76 290a 0a0a 2320 436f 6e76 6f6c 7574  nv)...# Convolut
-00007a30: 696f 6e20 7769 7468 2022 7361 6d65 2c20  ion with "same, 
-00007a40: 7661 6c69 6422 2070 6164 6469 6e67 0a40  valid" padding.@
-00007a50: 7265 6769 7374 6572 5f74 6f72 6368 5f6f  register_torch_o
-00007a60: 700a 6465 6620 5f63 6f6e 766f 6c75 7469  p.def _convoluti
-00007a70: 6f6e 5f6d 6f64 6528 636f 6e74 6578 742c  on_mode(context,
-00007a80: 206e 6f64 6529 3a0a 2020 2020 696e 7075   node):.    inpu
-00007a90: 7473 203d 205f 6765 745f 696e 7075 7473  ts = _get_inputs
-00007aa0: 2863 6f6e 7465 7874 2c20 6e6f 6465 2c20  (context, node, 
-00007ab0: 6578 7065 6374 6564 3d37 290a 2020 2020  expected=7).    
-00007ac0: 6d6f 6465 203d 2069 6e70 7574 735b 345d  mode = inputs[4]
-00007ad0: 2e76 616c 0a0a 2020 2020 636f 6e74 6578  .val..    contex
-00007ae0: 742e 6164 6428 0a20 2020 2020 2020 206d  t.add(.        m
-00007af0: 622e 636f 6e76 280a 2020 2020 2020 2020  b.conv(.        
-00007b00: 2020 2020 783d 696e 7075 7473 5b30 5d2c      x=inputs[0],
-00007b10: 0a20 2020 2020 2020 2020 2020 2077 6569  .            wei
-00007b20: 6768 743d 696e 7075 7473 5b31 5d2c 0a20  ght=inputs[1],. 
-00007b30: 2020 2020 2020 2020 2020 2062 6961 733d             bias=
-00007b40: 696e 7075 7473 5b32 5d2c 0a20 2020 2020  inputs[2],.     
-00007b50: 2020 2020 2020 2073 7472 6964 6573 3d69         strides=i
-00007b60: 6e70 7574 735b 335d 2c0a 2020 2020 2020  nputs[3],.      
-00007b70: 2020 2020 2020 7061 645f 7479 7065 3d6d        pad_type=m
-00007b80: 6f64 652c 0a20 2020 2020 2020 2020 2020  ode,.           
-00007b90: 2064 696c 6174 696f 6e73 3d69 6e70 7574   dilations=input
-00007ba0: 735b 355d 2c0a 2020 2020 2020 2020 2020  s[5],.          
-00007bb0: 2020 6772 6f75 7073 3d69 6e70 7574 735b    groups=inputs[
-00007bc0: 365d 2c0a 2020 2020 2020 2020 2020 2020  6],.            
-00007bd0: 6e61 6d65 3d6e 6f64 652e 6e61 6d65 2c0a  name=node.name,.
-00007be0: 2020 2020 2020 2020 290a 2020 2020 290a          ).    ).
-00007bf0: 0a0a 4072 6567 6973 7465 725f 746f 7263  ..@register_torc
-00007c00: 685f 6f70 0a64 6566 2073 6f66 746d 6178  h_op.def softmax
-00007c10: 2863 6f6e 7465 7874 2c20 6e6f 6465 293a  (context, node):
-00007c20: 0a20 2020 2069 6e70 7574 7320 3d20 5f67  .    inputs = _g
-00007c30: 6574 5f69 6e70 7574 7328 636f 6e74 6578  et_inputs(contex
-00007c40: 742c 206e 6f64 6529 0a0a 2020 2020 7820  t, node)..    x 
-00007c50: 3d20 696e 7075 7473 5b30 5d0a 2020 2020  = inputs[0].    
-00007c60: 6178 6973 203d 2069 6e70 7574 735b 315d  axis = inputs[1]
-00007c70: 0a20 2020 2072 6573 203d 206d 622e 736f  .    res = mb.so
-00007c80: 6674 6d61 7828 783d 782c 2061 7869 733d  ftmax(x=x, axis=
-00007c90: 6178 6973 2c20 6e61 6d65 3d6e 6f64 652e  axis, name=node.
-00007ca0: 6e61 6d65 290a 2020 2020 636f 6e74 6578  name).    contex
-00007cb0: 742e 6164 6428 7265 7329 0a0a 0a40 7265  t.add(res)...@re
-00007cc0: 6769 7374 6572 5f74 6f72 6368 5f6f 700a  gister_torch_op.
-00007cd0: 6465 6620 666c 6174 7465 6e28 636f 6e74  def flatten(cont
-00007ce0: 6578 742c 206e 6f64 6529 3a0a 2020 2020  ext, node):.    
-00007cf0: 696e 7075 7473 203d 205f 6765 745f 696e  inputs = _get_in
-00007d00: 7075 7473 2863 6f6e 7465 7874 2c20 6e6f  puts(context, no
-00007d10: 6465 290a 0a20 2020 2078 203d 2069 6e70  de)..    x = inp
-00007d20: 7574 735b 305d 0a20 2020 2064 696d 7320  uts[0].    dims 
-00007d30: 3d20 6c69 7374 2878 2e73 6861 7065 290a  = list(x.shape).
-00007d40: 2020 2020 7374 6172 745f 7661 6c20 3d20      start_val = 
-00007d50: 696e 7075 7473 5b31 5d2e 7661 6c0a 2020  inputs[1].val.  
-00007d60: 2020 656e 645f 7661 6c20 3d20 696e 7075    end_val = inpu
-00007d70: 7473 5b32 5d2e 7661 6c0a 0a20 2020 2073  ts[2].val..    s
-00007d80: 7461 7274 203d 206c 656e 2864 696d 7329  tart = len(dims)
-00007d90: 202b 2073 7461 7274 5f76 616c 2069 6620   + start_val if 
-00007da0: 7374 6172 745f 7661 6c20 3c20 3020 656c  start_val < 0 el
-00007db0: 7365 2073 7461 7274 5f76 616c 0a20 2020  se start_val.   
-00007dc0: 2065 6e64 203d 206c 656e 2864 696d 7329   end = len(dims)
-00007dd0: 202b 2065 6e64 5f76 616c 2069 6620 656e   + end_val if en
-00007de0: 645f 7661 6c20 3c20 3020 656c 7365 2065  d_val < 0 else e
-00007df0: 6e64 5f76 616c 0a0a 2020 2020 6966 2073  nd_val..    if s
-00007e00: 7461 7274 203e 206c 656e 2864 696d 7329  tart > len(dims)
-00007e10: 206f 7220 656e 6420 3e20 6c65 6e28 6469   or end > len(di
-00007e20: 6d73 2920 6f72 2073 7461 7274 203c 2030  ms) or start < 0
-00007e30: 206f 7220 656e 6420 3c20 303a 0a20 2020   or end < 0:.   
-00007e40: 2020 2020 2072 6169 7365 2056 616c 7565       raise Value
-00007e50: 4572 726f 7228 0a20 2020 2020 2020 2020  Error(.         
-00007e60: 2020 2022 496e 7661 6c69 6420 7374 6172     "Invalid star
-00007e70: 7420 616e 6420 656e 642e 2028 7374 6172  t and end. (star
-00007e80: 742c 2065 6e64 2920 3d3d 2028 7b7d 2c20  t, end) == ({}, 
-00007e90: 7b7d 2922 2e66 6f72 6d61 7428 7374 6172  {})".format(star
-00007ea0: 742c 2065 6e64 5f76 616c 290a 2020 2020  t, end_val).    
-00007eb0: 2020 2020 290a 2020 2020 6966 2073 7461      ).    if sta
-00007ec0: 7274 203e 2065 6e64 3a0a 2020 2020 2020  rt > end:.      
-00007ed0: 2020 7261 6973 6520 5661 6c75 6545 7272    raise ValueErr
-00007ee0: 6f72 280a 2020 2020 2020 2020 2020 2020  or(.            
-00007ef0: 2253 7461 7274 206d 7573 7420 6265 2062  "Start must be b
-00007f00: 6566 6f72 6520 656e 642e 2028 7374 6172  efore end. (star
-00007f10: 742c 2065 6e64 2920 3d3d 2028 7b7d 2c20  t, end) == ({}, 
-00007f20: 7b7d 2922 2e66 6f72 6d61 7428 7374 6172  {})".format(star
-00007f30: 742c 2065 6e64 5f76 616c 290a 2020 2020  t, end_val).    
-00007f40: 2020 2020 290a 2020 2020 785f 7368 6170      ).    x_shap
-00007f50: 6520 3d20 6d62 2e73 6861 7065 2878 3d78  e = mb.shape(x=x
-00007f60: 290a 0a20 2020 2073 6861 7065 3120 3d20  )..    shape1 = 
-00007f70: 6d62 2e73 6c69 6365 5f62 795f 696e 6465  mb.slice_by_inde
-00007f80: 7828 783d 785f 7368 6170 652c 2062 6567  x(x=x_shape, beg
-00007f90: 696e 3d5b 305d 2c20 656e 643d 5b73 7461  in=[0], end=[sta
-00007fa0: 7274 5d29 0a20 2020 2073 6861 7065 3220  rt]).    shape2 
-00007fb0: 3d20 6d62 2e73 6c69 6365 5f62 795f 696e  = mb.slice_by_in
-00007fc0: 6465 7828 783d 785f 7368 6170 652c 2062  dex(x=x_shape, b
-00007fd0: 6567 696e 3d5b 656e 6420 2b20 315d 2c20  egin=[end + 1], 
-00007fe0: 656e 643d 5b6c 656e 2864 696d 7329 5d29  end=[len(dims)])
-00007ff0: 0a0a 2020 2020 666c 6174 7465 6e5f 6469  ..    flatten_di
-00008000: 6d20 3d20 2d31 0a20 2020 2069 6620 6e6f  m = -1.    if no
-00008010: 7420 616e 795f 7379 6d62 6f6c 6963 2878  t any_symbolic(x
-00008020: 2e73 6861 7065 293a 0a20 2020 2020 2020  .shape):.       
-00008030: 2066 6c61 7474 656e 5f64 696d 203d 2031   flatten_dim = 1
-00008040: 0a20 2020 2020 2020 2066 6f72 2064 696d  .        for dim
-00008050: 2069 6e20 6469 6d73 5b73 7461 7274 3a20   in dims[start: 
-00008060: 656e 6420 2b20 315d 3a0a 2020 2020 2020  end + 1]:.      
-00008070: 2020 2020 2020 666c 6174 7465 6e5f 6469        flatten_di
-00008080: 6d20 2a3d 2064 696d 0a0a 2020 2020 7368  m *= dim..    sh
-00008090: 6170 6520 3d20 6d62 2e63 6f6e 6361 7428  ape = mb.concat(
-000080a0: 7661 6c75 6573 3d28 7368 6170 6531 2c20  values=(shape1, 
-000080b0: 5b66 6c61 7474 656e 5f64 696d 5d2c 2073  [flatten_dim], s
-000080c0: 6861 7065 3229 2c20 6178 6973 3d30 290a  hape2), axis=0).
-000080d0: 2020 2020 7368 6170 6520 3d20 6d62 2e63      shape = mb.c
-000080e0: 6173 7428 783d 7368 6170 652c 2064 7479  ast(x=shape, dty
-000080f0: 7065 3d22 696e 7433 3222 290a 2020 2020  pe="int32").    
-00008100: 7265 7368 6170 6520 3d20 6d62 2e72 6573  reshape = mb.res
-00008110: 6861 7065 2878 3d78 2c20 7368 6170 653d  hape(x=x, shape=
-00008120: 7368 6170 652c 206e 616d 653d 6e6f 6465  shape, name=node
-00008130: 2e6e 616d 6529 0a20 2020 2063 6f6e 7465  .name).    conte
-00008140: 7874 2e61 6464 2872 6573 6861 7065 290a  xt.add(reshape).
-00008150: 0a0a 4072 6567 6973 7465 725f 746f 7263  ..@register_torc
-00008160: 685f 6f70 0a64 6566 205f 7265 7368 6170  h_op.def _reshap
-00008170: 655f 6672 6f6d 5f74 656e 736f 7228 636f  e_from_tensor(co
-00008180: 6e74 6578 742c 206e 6f64 6529 3a0a 2020  ntext, node):.  
-00008190: 2020 696e 7075 7473 203d 205f 6765 745f    inputs = _get_
-000081a0: 696e 7075 7473 2863 6f6e 7465 7874 2c20  inputs(context, 
-000081b0: 6e6f 6465 2c20 6578 7065 6374 6564 3d32  node, expected=2
-000081c0: 290a 0a20 2020 2072 6573 6861 7065 203d  )..    reshape =
-000081d0: 206d 622e 7265 7368 6170 6528 783d 696e   mb.reshape(x=in
-000081e0: 7075 7473 5b30 5d2c 2073 6861 7065 3d69  puts[0], shape=i
-000081f0: 6e70 7574 735b 315d 2c20 6e61 6d65 3d6e  nputs[1], name=n
-00008200: 6f64 652e 6e61 6d65 290a 2020 2020 636f  ode.name).    co
-00008210: 6e74 6578 742e 6164 6428 7265 7368 6170  ntext.add(reshap
-00008220: 6529 0a0a 0a40 7265 6769 7374 6572 5f74  e)...@register_t
-00008230: 6f72 6368 5f6f 700a 6465 6620 736f 6674  orch_op.def soft
-00008240: 7369 676e 2863 6f6e 7465 7874 2c20 6e6f  sign(context, no
-00008250: 6465 293a 0a20 2020 2069 6e70 7574 7320  de):.    inputs 
-00008260: 3d20 5f67 6574 5f69 6e70 7574 7328 636f  = _get_inputs(co
-00008270: 6e74 6578 742c 206e 6f64 652c 2065 7870  ntext, node, exp
-00008280: 6563 7465 643d 3129 0a0a 2020 2020 7265  ected=1)..    re
-00008290: 7320 3d20 6d62 2e73 6f66 7473 6967 6e28  s = mb.softsign(
-000082a0: 783d 696e 7075 7473 5b30 5d2c 206e 616d  x=inputs[0], nam
-000082b0: 653d 6e6f 6465 2e6e 616d 6529 0a20 2020  e=node.name).   
-000082c0: 2063 6f6e 7465 7874 2e61 6464 2872 6573   context.add(res
-000082d0: 290a 0a0a 4072 6567 6973 7465 725f 746f  )...@register_to
-000082e0: 7263 685f 6f70 0a64 6566 2072 656c 7528  rch_op.def relu(
-000082f0: 636f 6e74 6578 742c 206e 6f64 6529 3a0a  context, node):.
-00008300: 2020 2020 696e 7075 7473 203d 205f 6765      inputs = _ge
-00008310: 745f 696e 7075 7473 2863 6f6e 7465 7874  t_inputs(context
-00008320: 2c20 6e6f 6465 2c20 6578 7065 6374 6564  , node, expected
-00008330: 3d31 290a 0a20 2020 2072 6573 203d 206d  =1)..    res = m
-00008340: 622e 7265 6c75 2878 3d69 6e70 7574 735b  b.relu(x=inputs[
-00008350: 305d 2c20 6e61 6d65 3d6e 6f64 652e 6e61  0], name=node.na
-00008360: 6d65 290a 2020 2020 636f 6e74 6578 742e  me).    context.
-00008370: 6164 6428 7265 7329 0a0a 0a40 7265 6769  add(res)...@regi
-00008380: 7374 6572 5f74 6f72 6368 5f6f 700a 6465  ster_torch_op.de
-00008390: 6620 7072 656c 7528 636f 6e74 6578 742c  f prelu(context,
-000083a0: 206e 6f64 6529 3a0a 2020 2020 696e 7075   node):.    inpu
-000083b0: 7473 203d 205f 6765 745f 696e 7075 7473  ts = _get_inputs
-000083c0: 2863 6f6e 7465 7874 2c20 6e6f 6465 2c20  (context, node, 
-000083d0: 6578 7065 6374 6564 3d32 290a 2020 2020  expected=2).    
-000083e0: 7820 3d20 696e 7075 7473 5b30 5d0a 2020  x = inputs[0].  
-000083f0: 2020 616c 7068 6120 3d20 696e 7075 7473    alpha = inputs
-00008400: 5b31 5d0a 2020 2020 2320 496e 2074 6865  [1].    # In the
-00008410: 204d 494c 2062 6163 6b65 6e64 2c20 6974   MIL backend, it
-00008420: 2061 7373 756d 6573 2074 6861 7420 7468   assumes that th
-00008430: 6520 696e 7075 7473 206f 6620 7072 656c  e inputs of prel
-00008440: 7520 7368 6f75 6c64 2068 6176 650a 2020  u should have.  
-00008450: 2020 2320 6174 206c 6561 7374 2072 616e    # at least ran
-00008460: 6b20 332c 2069 2e65 2e20 5b62 6174 6368  k 3, i.e. [batch
-00008470: 2c20 6368 616e 6e65 6c2c 2073 7061 7469  , channel, spati
-00008480: 616c 5f64 696d 732a 5d2e 0a20 2020 2069  al_dims*]..    i
-00008490: 6620 782e 7261 6e6b 203e 3d20 323a 0a20  f x.rank >= 2:. 
-000084a0: 2020 2020 2020 2061 6c70 6861 203d 2061         alpha = a
-000084b0: 6c70 6861 2e76 616c 0a20 2020 2020 2020  lpha.val.       
-000084c0: 2061 6c70 6861 203d 205f 6e70 2e6f 6e65   alpha = _np.one
-000084d0: 7328 2878 2e73 6861 7065 5b31 5d2c 2929  s((x.shape[1],))
-000084e0: 202a 2061 6c70 6861 0a0a 2020 2020 6966   * alpha..    if
-000084f0: 2078 2e72 616e 6b20 3c3d 2032 3a0a 2020   x.rank <= 2:.  
-00008500: 2020 2020 2020 6178 6573 203d 205b 312c        axes = [1,
-00008510: 2032 5d20 6966 2078 2e72 616e 6b20 3d3d   2] if x.rank ==
-00008520: 2031 2065 6c73 6520 5b32 5d0a 2020 2020   1 else [2].    
-00008530: 2020 2020 7820 3d20 6d62 2e65 7870 616e      x = mb.expan
-00008540: 645f 6469 6d73 2878 3d78 2c20 6178 6573  d_dims(x=x, axes
-00008550: 3d61 7865 7329 0a20 2020 2020 2020 2078  =axes).        x
-00008560: 203d 206d 622e 7072 656c 7528 783d 782c   = mb.prelu(x=x,
-00008570: 2061 6c70 6861 3d61 6c70 6861 290a 2020   alpha=alpha).  
-00008580: 2020 2020 2020 7265 7320 3d20 6d62 2e73        res = mb.s
-00008590: 7175 6565 7a65 2878 3d78 2c20 6178 6573  queeze(x=x, axes
-000085a0: 3d61 7865 732c 206e 616d 653d 6e6f 6465  =axes, name=node
-000085b0: 2e6e 616d 6529 0a20 2020 2065 6c73 653a  .name).    else:
-000085c0: 0a20 2020 2020 2020 2072 6573 203d 206d  .        res = m
-000085d0: 622e 7072 656c 7528 783d 782c 2061 6c70  b.prelu(x=x, alp
-000085e0: 6861 3d61 6c70 6861 2c20 6e61 6d65 3d6e  ha=alpha, name=n
-000085f0: 6f64 652e 6e61 6d65 290a 0a20 2020 2063  ode.name)..    c
-00008600: 6f6e 7465 7874 2e61 6464 2872 6573 290a  ontext.add(res).
-00008610: 0a0a 4072 6567 6973 7465 725f 746f 7263  ..@register_torc
-00008620: 685f 6f70 0a64 6566 206c 696e 7370 6163  h_op.def linspac
-00008630: 6528 636f 6e74 6578 742c 206e 6f64 6529  e(context, node)
-00008640: 3a0a 2020 2020 696e 7075 7473 203d 205f  :.    inputs = _
-00008650: 6765 745f 696e 7075 7473 2863 6f6e 7465  get_inputs(conte
-00008660: 7874 2c20 6e6f 6465 2c20 6d69 6e5f 6578  xt, node, min_ex
-00008670: 7065 6374 6564 3d33 290a 0a20 2020 2073  pected=3)..    s
-00008680: 7461 7274 203d 2069 6e70 7574 735b 305d  tart = inputs[0]
-00008690: 0a20 2020 2065 6e64 203d 2069 6e70 7574  .    end = input
-000086a0: 735b 315d 0a20 2020 206e 756d 7320 3d20  s[1].    nums = 
-000086b0: 696e 7075 7473 5b32 5d0a 2020 2020 7374  inputs[2].    st
-000086c0: 6172 7420 3d20 6d62 2e63 6173 7428 783d  art = mb.cast(x=
-000086d0: 7374 6172 742c 2064 7479 7065 3d22 6670  start, dtype="fp
-000086e0: 3332 2229 0a20 2020 2065 6e64 203d 206d  32").    end = m
-000086f0: 622e 6361 7374 2878 3d65 6e64 2c20 6474  b.cast(x=end, dt
-00008700: 7970 653d 2266 7033 3222 290a 0a20 2020  ype="fp32")..   
-00008710: 2069 6620 7374 6172 742e 6361 6e5f 6265   if start.can_be
-00008720: 5f66 6f6c 6465 645f 746f 5f63 6f6e 7374  _folded_to_const
-00008730: 2829 2061 6e64 2065 6e64 2e63 616e 5f62  () and end.can_b
-00008740: 655f 666f 6c64 6564 5f74 6f5f 636f 6e73  e_folded_to_cons
-00008750: 7428 2920 616e 6420 6e75 6d73 2e63 616e  t() and nums.can
-00008760: 5f62 655f 666f 6c64 6564 5f74 6f5f 636f  _be_folded_to_co
-00008770: 6e73 7428 293a 0a20 2020 2020 2020 2073  nst():.        s
-00008780: 7461 7274 5f76 616c 203d 2073 7461 7274  tart_val = start
-00008790: 2e76 616c 0a20 2020 2020 2020 2065 6e64  .val.        end
-000087a0: 5f76 616c 203d 2065 6e64 2e76 616c 0a20  _val = end.val. 
-000087b0: 2020 2020 2020 206e 756d 735f 7661 6c20         nums_val 
-000087c0: 3d20 6e75 6d73 2e76 616c 0a20 2020 2020  = nums.val.     
-000087d0: 2020 2069 6620 6e75 6d73 5f76 616c 203c     if nums_val <
-000087e0: 204d 4158 5f53 495a 455f 434f 4e53 5441   MAX_SIZE_CONSTA
-000087f0: 4e54 5f46 4f4c 4449 4e47 3a0a 2020 2020  NT_FOLDING:.    
-00008800: 2020 2020 2020 2020 7265 7320 3d20 6d62          res = mb
-00008810: 2e63 6f6e 7374 2876 616c 3d5f 6e70 2e6c  .const(val=_np.l
-00008820: 696e 7370 6163 6528 7374 6172 745f 7661  inspace(start_va
-00008830: 6c2c 2065 6e64 5f76 616c 2c20 6e75 6d73  l, end_val, nums
-00008840: 5f76 616c 292c 206e 616d 653d 6e6f 6465  _val), name=node
-00008850: 2e6e 616d 6529 0a20 2020 2020 2020 2020  .name).         
-00008860: 2020 2063 6f6e 7465 7874 2e61 6464 2872     context.add(r
-00008870: 6573 290a 2020 2020 2020 2020 2020 2020  es).            
-00008880: 7265 7475 726e 0a0a 2020 2020 6966 206e  return..    if n
-00008890: 756d 732e 7661 6c20 6973 204e 6f6e 653a  ums.val is None:
-000088a0: 0a20 2020 2020 2020 206d 7367 203d 2022  .        msg = "
-000088b0: 4479 6e61 6d69 6320 7374 6570 7320 696e  Dynamic steps in
-000088c0: 7075 7420 666f 7220 746f 7263 682e 6c69  put for torch.li
-000088d0: 6e73 7061 6365 2069 7320 6e6f 7420 7375  nspace is not su
-000088e0: 7070 6f72 7465 642e 2050 6c65 6173 6520  pported. Please 
-000088f0: 7573 6520 746f 7263 682e 6172 616e 6765  use torch.arange
-00008900: 2069 6e73 7465 6164 220a 2020 2020 2020   instead".      
-00008910: 2020 7261 6973 6520 4e6f 7449 6d70 6c65    raise NotImple
-00008920: 6d65 6e74 6564 4572 726f 7228 6d73 6729  mentedError(msg)
-00008930: 0a20 2020 2065 6c73 653a 0a20 2020 2020  .    else:.     
-00008940: 2020 2069 6620 6e75 6d73 2e76 616c 203d     if nums.val =
-00008950: 3d20 313a 0a20 2020 2020 2020 2020 2020  = 1:.           
-00008960: 2072 6573 203d 206d 622e 6578 7061 6e64   res = mb.expand
-00008970: 5f64 696d 7328 783d 7374 6172 742c 2061  _dims(x=start, a
-00008980: 7865 733d 5b30 5d2c 206e 616d 653d 6e6f  xes=[0], name=no
-00008990: 6465 2e6e 616d 6529 0a20 2020 2020 2020  de.name).       
-000089a0: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
-000089b0: 2020 2023 2073 7465 7020 3d20 2865 6e64     # step = (end
-000089c0: 202d 2073 7461 7274 2920 2f20 286e 756d   - start) / (num
-000089d0: 7320 2d20 3129 0a20 2020 2020 2020 2020  s - 1).         
-000089e0: 2020 2078 203d 206d 622e 7375 6228 783d     x = mb.sub(x=
-000089f0: 656e 642c 2079 3d73 7461 7274 290a 2020  end, y=start).  
-00008a00: 2020 2020 2020 2020 2020 7920 3d20 6d62            y = mb
-00008a10: 2e73 7562 2878 3d6e 756d 732c 2079 3d31  .sub(x=nums, y=1
-00008a20: 290a 2020 2020 2020 2020 2020 2020 7820  ).            x 
-00008a30: 3d20 6d62 2e63 6173 7428 783d 782c 2064  = mb.cast(x=x, d
-00008a40: 7479 7065 3d22 6670 3332 2229 0a20 2020  type="fp32").   
-00008a50: 2020 2020 2020 2020 2079 203d 206d 622e           y = mb.
-00008a60: 6361 7374 2878 3d79 2c20 6474 7970 653d  cast(x=y, dtype=
-00008a70: 2266 7033 3222 290a 2020 2020 2020 2020  "fp32").        
-00008a80: 2020 2020 7374 6570 203d 206d 622e 7265      step = mb.re
-00008a90: 616c 5f64 6976 2878 3d78 2c20 793d 7929  al_div(x=x, y=y)
-00008aa0: 0a0a 2020 2020 2020 2020 2020 2020 2320  ..            # 
-00008ab0: 4e6f 7465 2074 6861 7420 7468 6520 7261  Note that the ra
-00008ac0: 6e67 655f 3164 206f 7020 6578 636c 7564  nge_1d op exclud
-00008ad0: 6564 2074 6865 2065 6e64 2070 6f69 6e74  ed the end point
-00008ae0: 2c0a 2020 2020 2020 2020 2020 2020 2320  ,.            # 
-00008af0: 736f 2077 6520 6861 7665 2074 6f20 6164  so we have to ad
-00008b00: 6420 7468 6520 656e 6420 6261 636b 2074  d the end back t
-00008b10: 6f20 7468 6520 7265 7375 6c74 696e 6720  o the resulting 
-00008b20: 6172 7261 792e 0a20 2020 2020 2020 2020  array..         
-00008b30: 2020 2061 7261 6e67 6520 3d20 6d62 2e72     arange = mb.r
-00008b40: 616e 6765 5f31 6428 656e 643d 656e 642c  ange_1d(end=end,
-00008b50: 2073 7461 7274 3d73 7461 7274 2c20 7374   start=start, st
-00008b60: 6570 3d73 7465 7029 0a20 2020 2020 2020  ep=step).       
-00008b70: 2020 2020 206e 6577 5f65 6e64 203d 206d       new_end = m
-00008b80: 622e 6578 7061 6e64 5f64 696d 7328 783d  b.expand_dims(x=
-00008b90: 656e 642c 2061 7865 733d 5b30 5d29 0a20  end, axes=[0]). 
-00008ba0: 2020 2020 2020 2020 2020 2072 6573 203d             res =
-00008bb0: 206d 622e 636f 6e63 6174 2876 616c 7565   mb.concat(value
-00008bc0: 733d 5b61 7261 6e67 652c 206e 6577 5f65  s=[arange, new_e
-00008bd0: 6e64 5d2c 2061 7869 733d 302c 206e 616d  nd], axis=0, nam
-00008be0: 653d 6e6f 6465 2e6e 616d 6529 0a20 2020  e=node.name).   
-00008bf0: 2063 6f6e 7465 7874 2e61 6464 2872 6573   context.add(res
-00008c00: 290a 0a0a 4072 6567 6973 7465 725f 746f  )...@register_to
-00008c10: 7263 685f 6f70 0a64 6566 2072 656c 7536  rch_op.def relu6
-00008c20: 2863 6f6e 7465 7874 2c20 6e6f 6465 293a  (context, node):
-00008c30: 0a20 2020 2069 6e70 7574 7320 3d20 5f67  .    inputs = _g
-00008c40: 6574 5f69 6e70 7574 7328 636f 6e74 6578  et_inputs(contex
-00008c50: 742c 206e 6f64 652c 2065 7870 6563 7465  t, node, expecte
-00008c60: 643d 3129 0a0a 2020 2020 7265 7320 3d20  d=1)..    res = 
-00008c70: 6d62 2e72 656c 7536 2878 3d69 6e70 7574  mb.relu6(x=input
-00008c80: 735b 305d 2c20 6e61 6d65 3d6e 6f64 652e  s[0], name=node.
-00008c90: 6e61 6d65 290a 2020 2020 636f 6e74 6578  name).    contex
-00008ca0: 742e 6164 6428 7265 7329 0a0a 0a40 7265  t.add(res)...@re
-00008cb0: 6769 7374 6572 5f74 6f72 6368 5f6f 700a  gister_torch_op.
-00008cc0: 6465 6620 6569 6e73 756d 2863 6f6e 7465  def einsum(conte
-00008cd0: 7874 2c20 6e6f 6465 293a 0a20 2020 2061  xt, node):.    a
-00008ce0: 203d 2063 6f6e 7465 7874 5b6e 6f64 652e   = context[node.
-00008cf0: 696e 7075 7473 5b31 5d5d 5b30 5d0a 2020  inputs[1]][0].  
-00008d00: 2020 6220 3d20 636f 6e74 6578 745b 6e6f    b = context[no
-00008d10: 6465 2e69 6e70 7574 735b 315d 5d5b 315d  de.inputs[1]][1]
-00008d20: 0a20 2020 2065 7175 6174 696f 6e20 3d20  .    equation = 
-00008d30: 636f 6e74 6578 745b 6e6f 6465 2e69 6e70  context[node.inp
-00008d40: 7574 735b 305d 5d2e 7661 6c0a 2020 2020  uts[0]].val.    
-00008d50: 7820 3d20 6275 696c 645f 6569 6e73 756d  x = build_einsum
-00008d60: 5f6d 696c 2861 2c20 622c 2065 7175 6174  _mil(a, b, equat
-00008d70: 696f 6e2c 206e 6f64 652e 6e61 6d65 290a  ion, node.name).
-00008d80: 2020 2020 636f 6e74 6578 742e 6164 6428      context.add(
-00008d90: 7829 0a0a 0a40 7265 6769 7374 6572 5f74  x)...@register_t
-00008da0: 6f72 6368 5f6f 700a 6465 6620 6579 6528  orch_op.def eye(
-00008db0: 636f 6e74 6578 742c 206e 6f64 6529 3a0a  context, node):.
-00008dc0: 2020 2020 2320 544f 444f 3a20 7264 6172      # TODO: rdar
-00008dd0: 3a2f 2f31 3034 3430 3035 3638 2028 5b50  ://104400568 ([P
-00008de0: 7954 6f72 6368 5d20 5573 6520 4d49 4c20  yTorch] Use MIL 
-00008df0: 6f70 7320 746f 2063 6f6e 7374 7275 6374  ops to construct
-00008e00: 2074 6865 2065 7965 206d 6174 7269 7820   the eye matrix 
-00008e10: 696e 206f 7264 6572 2074 6f20 6176 6f69  in order to avoi
-00008e20: 6420 6469 7265 6374 6c79 2066 6f6c 6469  d directly foldi
-00008e30: 6e67 2074 6865 2069 6e70 7574 2069 6e74  ng the input int
-00008e40: 6f20 6120 636f 6e73 7429 0a20 2020 2069  o a const).    i
-00008e50: 6e70 7574 7320 3d20 5f67 6574 5f69 6e70  nputs = _get_inp
-00008e60: 7574 7328 636f 6e74 6578 742c 206e 6f64  uts(context, nod
-00008e70: 652c 2065 7870 6563 7465 643d 5b35 2c20  e, expected=[5, 
-00008e80: 365d 290a 2020 2020 6966 206c 656e 2869  6]).    if len(i
-00008e90: 6e70 7574 7329 203d 3d20 353a 0a20 2020  nputs) == 5:.   
-00008ea0: 2020 2020 2065 7965 203d 205f 6e70 2e65       eye = _np.e
-00008eb0: 7965 2869 6e70 7574 735b 305d 2e76 616c  ye(inputs[0].val
-00008ec0: 290a 2020 2020 6966 206c 656e 2869 6e70  ).    if len(inp
-00008ed0: 7574 7329 203d 3d20 363a 0a20 2020 2020  uts) == 6:.     
-00008ee0: 2020 2065 7965 203d 205f 6e70 2e65 7965     eye = _np.eye
-00008ef0: 2869 6e70 7574 735b 305d 2e76 616c 2c20  (inputs[0].val, 
-00008f00: 696e 7075 7473 5b31 5d2e 7661 6c29 0a20  inputs[1].val). 
-00008f10: 2020 2065 7965 203d 206d 622e 636f 6e73     eye = mb.cons
-00008f20: 7428 7661 6c3d 6579 652c 206e 616d 653d  t(val=eye, name=
-00008f30: 6e6f 6465 2e6e 616d 6529 0a20 2020 2063  node.name).    c
-00008f40: 6f6e 7465 7874 2e61 6464 2865 7965 290a  ontext.add(eye).
-00008f50: 0a0a 4072 6567 6973 7465 725f 746f 7263  ..@register_torc
-00008f60: 685f 6f70 0a64 6566 2065 6c75 2863 6f6e  h_op.def elu(con
-00008f70: 7465 7874 2c20 6e6f 6465 293a 0a20 2020  text, node):.   
-00008f80: 2023 2320 546f 7263 6820 706f 7274 2074   ## Torch port t
-00008f90: 6f20 4154 656e 2061 6464 7320 7363 616c  o ATen adds scal
-00008fa0: 6520 616e 6420 696e 7075 745f 7363 616c  e and input_scal
-00008fb0: 6520 7768 6963 6820 6973 2073 6574 2074  e which is set t
-00008fc0: 6f20 310a 2020 2020 696e 7075 7473 203d  o 1.    inputs =
-00008fd0: 205f 6765 745f 696e 7075 7473 2863 6f6e   _get_inputs(con
-00008fe0: 7465 7874 2c20 6e6f 6465 2c20 6578 7065  text, node, expe
-00008ff0: 6374 6564 3d34 290a 0a20 2020 2072 6573  cted=4)..    res
-00009000: 203d 206d 622e 656c 7528 783d 696e 7075   = mb.elu(x=inpu
-00009010: 7473 5b30 5d2c 2061 6c70 6861 3d69 6e70  ts[0], alpha=inp
-00009020: 7574 735b 315d 2c20 6e61 6d65 3d6e 6f64  uts[1], name=nod
-00009030: 652e 6e61 6d65 290a 2020 2020 636f 6e74  e.name).    cont
-00009040: 6578 742e 6164 6428 7265 7329 0a0a 0a40  ext.add(res)...@
-00009050: 7265 6769 7374 6572 5f74 6f72 6368 5f6f  register_torch_o
-00009060: 700a 6465 6620 6c65 616b 795f 7265 6c75  p.def leaky_relu
-00009070: 2863 6f6e 7465 7874 2c20 6e6f 6465 293a  (context, node):
-00009080: 0a20 2020 2069 6e70 7574 7320 3d20 5f67  .    inputs = _g
-00009090: 6574 5f69 6e70 7574 7328 636f 6e74 6578  et_inputs(contex
-000090a0: 742c 206e 6f64 652c 2065 7870 6563 7465  t, node, expecte
-000090b0: 643d 3229 0a0a 2020 2020 7265 7320 3d20  d=2)..    res = 
-000090c0: 6d62 2e6c 6561 6b79 5f72 656c 7528 783d  mb.leaky_relu(x=
-000090d0: 696e 7075 7473 5b30 5d2c 2061 6c70 6861  inputs[0], alpha
-000090e0: 3d69 6e70 7574 735b 315d 2c20 6e61 6d65  =inputs[1], name
-000090f0: 3d6e 6f64 652e 6e61 6d65 290a 2020 2020  =node.name).    
-00009100: 636f 6e74 6578 742e 6164 6428 7265 7329  context.add(res)
-00009110: 0a0a 0a40 7265 6769 7374 6572 5f74 6f72  ...@register_tor
-00009120: 6368 5f6f 700a 6465 6620 7272 656c 7528  ch_op.def rrelu(
-00009130: 636f 6e74 6578 742c 206e 6f64 6529 3a0a  context, node):.
-00009140: 2020 2020 696e 7075 7473 203d 205f 6765      inputs = _ge
-00009150: 745f 696e 7075 7473 2863 6f6e 7465 7874  t_inputs(context
-00009160: 2c20 6e6f 6465 2c20 6578 7065 6374 6564  , node, expected
-00009170: 3d35 290a 0a20 2020 2023 2041 6c70 6861  =5)..    # Alpha
-00009180: 2069 6e20 6576 616c 7561 7469 6f6e 206d   in evaluation m
-00009190: 6f64 6520 6973 206a 7573 7420 7468 6520  ode is just the 
-000091a0: 6176 6572 6167 6520 6265 7477 6565 6e20  average between 
-000091b0: 7570 7065 7220 616e 6420 6c6f 7765 722e  upper and lower.
-000091c0: 0a20 2020 206c 6f77 6572 5f61 6c70 6861  .    lower_alpha
-000091d0: 203d 2069 6e70 7574 735b 315d 0a20 2020   = inputs[1].   
-000091e0: 2075 7070 6572 5f61 6c70 6861 203d 2069   upper_alpha = i
-000091f0: 6e70 7574 735b 325d 0a20 2020 2061 6c70  nputs[2].    alp
-00009200: 6861 203d 2028 6c6f 7765 725f 616c 7068  ha = (lower_alph
-00009210: 612e 7661 6c20 2b20 7570 7065 725f 616c  a.val + upper_al
-00009220: 7068 612e 7661 6c29 202f 2032 0a0a 2020  pha.val) / 2..  
-00009230: 2020 7265 7320 3d20 6d62 2e6c 6561 6b79    res = mb.leaky
-00009240: 5f72 656c 7528 783d 696e 7075 7473 5b30  _relu(x=inputs[0
-00009250: 5d2c 2061 6c70 6861 3d61 6c70 6861 2c20  ], alpha=alpha, 
-00009260: 6e61 6d65 3d6e 6f64 652e 6e61 6d65 290a  name=node.name).
-00009270: 2020 2020 636f 6e74 6578 742e 6164 6428      context.add(
-00009280: 7265 7329 0a0a 0a40 7265 6769 7374 6572  res)...@register
-00009290: 5f74 6f72 6368 5f6f 700a 6465 6620 736f  _torch_op.def so
-000092a0: 6674 706c 7573 2863 6f6e 7465 7874 2c20  ftplus(context, 
-000092b0: 6e6f 6465 293a 0a20 2020 2069 6e70 7574  node):.    input
-000092c0: 7320 3d20 5f67 6574 5f69 6e70 7574 7328  s = _get_inputs(
-000092d0: 636f 6e74 6578 742c 206e 6f64 652c 2065  context, node, e
-000092e0: 7870 6563 7465 643d 3329 0a20 2020 2078  xpected=3).    x
-000092f0: 203d 2069 6e70 7574 735b 305d 0a20 2020   = inputs[0].   
-00009300: 2062 6574 615f 203d 2069 6e70 7574 735b   beta_ = inputs[
-00009310: 315d 2e76 616c 0a20 2020 2043 203d 2078  1].val.    C = x
-00009320: 2e73 6861 7065 5b31 5d0a 2020 2020 616c  .shape[1].    al
-00009330: 7068 615f 6272 203d 205f 6e70 2e72 6570  pha_br = _np.rep
-00009340: 6561 7428 312e 3020 2f20 6265 7461 5f2c  eat(1.0 / beta_,
-00009350: 2043 292e 6173 7479 7065 2827 666c 6f61   C).astype('floa
-00009360: 7433 3227 290a 2020 2020 6265 7461 5f62  t32').    beta_b
-00009370: 7220 3d20 5f6e 702e 7265 7065 6174 2862  r = _np.repeat(b
-00009380: 6574 615f 2c20 4329 2e61 7374 7970 6528  eta_, C).astype(
-00009390: 2766 6c6f 6174 3332 2729 0a0a 2020 2020  'float32')..    
-000093a0: 7265 7320 3d20 6d62 2e73 6f66 7470 6c75  res = mb.softplu
-000093b0: 735f 7061 7261 6d65 7472 6963 2878 3d78  s_parametric(x=x
-000093c0: 2c20 616c 7068 613d 616c 7068 615f 6272  , alpha=alpha_br
-000093d0: 2c20 6265 7461 3d62 6574 615f 6272 2c20  , beta=beta_br, 
-000093e0: 6e61 6d65 3d6e 6f64 652e 6e61 6d65 290a  name=node.name).
-000093f0: 2020 2020 636f 6e74 6578 742e 6164 6428      context.add(
-00009400: 7265 7329 0a0a 0a40 7265 6769 7374 6572  res)...@register
-00009410: 5f74 6f72 6368 5f6f 700a 6465 6620 6d69  _torch_op.def mi
-00009420: 7368 2863 6f6e 7465 7874 2c20 6e6f 6465  sh(context, node
-00009430: 293a 0a20 2020 2069 6e70 7574 7320 3d20  ):.    inputs = 
-00009440: 5f67 6574 5f69 6e70 7574 7328 636f 6e74  _get_inputs(cont
-00009450: 6578 742c 206e 6f64 652c 2065 7870 6563  ext, node, expec
-00009460: 7465 643d 3129 0a20 2020 2078 203d 2069  ted=1).    x = i
-00009470: 6e70 7574 735b 305d 0a0a 2020 2020 736f  nputs[0]..    so
-00009480: 6674 706c 7573 203d 206d 622e 736f 6674  ftplus = mb.soft
-00009490: 706c 7573 2878 3d78 290a 2020 2020 7461  plus(x=x).    ta
-000094a0: 6e68 203d 206d 622e 7461 6e68 2878 3d73  nh = mb.tanh(x=s
-000094b0: 6f66 7470 6c75 7329 0a20 2020 2072 6573  oftplus).    res
-000094c0: 203d 206d 622e 6d75 6c28 783d 782c 2079   = mb.mul(x=x, y
-000094d0: 3d74 616e 682c 206e 616d 653d 6e6f 6465  =tanh, name=node
-000094e0: 2e6e 616d 6529 0a20 2020 2063 6f6e 7465  .name).    conte
-000094f0: 7874 2e61 6464 2872 6573 290a 0a0a 6465  xt.add(res)...de
-00009500: 6620 5f61 646a 7573 745f 7061 645f 666f  f _adjust_pad_fo
-00009510: 725f 6365 696c 5f6d 6f64 6528 696e 7075  r_ceil_mode(inpu
-00009520: 745f 7368 6170 652c 206b 6572 6e65 6c5f  t_shape, kernel_
-00009530: 7369 7a65 2c20 7374 7269 6465 5f73 697a  size, stride_siz
-00009540: 6573 2c20 7061 645f 7369 7a65 7329 3a0a  es, pad_sizes):.
-00009550: 2020 2020 2222 2220 4769 7665 6e20 616e      """ Given an
-00009560: 2069 6e70 7574 2074 656e 736f 7220 616e   input tensor an
-00009570: 6420 706f 6f6c 696e 6720 7061 7261 6d65  d pooling parame
-00009580: 7465 7273 2c20 6164 6420 7468 6520 6578  ters, add the ex
-00009590: 7472 6120 696e 7075 740a 2020 2020 2020  tra input.      
-000095a0: 2020 7061 6464 696e 6720 6e65 6564 6564    padding needed
-000095b0: 2074 6f20 7265 706c 6963 6174 6520 6365   to replicate ce
-000095c0: 696c 5f6d 6f64 652e 0a20 2020 2020 2020  il_mode..       
-000095d0: 204d 494c 2033 4420 706f 6f6c 696e 6720   MIL 3D pooling 
-000095e0: 646f 6573 206e 6f74 2073 7570 706f 7274  does not support
-000095f0: 2063 6569 6c5f 6d6f 6465 206e 6174 6976   ceil_mode nativ
-00009600: 656c 792c 2062 7574 2077 6520 6361 6e0a  ely, but we can.
-00009610: 2020 2020 2020 2020 776f 726b 6172 6f75          workarou
-00009620: 6e64 2062 7920 7061 6464 696e 6720 7468  nd by padding th
-00009630: 6520 696e 7075 7420 6170 7072 6f70 7269  e input appropri
-00009640: 6174 656c 792e 0a0a 2020 2020 2020 2020  ately...        
-00009650: 5079 546f 7263 6820 6f75 7470 7574 2073  PyTorch output s
-00009660: 697a 6520 666f 726d 756c 6120 666f 7220  ize formula for 
-00009670: 706f 6f6c 696e 673a 0a20 2020 2020 2020  pooling:.       
-00009680: 2028 7265 6665 7265 6e63 653a 2068 7474   (reference: htt
-00009690: 7073 3a2f 2f67 6974 6875 622e 636f 6d2f  ps://github.com/
-000096a0: 7079 746f 7263 682f 7079 746f 7263 682f  pytorch/pytorch/
-000096b0: 626c 6f62 2f33 3735 6333 3061 3731 3737  blob/375c30a7177
-000096c0: 3434 3266 6239 6436 6465 3735 3136 6139  442fb9d6de7516a9
-000096d0: 6165 3430 3331 6165 3332 3463 342f 6174  ae4031ae324c4/at
-000096e0: 656e 2f73 7263 2f41 5465 6e2f 6e61 7469  en/src/ATen/nati
-000096f0: 7665 2f50 6f6f 6c2e 6823 4c32 3829 0a0a  ve/Pool.h#L28)..
-00009700: 2020 2020 2020 2020 5768 656e 2063 6569          When cei
-00009710: 6c20 6d6f 6465 2069 7320 5472 7565 3a0a  l mode is True:.
-00009720: 2020 2020 2020 2020 2020 2020 6f75 745f              out_
-00009730: 6469 6d20 3d20 666c 6f6f 7228 2869 6e5f  dim = floor((in_
-00009740: 6469 6d20 2b20 7061 645f 6c20 2b20 7061  dim + pad_l + pa
-00009750: 645f 7220 2d20 6b65 726e 656c 5f73 697a  d_r - kernel_siz
-00009760: 6520 2b20 2873 7472 6964 652d 3129 2920  e + (stride-1)) 
-00009770: 2f20 7374 7269 6465 2920 2b20 310a 2020  / stride) + 1.  
-00009780: 2020 2020 2020 2020 2020 6966 2028 6f75            if (ou
-00009790: 745f 6469 6d2d 3129 202a 2073 7472 6964  t_dim-1) * strid
-000097a0: 6520 3e3d 2069 6e5f 6469 6d20 2b20 7061  e >= in_dim + pa
-000097b0: 645f 6c20 616e 6420 2870 6164 5f6c 203e  d_l and (pad_l >
-000097c0: 2030 206f 7220 7061 645f 7220 3e20 3029   0 or pad_r > 0)
-000097d0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-000097e0: 2020 6f75 745f 6469 6d20 3d20 6f75 745f    out_dim = out_
-000097f0: 6469 6d20 2d20 310a 2020 2020 2020 2020  dim - 1.        
-00009800: 5768 656e 2063 6569 6c20 6d6f 6465 2069  When ceil mode i
-00009810: 7320 4661 6c73 653a 0a20 2020 2020 2020  s False:.       
-00009820: 2020 2020 206f 7574 5f64 696d 203d 2066       out_dim = f
-00009830: 6c6f 6f72 2828 696e 5f64 696d 202b 2070  loor((in_dim + p
-00009840: 6164 5f6c 202b 2070 6164 5f72 202d 206b  ad_l + pad_r - k
-00009850: 6572 6e65 6c5f 7369 7a65 2920 2f20 7374  ernel_size) / st
-00009860: 7269 6465 2920 2b20 310a 0a0a 2020 2020  ride) + 1...    
-00009870: 2020 2020 2320 666f 6c6c 6f77 2074 6865      # follow the
-00009880: 2061 7070 726f 6163 6820 6865 7265 2074   approach here t
-00009890: 6f20 6361 6c63 756c 6174 6520 7061 6464  o calculate padd
-000098a0: 696e 673a 0a20 2020 2020 2020 2023 2068  ing:.        # h
-000098b0: 7474 7073 3a2f 2f67 6974 6875 622e 636f  ttps://github.co
-000098c0: 6d2f 7079 746f 7263 682f 7079 746f 7263  m/pytorch/pytorc
-000098d0: 682f 626c 6f62 2f65 6466 3735 3163 6132  h/blob/edf751ca2
-000098e0: 6665 6465 6465 6364 6439 3336 3638 3734  fededecdd9366874
-000098f0: 6337 3631 3433 3163 3066 3631 6630 312f  c761431c0f61f01/
-00009900: 6174 656e 2f73 7263 2f41 5465 6e2f 6e61  aten/src/ATen/na
-00009910: 7469 7665 2f6d 6b6c 646e 6e2f 506f 6f6c  tive/mkldnn/Pool
-00009920: 696e 672e 6370 7023 4c31 3231 0a20 2020  ing.cpp#L121.   
-00009930: 2020 2020 2023 2077 6869 6368 206b 6565       # which kee
-00009940: 7073 2069 6e63 7265 6173 696e 6720 7468  ps increasing th
-00009950: 6520 7061 645f 7220 7661 6c75 6520 756e  e pad_r value un
-00009960: 7469 6c20 7468 6520 6f75 7470 7574 2073  til the output s
-00009970: 697a 6520 7769 7468 6f75 7420 7468 6520  ize without the 
-00009980: 6365 696c 206d 6f64 6520 6d61 7463 6865  ceil mode matche
-00009990: 7320 7468 6174 206f 6620 7468 6520 6365  s that of the ce
-000099a0: 696c 206d 6f64 650a 2020 2020 2222 220a  il mode.    """.
-000099b0: 0a20 2020 2064 6566 205f 6361 6c63 756c  .    def _calcul
-000099c0: 6174 655f 706f 6f6c 5f6f 7574 7075 745f  ate_pool_output_
-000099d0: 7369 7a65 2869 6e5f 6469 6d2c 206b 6572  size(in_dim, ker
-000099e0: 6e65 6c2c 2073 7472 6964 652c 2070 6164  nel, stride, pad
-000099f0: 5f6c 2c20 7061 645f 722c 2063 6569 6c5f  _l, pad_r, ceil_
-00009a00: 6d6f 6465 293a 0a20 2020 2020 2020 2069  mode):.        i
-00009a10: 6620 6365 696c 5f6d 6f64 653a 0a20 2020  f ceil_mode:.   
-00009a20: 2020 2020 2020 2020 206f 7574 5f64 696d           out_dim
-00009a30: 203d 205f 6d61 7468 2e66 6c6f 6f72 2828   = _math.floor((
-00009a40: 696e 5f64 696d 202b 2070 6164 5f72 202b  in_dim + pad_r +
-00009a50: 2070 6164 5f6c 202d 206b 6572 6e65 6c20   pad_l - kernel 
-00009a60: 2b20 7374 7269 6465 202d 2031 2920 2f20  + stride - 1) / 
-00009a70: 7374 7269 6465 2920 2b20 310a 2020 2020  stride) + 1.    
-00009a80: 2020 2020 2020 2020 6966 2028 6f75 745f          if (out_
-00009a90: 6469 6d20 2d20 3129 202a 2073 7472 6964  dim - 1) * strid
-00009aa0: 6520 3e3d 2069 6e5f 6469 6d20 2b20 7061  e >= in_dim + pa
-00009ab0: 645f 6c20 616e 6420 2870 6164 5f6c 203e  d_l and (pad_l >
-00009ac0: 2030 206f 7220 7061 645f 7220 3e20 3029   0 or pad_r > 0)
-00009ad0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00009ae0: 2020 6f75 745f 6469 6d20 3d20 6f75 745f    out_dim = out_
-00009af0: 6469 6d20 2d20 310a 2020 2020 2020 2020  dim - 1.        
-00009b00: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
-00009b10: 2020 6f75 745f 6469 6d20 3d20 5f6d 6174    out_dim = _mat
-00009b20: 682e 666c 6f6f 7228 2869 6e5f 6469 6d20  h.floor((in_dim 
-00009b30: 2b20 7061 645f 7220 2b20 7061 645f 6c20  + pad_r + pad_l 
-00009b40: 2d20 6b65 726e 656c 2920 2f20 7374 7269  - kernel) / stri
-00009b50: 6465 2920 2b20 310a 2020 2020 2020 2020  de) + 1.        
-00009b60: 7265 7475 726e 206f 7574 5f64 696d 0a0a  return out_dim..
-00009b70: 2020 2020 6e65 775f 7061 6420 3d20 7061      new_pad = pa
-00009b80: 645f 7369 7a65 732e 636f 7079 2829 0a20  d_sizes.copy(). 
-00009b90: 2020 2066 6f72 2069 6478 2069 6e20 7261     for idx in ra
-00009ba0: 6e67 6528 6c65 6e28 696e 7075 745f 7368  nge(len(input_sh
-00009bb0: 6170 6529 293a 0a20 2020 2020 2020 2069  ape)):.        i
-00009bc0: 6620 6973 5f73 796d 626f 6c69 6328 696e  f is_symbolic(in
-00009bd0: 7075 745f 7368 6170 655b 6964 785d 293a  put_shape[idx]):
-00009be0: 0a20 2020 2020 2020 2020 2020 206c 6f67  .            log
-00009bf0: 6765 722e 7761 726e 696e 6728 0a20 2020  ger.warning(.   
-00009c00: 2020 2020 2020 2020 2020 2020 2022 706f               "po
-00009c10: 6f6c 696e 6720 7061 6464 696e 6720 6164  oling padding ad
-00009c20: 6a75 7374 6564 2074 6f20 7375 7070 6f72  justed to suppor
-00009c30: 7420 6365 696c 5f6d 6f64 653d 5472 7565  t ceil_mode=True
-00009c40: 2c20 666f 7220 7379 6d62 6f6c 6963 2064  , for symbolic d
-00009c50: 696d 656e 7369 6f6e 2e22 0a20 2020 2020  imension.".     
-00009c60: 2020 2020 2020 2020 2020 2022 4f75 7470             "Outp
-00009c70: 7574 2073 6861 7065 206f 6620 7468 6520  ut shape of the 
-00009c80: 706f 6f6c 206f 7020 6d61 7962 6520 6265  pool op maybe be
-00009c90: 2077 726f 6e67 2066 6f72 2063 6572 7461   wrong for certa
-00009ca0: 696e 2069 6e70 7574 2073 6861 7065 732e  in input shapes.
-00009cb0: 220a 2020 2020 2020 2020 2020 2020 290a  ".            ).
-00009cc0: 2020 2020 2020 2020 2020 2020 6e65 775f              new_
-00009cd0: 7061 645b 3220 2a20 6964 7820 2b20 315d  pad[2 * idx + 1]
-00009ce0: 202b 3d20 7374 7269 6465 5f73 697a 6573   += stride_sizes
-00009cf0: 5b69 6478 5d20 2d20 310a 2020 2020 2020  [idx] - 1.      
-00009d00: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
-00009d10: 2020 2020 6f75 745f 6469 6d5f 7769 7468      out_dim_with
-00009d20: 5f63 6569 6c5f 6d6f 6465 203d 205f 6361  _ceil_mode = _ca
-00009d30: 6c63 756c 6174 655f 706f 6f6c 5f6f 7574  lculate_pool_out
-00009d40: 7075 745f 7369 7a65 280a 2020 2020 2020  put_size(.      
-00009d50: 2020 2020 2020 2020 2020 696e 7075 745f            input_
-00009d60: 7368 6170 655b 6964 785d 2c0a 2020 2020  shape[idx],.    
-00009d70: 2020 2020 2020 2020 2020 2020 6b65 726e              kern
-00009d80: 656c 5f73 697a 655b 6964 785d 2c0a 2020  el_size[idx],.  
-00009d90: 2020 2020 2020 2020 2020 2020 2020 7374                st
-00009da0: 7269 6465 5f73 697a 6573 5b69 6478 5d2c  ride_sizes[idx],
-00009db0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00009dc0: 2070 6164 5f73 697a 6573 5b32 202a 2069   pad_sizes[2 * i
-00009dd0: 6478 5d2c 0a20 2020 2020 2020 2020 2020  dx],.           
-00009de0: 2020 2020 2070 6164 5f73 697a 6573 5b32       pad_sizes[2
-00009df0: 202a 2069 6478 202b 2031 5d2c 0a20 2020   * idx + 1],.   
-00009e00: 2020 2020 2020 2020 2020 2020 2054 7275               Tru
-00009e10: 652c 0a20 2020 2020 2020 2020 2020 2029  e,.            )
-00009e20: 0a20 2020 2020 2020 2020 2020 2069 735f  .            is_
-00009e30: 6571 7561 6c20 3d20 4661 6c73 650a 2020  equal = False.  
-00009e40: 2020 2020 2020 2020 2020 7768 696c 6520            while 
-00009e50: 6e6f 7420 6973 5f65 7175 616c 3a0a 2020  not is_equal:.  
-00009e60: 2020 2020 2020 2020 2020 2020 2020 6f75                ou
-00009e70: 745f 6469 6d5f 7769 7468 6f75 745f 6365  t_dim_without_ce
-00009e80: 696c 5f6d 6f64 6520 3d20 5f63 616c 6375  il_mode = _calcu
-00009e90: 6c61 7465 5f70 6f6f 6c5f 6f75 7470 7574  late_pool_output
-00009ea0: 5f73 697a 6528 0a20 2020 2020 2020 2020  _size(.         
-00009eb0: 2020 2020 2020 2020 2020 2069 6e70 7574             input
-00009ec0: 5f73 6861 7065 5b69 6478 5d2c 0a20 2020  _shape[idx],.   
-00009ed0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009ee0: 206b 6572 6e65 6c5f 7369 7a65 5b69 6478   kernel_size[idx
-00009ef0: 5d2c 0a20 2020 2020 2020 2020 2020 2020  ],.             
-00009f00: 2020 2020 2020 2073 7472 6964 655f 7369         stride_si
-00009f10: 7a65 735b 6964 785d 2c0a 2020 2020 2020  zes[idx],.      
-00009f20: 2020 2020 2020 2020 2020 2020 2020 6e65                ne
-00009f30: 775f 7061 645b 3220 2a20 6964 785d 2c0a  w_pad[2 * idx],.
-00009f40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009f50: 2020 2020 6e65 775f 7061 645b 3220 2a20      new_pad[2 * 
-00009f60: 6964 7820 2b20 315d 2c0a 2020 2020 2020  idx + 1],.      
-00009f70: 2020 2020 2020 2020 2020 2020 2020 4661                Fa
-00009f80: 6c73 652c 0a20 2020 2020 2020 2020 2020  lse,.           
-00009f90: 2020 2020 2029 0a20 2020 2020 2020 2020       ).         
-00009fa0: 2020 2020 2020 2069 735f 6571 7561 6c20         is_equal 
-00009fb0: 3d20 5472 7565 0a20 2020 2020 2020 2020  = True.         
-00009fc0: 2020 2020 2020 2069 6620 6f75 745f 6469         if out_di
-00009fd0: 6d5f 7769 7468 6f75 745f 6365 696c 5f6d  m_without_ceil_m
-00009fe0: 6f64 6520 3c20 6f75 745f 6469 6d5f 7769  ode < out_dim_wi
-00009ff0: 7468 5f63 6569 6c5f 6d6f 6465 3a0a 2020  th_ceil_mode:.  
-0000a000: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a010: 2020 6e65 775f 7061 645b 3220 2a20 6964    new_pad[2 * id
-0000a020: 7820 2b20 315d 202b 3d20 310a 2020 2020  x + 1] += 1.    
-0000a030: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a040: 6973 5f65 7175 616c 203d 2046 616c 7365  is_equal = False
-0000a050: 0a0a 2020 2020 7265 7475 726e 206e 6577  ..    return new
-0000a060: 5f70 6164 0a0a 0a64 6566 205f 6d61 785f  _pad...def _max_
-0000a070: 706f 6f6c 2863 6f6e 7465 7874 2c20 6e6f  pool(context, no
-0000a080: 6465 2c20 696e 7075 7473 293a 0a20 2020  de, inputs):.   
-0000a090: 2078 203d 2069 6e70 7574 735b 305d 0a20   x = inputs[0]. 
-0000a0a0: 2020 206b 6572 6e65 6c5f 7369 7a65 7320     kernel_sizes 
-0000a0b0: 3d20 696e 7075 7473 5b31 5d0a 2020 2020  = inputs[1].    
-0000a0c0: 7374 7269 6465 7320 3d20 696e 7075 7473  strides = inputs
-0000a0d0: 5b32 5d0a 2020 2020 6966 2073 7472 6964  [2].    if strid
-0000a0e0: 6573 2e6f 702e 6f70 5f74 7970 6520 3d3d  es.op.op_type ==
-0000a0f0: 2022 636f 6e73 7422 2061 6e64 2028 6e6f   "const" and (no
-0000a100: 7420 6c69 7374 2873 7472 6964 6573 2e76  t list(strides.v
-0000a110: 616c 2929 3a0a 2020 2020 2020 2020 7374  al)):.        st
-0000a120: 7269 6465 7320 3d20 6d62 2e63 6f6e 7374  rides = mb.const
-0000a130: 2876 616c 3d6b 6572 6e65 6c5f 7369 7a65  (val=kernel_size
-0000a140: 732e 7661 6c2c 206e 616d 653d 7374 7269  s.val, name=stri
-0000a150: 6465 732e 6e61 6d65 290a 0a20 2020 2070  des.name)..    p
-0000a160: 6164 5f74 7970 6520 3d20 2263 7573 746f  ad_type = "custo
-0000a170: 6d22 0a20 2020 2023 204e 6565 6420 746f  m".    # Need to
-0000a180: 2065 7870 6c69 6369 746c 7920 7374 6174   explicitly stat
-0000a190: 6520 4c2d 522c 2054 2d42 2070 6164 0a20  e L-R, T-B pad. 
-0000a1a0: 2020 2070 6164 203d 2069 6e70 7574 735b     pad = inputs[
-0000a1b0: 335d 0a20 2020 2070 6164 203d 205f 6e70  3].    pad = _np
-0000a1c0: 2e72 6570 6561 7428 7061 642e 7661 6c2c  .repeat(pad.val,
-0000a1d0: 2032 290a 2020 2020 6469 6c61 7469 6f6e   2).    dilation
-0000a1e0: 203d 2069 6e70 7574 735b 345d 2e76 616c   = inputs[4].val
-0000a1f0: 0a20 2020 2063 6569 6c5f 6d6f 6465 203d  .    ceil_mode =
-0000a200: 2069 6e70 7574 735b 355d 2e76 616c 0a20   inputs[5].val. 
-0000a210: 2020 2069 6620 5f6e 702e 616e 7928 6469     if _np.any(di
-0000a220: 6c61 7469 6f6e 203e 2031 293a 0a20 2020  lation > 1):.   
-0000a230: 2020 2020 2023 2053 6565 3a20 7264 6172       # See: rdar
-0000a240: 3a2f 2f36 3036 3333 3733 3620 2849 6d70  ://60633736 (Imp
-0000a250: 6c65 6d65 6e74 2064 696c 6174 696f 6e20  lement dilation 
-0000a260: 666f 7220 6d69 6c20 6f70 206d 6178 5f70  for mil op max_p
-0000a270: 6f6f 6c29 0a20 2020 2020 2020 2072 6169  ool).        rai
-0000a280: 7365 2056 616c 7565 4572 726f 7228 2240  se ValueError("@
-0000a290: 6d61 785f 706f 6f6c 2064 6f65 7320 6e6f  max_pool does no
-0000a2a0: 7420 7375 7070 6f72 7420 6469 6c61 7469  t support dilati
-0000a2b0: 6f6e 203e 2031 2229 0a20 2020 2073 7061  on > 1").    spa
-0000a2c0: 7469 616c 5f72 616e 6b20 3d20 6c65 6e28  tial_rank = len(
-0000a2d0: 7061 6429 202f 2f20 320a 2020 2020 6966  pad) // 2.    if
-0000a2e0: 2073 7061 7469 616c 5f72 616e 6b20 3e20   spatial_rank > 
-0000a2f0: 3220 616e 6420 6365 696c 5f6d 6f64 6520  2 and ceil_mode 
-0000a300: 6973 2054 7275 6520 616e 6420 6c69 7374  is True and list
-0000a310: 2873 7472 6964 6573 2e76 616c 2920 213d  (strides.val) !=
-0000a320: 205b 315d 202a 206c 656e 2873 7472 6964   [1] * len(strid
-0000a330: 6573 2e76 616c 293a 0a20 2020 2020 2020  es.val):.       
-0000a340: 2023 2073 696e 6365 204d 494c 2064 6f65   # since MIL doe
-0000a350: 7320 6e6f 7420 7375 7070 6f72 7420 6365  s not support ce
-0000a360: 696c 5f6d 6f64 6520 666f 7220 3344 2070  il_mode for 3D p
-0000a370: 6f6f 6c2c 0a20 2020 2020 2020 2023 206e  ool,.        # n
-0000a380: 6565 6420 746f 2061 646a 7573 7420 7061  eed to adjust pa
-0000a390: 6464 696e 6720 7661 6c75 6573 2069 6620  dding values if 
-0000a3a0: 6365 696c 5f6d 6f64 6520 6973 2054 7275  ceil_mode is Tru
-0000a3b0: 650a 2020 2020 2020 2020 2320 6365 696c  e.        # ceil
-0000a3c0: 5f6d 6f64 6520 6f6e 6c79 2063 6175 7365  _mode only cause
-0000a3d0: 7320 616e 7920 6469 6666 6572 656e 6365  s any difference
-0000a3e0: 2074 686f 7567 682c 2069 6620 7468 6520   though, if the 
-0000a3f0: 7374 7269 6465 7320 6172 6520 6e6f 7420  strides are not 
-0000a400: 310a 2020 2020 2020 2020 785f 7370 6174  1.        x_spat
-0000a410: 6961 6c5f 6469 6d65 6e73 696f 6e73 203d  ial_dimensions =
-0000a420: 2078 2e73 6861 7065 5b2d 7370 6174 6961   x.shape[-spatia
-0000a430: 6c5f 7261 6e6b 3a5d 0a20 2020 2020 2020  l_rank:].       
-0000a440: 2070 6164 203d 205f 6164 6a75 7374 5f70   pad = _adjust_p
-0000a450: 6164 5f66 6f72 5f63 6569 6c5f 6d6f 6465  ad_for_ceil_mode
-0000a460: 2878 5f73 7061 7469 616c 5f64 696d 656e  (x_spatial_dimen
-0000a470: 7369 6f6e 732c 206b 6572 6e65 6c5f 7369  sions, kernel_si
-0000a480: 7a65 732e 7661 6c2c 2073 7472 6964 6573  zes.val, strides
-0000a490: 2e76 616c 2c20 7061 6429 0a0a 2020 2020  .val, pad)..    
-0000a4a0: 706f 6f6c 203d 206d 622e 6d61 785f 706f  pool = mb.max_po
-0000a4b0: 6f6c 280a 2020 2020 2020 2020 783d 782c  ol(.        x=x,
-0000a4c0: 0a20 2020 2020 2020 206b 6572 6e65 6c5f  .        kernel_
-0000a4d0: 7369 7a65 733d 6b65 726e 656c 5f73 697a  sizes=kernel_siz
-0000a4e0: 6573 2c0a 2020 2020 2020 2020 7374 7269  es,.        stri
-0000a4f0: 6465 733d 7374 7269 6465 732c 0a20 2020  des=strides,.   
-0000a500: 2020 2020 2070 6164 5f74 7970 653d 7061       pad_type=pa
-0000a510: 645f 7479 7065 2c0a 2020 2020 2020 2020  d_type,.        
-0000a520: 7061 643d 7061 642c 0a20 2020 2020 2020  pad=pad,.       
-0000a530: 206e 616d 653d 6e6f 6465 2e6e 616d 652c   name=node.name,
-0000a540: 0a20 2020 2020 2020 2063 6569 6c5f 6d6f  .        ceil_mo
-0000a550: 6465 3d63 6569 6c5f 6d6f 6465 2069 6620  de=ceil_mode if 
-0000a560: 7370 6174 6961 6c5f 7261 6e6b 203c 3d20  spatial_rank <= 
-0000a570: 3220 656c 7365 2046 616c 7365 2c0a 2020  2 else False,.  
-0000a580: 2020 290a 2020 2020 636f 6e74 6578 742e    ).    context.
-0000a590: 6164 6428 706f 6f6c 290a 0a0a 4072 6567  add(pool)...@reg
-0000a5a0: 6973 7465 725f 746f 7263 685f 6f70 0a64  ister_torch_op.d
-0000a5b0: 6566 206d 6178 5f70 6f6f 6c31 6428 636f  ef max_pool1d(co
-0000a5c0: 6e74 6578 742c 206e 6f64 6529 3a0a 2020  ntext, node):.  
-0000a5d0: 2020 696e 7075 7473 203d 205f 6765 745f    inputs = _get_
-0000a5e0: 696e 7075 7473 2863 6f6e 7465 7874 2c20  inputs(context, 
-0000a5f0: 6e6f 6465 2c20 6578 7065 6374 6564 3d36  node, expected=6
-0000a600: 290a 2020 2020 5f6d 6178 5f70 6f6f 6c28  ).    _max_pool(
-0000a610: 636f 6e74 6578 742c 206e 6f64 652c 2069  context, node, i
-0000a620: 6e70 7574 7329 0a0a 0a40 7265 6769 7374  nputs)...@regist
-0000a630: 6572 5f74 6f72 6368 5f6f 700a 6465 6620  er_torch_op.def 
-0000a640: 6d61 785f 706f 6f6c 3264 2863 6f6e 7465  max_pool2d(conte
-0000a650: 7874 2c20 6e6f 6465 293a 0a20 2020 2069  xt, node):.    i
-0000a660: 6e70 7574 7320 3d20 5f67 6574 5f69 6e70  nputs = _get_inp
-0000a670: 7574 7328 636f 6e74 6578 742c 206e 6f64  uts(context, nod
-0000a680: 652c 2065 7870 6563 7465 643d 3629 0a20  e, expected=6). 
-0000a690: 2020 205f 6d61 785f 706f 6f6c 2863 6f6e     _max_pool(con
-0000a6a0: 7465 7874 2c20 6e6f 6465 2c20 696e 7075  text, node, inpu
-0000a6b0: 7473 290a 0a0a 4072 6567 6973 7465 725f  ts)...@register_
-0000a6c0: 746f 7263 685f 6f70 0a64 6566 206d 6178  torch_op.def max
-0000a6d0: 5f70 6f6f 6c33 6428 636f 6e74 6578 742c  _pool3d(context,
-0000a6e0: 206e 6f64 6529 3a0a 2020 2020 696e 7075   node):.    inpu
-0000a6f0: 7473 203d 205f 6765 745f 696e 7075 7473  ts = _get_inputs
-0000a700: 2863 6f6e 7465 7874 2c20 6e6f 6465 2c20  (context, node, 
-0000a710: 6578 7065 6374 6564 3d36 290a 2020 2020  expected=6).    
-0000a720: 5f6d 6178 5f70 6f6f 6c28 636f 6e74 6578  _max_pool(contex
-0000a730: 742c 206e 6f64 652c 2069 6e70 7574 7329  t, node, inputs)
-0000a740: 0a0a 0a40 7265 6769 7374 6572 5f74 6f72  ...@register_tor
-0000a750: 6368 5f6f 700a 6465 6620 6d69 6e69 6d75  ch_op.def minimu
-0000a760: 6d28 636f 6e74 6578 742c 206e 6f64 6529  m(context, node)
-0000a770: 3a0a 2020 2020 696e 7075 7473 203d 205f  :.    inputs = _
-0000a780: 6765 745f 696e 7075 7473 2863 6f6e 7465  get_inputs(conte
-0000a790: 7874 2c20 6e6f 6465 2c20 6578 7065 6374  xt, node, expect
-0000a7a0: 6564 3d32 290a 2020 2020 6173 7365 7274  ed=2).    assert
-0000a7b0: 206c 656e 286e 6f64 652e 6f75 7470 7574   len(node.output
-0000a7c0: 7329 203d 3d20 310a 2020 2020 7820 3d20  s) == 1.    x = 
-0000a7d0: 636f 6e74 6578 745b 6e6f 6465 2e69 6e70  context[node.inp
-0000a7e0: 7574 735b 305d 5d0a 2020 2020 7920 3d20  uts[0]].    y = 
-0000a7f0: 636f 6e74 6578 745b 6e6f 6465 2e69 6e70  context[node.inp
-0000a800: 7574 735b 315d 5d0a 2020 2020 6f75 7420  uts[1]].    out 
-0000a810: 3d20 6d62 2e6d 696e 696d 756d 2878 3d78  = mb.minimum(x=x
-0000a820: 2c20 793d 792c 206e 616d 653d 6e6f 6465  , y=y, name=node
-0000a830: 2e6e 616d 6529 0a20 2020 2063 6f6e 7465  .name).    conte
-0000a840: 7874 2e61 6464 286f 7574 290a 0a0a 4072  xt.add(out)...@r
-0000a850: 6567 6973 7465 725f 746f 7263 685f 6f70  egister_torch_op
-0000a860: 0a64 6566 2063 6c61 6d70 5f6d 696e 2863  .def clamp_min(c
-0000a870: 6f6e 7465 7874 2c20 6e6f 6465 293a 0a20  ontext, node):. 
-0000a880: 2020 2078 203d 205f 6765 745f 696e 7075     x = _get_inpu
-0000a890: 7473 2863 6f6e 7465 7874 2c20 6e6f 6465  ts(context, node
-0000a8a0: 2c20 6578 7065 6374 6564 3d32 290a 2020  , expected=2).  
-0000a8b0: 2020 7820 3d20 6d62 2e63 6c69 7028 783d    x = mb.clip(x=
-0000a8c0: 785b 305d 2c20 616c 7068 613d 785b 315d  x[0], alpha=x[1]
-0000a8d0: 2c20 6265 7461 3d5f 6e70 2e69 6e66 2c20  , beta=_np.inf, 
-0000a8e0: 6e61 6d65 3d6e 6f64 652e 6e61 6d65 290a  name=node.name).
-0000a8f0: 2020 2020 636f 6e74 6578 742e 6164 6428      context.add(
-0000a900: 7829 0a0a 0a40 7265 6769 7374 6572 5f74  x)...@register_t
-0000a910: 6f72 6368 5f6f 700a 6465 6620 6d61 7869  orch_op.def maxi
-0000a920: 6d75 6d28 636f 6e74 6578 742c 206e 6f64  mum(context, nod
-0000a930: 6529 3a0a 2020 2020 696e 7075 7473 203d  e):.    inputs =
-0000a940: 205f 6765 745f 696e 7075 7473 2863 6f6e   _get_inputs(con
-0000a950: 7465 7874 2c20 6e6f 6465 2c20 6578 7065  text, node, expe
-0000a960: 6374 6564 3d32 290a 2020 2020 6173 7365  cted=2).    asse
-0000a970: 7274 206c 656e 286e 6f64 652e 6f75 7470  rt len(node.outp
-0000a980: 7574 7329 203d 3d20 310a 2020 2020 7820  uts) == 1.    x 
-0000a990: 3d20 636f 6e74 6578 745b 6e6f 6465 2e69  = context[node.i
-0000a9a0: 6e70 7574 735b 305d 5d0a 2020 2020 7920  nputs[0]].    y 
-0000a9b0: 3d20 636f 6e74 6578 745b 6e6f 6465 2e69  = context[node.i
-0000a9c0: 6e70 7574 735b 315d 5d0a 2020 2020 6f75  nputs[1]].    ou
-0000a9d0: 7420 3d20 6d62 2e6d 6178 696d 756d 2878  t = mb.maximum(x
-0000a9e0: 3d78 2c20 793d 792c 206e 616d 653d 6e6f  =x, y=y, name=no
-0000a9f0: 6465 2e6e 616d 6529 0a20 2020 2063 6f6e  de.name).    con
-0000aa00: 7465 7874 2e61 6464 286f 7574 290a 0a0a  text.add(out)...
-0000aa10: 4072 6567 6973 7465 725f 746f 7263 685f  @register_torch_
-0000aa20: 6f70 0a64 6566 2064 6976 2863 6f6e 7465  op.def div(conte
-0000aa30: 7874 2c20 6e6f 6465 293a 0a20 2020 2069  xt, node):.    i
-0000aa40: 6e70 7574 7320 3d20 5f67 6574 5f69 6e70  nputs = _get_inp
-0000aa50: 7574 7328 636f 6e74 6578 742c 206e 6f64  uts(context, nod
-0000aa60: 652c 2065 7870 6563 7465 643d 5b32 2c20  e, expected=[2, 
-0000aa70: 335d 290a 0a20 2020 2069 6620 6c65 6e28  3])..    if len(
-0000aa80: 696e 7075 7473 2920 3e20 3220 616e 6420  inputs) > 2 and 
-0000aa90: 696e 7075 7473 5b32 5d20 6973 206e 6f74  inputs[2] is not
-0000aaa0: 204e 6f6e 653a 0a20 2020 2020 2020 2072   None:.        r
-0000aab0: 6f75 6e64 696e 675f 6d6f 6465 203d 2069  ounding_mode = i
-0000aac0: 6e70 7574 735b 325d 2e76 616c 0a20 2020  nputs[2].val.   
-0000aad0: 2020 2020 2069 6620 726f 756e 6469 6e67       if rounding
-0000aae0: 5f6d 6f64 6520 3d3d 2022 666c 6f6f 7222  _mode == "floor"
-0000aaf0: 3a0a 2020 2020 2020 2020 2020 2020 2320  :.            # 
-0000ab00: 726f 756e 6420 746f 7761 7264 7320 6e65  round towards ne
-0000ab10: 6761 7469 7665 2069 6e66 696e 6974 790a  gative infinity.
-0000ab20: 2020 2020 2020 2020 2020 2020 2320 652e              # e.
-0000ab30: 672e 3a0a 2020 2020 2020 2020 2020 2020  g.:.            
-0000ab40: 2320 7661 6c75 6573 2062 6566 6f72 6520  # values before 
-0000ab50: 666c 6f6f 723a 205b 322e 362c 202d 332e  floor: [2.6, -3.
-0000ab60: 342c 202d 332e 365d 0a20 2020 2020 2020  4, -3.6].       
-0000ab70: 2020 2020 2023 2076 616c 7565 7320 6166       # values af
-0000ab80: 7465 7220 666c 6f6f 723a 205b 322c 202d  ter floor: [2, -
-0000ab90: 342c 202d 345d 0a20 2020 2020 2020 2020  4, -4].         
-0000aba0: 2020 2072 6573 203d 206d 622e 666c 6f6f     res = mb.floo
-0000abb0: 725f 6469 7628 783d 696e 7075 7473 5b30  r_div(x=inputs[0
-0000abc0: 5d2c 2079 3d69 6e70 7574 735b 315d 2c20  ], y=inputs[1], 
-0000abd0: 6e61 6d65 3d6e 6f64 652e 6e61 6d65 290a  name=node.name).
-0000abe0: 2020 2020 2020 2020 656c 6966 2072 6f75          elif rou
-0000abf0: 6e64 696e 675f 6d6f 6465 203d 3d20 2274  nding_mode == "t
-0000ac00: 7275 6e63 223a 0a20 2020 2020 2020 2020  runc":.         
-0000ac10: 2020 2023 2072 6f75 6e64 2074 6f77 6172     # round towar
-0000ac20: 6473 2030 0a20 2020 2020 2020 2020 2020  ds 0.           
-0000ac30: 2023 2065 2e67 2e3a 0a20 2020 2020 2020   # e.g.:.       
-0000ac40: 2020 2020 2023 2076 616c 7565 7320 6265       # values be
-0000ac50: 666f 7265 2074 7275 6e63 3a20 5b32 2e36  fore trunc: [2.6
-0000ac60: 2c20 2d33 2e34 2c20 2d33 2e36 5d0a 2020  , -3.4, -3.6].  
-0000ac70: 2020 2020 2020 2020 2020 2320 7661 6c75            # valu
-0000ac80: 6573 2061 6674 6572 2074 7275 6e63 3a20  es after trunc: 
-0000ac90: 5b32 2c20 2d33 2c20 2d33 5d0a 2020 2020  [2, -3, -3].    
-0000aca0: 2020 2020 2020 2020 7820 3d20 6d62 2e63          x = mb.c
-0000acb0: 6173 7428 783d 696e 7075 7473 5b30 5d2c  ast(x=inputs[0],
-0000acc0: 2064 7479 7065 3d22 6670 3332 2229 0a20   dtype="fp32"). 
-0000acd0: 2020 2020 2020 2020 2020 2079 203d 206d             y = m
-0000ace0: 622e 6361 7374 2878 3d69 6e70 7574 735b  b.cast(x=inputs[
-0000acf0: 315d 2c20 6474 7970 653d 2266 7033 3222  1], dtype="fp32"
-0000ad00: 290a 2020 2020 2020 2020 2020 2020 7a20  ).            z 
-0000ad10: 3d20 6d62 2e72 6561 6c5f 6469 7628 783d  = mb.real_div(x=
-0000ad20: 782c 2079 3d79 290a 2020 2020 2020 2020  x, y=y).        
-0000ad30: 2020 2020 7320 3d20 6d62 2e73 6967 6e28      s = mb.sign(
-0000ad40: 783d 7a29 0a20 2020 2020 2020 2020 2020  x=z).           
-0000ad50: 2061 6c6c 5f70 6f73 6974 6976 6520 3d20   all_positive = 
-0000ad60: 6d62 2e6d 756c 2878 3d7a 2c20 793d 7329  mb.mul(x=z, y=s)
-0000ad70: 0a20 2020 2020 2020 2020 2020 2061 6c6c  .            all
-0000ad80: 5f70 6f73 6974 6976 655f 666c 6f6f 7220  _positive_floor 
-0000ad90: 3d20 6d62 2e66 6c6f 6f72 2878 3d61 6c6c  = mb.floor(x=all
-0000ada0: 5f70 6f73 6974 6976 6529 0a20 2020 2020  _positive).     
-0000adb0: 2020 2020 2020 2072 6573 203d 206d 622e         res = mb.
-0000adc0: 6d75 6c28 783d 616c 6c5f 706f 7369 7469  mul(x=all_positi
-0000add0: 7665 5f66 6c6f 6f72 2c20 793d 732c 206e  ve_floor, y=s, n
-0000ade0: 616d 653d 6e6f 6465 2e6e 616d 6529 0a20  ame=node.name). 
-0000adf0: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
-0000ae00: 2020 2020 2020 2020 2072 6169 7365 204e           raise N
-0000ae10: 6f74 496d 706c 656d 656e 7465 6445 7272  otImplementedErr
-0000ae20: 6f72 280a 2020 2020 2020 2020 2020 2020  or(.            
-0000ae30: 2020 2020 2772 6f75 6e64 696e 6720 6d6f      'rounding mo
-0000ae40: 6465 2022 7b7d 2220 6e6f 7420 7375 7070  de "{}" not supp
-0000ae50: 6f72 7465 6420 696e 2074 6865 2022 6469  orted in the "di
-0000ae60: 7622 206f 7027 2e66 6f72 6d61 7428 726f  v" op'.format(ro
-0000ae70: 756e 6469 6e67 5f6d 6f64 6529 0a20 2020  unding_mode).   
-0000ae80: 2020 2020 2020 2020 2029 0a20 2020 2065           ).    e
-0000ae90: 6c73 653a 0a20 2020 2020 2020 2078 203d  lse:.        x =
-0000aea0: 206d 622e 6361 7374 2878 3d69 6e70 7574   mb.cast(x=input
-0000aeb0: 735b 305d 2c20 6474 7970 653d 2266 7033  s[0], dtype="fp3
-0000aec0: 3222 290a 2020 2020 2020 2020 7920 3d20  2").        y = 
-0000aed0: 6d62 2e63 6173 7428 783d 696e 7075 7473  mb.cast(x=inputs
-0000aee0: 5b31 5d2c 2064 7479 7065 3d22 6670 3332  [1], dtype="fp32
-0000aef0: 2229 0a20 2020 2020 2020 2072 6573 203d  ").        res =
-0000af00: 206d 622e 7265 616c 5f64 6976 2878 3d78   mb.real_div(x=x
-0000af10: 2c20 793d 792c 206e 616d 653d 6e6f 6465  , y=y, name=node
-0000af20: 2e6e 616d 6529 0a20 2020 2063 6f6e 7465  .name).    conte
-0000af30: 7874 2e61 6464 2872 6573 290a 0a0a 4072  xt.add(res)...@r
-0000af40: 6567 6973 7465 725f 746f 7263 685f 6f70  egister_torch_op
-0000af50: 2874 6f72 6368 5f61 6c69 6173 3d5b 2266  (torch_alias=["f
-0000af60: 6c6f 6f72 6469 7622 5d29 0a64 6566 2066  loordiv"]).def f
-0000af70: 6c6f 6f72 5f64 6976 6964 6528 636f 6e74  loor_divide(cont
-0000af80: 6578 742c 206e 6f64 6529 3a0a 2020 2020  ext, node):.    
-0000af90: 696e 7075 7473 203d 205f 6765 745f 696e  inputs = _get_in
-0000afa0: 7075 7473 2863 6f6e 7465 7874 2c20 6e6f  puts(context, no
-0000afb0: 6465 2c20 6578 7065 6374 6564 3d32 290a  de, expected=2).
-0000afc0: 2020 2020 696e 7075 7473 203d 2070 726f      inputs = pro
-0000afd0: 6d6f 7465 5f69 6e70 7574 5f64 7479 7065  mote_input_dtype
-0000afe0: 7328 696e 7075 7473 290a 2020 2020 6469  s(inputs).    di
-0000aff0: 765f 7265 7320 3d20 6d62 2e66 6c6f 6f72  v_res = mb.floor
-0000b000: 5f64 6976 2878 3d69 6e70 7574 735b 305d  _div(x=inputs[0]
-0000b010: 2c20 793d 696e 7075 7473 5b31 5d29 0a20  , y=inputs[1]). 
-0000b020: 2020 2023 2050 7974 6f72 6368 2773 2066     # Pytorch's f
-0000b030: 6c6f 6f72 5f64 6976 6964 6520 616c 7761  loor_divide alwa
-0000b040: 7973 2072 6574 7572 6e73 2066 7033 322c  ys returns fp32,
-0000b050: 2065 7665 6e20 6966 2074 6865 2069 6e70   even if the inp
-0000b060: 7574 7320 6172 6520 696e 740a 2020 2020  uts are int.    
-0000b070: 7265 7320 3d20 6d62 2e63 6173 7428 783d  res = mb.cast(x=
-0000b080: 6469 765f 7265 732c 2064 7479 7065 3d27  div_res, dtype='
-0000b090: 6670 3332 272c 206e 616d 653d 6e6f 6465  fp32', name=node
-0000b0a0: 2e6e 616d 6529 0a20 2020 2063 6f6e 7465  .name).    conte
-0000b0b0: 7874 2e61 6464 2872 6573 290a 0a0a 4072  xt.add(res)...@r
-0000b0c0: 6567 6973 7465 725f 746f 7263 685f 6f70  egister_torch_op
-0000b0d0: 0a64 6566 2074 7275 655f 6469 7669 6465  .def true_divide
-0000b0e0: 2863 6f6e 7465 7874 2c20 6e6f 6465 293a  (context, node):
-0000b0f0: 0a20 2020 2069 6e70 7574 7320 3d20 5f67  .    inputs = _g
-0000b100: 6574 5f69 6e70 7574 7328 636f 6e74 6578  et_inputs(contex
-0000b110: 742c 206e 6f64 652c 2065 7870 6563 7465  t, node, expecte
-0000b120: 643d 3229 0a20 2020 2072 6573 203d 206d  d=2).    res = m
-0000b130: 622e 7265 616c 5f64 6976 2878 3d69 6e70  b.real_div(x=inp
-0000b140: 7574 735b 305d 2c20 793d 696e 7075 7473  uts[0], y=inputs
-0000b150: 5b31 5d2c 206e 616d 653d 6e6f 6465 2e6e  [1], name=node.n
-0000b160: 616d 6529 0a20 2020 2063 6f6e 7465 7874  ame).    context
-0000b170: 2e61 6464 2872 6573 290a 0a0a 4072 6567  .add(res)...@reg
-0000b180: 6973 7465 725f 746f 7263 685f 6f70 0a64  ister_torch_op.d
-0000b190: 6566 206d 756c 2863 6f6e 7465 7874 2c20  ef mul(context, 
-0000b1a0: 6e6f 6465 293a 0a20 2020 2069 6e70 7574  node):.    input
-0000b1b0: 7320 3d20 5f67 6574 5f69 6e70 7574 7328  s = _get_inputs(
-0000b1c0: 636f 6e74 6578 742c 206e 6f64 652c 2065  context, node, e
-0000b1d0: 7870 6563 7465 643d 3229 0a20 2020 2078  xpected=2).    x
-0000b1e0: 2c20 7920 3d20 7072 6f6d 6f74 655f 696e  , y = promote_in
-0000b1f0: 7075 745f 6474 7970 6573 2869 6e70 7574  put_dtypes(input
-0000b200: 7329 0a20 2020 2072 6573 203d 206d 622e  s).    res = mb.
-0000b210: 6d75 6c28 783d 782c 2079 3d79 2c20 6e61  mul(x=x, y=y, na
-0000b220: 6d65 3d6e 6f64 652e 6e61 6d65 290a 2020  me=node.name).  
-0000b230: 2020 636f 6e74 6578 742e 6164 6428 7265    context.add(re
-0000b240: 7329 0a0a 0a40 7265 6769 7374 6572 5f74  s)...@register_t
-0000b250: 6f72 6368 5f6f 700a 6465 6620 706f 7728  orch_op.def pow(
-0000b260: 636f 6e74 6578 742c 206e 6f64 6529 3a0a  context, node):.
-0000b270: 2020 2020 696e 7075 7473 203d 205f 6765      inputs = _ge
-0000b280: 745f 696e 7075 7473 2863 6f6e 7465 7874  t_inputs(context
-0000b290: 2c20 6e6f 6465 2c20 6578 7065 6374 6564  , node, expected
-0000b2a0: 3d32 290a 2020 2020 782c 2079 203d 2070  =2).    x, y = p
-0000b2b0: 726f 6d6f 7465 5f69 6e70 7574 5f64 7479  romote_input_dty
-0000b2c0: 7065 7328 696e 7075 7473 290a 2020 2020  pes(inputs).    
-0000b2d0: 7265 7320 3d20 6d62 2e70 6f77 2878 3d78  res = mb.pow(x=x
-0000b2e0: 2c20 793d 792c 206e 616d 653d 6e6f 6465  , y=y, name=node
-0000b2f0: 2e6e 616d 6529 0a20 2020 2063 6f6e 7465  .name).    conte
-0000b300: 7874 2e61 6464 2872 6573 290a 0a0a 4072  xt.add(res)...@r
-0000b310: 6567 6973 7465 725f 746f 7263 685f 6f70  egister_torch_op
-0000b320: 2874 6f72 6368 5f61 6c69 6173 3d5b 2272  (torch_alias=["r
-0000b330: 7375 6222 5d29 0a64 6566 2073 7562 2863  sub"]).def sub(c
-0000b340: 6f6e 7465 7874 2c20 6e6f 6465 293a 0a20  ontext, node):. 
-0000b350: 2020 2069 6e70 7574 7320 3d20 5f67 6574     inputs = _get
-0000b360: 5f69 6e70 7574 7328 636f 6e74 6578 742c  _inputs(context,
-0000b370: 206e 6f64 652c 2065 7870 6563 7465 643d   node, expected=
-0000b380: 5b32 2c20 335d 290a 2020 2020 6173 7365  [2, 3]).    asse
-0000b390: 7274 206c 656e 286e 6f64 652e 6f75 7470  rt len(node.outp
-0000b3a0: 7574 7329 203d 3d20 310a 0a20 2020 2069  uts) == 1..    i
-0000b3b0: 6620 6e6f 6465 2e6b 696e 6420 3d3d 2022  f node.kind == "
-0000b3c0: 7273 7562 223a 0a20 2020 2020 2020 2023  rsub":.        #
-0000b3d0: 2072 7375 6220 7265 7665 7273 6573 2074   rsub reverses t
-0000b3e0: 6865 206f 7264 6572 206f 6620 6172 6775  he order of argu
-0000b3f0: 6d65 6e74 730a 2020 2020 2020 2020 7920  ments.        y 
-0000b400: 3d20 696e 7075 7473 5b30 5d0a 2020 2020  = inputs[0].    
-0000b410: 2020 2020 7820 3d20 696e 7075 7473 5b31      x = inputs[1
-0000b420: 5d0a 2020 2020 656c 7365 3a0a 2020 2020  ].    else:.    
-0000b430: 2020 2020 7820 3d20 696e 7075 7473 5b30      x = inputs[0
-0000b440: 5d0a 2020 2020 2020 2020 7920 3d20 696e  ].        y = in
-0000b450: 7075 7473 5b31 5d0a 0a20 2020 2069 6620  puts[1]..    if 
-0000b460: 6c65 6e28 696e 7075 7473 2920 3e20 323a  len(inputs) > 2:
-0000b470: 0a20 2020 2020 2020 2061 6c70 6861 203d  .        alpha =
-0000b480: 2069 6e70 7574 735b 325d 2e76 616c 0a0a   inputs[2].val..
-0000b490: 2020 2020 2020 2020 2320 544f 444f 2028          # TODO (
-0000b4a0: 7362 6572 6172 6469 293a 2033 7264 2070  sberardi): 3rd p
-0000b4b0: 6172 616d 2074 6f20 6174 656e 3a3a 7375  aram to aten::su
-0000b4c0: 6220 6973 2061 2073 6361 6c65 2066 6163  b is a scale fac
-0000b4d0: 746f 722c 206e 6565 6420 746f 2068 616e  tor, need to han
-0000b4e0: 646c 6520 7468 6174 2e0a 2020 2020 2020  dle that..      
-0000b4f0: 2020 2320 6f75 743d 696e 7075 742d 616c    # out=input-al
-0000b500: 7068 6120 7820 6f74 6865 720a 2020 2020  pha x other.    
-0000b510: 2020 2020 2320 7264 6172 3a2f 2f36 3031      # rdar://601
-0000b520: 3735 3733 360a 2020 2020 2020 2020 6966  75736.        if
-0000b530: 2061 6c70 6861 2021 3d20 313a 0a20 2020   alpha != 1:.   
-0000b540: 2020 2020 2020 2020 2072 6169 7365 2056           raise V
-0000b550: 616c 7565 4572 726f 7228 2253 5542 2064  alueError("SUB d
-0000b560: 6f65 7320 6e6f 7420 7375 7070 6f72 7420  oes not support 
-0000b570: 7363 616c 6520 6661 6374 6f72 2070 6172  scale factor par
-0000b580: 616d 2229 0a0a 2020 2020 782c 2079 203d  am")..    x, y =
-0000b590: 2070 726f 6d6f 7465 5f69 6e70 7574 5f64   promote_input_d
-0000b5a0: 7479 7065 7328 5b78 2c20 795d 290a 2020  types([x, y]).  
-0000b5b0: 2020 7265 7320 3d20 6d62 2e73 7562 2878    res = mb.sub(x
-0000b5c0: 3d78 2c20 793d 792c 206e 616d 653d 6e6f  =x, y=y, name=no
-0000b5d0: 6465 2e6e 616d 6529 0a20 2020 2063 6f6e  de.name).    con
-0000b5e0: 7465 7874 2e61 6464 2872 6573 290a 0a0a  text.add(res)...
-0000b5f0: 4072 6567 6973 7465 725f 746f 7263 685f  @register_torch_
-0000b600: 6f70 280a 2020 2020 746f 7263 685f 616c  op(.    torch_al
-0000b610: 6961 733d 5b0a 2020 2020 2020 2020 2273  ias=[.        "s
-0000b620: 756d 222c 0a20 2020 2020 2020 2022 6c6f  um",.        "lo
-0000b630: 6773 756d 6578 7022 2c0a 2020 2020 5d29  gsumexp",.    ])
-0000b640: 0a64 6566 206d 6561 6e28 636f 6e74 6578  .def mean(contex
-0000b650: 742c 206e 6f64 6529 3a0a 2020 2020 696e  t, node):.    in
-0000b660: 7075 7473 203d 205f 6765 745f 696e 7075  puts = _get_inpu
-0000b670: 7473 2863 6f6e 7465 7874 2c20 6e6f 6465  ts(context, node
-0000b680: 290a 0a20 2020 2078 203d 2069 6e70 7574  )..    x = input
-0000b690: 735b 305d 0a20 2020 2069 6620 7479 7065  s[0].    if type
-0000b6a0: 732e 6973 5f62 6f6f 6c28 782e 6474 7970  s.is_bool(x.dtyp
-0000b6b0: 6529 3a0a 2020 2020 2020 2020 2320 544f  e):.        # TO
-0000b6c0: 444f 3a20 496e 2074 6865 2066 7574 7572  DO: In the futur
-0000b6d0: 6520 7768 656e 204d 494c 206f 7020 7375  e when MIL op su
-0000b6e0: 7070 6f72 7473 2062 6f6f 6c2c 2077 6520  pports bool, we 
-0000b6f0: 6e65 6564 2074 6f20 7573 6520 6375 7272  need to use curr
-0000b700: 5f6f 7073 6574 5f76 6572 7369 6f6e 2074  _opset_version t
-0000b710: 6f20 6465 6369 6465 0a20 2020 2020 2020  o decide.       
-0000b720: 2023 2069 6620 7765 2077 616e 7420 746f   # if we want to
-0000b730: 2063 6173 7420 6f72 206e 6f74 2e0a 2020   cast or not..  
-0000b740: 2020 2020 2020 7820 3d20 6d62 2e63 6173        x = mb.cas
-0000b750: 7428 783d 782c 2064 7479 7065 3d22 6670  t(x=x, dtype="fp
-0000b760: 3332 2229 0a20 2020 206b 7761 7267 7320  32").    kwargs 
-0000b770: 3d20 7b22 7822 3a20 782c 2022 6e61 6d65  = {"x": x, "name
-0000b780: 223a 206e 6f64 652e 6e61 6d65 7d0a 0a20  ": node.name}.. 
-0000b790: 2020 2023 2040 6178 6573 2069 7320 6f70     # @axes is op
-0000b7a0: 7469 6f6e 616c 2c20 736f 206f 6d69 7420  tional, so omit 
-0000b7b0: 6966 204e 6f6e 652e 0a20 2020 2061 7865  if None..    axe
-0000b7c0: 7320 3d20 696e 7075 7473 5b31 5d0a 2020  s = inputs[1].  
-0000b7d0: 2020 6966 2061 7865 7320 6973 206e 6f74    if axes is not
-0000b7e0: 204e 6f6e 653a 0a20 2020 2020 2020 2023   None:.        #
-0000b7f0: 2040 6178 6573 206e 6565 6473 2074 6f20   @axes needs to 
-0000b800: 6265 2061 206c 6973 742c 2062 7574 2069  be a list, but i
-0000b810: 6620 6f6e 6c79 206f 6e65 2061 7869 7320  f only one axis 
-0000b820: 7761 7320 7370 6563 6966 6965 6420 696e  was specified in
-0000b830: 2074 6865 0a20 2020 2020 2020 2023 206d   the.        # m
-0000b840: 6f64 656c 2c20 6974 2077 696c 6c20 6265  odel, it will be
-0000b850: 2063 6f6e 7374 7275 6374 6564 2061 7320   constructed as 
-0000b860: 616e 2069 6e74 2e20 436f 6e73 7472 7563  an int. Construc
-0000b870: 7420 6120 6e65 7720 636f 6e73 7461 6e74  t a new constant
-0000b880: 2061 7320 610a 2020 2020 2020 2020 2320   as a.        # 
-0000b890: 6c69 7374 2e0a 2020 2020 2020 2020 6966  list..        if
-0000b8a0: 206e 6f74 2069 7369 6e73 7461 6e63 6528   not isinstance(
-0000b8b0: 6178 6573 2e76 616c 2c20 5f6e 702e 6e64  axes.val, _np.nd
-0000b8c0: 6172 7261 7929 3a0a 2020 2020 2020 2020  array):.        
-0000b8d0: 2020 2020 6178 6573 203d 206d 622e 636f      axes = mb.co
-0000b8e0: 6e73 7428 7661 6c3d 5b61 7865 732e 7661  nst(val=[axes.va
-0000b8f0: 6c5d 2c20 6e61 6d65 3d61 7865 732e 6e61  l], name=axes.na
-0000b900: 6d65 202b 2022 5f6c 6973 7422 290a 2020  me + "_list").  
-0000b910: 2020 2020 2020 2020 2020 636f 6e74 6578            contex
-0000b920: 742e 6164 6428 6178 6573 290a 2020 2020  t.add(axes).    
-0000b930: 2020 2020 6b77 6172 6773 5b22 6178 6573      kwargs["axes
-0000b940: 225d 203d 2061 7865 730a 0a20 2020 2023  "] = axes..    #
-0000b950: 2040 6b65 6570 5f64 696d 7320 6973 206f   @keep_dims is o
-0000b960: 7074 696f 6e61 6c2e 0a20 2020 2069 6620  ptional..    if 
-0000b970: 6c65 6e28 696e 7075 7473 2920 3e3d 2033  len(inputs) >= 3
-0000b980: 3a0a 2020 2020 2020 2020 6b65 6570 5f64  :.        keep_d
-0000b990: 696d 7320 3d20 696e 7075 7473 5b32 5d0a  ims = inputs[2].
-0000b9a0: 2020 2020 2020 2020 6b77 6172 6773 5b22          kwargs["
-0000b9b0: 6b65 6570 5f64 696d 7322 5d20 3d20 6b65  keep_dims"] = ke
-0000b9c0: 6570 5f64 696d 730a 0a20 2020 2023 204c  ep_dims..    # L
-0000b9d0: 6173 7420 696e 7075 7420 746f 206d 6561  ast input to mea
-0000b9e0: 6e20 6973 2061 6e20 6f70 7469 6f6e 616c  n is an optional
-0000b9f0: 206f 7574 7075 7420 7465 6e73 6f72 2e20   output tensor. 
-0000ba00: 5765 2061 6c77 6179 7320 6578 7065 6374  We always expect
-0000ba10: 2074 6869 7320 746f 0a20 2020 2023 2062   this to.    # b
-0000ba20: 6520 4e6f 6e65 206f 7220 6162 7365 6e74  e None or absent
-0000ba30: 2e0a 2020 2020 6173 7365 7274 206c 656e  ..    assert len
-0000ba40: 2869 6e70 7574 7329 203c 3d20 3320 6f72  (inputs) <= 3 or
-0000ba50: 2069 6e70 7574 735b 335d 2069 7320 4e6f   inputs[3] is No
-0000ba60: 6e65 0a20 2020 2069 6620 6e6f 6465 2e6b  ne.    if node.k
-0000ba70: 696e 6420 3d3d 2022 7375 6d22 3a0a 2020  ind == "sum":.  
-0000ba80: 2020 2020 2020 7265 7320 3d20 6d62 2e72        res = mb.r
-0000ba90: 6564 7563 655f 7375 6d28 2a2a 6b77 6172  educe_sum(**kwar
-0000baa0: 6773 290a 2020 2020 656c 6966 206e 6f64  gs).    elif nod
-0000bab0: 652e 6b69 6e64 203d 3d20 226c 6f67 7375  e.kind == "logsu
-0000bac0: 6d65 7870 223a 0a20 2020 2020 2020 2072  mexp":.        r
-0000bad0: 6573 203d 206d 622e 7265 6475 6365 5f6c  es = mb.reduce_l
-0000bae0: 6f67 5f73 756d 5f65 7870 282a 2a6b 7761  og_sum_exp(**kwa
-0000baf0: 7267 7329 0a20 2020 2065 6c73 653a 0a20  rgs).    else:. 
-0000bb00: 2020 2020 2020 2072 6573 203d 206d 622e         res = mb.
-0000bb10: 7265 6475 6365 5f6d 6561 6e28 2a2a 6b77  reduce_mean(**kw
-0000bb20: 6172 6773 290a 2020 2020 636f 6e74 6578  args).    contex
-0000bb30: 742e 6164 6428 7265 7329 0a0a 0a40 7265  t.add(res)...@re
-0000bb40: 6769 7374 6572 5f74 6f72 6368 5f6f 700a  gister_torch_op.
-0000bb50: 6465 6620 7371 7565 657a 6528 636f 6e74  def squeeze(cont
-0000bb60: 6578 742c 206e 6f64 6529 3a0a 2020 2020  ext, node):.    
-0000bb70: 696e 7075 7473 203d 205f 6765 745f 696e  inputs = _get_in
-0000bb80: 7075 7473 2863 6f6e 7465 7874 2c20 6e6f  puts(context, no
-0000bb90: 6465 290a 2020 2020 6966 206c 656e 2869  de).    if len(i
-0000bba0: 6e70 7574 7329 203d 3d20 313a 0a20 2020  nputs) == 1:.   
-0000bbb0: 2020 2020 2072 6573 203d 206d 622e 7371       res = mb.sq
-0000bbc0: 7565 657a 6528 783d 696e 7075 7473 5b30  ueeze(x=inputs[0
-0000bbd0: 5d2c 206e 616d 653d 6e6f 6465 2e6e 616d  ], name=node.nam
-0000bbe0: 6529 0a20 2020 2065 6c69 6620 6c65 6e28  e).    elif len(
-0000bbf0: 696e 7075 7473 2920 3d3d 2032 3a0a 2020  inputs) == 2:.  
-0000bc00: 2020 2020 2020 7371 7565 657a 655f 6469        squeeze_di
-0000bc10: 6d20 3d20 696e 7075 7473 5b31 5d2e 7661  m = inputs[1].va
-0000bc20: 6c0a 2020 2020 2020 2020 7265 7320 3d20  l.        res = 
-0000bc30: 6d62 2e73 7175 6565 7a65 2878 3d69 6e70  mb.squeeze(x=inp
-0000bc40: 7574 735b 305d 2c20 6178 6573 3d28 7371  uts[0], axes=(sq
-0000bc50: 7565 657a 655f 6469 6d2c 292c 206e 616d  ueeze_dim,), nam
-0000bc60: 653d 6e6f 6465 2e6e 616d 6529 0a20 2020  e=node.name).   
-0000bc70: 2063 6f6e 7465 7874 2e61 6464 2872 6573   context.add(res
-0000bc80: 290a 0a0a 4072 6567 6973 7465 725f 746f  )...@register_to
-0000bc90: 7263 685f 6f70 0a64 6566 2075 6e73 7175  rch_op.def unsqu
-0000bca0: 6565 7a65 2863 6f6e 7465 7874 2c20 6e6f  eeze(context, no
-0000bcb0: 6465 293a 0a20 2020 2069 6e70 7574 7320  de):.    inputs 
-0000bcc0: 3d20 5f67 6574 5f69 6e70 7574 7328 636f  = _get_inputs(co
-0000bcd0: 6e74 6578 742c 206e 6f64 652c 2065 7870  ntext, node, exp
-0000bce0: 6563 7465 643d 3229 0a20 2020 2075 6e73  ected=2).    uns
-0000bcf0: 7175 6565 7a65 203d 206d 622e 6578 7061  queeze = mb.expa
-0000bd00: 6e64 5f64 696d 7328 783d 696e 7075 7473  nd_dims(x=inputs
-0000bd10: 5b30 5d2c 2061 7865 733d 5b69 6e70 7574  [0], axes=[input
-0000bd20: 735b 315d 2e76 616c 5d2c 206e 616d 653d  s[1].val], name=
-0000bd30: 6e6f 6465 2e6e 616d 6529 0a20 2020 2063  node.name).    c
-0000bd40: 6f6e 7465 7874 2e61 6464 2875 6e73 7175  ontext.add(unsqu
-0000bd50: 6565 7a65 290a 0a0a 4072 6567 6973 7465  eeze)...@registe
-0000bd60: 725f 746f 7263 685f 6f70 0a64 6566 2073  r_torch_op.def s
-0000bd70: 697a 6528 636f 6e74 6578 742c 206e 6f64  ize(context, nod
-0000bd80: 6529 3a0a 2020 2020 696e 7075 7473 203d  e):.    inputs =
-0000bd90: 205f 6765 745f 696e 7075 7473 2863 6f6e   _get_inputs(con
-0000bda0: 7465 7874 2c20 6e6f 6465 2c20 6578 7065  text, node, expe
-0000bdb0: 6374 6564 3d5b 312c 2032 5d29 0a20 2020  cted=[1, 2]).   
-0000bdc0: 2078 203d 2069 6e70 7574 735b 305d 0a0a   x = inputs[0]..
-0000bdd0: 2020 2020 2320 4765 7420 7468 6520 7368      # Get the sh
-0000bde0: 6170 6520 6f66 2074 6865 2074 656e 736f  ape of the tenso
-0000bdf0: 722e 0a20 2020 2069 6620 7479 7065 732e  r..    if types.
-0000be00: 6973 5f63 6f6d 706c 6578 2878 2e64 7479  is_complex(x.dty
-0000be10: 7065 293a 0a20 2020 2020 2020 2073 697a  pe):.        siz
-0000be20: 655f 6e6f 6465 203d 206d 622e 636f 6d70  e_node = mb.comp
-0000be30: 6c65 785f 7368 6170 6528 783d 696e 7075  lex_shape(x=inpu
-0000be40: 7473 5b30 5d2c 206e 616d 653d 6e6f 6465  ts[0], name=node
-0000be50: 2e6e 616d 6520 2b20 225f 7368 6170 6522  .name + "_shape"
-0000be60: 290a 2020 2020 656c 7365 3a0a 2020 2020  ).    else:.    
-0000be70: 2020 2020 7369 7a65 5f6e 6f64 6520 3d20      size_node = 
-0000be80: 6d62 2e73 6861 7065 2878 3d69 6e70 7574  mb.shape(x=input
-0000be90: 735b 305d 2c20 6e61 6d65 3d6e 6f64 652e  s[0], name=node.
-0000bea0: 6e61 6d65 202b 2022 5f73 6861 7065 2229  name + "_shape")
-0000beb0: 0a0a 2020 2020 2320 4765 7420 7468 6520  ..    # Get the 
-0000bec0: 7369 7a65 206f 6620 7468 6520 7465 6e73  size of the tens
-0000bed0: 6f72 2061 6c6f 6e67 2074 6865 2069 6e70  or along the inp
-0000bee0: 7574 2064 696d 656e 7369 6f6e 2e0a 2020  ut dimension..  
-0000bef0: 2020 6966 206c 656e 286e 6f64 652e 696e    if len(node.in
-0000bf00: 7075 7473 2920 3d3d 2032 3a0a 2020 2020  puts) == 2:.    
-0000bf10: 2020 2020 6469 6d20 3d20 696e 7075 7473      dim = inputs
-0000bf20: 5b31 5d2e 7661 6c0a 2020 2020 2020 2020  [1].val.        
-0000bf30: 7369 7a65 5f6e 6f64 6520 3d20 5f6c 6973  size_node = _lis
-0000bf40: 745f 7365 6c65 6374 2873 697a 655f 6e6f  t_select(size_no
-0000bf50: 6465 2c20 6469 6d29 0a20 2020 2063 6f6e  de, dim).    con
-0000bf60: 7465 7874 2e61 6464 2873 697a 655f 6e6f  text.add(size_no
-0000bf70: 6465 2c20 6e6f 6465 2e6e 616d 6529 0a0a  de, node.name)..
-0000bf80: 0a40 7265 6769 7374 6572 5f74 6f72 6368  .@register_torch
-0000bf90: 5f6f 700a 6465 6620 5f73 6861 7065 5f61  _op.def _shape_a
-0000bfa0: 735f 7465 6e73 6f72 2863 6f6e 7465 7874  s_tensor(context
-0000bfb0: 2c20 6e6f 6465 293a 0a20 2020 2069 6e70  , node):.    inp
-0000bfc0: 7574 7320 3d20 5f67 6574 5f69 6e70 7574  uts = _get_input
-0000bfd0: 7328 636f 6e74 6578 742c 206e 6f64 652c  s(context, node,
-0000bfe0: 2065 7870 6563 7465 643d 3129 0a0a 2020   expected=1)..  
-0000bff0: 2020 2320 4765 7420 7468 6520 7368 6170    # Get the shap
-0000c000: 6520 6f66 2074 6865 2074 656e 736f 722e  e of the tensor.
-0000c010: 0a20 2020 2073 6861 7065 5f6e 6f64 6520  .    shape_node 
-0000c020: 3d20 6d62 2e73 6861 7065 2878 3d69 6e70  = mb.shape(x=inp
-0000c030: 7574 735b 305d 2c20 6e61 6d65 3d6e 6f64  uts[0], name=nod
-0000c040: 652e 6e61 6d65 290a 2020 2020 636f 6e74  e.name).    cont
-0000c050: 6578 742e 6164 6428 7368 6170 655f 6e6f  ext.add(shape_no
-0000c060: 6465 2c20 6e6f 6465 2e6e 616d 6529 0a0a  de, node.name)..
-0000c070: 0a40 7265 6769 7374 6572 5f74 6f72 6368  .@register_torch
-0000c080: 5f6f 7028 746f 7263 685f 616c 6961 733d  _op(torch_alias=
-0000c090: 5b22 7265 7368 6170 6522 5d29 0a64 6566  ["reshape"]).def
-0000c0a0: 2076 6965 7728 636f 6e74 6578 742c 206e   view(context, n
-0000c0b0: 6f64 6529 3a0a 2020 2020 696e 7075 7473  ode):.    inputs
-0000c0c0: 203d 205f 6765 745f 696e 7075 7473 2863   = _get_inputs(c
-0000c0d0: 6f6e 7465 7874 2c20 6e6f 6465 2c20 6578  ontext, node, ex
-0000c0e0: 7065 6374 6564 3d32 290a 2020 2020 7820  pected=2).    x 
-0000c0f0: 3d20 696e 7075 7473 5b30 5d0a 2020 2020  = inputs[0].    
-0000c100: 7368 6170 6520 3d20 696e 7075 7473 5b31  shape = inputs[1
-0000c110: 5d0a 0a20 2020 2069 6620 6973 696e 7374  ]..    if isinst
-0000c120: 616e 6365 2873 6861 7065 2c20 4c69 7374  ance(shape, List
-0000c130: 5661 7229 3a0a 2020 2020 2020 2020 6c65  Var):.        le
-0000c140: 6e67 7468 203d 206d 622e 6c69 7374 5f6c  ngth = mb.list_l
-0000c150: 656e 6774 6828 6c73 3d73 6861 7065 290a  ength(ls=shape).
-0000c160: 2020 2020 2020 2020 696e 6469 6365 7320          indices 
-0000c170: 3d20 6d62 2e72 616e 6765 5f31 6428 7374  = mb.range_1d(st
-0000c180: 6172 743d 302c 2065 6e64 3d6c 656e 6774  art=0, end=lengt
-0000c190: 682c 2073 7465 703d 3129 0a20 2020 2020  h, step=1).     
-0000c1a0: 2020 2073 6861 7065 203d 206d 622e 6c69     shape = mb.li
-0000c1b0: 7374 5f67 6174 6865 7228 6c73 3d73 6861  st_gather(ls=sha
-0000c1c0: 7065 2c20 696e 6469 6365 733d 696e 6469  pe, indices=indi
-0000c1d0: 6365 7329 0a0a 2020 2020 6966 2028 0a20  ces)..    if (. 
-0000c1e0: 2020 2020 2020 2069 7369 6e73 7461 6e63         isinstanc
-0000c1f0: 6528 7368 6170 652c 206c 6973 7429 0a20  e(shape, list). 
-0000c200: 2020 2020 2020 2061 6e64 2061 6c6c 285b         and all([
-0000c210: 6973 696e 7374 616e 6365 2864 696d 2c20  isinstance(dim, 
-0000c220: 5661 7229 2061 6e64 206c 656e 2864 696d  Var) and len(dim
-0000c230: 2e73 6861 7065 2920 3d3d 2030 2066 6f72  .shape) == 0 for
-0000c240: 2064 696d 2069 6e20 7368 6170 655d 290a   dim in shape]).
-0000c250: 2020 2020 2020 2020 616e 6420 616e 7928          and any(
-0000c260: 5b64 696d 2e76 616c 2069 7320 4e6f 6e65  [dim.val is None
-0000c270: 2066 6f72 2064 696d 2069 6e20 7368 6170   for dim in shap
-0000c280: 655d 290a 2020 2020 293a 0a20 2020 2020  e]).    ):.     
-0000c290: 2020 2073 6861 7065 203d 206d 622e 636f     shape = mb.co
-0000c2a0: 6e63 6174 2876 616c 7565 733d 7368 6170  ncat(values=shap
-0000c2b0: 652c 2061 7869 733d 3029 0a0a 2020 2020  e, axis=0)..    
-0000c2c0: 7368 6170 6520 3d20 6d62 2e63 6173 7428  shape = mb.cast(
-0000c2d0: 783d 7368 6170 652c 2064 7479 7065 3d22  x=shape, dtype="
-0000c2e0: 696e 7433 3222 290a 2020 2020 7669 6577  int32").    view
-0000c2f0: 203d 206d 622e 7265 7368 6170 6528 783d   = mb.reshape(x=
-0000c300: 782c 2073 6861 7065 3d73 6861 7065 2c20  x, shape=shape, 
-0000c310: 6e61 6d65 3d6e 6f64 652e 6e61 6d65 290a  name=node.name).
-0000c320: 2020 2020 636f 6e74 6578 742e 6164 6428      context.add(
-0000c330: 7669 6577 290a 0a0a 4072 6567 6973 7465  view)...@registe
-0000c340: 725f 746f 7263 685f 6f70 2874 6f72 6368  r_torch_op(torch
-0000c350: 5f61 6c69 6173 3d5b 2763 6f6e 7374 616e  _alias=['constan
-0000c360: 745f 7061 645f 6e64 275d 290a 6465 6620  t_pad_nd']).def 
-0000c370: 7061 6428 636f 6e74 6578 742c 206e 6f64  pad(context, nod
-0000c380: 6529 3a0a 2020 2020 696e 7075 7473 203d  e):.    inputs =
-0000c390: 205f 6765 745f 696e 7075 7473 2863 6f6e   _get_inputs(con
-0000c3a0: 7465 7874 2c20 6e6f 6465 290a 2020 2020  text, node).    
-0000c3b0: 7820 3d20 696e 7075 7473 5b30 5d0a 0a20  x = inputs[0].. 
-0000c3c0: 2020 2070 6164 203d 2069 6e70 7574 735b     pad = inputs[
-0000c3d0: 315d 0a20 2020 2069 6620 7061 642e 7661  1].    if pad.va
-0000c3e0: 6c20 6973 206e 6f74 204e 6f6e 653a 0a20  l is not None:. 
-0000c3f0: 2020 2020 2020 2070 6164 203d 2070 6164         pad = pad
-0000c400: 2e76 616c 2e72 6573 6861 7065 2828 2d31  .val.reshape((-1
-0000c410: 2c20 3229 295b 3a3a 2d31 5d2e 7265 7368  , 2))[::-1].resh
-0000c420: 6170 6528 2d31 292e 746f 6c69 7374 2829  ape(-1).tolist()
-0000c430: 0a20 2020 2020 2020 206d 6973 7369 6e67  .        missing
-0000c440: 5f64 696d 7320 3d20 782e 7261 6e6b 202d  _dims = x.rank -
-0000c450: 2028 6c65 6e28 7061 6429 202f 2f20 3229   (len(pad) // 2)
-0000c460: 0a20 2020 2020 2020 2070 6164 203d 205b  .        pad = [
-0000c470: 302c 2030 5d20 2a20 6d69 7373 696e 675f  0, 0] * missing_
-0000c480: 6469 6d73 202b 2070 6164 0a0a 2020 2020  dims + pad..    
-0000c490: 6966 206c 656e 2869 6e70 7574 7329 203d  if len(inputs) =
-0000c4a0: 3d20 343a 0a20 2020 2020 2020 206d 6f64  = 4:.        mod
-0000c4b0: 6520 3d20 696e 7075 7473 5b32 5d2e 7661  e = inputs[2].va
-0000c4c0: 6c0a 2020 2020 2020 2020 6173 7365 7274  l.        assert
-0000c4d0: 206d 6f64 6520 696e 2028 2763 6f6e 7374   mode in ('const
-0000c4e0: 616e 7427 2c20 2772 6566 6c65 6374 272c  ant', 'reflect',
-0000c4f0: 2027 7265 706c 6963 6174 6527 290a 2020   'replicate').  
-0000c500: 2020 2020 2020 7661 6c5f 696e 6465 7820        val_index 
-0000c510: 3d20 330a 2020 2020 656c 7365 3a0a 2020  = 3.    else:.  
-0000c520: 2020 2020 2020 6d6f 6465 203d 2027 636f        mode = 'co
-0000c530: 6e73 7461 6e74 270a 2020 2020 2020 2020  nstant'.        
-0000c540: 7661 6c5f 696e 6465 7820 3d20 320a 0a20  val_index = 2.. 
-0000c550: 2020 2073 6361 6c61 725f 7661 6c20 3d20     scalar_val = 
-0000c560: 696e 7075 7473 5b76 616c 5f69 6e64 6578  inputs[val_index
-0000c570: 5d20 6966 2069 6e70 7574 735b 7661 6c5f  ] if inputs[val_
-0000c580: 696e 6465 785d 2065 6c73 6520 302e 300a  index] else 0.0.
-0000c590: 2020 2020 6966 2069 6e70 7574 735b 7661      if inputs[va
-0000c5a0: 6c5f 696e 6465 785d 2061 6e64 2069 6e70  l_index] and inp
-0000c5b0: 7574 735b 7661 6c5f 696e 6465 785d 2e6f  uts[val_index].o
-0000c5c0: 702e 6f70 5f74 7970 6520 3d3d 2022 636f  p.op_type == "co
-0000c5d0: 6e73 7422 3a0a 2020 2020 2020 2020 7363  nst":.        sc
-0000c5e0: 616c 6172 5f76 616c 203d 2066 6c6f 6174  alar_val = float
-0000c5f0: 2873 6361 6c61 725f 7661 6c2e 7661 6c29  (scalar_val.val)
-0000c600: 0a0a 2020 2020 7265 7320 3d20 6d62 2e70  ..    res = mb.p
-0000c610: 6164 2878 3d78 2c20 7061 643d 7061 642c  ad(x=x, pad=pad,
-0000c620: 206d 6f64 653d 6d6f 6465 2c20 636f 6e73   mode=mode, cons
-0000c630: 7461 6e74 5f76 616c 3d73 6361 6c61 725f  tant_val=scalar_
-0000c640: 7661 6c2c 206e 616d 653d 6e6f 6465 2e6e  val, name=node.n
-0000c650: 616d 6529 0a20 2020 2063 6f6e 7465 7874  ame).    context
-0000c660: 2e61 6464 2872 6573 290a 0a0a 4072 6567  .add(res)...@reg
-0000c670: 6973 7465 725f 746f 7263 685f 6f70 0a64  ister_torch_op.d
-0000c680: 6566 2061 6461 7074 6976 655f 6176 675f  ef adaptive_avg_
-0000c690: 706f 6f6c 3264 2863 6f6e 7465 7874 2c20  pool2d(context, 
-0000c6a0: 6e6f 6465 293a 0a20 2020 205f 6164 6170  node):.    _adap
-0000c6b0: 7469 7665 5f70 6f6f 6c32 6428 636f 6e74  tive_pool2d(cont
-0000c6c0: 6578 742c 206e 6f64 652c 206d 622e 6176  ext, node, mb.av
-0000c6d0: 675f 706f 6f6c 2c20 6d62 2e72 6564 7563  g_pool, mb.reduc
-0000c6e0: 655f 6d65 616e 290a 0a0a 4072 6567 6973  e_mean)...@regis
-0000c6f0: 7465 725f 746f 7263 685f 6f70 0a64 6566  ter_torch_op.def
-0000c700: 2061 6461 7074 6976 655f 6d61 785f 706f   adaptive_max_po
-0000c710: 6f6c 3264 2863 6f6e 7465 7874 2c20 6e6f  ol2d(context, no
-0000c720: 6465 293a 0a20 2020 205f 6164 6170 7469  de):.    _adapti
-0000c730: 7665 5f70 6f6f 6c32 6428 636f 6e74 6578  ve_pool2d(contex
-0000c740: 742c 206e 6f64 652c 206d 622e 6d61 785f  t, node, mb.max_
-0000c750: 706f 6f6c 2c20 6d62 2e72 6564 7563 655f  pool, mb.reduce_
-0000c760: 6d61 7829 0a0a 0a64 6566 205f 6164 6170  max)...def _adap
-0000c770: 7469 7665 5f70 6f6f 6c32 645f 6e6f 6e5f  tive_pool2d_non_
-0000c780: 6669 7865 645f 6b65 726e 656c 5f73 697a  fixed_kernel_siz
-0000c790: 655f 616e 645f 7374 7269 6465 2878 2c20  e_and_stride(x, 
-0000c7a0: 6f75 7470 7574 5f73 6861 7065 2c20 6e61  output_shape, na
-0000c7b0: 6d65 2c20 7265 6475 6365 5f6f 7029 3a0a  me, reduce_op):.
-0000c7c0: 2020 2020 2727 270a 2020 2020 4966 2074      '''.    If t
-0000c7d0: 6865 2069 6e70 7574 2064 696d 656e 7369  he input dimensi
-0000c7e0: 6f6e 2069 7320 6e6f 7420 6576 656e 6c79  on is not evenly
-0000c7f0: 2064 6976 6973 6962 6c65 2062 7920 7468   divisible by th
-0000c800: 6520 6f75 7470 7574 2064 696d 656e 7369  e output dimensi
-0000c810: 6f6e 2c20 7468 656e 2074 6865 0a20 2020  on, then the.   
-0000c820: 2073 7472 6964 6520 616e 6420 6b65 726e   stride and kern
-0000c830: 656c 2073 697a 6520 7573 6564 2062 7920  el size used by 
-0000c840: 5079 546f 7263 6820 6973 206e 6f74 2066  PyTorch is not f
-0000c850: 6978 6564 2e20 5468 6973 2069 7320 7472  ixed. This is tr
-0000c860: 7565 2066 6f72 2062 6f74 6820 7468 650a  ue for both the.
-0000c870: 2020 2020 6865 6967 6874 2061 6e64 2077      height and w
-0000c880: 6964 7468 2064 696d 656e 7369 6f6e 2e0a  idth dimension..
-0000c890: 2020 2020 2727 270a 0a20 2020 2064 6566      '''..    def
-0000c8a0: 2067 6574 5f6b 6572 6e65 6c5f 696e 6465   get_kernel_inde
-0000c8b0: 7865 735f 3164 2869 6e5f 6469 6d65 6e73  xes_1d(in_dimens
-0000c8c0: 696f 6e2c 206f 7574 5f64 696d 656e 7369  ion, out_dimensi
-0000c8d0: 6f6e 293a 0a20 2020 2020 2020 2072 6573  on):.        res
-0000c8e0: 756c 7473 203d 205b 5d0a 2020 2020 2020  ults = [].      
-0000c8f0: 2020 666f 7220 6920 696e 2072 616e 6765    for i in range
-0000c900: 286f 7574 5f64 696d 656e 7369 6f6e 293a  (out_dimension):
-0000c910: 0a20 2020 2020 2020 2020 2020 2073 7461  .            sta
-0000c920: 7274 203d 205f 6d61 7468 2e66 6c6f 6f72  rt = _math.floor
-0000c930: 2869 202a 2069 6e5f 6469 6d65 6e73 696f  (i * in_dimensio
-0000c940: 6e20 2f20 6f75 745f 6469 6d65 6e73 696f  n / out_dimensio
-0000c950: 6e29 0a20 2020 2020 2020 2020 2020 2065  n).            e
-0000c960: 6e64 203d 205f 6d61 7468 2e63 6569 6c28  nd = _math.ceil(
-0000c970: 2869 202b 2031 2920 2a20 696e 5f64 696d  (i + 1) * in_dim
-0000c980: 656e 7369 6f6e 202f 206f 7574 5f64 696d  ension / out_dim
-0000c990: 656e 7369 6f6e 290a 2020 2020 2020 2020  ension).        
-0000c9a0: 2020 2020 7265 7375 6c74 732e 6170 7065      results.appe
-0000c9b0: 6e64 2828 7374 6172 742c 2065 6e64 2929  nd((start, end))
-0000c9c0: 0a0a 2020 2020 2020 2020 7265 7475 726e  ..        return
-0000c9d0: 2072 6573 756c 7473 0a0a 2020 2020 706f   results..    po
-0000c9e0: 6f6c 5f72 6573 756c 7473 203d 205b 5d0a  ol_results = [].
-0000c9f0: 0a20 2020 2066 6f72 2073 322c 2065 3220  .    for s2, e2 
-0000ca00: 696e 2067 6574 5f6b 6572 6e65 6c5f 696e  in get_kernel_in
-0000ca10: 6465 7865 735f 3164 2878 2e73 6861 7065  dexes_1d(x.shape
-0000ca20: 5b32 5d2c 206f 7574 7075 745f 7368 6170  [2], output_shap
-0000ca30: 655b 305d 293a 0a20 2020 2020 2020 2066  e[0]):.        f
-0000ca40: 6f72 2073 332c 2065 3320 696e 2067 6574  or s3, e3 in get
-0000ca50: 5f6b 6572 6e65 6c5f 696e 6465 7865 735f  _kernel_indexes_
-0000ca60: 3164 2878 2e73 6861 7065 5b33 5d2c 206f  1d(x.shape[3], o
-0000ca70: 7574 7075 745f 7368 6170 655b 315d 293a  utput_shape[1]):
-0000ca80: 0a20 2020 2020 2020 2020 2020 2063 7572  .            cur
-0000ca90: 5f6b 6572 6e65 6c20 3d20 6d62 2e73 6c69  _kernel = mb.sli
-0000caa0: 6365 5f62 795f 696e 6465 7828 0a20 2020  ce_by_index(.   
-0000cab0: 2020 2020 2020 2020 2020 2020 2078 3d78               x=x
-0000cac0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-0000cad0: 2020 6265 6769 6e3d 5b30 2c20 302c 2073    begin=[0, 0, s
-0000cae0: 322c 2073 335d 2c0a 2020 2020 2020 2020  2, s3],.        
-0000caf0: 2020 2020 2020 2020 656e 643d 5b78 2e73          end=[x.s
-0000cb00: 6861 7065 5b30 5d2c 2078 2e73 6861 7065  hape[0], x.shape
-0000cb10: 5b31 5d2c 2065 322c 2065 335d 2c0a 2020  [1], e2, e3],.  
-0000cb20: 2020 2020 2020 2020 2020 290a 2020 2020            ).    
-0000cb30: 2020 2020 2020 2020 6375 725f 7265 7375          cur_resu
-0000cb40: 6c74 203d 2072 6564 7563 655f 6f70 280a  lt = reduce_op(.
-0000cb50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000cb60: 783d 6375 725f 6b65 726e 656c 2c0a 2020  x=cur_kernel,.  
-0000cb70: 2020 2020 2020 2020 2020 2020 2020 6178                ax
-0000cb80: 6573 3d5b 2d32 2c20 2d31 5d2c 0a20 2020  es=[-2, -1],.   
-0000cb90: 2020 2020 2020 2020 2020 2020 206b 6565               kee
-0000cba0: 705f 6469 6d73 3d54 7275 650a 2020 2020  p_dims=True.    
-0000cbb0: 2020 2020 2020 2020 290a 2020 2020 2020          ).      
-0000cbc0: 2020 2020 2020 706f 6f6c 5f72 6573 756c        pool_resul
-0000cbd0: 7473 2e61 7070 656e 6428 6375 725f 7265  ts.append(cur_re
-0000cbe0: 7375 6c74 290a 0a20 2020 2072 6574 7572  sult)..    retur
-0000cbf0: 6e20 6d62 2e72 6573 6861 7065 280a 2020  n mb.reshape(.  
-0000cc00: 2020 2020 2020 783d 6d62 2e63 6f6e 6361        x=mb.conca
-0000cc10: 7428 7661 6c75 6573 3d70 6f6f 6c5f 7265  t(values=pool_re
-0000cc20: 7375 6c74 732c 2061 7869 733d 2d31 292c  sults, axis=-1),
-0000cc30: 0a20 2020 2020 2020 2073 6861 7065 3d5b  .        shape=[
-0000cc40: 782e 7368 6170 655b 305d 2c20 782e 7368  x.shape[0], x.sh
-0000cc50: 6170 655b 315d 2c20 6f75 7470 7574 5f73  ape[1], output_s
-0000cc60: 6861 7065 5b30 5d2c 206f 7574 7075 745f  hape[0], output_
-0000cc70: 7368 6170 655b 315d 5d2c 0a20 2020 2020  shape[1]],.     
-0000cc80: 2020 206e 616d 653d 6e61 6d65 2c0a 2020     name=name,.  
-0000cc90: 2020 290a 0a0a 6465 6620 5f61 6461 7074    )...def _adapt
-0000cca0: 6976 655f 706f 6f6c 3264 2863 6f6e 7465  ive_pool2d(conte
-0000ccb0: 7874 2c20 6e6f 6465 2c20 706f 6f6c 5f6f  xt, node, pool_o
-0000ccc0: 702c 2072 6564 7563 655f 6f70 293a 0a20  p, reduce_op):. 
-0000ccd0: 2020 2023 2047 6574 2069 6e70 7574 2074     # Get input t
-0000cce0: 656e 736f 7220 616e 6420 6f75 7470 7574  ensor and output
-0000ccf0: 2073 6861 7065 0a20 2020 2069 6e70 7574   shape.    input
-0000cd00: 7320 3d20 5f67 6574 5f69 6e70 7574 7328  s = _get_inputs(
-0000cd10: 636f 6e74 6578 742c 206e 6f64 652c 2065  context, node, e
-0000cd20: 7870 6563 7465 643d 3229 0a20 2020 2078  xpected=2).    x
-0000cd30: 203d 2069 6e70 7574 735b 305d 0a20 2020   = inputs[0].   
-0000cd40: 206f 7574 7075 745f 7368 6170 6520 3d20   output_shape = 
-0000cd50: 696e 7075 7473 5b31 5d2e 7661 6c0a 2020  inputs[1].val.  
-0000cd60: 2020 6173 7365 7274 2069 7369 6e73 7461    assert isinsta
-0000cd70: 6e63 6528 6f75 7470 7574 5f73 6861 7065  nce(output_shape
-0000cd80: 2c20 5f6e 702e 6e64 6172 7261 7929 2061  , _np.ndarray) a
-0000cd90: 6e64 206c 656e 286f 7574 7075 745f 7368  nd len(output_sh
-0000cda0: 6170 6529 203d 3d20 320a 2020 2020 6f75  ape) == 2.    ou
-0000cdb0: 7470 7574 5f73 6861 7065 203d 2074 7570  tput_shape = tup
-0000cdc0: 6c65 286f 7574 7075 745f 7368 6170 6529  le(output_shape)
-0000cdd0: 0a0a 2020 2020 6966 206f 7574 7075 745f  ..    if output_
-0000cde0: 7368 6170 6520 3d3d 2028 312c 2031 293a  shape == (1, 1):
-0000cdf0: 0a20 2020 2020 2020 2023 2052 6570 7265  .        # Repre
-0000ce00: 7365 6e74 2028 312c 3129 206f 7574 7075  sent (1,1) outpu
-0000ce10: 7420 7369 7a65 2077 6974 6820 676c 6f62  t size with glob
-0000ce20: 616c 2072 6564 7563 6520 6f70 0a20 2020  al reduce op.   
-0000ce30: 2020 2020 2072 6573 756c 7420 3d20 7265       result = re
-0000ce40: 6475 6365 5f6f 7028 783d 782c 2061 7865  duce_op(x=x, axe
-0000ce50: 733d 5b2d 322c 202d 315d 2c20 6b65 6570  s=[-2, -1], keep
-0000ce60: 5f64 696d 733d 5472 7565 2c20 6e61 6d65  _dims=True, name
-0000ce70: 3d6e 6f64 652e 6e61 6d65 290a 2020 2020  =node.name).    
-0000ce80: 656c 6966 2078 2e73 6861 7065 2069 7320  elif x.shape is 
-0000ce90: 4e6f 6e65 206f 7220 616e 795f 7379 6d62  None or any_symb
-0000cea0: 6f6c 6963 2878 2e73 6861 7065 293a 0a20  olic(x.shape):. 
-0000ceb0: 2020 2020 2020 2072 6169 7365 2056 616c         raise Val
-0000cec0: 7565 4572 726f 7228 0a20 2020 2020 2020  ueError(.       
-0000ced0: 2020 2020 2022 4164 6170 7469 7665 2070       "Adaptive p
-0000cee0: 6f6f 6c69 6e67 2069 7320 6f6e 6c79 2073  ooling is only s
-0000cef0: 7570 706f 7274 6564 2077 6865 6e20 696e  upported when in
-0000cf00: 7075 7420 7465 6e73 6f72 2073 697a 6520  put tensor size 
-0000cf10: 6973 206b 6e6f 776e 206f 7220 6f75 7470  is known or outp
-0000cf20: 7574 2073 697a 6520 3d3d 2028 312c 3129  ut size == (1,1)
-0000cf30: 2e20 220a 2020 2020 2020 2020 2020 2020  . ".            
-0000cf40: 2252 6563 6569 7665 643a 2069 6e70 7574  "Received: input
-0000cf50: 2073 697a 6520 3d3d 207b 7d2c 206f 7574   size == {}, out
-0000cf60: 7075 7420 7369 7a65 203d 3d20 7b7d 222e  put size == {}".
-0000cf70: 666f 726d 6174 280a 2020 2020 2020 2020  format(.        
-0000cf80: 2020 2020 2020 2020 782e 7368 6170 655f          x.shape_
-0000cf90: 7374 7228 292c 206f 7574 7075 745f 7368  str(), output_sh
-0000cfa0: 6170 652c 0a20 2020 2020 2020 2020 2020  ape,.           
-0000cfb0: 2029 0a20 2020 2020 2020 2029 0a20 2020   ).        ).   
-0000cfc0: 2065 6c69 6620 782e 7368 6170 655b 2d32   elif x.shape[-2
-0000cfd0: 5d20 2520 6f75 7470 7574 5f73 6861 7065  ] % output_shape
-0000cfe0: 5b2d 325d 203d 3d20 3020 616e 6420 782e  [-2] == 0 and x.
-0000cff0: 7368 6170 655b 2d31 5d20 2520 6f75 7470  shape[-1] % outp
-0000d000: 7574 5f73 6861 7065 5b2d 315d 203d 3d20  ut_shape[-1] == 
-0000d010: 303a 0a20 2020 2020 2020 2023 2053 7472  0:.        # Str
-0000d020: 6964 6520 616e 6420 616e 6420 6b65 726e  ide and and kern
-0000d030: 656c 2073 697a 6520 6973 2066 6978 6564  el size is fixed
-0000d040: 0a20 2020 2020 2020 2073 7472 6964 6573  .        strides
-0000d050: 203d 205b 696e 6420 2f2f 206f 7574 6420   = [ind // outd 
-0000d060: 666f 7220 696e 642c 206f 7574 6420 696e  for ind, outd in
-0000d070: 207a 6970 2878 2e73 6861 7065 5b2d 323a   zip(x.shape[-2:
-0000d080: 5d2c 206f 7574 7075 745f 7368 6170 6529  ], output_shape)
-0000d090: 5d0a 2020 2020 2020 2020 6b65 726e 656c  ].        kernel
-0000d0a0: 5f73 697a 6573 203d 205b 0a20 2020 2020  _sizes = [.     
-0000d0b0: 2020 2020 2020 2069 6e64 202d 2073 202a         ind - s *
-0000d0c0: 2028 6f75 7464 202d 2031 290a 2020 2020   (outd - 1).    
-0000d0d0: 2020 2020 2020 2020 666f 7220 696e 642c          for ind,
-0000d0e0: 206f 7574 642c 2073 2069 6e20 7a69 7028   outd, s in zip(
-0000d0f0: 782e 7368 6170 655b 2d32 3a5d 2c20 6f75  x.shape[-2:], ou
-0000d100: 7470 7574 5f73 6861 7065 2c20 7374 7269  tput_shape, stri
-0000d110: 6465 7329 0a20 2020 2020 2020 205d 0a20  des).        ]. 
-0000d120: 2020 2020 2020 2072 6573 756c 7420 3d20         result = 
-0000d130: 706f 6f6c 5f6f 7028 0a20 2020 2020 2020  pool_op(.       
-0000d140: 2020 2020 2078 3d78 2c0a 2020 2020 2020       x=x,.      
-0000d150: 2020 2020 2020 6b65 726e 656c 5f73 697a        kernel_siz
-0000d160: 6573 3d6b 6572 6e65 6c5f 7369 7a65 732c  es=kernel_sizes,
-0000d170: 0a20 2020 2020 2020 2020 2020 2073 7472  .            str
-0000d180: 6964 6573 3d73 7472 6964 6573 2c0a 2020  ides=strides,.  
-0000d190: 2020 2020 2020 2020 2020 7061 645f 7479            pad_ty
-0000d1a0: 7065 3d22 7661 6c69 6422 2c0a 2020 2020  pe="valid",.    
-0000d1b0: 2020 2020 2020 2020 6e61 6d65 3d6e 6f64          name=nod
-0000d1c0: 652e 6e61 6d65 2c0a 2020 2020 2020 2020  e.name,.        
-0000d1d0: 290a 2020 2020 656c 7365 3a0a 2020 2020  ).    else:.    
-0000d1e0: 2020 2020 7265 7375 6c74 203d 205f 6164      result = _ad
-0000d1f0: 6170 7469 7665 5f70 6f6f 6c32 645f 6e6f  aptive_pool2d_no
-0000d200: 6e5f 6669 7865 645f 6b65 726e 656c 5f73  n_fixed_kernel_s
-0000d210: 697a 655f 616e 645f 7374 7269 6465 280a  ize_and_stride(.
-0000d220: 2020 2020 2020 2020 2020 2020 782c 206f              x, o
-0000d230: 7574 7075 745f 7368 6170 652c 206e 6f64  utput_shape, nod
-0000d240: 652e 6e61 6d65 2c20 7265 6475 6365 5f6f  e.name, reduce_o
-0000d250: 700a 2020 2020 2020 2020 290a 0a20 2020  p.        )..   
-0000d260: 2063 6f6e 7465 7874 2e61 6464 2872 6573   context.add(res
-0000d270: 756c 7429 0a0a 0a40 7265 6769 7374 6572  ult)...@register
-0000d280: 5f74 6f72 6368 5f6f 700a 6465 6620 6261  _torch_op.def ba
-0000d290: 7463 685f 6e6f 726d 2863 6f6e 7465 7874  tch_norm(context
-0000d2a0: 2c20 6e6f 6465 293a 0a20 2020 2069 6e70  , node):.    inp
-0000d2b0: 7574 7320 3d20 5f67 6574 5f69 6e70 7574  uts = _get_input
-0000d2c0: 7328 636f 6e74 6578 742c 206e 6f64 652c  s(context, node,
-0000d2d0: 2065 7870 6563 7465 643d 3929 0a20 2020   expected=9).   
-0000d2e0: 2023 2069 6e70 7574 7320 736b 6970 7065   # inputs skippe
-0000d2f0: 643a 0a20 2020 2023 2020 2066 6c6f 6174  d:.    #   float
-0000d300: 206d 6f6d 656e 7475 6d20 2836 290a 2020   momentum (6).  
-0000d310: 2020 2320 2020 626f 6f6c 2063 7564 6e6e    #   bool cudnn
-0000d320: 5f65 6e61 626c 6564 2028 3829 0a20 2020  _enabled (8).   
-0000d330: 2069 6e70 7574 5f72 616e 6b20 3d20 696e   input_rank = in
-0000d340: 7075 7473 5b30 5d2e 7261 6e6b 0a20 2020  puts[0].rank.   
-0000d350: 2069 6620 696e 7075 745f 7261 6e6b 203c   if input_rank <
-0000d360: 2032 206f 7220 696e 7075 745f 7261 6e6b   2 or input_rank
-0000d370: 203e 2035 3a0a 2020 2020 2020 2020 7261   > 5:.        ra
-0000d380: 6973 6520 5661 6c75 6545 7272 6f72 280a  ise ValueError(.
-0000d390: 2020 2020 2020 2020 2020 2020 2242 6174              "Bat
-0000d3a0: 6368 4e6f 726d 3a20 456e 636f 756e 7465  chNorm: Encounte
-0000d3b0: 7265 6420 696e 7661 6c69 6420 696e 7075  red invalid inpu
-0000d3c0: 7420 7261 6e6b 2064 7572 696e 6720 7472  t rank during tr
-0000d3d0: 616e 736c 6174 696f 6e20 696e 2074 6f72  anslation in tor
-0000d3e0: 6368 2066 726f 6e74 656e 642e 220a 2020  ch frontend.".  
-0000d3f0: 2020 2020 2020 290a 0a20 2020 205f 696e        )..    _in
-0000d400: 7075 7420 3d20 696e 7075 7473 5b30 5d0a  put = inputs[0].
-0000d410: 2020 2020 7765 6967 6874 203d 2069 6e70      weight = inp
-0000d420: 7574 735b 315d 0a20 2020 2062 6961 7320  uts[1].    bias 
-0000d430: 3d20 696e 7075 7473 5b32 5d0a 2020 2020  = inputs[2].    
-0000d440: 7275 6e6e 696e 675f 6d65 616e 203d 2069  running_mean = i
-0000d450: 6e70 7574 735b 335d 0a20 2020 2072 756e  nputs[3].    run
-0000d460: 6e69 6e67 5f76 6172 203d 2069 6e70 7574  ning_var = input
-0000d470: 735b 345d 0a20 2020 2074 7261 696e 696e  s[4].    trainin
-0000d480: 6720 3d20 696e 7075 7473 5b35 5d2e 7661  g = inputs[5].va
-0000d490: 6c0a 2020 2020 6570 7320 3d20 696e 7075  l.    eps = inpu
-0000d4a0: 7473 5b37 5d0a 0a20 2020 2023 2049 6620  ts[7]..    # If 
-0000d4b0: 7472 6169 6e69 6e67 203d 2054 7275 652c  training = True,
-0000d4c0: 2074 6865 206d 6561 6e20 616e 6420 7661   the mean and va
-0000d4d0: 7269 616e 6365 206f 6620 7468 6520 6375  riance of the cu
-0000d4e0: 7272 656e 7420 6261 7463 6820 6f66 2064  rrent batch of d
-0000d4f0: 6174 6120 6172 6520 7573 6564 2074 6f20  ata are used to 
-0000d500: 6e6f 726d 616c 697a 6520 7468 6520 696e  normalize the in
-0000d510: 7075 7420 6461 7461 2e0a 2020 2020 2320  put data..    # 
-0000d520: 4966 2074 7261 696e 696e 6720 3d20 4661  If training = Fa
-0000d530: 6c73 652c 2064 6174 6120 7374 6174 6973  lse, data statis
-0000d540: 7469 6373 2072 756e 6e69 6e67 5f6d 6561  tics running_mea
-0000d550: 6e20 616e 6420 7275 6e6e 696e 675f 7661  n and running_va
-0000d560: 7220 6172 6520 7573 6564 2069 6e73 7465  r are used inste
-0000d570: 6164 2e0a 2020 2020 2320 4e6f 7465 2074  ad..    # Note t
-0000d580: 6861 742c 2065 7665 6e20 696e 2074 6865  hat, even in the
-0000d590: 2065 7661 6c75 6174 696f 6e20 6d6f 6465   evaluation mode
-0000d5a0: 2028 6166 7465 7220 6361 6c6c 696e 6720   (after calling 
-0000d5b0: 6d6f 6465 6c2e 6576 616c 2829 292c 2074  model.eval()), t
-0000d5c0: 6865 2074 7261 696e 696e 6720 7061 7261  he training para
-0000d5d0: 6d65 7465 7220 6361 6e20 7374 696c 6c20  meter can still 
-0000d5e0: 6265 2074 7275 650a 2020 2020 2320 616e  be true.    # an
-0000d5f0: 6420 6974 206a 7573 7420 7265 6665 7273  d it just refers
-0000d600: 2074 6f20 6120 6469 6666 6572 656e 7420   to a different 
-0000d610: 636f 6d70 7574 6174 696f 6e20 6173 206d  computation as m
-0000d620: 656e 7469 6f6e 6564 2061 626f 7665 2e0a  entioned above..
-0000d630: 0a20 2020 2023 2068 656c 7065 7220 6675  .    # helper fu
-0000d640: 6e63 7469 6f6e 7320 666f 7220 6469 6666  nctions for diff
-0000d650: 6572 656e 7420 7479 7065 206f 6620 6261  erent type of ba
-0000d660: 7463 6820 6e6f 726d 0a20 2020 2064 6566  tch norm.    def
-0000d670: 205f 6164 645f 6261 7463 685f 6e6f 726d   _add_batch_norm
-0000d680: 5f64 796e 616d 6963 2829 3a0a 2020 2020  _dynamic():.    
-0000d690: 2020 2020 7820 3d20 5f69 6e70 7574 0a0a      x = _input..
-0000d6a0: 2020 2020 2020 2020 6966 2074 7261 696e          if train
-0000d6b0: 696e 6720 6f72 2028 7275 6e6e 696e 675f  ing or (running_
-0000d6c0: 6d65 616e 2069 7320 4e6f 6e65 2920 6f72  mean is None) or
-0000d6d0: 2028 7275 6e6e 696e 675f 7661 7220 6973   (running_var is
-0000d6e0: 204e 6f6e 6529 3a0a 2020 2020 2020 2020   None):.        
-0000d6f0: 2020 2020 6178 6573 203d 205b 6178 6973      axes = [axis
-0000d700: 2066 6f72 2061 7869 7320 696e 2072 616e   for axis in ran
-0000d710: 6765 2878 2e72 616e 6b29 2069 6620 6178  ge(x.rank) if ax
-0000d720: 6973 2021 3d20 315d 0a20 2020 2020 2020  is != 1].       
-0000d730: 2020 2020 206d 6561 6e20 3d20 6d62 2e72       mean = mb.r
-0000d740: 6564 7563 655f 6d65 616e 2878 3d78 2c20  educe_mean(x=x, 
-0000d750: 6178 6573 3d61 7865 732c 206b 6565 705f  axes=axes, keep_
-0000d760: 6469 6d73 3d54 7275 6529 0a20 2020 2020  dims=True).     
-0000d770: 2020 2020 2020 206e 756d 203d 206d 622e         num = mb.
-0000d780: 7375 6228 783d 782c 2079 3d6d 6561 6e29  sub(x=x, y=mean)
-0000d790: 0a20 2020 2020 2020 2020 2020 2073 7175  .            squ
-0000d7a0: 6172 6520 3d20 6d62 2e6d 756c 2878 3d6e  are = mb.mul(x=n
-0000d7b0: 756d 2c20 793d 6e75 6d29 0a20 2020 2020  um, y=num).     
-0000d7c0: 2020 2020 2020 2076 6172 6961 6e63 6520         variance 
-0000d7d0: 3d20 6d62 2e72 6564 7563 655f 6d65 616e  = mb.reduce_mean
-0000d7e0: 2878 3d73 7175 6172 652c 2061 7865 733d  (x=square, axes=
-0000d7f0: 6178 6573 2c20 6b65 6570 5f64 696d 733d  axes, keep_dims=
-0000d800: 5472 7565 290a 2020 2020 2020 2020 2020  True).          
-0000d810: 2020 7368 6170 6520 3d20 6d62 2e73 6861    shape = mb.sha
-0000d820: 7065 2878 3d76 6172 6961 6e63 6529 0a20  pe(x=variance). 
-0000d830: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
-0000d840: 2020 2020 2020 2020 2073 6861 7065 203d           shape =
-0000d850: 205b 315d 202a 2078 2e72 616e 6b0a 2020   [1] * x.rank.  
-0000d860: 2020 2020 2020 2020 2020 7368 6170 655b            shape[
-0000d870: 315d 203d 202d 3120 6966 2061 6e79 5f73  1] = -1 if any_s
-0000d880: 796d 626f 6c69 6328 7275 6e6e 696e 675f  ymbolic(running_
-0000d890: 6d65 616e 2e73 6861 7065 2920 656c 7365  mean.shape) else
-0000d8a0: 2072 756e 6e69 6e67 5f6d 6561 6e2e 7368   running_mean.sh
-0000d8b0: 6170 655b 305d 0a20 2020 2020 2020 2020  ape[0].         
-0000d8c0: 2020 206d 6561 6e20 3d20 6d62 2e72 6573     mean = mb.res
-0000d8d0: 6861 7065 2878 3d72 756e 6e69 6e67 5f6d  hape(x=running_m
-0000d8e0: 6561 6e2c 2073 6861 7065 3d73 6861 7065  ean, shape=shape
-0000d8f0: 290a 2020 2020 2020 2020 2020 2020 6e75  ).            nu
-0000d900: 6d20 3d20 6d62 2e73 7562 2878 3d78 2c20  m = mb.sub(x=x, 
-0000d910: 793d 6d65 616e 290a 2020 2020 2020 2020  y=mean).        
-0000d920: 2020 2020 7661 7269 616e 6365 203d 206d      variance = m
-0000d930: 622e 7265 7368 6170 6528 783d 7275 6e6e  b.reshape(x=runn
-0000d940: 696e 675f 7661 722c 2073 6861 7065 3d73  ing_var, shape=s
-0000d950: 6861 7065 290a 0a20 2020 2020 2020 2076  hape)..        v
-0000d960: 6172 6961 6e63 655f 6164 645f 6570 7369  ariance_add_epsi
-0000d970: 6c6f 6e20 3d20 6d62 2e61 6464 2878 3d76  lon = mb.add(x=v
-0000d980: 6172 6961 6e63 652c 2079 3d65 7073 290a  ariance, y=eps).
-0000d990: 2020 2020 2020 2020 7371 7274 203d 206d          sqrt = m
-0000d9a0: 622e 7371 7274 2878 3d76 6172 6961 6e63  b.sqrt(x=varianc
-0000d9b0: 655f 6164 645f 6570 7369 6c6f 6e29 0a0a  e_add_epsilon)..
-0000d9c0: 2020 2020 2020 2020 6e61 6d65 203d 206e          name = n
-0000d9d0: 6f64 652e 6e61 6d65 2069 6620 7765 6967  ode.name if weig
-0000d9e0: 6874 2069 7320 4e6f 6e65 2061 6e64 2062  ht is None and b
-0000d9f0: 6961 7320 6973 204e 6f6e 6520 656c 7365  ias is None else
-0000da00: 206e 6f64 652e 6e61 6d65 202b 2022 5f64   node.name + "_d
-0000da10: 6976 220a 2020 2020 2020 2020 7820 3d20  iv".        x = 
-0000da20: 6d62 2e72 6561 6c5f 6469 7628 783d 6e75  mb.real_div(x=nu
-0000da30: 6d2c 2079 3d73 7172 742c 206e 616d 653d  m, y=sqrt, name=
-0000da40: 6e61 6d65 290a 0a20 2020 2020 2020 2069  name)..        i
-0000da50: 6620 7765 6967 6874 2069 7320 6e6f 7420  f weight is not 
-0000da60: 4e6f 6e65 3a0a 2020 2020 2020 2020 2020  None:.          
-0000da70: 2020 7765 6967 6874 5f72 6573 6861 7065    weight_reshape
-0000da80: 203d 206d 622e 7265 7368 6170 6528 783d   = mb.reshape(x=
-0000da90: 7765 6967 6874 2c20 7368 6170 653d 7368  weight, shape=sh
-0000daa0: 6170 6529 0a20 2020 2020 2020 2020 2020  ape).           
-0000dab0: 206e 616d 6520 3d20 6e6f 6465 2e6e 616d   name = node.nam
-0000dac0: 6520 6966 2062 6961 7320 6973 204e 6f6e  e if bias is Non
-0000dad0: 6520 656c 7365 206e 6f64 652e 6e61 6d65  e else node.name
-0000dae0: 202b 2022 5f6d 756c 220a 2020 2020 2020   + "_mul".      
-0000daf0: 2020 2020 2020 7820 3d20 6d62 2e6d 756c        x = mb.mul
-0000db00: 2878 3d78 2c20 793d 7765 6967 6874 5f72  (x=x, y=weight_r
-0000db10: 6573 6861 7065 2c20 6e61 6d65 3d6e 616d  eshape, name=nam
-0000db20: 6529 0a0a 2020 2020 2020 2020 6966 2062  e)..        if b
-0000db30: 6961 7320 6973 206e 6f74 204e 6f6e 653a  ias is not None:
-0000db40: 0a20 2020 2020 2020 2020 2020 2062 6961  .            bia
-0000db50: 735f 7265 7368 6170 6520 3d20 6d62 2e72  s_reshape = mb.r
-0000db60: 6573 6861 7065 2878 3d62 6961 732c 2073  eshape(x=bias, s
-0000db70: 6861 7065 3d73 6861 7065 290a 2020 2020  hape=shape).    
-0000db80: 2020 2020 2020 2020 7820 3d20 6d62 2e61          x = mb.a
-0000db90: 6464 2878 3d78 2c20 793d 6269 6173 5f72  dd(x=x, y=bias_r
-0000dba0: 6573 6861 7065 2c20 6e61 6d65 3d6e 6f64  eshape, name=nod
-0000dbb0: 652e 6e61 6d65 290a 0a20 2020 2020 2020  e.name)..       
-0000dbc0: 2063 6f6e 7465 7874 2e61 6464 2878 290a   context.add(x).
-0000dbd0: 0a20 2020 2064 6566 205f 6164 645f 6261  .    def _add_ba
-0000dbe0: 7463 685f 6e6f 726d 5f31 6428 293a 0a20  tch_norm_1d():. 
-0000dbf0: 2020 2020 2020 2023 2066 6972 7374 2065         # first e
-0000dc00: 7870 616e 6420 7468 6520 3364 2074 656e  xpand the 3d ten
-0000dc10: 736f 7220 746f 2034 642c 2061 6e64 2063  sor to 4d, and c
-0000dc20: 616c 6c20 7468 6520 7374 616e 6461 7264  all the standard
-0000dc30: 206d 622e 6261 7463 685f 6e6f 726d 0a20   mb.batch_norm. 
-0000dc40: 2020 2020 2020 2078 203d 206d 622e 6578         x = mb.ex
-0000dc50: 7061 6e64 5f64 696d 7328 783d 5f69 6e70  pand_dims(x=_inp
-0000dc60: 7574 2c20 6178 6573 3d5b 2d31 5d2c 206e  ut, axes=[-1], n
-0000dc70: 616d 653d 6e6f 6465 2e6e 616d 6520 2b20  ame=node.name + 
-0000dc80: 225f 7261 6e6b 325f 6578 7061 6e73 696f  "_rank2_expansio
-0000dc90: 6e22 290a 2020 2020 2020 2020 626e 203d  n").        bn =
-0000dca0: 206d 622e 6261 7463 685f 6e6f 726d 280a   mb.batch_norm(.
-0000dcb0: 2020 2020 2020 2020 2020 2020 783d 782c              x=x,
-0000dcc0: 0a20 2020 2020 2020 2020 2020 206d 6561  .            mea
-0000dcd0: 6e3d 7275 6e6e 696e 675f 6d65 616e 2c0a  n=running_mean,.
-0000dce0: 2020 2020 2020 2020 2020 2020 7661 7269              vari
-0000dcf0: 616e 6365 3d72 756e 6e69 6e67 5f76 6172  ance=running_var
-0000dd00: 2c0a 2020 2020 2020 2020 2020 2020 6761  ,.            ga
-0000dd10: 6d6d 613d 7765 6967 6874 2c0a 2020 2020  mma=weight,.    
-0000dd20: 2020 2020 2020 2020 6265 7461 3d62 6961          beta=bia
-0000dd30: 732c 0a20 2020 2020 2020 2020 2020 2065  s,.            e
-0000dd40: 7073 696c 6f6e 3d65 7073 2c0a 2020 2020  psilon=eps,.    
-0000dd50: 2020 2020 2020 2020 6e61 6d65 3d6e 6f64          name=nod
-0000dd60: 652e 6e61 6d65 202b 2022 5f62 6174 6368  e.name + "_batch
-0000dd70: 5f6e 6f72 6d5f 3164 222c 0a20 2020 2020  _norm_1d",.     
-0000dd80: 2020 2029 0a20 2020 2020 2020 2062 6e20     ).        bn 
-0000dd90: 3d20 6d62 2e73 7175 6565 7a65 2878 3d62  = mb.squeeze(x=b
-0000dda0: 6e2c 206e 616d 653d 6e6f 6465 2e6e 616d  n, name=node.nam
-0000ddb0: 652c 2061 7865 733d 5b2d 315d 290a 2020  e, axes=[-1]).  
-0000ddc0: 2020 2020 2020 636f 6e74 6578 742e 6164        context.ad
-0000ddd0: 6428 626e 290a 0a20 2020 2064 6566 205f  d(bn)..    def _
-0000dde0: 6164 645f 6261 7463 685f 6e6f 726d 2829  add_batch_norm()
-0000ddf0: 3a0a 2020 2020 2020 2020 626e 203d 206d  :.        bn = m
-0000de00: 622e 6261 7463 685f 6e6f 726d 280a 2020  b.batch_norm(.  
-0000de10: 2020 2020 2020 2020 2020 783d 5f69 6e70            x=_inp
-0000de20: 7574 2c0a 2020 2020 2020 2020 2020 2020  ut,.            
-0000de30: 6d65 616e 3d72 756e 6e69 6e67 5f6d 6561  mean=running_mea
-0000de40: 6e2c 0a20 2020 2020 2020 2020 2020 2076  n,.            v
-0000de50: 6172 6961 6e63 653d 7275 6e6e 696e 675f  ariance=running_
-0000de60: 7661 722c 0a20 2020 2020 2020 2020 2020  var,.           
-0000de70: 2067 616d 6d61 3d77 6569 6768 742c 0a20   gamma=weight,. 
-0000de80: 2020 2020 2020 2020 2020 2062 6574 613d             beta=
-0000de90: 6269 6173 2c0a 2020 2020 2020 2020 2020  bias,.          
-0000dea0: 2020 6570 7369 6c6f 6e3d 6570 732c 0a20    epsilon=eps,. 
-0000deb0: 2020 2020 2020 2020 2020 206e 616d 653d             name=
-0000dec0: 6e6f 6465 2e6e 616d 652c 0a20 2020 2020  node.name,.     
-0000ded0: 2020 2029 0a20 2020 2020 2020 2063 6f6e     ).        con
-0000dee0: 7465 7874 2e61 6464 2862 6e29 0a0a 2020  text.add(bn)..  
-0000def0: 2020 6973 5f62 6174 6368 5f6e 6f72 6d5f    is_batch_norm_
-0000df00: 3164 5f72 616e 6b5f 3220 3d20 696e 7075  1d_rank_2 = inpu
-0000df10: 745f 7261 6e6b 203d 3d20 320a 0a20 2020  t_rank == 2..   
-0000df20: 2069 6620 7472 6169 6e69 6e67 206f 7220   if training or 
-0000df30: 7275 6e6e 696e 675f 6d65 616e 2e76 616c  running_mean.val
-0000df40: 2069 7320 4e6f 6e65 206f 7220 7275 6e6e   is None or runn
-0000df50: 696e 675f 7661 722e 7661 6c20 6973 204e  ing_var.val is N
-0000df60: 6f6e 6520 6f72 2077 6569 6768 7420 6973  one or weight is
-0000df70: 204e 6f6e 6520 6f72 2062 6961 7320 6973   None or bias is
-0000df80: 204e 6f6e 653a 0a20 2020 2020 2020 205f   None:.        _
-0000df90: 6164 645f 6261 7463 685f 6e6f 726d 5f64  add_batch_norm_d
-0000dfa0: 796e 616d 6963 2829 0a20 2020 2065 6c69  ynamic().    eli
-0000dfb0: 6620 6973 5f62 6174 6368 5f6e 6f72 6d5f  f is_batch_norm_
-0000dfc0: 3164 5f72 616e 6b5f 323a 0a20 2020 2020  1d_rank_2:.     
-0000dfd0: 2020 205f 6164 645f 6261 7463 685f 6e6f     _add_batch_no
-0000dfe0: 726d 5f31 6428 290a 2020 2020 656c 7365  rm_1d().    else
-0000dff0: 3a0a 2020 2020 2020 2020 5f61 6464 5f62  :.        _add_b
-0000e000: 6174 6368 5f6e 6f72 6d28 290a 0a0a 4072  atch_norm()...@r
-0000e010: 6567 6973 7465 725f 746f 7263 685f 6f70  egister_torch_op
-0000e020: 0a64 6566 2069 6e73 7461 6e63 655f 6e6f  .def instance_no
-0000e030: 726d 2863 6f6e 7465 7874 2c20 6e6f 6465  rm(context, node
-0000e040: 293a 0a20 2020 2069 6e70 7574 7320 3d20  ):.    inputs = 
-0000e050: 5f67 6574 5f69 6e70 7574 7328 636f 6e74  _get_inputs(cont
-0000e060: 6578 742c 206e 6f64 652c 2065 7870 6563  ext, node, expec
-0000e070: 7465 643d 3929 0a20 2020 2078 203d 2069  ted=9).    x = i
-0000e080: 6e70 7574 735b 305d 0a20 2020 2077 6569  nputs[0].    wei
-0000e090: 6768 7420 3d20 696e 7075 7473 5b31 5d0a  ght = inputs[1].
-0000e0a0: 2020 2020 6269 6173 203d 2069 6e70 7574      bias = input
-0000e0b0: 735b 325d 0a20 2020 2065 7073 203d 2069  s[2].    eps = i
-0000e0c0: 6e70 7574 735b 375d 0a20 2020 2078 203d  nputs[7].    x =
-0000e0d0: 206d 622e 696e 7374 616e 6365 5f6e 6f72   mb.instance_nor
-0000e0e0: 6d28 0a20 2020 2020 2020 2078 3d78 2c0a  m(.        x=x,.
-0000e0f0: 2020 2020 2020 2020 6761 6d6d 613d 7765          gamma=we
-0000e100: 6967 6874 2c0a 2020 2020 2020 2020 6265  ight,.        be
-0000e110: 7461 3d62 6961 732c 0a20 2020 2020 2020  ta=bias,.       
-0000e120: 2065 7073 696c 6f6e 3d65 7073 2c0a 2020   epsilon=eps,.  
-0000e130: 2020 2020 2020 6e61 6d65 3d6e 6f64 652e        name=node.
-0000e140: 6e61 6d65 2c0a 2020 2020 290a 2020 2020  name,.    ).    
-0000e150: 636f 6e74 6578 742e 6164 6428 7829 0a0a  context.add(x)..
-0000e160: 0a40 7265 6769 7374 6572 5f74 6f72 6368  .@register_torch
-0000e170: 5f6f 700a 6465 6620 6772 6f75 705f 6e6f  _op.def group_no
-0000e180: 726d 2863 6f6e 7465 7874 2c20 6e6f 6465  rm(context, node
-0000e190: 293a 0a20 2020 2069 6e70 7574 7320 3d20  ):.    inputs = 
-0000e1a0: 5f67 6574 5f69 6e70 7574 7328 636f 6e74  _get_inputs(cont
-0000e1b0: 6578 742c 206e 6f64 652c 2065 7870 6563  ext, node, expec
-0000e1c0: 7465 643d 3629 0a20 2020 2078 203d 2069  ted=6).    x = i
-0000e1d0: 6e70 7574 735b 305d 0a20 2020 206e 756d  nputs[0].    num
-0000e1e0: 5f67 726f 7570 7320 3d20 696e 7075 7473  _groups = inputs
-0000e1f0: 5b31 5d2e 7661 6c0a 2020 2020 7765 6967  [1].val.    weig
-0000e200: 6874 203d 2069 6e70 7574 735b 325d 0a20  ht = inputs[2]. 
-0000e210: 2020 2062 6961 7320 3d20 696e 7075 7473     bias = inputs
-0000e220: 5b33 5d0a 2020 2020 6570 7320 3d20 696e  [3].    eps = in
-0000e230: 7075 7473 5b34 5d0a 2020 2020 6e2c 6320  puts[4].    n,c 
-0000e240: 3d20 782e 7368 6170 655b 305d 2c78 2e73  = x.shape[0],x.s
-0000e250: 6861 7065 5b31 5d20 2320 6174 206d 696e  hape[1] # at min
-0000e260: 696d 756d 2028 4e2c 2043 2920 7265 7175  imum (N, C) requ
-0000e270: 6972 6564 0a20 2020 2069 6e70 7574 5f73  ired.    input_s
-0000e280: 6861 7065 203d 205b 2a78 2e73 6861 7065  hape = [*x.shape
-0000e290: 5d20 2320 6e2c 2063 2c20 2a0a 2020 2020  ] # n, c, *.    
-0000e2a0: 6e75 6d5f 6772 6f75 7073 203d 2062 7569  num_groups = bui
-0000e2b0: 6c74 696e 732e 6d69 6e28 6e75 6d5f 6772  ltins.min(num_gr
-0000e2c0: 6f75 7073 2c63 290a 2020 2020 6e65 775f  oups,c).    new_
-0000e2d0: 7368 6170 6520 3d20 5b6e 2c20 6e75 6d5f  shape = [n, num_
-0000e2e0: 6772 6f75 7073 2c20 632f 2f6e 756d 5f67  groups, c//num_g
-0000e2f0: 726f 7570 735d 0a20 2020 206e 6577 5f73  roups].    new_s
-0000e300: 6861 7065 202b 3d20 5b2a 782e 7368 6170  hape += [*x.shap
-0000e310: 655b 323a 5d5d 2023 2061 6464 7320 7265  e[2:]] # adds re
-0000e320: 6d61 696e 696e 6720 6469 6d73 0a20 2020  maining dims.   
-0000e330: 206e 756d 5f65 7874 7261 5f61 7865 7320   num_extra_axes 
-0000e340: 3d20 6c65 6e28 782e 7368 6170 655b 323a  = len(x.shape[2:
-0000e350: 5d29 0a20 2020 2061 7865 735f 203d 205b  ]).    axes_ = [
-0000e360: 696e 7428 6929 2066 6f72 2069 2069 6e20  int(i) for i in 
-0000e370: 7261 6e67 6528 322c 2032 202b 206e 756d  range(2, 2 + num
-0000e380: 5f65 7874 7261 5f61 7865 7320 2b20 3129  _extra_axes + 1)
-0000e390: 5d0a 2020 2020 7765 6967 6874 5f73 6861  ].    weight_sha
-0000e3a0: 7065 2c20 6269 6173 5f73 6861 7065 203d  pe, bias_shape =
-0000e3b0: 205b 312c 635d 2c20 5b31 2c63 5d0a 2020   [1,c], [1,c].  
-0000e3c0: 2020 7765 6967 6874 5f73 6861 7065 202b    weight_shape +
-0000e3d0: 3d20 5b31 2066 6f72 205f 2069 6e20 7261  = [1 for _ in ra
-0000e3e0: 6e67 6528 6e75 6d5f 6578 7472 615f 6178  nge(num_extra_ax
-0000e3f0: 6573 295d 0a20 2020 2062 6961 735f 7368  es)].    bias_sh
-0000e400: 6170 6520 2b3d 205b 3120 666f 7220 5f20  ape += [1 for _ 
-0000e410: 696e 2072 616e 6765 286e 756d 5f65 7874  in range(num_ext
-0000e420: 7261 5f61 7865 7329 5d0a 0a20 2020 2078  ra_axes)]..    x
-0000e430: 203d 206d 622e 7265 7368 6170 6528 783d   = mb.reshape(x=
-0000e440: 782c 2073 6861 7065 3d6e 6577 5f73 6861  x, shape=new_sha
-0000e450: 7065 290a 2020 2020 6d65 616e 203d 206d  pe).    mean = m
-0000e460: 622e 7265 6475 6365 5f6d 6561 6e28 783d  b.reduce_mean(x=
-0000e470: 782c 2061 7865 733d 6178 6573 5f2c 206b  x, axes=axes_, k
-0000e480: 6565 705f 6469 6d73 3d54 7275 6529 0a20  eep_dims=True). 
-0000e490: 2020 2076 6172 203d 205f 7374 6428 782c     var = _std(x,
-0000e4a0: 6178 6573 5f2c 5472 7565 2c46 616c 7365  axes_,True,False
-0000e4b0: 2c65 7073 2e76 616c 290a 2020 2020 7820  ,eps.val).    x 
-0000e4c0: 3d20 6d62 2e73 7562 2878 3d78 2c79 3d6d  = mb.sub(x=x,y=m
-0000e4d0: 6561 6e29 0a20 2020 2078 203d 206d 622e  ean).    x = mb.
-0000e4e0: 7265 616c 5f64 6976 2878 3d78 2c79 3d76  real_div(x=x,y=v
-0000e4f0: 6172 290a 2020 2020 7820 3d20 6d62 2e72  ar).    x = mb.r
-0000e500: 6573 6861 7065 2878 3d78 2c20 7368 6170  eshape(x=x, shap
-0000e510: 653d 696e 7075 745f 7368 6170 6529 0a20  e=input_shape). 
-0000e520: 2020 2069 6620 7765 6967 6874 2069 7320     if weight is 
-0000e530: 6e6f 7420 4e6f 6e65 3a0a 2020 2020 2020  not None:.      
-0000e540: 2020 7765 6967 6874 203d 206d 622e 7265    weight = mb.re
-0000e550: 7368 6170 6528 783d 7765 6967 6874 2c20  shape(x=weight, 
-0000e560: 7368 6170 653d 7765 6967 6874 5f73 6861  shape=weight_sha
-0000e570: 7065 290a 2020 2020 2020 2020 7820 3d20  pe).        x = 
-0000e580: 6d62 2e6d 756c 2878 3d78 2c79 3d77 6569  mb.mul(x=x,y=wei
-0000e590: 6768 7429 0a20 2020 2069 6620 6269 6173  ght).    if bias
-0000e5a0: 2069 7320 6e6f 7420 4e6f 6e65 3a0a 2020   is not None:.  
-0000e5b0: 2020 2020 2020 6269 6173 203d 206d 622e        bias = mb.
-0000e5c0: 7265 7368 6170 6528 783d 6269 6173 2c20  reshape(x=bias, 
-0000e5d0: 7368 6170 653d 6269 6173 5f73 6861 7065  shape=bias_shape
-0000e5e0: 290a 2020 2020 2020 2020 7820 3d20 6d62  ).        x = mb
-0000e5f0: 2e61 6464 2878 3d78 2c79 3d62 6961 7329  .add(x=x,y=bias)
-0000e600: 0a20 2020 2063 6f6e 7465 7874 2e61 6464  .    context.add
-0000e610: 2878 2c6e 6f64 652e 6e61 6d65 290a 0a0a  (x,node.name)...
-0000e620: 4072 6567 6973 7465 725f 746f 7263 685f  @register_torch_
-0000e630: 6f70 0a64 6566 2065 6d62 6564 6469 6e67  op.def embedding
-0000e640: 2863 6f6e 7465 7874 2c20 6e6f 6465 293a  (context, node):
-0000e650: 0a20 2020 2069 6e70 7574 7320 3d20 5f67  .    inputs = _g
-0000e660: 6574 5f69 6e70 7574 7328 636f 6e74 6578  et_inputs(contex
-0000e670: 742c 206e 6f64 6529 0a20 2020 205f 696e  t, node).    _in
-0000e680: 7075 7420 3d20 696e 7075 7473 5b30 5d0a  put = inputs[0].
-0000e690: 2020 2020 696e 6469 6365 7320 3d20 696e      indices = in
-0000e6a0: 7075 7473 5b31 5d0a 0a20 2020 2070 6164  puts[1]..    pad
-0000e6b0: 6469 6e67 5f69 6478 203d 202d 310a 2020  ding_idx = -1.  
-0000e6c0: 2020 7363 616c 655f 6772 6164 5f62 795f    scale_grad_by_
-0000e6d0: 6672 6571 203d 2046 616c 7365 0a20 2020  freq = False.   
-0000e6e0: 2073 7061 7273 6520 3d20 4661 6c73 650a   sparse = False.
-0000e6f0: 2020 2020 6966 206c 656e 2869 6e70 7574      if len(input
-0000e700: 7329 203e 3d20 333a 0a20 2020 2020 2020  s) >= 3:.       
-0000e710: 2070 6164 6469 6e67 5f69 6478 203d 2069   padding_idx = i
-0000e720: 6e70 7574 735b 325d 2e76 616c 0a20 2020  nputs[2].val.   
-0000e730: 2069 6620 6c65 6e28 696e 7075 7473 2920   if len(inputs) 
-0000e740: 3e3d 2034 3a0a 2020 2020 2020 2020 7363  >= 4:.        sc
-0000e750: 616c 655f 6772 6164 5f62 795f 6672 6571  ale_grad_by_freq
-0000e760: 203d 2069 6e70 7574 735b 335d 2e76 616c   = inputs[3].val
-0000e770: 0a20 2020 2069 6620 6c65 6e28 696e 7075  .    if len(inpu
-0000e780: 7473 2920 3e3d 2035 3a0a 2020 2020 2020  ts) >= 5:.      
-0000e790: 2020 7370 6172 7365 203d 2069 6e70 7574    sparse = input
-0000e7a0: 735b 345d 2e76 616c 0a0a 2020 2020 6966  s[4].val..    if
-0000e7b0: 2070 6164 6469 6e67 5f69 6478 2021 3d20   padding_idx != 
-0000e7c0: 2d31 206f 7220 7363 616c 655f 6772 6164  -1 or scale_grad
-0000e7d0: 5f62 795f 6672 6571 206f 7220 7370 6172  _by_freq or spar
-0000e7e0: 7365 3a0a 2020 2020 2020 2020 6c6f 6767  se:.        logg
-0000e7f0: 6572 2e77 6172 6e69 6e67 280a 2020 2020  er.warning(.    
-0000e800: 2020 2020 2020 2020 2243 6f72 6520 4d4c          "Core ML
-0000e810: 2065 6d62 6564 6469 6e67 2028 6761 7468   embedding (gath
-0000e820: 6572 2920 6c61 7965 7220 646f 6573 206e  er) layer does n
-0000e830: 6f74 2073 7570 706f 7274 2061 6e79 2022  ot support any "
-0000e840: 0a20 2020 2020 2020 2020 2020 2022 696e  .            "in
-0000e850: 7075 7473 2062 6573 6964 6573 2074 6865  puts besides the
-0000e860: 2077 6569 6768 7473 2061 6e64 2069 6e64   weights and ind
-0000e870: 6963 6573 2e20 5468 6f73 6520 6769 7665  ices. Those give
-0000e880: 6e20 220a 2020 2020 2020 2020 2020 2020  n ".            
-0000e890: 2277 696c 6c20 6265 2069 676e 6f72 6564  "will be ignored
-0000e8a0: 2e22 0a20 2020 2020 2020 2029 0a0a 2020  .".        )..  
-0000e8b0: 2020 696e 6469 6365 7320 3d20 6d62 2e63    indices = mb.c
-0000e8c0: 6173 7428 783d 696e 6469 6365 732c 2064  ast(x=indices, d
-0000e8d0: 7479 7065 3d22 696e 7433 3222 290a 0a20  type="int32").. 
-0000e8e0: 2020 2023 2020 4368 616e 6769 6e67 2074     #  Changing t
-0000e8f0: 6865 2061 7869 7320 6672 6f6d 2030 2069  he axis from 0 i
-0000e900: 7320 6e6f 7420 616e 206f 7074 696f 6e20  s not an option 
-0000e910: 696e 2074 6f72 6368 2c20 736f 2077 6520  in torch, so we 
-0000e920: 646f 6e27 7420 6578 706f 7365 2069 740a  don't expose it.
-0000e930: 2020 2020 6761 7468 6572 203d 206d 622e      gather = mb.
-0000e940: 6761 7468 6572 2878 3d5f 696e 7075 742c  gather(x=_input,
-0000e950: 2069 6e64 6963 6573 3d69 6e64 6963 6573   indices=indices
-0000e960: 2c20 6e61 6d65 3d6e 6f64 652e 6e61 6d65  , name=node.name
-0000e970: 290a 2020 2020 636f 6e74 6578 742e 6164  ).    context.ad
-0000e980: 6428 6761 7468 6572 290a 0a0a 4072 6567  d(gather)...@reg
-0000e990: 6973 7465 725f 746f 7263 685f 6f70 0a64  ister_torch_op.d
-0000e9a0: 6566 2068 6172 6474 616e 6828 636f 6e74  ef hardtanh(cont
-0000e9b0: 6578 742c 206e 6f64 6529 3a0a 2020 2020  ext, node):.    
-0000e9c0: 696e 7075 7473 203d 205f 6765 745f 696e  inputs = _get_in
-0000e9d0: 7075 7473 2863 6f6e 7465 7874 2c20 6e6f  puts(context, no
-0000e9e0: 6465 2c20 6578 7065 6374 6564 3d33 290a  de, expected=3).
-0000e9f0: 2020 2020 5f69 6e70 7574 203d 2069 6e70      _input = inp
-0000ea00: 7574 735b 305d 0a20 2020 206d 696e 5f76  uts[0].    min_v
-0000ea10: 616c 203d 2069 6e70 7574 735b 315d 2e76  al = inputs[1].v
-0000ea20: 616c 0a20 2020 206d 6178 5f76 616c 203d  al.    max_val =
-0000ea30: 2069 6e70 7574 735b 325d 2e76 616c 0a0a   inputs[2].val..
-0000ea40: 2020 2020 7265 7320 3d20 6d62 2e63 6c69      res = mb.cli
-0000ea50: 7028 783d 5f69 6e70 7574 2c20 616c 7068  p(x=_input, alph
-0000ea60: 613d 6d69 6e5f 7661 6c2c 2062 6574 613d  a=min_val, beta=
-0000ea70: 6d61 785f 7661 6c2c 206e 616d 653d 6e6f  max_val, name=no
-0000ea80: 6465 2e6e 616d 6529 0a20 2020 2063 6f6e  de.name).    con
-0000ea90: 7465 7874 2e61 6464 2872 6573 290a 0a0a  text.add(res)...
-0000eaa0: 4072 6567 6973 7465 725f 746f 7263 685f  @register_torch_
-0000eab0: 6f70 2874 6f72 6368 5f61 6c69 6173 3d5b  op(torch_alias=[
-0000eac0: 2763 6f6e 6361 7427 5d29 0a64 6566 2063  'concat']).def c
-0000ead0: 6174 2863 6f6e 7465 7874 2c20 6e6f 6465  at(context, node
-0000eae0: 293a 0a20 2020 2069 6e70 7574 7320 3d20  ):.    inputs = 
-0000eaf0: 5f67 6574 5f69 6e70 7574 7328 636f 6e74  _get_inputs(cont
-0000eb00: 6578 742c 206e 6f64 6529 0a20 2020 2061  ext, node).    a
-0000eb10: 7869 7320 3d20 3020 6966 206c 656e 2869  xis = 0 if len(i
-0000eb20: 6e70 7574 7329 203d 3d20 3120 656c 7365  nputs) == 1 else
-0000eb30: 2069 6e70 7574 735b 315d 0a20 2020 2063   inputs[1].    c
-0000eb40: 6f6e 6361 7420 3d20 6d62 2e63 6f6e 6361  oncat = mb.conca
-0000eb50: 7428 0a20 2020 2020 2020 2076 616c 7565  t(.        value
-0000eb60: 733d 7072 6f6d 6f74 655f 696e 7075 745f  s=promote_input_
-0000eb70: 6474 7970 6573 2869 6e70 7574 735b 305d  dtypes(inputs[0]
-0000eb80: 292c 2061 7869 733d 6178 6973 2c20 6e61  ), axis=axis, na
-0000eb90: 6d65 3d6e 6f64 652e 6e61 6d65 0a20 2020  me=node.name.   
-0000eba0: 2029 0a20 2020 2063 6f6e 7465 7874 2e61   ).    context.a
-0000ebb0: 6464 2863 6f6e 6361 7429 0a0a 0a40 7265  dd(concat)...@re
-0000ebc0: 6769 7374 6572 5f74 6f72 6368 5f6f 700a  gister_torch_op.
-0000ebd0: 6465 6620 7374 6163 6b28 636f 6e74 6578  def stack(contex
-0000ebe0: 742c 206e 6f64 6529 3a0a 2020 2020 696e  t, node):.    in
-0000ebf0: 7075 7473 203d 205f 6765 745f 696e 7075  puts = _get_inpu
-0000ec00: 7473 2863 6f6e 7465 7874 2c20 6e6f 6465  ts(context, node
-0000ec10: 290a 0a20 2020 2076 616c 7565 7320 3d20  )..    values = 
-0000ec20: 696e 7075 7473 5b30 5d0a 0a20 2020 2069  inputs[0]..    i
-0000ec30: 6620 6c65 6e28 696e 7075 7473 2920 3c20  f len(inputs) < 
-0000ec40: 323a 0a20 2020 2020 2020 2061 7869 7320  2:.        axis 
-0000ec50: 3d20 300a 2020 2020 656c 7365 3a0a 2020  = 0.    else:.  
-0000ec60: 2020 2020 2020 6178 6973 203d 2069 6e70        axis = inp
-0000ec70: 7574 735b 315d 0a0a 2020 2020 6966 206c  uts[1]..    if l
-0000ec80: 656e 2876 616c 7565 7329 203d 3d20 313a  en(values) == 1:
-0000ec90: 0a20 2020 2020 2020 2072 6573 203d 206d  .        res = m
-0000eca0: 622e 6578 7061 6e64 5f64 696d 7328 783d  b.expand_dims(x=
-0000ecb0: 7661 6c75 6573 5b30 5d2c 2061 7865 733d  values[0], axes=
-0000ecc0: 5b61 7869 732e 7661 6c5d 2c20 6e61 6d65  [axis.val], name
-0000ecd0: 3d6e 6f64 652e 6e61 6d65 290a 2020 2020  =node.name).    
-0000ece0: 656c 7365 3a0a 2020 2020 2020 2020 7265  else:.        re
-0000ecf0: 7320 3d20 6d62 2e73 7461 636b 2876 616c  s = mb.stack(val
-0000ed00: 7565 733d 7661 6c75 6573 2c20 6178 6973  ues=values, axis
-0000ed10: 3d61 7869 732c 206e 616d 653d 6e6f 6465  =axis, name=node
-0000ed20: 2e6e 616d 6529 0a20 2020 2063 6f6e 7465  .name).    conte
-0000ed30: 7874 2e61 6464 2872 6573 290a 0a0a 4072  xt.add(res)...@r
-0000ed40: 6567 6973 7465 725f 746f 7263 685f 6f70  egister_torch_op
-0000ed50: 0a64 6566 2069 7465 6d28 636f 6e74 6578  .def item(contex
-0000ed60: 742c 206e 6f64 6529 3a0a 2020 2020 696e  t, node):.    in
-0000ed70: 7075 7473 203d 205f 6765 745f 696e 7075  puts = _get_inpu
-0000ed80: 7473 2863 6f6e 7465 7874 2c20 6e6f 6465  ts(context, node
-0000ed90: 2c20 6578 7065 6374 6564 3d31 290a 0a20  , expected=1).. 
-0000eda0: 2020 2069 6620 696e 7075 7473 5b30 5d2e     if inputs[0].
-0000edb0: 7368 6170 6520 3d3d 2028 293a 0a20 2020  shape == ():.   
-0000edc0: 2020 2020 2023 204d 494c 206f 7073 2074       # MIL ops t
-0000edd0: 6861 7420 7265 6475 6365 2061 6c72 6561  hat reduce alrea
-0000ede0: 6479 206f 7574 7075 7420 6120 7363 616c  dy output a scal
-0000edf0: 6172 2c20 736f 206e 6f20 6e65 6564 2074  ar, so no need t
-0000ee00: 6f20 646f 0a20 2020 2020 2020 2023 2061  o do.        # a
-0000ee10: 6e79 7468 696e 672e 0a20 2020 2020 2020  nything..       
-0000ee20: 2072 6573 203d 2069 6e70 7574 735b 305d   res = inputs[0]
-0000ee30: 0a20 2020 2065 6c69 6620 5f6e 702e 616c  .    elif _np.al
-0000ee40: 6c28 5b64 203d 3d20 3120 666f 7220 6420  l([d == 1 for d 
-0000ee50: 696e 2069 6e70 7574 735b 305d 2e73 6861  in inputs[0].sha
-0000ee60: 7065 5d29 3a0a 2020 2020 2020 2020 2320  pe]):.        # 
-0000ee70: 4974 656d 206f 6e6c 7920 6d61 6b65 7320  Item only makes 
-0000ee80: 7365 6e73 6520 7768 656e 2063 616c 6c65  sense when calle
-0000ee90: 6420 6f6e 2061 206c 656e 6774 6820 3120  d on a length 1 
-0000eea0: 7465 6e73 6f72 2e20 5765 2075 7365 0a20  tensor. We use. 
-0000eeb0: 2020 2020 2020 2023 2072 6564 7563 655f         # reduce_
-0000eec0: 6d61 7820 6173 2061 2077 6f72 6b61 726f  max as a workaro
-0000eed0: 756e 6420 666f 7220 6e6f 7420 6861 7669  und for not havi
-0000eee0: 6e67 2061 2077 6179 2074 6f20 6578 7472  ng a way to extr
-0000eef0: 6163 7420 6120 7363 616c 6172 0a20 2020  act a scalar.   
-0000ef00: 2020 2020 2023 2066 726f 6d20 6120 7379       # from a sy
-0000ef10: 6d62 6f6c 6963 2074 656e 736f 722e 0a20  mbolic tensor.. 
-0000ef20: 2020 2020 2020 2072 6573 203d 206d 622e         res = mb.
-0000ef30: 7265 6475 6365 5f6d 6178 2878 3d69 6e70  reduce_max(x=inp
-0000ef40: 7574 735b 305d 2c20 6e61 6d65 3d6e 6f64  uts[0], name=nod
-0000ef50: 652e 6e61 6d65 290a 2020 2020 656c 7365  e.name).    else
-0000ef60: 3a0a 2020 2020 2020 2020 7261 6973 6520  :.        raise 
-0000ef70: 5661 6c75 6545 7272 6f72 2822 6578 7065  ValueError("expe
-0000ef80: 6374 6564 2069 6e70 7574 2074 6f20 6265  cted input to be
-0000ef90: 2061 2073 6361 6c61 7220 6f72 2061 206c   a scalar or a l
-0000efa0: 656e 6774 6820 3120 7465 6e73 6f72 2229  ength 1 tensor")
-0000efb0: 0a20 2020 2063 6f6e 7465 7874 2e61 6464  .    context.add
-0000efc0: 2872 6573 2c20 6e6f 6465 2e6e 616d 6529  (res, node.name)
-0000efd0: 0a0a 0a64 6566 205f 6361 7374 2863 6f6e  ...def _cast(con
-0000efe0: 7465 7874 2c20 6e6f 6465 2c20 6474 7970  text, node, dtyp
-0000eff0: 652c 2064 7479 7065 5f6e 616d 6529 3a0a  e, dtype_name):.
-0000f000: 2020 2020 696e 7075 7473 203d 205f 6765      inputs = _ge
-0000f010: 745f 696e 7075 7473 2863 6f6e 7465 7874  t_inputs(context
-0000f020: 2c20 6e6f 6465 2c20 6578 7065 6374 6564  , node, expected
-0000f030: 3d31 290a 2020 2020 7820 3d20 696e 7075  =1).    x = inpu
-0000f040: 7473 5b30 5d0a 2020 2020 2320 496e 7075  ts[0].    # Inpu
-0000f050: 7420 6d75 7374 2065 6974 6865 7220 6265  t must either be
-0000f060: 2061 2073 6361 6c61 7220 6f72 2061 2028   a scalar or a (
-0000f070: 3120 7820 3120 7820 2e2e 2e20 7820 3129  1 x 1 x ... x 1)
-0000f080: 2074 656e 736f 720a 2020 2020 6966 206e   tensor.    if n
-0000f090: 6f74 2028 6c65 6e28 782e 7368 6170 6529  ot (len(x.shape)
-0000f0a0: 203d 3d20 3020 6f72 205f 6e70 2e61 6c6c   == 0 or _np.all
-0000f0b0: 285b 6420 3d3d 2031 2066 6f72 2064 2069  ([d == 1 for d i
-0000f0c0: 6e20 782e 7368 6170 655d 2929 3a0a 2020  n x.shape])):.  
-0000f0d0: 2020 2020 2020 7261 6973 6520 5661 6c75        raise Valu
-0000f0e0: 6545 7272 6f72 2822 696e 7075 7420 746f  eError("input to
-0000f0f0: 2063 6173 7420 6d75 7374 2062 6520 6569   cast must be ei
-0000f100: 7468 6572 2061 2073 6361 6c61 7220 6f72  ther a scalar or
-0000f110: 2061 206c 656e 6774 6820 3120 7465 6e73   a length 1 tens
-0000f120: 6f72 2229 0a0a 2020 2020 6966 2078 2e63  or")..    if x.c
-0000f130: 616e 5f62 655f 666f 6c64 6564 5f74 6f5f  an_be_folded_to_
-0000f140: 636f 6e73 7428 293a 0a20 2020 2020 2020  const():.       
-0000f150: 2023 2049 6620 7820 6973 2061 2063 6f6d   # If x is a com
-0000f160: 7069 6c65 2d74 696d 6520 636f 6e73 7461  pile-time consta
-0000f170: 6e74 2c20 6469 7265 6374 6c79 2063 6173  nt, directly cas
-0000f180: 7420 6974 2074 6f20 4064 7479 7065 2069  t it to @dtype i
-0000f190: 6620 6974 2773 0a20 2020 2020 2020 2023  f it's.        #
-0000f1a0: 206e 6f74 206f 6e65 2061 6c72 6561 6479   not one already
-0000f1b0: 2e0a 2020 2020 2020 2020 6966 206e 6f74  ..        if not
-0000f1c0: 2069 7369 6e73 7461 6e63 6528 782e 7661   isinstance(x.va
-0000f1d0: 6c2c 2064 7479 7065 293a 0a20 2020 2020  l, dtype):.     
-0000f1e0: 2020 2020 2020 2072 6573 203d 206d 622e         res = mb.
-0000f1f0: 636f 6e73 7428 7661 6c3d 6474 7970 6528  const(val=dtype(
-0000f200: 782e 7661 6c29 2c20 6e61 6d65 3d6e 6f64  x.val), name=nod
-0000f210: 652e 6e61 6d65 290a 2020 2020 2020 2020  e.name).        
-0000f220: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
-0000f230: 2020 7265 7320 3d20 780a 2020 2020 656c    res = x.    el
-0000f240: 6966 2078 2e73 6861 7065 203d 3d20 2831  if x.shape == (1
-0000f250: 2c29 3a0a 2020 2020 2020 2020 7820 3d20  ,):.        x = 
-0000f260: 6d62 2e73 7175 6565 7a65 2878 3d78 2c20  mb.squeeze(x=x, 
-0000f270: 6e61 6d65 3d6e 6f64 652e 6e61 6d65 202b  name=node.name +
-0000f280: 2022 5f69 7465 6d22 290a 2020 2020 2020   "_item").      
-0000f290: 2020 7265 7320 3d20 6d62 2e63 6173 7428    res = mb.cast(
-0000f2a0: 783d 782c 2064 7479 7065 3d64 7479 7065  x=x, dtype=dtype
-0000f2b0: 5f6e 616d 652c 206e 616d 653d 6e6f 6465  _name, name=node
-0000f2c0: 2e6e 616d 6529 0a20 2020 2065 6c73 653a  .name).    else:
-0000f2d0: 0a20 2020 2020 2020 2069 6620 6c65 6e28  .        if len(
-0000f2e0: 782e 7368 6170 6529 203e 2030 3a0a 2020  x.shape) > 0:.  
-0000f2f0: 2020 2020 2020 2020 2020 2320 544f 444f            # TODO
-0000f300: 3a20 5468 6572 6527 7320 6e6f 204d 494c  : There's no MIL
-0000f310: 206f 7020 746f 2065 7874 7261 6374 2061   op to extract a
-0000f320: 2076 616c 7565 2066 726f 6d20 6120 7379   value from a sy
-0000f330: 6d62 6f6c 6963 2074 656e 736f 722c 0a20  mbolic tensor,. 
-0000f340: 2020 2020 2020 2020 2020 2023 2073 6f20             # so 
-0000f350: 6173 2061 2077 6f72 6b61 726f 756e 6420  as a workaround 
-0000f360: 7765 2075 7365 2072 6564 7563 655f 6d61  we use reduce_ma
-0000f370: 7820 746f 2063 6f6e 7665 7274 2069 7420  x to convert it 
-0000f380: 746f 2061 2073 6361 6c61 722e 0a20 2020  to a scalar..   
-0000f390: 2020 2020 2020 2020 2078 203d 206d 622e           x = mb.
-0000f3a0: 7265 6475 6365 5f6d 6178 2878 3d78 2c20  reduce_max(x=x, 
-0000f3b0: 6e61 6d65 3d6e 6f64 652e 6e61 6d65 202b  name=node.name +
-0000f3c0: 2022 5f69 7465 6d22 290a 2020 2020 2020   "_item").      
-0000f3d0: 2020 7265 7320 3d20 6d62 2e63 6173 7428    res = mb.cast(
-0000f3e0: 783d 782c 2064 7479 7065 3d64 7479 7065  x=x, dtype=dtype
-0000f3f0: 5f6e 616d 652c 206e 616d 653d 6e6f 6465  _name, name=node
-0000f400: 2e6e 616d 6529 0a20 2020 2063 6f6e 7465  .name).    conte
-0000f410: 7874 2e61 6464 2872 6573 2c20 6e6f 6465  xt.add(res, node
-0000f420: 2e6e 616d 6529 0a0a 0a40 7265 6769 7374  .name)...@regist
-0000f430: 6572 5f74 6f72 6368 5f6f 7028 746f 7263  er_torch_op(torc
-0000f440: 685f 616c 6961 733d 5b22 626f 6f6c 225d  h_alias=["bool"]
-0000f450: 290a 6465 6620 5f62 6f6f 6c28 636f 6e74  ).def _bool(cont
-0000f460: 6578 742c 206e 6f64 6529 3a0a 2020 2020  ext, node):.    
-0000f470: 5f63 6173 7428 636f 6e74 6578 742c 206e  _cast(context, n
-0000f480: 6f64 652c 2062 6f6f 6c2c 2022 626f 6f6c  ode, bool, "bool
-0000f490: 2229 0a0a 0a40 7265 6769 7374 6572 5f74  ")...@register_t
-0000f4a0: 6f72 6368 5f6f 7028 746f 7263 685f 616c  orch_op(torch_al
-0000f4b0: 6961 733d 5b22 696e 7422 5d29 0a64 6566  ias=["int"]).def
-0000f4c0: 205f 696e 7428 636f 6e74 6578 742c 206e   _int(context, n
-0000f4d0: 6f64 6529 3a0a 2020 2020 5f63 6173 7428  ode):.    _cast(
-0000f4e0: 636f 6e74 6578 742c 206e 6f64 652c 2069  context, node, i
-0000f4f0: 6e74 2c20 2269 6e74 3332 2229 0a0a 0a40  nt, "int32")...@
-0000f500: 7265 6769 7374 6572 5f74 6f72 6368 5f6f  register_torch_o
-0000f510: 700a 6465 6620 6c61 7965 725f 6e6f 726d  p.def layer_norm
-0000f520: 2863 6f6e 7465 7874 2c20 6e6f 6465 293a  (context, node):
-0000f530: 0a20 2020 2069 6e70 7574 7320 3d20 5f67  .    inputs = _g
-0000f540: 6574 5f69 6e70 7574 7328 636f 6e74 6578  et_inputs(contex
-0000f550: 742c 206e 6f64 652c 2065 7870 6563 7465  t, node, expecte
-0000f560: 643d 3629 0a20 2020 205f 696e 7075 7420  d=6).    _input 
-0000f570: 3d20 696e 7075 7473 5b30 5d0a 2020 2020  = inputs[0].    
-0000f580: 6e6f 726d 616c 697a 6564 5f73 6861 7065  normalized_shape
-0000f590: 203d 2069 6e70 7574 735b 315d 0a20 2020   = inputs[1].   
-0000f5a0: 2077 6569 6768 7420 3d20 696e 7075 7473   weight = inputs
-0000f5b0: 5b32 5d0a 2020 2020 6269 6173 203d 2069  [2].    bias = i
-0000f5c0: 6e70 7574 735b 335d 0a20 2020 2065 7073  nputs[3].    eps
-0000f5d0: 203d 2069 6e70 7574 735b 345d 0a20 2020   = inputs[4].   
-0000f5e0: 2023 2063 7564 6e6e 5f65 6e61 626c 6520   # cudnn_enable 
-0000f5f0: 3d20 696e 7075 7473 5b35 5d20 756e 7573  = inputs[5] unus
-0000f600: 6564 0a0a 2020 2020 6c61 7965 725f 6e6f  ed..    layer_no
-0000f610: 726d 203d 206d 622e 6c61 7965 725f 6e6f  rm = mb.layer_no
-0000f620: 726d 280a 2020 2020 2020 2020 783d 5f69  rm(.        x=_i
-0000f630: 6e70 7574 2c0a 2020 2020 2020 2020 6178  nput,.        ax
-0000f640: 6573 3d6c 6973 7428 7261 6e67 6528 2d6c  es=list(range(-l
-0000f650: 656e 286e 6f72 6d61 6c69 7a65 645f 7368  en(normalized_sh
-0000f660: 6170 652e 7661 6c29 2c20 3029 292c 0a20  ape.val), 0)),. 
-0000f670: 2020 2020 2020 2067 616d 6d61 3d77 6569         gamma=wei
-0000f680: 6768 742c 0a20 2020 2020 2020 2062 6574  ght,.        bet
-0000f690: 613d 6269 6173 2c0a 2020 2020 2020 2020  a=bias,.        
-0000f6a0: 6570 7369 6c6f 6e3d 6570 732c 0a20 2020  epsilon=eps,.   
-0000f6b0: 2020 2020 206e 616d 653d 6e6f 6465 2e6e       name=node.n
-0000f6c0: 616d 652c 0a20 2020 2029 0a20 2020 2063  ame,.    ).    c
-0000f6d0: 6f6e 7465 7874 2e61 6464 286c 6179 6572  ontext.add(layer
-0000f6e0: 5f6e 6f72 6d29 0a0a 0a40 7265 6769 7374  _norm)...@regist
-0000f6f0: 6572 5f74 6f72 6368 5f6f 700a 6465 6620  er_torch_op.def 
-0000f700: 6e75 6d74 6f74 656e 736f 7228 636f 6e74  numtotensor(cont
-0000f710: 6578 742c 206e 6f64 6529 3a0a 2020 2020  ext, node):.    
-0000f720: 696e 7075 7473 203d 205f 6765 745f 696e  inputs = _get_in
-0000f730: 7075 7473 2863 6f6e 7465 7874 2c20 6e6f  puts(context, no
-0000f740: 6465 2c20 6578 7065 6374 6564 3d31 290a  de, expected=1).
-0000f750: 2020 2020 7820 3d20 696e 7075 7473 5b30      x = inputs[0
-0000f760: 5d0a 2020 2020 6966 2078 2e73 6861 7065  ].    if x.shape
-0000f770: 2021 3d20 2829 3a0a 2020 2020 2020 2020   != ():.        
-0000f780: 7261 6973 6520 5661 6c75 6545 7272 6f72  raise ValueError
-0000f790: 280a 2020 2020 2020 2020 2020 2020 226e  (.            "n
-0000f7a0: 756d 746f 7465 6e73 6f72 2065 7870 6563  umtotensor expec
-0000f7b0: 7465 6420 7363 616c 6172 2069 6e70 7574  ted scalar input
-0000f7c0: 2c20 676f 7420 7465 6e73 6f72 2077 6974  , got tensor wit
-0000f7d0: 6820 7368 6170 6520 7b7d 222e 666f 726d  h shape {}".form
-0000f7e0: 6174 280a 2020 2020 2020 2020 2020 2020  at(.            
-0000f7f0: 2020 2020 782e 7368 6170 650a 2020 2020      x.shape.    
-0000f800: 2020 2020 2020 2020 290a 2020 2020 2020          ).      
-0000f810: 2020 290a 0a20 2020 2069 6620 782e 6361    )..    if x.ca
-0000f820: 6e5f 6265 5f66 6f6c 6465 645f 746f 5f63  n_be_folded_to_c
-0000f830: 6f6e 7374 2829 3a0a 2020 2020 2020 2020  onst():.        
-0000f840: 7265 7320 3d20 6d62 2e63 6f6e 7374 2876  res = mb.const(v
-0000f850: 616c 3d5b 782e 7661 6c5d 2c20 6e61 6d65  al=[x.val], name
-0000f860: 3d6e 6f64 652e 6e61 6d65 290a 2020 2020  =node.name).    
-0000f870: 2020 2020 636f 6e74 6578 742e 6164 6428      context.add(
-0000f880: 7265 7329 0a20 2020 2065 6c73 653a 0a20  res).    else:. 
-0000f890: 2020 2020 2020 2063 6f6e 7465 7874 2e61         context.a
-0000f8a0: 6464 2878 2c20 6e6f 6465 2e6e 616d 6529  dd(x, node.name)
-0000f8b0: 0a0a 0a64 6566 205f 6966 7a6f 5f74 6f5f  ...def _ifzo_to_
-0000f8c0: 6966 6f7a 2877 6569 6768 7473 2c20 6e61  ifoz(weights, na
-0000f8d0: 6d65 293a 0a20 2020 2022 2222 0a20 2020  me):.    """.   
-0000f8e0: 2069 2c20 662c 207a 2c20 6f20 2d3e 2069   i, f, z, o -> i
-0000f8f0: 2c20 662c 206f 2c20 7a0a 2020 2020 7768  , f, o, z.    wh
-0000f900: 6572 6520 7765 6967 6874 735f 7370 6c69  ere weights_spli
-0000f910: 745b 305d 203d 3d20 692c 2065 7463 2e0a  t[0] == i, etc..
-0000f920: 2020 2020 5573 6564 2074 6f20 7472 616e      Used to tran
-0000f930: 7366 6f72 6d20 6c73 746d 2077 6569 6768  sform lstm weigh
-0000f940: 7473 2066 726f 6d20 7079 746f 7263 680a  ts from pytorch.
-0000f950: 2020 2020 746f 2043 6f72 6520 4d4c 2066      to Core ML f
-0000f960: 6f72 6d61 740a 2020 2020 2222 220a 2020  ormat.    """.  
-0000f970: 2020 7370 6c69 745f 7369 7a65 203d 2077    split_size = w
-0000f980: 6569 6768 7473 2e73 6861 7065 5b30 5d20  eights.shape[0] 
-0000f990: 2f2f 2034 0a20 2020 2077 6569 6768 7473  // 4.    weights
-0000f9a0: 5f73 706c 6974 203d 206d 622e 7370 6c69  _split = mb.spli
-0000f9b0: 7428 783d 7765 6967 6874 732c 2073 706c  t(x=weights, spl
-0000f9c0: 6974 5f73 697a 6573 3d5f 6e70 2e61 7272  it_sizes=_np.arr
-0000f9d0: 6179 285b 7370 6c69 745f 7369 7a65 5d20  ay([split_size] 
-0000f9e0: 2a20 3429 2c20 6178 6973 3d30 290a 2020  * 4), axis=0).  
-0000f9f0: 2020 7265 7475 726e 206d 622e 636f 6e63    return mb.conc
-0000fa00: 6174 280a 2020 2020 2020 2020 7661 6c75  at(.        valu
-0000fa10: 6573 3d5b 7765 6967 6874 735f 7370 6c69  es=[weights_spli
-0000fa20: 745b 305d 2c20 7765 6967 6874 735f 7370  t[0], weights_sp
-0000fa30: 6c69 745b 315d 2c20 7765 6967 6874 735f  lit[1], weights_
-0000fa40: 7370 6c69 745b 335d 2c20 7765 6967 6874  split[3], weight
-0000fa50: 735f 7370 6c69 745b 325d 5d2c 0a20 2020  s_split[2]],.   
-0000fa60: 2020 2020 2061 7869 733d 302c 0a20 2020       axis=0,.   
-0000fa70: 2029 0a0a 0a64 6566 205f 7079 746f 7263   )...def _pytorc
-0000fa80: 685f 6869 6464 656e 5f74 6f5f 636f 7265  h_hidden_to_core
-0000fa90: 6d6c 5f6d 696c 6f70 7328 782c 206e 616d  ml_milops(x, nam
-0000faa0: 6529 3a0a 2020 2020 2222 220a 2020 2020  e):.    """.    
-0000fab0: 5573 6564 2074 6f20 7472 616e 7366 6f72  Used to transfor
-0000fac0: 6d20 6c73 746d 2073 7461 7465 2076 616c  m lstm state val
-0000fad0: 7565 7320 2868 6e2c 2063 6e29 0a20 2020  ues (hn, cn).   
-0000fae0: 2066 726f 6d20 7079 746f 7263 6820 746f   from pytorch to
-0000faf0: 2043 6f72 6520 4d4c 2066 6f72 6d61 742e   Core ML format.
-0000fb00: 0a20 2020 2022 2222 0a20 2020 2073 706c  .    """.    spl
-0000fb10: 6974 5f73 697a 6520 3d20 782e 7368 6170  it_size = x.shap
-0000fb20: 655b 305d 202f 2f20 320a 2020 2020 785f  e[0] // 2.    x_
-0000fb30: 7370 6c69 7420 3d20 6d62 2e73 706c 6974  split = mb.split
-0000fb40: 2878 3d78 2c20 7370 6c69 745f 7369 7a65  (x=x, split_size
-0000fb50: 733d 5f6e 702e 6172 7261 7928 5b73 706c  s=_np.array([spl
-0000fb60: 6974 5f73 697a 655d 202a 2032 292c 2061  it_size] * 2), a
-0000fb70: 7869 733d 3029 0a20 2020 2078 5f63 6f6e  xis=0).    x_con
-0000fb80: 6361 7420 3d20 6d62 2e63 6f6e 6361 7428  cat = mb.concat(
-0000fb90: 0a20 2020 2020 2020 2076 616c 7565 733d  .        values=
-0000fba0: 5b78 5f73 706c 6974 5b30 5d2c 2078 5f73  [x_split[0], x_s
-0000fbb0: 706c 6974 5b31 5d5d 2c0a 2020 2020 2020  plit[1]],.      
-0000fbc0: 2020 6178 6973 3d32 2c0a 2020 2020 290a    axis=2,.    ).
-0000fbd0: 2020 2020 2320 2834 2e29 2053 6565 2064      # (4.) See d
-0000fbe0: 6f63 7374 7269 6e67 2074 6f20 406c 7374  ocstring to @lst
-0000fbf0: 6d0a 2020 2020 7265 7475 726e 206d 622e  m.    return mb.
-0000fc00: 7371 7565 657a 6528 783d 785f 636f 6e63  squeeze(x=x_conc
-0000fc10: 6174 2c20 6178 6573 3d5f 6e70 2e61 7272  at, axes=_np.arr
-0000fc20: 6179 285b 305d 292c 206e 616d 653d 6e61  ay([0]), name=na
-0000fc30: 6d65 290a 0a0a 6465 6620 5f61 6464 5f67  me)...def _add_g
-0000fc40: 7275 5f6c 6179 6572 285f 696e 7075 742c  ru_layer(_input,
-0000fc50: 2068 302c 2077 692c 2077 682c 2062 692c   h0, wi, wh, bi,
-0000fc60: 2062 682c 2068 5f6c 6973 745f 6e61 6d65   bh, h_list_name
-0000fc70: 2c20 685f 6e61 6d65 293a 0a20 2020 2022  , h_name):.    "
-0000fc80: 2222 0a20 2020 2041 6464 2061 2073 696e  "".    Add a sin
-0000fc90: 676c 6520 4752 5520 6c61 7965 722e 0a20  gle GRU layer.. 
-0000fca0: 2020 2050 6c65 6173 6520 6e6f 7465 2074     Please note t
-0000fcb0: 6861 7420 7468 6520 436f 7265 204d 4c20  hat the Core ML 
-0000fcc0: 4752 5520 6861 7320 6469 6666 6572 656e  GRU has differen
-0000fcd0: 7420 6465 6669 6e69 7469 6f6e 2066 726f  t definition fro
-0000fce0: 6d20 546f 7263 682c 0a20 2020 2073 6f20  m Torch,.    so 
-0000fcf0: 7765 2063 616e 6e6f 7420 7573 6520 6d62  we cannot use mb
-0000fd00: 2e67 7275 2c20 616e 6420 6e65 6564 2074  .gru, and need t
-0000fd10: 6f20 696d 706c 656d 656e 7420 6974 2077  o implement it w
-0000fd20: 6974 6820 7768 696c 6520 6c6f 6f70 2e0a  ith while loop..
-0000fd30: 2020 2020 546f 2062 6520 6d6f 7265 2073      To be more s
-0000fd40: 7065 6369 6669 632c 2069 6e20 436f 7265  pecific, in Core
-0000fd50: 204d 4c3a 0a0a 2020 2020 6f5f 7420 3d20   ML:..    o_t = 
-0000fd60: 6163 7469 7661 7469 6f6e 2857 5f7b 696f  activation(W_{io
-0000fd70: 7d20 785f 7420 2b20 725f 7420 2a20 575f  } x_t + r_t * W_
-0000fd80: 7b68 6f7d 2068 5f28 74e2 8892 3129 202b  {ho} h_(t...1) +
-0000fd90: 2062 5f7b 6f7d 290a 0a20 2020 2077 6869   b_{o})..    whi
-0000fda0: 6c65 2074 6f72 6368 2068 6173 0a20 2020  le torch has.   
-0000fdb0: 206f 5f74 203d 2061 6374 6976 6174 696f   o_t = activatio
-0000fdc0: 6e28 575f 7b69 6f7d 2078 5f74 202b 2062  n(W_{io} x_t + b
-0000fdd0: 5f7b 696f 7d20 2b20 725f 7420 2a20 2857  _{io} + r_t * (W
-0000fde0: 5f7b 686f 7d20 685f 2874 e288 9231 2920  _{ho} h_(t...1) 
-0000fdf0: 2b20 625f 7b68 6f7d 2929 0a0a 2020 2020  + b_{ho}))..    
-0000fe00: 496e 7075 7473 3a0a 2020 2020 2020 2020  Inputs:.        
-0000fe10: 5f69 6e70 7574 203a 2028 7365 715f 6c65  _input : (seq_le
-0000fe20: 6e2c 2062 6174 6368 5f73 697a 652c 2069  n, batch_size, i
-0000fe30: 6e70 7574 5f64 696d 290a 2020 2020 2020  nput_dim).      
-0000fe40: 2020 6830 203a 2028 312c 2062 6174 6368    h0 : (1, batch
-0000fe50: 5f73 697a 652c 2068 6964 6465 6e5f 6469  _size, hidden_di
-0000fe60: 6d29 0a20 2020 2020 2020 2077 6920 3a20  m).        wi : 
-0000fe70: 2833 2a68 6964 6465 6e5f 6469 6d2c 2069  (3*hidden_dim, i
-0000fe80: 6e70 7574 5f64 696d 2920 666f 7220 7468  nput_dim) for th
-0000fe90: 6520 6669 7273 7420 6c61 7965 722c 2065  e first layer, e
-0000fea0: 6c73 6520 2833 2a68 6964 6465 6e5f 6469  lse (3*hidden_di
-0000feb0: 6d2c 2068 6964 6465 6e5f 6469 6d29 0a20  m, hidden_dim). 
-0000fec0: 2020 2020 2020 2077 6820 3a20 2833 2a68         wh : (3*h
-0000fed0: 6964 6465 6e5f 6469 6d2c 2068 6964 6465  idden_dim, hidde
-0000fee0: 6e5f 6469 6d29 0a20 2020 2020 2020 2062  n_dim).        b
-0000fef0: 6920 3a20 2833 2a68 6964 6465 6e5f 6469  i : (3*hidden_di
-0000ff00: 6d29 0a20 2020 2020 2020 2062 6820 3a20  m).        bh : 
-0000ff10: 2833 2a68 6964 6465 6e5f 6469 6d29 0a0a  (3*hidden_dim)..
-0000ff20: 2020 2020 5265 7475 726e 3a0a 2020 2020      Return:.    
-0000ff30: 2020 2020 685f 6c69 7374 203a 2074 6865      h_list : the
-0000ff40: 206c 6973 7420 636f 6e74 6169 6e73 2061   list contains a
-0000ff50: 6c6c 2068 6964 6465 6e20 7374 6174 6573  ll hidden states
-0000ff60: 2066 6f72 2065 6163 6820 7469 6d65 2073   for each time s
-0000ff70: 7465 700a 2020 2020 2020 2020 2020 2020  tep.            
-0000ff80: 2020 2020 2077 6974 6820 7368 6170 6520       with shape 
-0000ff90: 2873 6571 5f6c 656e 2c20 6261 7463 685f  (seq_len, batch_
-0000ffa0: 7369 7a65 2c20 6869 6464 656e 5f64 696d  size, hidden_dim
-0000ffb0: 290a 2020 2020 2020 2020 6820 3a20 7468  ).        h : th
-0000ffc0: 6520 6c61 7374 2068 6964 6465 6e20 7374  e last hidden st
-0000ffd0: 6174 652c 2077 6974 6820 7368 6170 6520  ate, with shape 
-0000ffe0: 2831 2c20 6261 7463 685f 7369 7a65 2c20  (1, batch_size, 
-0000fff0: 6869 6464 656e 5f64 696d 0a20 2020 2022  hidden_dim.    "
-00010000: 2222 0a0a 2020 2020 2320 7370 6c69 7420  ""..    # split 
-00010010: 7468 6520 7765 6967 6874 7320 616e 6420  the weights and 
-00010020: 6269 6173 0a20 2020 2077 5f69 722c 2077  bias.    w_ir, w
-00010030: 5f69 7a2c 2077 5f69 6e20 3d20 5f6e 702e  _iz, w_in = _np.
-00010040: 7370 6c69 7428 7769 2c20 3329 0a20 2020  split(wi, 3).   
-00010050: 2077 5f68 722c 2077 5f68 7a2c 2077 5f68   w_hr, w_hz, w_h
-00010060: 6e20 3d20 5f6e 702e 7370 6c69 7428 7768  n = _np.split(wh
-00010070: 2c20 3329 0a20 2020 2062 5f69 722c 2062  , 3).    b_ir, b
-00010080: 5f69 7a2c 2062 5f69 6e20 3d20 5f6e 702e  _iz, b_in = _np.
-00010090: 7370 6c69 7428 6269 2c20 3329 0a20 2020  split(bi, 3).   
-000100a0: 2062 5f68 722c 2062 5f68 7a2c 2062 5f68   b_hr, b_hz, b_h
-000100b0: 6e20 3d20 5f6e 702e 7370 6c69 7428 6268  n = _np.split(bh
-000100c0: 2c20 3329 0a0a 2020 2020 2320 616c 6c6f  , 3)..    # allo
-000100d0: 6361 7465 2068 6c69 7374 0a20 2020 2023  cate hlist.    #
-000100e0: 2068 6c69 7374 203a 2028 7365 715f 6c65   hlist : (seq_le
-000100f0: 6e2c 2062 6174 6368 5f73 697a 652c 2068  n, batch_size, h
-00010100: 6964 6465 6e5f 6469 6d29 0a20 2020 2078  idden_dim).    x
-00010110: 5f73 6861 7065 203d 206d 622e 7368 6170  _shape = mb.shap
-00010120: 6528 783d 5f69 6e70 7574 290a 2020 2020  e(x=_input).    
-00010130: 7365 715f 6c65 6e20 3d20 6d62 2e73 6c69  seq_len = mb.sli
-00010140: 6365 5f62 795f 696e 6465 7828 783d 785f  ce_by_index(x=x_
-00010150: 7368 6170 652c 2062 6567 696e 3d5b 305d  shape, begin=[0]
-00010160: 2c20 656e 643d 5b31 5d29 0a20 2020 2068  , end=[1]).    h
-00010170: 5f73 6861 7065 203d 206d 622e 7368 6170  _shape = mb.shap
-00010180: 6528 783d 6830 290a 2020 2020 685f 7368  e(x=h0).    h_sh
-00010190: 6170 6520 3d20 6d62 2e73 6c69 6365 5f62  ape = mb.slice_b
-000101a0: 795f 696e 6465 7828 783d 685f 7368 6170  y_index(x=h_shap
-000101b0: 652c 2062 6567 696e 3d5b 315d 2c20 656e  e, begin=[1], en
-000101c0: 643d 5b33 5d29 0a20 2020 2068 5f6c 6973  d=[3]).    h_lis
-000101d0: 745f 7368 6170 6520 3d20 6d62 2e63 6f6e  t_shape = mb.con
-000101e0: 6361 7428 7661 6c75 6573 3d5b 7365 715f  cat(values=[seq_
-000101f0: 6c65 6e2c 2068 5f73 6861 7065 5d2c 2061  len, h_shape], a
-00010200: 7869 733d 3029 0a20 2020 2068 5f6c 6973  xis=0).    h_lis
-00010210: 7420 3d20 6d62 2e66 696c 6c28 7368 6170  t = mb.fill(shap
-00010220: 653d 685f 6c69 7374 5f73 6861 7065 290a  e=h_list_shape).
-00010230: 0a20 2020 2023 2063 6f6e 6361 7465 2068  .    # concate h
-00010240: 3020 746f 2068 5f6c 6973 740a 2020 2020  0 to h_list.    
-00010250: 2320 685f 6c69 7374 3a20 2873 6571 5f6c  # h_list: (seq_l
-00010260: 656e 202b 2031 2c20 6261 7463 685f 7369  en + 1, batch_si
-00010270: 7a65 2c20 6869 6464 656e 5f64 696d 290a  ze, hidden_dim).
-00010280: 2020 2020 685f 6c69 7374 203d 206d 622e      h_list = mb.
-00010290: 636f 6e63 6174 2876 616c 7565 733d 5b68  concat(values=[h
-000102a0: 302c 2068 5f6c 6973 745d 2c20 6178 6973  0, h_list], axis
-000102b0: 3d30 290a 0a20 2020 2064 6566 2063 6f6e  =0)..    def con
-000102c0: 6428 692c 2068 5f6c 6973 7429 3a0a 2020  d(i, h_list):.  
-000102d0: 2020 2020 2020 7265 7475 726e 206d 622e        return mb.
-000102e0: 6c65 7373 2878 3d69 2c20 793d 7365 715f  less(x=i, y=seq_
-000102f0: 6c65 6e29 0a0a 2020 2020 6465 6620 626f  len)..    def bo
-00010300: 6479 2869 2c20 685f 6c69 7374 293a 0a20  dy(i, h_list):. 
-00010310: 2020 2020 2020 2023 2073 6c69 6365 2066         # slice f
-00010320: 6f72 2074 6865 2078 2061 6e64 2073 7461  or the x and sta
-00010330: 7465 2066 6f72 2074 696d 6520 7374 6570  te for time step
-00010340: 2069 0a20 2020 2020 2020 2023 2074 6865   i.        # the
-00010350: 2072 6573 756c 7469 6e67 2073 6861 7065   resulting shape
-00010360: 3a0a 2020 2020 2020 2020 2320 7874 203a  :.        # xt :
-00010370: 2028 6261 7463 685f 7369 7a65 2c20 696e   (batch_size, in
-00010380: 7075 745f 6469 6d29 0a20 2020 2020 2020  put_dim).       
-00010390: 2023 2068 5f70 7265 7620 3a20 2862 6174   # h_prev : (bat
-000103a0: 6368 5f73 697a 652c 2068 6964 6465 6e5f  ch_size, hidden_
-000103b0: 6469 6d29 0a0a 2020 2020 2020 2020 7874  dim)..        xt
-000103c0: 203d 206d 622e 6761 7468 6572 2878 3d5f   = mb.gather(x=_
-000103d0: 696e 7075 742c 2069 6e64 6963 6573 3d69  input, indices=i
-000103e0: 2c20 6178 6973 3d30 290a 2020 2020 2020  , axis=0).      
-000103f0: 2020 685f 7072 6576 203d 206d 622e 6761    h_prev = mb.ga
-00010400: 7468 6572 2878 3d68 5f6c 6973 742c 2069  ther(x=h_list, i
-00010410: 6e64 6963 6573 3d69 2c20 6178 6973 3d30  ndices=i, axis=0
-00010420: 290a 0a20 2020 2020 2020 2078 7420 3d20  )..        xt = 
-00010430: 6d62 2e73 7175 6565 7a65 2878 3d78 742c  mb.squeeze(x=xt,
-00010440: 2061 7865 733d 5b30 5d29 0a20 2020 2020   axes=[0]).     
-00010450: 2020 2068 5f70 7265 7620 3d20 6d62 2e73     h_prev = mb.s
-00010460: 7175 6565 7a65 2878 3d68 5f70 7265 762c  queeze(x=h_prev,
-00010470: 2061 7865 733d 5b30 5d29 0a0a 2020 2020   axes=[0])..    
-00010480: 2020 2020 2320 7274 203d 2073 6967 6d6f      # rt = sigmo
-00010490: 6964 2877 6972 202a 2078 7420 2b20 7768  id(wir * xt + wh
-000104a0: 7220 2a20 685f 7072 6576 202b 2062 6972  r * h_prev + bir
-000104b0: 202b 2062 6872 290a 2020 2020 2020 2020   + bhr).        
-000104c0: 2320 7274 203a 2028 6261 7463 685f 7369  # rt : (batch_si
-000104d0: 7a65 2c20 6869 6464 656e 5f64 696d 290a  ze, hidden_dim).
-000104e0: 2020 2020 2020 2020 7274 5f31 203d 206d          rt_1 = m
-000104f0: 622e 6c69 6e65 6172 2878 3d78 742c 2077  b.linear(x=xt, w
-00010500: 6569 6768 743d 775f 6972 2c20 6269 6173  eight=w_ir, bias
-00010510: 3d62 5f69 7229 0a20 2020 2020 2020 2072  =b_ir).        r
-00010520: 745f 3220 3d20 6d62 2e6c 696e 6561 7228  t_2 = mb.linear(
-00010530: 783d 685f 7072 6576 2c20 7765 6967 6874  x=h_prev, weight
-00010540: 3d77 5f68 722c 2062 6961 733d 625f 6872  =w_hr, bias=b_hr
-00010550: 290a 2020 2020 2020 2020 7274 203d 206d  ).        rt = m
-00010560: 622e 6164 6428 783d 7274 5f31 2c20 793d  b.add(x=rt_1, y=
-00010570: 7274 5f32 290a 2020 2020 2020 2020 7274  rt_2).        rt
-00010580: 203d 206d 622e 7369 676d 6f69 6428 783d   = mb.sigmoid(x=
-00010590: 7274 290a 0a20 2020 2020 2020 2023 207a  rt)..        # z
-000105a0: 7420 3d20 7369 676d 6f69 6428 7769 7a20  t = sigmoid(wiz 
-000105b0: 2a20 7874 202b 2077 687a 202a 2068 5f70  * xt + whz * h_p
-000105c0: 7265 7620 2b20 6269 7a20 2b20 6268 7a29  rev + biz + bhz)
-000105d0: 0a20 2020 2020 2020 2023 207a 7420 3a20  .        # zt : 
-000105e0: 2862 6174 6368 5f73 697a 652c 2068 6964  (batch_size, hid
-000105f0: 6465 6e5f 6469 6d29 0a20 2020 2020 2020  den_dim).       
-00010600: 207a 745f 3120 3d20 6d62 2e6c 696e 6561   zt_1 = mb.linea
-00010610: 7228 783d 7874 2c20 7765 6967 6874 3d77  r(x=xt, weight=w
-00010620: 5f69 7a2c 2062 6961 733d 625f 697a 290a  _iz, bias=b_iz).
-00010630: 2020 2020 2020 2020 7a74 5f32 203d 206d          zt_2 = m
-00010640: 622e 6c69 6e65 6172 2878 3d68 5f70 7265  b.linear(x=h_pre
-00010650: 762c 2077 6569 6768 743d 775f 687a 2c20  v, weight=w_hz, 
-00010660: 6269 6173 3d62 5f68 7a29 0a20 2020 2020  bias=b_hz).     
-00010670: 2020 207a 7420 3d20 6d62 2e61 6464 2878     zt = mb.add(x
-00010680: 3d7a 745f 312c 2079 3d7a 745f 3229 0a20  =zt_1, y=zt_2). 
-00010690: 2020 2020 2020 207a 7420 3d20 6d62 2e73         zt = mb.s
-000106a0: 6967 6d6f 6964 2878 3d7a 7429 0a0a 2020  igmoid(x=zt)..  
-000106b0: 2020 2020 2020 2320 6e74 203d 2074 616e        # nt = tan
-000106c0: 6828 7769 6e20 2a20 7874 202b 2062 696e  h(win * xt + bin
-000106d0: 202b 2072 7428 7768 6e20 2a20 685f 7072   + rt(whn * h_pr
-000106e0: 6576 202b 2062 686e 2929 0a20 2020 2020  ev + bhn)).     
-000106f0: 2020 2023 206e 7420 3a20 2862 6174 6368     # nt : (batch
-00010700: 5f73 697a 652c 2068 6964 6465 6e5f 6469  _size, hidden_di
-00010710: 6d29 0a20 2020 2020 2020 206e 745f 3120  m).        nt_1 
-00010720: 3d20 6d62 2e6c 696e 6561 7228 783d 7874  = mb.linear(x=xt
-00010730: 2c20 7765 6967 6874 3d77 5f69 6e2c 2062  , weight=w_in, b
-00010740: 6961 733d 625f 696e 290a 2020 2020 2020  ias=b_in).      
-00010750: 2020 6e74 5f32 203d 206d 622e 6c69 6e65    nt_2 = mb.line
-00010760: 6172 2878 3d68 5f70 7265 762c 2077 6569  ar(x=h_prev, wei
-00010770: 6768 743d 775f 686e 2c20 6269 6173 3d62  ght=w_hn, bias=b
-00010780: 5f68 6e29 0a20 2020 2020 2020 206e 745f  _hn).        nt_
-00010790: 3220 3d20 6d62 2e6d 756c 2878 3d72 742c  2 = mb.mul(x=rt,
-000107a0: 2079 3d6e 745f 3229 0a20 2020 2020 2020   y=nt_2).       
-000107b0: 206e 7420 3d20 6d62 2e61 6464 2878 3d6e   nt = mb.add(x=n
-000107c0: 745f 312c 2079 3d6e 745f 3229 0a20 2020  t_1, y=nt_2).   
-000107d0: 2020 2020 206e 7420 3d20 6d62 2e74 616e       nt = mb.tan
-000107e0: 6828 783d 6e74 290a 0a20 2020 2020 2020  h(x=nt)..       
-000107f0: 2023 2068 203d 2028 312d 7a74 2920 2a20   # h = (1-zt) * 
-00010800: 6e74 202b 207a 742a 2068 5f70 7265 760a  nt + zt* h_prev.
-00010810: 2020 2020 2020 2020 2320 6820 3a20 2862          # h : (b
-00010820: 6174 6368 5f73 697a 652c 2068 6964 6465  atch_size, hidde
-00010830: 6e5f 6469 6d29 0a20 2020 2020 2020 2068  n_dim).        h
-00010840: 5f31 203d 206d 622e 7375 6228 783d 312e  _1 = mb.sub(x=1.
-00010850: 2c20 793d 7a74 290a 2020 2020 2020 2020  , y=zt).        
-00010860: 685f 3120 3d20 6d62 2e6d 756c 2878 3d68  h_1 = mb.mul(x=h
-00010870: 5f31 2c20 793d 6e74 290a 2020 2020 2020  _1, y=nt).      
-00010880: 2020 685f 3220 3d20 6d62 2e6d 756c 2878    h_2 = mb.mul(x
-00010890: 3d7a 742c 2079 3d68 5f70 7265 7629 0a20  =zt, y=h_prev). 
-000108a0: 2020 2020 2020 2068 203d 206d 622e 6164         h = mb.ad
-000108b0: 6428 783d 685f 312c 2079 3d68 5f32 290a  d(x=h_1, y=h_2).
-000108c0: 0a20 2020 2020 2020 2023 2075 7064 6174  .        # updat
-000108d0: 6520 636f 756e 7465 720a 2020 2020 2020  e counter.      
-000108e0: 2020 636f 756e 7465 7220 3d20 6d62 2e61    counter = mb.a
-000108f0: 6464 2878 3d69 2c20 793d 3129 0a0a 2020  dd(x=i, y=1)..  
-00010900: 2020 2020 2020 2320 7570 6461 7465 2068        # update h
-00010910: 2061 6e64 2068 5f6c 6973 740a 2020 2020   and h_list.    
-00010920: 2020 2020 6820 3d20 6d62 2e65 7870 616e      h = mb.expan
-00010930: 645f 6469 6d73 2878 3d68 2c20 6178 6573  d_dims(x=h, axes
-00010940: 3d5b 305d 290a 2020 2020 2020 2020 685f  =[0]).        h_
-00010950: 6c69 7374 203d 206d 622e 7363 6174 7465  list = mb.scatte
-00010960: 7228 6461 7461 3d68 5f6c 6973 742c 2069  r(data=h_list, i
-00010970: 6e64 6963 6573 3d63 6f75 6e74 6572 2c20  ndices=counter, 
-00010980: 7570 6461 7465 733d 6829 0a0a 2020 2020  updates=h)..    
-00010990: 2020 2020 7265 7475 726e 2028 0a20 2020      return (.   
-000109a0: 2020 2020 2020 2020 2063 6f75 6e74 6572           counter
-000109b0: 2c0a 2020 2020 2020 2020 2020 2020 685f  ,.            h_
-000109c0: 6c69 7374 2c0a 2020 2020 2020 2020 290a  list,.        ).
-000109d0: 0a20 2020 205f 2c20 685f 6c69 7374 203d  .    _, h_list =
-000109e0: 206d 622e 7768 696c 655f 6c6f 6f70 280a   mb.while_loop(.
-000109f0: 2020 2020 2020 2020 5f63 6f6e 643d 636f          _cond=co
-00010a00: 6e64 2c20 5f62 6f64 793d 626f 6479 2c20  nd, _body=body, 
-00010a10: 6c6f 6f70 5f76 6172 733d 285b 305d 2c20  loop_vars=([0], 
-00010a20: 685f 6c69 7374 292c 0a20 2020 2029 0a0a  h_list),.    )..
-00010a30: 2020 2020 2320 736c 6963 6520 6830 206f      # slice h0 o
-00010a40: 7574 206f 6620 685f 6c69 7374 0a20 2020  ut of h_list.   
-00010a50: 2068 5f6c 6973 7420 3d20 6d62 2e73 6c69   h_list = mb.sli
-00010a60: 6365 5f62 795f 696e 6465 7828 0a20 2020  ce_by_index(.   
-00010a70: 2020 2020 2078 3d68 5f6c 6973 742c 0a20       x=h_list,. 
-00010a80: 2020 2020 2020 2062 6567 696e 3d5b 312c         begin=[1,
-00010a90: 2030 2c20 305d 2c0a 2020 2020 2020 2020   0, 0],.        
-00010aa0: 656e 643d 5b30 2c20 302c 2030 5d2c 0a20  end=[0, 0, 0],. 
-00010ab0: 2020 2020 2020 2062 6567 696e 5f6d 6173         begin_mas
-00010ac0: 6b3d 5b46 616c 7365 2c20 5472 7565 2c20  k=[False, True, 
-00010ad0: 5472 7565 5d2c 0a20 2020 2020 2020 2065  True],.        e
-00010ae0: 6e64 5f6d 6173 6b3d 5b54 7275 652c 2054  nd_mask=[True, T
-00010af0: 7275 652c 2054 7275 655d 2c0a 2020 2020  rue, True],.    
-00010b00: 2020 2020 6e61 6d65 3d68 5f6c 6973 745f      name=h_list_
-00010b10: 6e61 6d65 2c0a 2020 2020 290a 0a20 2020  name,.    )..   
-00010b20: 2023 2067 6574 2074 6865 206c 6173 7420   # get the last 
-00010b30: 7374 6174 6520 6f66 2068 5f6c 6973 740a  state of h_list.
-00010b40: 2020 2020 6966 2073 6571 5f6c 656e 2e76      if seq_len.v
-00010b50: 616c 2069 7320 4e6f 6e65 206f 7220 7365  al is None or se
-00010b60: 715f 6c65 6e2e 7661 6c20 3e20 313a 0a20  q_len.val > 1:. 
-00010b70: 2020 2020 2020 2068 203d 206d 622e 736c         h = mb.sl
-00010b80: 6963 655f 6279 5f69 6e64 6578 280a 2020  ice_by_index(.  
-00010b90: 2020 2020 2020 2020 2020 783d 685f 6c69            x=h_li
-00010ba0: 7374 2c0a 2020 2020 2020 2020 2020 2020  st,.            
-00010bb0: 6265 6769 6e3d 5b2d 312c 2030 2c20 305d  begin=[-1, 0, 0]
-00010bc0: 2c0a 2020 2020 2020 2020 2020 2020 656e  ,.            en
-00010bd0: 643d 5b2d 322c 2030 2c20 305d 2c0a 2020  d=[-2, 0, 0],.  
-00010be0: 2020 2020 2020 2020 2020 6265 6769 6e5f            begin_
-00010bf0: 6d61 736b 3d5b 4661 6c73 652c 2054 7275  mask=[False, Tru
-00010c00: 652c 2054 7275 655d 2c0a 2020 2020 2020  e, True],.      
-00010c10: 2020 2020 2020 656e 645f 6d61 736b 3d5b        end_mask=[
-00010c20: 4661 6c73 652c 2054 7275 652c 2054 7275  False, True, Tru
-00010c30: 655d 2c0a 2020 2020 2020 2020 2020 2020  e],.            
-00010c40: 7374 7269 6465 3d5b 2d31 2c20 312c 2031  stride=[-1, 1, 1
-00010c50: 5d2c 0a20 2020 2020 2020 2020 2020 206e  ],.            n
-00010c60: 616d 653d 685f 6e61 6d65 2c0a 2020 2020  ame=h_name,.    
-00010c70: 2020 2020 290a 2020 2020 656c 7365 3a0a      ).    else:.
-00010c80: 2020 2020 2020 2020 6820 3d20 685f 6c69          h = h_li
-00010c90: 7374 0a0a 2020 2020 7265 7475 726e 2068  st..    return h
-00010ca0: 5f6c 6973 742c 2068 0a0a 0a40 7265 6769  _list, h...@regi
-00010cb0: 7374 6572 5f74 6f72 6368 5f6f 700a 6465  ster_torch_op.de
-00010cc0: 6620 6772 7528 636f 6e74 6578 742c 206e  f gru(context, n
-00010cd0: 6f64 6529 3a0a 2020 2020 696e 7075 7473  ode):.    inputs
-00010ce0: 203d 205f 6765 745f 696e 7075 7473 2863   = _get_inputs(c
-00010cf0: 6f6e 7465 7874 2c20 6e6f 6465 2c20 6578  ontext, node, ex
-00010d00: 7065 6374 6564 3d39 290a 0a20 2020 205f  pected=9)..    _
-00010d10: 696e 7075 7420 3d20 696e 7075 7473 5b30  input = inputs[0
-00010d20: 5d0a 2020 2020 6830 203d 2069 6e70 7574  ].    h0 = input
-00010d30: 735b 315d 0a20 2020 2077 6569 6768 7473  s[1].    weights
-00010d40: 5f6c 6973 7420 3d20 696e 7075 7473 5b32  _list = inputs[2
-00010d50: 5d0a 2020 2020 6861 735f 6269 6173 203d  ].    has_bias =
-00010d60: 2069 6e70 7574 735b 335d 2e76 616c 0a20   inputs[3].val. 
-00010d70: 2020 206e 756d 5f6c 6179 6572 7320 3d20     num_layers = 
-00010d80: 696e 7075 7473 5b34 5d2e 7661 6c0a 2020  inputs[4].val.  
-00010d90: 2020 6472 6f70 6f75 7420 3d20 696e 7075    dropout = inpu
-00010da0: 7473 5b35 5d0a 2020 2020 6269 6469 7265  ts[5].    bidire
-00010db0: 6374 696f 6e61 6c20 3d20 696e 7075 7473  ctional = inputs
-00010dc0: 5b37 5d2e 7661 6c0a 2020 2020 6261 7463  [7].val.    batc
-00010dd0: 685f 6669 7273 7420 3d20 696e 7075 7473  h_first = inputs
-00010de0: 5b38 5d2e 7661 6c0a 0a20 2020 2023 2046  [8].val..    # F
-00010df0: 6f72 2065 6163 6820 6c61 7965 7220 6f66  or each layer of
-00010e00: 2047 5255 2c20 7468 6520 6c61 796f 7574   GRU, the layout
-00010e10: 206f 6620 7468 6520 7765 6967 6874 7320   of the weights 
-00010e20: 6c69 7374 2069 7320 5b57 692c 2057 682c  list is [Wi, Wh,
-00010e30: 2062 692c 2062 685d 2077 6974 6820 6861   bi, bh] with ha
-00010e40: 735f 6269 6173 203d 3d20 5472 7565 2c0a  s_bias == True,.
-00010e50: 2020 2020 2320 616e 6420 6973 205b 5769      # and is [Wi
-00010e60: 2c20 5768 5d20 7769 7468 2062 6961 7320  , Wh] with bias 
-00010e70: 3d3d 2046 616c 7365 2e0a 2020 2020 2320  == False..    # 
-00010e80: 4966 2062 6964 6972 6563 7469 6f6e 616c  If bidirectional
-00010e90: 203d 3d20 5472 7565 2c20 7468 6520 6c69   == True, the li
-00010ea0: 7374 2069 7320 646f 7562 6c65 2075 702c  st is double up,
-00010eb0: 2063 6f72 7265 7370 6f6e 6469 6e67 2074   corresponding t
-00010ec0: 6f20 666f 7277 6172 6420 616e 6420 6261  o forward and ba
-00010ed0: 636b 7761 7264 2064 6972 6563 7469 6f6e  ckward direction
-00010ee0: 2e0a 2020 2020 6578 7065 6374 6564 5f6e  ..    expected_n
-00010ef0: 756d 5f77 6569 6768 7473 203d 2032 202a  um_weights = 2 *
-00010f00: 206e 756d 5f6c 6179 6572 7320 2a20 2869   num_layers * (i
-00010f10: 6e74 2868 6173 5f62 6961 7329 202b 2031  nt(has_bias) + 1
-00010f20: 2920 2a20 2869 6e74 2862 6964 6972 6563  ) * (int(bidirec
-00010f30: 7469 6f6e 616c 2920 2b20 3129 0a20 2020  tional) + 1).   
-00010f40: 2069 6620 6c65 6e28 7765 6967 6874 735f   if len(weights_
-00010f50: 6c69 7374 2920 213d 2065 7870 6563 7465  list) != expecte
-00010f60: 645f 6e75 6d5f 7765 6967 6874 733a 0a20  d_num_weights:. 
-00010f70: 2020 2020 2020 2072 6169 7365 2056 616c         raise Val
-00010f80: 7565 4572 726f 7228 0a20 2020 2020 2020  ueError(.       
-00010f90: 2020 2020 2022 496e 636f 7272 6563 7420       "Incorrect 
-00010fa0: 7765 6967 6874 7320 7368 6170 6520 666f  weights shape fo
-00010fb0: 7220 6772 7520 6c61 7965 723a 2045 7870  r gru layer: Exp
-00010fc0: 6563 7465 643a 207b 7d2e 2052 6563 6965  ected: {}. Recie
-00010fd0: 7665 6420 7b7d 222e 666f 726d 6174 280a  ved {}".format(.
-00010fe0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010ff0: 6578 7065 6374 6564 5f6e 756d 5f77 6569  expected_num_wei
-00011000: 6768 7473 2c20 6c65 6e28 7765 6967 6874  ghts, len(weight
-00011010: 735f 6c69 7374 290a 2020 2020 2020 2020  s_list).        
-00011020: 2020 2020 290a 2020 2020 2020 2020 290a      ).        ).
-00011030: 0a20 2020 2023 2054 7261 6e73 706f 7365  .    # Transpose
-00011040: 2074 6865 2069 6e70 7574 2064 6174 6120   the input data 
-00011050: 746f 2028 7365 715f 6c65 6e2c 2062 6174  to (seq_len, bat
-00011060: 6368 5f73 697a 652c 2069 6e70 7574 5f64  ch_size, input_d
-00011070: 696d 2920 6966 2062 6174 6368 5f66 6972  im) if batch_fir
-00011080: 7374 203d 3d20 5472 7565 0a20 2020 2069  st == True.    i
-00011090: 6620 6261 7463 685f 6669 7273 743a 0a20  f batch_first:. 
-000110a0: 2020 2020 2020 205f 696e 7075 7420 3d20         _input = 
-000110b0: 6d62 2e74 7261 6e73 706f 7365 2878 3d5f  mb.transpose(x=_
-000110c0: 696e 7075 742c 2070 6572 6d3d 5b31 2c20  input, perm=[1, 
-000110d0: 302c 2032 5d29 0a0a 2020 2020 2320 6974  0, 2])..    # it
-000110e0: 6572 6174 6520 7468 726f 7567 6820 616c  erate through al
-000110f0: 6c20 7468 6520 6c61 7965 7273 0a20 2020  l the layers.   
-00011100: 2078 203d 205f 696e 7075 740a 2020 2020   x = _input.    
-00011110: 7374 6174 655f 6f75 745f 6c69 7374 203d  state_out_list =
-00011120: 205b 5d0a 0a20 2020 2064 6566 205f 6765   []..    def _ge
-00011130: 745f 7765 6967 6874 735f 616e 645f 6269  t_weights_and_bi
-00011140: 6173 2877 6569 6768 7473 5f6c 6973 742c  as(weights_list,
-00011150: 2069 6e64 6578 2c20 6e75 6d5f 6c61 7965   index, num_laye
-00011160: 7273 2c20 6861 735f 6269 6173 2c20 6269  rs, has_bias, bi
-00011170: 6469 7265 6374 696f 6e61 6c2c 206d 6f64  directional, mod
-00011180: 6529 3a0a 2020 2020 2020 2020 6e75 6d5f  e):.        num_
-00011190: 7765 6967 6874 735f 7065 725f 6c61 7965  weights_per_laye
-000111a0: 7220 3d20 6c65 6e28 7765 6967 6874 735f  r = len(weights_
-000111b0: 6c69 7374 2920 2f2f 206e 756d 5f6c 6179  list) // num_lay
-000111c0: 6572 730a 2020 2020 2020 2020 7765 6967  ers.        weig
-000111d0: 6874 7320 3d20 7765 6967 6874 735f 6c69  hts = weights_li
-000111e0: 7374 5b0a 2020 2020 2020 2020 2020 2020  st[.            
-000111f0: 6e75 6d5f 7765 6967 6874 735f 7065 725f  num_weights_per_
-00011200: 6c61 7965 7220 2a20 696e 6465 7820 3a20  layer * index : 
-00011210: 6e75 6d5f 7765 6967 6874 735f 7065 725f  num_weights_per_
-00011220: 6c61 7965 7220 2a20 2869 6e64 6578 202b  layer * (index +
-00011230: 2031 290a 2020 2020 2020 2020 5d0a 0a20   1).        ].. 
-00011240: 2020 2020 2020 2069 6620 6269 6469 7265         if bidire
-00011250: 6374 696f 6e61 6c3a 0a20 2020 2020 2020  ctional:.       
-00011260: 2020 2020 2077 6569 6768 7473 5f66 2c20       weights_f, 
-00011270: 7765 6967 6874 735f 7220 3d20 280a 2020  weights_r = (.  
-00011280: 2020 2020 2020 2020 2020 2020 2020 7765                we
-00011290: 6967 6874 735b 3a20 6e75 6d5f 7765 6967  ights[: num_weig
-000112a0: 6874 735f 7065 725f 6c61 7965 7220 2f2f  hts_per_layer //
-000112b0: 2032 5d2c 0a20 2020 2020 2020 2020 2020   2],.           
-000112c0: 2020 2020 2077 6569 6768 7473 5b6e 756d       weights[num
-000112d0: 5f77 6569 6768 7473 5f70 6572 5f6c 6179  _weights_per_lay
-000112e0: 6572 202f 2f20 3220 3a5d 2c0a 2020 2020  er // 2 :],.    
-000112f0: 2020 2020 2020 2020 290a 2020 2020 2020          ).      
-00011300: 2020 2020 2020 6173 7365 7274 206c 656e        assert len
-00011310: 2877 6569 6768 7473 5f66 2920 3d3d 206c  (weights_f) == l
-00011320: 656e 2877 6569 6768 7473 5f72 290a 2020  en(weights_r).  
-00011330: 2020 2020 2020 656c 7365 3a0a 2020 2020        else:.    
-00011340: 2020 2020 2020 2020 7765 6967 6874 735f          weights_
-00011350: 662c 2077 6569 6768 7473 5f72 203d 2077  f, weights_r = w
-00011360: 6569 6768 7473 2c20 5b5d 0a0a 2020 2020  eights, []..    
-00011370: 2020 2020 6966 206d 6f64 6520 3d3d 2022      if mode == "
-00011380: 666f 7277 6172 6422 3a0a 2020 2020 2020  forward":.      
-00011390: 2020 2020 2020 7765 6967 6874 7320 3d20        weights = 
-000113a0: 7765 6967 6874 735f 660a 2020 2020 2020  weights_f.      
-000113b0: 2020 656c 6966 206d 6f64 6520 3d3d 2022    elif mode == "
-000113c0: 7265 7665 7273 6522 3a0a 2020 2020 2020  reverse":.      
-000113d0: 2020 2020 2020 7765 6967 6874 7320 3d20        weights = 
-000113e0: 7765 6967 6874 735f 720a 0a20 2020 2020  weights_r..     
-000113f0: 2020 2077 692c 2077 6820 3d20 7765 6967     wi, wh = weig
-00011400: 6874 735b 305d 2e76 616c 2c20 7765 6967  hts[0].val, weig
-00011410: 6874 735b 315d 2e76 616c 0a0a 2020 2020  hts[1].val..    
-00011420: 2020 2020 6966 2068 6173 5f62 6961 733a      if has_bias:
-00011430: 0a20 2020 2020 2020 2020 2020 2062 692c  .            bi,
-00011440: 2062 6820 3d20 7765 6967 6874 735b 325d   bh = weights[2]
-00011450: 2e76 616c 2c20 7765 6967 6874 735b 335d  .val, weights[3]
-00011460: 2e76 616c 0a20 2020 2020 2020 2065 6c73  .val.        els
-00011470: 653a 0a20 2020 2020 2020 2020 2020 2068  e:.            h
-00011480: 6964 6465 6e5f 6469 6d20 3d20 7768 2e73  idden_dim = wh.s
-00011490: 6861 7065 5b31 5d0a 2020 2020 2020 2020  hape[1].        
-000114a0: 2020 2020 6269 2c20 6268 203d 205f 6e70      bi, bh = _np
-000114b0: 2e7a 6572 6f73 2833 202a 2068 6964 6465  .zeros(3 * hidde
-000114c0: 6e5f 6469 6d29 2c20 5f6e 702e 7a65 726f  n_dim), _np.zero
-000114d0: 7328 3320 2a20 6869 6464 656e 5f64 696d  s(3 * hidden_dim
-000114e0: 290a 0a20 2020 2020 2020 2072 6574 7572  )..        retur
-000114f0: 6e20 7769 2c20 7768 2c20 6269 2c20 6268  n wi, wh, bi, bh
-00011500: 0a0a 2020 2020 6465 6620 5f67 6574 5f69  ..    def _get_i
-00011510: 6e69 7469 616c 5f73 7461 7465 2868 302c  nitial_state(h0,
-00011520: 2069 2c20 6269 6469 7265 6374 696f 6e61   i, bidirectiona
-00011530: 6c2c 206d 6f64 6529 3a0a 0a20 2020 2020  l, mode):..     
-00011540: 2020 2069 6620 6d6f 6465 203d 3d20 2266     if mode == "f
-00011550: 6f72 7761 7264 223a 0a20 2020 2020 2020  orward":.       
-00011560: 2020 2020 2072 6574 7572 6e20 6d62 2e73       return mb.s
-00011570: 6c69 6365 5f62 795f 696e 6465 7828 0a20  lice_by_index(. 
-00011580: 2020 2020 2020 2020 2020 2020 2020 2078                 x
-00011590: 3d68 302c 0a20 2020 2020 2020 2020 2020  =h0,.           
-000115a0: 2020 2020 2062 6567 696e 3d5b 2831 202b       begin=[(1 +
-000115b0: 2069 6e74 2862 6964 6972 6563 7469 6f6e   int(bidirection
-000115c0: 616c 2929 202a 2069 2c20 302c 2030 5d2c  al)) * i, 0, 0],
-000115d0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000115e0: 2065 6e64 3d5b 2831 202b 2069 6e74 2862   end=[(1 + int(b
-000115f0: 6964 6972 6563 7469 6f6e 616c 2929 202a  idirectional)) *
-00011600: 2069 202b 2031 2c20 302c 2030 5d2c 0a20   i + 1, 0, 0],. 
-00011610: 2020 2020 2020 2020 2020 2020 2020 2062                 b
-00011620: 6567 696e 5f6d 6173 6b3d 5b46 616c 7365  egin_mask=[False
-00011630: 2c20 5472 7565 2c20 5472 7565 5d2c 0a20  , True, True],. 
-00011640: 2020 2020 2020 2020 2020 2020 2020 2065                 e
-00011650: 6e64 5f6d 6173 6b3d 5b46 616c 7365 2c20  nd_mask=[False, 
-00011660: 5472 7565 2c20 5472 7565 5d2c 0a20 2020  True, True],.   
-00011670: 2020 2020 2020 2020 2029 0a20 2020 2020           ).     
-00011680: 2020 2069 6620 6d6f 6465 203d 3d20 2272     if mode == "r
-00011690: 6576 6572 7365 223a 0a20 2020 2020 2020  everse":.       
-000116a0: 2020 2020 2061 7373 6572 7420 6269 6469       assert bidi
-000116b0: 7265 6374 696f 6e61 6c0a 2020 2020 2020  rectional.      
-000116c0: 2020 2020 2020 7265 7475 726e 206d 622e        return mb.
-000116d0: 736c 6963 655f 6279 5f69 6e64 6578 280a  slice_by_index(.
-000116e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000116f0: 783d 6830 2c0a 2020 2020 2020 2020 2020  x=h0,.          
-00011700: 2020 2020 2020 6265 6769 6e3d 5b32 202a        begin=[2 *
-00011710: 2069 202b 2031 2c20 302c 2030 5d2c 0a20   i + 1, 0, 0],. 
-00011720: 2020 2020 2020 2020 2020 2020 2020 2065                 e
-00011730: 6e64 3d5b 3220 2a20 2869 202b 2031 292c  nd=[2 * (i + 1),
-00011740: 2030 2c20 305d 2c0a 2020 2020 2020 2020   0, 0],.        
-00011750: 2020 2020 2020 2020 6265 6769 6e5f 6d61          begin_ma
-00011760: 736b 3d5b 4661 6c73 652c 2054 7275 652c  sk=[False, True,
-00011770: 2054 7275 655d 2c0a 2020 2020 2020 2020   True],.        
-00011780: 2020 2020 2020 2020 656e 645f 6d61 736b          end_mask
-00011790: 3d5b 4661 6c73 652c 2054 7275 652c 2054  =[False, True, T
-000117a0: 7275 655d 2c0a 2020 2020 2020 2020 2020  rue],.          
-000117b0: 2020 290a 0a20 2020 2073 6571 5f6f 7574    )..    seq_out
-000117c0: 7075 745f 6e61 6d65 203d 206e 6f64 652e  put_name = node.
-000117d0: 6f75 7470 7574 735b 305d 2020 2320 6f75  outputs[0]  # ou
-000117e0: 7470 7574 2073 6571 7565 6e63 6520 6e61  tput sequence na
-000117f0: 6d65 0a20 2020 2073 7461 7465 5f6f 7574  me.    state_out
-00011800: 7075 745f 6e61 6d65 203d 206e 6f64 652e  put_name = node.
-00011810: 6f75 7470 7574 735b 315d 2020 2320 6f75  outputs[1]  # ou
-00011820: 7470 7574 2073 7461 7465 206e 616d 650a  tput state name.
-00011830: 0a20 2020 2066 6f72 2069 2069 6e20 7261  .    for i in ra
-00011840: 6e67 6528 6e75 6d5f 6c61 7965 7273 293a  nge(num_layers):
-00011850: 0a20 2020 2020 2020 2023 2067 6574 206c  .        # get l
-00011860: 6179 6572 206e 616d 6573 0a20 2020 2020  ayer names.     
-00011870: 2020 2078 5f6e 616d 6520 3d20 7365 715f     x_name = seq_
-00011880: 6f75 7470 7574 5f6e 616d 6520 2b20 225f  output_name + "_
-00011890: 6c61 7965 725f 2220 2b20 7374 7228 6929  layer_" + str(i)
-000118a0: 2069 6620 6920 3c20 6e75 6d5f 6c61 7965   if i < num_laye
-000118b0: 7273 202d 2031 2065 6c73 6520 7365 715f  rs - 1 else seq_
-000118c0: 6f75 7470 7574 5f6e 616d 650a 2020 2020  output_name.    
-000118d0: 2020 2020 685f 6e61 6d65 203d 2073 7461      h_name = sta
-000118e0: 7465 5f6f 7574 7075 745f 6e61 6d65 202b  te_output_name +
-000118f0: 2027 5f6c 6179 6572 5f27 202b 2073 7472   '_layer_' + str
-00011900: 2869 2920 6966 206e 756d 5f6c 6179 6572  (i) if num_layer
-00011910: 7320 3e20 3020 656c 7365 2073 7461 7465  s > 0 else state
-00011920: 5f6f 7574 7075 745f 6e61 6d65 0a0a 2020  _output_name..  
-00011930: 2020 2020 2020 6966 2062 6174 6368 5f66        if batch_f
-00011940: 6972 7374 3a0a 2020 2020 2020 2020 2020  irst:.          
-00011950: 2020 785f 6e61 6d65 202b 3d20 225f 746d    x_name += "_tm
-00011960: 7022 0a0a 2020 2020 2020 2020 6966 2062  p"..        if b
-00011970: 6964 6972 6563 7469 6f6e 616c 3a0a 2020  idirectional:.  
-00011980: 2020 2020 2020 2020 2020 785f 665f 6e61            x_f_na
-00011990: 6d65 203d 2078 5f6e 616d 6520 2b20 275f  me = x_name + '_
-000119a0: 666f 7277 6172 6427 0a20 2020 2020 2020  forward'.       
-000119b0: 2020 2020 2068 5f66 5f6e 616d 6520 3d20       h_f_name = 
-000119c0: 685f 6e61 6d65 202b 2027 5f66 6f72 7761  h_name + '_forwa
-000119d0: 7264 270a 2020 2020 2020 2020 2020 2020  rd'.            
-000119e0: 785f 725f 6e61 6d65 203d 2078 5f6e 616d  x_r_name = x_nam
-000119f0: 6520 2b20 275f 6261 636b 7761 7264 270a  e + '_backward'.
-00011a00: 2020 2020 2020 2020 2020 2020 685f 725f              h_r_
-00011a10: 6e61 6d65 203d 2068 5f6e 616d 6520 2b20  name = h_name + 
-00011a20: 275f 6261 636b 7761 7264 270a 2020 2020  '_backward'.    
-00011a30: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
-00011a40: 2020 2020 2020 785f 665f 6e61 6d65 203d        x_f_name =
-00011a50: 2078 5f6e 616d 650a 2020 2020 2020 2020   x_name.        
-00011a60: 2020 2020 685f 665f 6e61 6d65 203d 2068      h_f_name = h
-00011a70: 5f6e 616d 650a 0a20 2020 2020 2020 2023  _name..        #
-00011a80: 2066 6f72 7761 7264 2064 6972 6563 7469   forward directi
-00011a90: 6f6e 0a20 2020 2020 2020 2078 5f66 203d  on.        x_f =
-00011aa0: 2078 0a20 2020 2020 2020 2077 695f 662c   x.        wi_f,
-00011ab0: 2077 685f 662c 2062 695f 662c 2062 685f   wh_f, bi_f, bh_
-00011ac0: 6620 3d20 5f67 6574 5f77 6569 6768 7473  f = _get_weights
-00011ad0: 5f61 6e64 5f62 6961 7328 0a20 2020 2020  _and_bias(.     
-00011ae0: 2020 2020 2020 2077 6569 6768 7473 5f6c         weights_l
-00011af0: 6973 742c 2069 2c20 6e75 6d5f 6c61 7965  ist, i, num_laye
-00011b00: 7273 2c20 6861 735f 6269 6173 2c20 6269  rs, has_bias, bi
-00011b10: 6469 7265 6374 696f 6e61 6c2c 2022 666f  directional, "fo
-00011b20: 7277 6172 6422 0a20 2020 2020 2020 2029  rward".        )
-00011b30: 0a20 2020 2020 2020 2069 6e69 7469 616c  .        initial
-00011b40: 5f68 5f66 203d 205f 6765 745f 696e 6974  _h_f = _get_init
-00011b50: 6961 6c5f 7374 6174 6528 6830 2c20 692c  ial_state(h0, i,
-00011b60: 2062 6964 6972 6563 7469 6f6e 616c 2c20   bidirectional, 
-00011b70: 2266 6f72 7761 7264 2229 0a20 2020 2020  "forward").     
-00011b80: 2020 2078 5f66 2c20 685f 6620 3d20 5f61     x_f, h_f = _a
-00011b90: 6464 5f67 7275 5f6c 6179 6572 2878 5f66  dd_gru_layer(x_f
-00011ba0: 2c20 696e 6974 6961 6c5f 685f 662c 2077  , initial_h_f, w
-00011bb0: 695f 662c 2077 685f 662c 2062 695f 662c  i_f, wh_f, bi_f,
-00011bc0: 2062 685f 662c 2078 5f66 5f6e 616d 652c   bh_f, x_f_name,
-00011bd0: 2068 5f66 5f6e 616d 6529 0a0a 2020 2020   h_f_name)..    
-00011be0: 2020 2020 2320 7265 7665 7273 6520 6469      # reverse di
-00011bf0: 7265 6374 696f 6e0a 2020 2020 2020 2020  rection.        
-00011c00: 6966 2062 6964 6972 6563 7469 6f6e 616c  if bidirectional
-00011c10: 3a0a 2020 2020 2020 2020 2020 2020 785f  :.            x_
-00011c20: 7220 3d20 6d62 2e72 6576 6572 7365 2878  r = mb.reverse(x
-00011c30: 3d78 2c20 6178 6573 3d5b 305d 290a 2020  =x, axes=[0]).  
-00011c40: 2020 2020 2020 2020 2020 7769 5f72 2c20            wi_r, 
-00011c50: 7768 5f72 2c20 6269 5f72 2c20 6268 5f72  wh_r, bi_r, bh_r
-00011c60: 203d 205f 6765 745f 7765 6967 6874 735f   = _get_weights_
-00011c70: 616e 645f 6269 6173 280a 2020 2020 2020  and_bias(.      
-00011c80: 2020 2020 2020 2020 2020 7765 6967 6874            weight
-00011c90: 735f 6c69 7374 2c20 692c 206e 756d 5f6c  s_list, i, num_l
-00011ca0: 6179 6572 732c 2068 6173 5f62 6961 732c  ayers, has_bias,
-00011cb0: 2062 6964 6972 6563 7469 6f6e 616c 2c20   bidirectional, 
-00011cc0: 2272 6576 6572 7365 220a 2020 2020 2020  "reverse".      
-00011cd0: 2020 2020 2020 290a 2020 2020 2020 2020        ).        
-00011ce0: 2020 2020 696e 6974 6961 6c5f 685f 7220      initial_h_r 
-00011cf0: 3d20 5f67 6574 5f69 6e69 7469 616c 5f73  = _get_initial_s
-00011d00: 7461 7465 2868 302c 2069 2c20 6269 6469  tate(h0, i, bidi
-00011d10: 7265 6374 696f 6e61 6c2c 2022 7265 7665  rectional, "reve
-00011d20: 7273 6522 290a 2020 2020 2020 2020 2020  rse").          
-00011d30: 2020 785f 722c 2068 5f72 203d 205f 6164    x_r, h_r = _ad
-00011d40: 645f 6772 755f 6c61 7965 7228 0a20 2020  d_gru_layer(.   
-00011d50: 2020 2020 2020 2020 2020 2020 2078 5f72               x_r
-00011d60: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-00011d70: 2020 696e 6974 6961 6c5f 685f 722c 0a20    initial_h_r,. 
-00011d80: 2020 2020 2020 2020 2020 2020 2020 2077                 w
-00011d90: 695f 722c 0a20 2020 2020 2020 2020 2020  i_r,.           
-00011da0: 2020 2020 2077 685f 722c 0a20 2020 2020       wh_r,.     
-00011db0: 2020 2020 2020 2020 2020 2062 695f 722c             bi_r,
-00011dc0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00011dd0: 2062 685f 722c 0a20 2020 2020 2020 2020   bh_r,.         
-00011de0: 2020 2020 2020 2078 5f72 5f6e 616d 6520         x_r_name 
-00011df0: 2b20 225f 7265 7665 7273 6522 2c0a 2020  + "_reverse",.  
-00011e00: 2020 2020 2020 2020 2020 2020 2020 685f                h_
-00011e10: 725f 6e61 6d65 2c0a 2020 2020 2020 2020  r_name,.        
-00011e20: 2020 2020 290a 2020 2020 2020 2020 2020      ).          
-00011e30: 2020 785f 7220 3d20 6d62 2e72 6576 6572    x_r = mb.rever
-00011e40: 7365 2878 3d78 5f72 2c20 6178 6573 3d5b  se(x=x_r, axes=[
-00011e50: 305d 2c20 6e61 6d65 3d78 5f72 5f6e 616d  0], name=x_r_nam
-00011e60: 6529 0a0a 2020 2020 2020 2020 2020 2020  e)..            
-00011e70: 2320 636f 6e63 6174 6520 6f75 7470 7574  # concate output
-00011e80: 2066 726f 6d20 666f 7277 6172 6420 616e   from forward an
-00011e90: 6420 7265 7665 7273 6520 6469 7265 6374  d reverse direct
-00011ea0: 696f 6e0a 2020 2020 2020 2020 2020 2020  ion.            
-00011eb0: 7820 3d20 6d62 2e63 6f6e 6361 7428 7661  x = mb.concat(va
-00011ec0: 6c75 6573 3d5b 785f 662c 2078 5f72 5d2c  lues=[x_f, x_r],
-00011ed0: 2061 7869 733d 322c 206e 616d 653d 785f   axis=2, name=x_
-00011ee0: 6e61 6d65 290a 2020 2020 2020 2020 2020  name).          
-00011ef0: 2020 6820 3d20 6d62 2e63 6f6e 6361 7428    h = mb.concat(
-00011f00: 7661 6c75 6573 3d5b 685f 662c 2068 5f72  values=[h_f, h_r
-00011f10: 5d2c 2061 7869 733d 302c 206e 616d 653d  ], axis=0, name=
-00011f20: 685f 6e61 6d65 290a 2020 2020 2020 2020  h_name).        
-00011f30: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
-00011f40: 2020 7820 3d20 785f 660a 2020 2020 2020    x = x_f.      
-00011f50: 2020 2020 2020 6820 3d20 685f 660a 0a20        h = h_f.. 
-00011f60: 2020 2020 2020 2073 7461 7465 5f6f 7574         state_out
-00011f70: 5f6c 6973 742e 6170 7065 6e64 2868 290a  _list.append(h).
-00011f80: 0a20 2020 2023 2072 6e6e 206f 7574 7075  .    # rnn outpu
-00011f90: 740a 2020 2020 6966 2062 6174 6368 5f66  t.    if batch_f
-00011fa0: 6972 7374 3a0a 2020 2020 2020 2020 7820  irst:.        x 
-00011fb0: 3d20 6d62 2e74 7261 6e73 706f 7365 2878  = mb.transpose(x
-00011fc0: 3d78 2c20 7065 726d 3d5b 312c 2030 2c20  =x, perm=[1, 0, 
-00011fd0: 325d 2c20 6e61 6d65 3d73 6571 5f6f 7574  2], name=seq_out
-00011fe0: 7075 745f 6e61 6d65 290a 2020 2020 636f  put_name).    co
-00011ff0: 6e74 6578 742e 6164 6428 782c 2073 6571  ntext.add(x, seq
-00012000: 5f6f 7574 7075 745f 6e61 6d65 290a 0a20  _output_name).. 
-00012010: 2020 2023 2073 7461 7465 206f 7574 7075     # state outpu
-00012020: 740a 2020 2020 6966 206c 656e 2873 7461  t.    if len(sta
-00012030: 7465 5f6f 7574 5f6c 6973 7429 203e 2031  te_out_list) > 1
-00012040: 3a0a 2020 2020 2020 2020 6820 3d20 6d62  :.        h = mb
-00012050: 2e63 6f6e 6361 7428 7661 6c75 6573 3d73  .concat(values=s
-00012060: 7461 7465 5f6f 7574 5f6c 6973 742c 2061  tate_out_list, a
-00012070: 7869 733d 302c 206e 616d 653d 7374 6174  xis=0, name=stat
-00012080: 655f 6f75 7470 7574 5f6e 616d 6529 0a20  e_output_name). 
-00012090: 2020 2063 6f6e 7465 7874 2e61 6464 2868     context.add(h
-000120a0: 2c20 7374 6174 655f 6f75 7470 7574 5f6e  , state_output_n
-000120b0: 616d 6529 0a0a 0a64 6566 205f 6164 645f  ame)...def _add_
-000120c0: 7369 6d70 6c65 5f72 6e6e 2863 6f6e 7465  simple_rnn(conte
-000120d0: 7874 2c20 6e6f 6465 2c20 6163 7469 7661  xt, node, activa
-000120e0: 7469 6f6e 293a 0a20 2020 2069 6e70 7574  tion):.    input
-000120f0: 7320 3d20 5f67 6574 5f69 6e70 7574 7328  s = _get_inputs(
-00012100: 636f 6e74 6578 742c 206e 6f64 652c 2065  context, node, e
-00012110: 7870 6563 7465 643d 3929 0a0a 2020 2020  xpected=9)..    
-00012120: 2727 270a 2020 2020 4261 7463 6820 7369  '''.    Batch si
-00012130: 7a65 3a20 420a 2020 2020 5365 7175 656e  ze: B.    Sequen
-00012140: 6365 206c 656e 6774 683a 2053 0a20 2020  ce length: S.   
-00012150: 2049 6e70 7574 2064 696d 656e 7369 6f6e   Input dimension
-00012160: 3a20 430a 2020 2020 4869 6464 656e 2064  : C.    Hidden d
-00012170: 696d 656e 7369 6f6e 3a20 480a 0a20 2020  imension: H..   
-00012180: 2028 3129 205f 696e 7075 7420 3a20 2842   (1) _input : (B
-00012190: 2c20 532c 2043 2920 6966 2062 6174 6368  , S, C) if batch
-000121a0: 5f66 6972 7374 203d 3d20 5472 7565 2c20  _first == True, 
-000121b0: 656c 7365 2028 532c 2042 2c20 4329 0a20  else (S, B, C). 
-000121c0: 2020 2028 3229 2068 303a 2028 6e75 6d5f     (2) h0: (num_
-000121d0: 6c61 7965 7273 2c20 422c 2048 290a 2020  layers, B, H).  
-000121e0: 2020 2727 270a 2020 2020 5f69 6e70 7574    '''.    _input
-000121f0: 203d 2069 6e70 7574 735b 305d 0a20 2020   = inputs[0].   
-00012200: 2068 3020 3d20 696e 7075 7473 5b31 5d0a   h0 = inputs[1].
-00012210: 2020 2020 7765 6967 6874 735f 6c69 7374      weights_list
-00012220: 203d 2069 6e70 7574 735b 325d 0a20 2020   = inputs[2].   
-00012230: 2068 6173 5f62 6961 7320 3d20 696e 7075   has_bias = inpu
-00012240: 7473 5b33 5d2e 7661 6c0a 2020 2020 6e75  ts[3].val.    nu
-00012250: 6d5f 6c61 7965 7273 203d 2069 6e70 7574  m_layers = input
-00012260: 735b 345d 2e76 616c 0a20 2020 2064 726f  s[4].val.    dro
-00012270: 706f 7574 203d 2069 6e70 7574 735b 355d  pout = inputs[5]
-00012280: 0a20 2020 2062 6964 6972 6563 7469 6f6e  .    bidirection
-00012290: 616c 203d 2069 6e70 7574 735b 375d 2e76  al = inputs[7].v
-000122a0: 616c 0a20 2020 2062 6174 6368 5f66 6972  al.    batch_fir
-000122b0: 7374 203d 2069 6e70 7574 735b 385d 2e76  st = inputs[8].v
-000122c0: 616c 0a0a 2020 2020 2320 5765 206f 6e6c  al..    # We onl
-000122d0: 7920 7375 7070 6f72 7420 756e 692d 6469  y support uni-di
-000122e0: 7265 6374 696f 6e61 6c20 7369 6d70 6c65  rectional simple
-000122f0: 2052 4e4e 206e 6f77 0a20 2020 2069 6620   RNN now.    if 
-00012300: 6269 6469 7265 6374 696f 6e61 6c3a 0a20  bidirectional:. 
-00012310: 2020 2020 2020 2072 6169 7365 204e 6f74         raise Not
-00012320: 496d 706c 656d 656e 7465 6445 7272 6f72  ImplementedError
-00012330: 2822 4269 6469 7265 6374 696f 6e61 6c20  ("Bidirectional 
-00012340: 7369 6d70 6c65 2052 4e4e 206e 6f74 2073  simple RNN not s
-00012350: 7570 706f 7274 6564 2e22 290a 0a20 2020  upported.")..   
-00012360: 2065 7870 6563 7465 645f 6e75 6d5f 7765   expected_num_we
-00012370: 6967 6874 7320 3d20 3220 2a20 6e75 6d5f  ights = 2 * num_
-00012380: 6c61 7965 7273 202a 2028 696e 7428 6861  layers * (int(ha
-00012390: 735f 6269 6173 2920 2b20 3129 0a20 2020  s_bias) + 1).   
-000123a0: 2069 6620 6c65 6e28 7765 6967 6874 735f   if len(weights_
-000123b0: 6c69 7374 2920 213d 2065 7870 6563 7465  list) != expecte
-000123c0: 645f 6e75 6d5f 7765 6967 6874 733a 0a20  d_num_weights:. 
-000123d0: 2020 2020 2020 2072 6169 7365 2056 616c         raise Val
-000123e0: 7565 4572 726f 7228 0a20 2020 2020 2020  ueError(.       
-000123f0: 2020 2020 2022 496e 636f 7272 6563 7420       "Incorrect 
-00012400: 7765 6967 6874 7320 7368 6170 6520 666f  weights shape fo
-00012410: 7220 6c73 746d 206c 6179 6572 3a20 4578  r lstm layer: Ex
-00012420: 7065 6374 6564 3a20 7b7d 2e20 5265 6369  pected: {}. Reci
-00012430: 6576 6564 207b 7d22 2e66 6f72 6d61 7428  eved {}".format(
-00012440: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00012450: 2065 7870 6563 7465 645f 6e75 6d5f 7765   expected_num_we
-00012460: 6967 6874 732c 206c 656e 2877 6569 6768  ights, len(weigh
-00012470: 7473 5f6c 6973 7429 0a20 2020 2020 2020  ts_list).       
-00012480: 2020 2020 2029 0a20 2020 2020 2020 2029       ).        )
-00012490: 0a0a 2020 2020 2320 5472 616e 7370 6f73  ..    # Transpos
-000124a0: 6520 7468 6520 696e 7075 7420 6461 7461  e the input data
-000124b0: 2074 6f20 2853 2c20 422c 2043 2920 6966   to (S, B, C) if
-000124c0: 2062 6174 6368 5f66 6972 7374 203d 3d20   batch_first == 
-000124d0: 5472 7565 0a20 2020 2069 6620 6261 7463  True.    if batc
-000124e0: 685f 6669 7273 743a 0a20 2020 2020 2020  h_first:.       
-000124f0: 205f 696e 7075 7420 3d20 6d62 2e74 7261   _input = mb.tra
-00012500: 6e73 706f 7365 2878 3d5f 696e 7075 742c  nspose(x=_input,
-00012510: 2070 6572 6d3d 5b31 2c20 302c 2032 5d29   perm=[1, 0, 2])
-00012520: 0a0a 2020 2020 7374 6174 655f 6f75 745f  ..    state_out_
-00012530: 6c69 7374 203d 205b 5d0a 2020 2020 6f75  list = [].    ou
-00012540: 7420 3d20 5f69 6e70 7574 0a0a 2020 2020  t = _input..    
-00012550: 666f 7220 6920 696e 2072 616e 6765 286e  for i in range(n
-00012560: 756d 5f6c 6179 6572 7329 3a0a 2020 2020  um_layers):.    
-00012570: 2020 2020 6966 2068 6173 5f62 6961 733a      if has_bias:
-00012580: 0a20 2020 2020 2020 2020 2020 2077 6569  .            wei
-00012590: 6768 745f 6968 203d 2077 6569 6768 7473  ght_ih = weights
-000125a0: 5f6c 6973 745b 3420 2a20 695d 0a20 2020  _list[4 * i].   
-000125b0: 2020 2020 2020 2020 2077 6569 6768 745f           weight_
-000125c0: 6868 203d 2077 6569 6768 7473 5f6c 6973  hh = weights_lis
-000125d0: 745b 3420 2a20 6920 2b20 315d 0a20 2020  t[4 * i + 1].   
-000125e0: 2020 2020 2020 2020 2062 6961 7320 3d20           bias = 
-000125f0: 6d62 2e61 6464 2878 3d77 6569 6768 7473  mb.add(x=weights
-00012600: 5f6c 6973 745b 3420 2a20 6920 2b20 325d  _list[4 * i + 2]
-00012610: 2c20 793d 7765 6967 6874 735f 6c69 7374  , y=weights_list
-00012620: 5b34 202a 2069 202b 2033 5d29 0a20 2020  [4 * i + 3]).   
-00012630: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
-00012640: 2020 2020 2020 2077 6569 6768 745f 6968         weight_ih
-00012650: 203d 2077 6569 6768 7473 5f6c 6973 745b   = weights_list[
-00012660: 3220 2a20 695d 0a20 2020 2020 2020 2020  2 * i].         
-00012670: 2020 2077 6569 6768 745f 6868 203d 2077     weight_hh = w
-00012680: 6569 6768 7473 5f6c 6973 745b 3220 2a20  eights_list[2 * 
-00012690: 6920 2b20 315d 0a20 2020 2020 2020 2020  i + 1].         
-000126a0: 2020 2062 6961 7320 3d20 4e6f 6e65 0a0a     bias = None..
-000126b0: 2020 2020 2020 2020 2320 6765 7420 7468          # get th
-000126c0: 6520 696e 6974 6961 6c20 7374 6174 650a  e initial state.
-000126d0: 2020 2020 2020 2020 696e 6974 6961 6c5f          initial_
-000126e0: 6820 3d20 6d62 2e73 6c69 6365 5f62 795f  h = mb.slice_by_
-000126f0: 696e 6465 7828 0a20 2020 2020 2020 2020  index(.         
-00012700: 2020 2078 3d68 302c 0a20 2020 2020 2020     x=h0,.       
-00012710: 2020 2020 2062 6567 696e 3d5b 692c 2030       begin=[i, 0
-00012720: 2c20 305d 2c0a 2020 2020 2020 2020 2020  , 0],.          
-00012730: 2020 656e 643d 5b30 2c20 302c 2030 5d2c    end=[0, 0, 0],
-00012740: 0a20 2020 2020 2020 2020 2020 2073 7472  .            str
-00012750: 6964 653d 5b31 2c20 312c 2031 5d2c 0a20  ide=[1, 1, 1],. 
-00012760: 2020 2020 2020 2020 2020 2062 6567 696e             begin
-00012770: 5f6d 6173 6b3d 5b46 616c 7365 2c20 5472  _mask=[False, Tr
-00012780: 7565 2c20 5472 7565 5d2c 0a20 2020 2020  ue, True],.     
-00012790: 2020 2020 2020 2065 6e64 5f6d 6173 6b3d         end_mask=
-000127a0: 5b46 616c 7365 2c20 5472 7565 2c20 5472  [False, True, Tr
-000127b0: 7565 5d2c 0a20 2020 2020 2020 2020 2020  ue],.           
-000127c0: 2073 7175 6565 7a65 5f6d 6173 6b3d 5b54   squeeze_mask=[T
-000127d0: 7275 652c 2046 616c 7365 2c20 4661 6c73  rue, False, Fals
-000127e0: 655d 2c0a 2020 2020 2020 2020 290a 0a20  e],.        ).. 
-000127f0: 2020 2020 2020 2023 2067 6574 2074 6865         # get the
-00012800: 2052 4e4e 206f 7574 7075 7420 666f 7220   RNN output for 
-00012810: 6561 6368 2075 6e69 740a 2020 2020 2020  each unit.      
-00012820: 2020 6f75 742c 2073 7461 7465 203d 206d    out, state = m
-00012830: 622e 726e 6e28 0a20 2020 2020 2020 2020  b.rnn(.         
-00012840: 2020 2078 3d6f 7574 2c0a 2020 2020 2020     x=out,.      
-00012850: 2020 2020 2020 696e 6974 6961 6c5f 683d        initial_h=
-00012860: 696e 6974 6961 6c5f 682c 0a20 2020 2020  initial_h,.     
-00012870: 2020 2020 2020 2077 6569 6768 745f 6968         weight_ih
-00012880: 3d77 6569 6768 745f 6968 2c0a 2020 2020  =weight_ih,.    
-00012890: 2020 2020 2020 2020 7765 6967 6874 5f68          weight_h
-000128a0: 683d 7765 6967 6874 5f68 682c 0a20 2020  h=weight_hh,.   
-000128b0: 2020 2020 2020 2020 2062 6961 733d 6269           bias=bi
-000128c0: 6173 2c0a 2020 2020 2020 2020 2020 2020  as,.            
-000128d0: 6f75 7470 7574 5f73 6571 7565 6e63 653d  output_sequence=
-000128e0: 5472 7565 2c0a 2020 2020 2020 2020 2020  True,.          
-000128f0: 2020 6163 7469 7661 7469 6f6e 3d61 6374    activation=act
-00012900: 6976 6174 696f 6e2c 0a20 2020 2020 2020  ivation,.       
-00012910: 2029 0a0a 2020 2020 2020 2020 2320 6170   )..        # ap
-00012920: 7065 6e64 2073 7461 7465 2074 6f20 6c69  pend state to li
-00012930: 7374 7320 7768 6963 6820 7769 6c6c 2073  sts which will s
-00012940: 7461 636b 206c 6174 6572 0a20 2020 2020  tack later.     
-00012950: 2020 2073 7461 7465 5f6f 7574 5f6c 6973     state_out_lis
-00012960: 742e 6170 7065 6e64 2873 7461 7465 290a  t.append(state).
-00012970: 0a20 2020 2023 2072 6e6e 206f 7574 7075  .    # rnn outpu
-00012980: 740a 2020 2020 6f75 7470 7574 5f6e 616d  t.    output_nam
-00012990: 6520 3d20 6e6f 6465 2e6f 7574 7075 7473  e = node.outputs
-000129a0: 5b30 5d0a 2020 2020 6966 2062 6174 6368  [0].    if batch
-000129b0: 5f66 6972 7374 3a0a 2020 2020 2020 2020  _first:.        
-000129c0: 6f75 7420 3d20 6d62 2e74 7261 6e73 706f  out = mb.transpo
-000129d0: 7365 2878 3d6f 7574 2c20 7065 726d 3d5b  se(x=out, perm=[
-000129e0: 312c 2030 2c20 325d 2c20 6e61 6d65 3d6f  1, 0, 2], name=o
-000129f0: 7574 7075 745f 6e61 6d65 290a 2020 2020  utput_name).    
-00012a00: 656c 7365 3a0a 2020 2020 2020 2020 6f75  else:.        ou
-00012a10: 7420 3d20 6d62 2e69 6465 6e74 6974 7928  t = mb.identity(
-00012a20: 783d 6f75 742c 206e 616d 653d 6f75 7470  x=out, name=outp
-00012a30: 7574 5f6e 616d 6529 0a20 2020 2063 6f6e  ut_name).    con
-00012a40: 7465 7874 2e61 6464 286f 7574 2c20 6f75  text.add(out, ou
-00012a50: 7470 7574 5f6e 616d 6529 0a0a 2020 2020  tput_name)..    
-00012a60: 2320 7374 6163 6b20 7468 6520 7374 6174  # stack the stat
-00012a70: 6573 2069 6e74 6f20 6120 7369 6e67 6c65  es into a single
-00012a80: 2074 656e 736f 720a 2020 2020 7374 6174   tensor.    stat
-00012a90: 655f 6f75 7470 7574 5f6e 616d 6520 3d20  e_output_name = 
-00012aa0: 6e6f 6465 2e6f 7574 7075 7473 5b31 5d0a  node.outputs[1].
-00012ab0: 2020 2020 6966 206e 756d 5f6c 6179 6572      if num_layer
-00012ac0: 7320 3d3d 2031 3a0a 2020 2020 2020 2020  s == 1:.        
-00012ad0: 7374 6174 6520 3d20 6d62 2e65 7870 616e  state = mb.expan
-00012ae0: 645f 6469 6d73 2878 3d73 7461 7465 5f6f  d_dims(x=state_o
-00012af0: 7574 5f6c 6973 745b 305d 2c20 6178 6573  ut_list[0], axes
-00012b00: 3d5b 305d 2c20 6e61 6d65 3d73 7461 7465  =[0], name=state
-00012b10: 5f6f 7574 7075 745f 6e61 6d65 290a 2020  _output_name).  
-00012b20: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
-00012b30: 7374 6174 6520 3d20 6d62 2e73 7461 636b  state = mb.stack
-00012b40: 2876 616c 7565 733d 7374 6174 655f 6f75  (values=state_ou
-00012b50: 745f 6c69 7374 2c20 6178 6973 3d30 2c20  t_list, axis=0, 
-00012b60: 6e61 6d65 3d73 7461 7465 5f6f 7574 7075  name=state_outpu
-00012b70: 745f 6e61 6d65 290a 2020 2020 636f 6e74  t_name).    cont
-00012b80: 6578 742e 6164 6428 7374 6174 652c 2073  ext.add(state, s
-00012b90: 7461 7465 5f6f 7574 7075 745f 6e61 6d65  tate_output_name
-00012ba0: 290a 0a0a 4072 6567 6973 7465 725f 746f  )...@register_to
-00012bb0: 7263 685f 6f70 0a64 6566 2072 6e6e 5f74  rch_op.def rnn_t
-00012bc0: 616e 6828 636f 6e74 6578 742c 206e 6f64  anh(context, nod
-00012bd0: 6529 3a0a 2020 2020 5f61 6464 5f73 696d  e):.    _add_sim
-00012be0: 706c 655f 726e 6e28 636f 6e74 6578 742c  ple_rnn(context,
-00012bf0: 206e 6f64 652c 2022 7461 6e68 2229 0a0a   node, "tanh")..
-00012c00: 0a40 7265 6769 7374 6572 5f74 6f72 6368  .@register_torch
-00012c10: 5f6f 700a 6465 6620 726e 6e5f 7265 6c75  _op.def rnn_relu
-00012c20: 2863 6f6e 7465 7874 2c20 6e6f 6465 293a  (context, node):
-00012c30: 0a20 2020 205f 6164 645f 7369 6d70 6c65  .    _add_simple
-00012c40: 5f72 6e6e 2863 6f6e 7465 7874 2c20 6e6f  _rnn(context, no
-00012c50: 6465 2c20 2272 656c 7522 290a 0a0a 6465  de, "relu")...de
-00012c60: 6620 5f61 6464 5f6d 696c 5f6c 7374 6d28  f _add_mil_lstm(
-00012c70: 696e 7075 742c 2069 6e69 7469 616c 5f68  input, initial_h
-00012c80: 2c20 696e 6974 6961 6c5f 632c 2077 6569  , initial_c, wei
-00012c90: 6768 7473 2c20 6861 735f 6269 6173 2c20  ghts, has_bias, 
-00012ca0: 6269 6469 7265 6374 696f 6e61 6c2c 206e  bidirectional, n
-00012cb0: 616d 6529 3a0a 2020 2020 2222 220a 2020  ame):.    """.  
-00012cc0: 2020 4d6f 7374 206f 6620 7468 6973 2063    Most of this c
-00012cd0: 6f64 6520 6973 2074 6f20 7472 616e 7366  ode is to transf
-00012ce0: 6f72 6d20 7468 6520 7465 6e73 6f72 7320  orm the tensors 
-00012cf0: 696e 746f 0a20 2020 2061 2073 6861 7065  into.    a shape
-00012d00: 2061 6363 6570 7461 626c 6520 6279 2074   acceptable by t
-00012d10: 6865 2043 6f72 6520 4d4c 2069 6d70 6c65  he Core ML imple
-00012d20: 6d65 6e74 6174 696f 6e20 6f66 204c 5354  mentation of LST
-00012d30: 4d2e 0a0a 2020 2020 466f 7220 7765 6967  M...    For weig
-00012d40: 6874 732c 2062 6961 7365 732c 2020 7065  hts, biases,  pe
-00012d50: 7220 6469 7265 6374 696f 6e2c 2070 7974  r direction, pyt
-00012d60: 6f72 6368 2075 7365 7320 7477 6f20 7465  orch uses two te
-00012d70: 6e73 6f72 733a 0a20 2020 2028 6969 2c20  nsors:.    (ii, 
-00012d80: 6966 2c20 6967 2c20 696f 2920 7374 6163  if, ig, io) stac
-00012d90: 6b65 6420 6f6e 2074 6f70 206f 6620 6561  ked on top of ea
-00012da0: 6368 206f 7468 6572 2066 6f72 2065 6163  ch other for eac
-00012db0: 6820 6c61 7965 7220 2874 656e 736f 7220  h layer (tensor 
-00012dc0: 3129 0a20 2020 2061 6e64 2028 6869 2c20  1).    and (hi, 
-00012dd0: 6866 2c20 6867 2c20 686f 2920 7374 6163  hf, hg, ho) stac
-00012de0: 6b65 6420 6f6e 2074 6f70 206f 6620 6561  ked on top of ea
-00012df0: 6368 206f 7468 6572 2066 6f72 2065 6163  ch other for eac
-00012e00: 6820 6c61 7965 7220 2874 656e 736f 7220  h layer (tensor 
-00012e10: 3229 2e0a 2020 2020 5468 6174 2069 732c  2)..    That is,
-00012e20: 2020 2857 5f69 697c 575f 6966 7c57 5f69    (W_ii|W_if|W_i
-00012e30: 677c 575f 696f 292c 206f 6620 7368 6170  g|W_io), of shap
-00012e40: 6520 2834 2a68 6964 6465 6e5f 7369 7a65  e (4*hidden_size
-00012e50: 2c20 696e 7075 745f 7369 7a65 2920 616e  , input_size) an
-00012e60: 640a 2020 2020 2857 5f68 697c 575f 6866  d.    (W_hi|W_hf
-00012e70: 7c57 5f68 677c 575f 686f 292c 206f 6620  |W_hg|W_ho), of 
-00012e80: 7368 6170 6520 2834 2a68 6964 6465 6e5f  shape (4*hidden_
-00012e90: 7369 7a65 2c20 6869 6464 656e 5f73 697a  size, hidden_siz
-00012ea0: 6529 2e0a 0a0a 2020 2020 5468 6520 436f  e)....    The Co
-00012eb0: 7265 204d 4c20 4c53 544d 206f 7020 6578  re ML LSTM op ex
-00012ec0: 7065 6374 7320 7477 6f20 7465 6e73 6f72  pects two tensor
-00012ed0: 732c 2077 6569 6768 7420 616e 6420 6269  s, weight and bi
-00012ee0: 6173 2e20 536f 0a20 2020 2074 6865 2074  as. So.    the t
-00012ef0: 656e 736f 7273 2066 6f72 2077 6569 6768  ensors for weigh
-00012f00: 7420 616e 6420 6269 6173 2061 7265 2073  t and bias are s
-00012f10: 6570 6572 6174 6564 2066 726f 6d20 7079  eperated from py
-00012f20: 746f 7263 6827 7320 4077 6569 6768 7473  torch's @weights
-00012f30: 206c 6973 7420 2831 2e29 2e0a 2020 2020   list (1.)..    
-00012f40: 466f 7220 6269 6173 2074 656e 736f 722c  For bias tensor,
-00012f50: 2074 6865 2043 6f72 6520 4d4c 204c 5354   the Core ML LST
-00012f60: 4d20 6f70 2065 7870 6563 7473 2074 6865  M op expects the
-00012f70: 2066 6f72 6d20 6969 2c20 6966 2c20 696f   form ii, if, io
-00012f80: 2c20 6967 2061 6e64 2068 692c 2068 662c  , ig and hi, hf,
-00012f90: 2068 6f2c 2068 672c 0a20 2020 2072 6571   ho, hg,.    req
-00012fa0: 7569 7269 6e67 2074 6865 2069 667a 6f5f  uiring the ifzo_
-00012fb0: 746f 5f69 666f 7a20 6675 6e63 7469 6f6e  to_ifoz function
-00012fc0: 2e20 4675 7274 6865 7220 6164 6469 6e67  . Further adding
-00012fd0: 2069 6e70 7574 2061 6e64 2068 6964 6465   input and hidde
-00012fe0: 6e20 6269 6173 2069 6e74 6f20 6f6e 6520  n bias into one 
-00012ff0: 2832 2e29 2e0a 2020 2020 5369 6d69 6c61  (2.)..    Simila
-00013000: 7220 746f 2062 6961 732c 2069 6e70 7574  r to bias, input
-00013010: 2061 6e64 2068 6964 6465 6e20 7765 6967   and hidden weig
-00013020: 6874 2072 6571 7569 7265 7320 6469 6666  ht requires diff
-00013030: 6572 656e 7420 6c61 796f 7574 2e20 2833  erent layout. (3
-00013040: 2e29 0a0a 2020 2020 696e 6974 6961 6c5f  .)..    initial_
-00013050: 6820 616e 6420 696e 6974 6961 6c5f 6320  h and initial_c 
-00013060: 6172 6520 6c69 7374 206f 6620 226e 756d  are list of "num
-00013070: 5f6c 6179 6572 7322 2074 656e 736f 7273  _layers" tensors
-00013080: 2c20 6561 6368 206f 6620 7368 6170 6520  , each of shape 
-00013090: 5b6e 5f64 6972 6563 7469 6f6e 732c 2042  [n_directions, B
-000130a0: 2c20 485d 2c0a 2020 2020 7768 6572 6520  , H],.    where 
-000130b0: 6e5f 6469 7265 6374 696f 6e73 203d 2031  n_directions = 1
-000130c0: 206f 7220 320a 2020 2020 7768 6572 6561   or 2.    wherea
-000130d0: 7320 7468 6520 7368 6170 6573 206f 6620  s the shapes of 
-000130e0: 7468 6520 696e 6974 6961 6c20 7374 6174  the initial stat
-000130f0: 6573 2074 6f20 4d49 4c27 7320 4c53 544d  es to MIL's LSTM
-00013100: 2c20 4269 4c53 544d 206d 7573 7420 6265  , BiLSTM must be
-00013110: 205b 422c 2048 5d20 616e 6420 5b42 2c20   [B, H] and [B, 
-00013120: 322a 485d 2072 6573 7065 6374 6976 656c  2*H] respectivel
-00013130: 792e 0a20 2020 2054 6869 7320 6d65 616e  y..    This mean
-00013140: 7320 7765 206e 6565 6420 746f 2064 6f20  s we need to do 
-00013150: 7468 6520 666f 6c6c 6f77 696e 6720 7472  the following tr
-00013160: 616e 7366 6f72 6d61 7469 6f6e 733a 0a20  ansformations:. 
-00013170: 2020 202d 2069 6620 6974 7320 616e 204c     - if its an L
-00013180: 5354 4d20 286e 5f64 6972 6563 7469 6f6e  STM (n_direction
-00013190: 733d 3129 3a0a 2020 2020 2020 2020 2020  s=1):.          
-000131a0: 2020 7371 7565 657a 6520 7468 6520 6669    squeeze the fi
-000131b0: 7273 7420 6469 6d65 6e73 696f 6e20 6f66  rst dimension of
-000131c0: 2069 6e69 7469 616c 5f68 2f69 6e69 7469   initial_h/initi
-000131d0: 616c 5f63 202c 2062 6566 6f72 6520 6665  al_c , before fe
-000131e0: 6564 696e 6720 6974 2074 6f20 4d49 4c27  eding it to MIL'
-000131f0: 7320 4c53 544d 0a20 2020 202d 2069 6620  s LSTM.    - if 
-00013200: 6974 7320 6120 4269 4c53 544d 2028 6e5f  its a BiLSTM (n_
-00013210: 6469 7265 6374 696f 6e73 3d32 293a 0a20  directions=2):. 
-00013220: 2020 2020 2020 2020 2020 202d 2073 706c             - spl
-00013230: 6974 2074 6865 2069 6e70 7574 2c20 7368  it the input, sh
-00013240: 6170 653d 2832 2c20 422c 2048 292c 2074  ape=(2, B, H), t
-00013250: 6f20 6765 7420 2831 2c42 2c48 2920 616e  o get (1,B,H) an
-00013260: 6420 2831 2c42 2c48 290a 2020 2020 2020  d (1,B,H).      
-00013270: 2020 2020 2020 2d20 636f 6e63 6174 656e        - concaten
-00013280: 6174 6520 746f 2067 6574 2028 312c 422c  ate to get (1,B,
-00013290: 322a 4829 0a20 2020 2020 2020 2020 2020  2*H).           
-000132a0: 202d 2073 7175 6565 7a65 2074 6f20 6765   - squeeze to ge
-000132b0: 7420 2842 2c32 2a48 290a 2020 2020 2222  t (B,2*H).    ""
-000132c0: 220a 0a20 2020 2069 6620 6269 6469 7265  "..    if bidire
-000132d0: 6374 696f 6e61 6c3a 0a20 2020 2020 2020  ctional:.       
-000132e0: 2069 6620 6861 735f 6269 6173 3a0a 2020   if has_bias:.  
-000132f0: 2020 2020 2020 2020 2020 2320 2831 2e29            # (1.)
-00013300: 0a20 2020 2020 2020 2020 2020 2062 6961  .            bia
-00013310: 7365 7320 3d20 7765 6967 6874 735b 323a  ses = weights[2:
-00013320: 345d 202b 2077 6569 6768 7473 5b36 3a38  4] + weights[6:8
-00013330: 5d0a 2020 2020 2020 2020 2020 2020 7765  ].            we
-00013340: 6967 6874 7320 3d20 7765 6967 6874 735b  ights = weights[
-00013350: 303a 325d 202b 2077 6569 6768 7473 5b34  0:2] + weights[4
-00013360: 3a36 5d0a 0a20 2020 2020 2020 2020 2020  :6]..           
-00013370: 2023 2028 322e 290a 2020 2020 2020 2020   # (2.).        
-00013380: 2020 2020 6173 7365 7274 206c 656e 2862      assert len(b
-00013390: 6961 7365 7329 203d 3d20 340a 2020 2020  iases) == 4.    
-000133a0: 2020 2020 2020 2020 666f 7220 696e 6465          for inde
-000133b0: 7820 696e 2072 616e 6765 286c 656e 2862  x in range(len(b
-000133c0: 6961 7365 7329 293a 0a20 2020 2020 2020  iases)):.       
-000133d0: 2020 2020 2020 2020 2062 6961 7365 735b           biases[
-000133e0: 696e 6465 785d 203d 205f 6966 7a6f 5f74  index] = _ifzo_t
-000133f0: 6f5f 6966 6f7a 280a 2020 2020 2020 2020  o_ifoz(.        
-00013400: 2020 2020 2020 2020 2020 2020 6269 6173              bias
-00013410: 6573 5b69 6e64 6578 5d2c 0a20 2020 2020  es[index],.     
-00013420: 2020 2020 2020 2020 2020 2020 2020 206e                 n
-00013430: 616d 653d 227b 7d5f 6c73 746d 5f62 6961  ame="{}_lstm_bia
-00013440: 735f 7265 7368 6170 655f 7b7d 222e 666f  s_reshape_{}".fo
-00013450: 726d 6174 286e 616d 652c 2069 6e64 6578  rmat(name, index
-00013460: 292c 0a20 2020 2020 2020 2020 2020 2020  ),.             
-00013470: 2020 2029 0a20 2020 2020 2020 2020 2020     ).           
-00013480: 2066 5f62 203d 206d 622e 6164 6428 783d   f_b = mb.add(x=
-00013490: 6269 6173 6573 5b30 5d2c 2079 3d62 6961  biases[0], y=bia
-000134a0: 7365 735b 315d 2c20 290a 2020 2020 2020  ses[1], ).      
-000134b0: 2020 2020 2020 725f 6220 3d20 6d62 2e61        r_b = mb.a
-000134c0: 6464 2878 3d62 6961 7365 735b 325d 2c20  dd(x=biases[2], 
-000134d0: 793d 6269 6173 6573 5b33 5d2c 2029 0a0a  y=biases[3], )..
-000134e0: 2020 2020 2020 2020 2320 2833 2e29 0a20          # (3.). 
-000134f0: 2020 2020 2020 2066 5f69 685f 7720 3d20         f_ih_w = 
-00013500: 5f69 667a 6f5f 746f 5f69 666f 7a28 0a20  _ifzo_to_ifoz(. 
-00013510: 2020 2020 2020 2020 2020 2077 6569 6768             weigh
-00013520: 7473 5b30 5d2c 206e 616d 653d 6e61 6d65  ts[0], name=name
-00013530: 202b 2022 5f6c 7374 6d5f 666f 7277 6172   + "_lstm_forwar
-00013540: 645f 6968 5f77 6569 6768 7473 5f69 666f  d_ih_weights_ifo
-00013550: 7a5f 746f 5f69 667a 6f22 2c0a 2020 2020  z_to_ifzo",.    
-00013560: 2020 2020 290a 2020 2020 2020 2020 665f      ).        f_
-00013570: 6868 5f77 203d 205f 6966 7a6f 5f74 6f5f  hh_w = _ifzo_to_
-00013580: 6966 6f7a 280a 2020 2020 2020 2020 2020  ifoz(.          
-00013590: 2020 7765 6967 6874 735b 315d 2c20 6e61    weights[1], na
-000135a0: 6d65 3d6e 616d 6520 2b20 225f 6c73 746d  me=name + "_lstm
-000135b0: 5f66 6f72 7761 7264 5f68 685f 7765 6967  _forward_hh_weig
-000135c0: 6874 735f 6966 6f7a 5f74 6f5f 6966 7a6f  hts_ifoz_to_ifzo
-000135d0: 222c 0a20 2020 2020 2020 2029 0a20 2020  ",.        ).   
-000135e0: 2020 2020 2072 5f69 685f 7720 3d20 5f69       r_ih_w = _i
-000135f0: 667a 6f5f 746f 5f69 666f 7a28 0a20 2020  fzo_to_ifoz(.   
-00013600: 2020 2020 2020 2020 2077 6569 6768 7473           weights
-00013610: 5b32 5d2c 206e 616d 653d 6e61 6d65 202b  [2], name=name +
-00013620: 2022 5f6c 7374 6d5f 7265 7665 7273 655f   "_lstm_reverse_
-00013630: 6968 5f77 6569 6768 7473 5f69 666f 7a5f  ih_weights_ifoz_
-00013640: 746f 5f69 667a 6f22 2c0a 2020 2020 2020  to_ifzo",.      
-00013650: 2020 290a 2020 2020 2020 2020 725f 6868    ).        r_hh
-00013660: 5f77 203d 205f 6966 7a6f 5f74 6f5f 6966  _w = _ifzo_to_if
-00013670: 6f7a 280a 2020 2020 2020 2020 2020 2020  oz(.            
-00013680: 7765 6967 6874 735b 335d 2c20 6e61 6d65  weights[3], name
-00013690: 3d6e 616d 6520 2b20 225f 6c73 746d 5f72  =name + "_lstm_r
-000136a0: 6576 6572 7365 5f68 685f 7765 6967 6874  everse_hh_weight
-000136b0: 735f 6966 6f7a 5f74 6f5f 6966 7a6f 222c  s_ifoz_to_ifzo",
-000136c0: 0a20 2020 2020 2020 2029 0a0a 2020 2020  .        )..    
-000136d0: 2020 2020 6820 3d20 5f70 7974 6f72 6368      h = _pytorch
-000136e0: 5f68 6964 6465 6e5f 746f 5f63 6f72 656d  _hidden_to_corem
-000136f0: 6c5f 6d69 6c6f 7073 2869 6e69 7469 616c  l_milops(initial
-00013700: 5f68 2c20 6e61 6d65 3d6e 616d 6520 2b20  _h, name=name + 
-00013710: 225f 6c73 746d 5f68 305f 7265 7368 6170  "_lstm_h0_reshap
-00013720: 6564 2229 0a20 2020 2020 2020 2063 203d  ed").        c =
-00013730: 205f 7079 746f 7263 685f 6869 6464 656e   _pytorch_hidden
-00013740: 5f74 6f5f 636f 7265 6d6c 5f6d 696c 6f70  _to_coreml_milop
-00013750: 7328 696e 6974 6961 6c5f 632c 206e 616d  s(initial_c, nam
-00013760: 653d 6e61 6d65 202b 2022 5f6c 7374 6d5f  e=name + "_lstm_
-00013770: 6330 5f72 6573 6861 7065 6422 290a 2020  c0_reshaped").  
-00013780: 2020 2020 2020 7265 7475 726e 206d 622e        return mb.
-00013790: 6c73 746d 2878 3d69 6e70 7574 2c0a 2020  lstm(x=input,.  
-000137a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000137b0: 2020 2020 2069 6e69 7469 616c 5f68 3d68       initial_h=h
-000137c0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-000137d0: 2020 2020 2020 2020 2069 6e69 7469 616c           initial
-000137e0: 5f63 3d63 2c0a 2020 2020 2020 2020 2020  _c=c,.          
-000137f0: 2020 2020 2020 2020 2020 2020 2077 6569               wei
-00013800: 6768 745f 6968 3d66 5f69 685f 772c 0a20  ght_ih=f_ih_w,. 
-00013810: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013820: 2020 2020 2020 7765 6967 6874 5f68 683d        weight_hh=
-00013830: 665f 6868 5f77 2c0a 2020 2020 2020 2020  f_hh_w,.        
-00013840: 2020 2020 2020 2020 2020 2020 2020 2077                 w
-00013850: 6569 6768 745f 6968 5f62 6163 6b3d 725f  eight_ih_back=r_
-00013860: 6968 5f77 2c0a 2020 2020 2020 2020 2020  ih_w,.          
-00013870: 2020 2020 2020 2020 2020 2020 2077 6569               wei
-00013880: 6768 745f 6868 5f62 6163 6b3d 725f 6868  ght_hh_back=r_hh
-00013890: 5f77 2c0a 2020 2020 2020 2020 2020 2020  _w,.            
-000138a0: 2020 2020 2020 2020 2020 2062 6961 733d             bias=
-000138b0: 2866 5f62 2069 6620 6861 735f 6269 6173  (f_b if has_bias
-000138c0: 2065 6c73 6520 4e6f 6e65 292c 0a20 2020   else None),.   
-000138d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000138e0: 2020 2020 6269 6173 5f62 6163 6b3d 2872      bias_back=(r
-000138f0: 5f62 2069 6620 6861 735f 6269 6173 2065  _b if has_bias e
-00013900: 6c73 6520 4e6f 6e65 292c 0a20 2020 2020  lse None),.     
-00013910: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013920: 2020 6469 7265 6374 696f 6e3d 2262 6964    direction="bid
-00013930: 6972 6563 7469 6f6e 616c 222c 0a20 2020  irectional",.   
-00013940: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013950: 2020 2020 6f75 7470 7574 5f73 6571 7565      output_seque
-00013960: 6e63 653d 5472 7565 2c0a 2020 2020 2020  nce=True,.      
-00013970: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013980: 206e 616d 653d 6e61 6d65 290a 2020 2020   name=name).    
-00013990: 656c 7365 3a0a 2020 2020 2020 2020 6966  else:.        if
-000139a0: 2068 6173 5f62 6961 733a 0a20 2020 2020   has_bias:.     
-000139b0: 2020 2020 2020 2023 2028 312e 290a 2020         # (1.).  
-000139c0: 2020 2020 2020 2020 2020 6269 6173 6573            biases
-000139d0: 203d 2077 6569 6768 7473 5b6c 656e 2877   = weights[len(w
-000139e0: 6569 6768 7473 2920 2f2f 2032 3a5d 0a20  eights) // 2:]. 
-000139f0: 2020 2020 2020 2020 2020 2077 6569 6768             weigh
-00013a00: 7473 203d 2077 6569 6768 7473 5b3a 206c  ts = weights[: l
-00013a10: 656e 2877 6569 6768 7473 2920 2f2f 2032  en(weights) // 2
-00013a20: 5d0a 2020 2020 2020 2020 2020 2020 2320  ].            # 
-00013a30: 2832 2e29 0a20 2020 2020 2020 2020 2020  (2.).           
-00013a40: 2062 203d 206d 622e 6164 6428 783d 6269   b = mb.add(x=bi
-00013a50: 6173 6573 5b30 5d2c 2079 3d62 6961 7365  ases[0], y=biase
-00013a60: 735b 315d 2c20 290a 2020 2020 2020 2020  s[1], ).        
-00013a70: 2020 2020 6220 3d20 5f69 667a 6f5f 746f      b = _ifzo_to
-00013a80: 5f69 666f 7a28 0a20 2020 2020 2020 2020  _ifoz(.         
-00013a90: 2020 2020 2020 2062 2c20 6e61 6d65 3d6e         b, name=n
-00013aa0: 616d 6520 2b20 225f 6c73 746d 5f62 6961  ame + "_lstm_bia
-00013ab0: 735f 7472 616e 7366 6f72 6d65 6422 2c0a  s_transformed",.
-00013ac0: 2020 2020 2020 2020 2020 2020 290a 2020              ).  
-00013ad0: 2020 2020 2020 2320 2833 2e29 0a20 2020        # (3.).   
-00013ae0: 2020 2020 2066 5f69 685f 7720 3d20 5f69       f_ih_w = _i
-00013af0: 667a 6f5f 746f 5f69 666f 7a28 0a20 2020  fzo_to_ifoz(.   
-00013b00: 2020 2020 2020 2020 2077 6569 6768 7473           weights
-00013b10: 5b30 5d2c 206e 616d 653d 6e61 6d65 202b  [0], name=name +
-00013b20: 2022 5f6c 7374 6d5f 6968 5f77 6569 6768   "_lstm_ih_weigh
-00013b30: 7473 5f69 666f 7a5f 746f 5f69 667a 6f22  ts_ifoz_to_ifzo"
-00013b40: 2c0a 2020 2020 2020 2020 290a 2020 2020  ,.        ).    
-00013b50: 2020 2020 665f 6868 5f77 203d 205f 6966      f_hh_w = _if
-00013b60: 7a6f 5f74 6f5f 6966 6f7a 280a 2020 2020  zo_to_ifoz(.    
-00013b70: 2020 2020 2020 2020 7765 6967 6874 735b          weights[
-00013b80: 315d 2c20 6e61 6d65 3d6e 616d 6520 2b20  1], name=name + 
-00013b90: 225f 6c73 746d 5f68 685f 7765 6967 6874  "_lstm_hh_weight
-00013ba0: 735f 6966 6f7a 5f74 6f5f 6966 7a6f 222c  s_ifoz_to_ifzo",
-00013bb0: 0a20 2020 2020 2020 2029 0a0a 2020 2020  .        )..    
-00013bc0: 2020 2020 6820 3d20 6d62 2e73 7175 6565      h = mb.squee
-00013bd0: 7a65 2878 3d69 6e69 7469 616c 5f68 2c20  ze(x=initial_h, 
-00013be0: 6178 6573 3d5f 6e70 2e61 7272 6179 285b  axes=_np.array([
-00013bf0: 305d 292c 206e 616d 653d 6e61 6d65 202b  0]), name=name +
-00013c00: 2022 5f6c 7374 6d5f 6830 5f73 7175 6565   "_lstm_h0_squee
-00013c10: 7a65 2229 0a20 2020 2020 2020 2063 203d  ze").        c =
-00013c20: 206d 622e 7371 7565 657a 6528 783d 696e   mb.squeeze(x=in
-00013c30: 6974 6961 6c5f 632c 2061 7865 733d 5f6e  itial_c, axes=_n
-00013c40: 702e 6172 7261 7928 5b30 5d29 2c20 6e61  p.array([0]), na
-00013c50: 6d65 3d6e 616d 6520 2b20 225f 6c73 746d  me=name + "_lstm
-00013c60: 5f63 305f 7371 7565 657a 6522 290a 0a20  _c0_squeeze").. 
-00013c70: 2020 2020 2020 2072 6574 7572 6e20 6d62         return mb
-00013c80: 2e6c 7374 6d28 783d 696e 7075 742c 0a20  .lstm(x=input,. 
-00013c90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013ca0: 2020 2020 2020 696e 6974 6961 6c5f 683d        initial_h=
-00013cb0: 682c 0a20 2020 2020 2020 2020 2020 2020  h,.             
-00013cc0: 2020 2020 2020 2020 2020 696e 6974 6961            initia
-00013cd0: 6c5f 633d 632c 0a20 2020 2020 2020 2020  l_c=c,.         
-00013ce0: 2020 2020 2020 2020 2020 2020 2020 7765                we
-00013cf0: 6967 6874 5f69 683d 665f 6968 5f77 2c0a  ight_ih=f_ih_w,.
-00013d00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013d10: 2020 2020 2020 2077 6569 6768 745f 6868         weight_hh
-00013d20: 3d66 5f68 685f 772c 0a20 2020 2020 2020  =f_hh_w,.       
-00013d30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013d40: 6269 6173 3d28 6220 6966 2068 6173 5f62  bias=(b if has_b
-00013d50: 6961 7320 656c 7365 204e 6f6e 6529 2c0a  ias else None),.
-00013d60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013d70: 2020 2020 2020 2064 6972 6563 7469 6f6e         direction
-00013d80: 3d22 666f 7277 6172 6422 2c0a 2020 2020  ="forward",.    
-00013d90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013da0: 2020 206f 7574 7075 745f 7365 7175 656e     output_sequen
-00013db0: 6365 3d54 7275 652c 0a20 2020 2020 2020  ce=True,.       
-00013dc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013dd0: 6e61 6d65 3d6e 616d 6529 0a0a 0a40 7265  name=name)...@re
-00013de0: 6769 7374 6572 5f74 6f72 6368 5f6f 700a  gister_torch_op.
-00013df0: 6465 6620 6c73 746d 2863 6f6e 7465 7874  def lstm(context
-00013e00: 2c20 6e6f 6465 293a 0a20 2020 2069 6e70  , node):.    inp
-00013e10: 7574 7320 3d20 5f67 6574 5f69 6e70 7574  uts = _get_input
-00013e20: 7328 636f 6e74 6578 742c 206e 6f64 652c  s(context, node,
-00013e30: 2065 7870 6563 7465 643d 3929 0a0a 2020   expected=9)..  
-00013e40: 2020 5f69 6e70 7574 203d 2069 6e70 7574    _input = input
-00013e50: 735b 305d 0a0a 2020 2020 2320 7468 6572  s[0]..    # ther
-00013e60: 6520 6172 6520 7477 6f20 6361 7365 7320  e are two cases 
-00013e70: 6865 7265 2c0a 2020 2020 2320 2831 2920  here,.    # (1) 
-00013e80: 7468 6520 696e 7075 7420 7465 6e73 6f72  the input tensor
-00013e90: 2069 7320 6120 5061 636b 6564 5365 7175   is a PackedSequ
-00013ea0: 656e 6365 206f 626a 6563 742c 0a20 2020  ence object,.   
-00013eb0: 2023 2069 6e20 7468 6973 2063 6173 652c   # in this case,
-00013ec0: 2074 6865 2073 6563 6f6e 6420 696e 7075   the second inpu
-00013ed0: 7420 6f66 2074 6865 206c 7374 6d20 6c61  t of the lstm la
-00013ee0: 7965 7220 6973 2074 6865 2062 6174 6368  yer is the batch
-00013ef0: 5f73 697a 6520 284d 494c 2056 6172 292e  _size (MIL Var).
-00013f00: 0a20 2020 2023 2028 3229 2074 6865 2069  .    # (2) the i
-00013f10: 6e70 7574 2074 656e 736f 7220 6973 2061  nput tensor is a
-00013f20: 206e 6f72 6d61 6c20 7465 6e73 6f72 2c0a   normal tensor,.
-00013f30: 2020 2020 2320 696e 2074 6869 7320 6361      # in this ca
-00013f40: 7365 2c20 7468 6520 7365 636f 6e64 2069  se, the second i
-00013f50: 6e70 7574 2069 7320 616e 2061 7272 6179  nput is an array
-00013f60: 2e0a 2020 2020 2320 4173 2074 6865 2072  ..    # As the r
-00013f70: 6573 756c 742c 2077 6520 6361 6e20 7573  esult, we can us
-00013f80: 6520 7468 6520 7365 636f 6e64 2069 6e70  e the second inp
-00013f90: 7574 2074 6f20 6964 656e 7469 6679 2077  ut to identify w
-00013fa0: 6869 6368 2063 6174 6567 6f72 7920 7468  hich category th
-00013fb0: 6520 6772 6170 6820 6973 2e0a 0a20 2020  e graph is...   
-00013fc0: 2068 6173 5f62 6174 6368 5f73 697a 6573   has_batch_sizes
-00013fd0: 203d 206e 6f74 2069 7369 6e73 7461 6e63   = not isinstanc
-00013fe0: 6528 696e 7075 7473 5b31 5d2c 2049 7465  e(inputs[1], Ite
-00013ff0: 7261 626c 6529 0a20 2020 2069 6620 6861  rable).    if ha
-00014000: 735f 6261 7463 685f 7369 7a65 733a 0a20  s_batch_sizes:. 
-00014010: 2020 2020 2020 2062 6174 6368 5f73 697a         batch_siz
-00014020: 6573 203d 2069 6e70 7574 735b 315d 0a20  es = inputs[1]. 
-00014030: 2020 2020 2020 2068 302c 2063 3020 3d20         h0, c0 = 
-00014040: 696e 7075 7473 5b32 5d0a 2020 2020 2020  inputs[2].      
-00014050: 2020 7765 6967 6874 735f 6c69 7374 203d    weights_list =
-00014060: 2069 6e70 7574 735b 335d 0a20 2020 2020   inputs[3].     
-00014070: 2020 2068 6173 5f62 6961 7320 3d20 696e     has_bias = in
-00014080: 7075 7473 5b34 5d2e 7661 6c0a 2020 2020  puts[4].val.    
-00014090: 2020 2020 6e75 6d5f 6c61 7965 7273 203d      num_layers =
-000140a0: 2069 6e70 7574 735b 355d 2e76 616c 0a20   inputs[5].val. 
-000140b0: 2020 2020 2020 2064 726f 706f 7574 203d         dropout =
-000140c0: 2069 6e70 7574 735b 365d 0a20 2020 2020   inputs[6].     
-000140d0: 2020 2062 6964 6972 6563 7469 6f6e 616c     bidirectional
-000140e0: 203d 2069 6e70 7574 735b 385d 2e76 616c   = inputs[8].val
-000140f0: 0a20 2020 2020 2020 2023 2074 6865 206f  .        # the o
-00014100: 7574 7075 7420 6f66 2074 6865 205f 7061  utput of the _pa
-00014110: 636b 5f70 6164 6465 645f 7365 7175 656e  ck_padded_sequen
-00014120: 6365 2069 7320 616c 7761 7973 2069 6e20  ce is always in 
-00014130: 7468 6520 6c61 796f 7574 206f 6620 6261  the layout of ba
-00014140: 7463 6820 6669 7273 740a 2020 2020 2020  tch first.      
-00014150: 2020 6261 7463 685f 6669 7273 7420 3d20    batch_first = 
-00014160: 5472 7565 0a20 2020 2065 6c73 653a 0a20  True.    else:. 
-00014170: 2020 2020 2020 2068 302c 2063 3020 3d20         h0, c0 = 
-00014180: 696e 7075 7473 5b31 5d0a 2020 2020 2020  inputs[1].      
-00014190: 2020 7765 6967 6874 735f 6c69 7374 203d    weights_list =
-000141a0: 2069 6e70 7574 735b 325d 0a20 2020 2020   inputs[2].     
-000141b0: 2020 2068 6173 5f62 6961 7320 3d20 696e     has_bias = in
-000141c0: 7075 7473 5b33 5d2e 7661 6c0a 2020 2020  puts[3].val.    
-000141d0: 2020 2020 6e75 6d5f 6c61 7965 7273 203d      num_layers =
-000141e0: 2069 6e70 7574 735b 345d 2e76 616c 0a20   inputs[4].val. 
-000141f0: 2020 2020 2020 2064 726f 706f 7574 203d         dropout =
-00014200: 2069 6e70 7574 735b 355d 0a20 2020 2020   inputs[5].     
-00014210: 2020 2062 6964 6972 6563 7469 6f6e 616c     bidirectional
-00014220: 203d 2069 6e70 7574 735b 375d 2e76 616c   = inputs[7].val
-00014230: 0a20 2020 2020 2020 2062 6174 6368 5f66  .        batch_f
-00014240: 6972 7374 203d 2069 6e70 7574 735b 385d  irst = inputs[8]
-00014250: 2e76 616c 0a0a 2020 2020 2727 270a 2020  .val..    '''.  
-00014260: 2020 546f 7263 6820 4c53 544d 206c 6179    Torch LSTM lay
-00014270: 6572 2773 2069 6e70 7574 2073 6861 7065  er's input shape
-00014280: 733a 0a0a 2020 2020 2831 2920 6669 7273  s:..    (1) firs
-00014290: 7420 696e 7075 740a 2020 2020 2020 2020  t input.        
-000142a0: 2853 6571 2c20 422c 2043 2920 3a20 6966  (Seq, B, C) : if
-000142b0: 2062 6174 6368 5f66 6972 7374 203d 2046   batch_first = F
-000142c0: 616c 7365 0a20 2020 2020 2020 2028 422c  alse.        (B,
-000142d0: 2053 6571 2c20 4329 203a 2069 6620 6261   Seq, C) : if ba
-000142e0: 7463 685f 6669 7273 7420 3d20 5472 7565  tch_first = True
-000142f0: 0a0a 2020 2020 2832 2920 2620 2833 2920  ..    (2) & (3) 
-00014300: 696e 6974 6961 6c69 7a61 7469 6f6e 2073  initialization s
-00014310: 7461 7465 730a 2020 2020 2020 2020 286e  tates.        (n
-00014320: 756d 5f6c 6179 6572 732c 2042 2c20 4829  um_layers, B, H)
-00014330: 203a 2069 6620 6269 6469 7265 6374 696f   : if bidirectio
-00014340: 6e61 6c20 3d20 4661 6c73 650a 2020 2020  nal = False.    
-00014350: 2020 2020 286e 756d 5f6c 6179 6572 7320      (num_layers 
-00014360: 2a20 322c 2042 2c20 4829 203a 2069 6620  * 2, B, H) : if 
-00014370: 6269 6469 7265 6374 696f 6e61 6c20 3d20  bidirectional = 
-00014380: 5472 7565 0a0a 0a20 2020 2046 6f72 2074  True...    For t
-00014390: 6865 204d 494c 204c 5354 4d20 6c61 7965  he MIL LSTM laye
-000143a0: 722c 2074 6865 7365 2061 7265 2074 6865  r, these are the
-000143b0: 2069 6e70 7574 2073 6861 7065 733a 0a0a   input shapes:..
-000143c0: 2020 2020 2831 2920 6669 7273 7420 696e      (1) first in
-000143d0: 7075 743a 2028 5365 712c 2042 2c20 4329  put: (Seq, B, C)
-000143e0: 0a20 2020 2020 2020 2020 2020 7468 6973  .           this
-000143f0: 206d 6561 6e73 2c20 6966 2062 6174 6368   means, if batch
-00014400: 5f66 6972 7374 3d54 7275 652c 2077 6520  _first=True, we 
-00014410: 6e65 6564 2074 6f20 696e 7365 7274 2061  need to insert a
-00014420: 2074 7261 6e73 706f 7365 206f 7020 6669   transpose op fi
-00014430: 7273 740a 0a20 2020 2028 3229 2026 2028  rst..    (2) & (
-00014440: 3329 2069 6e69 7469 616c 697a 6174 696f  3) initializatio
-00014450: 6e20 7374 6174 6573 0a20 2020 2020 2020  n states.       
-00014460: 204d 494c 2773 204c 5354 4d20 6c61 7965   MIL's LSTM laye
-00014470: 7220 646f 6573 206e 6f74 206e 6174 6976  r does not nativ
-00014480: 656c 7920 7375 7070 6f72 7420 7468 6520  ely support the 
-00014490: 226e 756d 5f6c 6179 6572 7322 2070 6172  "num_layers" par
-000144a0: 616d 6574 6572 732e 0a20 2020 2020 2020  ameters..       
-000144b0: 2053 6f2c 2077 6865 6e20 6e75 6d5f 6c61   So, when num_la
-000144c0: 7965 7273 203e 2031 2c20 7765 2061 6464  yers > 1, we add
-000144d0: 206d 756c 7469 706c 6520 4d49 4c20 4c53   multiple MIL LS
-000144e0: 544d 206f 7073 2069 6e20 6120 7365 7175  TM ops in a sequ
-000144f0: 656e 6365 2e0a 2020 2020 2020 2020 4561  ence..        Ea
-00014500: 6368 206f 6620 7468 6573 6520 4c53 544d  ch of these LSTM
-00014510: 206f 7073 2077 696c 6c20 7461 6b65 2069   ops will take i
-00014520: 6e20 696e 6974 6961 6c69 7a61 7469 6f6e  n initialization
-00014530: 2073 7461 7465 7320 696e 2074 6865 2066   states in the f
-00014540: 6f6c 6c6f 7769 6e67 2073 6861 7065 3a0a  ollowing shape:.
-00014550: 2020 2020 2020 2020 2842 2c20 4829 2069          (B, H) i
-00014560: 6620 6269 6469 7265 6374 696f 6e61 6c20  f bidirectional 
-00014570: 3d20 4661 6c73 650a 2020 2020 2020 2020  = False.        
-00014580: 2842 2c20 322a 4829 2069 6620 6269 6469  (B, 2*H) if bidi
-00014590: 7265 6374 696f 6e61 6c20 3d20 5472 7565  rectional = True
-000145a0: 0a20 2020 2027 2727 0a0a 2020 2020 6966  .    '''..    if
-000145b0: 2062 6174 6368 5f66 6972 7374 3a0a 2020   batch_first:.  
-000145c0: 2020 2020 2020 5f69 6e70 7574 203d 206d        _input = m
-000145d0: 622e 7472 616e 7370 6f73 6528 783d 5f69  b.transpose(x=_i
-000145e0: 6e70 7574 2c20 7065 726d 3d5b 312c 2030  nput, perm=[1, 0
-000145f0: 2c20 325d 2c20 6e61 6d65 3d5f 696e 7075  , 2], name=_inpu
-00014600: 742e 6e61 6d65 202b 2022 5f62 6174 6368  t.name + "_batch
-00014610: 5f66 6972 7374 5f74 7261 6e73 706f 7365  _first_transpose
-00014620: 2229 0a0a 2020 2020 6578 7065 6374 6564  ")..    expected
-00014630: 5f6e 756d 5f77 6569 6768 7473 203d 2032  _num_weights = 2
-00014640: 202a 206e 756d 5f6c 6179 6572 7320 2a20   * num_layers * 
-00014650: 2869 6e74 2862 6964 6972 6563 7469 6f6e  (int(bidirection
-00014660: 616c 2920 2b20 3129 202a 2028 696e 7428  al) + 1) * (int(
-00014670: 6861 735f 6269 6173 2920 2b20 3129 0a20  has_bias) + 1). 
-00014680: 2020 2069 6620 6c65 6e28 7765 6967 6874     if len(weight
-00014690: 735f 6c69 7374 2920 213d 2065 7870 6563  s_list) != expec
-000146a0: 7465 645f 6e75 6d5f 7765 6967 6874 733a  ted_num_weights:
-000146b0: 0a20 2020 2020 2020 2072 6169 7365 2056  .        raise V
-000146c0: 616c 7565 4572 726f 7228 0a20 2020 2020  alueError(.     
-000146d0: 2020 2020 2020 2022 496e 636f 7272 6563         "Incorrec
-000146e0: 7420 7765 6967 6874 7320 7368 6170 6520  t weights shape 
-000146f0: 666f 7220 6c73 746d 206c 6179 6572 3a20  for lstm layer: 
-00014700: 4578 7065 6374 6564 3a20 7b7d 2e20 5265  Expected: {}. Re
-00014710: 6369 6576 6564 207b 7d22 2e66 6f72 6d61  cieved {}".forma
-00014720: 7428 0a20 2020 2020 2020 2020 2020 2020  t(.             
-00014730: 2020 2065 7870 6563 7465 645f 6e75 6d5f     expected_num_
-00014740: 7765 6967 6874 732c 206c 656e 2877 6569  weights, len(wei
-00014750: 6768 7473 5f6c 6973 7429 0a20 2020 2020  ghts_list).     
-00014760: 2020 2020 2020 2029 0a20 2020 2020 2020         ).       
-00014770: 2029 0a0a 2020 2020 2320 7368 6170 6520   )..    # shape 
-00014780: 6f66 2068 3020 616e 6420 6330 2061 7265  of h0 and c0 are
-00014790: 2028 6e75 6d5f 6c61 7965 7273 202a 206e   (num_layers * n
-000147a0: 5f64 6972 6563 7469 6f6e 732c 2042 2c20  _directions, B, 
-000147b0: 4829 0a20 2020 2069 6620 6e75 6d5f 6c61  H).    if num_la
-000147c0: 7965 7273 203d 3d20 313a 0a20 2020 2020  yers == 1:.     
-000147d0: 2020 2061 6c6c 5f69 6e69 7469 616c 5f68     all_initial_h
-000147e0: 203d 205b 6830 5d20 2023 205b 286e 5f64   = [h0]  # [(n_d
-000147f0: 6972 6563 7469 6f6e 732c 2042 2c20 4829  irections, B, H)
-00014800: 5d0a 2020 2020 2020 2020 616c 6c5f 696e  ].        all_in
-00014810: 6974 6961 6c5f 6320 3d20 5b63 305d 2020  itial_c = [c0]  
-00014820: 2320 5b28 6e5f 6469 7265 6374 696f 6e73  # [(n_directions
-00014830: 2c20 422c 2048 295d 0a20 2020 2065 6c73  , B, H)].    els
-00014840: 653a 0a20 2020 2020 2020 2061 6c6c 5f69  e:.        all_i
-00014850: 6e69 7469 616c 5f68 203d 206d 622e 7370  nitial_h = mb.sp
-00014860: 6c69 7428 0a20 2020 2020 2020 2020 2020  lit(.           
-00014870: 2078 3d68 302c 206e 756d 5f73 706c 6974   x=h0, num_split
-00014880: 733d 6e75 6d5f 6c61 7965 7273 2c20 6178  s=num_layers, ax
-00014890: 6973 3d30 0a20 2020 2020 2020 2029 2020  is=0.        )  
-000148a0: 2320 5b28 6e5f 6469 7265 6374 696f 6e73  # [(n_directions
-000148b0: 2c20 422c 2048 295d 0a20 2020 2020 2020  , B, H)].       
-000148c0: 2061 6c6c 5f69 6e69 7469 616c 5f63 203d   all_initial_c =
-000148d0: 206d 622e 7370 6c69 7428 0a20 2020 2020   mb.split(.     
-000148e0: 2020 2020 2020 2078 3d63 302c 206e 756d         x=c0, num
-000148f0: 5f73 706c 6974 733d 6e75 6d5f 6c61 7965  _splits=num_laye
-00014900: 7273 2c20 6178 6973 3d30 0a20 2020 2020  rs, axis=0.     
-00014910: 2020 2029 2020 2320 5b28 6e5f 6469 7265     )  # [(n_dire
-00014920: 6374 696f 6e73 2c20 422c 2048 295d 0a0a  ctions, B, H)]..
-00014930: 2020 2020 6e5f 7765 6967 6874 735f 7065      n_weights_pe
-00014940: 725f 6c61 7965 7220 3d20 696e 7428 6c65  r_layer = int(le
-00014950: 6e28 7765 6967 6874 735f 6c69 7374 2920  n(weights_list) 
-00014960: 2f20 6e75 6d5f 6c61 7965 7273 290a 2020  / num_layers).  
-00014970: 2020 7820 3d20 5f69 6e70 7574 0a20 2020    x = _input.   
-00014980: 2068 5f6f 7574 5f6c 6973 7420 3d20 5b5d   h_out_list = []
-00014990: 0a20 2020 2063 5f6f 7574 5f6c 6973 7420  .    c_out_list 
-000149a0: 3d20 5b5d 0a20 2020 2066 6f72 2069 2069  = [].    for i i
-000149b0: 6e20 7261 6e67 6528 6e75 6d5f 6c61 7965  n range(num_laye
-000149c0: 7273 293a 0a20 2020 2020 2020 2069 6620  rs):.        if 
-000149d0: 6920 3c20 6e75 6d5f 6c61 7965 7273 202d  i < num_layers -
-000149e0: 2031 3a0a 2020 2020 2020 2020 2020 2020   1:.            
-000149f0: 6f70 5f6e 616d 6520 3d20 6e6f 6465 2e6e  op_name = node.n
-00014a00: 616d 6520 2b20 225f 6c73 746d 5f6c 6179  ame + "_lstm_lay
-00014a10: 6572 5f7b 7d22 2e66 6f72 6d61 7428 6929  er_{}".format(i)
-00014a20: 0a20 2020 2020 2020 2065 6c73 653a 0a20  .        else:. 
-00014a30: 2020 2020 2020 2020 2020 2069 6620 6261             if ba
-00014a40: 7463 685f 6669 7273 743a 0a20 2020 2020  tch_first:.     
-00014a50: 2020 2020 2020 2020 2020 206f 705f 6e61             op_na
-00014a60: 6d65 203d 206e 6f64 652e 6e61 6d65 202b  me = node.name +
-00014a70: 2022 5f62 6174 6368 5f66 6972 7374 220a   "_batch_first".
-00014a80: 2020 2020 2020 2020 2020 2020 656c 7365              else
-00014a90: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00014aa0: 2020 6f70 5f6e 616d 6520 3d20 6e6f 6465    op_name = node
-00014ab0: 2e6e 616d 650a 0a20 2020 2020 2020 206c  .name..        l
-00014ac0: 7374 6d5f 6f75 7420 3d20 5f61 6464 5f6d  stm_out = _add_m
-00014ad0: 696c 5f6c 7374 6d28 0a20 2020 2020 2020  il_lstm(.       
-00014ae0: 2020 2020 2069 6e70 7574 3d78 2c0a 2020       input=x,.  
-00014af0: 2020 2020 2020 2020 2020 696e 6974 6961            initia
-00014b00: 6c5f 683d 616c 6c5f 696e 6974 6961 6c5f  l_h=all_initial_
-00014b10: 685b 695d 2c0a 2020 2020 2020 2020 2020  h[i],.          
-00014b20: 2020 696e 6974 6961 6c5f 633d 616c 6c5f    initial_c=all_
-00014b30: 696e 6974 6961 6c5f 635b 695d 2c0a 2020  initial_c[i],.  
-00014b40: 2020 2020 2020 2020 2020 7765 6967 6874            weight
-00014b50: 733d 7765 6967 6874 735f 6c69 7374 5b0a  s=weights_list[.
-00014b60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00014b70: 6920 2a20 6e5f 7765 6967 6874 735f 7065  i * n_weights_pe
-00014b80: 725f 6c61 7965 7220 3a20 2869 202b 2031  r_layer : (i + 1
-00014b90: 2920 2a20 6e5f 7765 6967 6874 735f 7065  ) * n_weights_pe
-00014ba0: 725f 6c61 7965 720a 2020 2020 2020 2020  r_layer.        
-00014bb0: 2020 2020 5d2c 0a20 2020 2020 2020 2020      ],.         
-00014bc0: 2020 2068 6173 5f62 6961 733d 6861 735f     has_bias=has_
-00014bd0: 6269 6173 2c0a 2020 2020 2020 2020 2020  bias,.          
-00014be0: 2020 6269 6469 7265 6374 696f 6e61 6c3d    bidirectional=
-00014bf0: 6269 6469 7265 6374 696f 6e61 6c2c 0a20  bidirectional,. 
-00014c00: 2020 2020 2020 2020 2020 206e 616d 653d             name=
-00014c10: 6f70 5f6e 616d 652c 0a20 2020 2020 2020  op_name,.       
-00014c20: 2029 0a20 2020 2020 2020 2023 2073 6861   ).        # sha
-00014c30: 7065 206f 6620 6c73 746d 5f6f 7574 5b30  pe of lstm_out[0
-00014c40: 5d20 3d3d 2028 532c 422c 4829 2069 6620  ] == (S,B,H) if 
-00014c50: 6269 6469 7265 6374 696f 6e61 6c20 3d20  bidirectional = 
-00014c60: 5472 7565 2065 6c73 6520 2853 2c20 422c  True else (S, B,
-00014c70: 2032 2a48 290a 2020 2020 2020 2020 7820   2*H).        x 
-00014c80: 3d20 6c73 746d 5f6f 7574 5b30 5d0a 2020  = lstm_out[0].  
-00014c90: 2020 2020 2020 2320 7368 6170 6520 6f66        # shape of
-00014ca0: 206c 7374 6d5f 6f75 745b 315d 203d 3d20   lstm_out[1] == 
-00014cb0: 2842 2c48 2920 6966 2062 6964 6972 6563  (B,H) if bidirec
-00014cc0: 7469 6f6e 616c 203d 2046 616c 7365 2065  tional = False e
-00014cd0: 6c73 6520 2842 2c20 322a 4829 0a20 2020  lse (B, 2*H).   
-00014ce0: 2020 2020 2068 5f6f 7574 5f6c 6973 742e       h_out_list.
-00014cf0: 6170 7065 6e64 286c 7374 6d5f 6f75 745b  append(lstm_out[
-00014d00: 315d 290a 2020 2020 2020 2020 2320 7368  1]).        # sh
-00014d10: 6170 6520 6f66 206c 7374 6d5f 6f75 745b  ape of lstm_out[
-00014d20: 325d 203d 3d20 2842 2c48 2920 6966 2062  2] == (B,H) if b
-00014d30: 6964 6972 6563 7469 6f6e 616c 203d 2046  idirectional = F
-00014d40: 616c 7365 2065 6c73 6520 2842 2c20 322a  alse else (B, 2*
-00014d50: 4829 0a20 2020 2020 2020 2063 5f6f 7574  H).        c_out
-00014d60: 5f6c 6973 742e 6170 7065 6e64 286c 7374  _list.append(lst
-00014d70: 6d5f 6f75 745b 325d 290a 0a20 2020 2027  m_out[2])..    '
-00014d80: 2727 0a20 2020 2046 6f72 2074 6f72 6368  ''.    For torch
-00014d90: 2c20 7468 6573 6520 6172 6520 7468 6520  , these are the 
-00014da0: 6469 6d65 6e73 696f 6e73 206f 6620 7468  dimensions of th
-00014db0: 6520 3320 6f75 7470 7574 2074 656e 736f  e 3 output tenso
-00014dc0: 7273 3a0a 2020 2020 2831 2920 6f75 7470  rs:.    (1) outp
-00014dd0: 7574 5b30 5d20 3a0a 2020 2020 2020 2020  ut[0] :.        
-00014de0: 2020 2020 2853 6571 2c20 422c 2048 2920      (Seq, B, H) 
-00014df0: 6966 2062 6174 6368 5f66 6972 7374 203d  if batch_first =
-00014e00: 2046 616c 7365 2c20 6269 6469 7265 6374   False, bidirect
-00014e10: 696f 6e61 6c20 3d20 4661 6c73 650a 2020  ional = False.  
-00014e20: 2020 2020 2020 2020 2020 2853 6571 2c20            (Seq, 
-00014e30: 422c 2032 2a48 2920 6966 2062 6174 6368  B, 2*H) if batch
-00014e40: 5f66 6972 7374 203d 2046 616c 7365 2c20  _first = False, 
-00014e50: 6269 6469 7265 6374 696f 6e61 6c20 3d20  bidirectional = 
-00014e60: 5472 7565 0a20 2020 2020 2020 2020 2020  True.           
-00014e70: 2028 422c 2053 6571 2c20 4829 2069 6620   (B, Seq, H) if 
-00014e80: 6261 7463 685f 6669 7273 7420 3d20 5472  batch_first = Tr
-00014e90: 7565 2c20 6269 6469 7265 6374 696f 6e61  ue, bidirectiona
-00014ea0: 6c20 3d20 4661 6c73 650a 2020 2020 2020  l = False.      
-00014eb0: 2020 2020 2020 2842 2c20 5365 712c 2032        (B, Seq, 2
-00014ec0: 2a48 2920 6966 2062 6174 6368 5f66 6972  *H) if batch_fir
-00014ed0: 7374 203d 2054 7275 652c 2062 6964 6972  st = True, bidir
-00014ee0: 6563 7469 6f6e 616c 203d 2054 7275 650a  ectional = True.
-00014ef0: 0a20 2020 2028 3229 2026 2028 3329 2074  .    (2) & (3) t
-00014f00: 6865 7365 2061 7265 2074 6865 2073 7461  hese are the sta
-00014f10: 7465 206f 7574 7075 7473 3a0a 2020 2020  te outputs:.    
-00014f20: 2020 2020 2020 2020 286e 756d 5f6c 6179          (num_lay
-00014f30: 6572 732c 2042 2c20 4829 2069 6620 6269  ers, B, H) if bi
-00014f40: 6469 7265 6374 696f 6e61 6c20 3d20 4661  directional = Fa
-00014f50: 6c73 650a 2020 2020 2020 2020 2020 2020  lse.            
-00014f60: 286e 756d 5f6c 6179 6572 7320 2a20 322c  (num_layers * 2,
-00014f70: 2042 2c20 4829 2069 6620 6269 6469 7265   B, H) if bidire
-00014f80: 6374 696f 6e61 6c20 3d20 5472 7565 0a0a  ctional = True..
-00014f90: 2020 2020 4d49 4c20 6c73 746d 206c 6179      MIL lstm lay
-00014fa0: 6572 2773 206f 7574 7075 7420 7368 6170  er's output shap
-00014fb0: 6573 3a0a 2020 2020 2831 2920 6f75 7470  es:.    (1) outp
-00014fc0: 7574 5b30 5d3a 0a20 2020 2020 2020 2028  ut[0]:.        (
-00014fd0: 5365 712c 2042 2c20 4829 2069 6620 6269  Seq, B, H) if bi
-00014fe0: 6469 7265 6374 696f 6e61 6c20 3d20 4661  directional = Fa
-00014ff0: 6c73 650a 2020 2020 2020 2020 2853 6571  lse.        (Seq
-00015000: 2c20 422c 2032 2a48 2920 6966 2062 6964  , B, 2*H) if bid
-00015010: 6972 6563 7469 6f6e 616c 203d 2054 7275  irectional = Tru
-00015020: 650a 2020 2020 2020 2020 5468 6973 206d  e.        This m
-00015030: 6561 6e73 2077 6520 6e65 6564 2061 2074  eans we need a t
-00015040: 7261 6e73 706f 7365 206f 7020 6966 2062  ranspose op if b
-00015050: 6174 6368 5f66 6972 7374 2069 7320 5472  atch_first is Tr
-00015060: 7565 0a0a 2020 2020 2832 2920 2620 2833  ue..    (2) & (3
-00015070: 2920 7368 6170 6573 206f 6620 7468 6520  ) shapes of the 
-00015080: 7374 6174 6520 6f75 7470 7574 733a 0a20  state outputs:. 
-00015090: 2020 2020 2020 2065 6163 6820 4d49 4c20         each MIL 
-000150a0: 4c53 544d 206f 7020 7769 6c6c 2070 726f  LSTM op will pro
-000150b0: 6475 6365 2066 696e 616c 2073 7461 7465  duce final state
-000150c0: 2074 656e 736f 7273 2077 6974 6820 7468   tensors with th
-000150d0: 6520 666f 6c6c 6f77 696e 6720 7368 6170  e following shap
-000150e0: 653a 0a20 2020 2020 2020 2028 422c 2048  e:.        (B, H
-000150f0: 2920 6966 2062 6964 6972 6563 7469 6f6e  ) if bidirection
-00015100: 616c 203d 2046 616c 7365 0a20 2020 2020  al = False.     
-00015110: 2020 2028 422c 2032 2a48 2920 6966 2062     (B, 2*H) if b
-00015120: 6964 6972 6563 7469 6f6e 616c 203d 2054  idirectional = T
-00015130: 7275 650a 0a20 2020 2020 2020 2073 7461  rue..        sta
-00015140: 636b 2f65 7870 616e 6420 7468 6520 6669  ck/expand the fi
-00015150: 6e61 6c20 7374 6174 6520 7465 6e73 6f72  nal state tensor
-00015160: 7320 746f 206d 6174 6368 2074 6865 2054  s to match the T
-00015170: 6f72 6368 206f 7574 7075 740a 2020 2020  orch output.    
-00015180: 2727 270a 2020 2020 666f 7220 696e 6465  '''.    for inde
-00015190: 782c 2028 6e61 6d65 2c20 6f75 7470 7574  x, (name, output
-000151a0: 2920 696e 2065 6e75 6d65 7261 7465 287a  ) in enumerate(z
-000151b0: 6970 286e 6f64 652e 6f75 7470 7574 732c  ip(node.outputs,
-000151c0: 206c 7374 6d5f 6f75 7429 293a 0a20 2020   lstm_out)):.   
-000151d0: 2020 2020 2069 6620 696e 6465 7820 3e20       if index > 
-000151e0: 303a 0a20 2020 2020 2020 2020 2020 2023  0:.            #
-000151f0: 2069 6e64 6578 203e 2030 203d 3d3d 3e20   index > 0 ===> 
-00015200: 6974 7320 6f6e 6520 6f66 2074 6865 2073  its one of the s
-00015210: 7461 7465 206f 7574 7075 7473 2028 6820  tate outputs (h 
-00015220: 6f72 2063 290a 2020 2020 2020 2020 2020  or c).          
-00015230: 2020 6966 2062 6964 6972 6563 7469 6f6e    if bidirection
-00015240: 616c 3a0a 2020 2020 2020 2020 2020 2020  al:.            
-00015250: 2020 2020 6966 206e 756d 5f6c 6179 6572      if num_layer
-00015260: 7320 3d3d 2031 3a0a 2020 2020 2020 2020  s == 1:.        
-00015270: 2020 2020 2020 2020 2020 2020 6f75 7431              out1
-00015280: 2c20 6f75 7432 203d 206d 622e 7370 6c69  , out2 = mb.spli
-00015290: 7428 0a20 2020 2020 2020 2020 2020 2020  t(.             
-000152a0: 2020 2020 2020 2020 2020 2078 3d6f 7574             x=out
-000152b0: 7075 742c 206e 756d 5f73 706c 6974 733d  put, num_splits=
-000152c0: 322c 2061 7869 733d 310a 2020 2020 2020  2, axis=1.      
-000152d0: 2020 2020 2020 2020 2020 2020 2020 2920                ) 
-000152e0: 2023 2065 6163 6820 6f75 7470 7574 206f   # each output o
-000152f0: 6620 7368 6170 6520 5b42 2c20 485d 2061  f shape [B, H] a
-00015300: 6674 6572 2074 6865 2073 706c 6974 0a20  fter the split. 
-00015310: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015320: 2020 2066 696e 616c 5f6f 7574 203d 206d     final_out = m
-00015330: 622e 7374 6163 6b28 0a20 2020 2020 2020  b.stack(.       
-00015340: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015350: 2076 616c 7565 733d 5b6f 7574 312c 206f   values=[out1, o
-00015360: 7574 325d 2c20 6178 6973 3d30 2c20 6e61  ut2], axis=0, na
-00015370: 6d65 3d6e 616d 650a 2020 2020 2020 2020  me=name.        
-00015380: 2020 2020 2020 2020 2020 2020 2920 2023              )  #
-00015390: 205b 322c 2042 2c20 485d 0a20 2020 2020   [2, B, H].     
-000153a0: 2020 2020 2020 2020 2020 2020 2020 2063                 c
-000153b0: 6f6e 7465 7874 2e61 6464 2866 696e 616c  ontext.add(final
-000153c0: 5f6f 7574 2c20 6e61 6d65 290a 2020 2020  _out, name).    
-000153d0: 2020 2020 2020 2020 2020 2020 656c 7365              else
-000153e0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-000153f0: 2020 2020 2020 6f75 745f 7374 6174 655f        out_state_
-00015400: 7465 6e73 6f72 735f 6c69 7374 203d 2028  tensors_list = (
-00015410: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00015420: 2020 2020 2020 2020 2068 5f6f 7574 5f6c           h_out_l
-00015430: 6973 7420 6966 2069 6e64 6578 203d 3d20  ist if index == 
-00015440: 3120 656c 7365 2063 5f6f 7574 5f6c 6973  1 else c_out_lis
-00015450: 740a 2020 2020 2020 2020 2020 2020 2020  t.              
-00015460: 2020 2020 2020 2920 2023 2065 6163 6820        )  # each 
-00015470: 7465 6e73 6f72 2069 6e20 7468 6520 6c69  tensor in the li
-00015480: 7374 2069 7320 6f66 2073 6861 7065 2028  st is of shape (
-00015490: 422c 2032 2a48 290a 2020 2020 2020 2020  B, 2*H).        
-000154a0: 2020 2020 2020 2020 2020 2020 6c69 7374              list
-000154b0: 5f6f 665f 7465 6e73 6f72 735f 746f 5f73  _of_tensors_to_s
-000154c0: 7461 636b 203d 205b 5d0a 2020 2020 2020  tack = [].      
-000154d0: 2020 2020 2020 2020 2020 2020 2020 666f                fo
-000154e0: 7220 6920 696e 2072 616e 6765 286e 756d  r i in range(num
-000154f0: 5f6c 6179 6572 7329 3a0a 2020 2020 2020  _layers):.      
-00015500: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015510: 2020 6f75 7431 2c20 6f75 7432 203d 206d    out1, out2 = m
-00015520: 622e 7370 6c69 7428 0a20 2020 2020 2020  b.split(.       
-00015530: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015540: 2020 2020 2078 3d6f 7574 5f73 7461 7465       x=out_state
-00015550: 5f74 656e 736f 7273 5f6c 6973 745b 695d  _tensors_list[i]
-00015560: 2c20 6e75 6d5f 7370 6c69 7473 3d32 2c20  , num_splits=2, 
-00015570: 6178 6973 3d31 0a20 2020 2020 2020 2020  axis=1.         
-00015580: 2020 2020 2020 2020 2020 2020 2020 2029                 )
-00015590: 2020 2320 6561 6368 206f 7574 7075 7420    # each output 
-000155a0: 6f66 2073 6861 7065 205b 422c 2048 5d20  of shape [B, H] 
-000155b0: 6166 7465 7220 7468 6520 7370 6c69 740a  after the split.
-000155c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000155d0: 2020 2020 2020 2020 6f75 7420 3d20 6d62          out = mb
-000155e0: 2e73 7461 636b 2876 616c 7565 733d 5b6f  .stack(values=[o
-000155f0: 7574 312c 206f 7574 325d 2c20 6178 6973  ut1, out2], axis
-00015600: 3d30 2920 2023 205b 322c 2042 2c20 485d  =0)  # [2, B, H]
-00015610: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00015620: 2020 2020 2020 2020 206c 6973 745f 6f66           list_of
-00015630: 5f74 656e 736f 7273 5f74 6f5f 7374 6163  _tensors_to_stac
-00015640: 6b2e 6170 7065 6e64 286f 7574 290a 2020  k.append(out).  
-00015650: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015660: 2020 6669 6e61 6c5f 6f75 7420 3d20 6d62    final_out = mb
-00015670: 2e63 6f6e 6361 7428 0a20 2020 2020 2020  .concat(.       
-00015680: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015690: 2076 616c 7565 733d 6c69 7374 5f6f 665f   values=list_of_
-000156a0: 7465 6e73 6f72 735f 746f 5f73 7461 636b  tensors_to_stack
-000156b0: 2c20 6178 6973 3d30 2c20 6e61 6d65 3d6e  , axis=0, name=n
-000156c0: 616d 650a 2020 2020 2020 2020 2020 2020  ame.            
-000156d0: 2020 2020 2020 2020 2920 2023 206f 7574          )  # out
-000156e0: 7075 7420 6f66 2073 6861 7065 2028 6e75  put of shape (nu
-000156f0: 6d5f 6c61 7965 7273 202a 2032 2c20 422c  m_layers * 2, B,
-00015700: 2048 290a 2020 2020 2020 2020 2020 2020   H).            
-00015710: 2020 2020 2020 2020 636f 6e74 6578 742e          context.
-00015720: 6164 6428 6669 6e61 6c5f 6f75 742c 206e  add(final_out, n
-00015730: 616d 6529 0a20 2020 2020 2020 2020 2020  ame).           
-00015740: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
-00015750: 2020 2020 2020 2069 6620 6e75 6d5f 6c61         if num_la
-00015760: 7965 7273 203d 3d20 313a 0a20 2020 2020  yers == 1:.     
-00015770: 2020 2020 2020 2020 2020 2020 2020 2075                 u
-00015780: 6e73 7175 6565 7a65 203d 206d 622e 6578  nsqueeze = mb.ex
-00015790: 7061 6e64 5f64 696d 7328 783d 6f75 7470  pand_dims(x=outp
-000157a0: 7574 2c20 6178 6573 3d5b 305d 2c20 6e61  ut, axes=[0], na
-000157b0: 6d65 3d6e 616d 6529 0a20 2020 2020 2020  me=name).       
-000157c0: 2020 2020 2020 2020 2020 2020 2063 6f6e               con
-000157d0: 7465 7874 2e61 6464 2875 6e73 7175 6565  text.add(unsquee
-000157e0: 7a65 2c20 6e61 6d65 290a 2020 2020 2020  ze, name).      
-000157f0: 2020 2020 2020 2020 2020 656c 7365 3a0a            else:.
-00015800: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015810: 2020 2020 6f75 7420 3d20 6d62 2e73 7461      out = mb.sta
-00015820: 636b 280a 2020 2020 2020 2020 2020 2020  ck(.            
-00015830: 2020 2020 2020 2020 2020 2020 7661 6c75              valu
-00015840: 6573 3d68 5f6f 7574 5f6c 6973 7420 6966  es=h_out_list if
-00015850: 2069 6e64 6578 203d 3d20 3120 656c 7365   index == 1 else
-00015860: 2063 5f6f 7574 5f6c 6973 742c 0a20 2020   c_out_list,.   
-00015870: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015880: 2020 2020 2061 7869 733d 302c 0a20 2020       axis=0,.   
-00015890: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000158a0: 2020 2020 206e 616d 653d 6e61 6d65 2c0a       name=name,.
-000158b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000158c0: 2020 2020 290a 2020 2020 2020 2020 2020      ).          
-000158d0: 2020 2020 2020 2020 2020 636f 6e74 6578            contex
-000158e0: 742e 6164 6428 6f75 742c 206e 616d 6529  t.add(out, name)
-000158f0: 0a20 2020 2020 2020 2065 6c73 653a 0a20  .        else:. 
-00015900: 2020 2020 2020 2020 2020 2069 6620 6261             if ba
-00015910: 7463 685f 6669 7273 743a 0a20 2020 2020  tch_first:.     
-00015920: 2020 2020 2020 2020 2020 206f 7574 7075             outpu
-00015930: 7420 3d20 6d62 2e74 7261 6e73 706f 7365  t = mb.transpose
-00015940: 2878 3d6f 7574 7075 742c 2070 6572 6d3d  (x=output, perm=
-00015950: 5b31 2c20 302c 2032 5d2c 206e 616d 653d  [1, 0, 2], name=
-00015960: 6e61 6d65 290a 2020 2020 2020 2020 2020  name).          
-00015970: 2020 636f 6e74 6578 742e 6164 6428 6f75    context.add(ou
-00015980: 7470 7574 2c20 6e61 6d65 290a 0a0a 6465  tput, name)...de
-00015990: 6620 5f67 6574 5f73 6361 6c65 735f 6672  f _get_scales_fr
-000159a0: 6f6d 5f6f 7574 7075 745f 7369 7a65 286f  om_output_size(o
-000159b0: 7574 7075 745f 7369 7a65 2c20 696e 7075  utput_size, inpu
-000159c0: 745f 7368 6170 6529 3a0a 2020 2020 7363  t_shape):.    sc
-000159d0: 616c 6573 203d 205b 5d0a 2020 2020 6966  ales = [].    if
-000159e0: 206f 7574 7075 745f 7369 7a65 2069 7320   output_size is 
-000159f0: 6e6f 7420 4e6f 6e65 3a0a 2020 2020 2020  not None:.      
-00015a00: 2020 2320 6f75 7470 7574 5f73 697a 6520    # output_size 
-00015a10: 7769 6c6c 2062 6520 6569 7468 6572 0a20  will be either. 
-00015a20: 2020 2020 2020 2023 2028 3129 2041 206c         # (1) A l
-00015a30: 6973 7420 6f66 2056 6172 2c20 616e 6420  ist of Var, and 
-00015a40: 6561 6368 2056 6172 2069 6e64 6963 6174  each Var indicat
-00015a50: 6573 2074 6865 206f 7574 7075 7420 7369  es the output si
-00015a60: 7a65 2066 6f72 2074 6861 7420 6469 6d65  ze for that dime
-00015a70: 6e73 696f 6e0a 2020 2020 2020 2020 2320  nsion.        # 
-00015a80: 2832 2920 4120 7369 6e67 6c65 2056 6172  (2) A single Var
-00015a90: 2077 6869 6368 2069 6e64 6963 6174 6573   which indicates
-00015aa0: 2074 6865 2077 686f 6c65 206f 7574 7075   the whole outpu
-00015ab0: 7420 7369 7a65 0a20 2020 2020 2020 2023  t size.        #
-00015ac0: 2028 3329 2041 206e 756d 7079 2061 7272   (3) A numpy arr
-00015ad0: 6179 0a0a 2020 2020 2020 2020 6966 2069  ay..        if i
-00015ae0: 7369 6e73 7461 6e63 6528 6f75 7470 7574  sinstance(output
-00015af0: 5f73 697a 652c 206c 6973 7429 3a0a 2020  _size, list):.  
-00015b00: 2020 2020 2020 2020 2020 6f75 7470 7574            output
-00015b10: 5f73 697a 6520 3d20 5b78 2e76 616c 2066  _size = [x.val f
-00015b20: 6f72 2078 2069 6e20 6f75 7470 7574 5f73  or x in output_s
-00015b30: 697a 655d 0a20 2020 2020 2020 2069 6620  ize].        if 
-00015b40: 6973 696e 7374 616e 6365 286f 7574 7075  isinstance(outpu
-00015b50: 745f 7369 7a65 2c20 5661 7229 3a0a 2020  t_size, Var):.  
-00015b60: 2020 2020 2020 2020 2020 6f75 7470 7574            output
-00015b70: 5f73 697a 6520 3d20 5b78 2066 6f72 2078  _size = [x for x
-00015b80: 2069 6e20 6f75 7470 7574 5f73 697a 652e   in output_size.
-00015b90: 7661 6c5d 0a20 2020 2020 2020 2069 6620  val].        if 
-00015ba0: 6973 696e 7374 616e 6365 286f 7574 7075  isinstance(outpu
-00015bb0: 745f 7369 7a65 2c20 5f6e 702e 6e64 6172  t_size, _np.ndar
-00015bc0: 7261 7929 3a0a 2020 2020 2020 2020 2020  ray):.          
-00015bd0: 2020 6f75 7470 7574 5f73 697a 6520 3d20    output_size = 
-00015be0: 6f75 7470 7574 5f73 697a 652e 746f 6c69  output_size.toli
-00015bf0: 7374 2829 0a0a 2020 2020 2020 2020 2320  st()..        # 
-00015c00: 6f75 7470 7574 2073 697a 6520 6973 2063  output size is c
-00015c10: 6f6d 7075 7465 6420 7573 696e 6720 7468  omputed using th
-00015c20: 6520 666f 726d 756c 6120 666c 6f6f 7220  e formula floor 
-00015c30: 2873 6361 6c65 202a 2069 6e70 7574 5f73  (scale * input_s
-00015c40: 697a 6529 2069 6e20 436f 7265 204d 4c20  ize) in Core ML 
-00015c50: 2861 6e64 2050 7954 6f72 6368 292e 0a20  (and PyTorch).. 
-00015c60: 2020 2020 2020 2023 2054 6875 732c 2077         # Thus, w
-00015c70: 6865 6e20 636f 6d70 7574 696e 6720 7468  hen computing th
-00015c80: 6520 7363 616c 6573 2066 726f 6d20 7468  e scales from th
-00015c90: 6520 6f75 7470 7574 2073 697a 652c 2077  e output size, w
-00015ca0: 6520 6164 6420 6120 736d 616c 6c20 706f  e add a small po
-00015cb0: 7369 7469 7665 2063 6f6e 7374 616e 7420  sitive constant 
-00015cc0: 746f 2074 6865 206f 7574 7075 7420 7369  to the output si
-00015cd0: 7a65 0a20 2020 2020 2020 2023 2074 6f20  ze.        # to 
-00015ce0: 6d61 6b65 2073 7572 6520 7468 6174 2074  make sure that t
-00015cf0: 6865 2066 6c6f 6f72 2066 6f72 6d75 6c61  he floor formula
-00015d00: 2072 6573 756c 7473 2069 6e20 7468 6520   results in the 
-00015d10: 636f 7272 6563 7420 6f75 7470 7574 2073  correct output s
-00015d20: 697a 6520 616e 6420 6e6f 7420 3120 756e  ize and not 1 un
-00015d30: 6974 2073 6d61 6c6c 6572 2e0a 2020 2020  it smaller..    
-00015d40: 2020 2020 2320 466f 7220 696e 7374 616e      # For instan
-00015d50: 6365 2c20 6966 206f 7574 7075 7420 7369  ce, if output si
-00015d60: 7a65 203d 2035 2061 6e64 2069 6e70 7574  ze = 5 and input
-00015d70: 2073 697a 6520 3d20 322c 2074 6865 6e20   size = 2, then 
-00015d80: 7363 616c 6520 7769 6c6c 2062 6520 322e  scale will be 2.
-00015d90: 352c 2077 6869 6368 2063 616e 2067 6574  5, which can get
-00015da0: 0a20 2020 2020 2020 2023 2072 6570 7265  .        # repre
-00015db0: 7365 6e74 6564 2061 7320 322e 3439 3939  sented as 2.4999
-00015dc0: 3920 6475 6520 746f 2066 6c6f 6174 2070  9 due to float p
-00015dd0: 7265 6369 7369 6f6e 2069 7373 7565 732c  recision issues,
-00015de0: 2061 6e64 2074 6869 7320 6d69 6768 7420   and this might 
-00015df0: 7265 7375 6c74 696e 2061 6e20 6f75 7470  resultin an outp
-00015e00: 7574 2073 697a 6520 6f66 2034 0a20 2020  ut size of 4.   
-00015e10: 2020 2020 2023 2069 6e73 7465 6164 206f       # instead o
-00015e20: 6620 352c 2077 6974 686f 7574 2074 6865  f 5, without the
-00015e30: 2065 7073 696c 6f6e 2063 6f72 7265 6374   epsilon correct
-00015e40: 696f 6e2e 0a0a 2020 2020 2020 2020 6966  ion...        if
-00015e50: 206c 656e 286f 7574 7075 745f 7369 7a65   len(output_size
-00015e60: 2920 3d3d 2031 3a0a 2020 2020 2020 2020  ) == 1:.        
-00015e70: 2020 2020 2320 3164 2075 7073 616d 706c      # 1d upsampl
-00015e80: 696e 670a 2020 2020 2020 2020 2020 2020  ing.            
-00015e90: 486f 7574 203d 206f 7574 7075 745f 7369  Hout = output_si
-00015ea0: 7a65 5b30 5d0a 2020 2020 2020 2020 2020  ze[0].          
-00015eb0: 2020 4869 6e20 3d20 696e 7075 745f 7368    Hin = input_sh
-00015ec0: 6170 655b 2d31 5d0a 2020 2020 2020 2020  ape[-1].        
-00015ed0: 2020 2020 7363 616c 6573 5f68 203d 2048      scales_h = H
-00015ee0: 6f75 7420 2f20 4869 6e20 6966 2048 6f75  out / Hin if Hou
-00015ef0: 7420 2520 4869 6e20 3d3d 2030 2065 6c73  t % Hin == 0 els
-00015f00: 6520 2848 6f75 7420 2b20 3165 2d34 2920  e (Hout + 1e-4) 
-00015f10: 2f20 4869 6e0a 2020 2020 2020 2020 2020  / Hin.          
-00015f20: 2020 7363 616c 6573 203d 2073 6361 6c65    scales = scale
-00015f30: 735f 680a 2020 2020 2020 2020 656c 6966  s_h.        elif
-00015f40: 206c 656e 286f 7574 7075 745f 7369 7a65   len(output_size
-00015f50: 2920 3d3d 2032 3a0a 2020 2020 2020 2020  ) == 2:.        
-00015f60: 2020 2020 2320 3264 2075 7073 616d 706c      # 2d upsampl
-00015f70: 696e 670a 2020 2020 2020 2020 2020 2020  ing.            
-00015f80: 486f 7574 2c20 576f 7574 203d 206f 7574  Hout, Wout = out
-00015f90: 7075 745f 7369 7a65 5b30 5d2c 206f 7574  put_size[0], out
-00015fa0: 7075 745f 7369 7a65 5b31 5d0a 2020 2020  put_size[1].    
-00015fb0: 2020 2020 2020 2020 4869 6e2c 2057 696e          Hin, Win
-00015fc0: 203d 2069 6e70 7574 5f73 6861 7065 5b2d   = input_shape[-
-00015fd0: 325d 2c20 696e 7075 745f 7368 6170 655b  2], input_shape[
-00015fe0: 2d31 5d0a 2020 2020 2020 2020 2020 2020  -1].            
-00015ff0: 7363 616c 6573 5f68 203d 2048 6f75 7420  scales_h = Hout 
-00016000: 2f20 4869 6e20 6966 2048 6f75 7420 2520  / Hin if Hout % 
-00016010: 4869 6e20 3d3d 2030 2065 6c73 6520 2848  Hin == 0 else (H
-00016020: 6f75 7420 2b20 3165 2d34 2920 2f20 4869  out + 1e-4) / Hi
-00016030: 6e0a 2020 2020 2020 2020 2020 2020 7363  n.            sc
-00016040: 616c 6573 5f77 203d 2057 6f75 7420 2f20  ales_w = Wout / 
-00016050: 5769 6e20 6966 2057 6f75 7420 2520 5769  Win if Wout % Wi
-00016060: 6e20 3d3d 2030 2065 6c73 6520 2857 6f75  n == 0 else (Wou
-00016070: 7420 2b20 3165 2d34 2920 2f20 5769 6e0a  t + 1e-4) / Win.
-00016080: 2020 2020 2020 2020 2020 2020 7363 616c              scal
-00016090: 6573 203d 205b 7363 616c 6573 5f68 2c20  es = [scales_h, 
-000160a0: 7363 616c 6573 5f77 5d0a 2020 2020 2020  scales_w].      
-000160b0: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
-000160c0: 2020 2020 6d73 6720 3d20 224f 6e6c 7920      msg = "Only 
-000160d0: 3164 2061 6e64 2032 6420 756e 7361 6d70  1d and 2d unsamp
-000160e0: 6c69 6e67 2061 7265 2073 7570 706f 7274  ling are support
-000160f0: 6564 2e22 0a20 2020 2020 2020 2020 2020  ed.".           
-00016100: 2072 6169 7365 204e 6f74 496d 706c 656d   raise NotImplem
-00016110: 656e 7465 6445 7272 6f72 286d 7367 290a  entedError(msg).
-00016120: 0a20 2020 2072 6574 7572 6e20 7363 616c  .    return scal
-00016130: 6573 0a0a 0a64 6566 205f 6973 5f66 6c6f  es...def _is_flo
-00016140: 6174 5f76 616c 7565 2878 2c20 7468 7265  at_value(x, thre
-00016150: 7368 6f6c 643d 302e 3030 3129 3a0a 2020  shold=0.001):.  
-00016160: 2020 7265 7475 726e 2078 202d 205f 6d61    return x - _ma
-00016170: 7468 2e66 6c6f 6f72 2878 2920 3e20 7468  th.floor(x) > th
-00016180: 7265 7368 6f6c 640a 0a0a 4072 6567 6973  reshold...@regis
-00016190: 7465 725f 746f 7263 685f 6f70 0a64 6566  ter_torch_op.def
-000161a0: 2075 7073 616d 706c 655f 6c69 6e65 6172   upsample_linear
-000161b0: 3164 2863 6f6e 7465 7874 2c20 6e6f 6465  1d(context, node
-000161c0: 293a 0a20 2020 2069 6e70 7574 7320 3d20  ):.    inputs = 
-000161d0: 5f67 6574 5f69 6e70 7574 7328 636f 6e74  _get_inputs(cont
-000161e0: 6578 742c 206e 6f64 6529 0a20 2020 2078  ext, node).    x
-000161f0: 203d 2069 6e70 7574 735b 305d 0a20 2020   = inputs[0].   
-00016200: 206f 7574 7075 745f 7369 7a65 203d 2069   output_size = i
-00016210: 6e70 7574 735b 315d 0a20 2020 2061 6c69  nputs[1].    ali
-00016220: 676e 5f63 6f72 6e65 7273 203d 2062 6f6f  gn_corners = boo
-00016230: 6c28 696e 7075 7473 5b32 5d2e 7661 6c29  l(inputs[2].val)
-00016240: 0a20 2020 2073 6361 6c65 203d 2069 6e70  .    scale = inp
-00016250: 7574 735b 335d 0a0a 2020 2020 7363 616c  uts[3]..    scal
-00016260: 655f 6661 6374 6f72 203d 204e 6f6e 650a  e_factor = None.
-00016270: 0a20 2020 2069 6620 7363 616c 6520 6973  .    if scale is
-00016280: 206e 6f74 204e 6f6e 6520 616e 6420 7363   not None and sc
-00016290: 616c 652e 7661 6c20 6973 206e 6f74 204e  ale.val is not N
-000162a0: 6f6e 6520 616e 6420 7363 616c 652e 7368  one and scale.sh
-000162b0: 6170 6520 3d3d 2028 312c 293a 0a20 2020  ape == (1,):.   
-000162c0: 2020 2020 2023 2047 6574 2074 6865 2073       # Get the s
-000162d0: 6361 6c65 2066 6163 746f 7220 6672 6f6d  cale factor from
-000162e0: 2070 726f 7669 6465 6420 696e 7075 7473   provided inputs
-000162f0: 0a20 2020 2020 2020 2023 2054 6869 7320  .        # This 
-00016300: 6861 7070 656e 7320 7768 656e 2072 6563  happens when rec
-00016310: 6f6d 7075 7465 5f73 6361 6c65 5f66 6163  ompute_scale_fac
-00016320: 746f 7220 3d20 4661 6c73 650a 2020 2020  tor = False.    
-00016330: 2020 2020 7363 616c 655f 6661 6374 6f72      scale_factor
-00016340: 203d 2073 6361 6c65 2e76 616c 5b30 5d0a   = scale.val[0].
-00016350: 0a20 2020 2020 2020 2023 2043 7572 7265  .        # Curre
-00016360: 6e74 6c79 2c20 7765 2061 7265 206e 6f74  ntly, we are not
-00016370: 2073 7570 706f 7274 696e 6720 7265 636f   supporting reco
-00016380: 6d70 7574 655f 7363 616c 655f 6661 6374  mpute_scale_fact
-00016390: 6f72 203d 2046 616c 7365 2c20 616c 6967  or = False, alig
-000163a0: 6e5f 636f 726e 6572 7320 3d20 4661 6c73  n_corners = Fals
-000163b0: 6520 7769 7468 2066 6c6f 6174 206f 7574  e with float out
-000163c0: 7075 7420 7369 7a65 0a20 2020 2020 2020  put size.       
-000163d0: 205f 2c20 5f2c 2068 203d 2078 2e73 6861   _, _, h = x.sha
-000163e0: 7065 0a20 2020 2020 2020 2069 6620 6e6f  pe.        if no
-000163f0: 7420 6973 5f73 796d 626f 6c69 6328 6829  t is_symbolic(h)
-00016400: 3a0a 2020 2020 2020 2020 2020 2020 2320  :.            # 
-00016410: 466f 7220 7468 6520 7374 6174 6963 2069  For the static i
-00016420: 6e70 7574 2073 6861 7065 2c20 7765 2063  nput shape, we c
-00016430: 616e 2063 6f6d 7075 7465 2074 6865 206f  an compute the o
-00016440: 7574 7075 7420 7369 7a65 2062 6566 6f72  utput size befor
-00016450: 6568 616e 642c 2061 6e64 2063 6865 636b  ehand, and check
-00016460: 2069 6620 6974 2069 7320 6120 666c 6f61   if it is a floa
-00016470: 7420 7661 6c75 650a 2020 2020 2020 2020  t value.        
-00016480: 2020 2020 6f75 7470 7574 5f73 697a 6520      output_size 
-00016490: 3d20 6820 2a20 7363 616c 655f 6661 6374  = h * scale_fact
-000164a0: 6f72 0a20 2020 2020 2020 2020 2020 2069  or.            i
-000164b0: 735f 666c 6f61 7420 3d20 5f69 735f 666c  s_float = _is_fl
-000164c0: 6f61 745f 7661 6c75 6528 6f75 7470 7574  oat_value(output
-000164d0: 5f73 697a 6529 0a20 2020 2020 2020 2065  _size).        e
-000164e0: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
-000164f0: 2023 2046 6f72 2074 6865 2064 796e 616d   # For the dynam
-00016500: 6963 2069 6e70 7574 2073 6861 7065 2c20  ic input shape, 
-00016510: 7765 2063 6865 636b 2069 6620 7468 6520  we check if the 
-00016520: 7363 616c 6520 6661 6374 6f72 2069 7473  scale factor its
-00016530: 656c 6620 6973 2066 6c6f 6174 0a20 2020  elf is float.   
-00016540: 2020 2020 2020 2020 2069 735f 666c 6f61           is_floa
-00016550: 7420 3d20 5f69 735f 666c 6f61 745f 7661  t = _is_float_va
-00016560: 6c75 6528 7363 616c 655f 6661 6374 6f72  lue(scale_factor
-00016570: 290a 0a20 2020 2020 2020 2069 6620 6973  )..        if is
-00016580: 5f66 6c6f 6174 2061 6e64 206e 6f74 2061  _float and not a
-00016590: 6c69 676e 5f63 6f72 6e65 7273 3a0a 2020  lign_corners:.  
-000165a0: 2020 2020 2020 2020 2020 6d73 6720 3d20            msg = 
-000165b0: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
-000165c0: 2020 2272 6563 6f6d 7075 7465 5f73 6361    "recompute_sca
-000165d0: 6c65 5f66 6163 746f 7220 3d20 4661 6c73  le_factor = Fals
-000165e0: 652c 2061 6c69 676e 5f63 6f72 6e65 7273  e, align_corners
-000165f0: 203d 2046 616c 7365 2077 6974 6820 666c   = False with fl
-00016600: 6f61 7420 6f75 7470 7574 2073 697a 6520  oat output size 
-00016610: 6973 2022 0a20 2020 2020 2020 2020 2020  is ".           
-00016620: 2020 2020 202b 2022 6e6f 7420 7375 7070       + "not supp
-00016630: 6f72 7465 6420 666f 7220 7468 6520 7570  orted for the up
-00016640: 7361 6d70 6c65 206f 7020 7b7d 222e 666f  sample op {}".fo
-00016650: 726d 6174 286e 6f64 652e 6e61 6d65 290a  rmat(node.name).
-00016660: 2020 2020 2020 2020 2020 2020 290a 2020              ).  
-00016670: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
-00016680: 4e6f 7449 6d70 6c65 6d65 6e74 6564 4572  NotImplementedEr
-00016690: 726f 7228 6d73 6729 0a0a 2020 2020 656c  ror(msg)..    el
-000166a0: 6966 2069 7369 6e73 7461 6e63 6528 6f75  if isinstance(ou
-000166b0: 7470 7574 5f73 697a 652c 206c 6973 7429  tput_size, list)
-000166c0: 3a0a 2020 2020 2020 2020 2320 5768 656e  :.        # When
-000166d0: 2074 6865 2069 6e70 7574 2073 6861 7065   the input shape
-000166e0: 2069 7320 6479 6e61 6d69 6320 616e 6420   is dynamic and 
-000166f0: 7265 636f 6d70 7574 655f 7363 616c 655f  recompute_scale_
-00016700: 6661 6374 6f72 203d 2054 7275 652c 0a20  factor = True,. 
-00016710: 2020 2020 2020 2023 2077 6520 6e65 6564         # we need
-00016720: 2074 6f20 7472 6163 6520 7468 6520 6772   to trace the gr
-00016730: 6170 6820 746f 2066 696e 6420 7468 6520  aph to find the 
-00016740: 7363 616c 6520 6661 6374 6f72 2e0a 2020  scale factor..  
-00016750: 2020 2020 2020 7820 3d20 6d62 2e65 7870        x = mb.exp
-00016760: 616e 645f 6469 6d73 2878 3d78 2c20 6178  and_dims(x=x, ax
-00016770: 6573 3d5b 335d 290a 2020 2020 2020 2020  es=[3]).        
-00016780: 7820 3d20 6d62 2e74 6f72 6368 5f75 7073  x = mb.torch_ups
-00016790: 616d 706c 655f 6269 6c69 6e65 6172 280a  ample_bilinear(.
-000167a0: 2020 2020 2020 2020 2020 2020 783d 782c              x=x,
-000167b0: 0a20 2020 2020 2020 2020 2020 206f 7574  .            out
-000167c0: 7075 745f 6865 6967 6874 3d6f 7574 7075  put_height=outpu
-000167d0: 745f 7369 7a65 5b30 5d2c 0a20 2020 2020  t_size[0],.     
-000167e0: 2020 2020 2020 206f 7574 7075 745f 7769         output_wi
-000167f0: 6474 683d 312c 0a20 2020 2020 2020 2020  dth=1,.         
-00016800: 2020 2061 6c69 676e 5f63 6f72 6e65 7273     align_corners
-00016810: 3d61 6c69 676e 5f63 6f72 6e65 7273 2c0a  =align_corners,.
-00016820: 2020 2020 2020 2020 290a 2020 2020 2020          ).      
-00016830: 2020 7820 3d20 6d62 2e73 7175 6565 7a65    x = mb.squeeze
-00016840: 2878 3d78 2c20 6178 6573 3d5b 335d 2c20  (x=x, axes=[3], 
-00016850: 6e61 6d65 3d6e 6f64 652e 6e61 6d65 290a  name=node.name).
-00016860: 2020 2020 2020 2020 636f 6e74 6578 742e          context.
-00016870: 6164 6428 7829 0a20 2020 2020 2020 2072  add(x).        r
-00016880: 6574 7572 6e0a 0a20 2020 2065 6c69 6620  eturn..    elif 
-00016890: 6f75 7470 7574 5f73 697a 652e 7661 6c20  output_size.val 
-000168a0: 6973 206e 6f74 204e 6f6e 653a 0a20 2020  is not None:.   
-000168b0: 2020 2020 2023 2049 6e66 6572 2074 6865       # Infer the
-000168c0: 2073 6361 6c65 2066 6163 746f 7220 6672   scale factor fr
-000168d0: 6f6d 2074 6865 2070 726f 7669 6465 6420  om the provided 
-000168e0: 6f75 7470 7574 2073 697a 650a 2020 2020  output size.    
-000168f0: 2020 2020 7363 616c 655f 6661 6374 6f72      scale_factor
-00016900: 203d 205f 6765 745f 7363 616c 6573 5f66   = _get_scales_f
-00016910: 726f 6d5f 6f75 7470 7574 5f73 697a 6528  rom_output_size(
-00016920: 6f75 7470 7574 5f73 697a 652c 2078 2e73  output_size, x.s
-00016930: 6861 7065 290a 0a20 2020 2023 2045 7870  hape)..    # Exp
-00016940: 616e 6420 7468 6520 696e 7075 7420 746f  and the input to
-00016950: 2061 2034 6420 7465 6e73 6f72 2c20 616e   a 4d tensor, an
-00016960: 6420 7573 6520 4d49 4c27 7320 7570 7361  d use MIL's upsa
-00016970: 6d70 6c65 5f62 696c 696e 6561 7220 6f70  mple_bilinear op
-00016980: 0a20 2020 2078 203d 206d 622e 6578 7061  .    x = mb.expa
-00016990: 6e64 5f64 696d 7328 783d 782c 2061 7865  nd_dims(x=x, axe
-000169a0: 733d 5b33 5d29 0a20 2020 2078 203d 206d  s=[3]).    x = m
-000169b0: 622e 7570 7361 6d70 6c65 5f62 696c 696e  b.upsample_bilin
-000169c0: 6561 7228 0a20 2020 2020 2020 2078 3d78  ear(.        x=x
-000169d0: 2c0a 2020 2020 2020 2020 7363 616c 655f  ,.        scale_
-000169e0: 6661 6374 6f72 5f68 6569 6768 743d 7363  factor_height=sc
-000169f0: 616c 655f 6661 6374 6f72 2c0a 2020 2020  ale_factor,.    
-00016a00: 2020 2020 7363 616c 655f 6661 6374 6f72      scale_factor
-00016a10: 5f77 6964 7468 3d31 2e2c 0a20 2020 2020  _width=1.,.     
-00016a20: 2020 2061 6c69 676e 5f63 6f72 6e65 7273     align_corners
-00016a30: 3d61 6c69 676e 5f63 6f72 6e65 7273 2c0a  =align_corners,.
-00016a40: 2020 2020 290a 2020 2020 7820 3d20 6d62      ).    x = mb
-00016a50: 2e73 7175 6565 7a65 2878 3d78 2c20 6178  .squeeze(x=x, ax
-00016a60: 6573 3d5b 335d 2c20 6e61 6d65 3d6e 6f64  es=[3], name=nod
-00016a70: 652e 6e61 6d65 290a 2020 2020 636f 6e74  e.name).    cont
-00016a80: 6578 742e 6164 6428 7829 0a0a 0a40 7265  ext.add(x)...@re
-00016a90: 6769 7374 6572 5f74 6f72 6368 5f6f 700a  gister_torch_op.
-00016aa0: 6465 6620 7570 7361 6d70 6c65 5f62 696c  def upsample_bil
-00016ab0: 696e 6561 7232 6428 636f 6e74 6578 742c  inear2d(context,
-00016ac0: 206e 6f64 6529 3a0a 2020 2020 696e 7075   node):.    inpu
-00016ad0: 7473 203d 205f 6765 745f 696e 7075 7473  ts = _get_inputs
-00016ae0: 2863 6f6e 7465 7874 2c20 6e6f 6465 290a  (context, node).
-00016af0: 2020 2020 5f69 6e70 7574 203d 2069 6e70      _input = inp
-00016b00: 7574 735b 305d 0a20 2020 206f 7574 7075  uts[0].    outpu
-00016b10: 745f 7369 7a65 203d 2069 6e70 7574 735b  t_size = inputs[
-00016b20: 315d 0a20 2020 2061 6c69 676e 5f63 6f72  1].    align_cor
-00016b30: 6e65 7273 203d 2062 6f6f 6c28 696e 7075  ners = bool(inpu
-00016b40: 7473 5b32 5d2e 7661 6c29 0a20 2020 2073  ts[2].val).    s
-00016b50: 6361 6c65 5f66 6163 746f 7273 203d 2069  cale_factors = i
-00016b60: 6e70 7574 735b 335d 0a0a 2020 2020 7363  nputs[3]..    sc
-00016b70: 616c 6573 5f68 2c20 7363 616c 6573 5f77  ales_h, scales_w
-00016b80: 203d 204e 6f6e 652c 204e 6f6e 650a 0a20   = None, None.. 
-00016b90: 2020 2069 6620 280a 2020 2020 2020 2020     if (.        
-00016ba0: 7363 616c 655f 6661 6374 6f72 7320 6973  scale_factors is
-00016bb0: 206e 6f74 204e 6f6e 650a 2020 2020 2020   not None.      
-00016bc0: 2020 616e 6420 7363 616c 655f 6661 6374    and scale_fact
-00016bd0: 6f72 732e 7661 6c20 6973 206e 6f74 204e  ors.val is not N
-00016be0: 6f6e 650a 2020 2020 2020 2020 616e 6420  one.        and 
-00016bf0: 7363 616c 655f 6661 6374 6f72 732e 7261  scale_factors.ra
-00016c00: 6e6b 203d 3d20 310a 2020 2020 2020 2020  nk == 1.        
-00016c10: 616e 6420 7363 616c 655f 6661 6374 6f72  and scale_factor
-00016c20: 732e 7368 6170 655b 305d 203d 3d20 320a  s.shape[0] == 2.
-00016c30: 2020 2020 293a 0a20 2020 2020 2020 2023      ):.        #
-00016c40: 2067 6574 2073 6361 6c65 2066 6163 746f   get scale facto
-00016c50: 7273 2066 726f 6d20 7072 6f76 6964 6564  rs from provided
-00016c60: 2069 6e70 7574 730a 2020 2020 2020 2020   inputs.        
-00016c70: 2320 7468 6973 2068 6170 7065 6e73 2077  # this happens w
-00016c80: 6865 6e20 7265 636f 6d70 7574 655f 7363  hen recompute_sc
-00016c90: 616c 655f 6661 6374 6f72 203d 2046 616c  ale_factor = Fal
-00016ca0: 7365 0a20 2020 2020 2020 2073 6361 6c65  se.        scale
-00016cb0: 5f66 6163 746f 7273 203d 2073 6361 6c65  _factors = scale
-00016cc0: 5f66 6163 746f 7273 2e76 616c 0a20 2020  _factors.val.   
-00016cd0: 2020 2020 2073 6361 6c65 735f 6820 3d20       scales_h = 
-00016ce0: 7363 616c 655f 6661 6374 6f72 735b 305d  scale_factors[0]
-00016cf0: 0a20 2020 2020 2020 2073 6361 6c65 735f  .        scales_
-00016d00: 7720 3d20 7363 616c 655f 6661 6374 6f72  w = scale_factor
-00016d10: 735b 315d 0a0a 2020 2020 2020 2020 2320  s[1]..        # 
-00016d20: 6375 7272 656e 746c 792c 2077 6520 6172  currently, we ar
-00016d30: 6520 6e6f 7420 7375 7070 6f72 7469 6e67  e not supporting
-00016d40: 2072 6563 6f6d 7075 7465 5f73 6361 6c65   recompute_scale
-00016d50: 5f66 6163 746f 7220 3d20 4661 6c73 652c  _factor = False,
-00016d60: 2061 6c69 676e 5f63 6f72 6e65 7273 203d   align_corners =
-00016d70: 2046 616c 7365 2077 6974 6820 666c 6f61   False with floa
-00016d80: 7420 6f75 7470 7574 2073 697a 650a 2020  t output size.  
-00016d90: 2020 2020 2020 5f2c 205f 2c20 682c 2077        _, _, h, w
-00016da0: 203d 205f 696e 7075 742e 7368 6170 650a   = _input.shape.
-00016db0: 2020 2020 2020 2020 6966 206e 6f74 2069          if not i
-00016dc0: 735f 7379 6d62 6f6c 6963 2868 2920 616e  s_symbolic(h) an
-00016dd0: 6420 6e6f 7420 6973 5f73 796d 626f 6c69  d not is_symboli
-00016de0: 6328 7729 3a0a 2020 2020 2020 2020 2020  c(w):.          
-00016df0: 2020 2320 466f 7220 7468 6520 7374 6174    # For the stat
-00016e00: 6963 2069 6e70 7574 2073 6861 7065 2c20  ic input shape, 
-00016e10: 7765 2063 616e 2063 6f6d 7075 7465 2074  we can compute t
-00016e20: 6865 206f 7574 7075 7420 7369 7a65 2062  he output size b
-00016e30: 6566 6f72 6568 616e 640a 2020 2020 2020  eforehand.      
-00016e40: 2020 2020 2020 6f75 7470 7574 5f68 203d        output_h =
-00016e50: 2068 202a 2073 6361 6c65 735f 680a 2020   h * scales_h.  
-00016e60: 2020 2020 2020 2020 2020 6f75 7470 7574            output
-00016e70: 5f77 203d 2077 202a 2073 6361 6c65 735f  _w = w * scales_
-00016e80: 770a 2020 2020 2020 2020 2020 2020 6973  w.            is
-00016e90: 5f68 5f66 6c6f 6174 203d 205f 6973 5f66  _h_float = _is_f
-00016ea0: 6c6f 6174 5f76 616c 7565 286f 7574 7075  loat_value(outpu
-00016eb0: 745f 6829 0a20 2020 2020 2020 2020 2020  t_h).           
-00016ec0: 2069 735f 775f 666c 6f61 7420 3d20 5f69   is_w_float = _i
-00016ed0: 735f 666c 6f61 745f 7661 6c75 6528 6f75  s_float_value(ou
-00016ee0: 7470 7574 5f77 290a 0a20 2020 2020 2020  tput_w)..       
-00016ef0: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
-00016f00: 2020 2023 2046 6f72 2074 6865 2064 796e     # For the dyn
-00016f10: 616d 6963 2069 6e70 7574 2073 6861 7065  amic input shape
-00016f20: 2c20 7765 2063 6865 636b 2069 6620 7468  , we check if th
-00016f30: 6520 7363 616c 6520 6661 6374 6f72 2069  e scale factor i
-00016f40: 7473 656c 6620 6973 2066 6c6f 6174 0a20  tself is float. 
-00016f50: 2020 2020 2020 2020 2020 2069 735f 685f             is_h_
-00016f60: 666c 6f61 7420 3d20 5f69 735f 666c 6f61  float = _is_floa
-00016f70: 745f 7661 6c75 6528 7363 616c 6573 5f68  t_value(scales_h
-00016f80: 290a 2020 2020 2020 2020 2020 2020 6973  ).            is
-00016f90: 5f77 5f66 6c6f 6174 203d 205f 6973 5f66  _w_float = _is_f
-00016fa0: 6c6f 6174 5f76 616c 7565 2873 6361 6c65  loat_value(scale
-00016fb0: 735f 7729 0a0a 2020 2020 2020 2020 6966  s_w)..        if
-00016fc0: 2028 6973 5f68 5f66 6c6f 6174 206f 7220   (is_h_float or 
-00016fd0: 6973 5f77 5f66 6c6f 6174 2920 616e 6420  is_w_float) and 
-00016fe0: 6e6f 7420 616c 6967 6e5f 636f 726e 6572  not align_corner
-00016ff0: 733a 0a20 2020 2020 2020 2020 2020 206d  s:.            m
-00017000: 7367 203d 2028 0a20 2020 2020 2020 2020  sg = (.         
-00017010: 2020 2020 2020 2022 7265 636f 6d70 7574         "recomput
-00017020: 655f 7363 616c 655f 6661 6374 6f72 203d  e_scale_factor =
-00017030: 2046 616c 7365 2c20 616c 6967 6e5f 636f   False, align_co
-00017040: 726e 6572 7320 3d20 4661 6c73 6520 7769  rners = False wi
-00017050: 7468 2066 6c6f 6174 206f 7574 7075 7420  th float output 
-00017060: 7369 7a65 2069 7320 220a 2020 2020 2020  size is ".      
-00017070: 2020 2020 2020 2020 2020 2b20 226e 6f74            + "not
-00017080: 2073 7570 706f 7274 6564 2066 6f72 2074   supported for t
-00017090: 6865 2075 7073 616d 706c 6520 6f70 207b  he upsample op {
-000170a0: 7d22 2e66 6f72 6d61 7428 6e6f 6465 2e6e  }".format(node.n
-000170b0: 616d 6529 0a20 2020 2020 2020 2020 2020  ame).           
-000170c0: 2029 0a20 2020 2020 2020 2020 2020 2072   ).            r
-000170d0: 6169 7365 204e 6f74 496d 706c 656d 656e  aise NotImplemen
-000170e0: 7465 6445 7272 6f72 286d 7367 290a 0a20  tedError(msg).. 
-000170f0: 2020 2065 6c69 6620 280a 2020 2020 2020     elif (.      
-00017100: 2020 6973 696e 7374 616e 6365 286f 7574    isinstance(out
-00017110: 7075 745f 7369 7a65 2c20 6c69 7374 290a  put_size, list).
-00017120: 2020 2020 2020 2020 616e 6420 6f75 7470          and outp
-00017130: 7574 5f73 697a 655b 305d 2e76 616c 2069  ut_size[0].val i
-00017140: 7320 4e6f 6e65 0a20 2020 2020 2020 2061  s None.        a
-00017150: 6e64 206f 7574 7075 745f 7369 7a65 5b31  nd output_size[1
-00017160: 5d2e 7661 6c20 6973 204e 6f6e 650a 2020  ].val is None.  
-00017170: 2020 293a 0a20 2020 2020 2020 2023 2074    ):.        # t
-00017180: 6865 2069 6e70 7574 2073 6861 7065 2069  he input shape i
-00017190: 7320 6479 6e61 6d69 6320 616e 6420 7265  s dynamic and re
-000171a0: 636f 6d70 7574 655f 7363 616c 655f 6661  compute_scale_fa
-000171b0: 6374 6f72 203d 2054 7275 650a 2020 2020  ctor = True.    
-000171c0: 2020 2020 2320 6e65 6564 2074 6f20 7472      # need to tr
-000171d0: 6163 6520 7468 6520 6772 6170 6820 746f  ace the graph to
-000171e0: 2066 696e 6420 7468 6520 7363 616c 6520   find the scale 
-000171f0: 6661 6374 6f72 0a20 2020 2020 2020 2023  factor.        #
-00017200: 2077 6520 6465 6669 6e65 2061 2074 6f72   we define a tor
-00017210: 6368 2066 726f 6e74 2065 6e64 206f 7020  ch front end op 
-00017220: 6d62 2e74 6f72 6368 5f75 7073 616d 706c  mb.torch_upsampl
-00017230: 655f 6269 6c69 6e65 6172 2074 6f20 7265  e_bilinear to re
-00017240: 736f 6c76 6520 7468 6520 636f 6e73 7420  solve the const 
-00017250: 7363 616c 696e 6720 6661 6374 6f72 0a20  scaling factor. 
-00017260: 2020 2020 2020 2074 6f72 6368 5f75 7073         torch_ups
-00017270: 616d 706c 655f 6269 6c69 6e65 6172 203d  ample_bilinear =
-00017280: 206d 622e 746f 7263 685f 7570 7361 6d70   mb.torch_upsamp
-00017290: 6c65 5f62 696c 696e 6561 7228 0a20 2020  le_bilinear(.   
-000172a0: 2020 2020 2020 2020 2078 3d5f 696e 7075           x=_inpu
-000172b0: 742c 0a20 2020 2020 2020 2020 2020 206f  t,.            o
-000172c0: 7574 7075 745f 6865 6967 6874 3d6f 7574  utput_height=out
-000172d0: 7075 745f 7369 7a65 5b30 5d2c 0a20 2020  put_size[0],.   
-000172e0: 2020 2020 2020 2020 206f 7574 7075 745f           output_
-000172f0: 7769 6474 683d 6f75 7470 7574 5f73 697a  width=output_siz
-00017300: 655b 315d 2c0a 2020 2020 2020 2020 2020  e[1],.          
-00017310: 2020 616c 6967 6e5f 636f 726e 6572 733d    align_corners=
-00017320: 616c 6967 6e5f 636f 726e 6572 732c 0a20  align_corners,. 
-00017330: 2020 2020 2020 2020 2020 206e 616d 653d             name=
-00017340: 6e6f 6465 2e6e 616d 652c 0a20 2020 2020  node.name,.     
-00017350: 2020 2029 0a20 2020 2020 2020 2063 6f6e     ).        con
-00017360: 7465 7874 2e61 6464 2874 6f72 6368 5f75  text.add(torch_u
-00017370: 7073 616d 706c 655f 6269 6c69 6e65 6172  psample_bilinear
-00017380: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
-00017390: 0a20 2020 2065 6c73 653a 0a20 2020 2020  .    else:.     
-000173a0: 2020 2023 2069 6e66 6572 2073 6361 6c65     # infer scale
-000173b0: 2066 6163 746f 7273 2066 726f 6d20 6f75   factors from ou
-000173c0: 7470 7574 2073 697a 6573 0a20 2020 2020  tput sizes.     
-000173d0: 2020 2023 2054 6869 7320 6861 7070 656e     # This happen
-000173e0: 7320 7768 656e 2072 6563 6f6d 7075 7465  s when recompute
-000173f0: 5f73 6361 6c65 5f66 6163 746f 7220 3d20  _scale_factor = 
-00017400: 5472 7565 206f 7220 7468 6520 6f75 7470  True or the outp
-00017410: 7574 5f73 697a 6520 6973 2073 7065 6369  ut_size is speci
-00017420: 6669 6564 0a20 2020 2020 2020 2073 6361  fied.        sca
-00017430: 6c65 7320 3d20 5f67 6574 5f73 6361 6c65  les = _get_scale
-00017440: 735f 6672 6f6d 5f6f 7574 7075 745f 7369  s_from_output_si
-00017450: 7a65 286f 7574 7075 745f 7369 7a65 2c20  ze(output_size, 
-00017460: 5f69 6e70 7574 2e73 6861 7065 290a 2020  _input.shape).  
-00017470: 2020 2020 2020 6966 2073 6361 6c65 733a        if scales:
-00017480: 0a20 2020 2020 2020 2020 2020 2073 6361  .            sca
-00017490: 6c65 735f 682c 2073 6361 6c65 735f 7720  les_h, scales_w 
-000174a0: 3d20 7363 616c 6573 0a0a 2020 2020 6966  = scales..    if
-000174b0: 2073 6361 6c65 735f 6820 6973 204e 6f6e   scales_h is Non
-000174c0: 6520 6f72 2073 6361 6c65 735f 7720 6973  e or scales_w is
-000174d0: 204e 6f6e 653a 0a20 2020 2020 2020 2069   None:.        i
-000174e0: 6620 6c65 6e28 696e 7075 7473 2920 3d3d  f len(inputs) ==
-000174f0: 2035 3a0a 2020 2020 2020 2020 2020 2020   5:.            
-00017500: 2320 466f 7220 746f 7263 683d 3d31 2e35  # For torch==1.5
-00017510: 2e30 2c20 7570 7361 6d70 6c65 5f62 696c  .0, upsample_bil
-00017520: 696e 6561 7232 6420 6861 7320 3520 696e  inear2d has 5 in
-00017530: 7075 7473 2e0a 2020 2020 2020 2020 2020  puts..          
-00017540: 2020 7363 616c 6573 5f68 203d 2069 6e70    scales_h = inp
-00017550: 7574 735b 335d 0a20 2020 2020 2020 2020  uts[3].         
-00017560: 2020 2073 6361 6c65 735f 7720 3d20 696e     scales_w = in
-00017570: 7075 7473 5b34 5d0a 2020 2020 2020 2020  puts[4].        
-00017580: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
-00017590: 2020 7261 6973 6520 5661 6c75 6545 7272    raise ValueErr
-000175a0: 6f72 2822 4661 696c 6564 2074 6f20 696e  or("Failed to in
-000175b0: 6665 7220 7363 616c 6520 6661 6374 6f72  fer scale factor
-000175c0: 7320 6672 6f6d 2069 6e70 7574 732e 2229  s from inputs.")
-000175d0: 0a0a 2020 2020 7570 7361 6d70 6c65 5f62  ..    upsample_b
-000175e0: 696c 696e 6561 7220 3d20 6d62 2e75 7073  ilinear = mb.ups
-000175f0: 616d 706c 655f 6269 6c69 6e65 6172 280a  ample_bilinear(.
-00017600: 2020 2020 2020 2020 783d 5f69 6e70 7574          x=_input
-00017610: 2c0a 2020 2020 2020 2020 7363 616c 655f  ,.        scale_
-00017620: 6661 6374 6f72 5f68 6569 6768 743d 7363  factor_height=sc
-00017630: 616c 6573 5f68 2c0a 2020 2020 2020 2020  ales_h,.        
-00017640: 7363 616c 655f 6661 6374 6f72 5f77 6964  scale_factor_wid
-00017650: 7468 3d73 6361 6c65 735f 772c 0a20 2020  th=scales_w,.   
-00017660: 2020 2020 2061 6c69 676e 5f63 6f72 6e65       align_corne
-00017670: 7273 3d61 6c69 676e 5f63 6f72 6e65 7273  rs=align_corners
-00017680: 2c0a 2020 2020 2020 2020 6e61 6d65 3d6e  ,.        name=n
-00017690: 6f64 652e 6e61 6d65 2c0a 2020 2020 290a  ode.name,.    ).
-000176a0: 2020 2020 636f 6e74 6578 742e 6164 6428      context.add(
-000176b0: 7570 7361 6d70 6c65 5f62 696c 696e 6561  upsample_bilinea
-000176c0: 7229 0a0a 0a40 7265 6769 7374 6572 5f74  r)...@register_t
-000176d0: 6f72 6368 5f6f 700a 6465 6620 7570 7361  orch_op.def upsa
-000176e0: 6d70 6c65 5f6e 6561 7265 7374 3164 2863  mple_nearest1d(c
-000176f0: 6f6e 7465 7874 2c20 6e6f 6465 293a 0a20  ontext, node):. 
-00017700: 2020 2069 6e70 7574 7320 3d20 5f67 6574     inputs = _get
-00017710: 5f69 6e70 7574 7328 636f 6e74 6578 742c  _inputs(context,
-00017720: 206e 6f64 6529 0a20 2020 2078 203d 2069   node).    x = i
-00017730: 6e70 7574 735b 305d 0a20 2020 206f 7574  nputs[0].    out
-00017740: 7075 745f 7369 7a65 203d 2069 6e70 7574  put_size = input
-00017750: 735b 315d 0a20 2020 2073 6361 6c65 203d  s[1].    scale =
-00017760: 2069 6e70 7574 735b 325d 0a0a 2020 2020   inputs[2]..    
-00017770: 7363 616c 655f 6661 6374 6f72 203d 204e  scale_factor = N
-00017780: 6f6e 650a 0a20 2020 2069 6620 7363 616c  one..    if scal
-00017790: 6520 6973 206e 6f74 204e 6f6e 6520 616e  e is not None an
-000177a0: 6420 7363 616c 652e 7661 6c20 6973 206e  d scale.val is n
-000177b0: 6f74 204e 6f6e 6520 616e 6420 7363 616c  ot None and scal
-000177c0: 652e 7368 6170 6520 3d3d 2028 312c 293a  e.shape == (1,):
-000177d0: 0a20 2020 2020 2020 2023 2047 6574 2074  .        # Get t
-000177e0: 6865 2073 6361 6c65 2066 6163 746f 7220  he scale factor 
-000177f0: 6672 6f6d 2070 726f 7669 6465 6420 696e  from provided in
-00017800: 7075 7473 0a20 2020 2020 2020 2023 2054  puts.        # T
-00017810: 6869 7320 6861 7070 656e 7320 7768 656e  his happens when
-00017820: 2072 6563 6f6d 7075 7465 5f73 6361 6c65   recompute_scale
-00017830: 5f66 6163 746f 7220 3d20 4661 6c73 650a  _factor = False.
-00017840: 2020 2020 2020 2020 7363 616c 655f 6661          scale_fa
-00017850: 6374 6f72 203d 2073 6361 6c65 2e76 616c  ctor = scale.val
-00017860: 5b30 5d0a 0a20 2020 2065 6c69 6620 6973  [0]..    elif is
-00017870: 696e 7374 616e 6365 286f 7574 7075 745f  instance(output_
-00017880: 7369 7a65 2c20 6c69 7374 293a 0a20 2020  size, list):.   
-00017890: 2020 2020 2023 2057 6865 6e20 7468 6520       # When the 
-000178a0: 696e 7075 7420 7368 6170 6520 6973 2064  input shape is d
-000178b0: 796e 616d 6963 2061 6e64 2072 6563 6f6d  ynamic and recom
-000178c0: 7075 7465 5f73 6361 6c65 5f66 6163 746f  pute_scale_facto
-000178d0: 7220 3d20 5472 7565 2c0a 2020 2020 2020  r = True,.      
-000178e0: 2020 2320 7765 206e 6565 6420 746f 2074    # we need to t
-000178f0: 7261 6365 2074 6865 2067 7261 7068 2074  race the graph t
-00017900: 6f20 6669 6e64 2074 6865 2073 6361 6c65  o find the scale
-00017910: 2066 6163 746f 722e 0a20 2020 2020 2020   factor..       
-00017920: 2078 203d 206d 622e 6578 7061 6e64 5f64   x = mb.expand_d
-00017930: 696d 7328 783d 782c 2061 7865 733d 5b33  ims(x=x, axes=[3
-00017940: 5d29 0a20 2020 2020 2020 2078 203d 206d  ]).        x = m
-00017950: 622e 746f 7263 685f 7570 7361 6d70 6c65  b.torch_upsample
-00017960: 5f6e 6561 7265 7374 5f6e 6569 6768 626f  _nearest_neighbo
-00017970: 7228 0a20 2020 2020 2020 2020 2020 2078  r(.            x
-00017980: 3d78 2c0a 2020 2020 2020 2020 2020 2020  =x,.            
-00017990: 6f75 7470 7574 5f68 6569 6768 743d 6f75  output_height=ou
-000179a0: 7470 7574 5f73 697a 655b 305d 2c0a 2020  tput_size[0],.  
-000179b0: 2020 2020 2020 2020 2020 6f75 7470 7574            output
-000179c0: 5f77 6964 7468 3d31 2c0a 2020 2020 2020  _width=1,.      
-000179d0: 2020 290a 2020 2020 2020 2020 7820 3d20    ).        x = 
-000179e0: 6d62 2e73 7175 6565 7a65 2878 3d78 2c20  mb.squeeze(x=x, 
-000179f0: 6178 6573 3d5b 335d 2c20 6e61 6d65 3d6e  axes=[3], name=n
-00017a00: 6f64 652e 6e61 6d65 290a 2020 2020 2020  ode.name).      
-00017a10: 2020 636f 6e74 6578 742e 6164 6428 7829    context.add(x)
-00017a20: 0a20 2020 2020 2020 2072 6574 7572 6e0a  .        return.
-00017a30: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
-00017a40: 2020 2320 496e 6665 7220 7363 616c 6520    # Infer scale 
-00017a50: 6661 6374 6f72 7320 6672 6f6d 206f 7574  factors from out
-00017a60: 7075 7420 7369 7a65 730a 2020 2020 2020  put sizes.      
-00017a70: 2020 7363 616c 655f 6661 6374 6f72 203d    scale_factor =
-00017a80: 205f 6765 745f 7363 616c 6573 5f66 726f   _get_scales_fro
-00017a90: 6d5f 6f75 7470 7574 5f73 697a 6528 6f75  m_output_size(ou
-00017aa0: 7470 7574 5f73 697a 652c 2078 2e73 6861  tput_size, x.sha
-00017ab0: 7065 290a 0a20 2020 2078 203d 206d 622e  pe)..    x = mb.
-00017ac0: 6578 7061 6e64 5f64 696d 7328 783d 782c  expand_dims(x=x,
-00017ad0: 2061 7865 733d 5b33 5d29 0a20 2020 2078   axes=[3]).    x
-00017ae0: 203d 206d 622e 7570 7361 6d70 6c65 5f6e   = mb.upsample_n
-00017af0: 6561 7265 7374 5f6e 6569 6768 626f 7228  earest_neighbor(
-00017b00: 0a20 2020 2020 2020 2078 3d78 2c0a 2020  .        x=x,.  
-00017b10: 2020 2020 2020 7363 616c 655f 6661 6374        scale_fact
-00017b20: 6f72 5f68 6569 6768 743d 7363 616c 655f  or_height=scale_
-00017b30: 6661 6374 6f72 2c0a 2020 2020 2020 2020  factor,.        
-00017b40: 7363 616c 655f 6661 6374 6f72 5f77 6964  scale_factor_wid
-00017b50: 7468 3d31 2e2c 0a20 2020 2029 0a20 2020  th=1.,.    ).   
-00017b60: 2078 203d 206d 622e 7371 7565 657a 6528   x = mb.squeeze(
-00017b70: 783d 782c 2061 7865 733d 5b33 5d2c 206e  x=x, axes=[3], n
-00017b80: 616d 653d 6e6f 6465 2e6e 616d 6529 0a20  ame=node.name). 
-00017b90: 2020 2063 6f6e 7465 7874 2e61 6464 2878     context.add(x
-00017ba0: 290a 0a0a 4072 6567 6973 7465 725f 746f  )...@register_to
-00017bb0: 7263 685f 6f70 0a64 6566 2075 7073 616d  rch_op.def upsam
-00017bc0: 706c 655f 6e65 6172 6573 7432 6428 636f  ple_nearest2d(co
-00017bd0: 6e74 6578 742c 206e 6f64 6529 3a0a 2020  ntext, node):.  
-00017be0: 2020 696e 7075 7473 203d 205f 6765 745f    inputs = _get_
-00017bf0: 696e 7075 7473 2863 6f6e 7465 7874 2c20  inputs(context, 
-00017c00: 6e6f 6465 290a 2020 2020 5f69 6e70 7574  node).    _input
-00017c10: 203d 2069 6e70 7574 735b 305d 0a20 2020   = inputs[0].   
-00017c20: 2073 6361 6c65 735f 682c 2073 6361 6c65   scales_h, scale
-00017c30: 735f 7720 3d20 4e6f 6e65 2c20 4e6f 6e65  s_w = None, None
-00017c40: 0a0a 2020 2020 6f75 7470 7574 5f73 697a  ..    output_siz
-00017c50: 6520 3d20 696e 7075 7473 5b31 5d0a 2020  e = inputs[1].  
-00017c60: 2020 7363 616c 655f 6661 6374 6f72 7320    scale_factors 
-00017c70: 3d20 696e 7075 7473 5b32 5d0a 0a20 2020  = inputs[2]..   
-00017c80: 2069 6620 280a 2020 2020 2020 2020 7363   if (.        sc
-00017c90: 616c 655f 6661 6374 6f72 7320 6973 206e  ale_factors is n
-00017ca0: 6f74 204e 6f6e 650a 2020 2020 2020 2020  ot None.        
-00017cb0: 616e 6420 7363 616c 655f 6661 6374 6f72  and scale_factor
-00017cc0: 732e 7661 6c20 6973 206e 6f74 204e 6f6e  s.val is not Non
-00017cd0: 650a 2020 2020 2020 2020 616e 6420 7363  e.        and sc
-00017ce0: 616c 655f 6661 6374 6f72 732e 7261 6e6b  ale_factors.rank
-00017cf0: 203d 3d20 310a 2020 2020 2020 2020 616e   == 1.        an
-00017d00: 6420 7363 616c 655f 6661 6374 6f72 732e  d scale_factors.
-00017d10: 7368 6170 655b 305d 203d 3d20 320a 2020  shape[0] == 2.  
-00017d20: 2020 293a 0a20 2020 2020 2020 2023 2067    ):.        # g
-00017d30: 6574 2073 6361 6c65 2066 6163 746f 7273  et scale factors
-00017d40: 2066 726f 6d20 7072 6f76 6964 6564 2069   from provided i
-00017d50: 6e70 7574 730a 2020 2020 2020 2020 7363  nputs.        sc
-00017d60: 616c 655f 6661 6374 6f72 7320 3d20 7363  ale_factors = sc
-00017d70: 616c 655f 6661 6374 6f72 732e 7661 6c0a  ale_factors.val.
-00017d80: 2020 2020 2020 2020 7363 616c 6573 5f68          scales_h
-00017d90: 203d 2073 6361 6c65 5f66 6163 746f 7273   = scale_factors
-00017da0: 5b30 5d0a 2020 2020 2020 2020 7363 616c  [0].        scal
-00017db0: 6573 5f77 203d 2073 6361 6c65 5f66 6163  es_w = scale_fac
-00017dc0: 746f 7273 5b31 5d0a 2020 2020 656c 6966  tors[1].    elif
-00017dd0: 2028 0a20 2020 2020 2020 2069 7369 6e73   (.        isins
-00017de0: 7461 6e63 6528 6f75 7470 7574 5f73 697a  tance(output_siz
-00017df0: 652c 206c 6973 7429 0a20 2020 2020 2020  e, list).       
-00017e00: 2061 6e64 206f 7574 7075 745f 7369 7a65   and output_size
-00017e10: 5b30 5d2e 7661 6c20 6973 204e 6f6e 650a  [0].val is None.
-00017e20: 2020 2020 2020 2020 616e 6420 6f75 7470          and outp
-00017e30: 7574 5f73 697a 655b 315d 2e76 616c 2069  ut_size[1].val i
-00017e40: 7320 4e6f 6e65 0a20 2020 2029 3a0a 2020  s None.    ):.  
-00017e50: 2020 2020 2020 2320 7468 6520 696e 7075        # the inpu
-00017e60: 7420 7368 6170 6520 6973 2064 796e 616d  t shape is dynam
-00017e70: 6963 2061 6e64 2072 6563 6f6d 7075 7465  ic and recompute
-00017e80: 5f73 6361 6c65 5f66 6163 746f 7220 3d20  _scale_factor = 
-00017e90: 5472 7565 0a20 2020 2020 2020 2023 206e  True.        # n
-00017ea0: 6565 6420 746f 2074 7261 6365 2074 6865  eed to trace the
-00017eb0: 2067 7261 7068 2074 6f20 6669 6e64 2074   graph to find t
-00017ec0: 6865 2073 6361 6c65 2066 6163 746f 720a  he scale factor.
-00017ed0: 2020 2020 2020 2020 2320 7765 2064 6566          # we def
-00017ee0: 696e 6520 6120 746f 7263 6820 6672 6f6e  ine a torch fron
-00017ef0: 7420 656e 6420 6f70 206d 622e 746f 7263  t end op mb.torc
-00017f00: 685f 7570 7361 6d70 6c65 5f6e 6561 7265  h_upsample_neare
-00017f10: 7374 5f6e 6569 6768 626f 7220 746f 2072  st_neighbor to r
-00017f20: 6573 6f6c 7665 2074 6865 2063 6f6e 7374  esolve the const
-00017f30: 2073 6361 6c69 6e67 2066 6163 746f 720a   scaling factor.
-00017f40: 2020 2020 2020 2020 746f 7263 685f 7570          torch_up
-00017f50: 7361 6d70 6c65 5f6e 6561 7265 7374 3264  sample_nearest2d
-00017f60: 203d 206d 622e 746f 7263 685f 7570 7361   = mb.torch_upsa
-00017f70: 6d70 6c65 5f6e 6561 7265 7374 5f6e 6569  mple_nearest_nei
-00017f80: 6768 626f 7228 0a20 2020 2020 2020 2020  ghbor(.         
-00017f90: 2020 2078 3d5f 696e 7075 742c 0a20 2020     x=_input,.   
-00017fa0: 2020 2020 2020 2020 206f 7574 7075 745f           output_
-00017fb0: 6865 6967 6874 3d6f 7574 7075 745f 7369  height=output_si
-00017fc0: 7a65 5b30 5d2c 0a20 2020 2020 2020 2020  ze[0],.         
-00017fd0: 2020 206f 7574 7075 745f 7769 6474 683d     output_width=
-00017fe0: 6f75 7470 7574 5f73 697a 655b 315d 2c0a  output_size[1],.
-00017ff0: 2020 2020 2020 2020 2020 2020 6e61 6d65              name
-00018000: 3d6e 6f64 652e 6e61 6d65 2c0a 2020 2020  =node.name,.    
-00018010: 2020 2020 290a 2020 2020 2020 2020 636f      ).        co
-00018020: 6e74 6578 742e 6164 6428 746f 7263 685f  ntext.add(torch_
-00018030: 7570 7361 6d70 6c65 5f6e 6561 7265 7374  upsample_nearest
-00018040: 3264 290a 2020 2020 2020 2020 7265 7475  2d).        retu
-00018050: 726e 0a20 2020 2065 6c73 653a 0a20 2020  rn.    else:.   
-00018060: 2020 2020 2023 2069 6e66 6572 2073 6361       # infer sca
-00018070: 6c65 2066 6163 746f 7273 2066 726f 6d20  le factors from 
-00018080: 6f75 7470 7574 2073 697a 6573 0a20 2020  output sizes.   
-00018090: 2020 2020 2073 6361 6c65 7320 3d20 5f67       scales = _g
-000180a0: 6574 5f73 6361 6c65 735f 6672 6f6d 5f6f  et_scales_from_o
-000180b0: 7574 7075 745f 7369 7a65 286f 7574 7075  utput_size(outpu
-000180c0: 745f 7369 7a65 2c20 5f69 6e70 7574 2e73  t_size, _input.s
-000180d0: 6861 7065 290a 2020 2020 2020 2020 6966  hape).        if
-000180e0: 2073 6361 6c65 733a 0a20 2020 2020 2020   scales:.       
-000180f0: 2020 2020 2073 6361 6c65 735f 682c 2073       scales_h, s
-00018100: 6361 6c65 735f 7720 3d20 7363 616c 6573  cales_w = scales
-00018110: 0a0a 2020 2020 6966 2073 6361 6c65 735f  ..    if scales_
-00018120: 6820 6973 204e 6f6e 6520 6f72 2073 6361  h is None or sca
-00018130: 6c65 735f 7720 6973 204e 6f6e 653a 0a20  les_w is None:. 
-00018140: 2020 2020 2020 2069 6620 6c65 6e28 696e         if len(in
-00018150: 7075 7473 2920 3d3d 2035 3a0a 2020 2020  puts) == 5:.    
-00018160: 2020 2020 2020 2020 2320 466f 7220 746f          # For to
-00018170: 7263 683d 3d31 2e35 2e30 2c20 7570 7361  rch==1.5.0, upsa
-00018180: 6d70 6c65 5f62 696c 696e 6561 7232 6420  mple_bilinear2d 
-00018190: 6861 7320 3520 696e 7075 7473 2e0a 2020  has 5 inputs..  
-000181a0: 2020 2020 2020 2020 2020 7363 616c 6573            scales
-000181b0: 5f68 203d 2069 6e70 7574 735b 335d 0a20  _h = inputs[3]. 
-000181c0: 2020 2020 2020 2020 2020 2073 6361 6c65             scale
-000181d0: 735f 7720 3d20 696e 7075 7473 5b34 5d0a  s_w = inputs[4].
-000181e0: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
-000181f0: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
-00018200: 5661 6c75 6545 7272 6f72 2822 4661 696c  ValueError("Fail
-00018210: 6564 2074 6f20 696e 6665 7220 7363 616c  ed to infer scal
-00018220: 6520 6661 6374 6f72 7320 6672 6f6d 2069  e factors from i
-00018230: 6e70 7574 732e 2229 0a0a 2020 2020 7570  nputs.")..    up
-00018240: 7361 6d70 6c65 5f6e 6561 7265 7374 3264  sample_nearest2d
-00018250: 203d 206d 622e 7570 7361 6d70 6c65 5f6e   = mb.upsample_n
-00018260: 6561 7265 7374 5f6e 6569 6768 626f 7228  earest_neighbor(
-00018270: 0a20 2020 2020 2020 2078 3d5f 696e 7075  .        x=_inpu
-00018280: 742c 0a20 2020 2020 2020 2073 6361 6c65  t,.        scale
-00018290: 5f66 6163 746f 725f 6865 6967 6874 3d73  _factor_height=s
-000182a0: 6361 6c65 735f 682c 0a20 2020 2020 2020  cales_h,.       
-000182b0: 2073 6361 6c65 5f66 6163 746f 725f 7769   scale_factor_wi
-000182c0: 6474 683d 7363 616c 6573 5f77 2c0a 2020  dth=scales_w,.  
-000182d0: 2020 2020 2020 6e61 6d65 3d6e 6f64 652e        name=node.
-000182e0: 6e61 6d65 2c0a 2020 2020 290a 2020 2020  name,.    ).    
-000182f0: 636f 6e74 6578 742e 6164 6428 7570 7361  context.add(upsa
-00018300: 6d70 6c65 5f6e 6561 7265 7374 3264 290a  mple_nearest2d).
-00018310: 0a0a 4072 6567 6973 7465 725f 746f 7263  ..@register_torc
-00018320: 685f 6f70 2874 6f72 6368 5f61 6c69 6173  h_op(torch_alias
-00018330: 3d5b 226c 6973 7475 6e70 6163 6b22 5d29  =["listunpack"])
-00018340: 0a64 6566 2074 7570 6c65 756e 7061 636b  .def tupleunpack
-00018350: 2863 6f6e 7465 7874 2c20 6e6f 6465 293a  (context, node):
-00018360: 0a20 2020 2069 6e70 7574 7320 3d20 5f67  .    inputs = _g
-00018370: 6574 5f69 6e70 7574 7328 636f 6e74 6578  et_inputs(contex
-00018380: 742c 206e 6f64 652c 2065 7870 6563 7465  t, node, expecte
-00018390: 643d 3129 0a20 2020 2076 616c 7565 7320  d=1).    values 
-000183a0: 3d20 696e 7075 7473 5b30 5d0a 0a20 2020  = inputs[0]..   
-000183b0: 2023 204e 6f64 6520 696e 7075 7420 636f   # Node input co
-000183c0: 756c 6420 6861 7665 2062 6565 6e20 7475  uld have been tu
-000183d0: 726e 6564 2069 6e74 6f20 636f 6e73 7461  rned into consta
-000183e0: 6e74 2061 7272 6179 2069 6e20 4074 7570  nt array in @tup
-000183f0: 6c65 636f 6e73 7472 7563 740a 2020 2020  leconstruct.    
-00018400: 6966 206e 6f74 2069 7369 6e73 7461 6e63  if not isinstanc
-00018410: 6528 7661 6c75 6573 2c20 2874 7570 6c65  e(values, (tuple
-00018420: 2c20 6c69 7374 2929 3a0a 2020 2020 2020  , list)):.      
-00018430: 2020 6966 2076 616c 7565 732e 7661 6c20    if values.val 
-00018440: 6973 206e 6f74 204e 6f6e 653a 0a20 2020  is not None:.   
-00018450: 2020 2020 2020 2020 2076 616c 7565 7320           values 
-00018460: 3d20 7661 6c75 6573 2e76 616c 0a20 2020  = values.val.   
-00018470: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
-00018480: 2020 2020 2020 2023 2054 6865 2060 7661         # The `va
-00018490: 6c75 6573 6020 636f 756c 6420 6265 2061  lues` could be a
-000184a0: 2073 696e 676c 6520 5661 7220 7769 7468   single Var with
-000184b0: 2073 796d 626f 6c69 6320 7661 6c2e 0a20   symbolic val.. 
-000184c0: 2020 2020 2020 2020 2020 2076 616c 7565             value
-000184d0: 7320 3d20 5b76 616c 7565 735d 0a0a 2020  s = [values]..  
-000184e0: 2020 6966 206c 656e 2876 616c 7565 7329    if len(values)
-000184f0: 2021 3d20 6c65 6e28 6e6f 6465 2e6f 7574   != len(node.out
-00018500: 7075 7473 293a 0a20 2020 2020 2020 2072  puts):.        r
-00018510: 6169 7365 2056 616c 7565 4572 726f 7228  aise ValueError(
-00018520: 6622 756e 7061 636b 206e 6f64 6520 6578  f"unpack node ex
-00018530: 7065 6374 6564 207b 6c65 6e28 6e6f 6465  pected {len(node
-00018540: 2e6f 7574 7075 7473 297d 206f 7574 7075  .outputs)} outpu
-00018550: 7473 2c20 676f 7420 7b6c 656e 2876 616c  ts, got {len(val
-00018560: 7565 7329 7d22 290a 0a20 2020 2023 2040  ues)}")..    # @
-00018570: 7661 6c75 6520 6973 2065 6974 6865 7220  value is either 
-00018580: 6120 6e75 6d70 7920 7072 696d 6974 6976  a numpy primitiv
-00018590: 6520 6f72 2061 2056 6172 206f 626a 6563  e or a Var objec
-000185a0: 740a 2020 2020 666f 7220 7661 6c75 652c  t.    for value,
-000185b0: 206f 7574 7075 7420 696e 207a 6970 2876   output in zip(v
-000185c0: 616c 7565 732c 206e 6f64 652e 6f75 7470  alues, node.outp
-000185d0: 7574 7329 3a0a 2020 2020 2020 2020 6966  uts):.        if
-000185e0: 206e 6f74 2069 7369 6e73 7461 6e63 6528   not isinstance(
-000185f0: 7661 6c75 652c 2056 6172 293a 0a20 2020  value, Var):.   
-00018600: 2020 2020 2020 2020 2076 616c 7565 203d           value =
-00018610: 205f 636f 6e73 7472 7563 745f 636f 6e73   _construct_cons
-00018620: 7461 6e74 2876 616c 7565 2c20 6e61 6d65  tant(value, name
-00018630: 3d6f 7574 7075 7429 0a20 2020 2020 2020  =output).       
-00018640: 2061 7373 6572 7420 6973 696e 7374 616e   assert isinstan
-00018650: 6365 2876 616c 7565 2c20 5661 7229 0a20  ce(value, Var). 
-00018660: 2020 2020 2020 2063 6f6e 7465 7874 2e61         context.a
-00018670: 6464 2876 616c 7565 2c20 6f75 7470 7574  dd(value, output
-00018680: 290a 0a0a 4072 6567 6973 7465 725f 746f  )...@register_to
-00018690: 7263 685f 6f70 0a64 6566 206c 6f6f 7028  rch_op.def loop(
-000186a0: 636f 6e74 6578 742c 206e 6f64 6529 3a0a  context, node):.
-000186b0: 2020 2020 2222 2220 496e 2054 6f72 6368      """ In Torch
-000186c0: 4952 2c20 6120 6c6f 6f70 206c 6f6f 6b73  IR, a loop looks
-000186d0: 206c 696b 653a 0a20 2020 2020 2020 2020   like:.         
-000186e0: 2020 2025 795f 312c 202e 2e2e 2c20 2579     %y_1, ..., %y
-000186f0: 5f72 203d 2070 7269 6d3a 3a4c 6f6f 7028  _r = prim::Loop(
-00018700: 256d 6178 5f74 7269 705f 636f 756e 742c  %max_trip_count,
-00018710: 2025 696e 6974 6961 6c5f 636f 6e64 6974   %initial_condit
-00018720: 696f 6e2c 2025 785f 312c 202e 2e2e 2c20  ion, %x_1, ..., 
-00018730: 2578 5f72 290a 2020 2020 2020 2020 2020  %x_r).          
-00018740: 2020 626c 6f63 6b30 2825 692c 2025 615f    block0(%i, %a_
-00018750: 312c 202e 2e2e 2c20 2561 5f72 293a 0a20  1, ..., %a_r):. 
-00018760: 2020 2020 2020 2020 2020 2020 2020 2025                 %
-00018770: 625f 312c 202e 2e2e 2c20 2562 5f6d 203d  b_1, ..., %b_m =
-00018780: 2073 6f6d 653a 3a6e 6f64 6528 2561 5f76   some::node(%a_v
-00018790: 616c 7565 5f66 726f 6d5f 6f75 7465 725f  alue_from_outer_
-000187a0: 626c 6f63 6b2c 2025 615f 3129 0a20 2020  block, %a_1).   
-000187b0: 2020 2020 2020 2020 2020 2020 2025 6974               %it
-000187c0: 6572 5f63 6f6e 6469 7469 6f6e 203d 2073  er_condition = s
-000187d0: 6f6d 653a 3a6f 7468 6572 5f6e 6f64 6528  ome::other_node(
-000187e0: 2561 5f32 290a 2020 2020 2020 2020 2020  %a_2).          
-000187f0: 2020 2020 2020 2d3e 2028 2569 7465 725f        -> (%iter_
-00018800: 636f 6e64 6974 696f 6e2c 2025 625f 312c  condition, %b_1,
-00018810: 202e 2e2e 2c20 2562 5f72 290a 0a20 2020   ..., %b_r)..   
-00018820: 2020 2020 2054 6869 7320 7472 616e 736c       This transl
-00018830: 6174 6573 2074 6f20 7073 6575 646f 2063  ates to pseudo c
-00018840: 6f64 6520 6173 3a0a 2020 2020 2020 2020  ode as:.        
-00018850: 2020 2020 795f 312c 202e 2e2e 2c20 795f      y_1, ..., y_
-00018860: 7220 3d20 785f 312c 202e 2e2e 2c20 785f  r = x_1, ..., x_
-00018870: 720a 2020 2020 2020 2020 2020 2020 636f  r.            co
-00018880: 6e64 6974 696f 6e20 3d20 696e 6974 6961  ndition = initia
-00018890: 6c5f 636f 6e64 6974 696f 6e0a 2020 2020  l_condition.    
-000188a0: 2020 2020 2020 2020 6920 3d20 300a 2020          i = 0.  
-000188b0: 2020 2020 2020 2020 2020 7768 696c 6520            while 
-000188c0: 636f 6e64 6974 696f 6e20 616e 6420 6920  condition and i 
-000188d0: 3c20 6d61 785f 7472 6970 5f63 6f75 6e74  < max_trip_count
-000188e0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-000188f0: 2020 615f 312c 202e 2e2e 2c20 615f 7220    a_1, ..., a_r 
-00018900: 3d20 795f 312c 202e 2e2e 2c20 795f 720a  = y_1, ..., y_r.
-00018910: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00018920: 2023 2323 2323 2323 2323 2323 2323 2323   ###############
-00018930: 2323 2323 2323 2323 2323 2323 2323 2323  ################
-00018940: 2323 2323 2323 2323 2323 2323 2323 2323  ################
-00018950: 2323 2323 2323 2323 2323 2323 230a 2020  #############.  
-00018960: 2020 2020 2020 2020 2020 2020 2020 2320                # 
-00018970: 4163 7475 616c 2062 6f64 7920 6f66 2074  Actual body of t
-00018980: 6865 206c 6f6f 700a 2020 2020 2020 2020  he loop.        
-00018990: 2020 2020 2020 2020 625f 312c 202e 2e2e          b_1, ...
-000189a0: 2c20 625f 6d20 3d20 736f 6d65 3a3a 6e6f  , b_m = some::no
-000189b0: 6465 2861 5f76 616c 7565 5f66 726f 6d5f  de(a_value_from_
-000189c0: 6f75 7473 6964 655f 6f66 5f74 6865 5f6c  outside_of_the_l
-000189d0: 6f6f 702c 2061 5f31 290a 2020 2020 2020  oop, a_1).      
-000189e0: 2020 2020 2020 2020 2020 6974 6572 5f63            iter_c
-000189f0: 6f6e 6469 7469 6f6e 203d 2073 6f6d 653a  ondition = some:
-00018a00: 3a6e 6f64 6528 615f 3229 0a20 2020 2020  :node(a_2).     
-00018a10: 2020 2020 2020 2020 2020 2023 2323 2323             #####
-00018a20: 2323 2323 2323 2323 2323 2323 2323 2323  ################
-00018a30: 2323 2323 2323 2323 2323 2323 2323 2323  ################
-00018a40: 2323 2323 2323 2323 2323 2323 2323 2323  ################
-00018a50: 2323 2323 2323 230a 0a20 2020 2020 2020  #######..       
-00018a60: 2020 2020 2020 2020 2079 5f31 2c20 2e2e           y_1, ..
-00018a70: 2e2c 2079 5f72 203d 2062 5f31 2c20 2e2e  ., y_r = b_1, ..
-00018a80: 2e2c 2062 5f72 0a20 2020 2020 2020 2020  ., b_r.         
-00018a90: 2020 2020 2020 2063 6f6e 6469 7469 6f6e         condition
-00018aa0: 203d 2069 7465 725f 636f 6e64 6974 696f   = iter_conditio
-00018ab0: 6e0a 2020 2020 2020 2020 2020 2020 2020  n.              
-00018ac0: 2020 6920 2b3d 2031 0a0a 2020 2020 2020    i += 1..      
-00018ad0: 2020 5768 6963 6820 6675 7274 6865 7220    Which further 
-00018ae0: 7472 616e 736c 6174 6573 2074 6f20 4d49  translates to MI
-00018af0: 4c20 7768 696c 655f 6c6f 6f70 2061 733a  L while_loop as:
-00018b00: 0a20 2020 2020 2020 2020 2020 206c 6f6f  .            loo
-00018b10: 705f 7661 7273 203d 2028 302c 2069 6e69  p_vars = (0, ini
-00018b20: 7469 616c 5f63 6f6e 6469 7469 6f6e 2c20  tial_condition, 
-00018b30: 785f 312c 202e 2e2e 2c20 785f 7229 0a20  x_1, ..., x_r). 
-00018b40: 2020 2020 2020 2020 2020 205f 636f 6e64             _cond
-00018b50: 203d 207b 0a20 2020 2020 2020 2020 2020   = {.           
-00018b60: 2020 2020 2072 6574 7572 6e20 286c 6f6f       return (loo
-00018b70: 705f 7661 7273 5b31 5d20 616e 6420 6c6f  p_vars[1] and lo
-00018b80: 6f70 5f76 6172 735b 305d 203c 206d 6178  op_vars[0] < max
-00018b90: 5f74 7269 705f 636f 756e 7429 0a20 2020  _trip_count).   
-00018ba0: 2020 2020 2020 2020 207d 0a20 2020 2020           }.     
-00018bb0: 2020 2020 2020 205f 626f 6479 203d 207b         _body = {
-00018bc0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00018bd0: 2061 5f31 2c20 2e2e 2e2c 2061 5f72 203d   a_1, ..., a_r =
-00018be0: 206c 6f6f 705f 7661 7273 5b32 5d2c 202e   loop_vars[2], .
-00018bf0: 2e2e 2c20 6c6f 6f70 5f76 6172 735b 2d31  .., loop_vars[-1
-00018c00: 5d0a 2020 2020 2020 2020 2020 2020 2020  ].              
-00018c10: 2020 625f 312c 202e 2e2e 2c20 625f 6d20    b_1, ..., b_m 
-00018c20: 3d20 736f 6d65 3a3a 6e6f 6465 2861 5f76  = some::node(a_v
-00018c30: 616c 7565 5f66 726f 6d5f 6f75 7473 6964  alue_from_outsid
-00018c40: 655f 6f66 5f74 6865 5f6c 6f6f 702c 2061  e_of_the_loop, a
-00018c50: 5f31 290a 2020 2020 2020 2020 2020 2020  _1).            
-00018c60: 2020 2020 6974 6572 5f63 6f6e 6469 7469      iter_conditi
-00018c70: 6f6e 203d 2073 6f6d 653a 3a6e 6f64 6528  on = some::node(
-00018c80: 615f 3229 0a20 2020 2020 2020 2020 2020  a_2).           
-00018c90: 2020 2020 2072 6574 7572 6e20 286c 6f6f       return (loo
-00018ca0: 705f 7661 7273 5b30 5d20 2b20 312c 2069  p_vars[0] + 1, i
-00018cb0: 7465 725f 636f 6e64 6974 696f 6e2c 2062  ter_condition, b
-00018cc0: 5f31 2c20 2e2e 2e2c 2062 5f72 290a 2020  _1, ..., b_r).  
-00018cd0: 2020 2020 2020 2020 2020 7d0a 0a20 2020            }..   
-00018ce0: 2020 2020 2046 6f72 206c 6f6f 7073 2070       For loops p
-00018cf0: 6173 7320 5472 7565 2066 6f72 2025 696e  ass True for %in
-00018d00: 6974 6961 6c5f 636f 6e64 6974 696f 6e20  itial_condition 
-00018d10: 616e 6420 2569 7465 725f 636f 6e64 6974  and %iter_condit
-00018d20: 696f 6e0a 2020 2020 2020 2020 5768 696c  ion.        Whil
-00018d30: 6520 6c6f 6f70 7320 7365 7420 256d 6178  e loops set %max
-00018d40: 5f74 7269 705f 636f 756e 7420 746f 2049  _trip_count to I
-00018d50: 4e54 5f4d 4158 2061 6e64 2025 6920 6973  NT_MAX and %i is
-00018d60: 2075 6e75 7365 640a 2020 2020 2222 220a   unused.    """.
-00018d70: 2020 2020 6e61 6d65 203d 206e 6f64 652e      name = node.
-00018d80: 6e61 6d65 0a20 2020 2023 2069 6e70 7574  name.    # input
-00018d90: 735b 305d 3a20 6d61 7820 6974 6572 2063  s[0]: max iter c
-00018da0: 6f75 6e74 0a20 2020 2023 2069 6e70 7574  ount.    # input
-00018db0: 735b 315d 3a20 696e 6974 6961 6c20 636f  s[1]: initial co
-00018dc0: 6e64 6974 696f 6e0a 2020 2020 2320 696e  ndition.    # in
-00018dd0: 7075 7473 5b32 5d3a 2062 6c6f 636b 2069  puts[2]: block i
-00018de0: 6e70 7574 2030 0a20 2020 2023 202e 2e2e  nput 0.    # ...
-00018df0: 0a20 2020 2023 2069 6e70 7574 735b 4e2b  .    # inputs[N+
-00018e00: 325d 3a20 626c 6f63 6b20 696e 7075 7420  2]: block input 
-00018e10: 4e0a 2020 2020 696e 7075 7473 203d 205f  N.    inputs = _
-00018e20: 6765 745f 696e 7075 7473 2863 6f6e 7465  get_inputs(conte
-00018e30: 7874 2c20 6e6f 6465 290a 2020 2020 6d61  xt, node).    ma
-00018e40: 785f 6974 6572 5f63 6f75 6e74 203d 2069  x_iter_count = i
-00018e50: 6e70 7574 735b 305d 0a0a 2020 2020 2320  nputs[0]..    # 
-00018e60: 4d61 6769 6320 6465 6661 756c 7420 7369  Magic default si
-00018e70: 676e 616c 7320 7468 6973 2069 7320 6120  gnals this is a 
-00018e80: 7768 696c 652d 6f6e 6c79 206c 6f6f 702c  while-only loop,
-00018e90: 2073 6f20 6e6f 2069 7465 7261 7469 6f6e   so no iteration
-00018ea0: 2063 6f75 6e74 0a20 2020 2023 2069 7320   count.    # is 
-00018eb0: 6e65 6564 6564 2e0a 2020 2020 6861 735f  needed..    has_
-00018ec0: 6974 6572 5f63 6f75 6e74 203d 206d 6178  iter_count = max
-00018ed0: 5f69 7465 725f 636f 756e 7420 6973 206e  _iter_count is n
-00018ee0: 6f74 204e 6f6e 650a 0a20 2020 2023 2043  ot None..    # C
-00018ef0: 7265 6174 6520 616e 2069 6e74 6572 6174  reate an interat
-00018f00: 696f 6e20 636f 756e 742e 2054 6869 7320  ion count. This 
-00018f10: 7769 6c6c 206f 6e6c 7920 6265 2075 7365  will only be use
-00018f20: 6420 6966 2074 6869 7320 6973 2061 2066  d if this is a f
-00018f30: 6f72 206c 6f6f 702e 0a20 2020 2069 7465  or loop..    ite
-00018f40: 725f 636f 756e 7420 3d20 6d62 2e63 6f6e  r_count = mb.con
-00018f50: 7374 2876 616c 3d30 2c20 6e61 6d65 3d6e  st(val=0, name=n
-00018f60: 6f64 652e 6e61 6d65 202b 2022 5f69 7465  ode.name + "_ite
-00018f70: 7222 290a 2020 2020 2320 406c 6f6f 705f  r").    # @loop_
-00018f80: 7661 7273 2069 7320 7475 706c 6528 6974  vars is tuple(it
-00018f90: 6572 5f63 6f75 6e74 2c20 636f 6e64 2c20  er_count, cond, 
-00018fa0: 696e 7075 7473 2e2e 2e29 0a20 2020 206c  inputs...).    l
-00018fb0: 6f6f 705f 7661 7273 203d 2074 7570 6c65  oop_vars = tuple
-00018fc0: 285b 6974 6572 5f63 6f75 6e74 5d20 2b20  ([iter_count] + 
-00018fd0: 696e 7075 7473 5b31 3a5d 290a 0a20 2020  inputs[1:])..   
-00018fe0: 2064 6566 205f 6c6f 6f70 5f63 6f6e 6428   def _loop_cond(
-00018ff0: 2a6c 6f6f 705f 7661 7273 293a 0a20 2020  *loop_vars):.   
-00019000: 2020 2020 2063 6f6e 6420 3d20 6c6f 6f70       cond = loop
-00019010: 5f76 6172 735b 315d 0a0a 2020 2020 2020  _vars[1]..      
-00019020: 2020 2320 4368 6563 6b20 7468 6520 6974    # Check the it
-00019030: 6572 6174 696f 6e20 636f 756e 7420 6966  eration count if
-00019040: 2077 6527 7265 206b 6565 7069 6e67 2074   we're keeping t
-00019050: 7261 636b 2e0a 2020 2020 2020 2020 6966  rack..        if
-00019060: 2068 6173 5f69 7465 725f 636f 756e 743a   has_iter_count:
-00019070: 0a20 2020 2020 2020 2020 2020 2069 7465  .            ite
-00019080: 725f 636f 756e 7420 3d20 6c6f 6f70 5f76  r_count = loop_v
-00019090: 6172 735b 305d 0a20 2020 2020 2020 2020  ars[0].         
-000190a0: 2020 2069 7465 725f 636f 6e64 203d 206d     iter_cond = m
-000190b0: 622e 6c65 7373 280a 2020 2020 2020 2020  b.less(.        
-000190c0: 2020 2020 2020 2020 783d 6974 6572 5f63          x=iter_c
-000190d0: 6f75 6e74 2c20 793d 6d61 785f 6974 6572  ount, y=max_iter
-000190e0: 5f63 6f75 6e74 2c20 6e61 6d65 3d6e 6f64  _count, name=nod
-000190f0: 652e 6e61 6d65 202b 2022 5f63 6f6e 6422  e.name + "_cond"
-00019100: 0a20 2020 2020 2020 2020 2020 2029 0a20  .            ). 
-00019110: 2020 2020 2020 2020 2020 2072 6574 7572             retur
-00019120: 6e20 6d62 2e6c 6f67 6963 616c 5f61 6e64  n mb.logical_and
-00019130: 2878 3d63 6f6e 642c 2079 3d69 7465 725f  (x=cond, y=iter_
-00019140: 636f 6e64 290a 2020 2020 2020 2020 656c  cond).        el
-00019150: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
-00019160: 7265 7475 726e 206d 622e 6964 656e 7469  return mb.identi
-00019170: 7479 2878 3d63 6f6e 6429 0a0a 2020 2020  ty(x=cond)..    
-00019180: 6465 6620 5f73 6861 7065 735f 6172 655f  def _shapes_are_
-00019190: 6571 7569 7661 6c65 6e74 2873 6861 7065  equivalent(shape
-000191a0: 312c 2073 6861 7065 3229 3a0a 2020 2020  1, shape2):.    
-000191b0: 2020 2020 2222 2220 436f 6d70 6172 6573      """ Compares
-000191c0: 2074 776f 2073 6574 7320 6f66 2074 656e   two sets of ten
-000191d0: 736f 7220 7368 6170 6573 2061 6e64 2072  sor shapes and r
-000191e0: 6574 7572 6e73 2054 7275 6520 6966 2074  eturns True if t
-000191f0: 6865 7920 6172 650a 2020 2020 2020 2020  hey are.        
-00019200: 2020 2020 6571 7569 7661 6c65 6e74 2e20      equivalent. 
-00019210: 5468 6174 2069 732c 2074 6865 7920 6172  That is, they ar
-00019220: 6520 7468 6520 7361 6d65 2072 616e 6b2c  e the same rank,
-00019230: 2061 6e64 2065 6163 6820 6469 6d65 6e73   and each dimens
-00019240: 696f 6e0a 2020 2020 2020 2020 2020 2020  ion.            
-00019250: 6973 2074 6865 2073 616d 6520 6f72 2073  is the same or s
-00019260: 796d 626f 6c69 632e 0a20 2020 2020 2020  ymbolic..       
-00019270: 2022 2222 0a20 2020 2020 2020 2069 6620   """.        if 
-00019280: 6c65 6e28 7368 6170 6531 2920 213d 206c  len(shape1) != l
-00019290: 656e 2873 6861 7065 3229 3a0a 2020 2020  en(shape2):.    
-000192a0: 2020 2020 2020 2020 7265 7475 726e 2046          return F
-000192b0: 616c 7365 0a0a 2020 2020 2020 2020 2320  alse..        # 
-000192c0: 4561 6368 2064 696d 656e 7369 6f6e 206d  Each dimension m
-000192d0: 7573 7420 6861 7665 2074 6865 2073 616d  ust have the sam
-000192e0: 6520 696e 7465 6765 7220 6c65 6e67 7468  e integer length
-000192f0: 2c20 6f72 2065 6c73 6520 6265 0a20 2020  , or else be.   
-00019300: 2020 2020 2023 2073 796d 626f 6c69 632e       # symbolic.
-00019310: 0a20 2020 2020 2020 2061 6c6c 5f65 7175  .        all_equ
-00019320: 6976 616c 656e 7420 3d20 5b0a 2020 2020  ivalent = [.    
-00019330: 2020 2020 2020 2020 7331 203d 3d20 7332          s1 == s2
-00019340: 206f 7220 2869 7369 6e73 7461 6e63 6528   or (isinstance(
-00019350: 7331 2c20 5379 6d62 6f6c 2920 616e 6420  s1, Symbol) and 
-00019360: 6973 696e 7374 616e 6365 2873 322c 2053  isinstance(s2, S
-00019370: 796d 626f 6c29 290a 2020 2020 2020 2020  ymbol)).        
-00019380: 2020 2020 666f 7220 7331 2c20 7332 2069      for s1, s2 i
-00019390: 6e20 7a69 7028 7368 6170 6531 2c20 7368  n zip(shape1, sh
-000193a0: 6170 6532 290a 2020 2020 2020 2020 5d0a  ape2).        ].
-000193b0: 2020 2020 2020 2020 7265 7475 726e 2061          return a
-000193c0: 6c6c 5f65 7175 6976 616c 656e 740a 0a20  ll_equivalent.. 
-000193d0: 2020 2064 6566 205f 6c6f 6f70 5f62 6f64     def _loop_bod
-000193e0: 7928 2a6c 6f6f 705f 7661 7273 293a 0a20  y(*loop_vars):. 
-000193f0: 2020 2020 2020 2062 6c6f 636b 203d 206e         block = n
-00019400: 6f64 652e 626c 6f63 6b73 5b30 5d0a 2020  ode.blocks[0].  
-00019410: 2020 2020 2020 6974 6572 5f76 6172 203d        iter_var =
-00019420: 206c 6f6f 705f 7661 7273 5b30 5d0a 2020   loop_vars[0].  
-00019430: 2020 2020 2020 696e 7075 7473 203d 2028        inputs = (
-00019440: 6974 6572 5f76 6172 2c29 202b 206c 6f6f  iter_var,) + loo
-00019450: 705f 7661 7273 5b32 3a5d 0a20 2020 2020  p_vars[2:].     
-00019460: 2020 2072 6573 203d 2063 6f6e 7665 7274     res = convert
-00019470: 5f62 6c6f 636b 2863 6f6e 7465 7874 2c20  _block(context, 
-00019480: 626c 6f63 6b2c 2069 6e70 7574 7329 0a0a  block, inputs)..
-00019490: 2020 2020 2020 2020 666f 7220 696e 7075          for inpu
-000194a0: 745f 7661 722c 206f 7574 7075 745f 7661  t_var, output_va
-000194b0: 7220 696e 207a 6970 286c 6f6f 705f 7661  r in zip(loop_va
-000194c0: 7273 5b32 3a5d 2c20 7265 735b 313a 5d29  rs[2:], res[1:])
-000194d0: 3a0a 2020 2020 2020 2020 2020 2020 6966  :.            if
-000194e0: 206e 6f74 205f 7368 6170 6573 5f61 7265   not _shapes_are
-000194f0: 5f65 7175 6976 616c 656e 7428 696e 7075  _equivalent(inpu
-00019500: 745f 7661 722e 7368 6170 652c 206f 7574  t_var.shape, out
-00019510: 7075 745f 7661 722e 7368 6170 6529 3a0a  put_var.shape):.
-00019520: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00019530: 6c6f 6767 6572 2e77 6172 6e69 6e67 280a  logger.warning(.
-00019540: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00019550: 2020 2020 2264 6574 6563 7465 6420 6368      "detected ch
-00019560: 616e 6765 2069 6e20 7368 6170 6520 6f66  ange in shape of
-00019570: 206c 6f6f 7020 7661 7269 6162 6c65 2e20   loop variable. 
-00019580: 7468 6973 2063 6f75 6c64 206c 6561 6420  this could lead 
-00019590: 746f 2069 6e63 6f72 7265 6374 2069 6e66  to incorrect inf
-000195a0: 6572 656e 6365 2072 6573 756c 7473 2122  erence results!"
-000195b0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000195c0: 2029 0a20 2020 2020 2020 2020 2020 2020   ).             
-000195d0: 2020 206c 6f67 6765 722e 7761 726e 696e     logger.warnin
-000195e0: 6728 0a20 2020 2020 2020 2020 2020 2020  g(.             
-000195f0: 2020 2020 2020 2022 7b7d 3a7b 7d20 2d3e         "{}:{} ->
-00019600: 207b 7d3a 7b7d 222e 666f 726d 6174 280a   {}:{}".format(.
-00019610: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00019620: 2020 2020 2020 2020 696e 7075 745f 7661          input_va
-00019630: 722e 6e61 6d65 2c0a 2020 2020 2020 2020  r.name,.        
-00019640: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00019650: 696e 7075 745f 7661 722e 7368 6170 652c  input_var.shape,
-00019660: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00019670: 2020 2020 2020 2020 206f 7574 7075 745f           output_
-00019680: 7661 722e 6e61 6d65 2c0a 2020 2020 2020  var.name,.      
-00019690: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000196a0: 2020 6f75 7470 7574 5f76 6172 2e73 6861    output_var.sha
-000196b0: 7065 2c0a 2020 2020 2020 2020 2020 2020  pe,.            
-000196c0: 2020 2020 2020 2020 290a 2020 2020 2020          ).      
-000196d0: 2020 2020 2020 2020 2020 290a 0a20 2020            )..   
-000196e0: 2020 2020 2023 2055 7064 6174 6520 7468       # Update th
-000196f0: 6520 6974 6572 6174 696f 6e20 636f 756e  e iteration coun
-00019700: 7420 6966 2077 6527 7265 206b 6565 7069  t if we're keepi
-00019710: 6e67 2074 7261 636b 2e0a 2020 2020 2020  ng track..      
-00019720: 2020 6966 2068 6173 5f69 7465 725f 636f    if has_iter_co
-00019730: 756e 743a 0a20 2020 2020 2020 2020 2020  unt:.           
-00019740: 2069 7465 725f 7661 7220 3d20 6d62 2e61   iter_var = mb.a
-00019750: 6464 2878 3d69 7465 725f 7661 722c 2079  dd(x=iter_var, y
-00019760: 3d31 2c20 6e61 6d65 3d69 7465 725f 7661  =1, name=iter_va
-00019770: 722e 6e61 6d65 202b 2022 5f69 6e63 2229  r.name + "_inc")
-00019780: 0a20 2020 2020 2020 2065 6c73 653a 0a20  .        else:. 
-00019790: 2020 2020 2020 2020 2020 2069 7465 725f             iter_
-000197a0: 7661 7220 3d20 6d62 2e69 6465 6e74 6974  var = mb.identit
-000197b0: 7928 783d 6974 6572 5f76 6172 290a 0a20  y(x=iter_var).. 
-000197c0: 2020 2020 2020 2023 204d 7573 7420 7265         # Must re
-000197d0: 7475 726e 2074 7570 6c65 2077 6974 6820  turn tuple with 
-000197e0: 7361 6d65 206c 656e 6774 6820 616e 6420  same length and 
-000197f0: 7479 7065 7320 6173 2040 6c6f 6f70 5f76  types as @loop_v
-00019800: 6172 732e 0a20 2020 2020 2020 2072 6574  ars..        ret
-00019810: 7572 6e20 7475 706c 6528 0a20 2020 2020  urn tuple(.     
-00019820: 2020 2020 2020 205b 0a20 2020 2020 2020         [.       
-00019830: 2020 2020 2020 2020 2069 7465 725f 7661           iter_va
-00019840: 722c 0a20 2020 2020 2020 2020 2020 205d  r,.            ]
-00019850: 0a20 2020 2020 2020 2020 2020 202b 2072  .            + r
-00019860: 6573 0a20 2020 2020 2020 2029 0a0a 2020  es.        )..  
-00019870: 2020 6c6f 6f70 203d 206d 622e 7768 696c    loop = mb.whil
-00019880: 655f 6c6f 6f70 280a 2020 2020 2020 2020  e_loop(.        
-00019890: 5f63 6f6e 643d 5f6c 6f6f 705f 636f 6e64  _cond=_loop_cond
-000198a0: 2c20 5f62 6f64 793d 5f6c 6f6f 705f 626f  , _body=_loop_bo
-000198b0: 6479 2c20 6c6f 6f70 5f76 6172 733d 6c6f  dy, loop_vars=lo
-000198c0: 6f70 5f76 6172 732c 206e 616d 653d 6e61  op_vars, name=na
-000198d0: 6d65 0a20 2020 2029 0a0a 2020 2020 2320  me.    )..    # 
-000198e0: 4d61 6b65 2073 7572 6520 7468 6520 6c6f  Make sure the lo
-000198f0: 6f70 2072 6574 7572 6e65 6420 7468 6520  op returned the 
-00019900: 6578 7065 6374 6564 206e 756d 6265 7220  expected number 
-00019910: 6f66 206f 7574 7075 7473 2e20 4e6f 7465  of outputs. Note
-00019920: 2074 6861 7420 7468 650a 2020 2020 2320   that the.    # 
-00019930: 6669 7273 7420 7477 6f20 6c6f 6f70 206f  first two loop o
-00019940: 7574 7075 7473 2061 7265 2074 6865 2069  utputs are the i
-00019950: 7465 7261 7469 6f6e 2063 6f75 6e74 2061  teration count a
-00019960: 6e64 2063 6f6e 6469 7469 6f6e 2e0a 2020  nd condition..  
-00019970: 2020 6173 7365 7274 206c 656e 286c 6f6f    assert len(loo
-00019980: 7029 202d 2032 203d 3d20 6c65 6e28 6e6f  p) - 2 == len(no
-00019990: 6465 2e6f 7574 7075 7473 290a 2020 2020  de.outputs).    
-000199a0: 666f 7220 6f75 7470 7574 5f6e 616d 652c  for output_name,
-000199b0: 206f 7574 7075 745f 7661 7220 696e 207a   output_var in z
-000199c0: 6970 286e 6f64 652e 6f75 7470 7574 732c  ip(node.outputs,
-000199d0: 206c 6f6f 705b 323a 5d29 3a0a 2020 2020   loop[2:]):.    
-000199e0: 2020 2020 636f 6e74 6578 742e 6164 6428      context.add(
-000199f0: 6f75 7470 7574 5f76 6172 2c20 746f 7263  output_var, torc
-00019a00: 685f 6e61 6d65 3d6f 7574 7075 745f 6e61  h_name=output_na
-00019a10: 6d65 290a 0a0a 4072 6567 6973 7465 725f  me)...@register_
-00019a20: 746f 7263 685f 6f70 2874 6f72 6368 5f61  torch_op(torch_a
-00019a30: 6c69 6173 3d5b 2269 6622 5d29 0a64 6566  lias=["if"]).def
-00019a40: 205f 6966 2863 6f6e 7465 7874 2c20 6e6f   _if(context, no
-00019a50: 6465 293a 0a20 2020 2022 2222 2049 6e20  de):.    """ In 
-00019a60: 546f 7263 6849 522c 2061 2063 6f6e 6469  TorchIR, a condi
-00019a70: 7469 6f6e 616c 206c 6f6f 6b73 206c 696b  tional looks lik
-00019a80: 653a 0a20 2020 2020 2020 2020 2020 2025  e:.            %
-00019a90: 795f 312c 202e 2e2e 2c20 2579 5f72 203d  y_1, ..., %y_r =
-00019aa0: 2070 7269 6d3a 3a49 6628 2563 6f6e 6469   prim::If(%condi
-00019ab0: 7469 6f6e 290a 2020 2020 2020 2020 2020  tion).          
-00019ac0: 2020 626c 6f63 6b30 2829 3a20 2023 2054    block0():  # T
-00019ad0: 5255 4520 4252 414e 4348 2c20 6e65 7665  RUE BRANCH, neve
-00019ae0: 7220 7461 6b65 7320 6172 6775 6d65 6e74  r takes argument
-00019af0: 732c 2068 6173 2074 6f20 7265 7475 726e  s, has to return
-00019b00: 2072 206f 7574 7075 7473 0a20 2020 2020   r outputs.     
-00019b10: 2020 2020 2020 2020 2020 2025 745f 312c             %t_1,
-00019b20: 202e 2e2e 2c20 2574 5f6b 203d 2073 6f6d   ..., %t_k = som
-00019b30: 653a 3a6e 6f64 6528 2561 5f76 616c 7565  e::node(%a_value
-00019b40: 5f66 726f 6d5f 6f75 7465 725f 626c 6f63  _from_outer_bloc
-00019b50: 6b29 0a20 2020 2020 2020 2020 2020 2020  k).             
-00019b60: 2020 202d 3e20 2825 745f 312c 202e 2e2e     -> (%t_1, ...
-00019b70: 2c20 2574 5f72 290a 2020 2020 2020 2020  , %t_r).        
-00019b80: 2020 2020 626c 6f63 6b31 2829 3a20 2023      block1():  #
-00019b90: 2046 414c 5345 2042 5241 4e43 482c 206e   FALSE BRANCH, n
-00019ba0: 6576 6572 2074 616b 6573 2061 7267 756d  ever takes argum
-00019bb0: 656e 7473 2c20 6861 7320 746f 2072 6574  ents, has to ret
-00019bc0: 7572 6e20 7220 6f75 7470 7574 730a 2020  urn r outputs.  
-00019bd0: 2020 2020 2020 2020 2020 2020 2020 2566                %f
-00019be0: 5f31 2c20 2e2e 2e2c 2025 665f 6d20 3d20  _1, ..., %f_m = 
-00019bf0: 736f 6d65 3a3a 6e6f 6465 2825 615f 7661  some::node(%a_va
-00019c00: 6c75 655f 6672 6f6d 5f6f 7574 6572 5f62  lue_from_outer_b
-00019c10: 6c6f 636b 290a 2020 2020 2020 2020 2020  lock).          
-00019c20: 2020 2020 2020 2d3e 2028 2566 5f31 2c20        -> (%f_1, 
-00019c30: 2e2e 2e2c 2025 665f 7229 0a0a 2020 2020  ..., %f_r)..    
-00019c40: 2020 2020 5468 6973 2074 7261 6e73 6c61      This transla
-00019c50: 7465 7320 746f 2070 7365 7564 6f20 636f  tes to pseudo co
-00019c60: 6465 2061 733a 0a20 2020 2020 2020 2020  de as:.         
-00019c70: 2020 2069 6620 2863 6f6e 6469 7469 6f6e     if (condition
-00019c80: 293a 0a20 2020 2020 2020 2020 2020 2020  ):.             
-00019c90: 2020 2074 5f31 2c20 2e2e 2e2c 2074 5f6b     t_1, ..., t_k
-00019ca0: 203d 2073 6f6d 653a 3a6e 6f64 6528 615f   = some::node(a_
-00019cb0: 7661 6c75 655f 6672 6f6d 5f6f 7574 6572  value_from_outer
-00019cc0: 5f62 6c6f 636b 290a 2020 2020 2020 2020  _block).        
-00019cd0: 2020 2020 2020 2020 795f 312c 202e 2e2e          y_1, ...
-00019ce0: 2c20 795f 7220 3d20 745f 312c 202e 2e2e  , y_r = t_1, ...
-00019cf0: 2c20 745f 720a 2020 2020 2020 2020 2020  , t_r.          
-00019d00: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
-00019d10: 2020 2020 2020 2020 665f 312c 202e 2e2e          f_1, ...
-00019d20: 2c20 665f 6d20 3d20 736f 6d65 3a3a 6e6f  , f_m = some::no
-00019d30: 6465 2861 5f76 616c 7565 5f66 726f 6d5f  de(a_value_from_
-00019d40: 6f75 7465 725f 626c 6f63 6b29 0a20 2020  outer_block).   
-00019d50: 2020 2020 2020 2020 2020 2020 2079 5f31               y_1
-00019d60: 2c20 2e2e 2e2c 2079 5f72 203d 2066 5f31  , ..., y_r = f_1
-00019d70: 2c20 2e2e 2e2c 2066 5f72 0a0a 2020 2020  , ..., f_r..    
-00019d80: 2020 2020 5768 6963 6820 6675 7274 6865      Which furthe
-00019d90: 7220 7472 616e 736c 6174 6573 2074 6f20  r translates to 
-00019da0: 4d49 4c20 636f 6e64 2061 733a 0a20 2020  MIL cond as:.   
-00019db0: 2020 2020 2020 2020 205f 7472 7565 203d           _true =
-00019dc0: 207b 0a20 2020 2020 2020 2020 2020 2020   {.             
-00019dd0: 2020 2074 5f31 2c20 2e2e 2e2c 2074 5f6b     t_1, ..., t_k
-00019de0: 203d 2073 6f6d 653a 3a6e 6f64 6528 615f   = some::node(a_
-00019df0: 7661 6c75 655f 6672 6f6d 5f6f 7574 6572  value_from_outer
-00019e00: 5f62 6c6f 636b 290a 2020 2020 2020 2020  _block).        
-00019e10: 2020 2020 2020 2020 7265 7475 726e 2028          return (
-00019e20: 745f 312c 202e 2e2e 2c20 745f 7229 0a20  t_1, ..., t_r). 
-00019e30: 2020 2020 2020 2020 2020 207d 0a20 2020             }.   
-00019e40: 2020 2020 2020 2020 205f 6661 6c73 6520           _false 
-00019e50: 3d20 7b0a 2020 2020 2020 2020 2020 2020  = {.            
-00019e60: 2020 2020 665f 312c 202e 2e2e 2c20 665f      f_1, ..., f_
-00019e70: 6d20 3d20 736f 6d65 3a3a 6e6f 6465 2861  m = some::node(a
-00019e80: 5f76 616c 7565 5f66 726f 6d5f 6f75 7465  _value_from_oute
-00019e90: 725f 626c 6f63 6b29 0a20 2020 2020 2020  r_block).       
-00019ea0: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
-00019eb0: 2866 5f31 2c20 2e2e 2e2c 2066 5f6d 290a  (f_1, ..., f_m).
-00019ec0: 2020 2020 2020 2020 2020 2020 7d0a 2020              }.  
-00019ed0: 2020 2222 220a 2020 2020 6e61 6d65 203d    """.    name =
-00019ee0: 206e 6f64 652e 6e61 6d65 0a20 2020 2023   node.name.    #
-00019ef0: 2069 6e70 7574 735b 305d 3a20 636f 6e64   inputs[0]: cond
-00019f00: 6974 696f 6e0a 2020 2020 696e 7075 7473  ition.    inputs
-00019f10: 203d 205f 6765 745f 696e 7075 7473 2863   = _get_inputs(c
-00019f20: 6f6e 7465 7874 2c20 6e6f 6465 2c20 6578  ontext, node, ex
-00019f30: 7065 6374 6564 3d31 290a 2020 2020 636f  pected=1).    co
-00019f40: 6e64 6974 696f 6e20 3d20 696e 7075 7473  ndition = inputs
-00019f50: 5b30 5d0a 0a20 2020 2061 7373 6572 7420  [0]..    assert 
-00019f60: 6c65 6e28 6e6f 6465 2e62 6c6f 636b 7329  len(node.blocks)
-00019f70: 203d 3d20 320a 2020 2020 7472 7565 5f62   == 2.    true_b
-00019f80: 6c6f 636b 203d 206e 6f64 652e 626c 6f63  lock = node.bloc
-00019f90: 6b73 5b30 5d0a 2020 2020 6661 6c73 655f  ks[0].    false_
-00019fa0: 626c 6f63 6b20 3d20 6e6f 6465 2e62 6c6f  block = node.blo
-00019fb0: 636b 735b 315d 0a0a 2020 2020 6465 6620  cks[1]..    def 
-00019fc0: 5f74 7275 655f 7061 7468 2829 3a0a 2020  _true_path():.  
-00019fd0: 2020 2020 2020 7265 7320 3d20 636f 6e76        res = conv
-00019fe0: 6572 745f 626c 6f63 6b28 636f 6e74 6578  ert_block(contex
-00019ff0: 742c 2074 7275 655f 626c 6f63 6b2c 205b  t, true_block, [
-0001a000: 5d29 0a20 2020 2020 2020 2072 6574 7572  ]).        retur
-0001a010: 6e20 7475 706c 6528 7265 7329 0a0a 2020  n tuple(res)..  
-0001a020: 2020 6465 6620 5f66 616c 7365 5f70 6174    def _false_pat
-0001a030: 6828 293a 0a20 2020 2020 2020 2072 6573  h():.        res
-0001a040: 203d 2063 6f6e 7665 7274 5f62 6c6f 636b   = convert_block
-0001a050: 2863 6f6e 7465 7874 2c20 6661 6c73 655f  (context, false_
-0001a060: 626c 6f63 6b2c 205b 5d29 0a20 2020 2020  block, []).     
-0001a070: 2020 2072 6574 7572 6e20 7475 706c 6528     return tuple(
-0001a080: 7265 7329 0a0a 2020 2020 636f 6e64 203d  res)..    cond =
-0001a090: 206d 622e 636f 6e64 280a 2020 2020 2020   mb.cond(.      
-0001a0a0: 2020 7072 6564 3d63 6f6e 6469 7469 6f6e    pred=condition
-0001a0b0: 2c20 5f74 7275 655f 666e 3d5f 7472 7565  , _true_fn=_true
-0001a0c0: 5f70 6174 682c 205f 6661 6c73 655f 666e  _path, _false_fn
-0001a0d0: 3d5f 6661 6c73 655f 7061 7468 2c20 6e61  =_false_path, na
-0001a0e0: 6d65 3d6e 616d 650a 2020 2020 290a 2020  me=name.    ).  
-0001a0f0: 2020 2320 4966 2074 6865 2063 6f6e 6469    # If the condi
-0001a100: 7469 6f6e 206f 6e6c 7920 7265 7475 726e  tion only return
-0001a110: 7320 6f6e 6520 6974 656d 2c20 7772 6170  s one item, wrap
-0001a120: 2069 7420 696e 2061 2074 7570 6c65 2e0a   it in a tuple..
-0001a130: 2020 2020 6966 206e 6f74 2069 7369 6e73      if not isins
-0001a140: 7461 6e63 6528 636f 6e64 2c20 2874 7570  tance(cond, (tup
-0001a150: 6c65 2c20 6c69 7374 2929 3a0a 2020 2020  le, list)):.    
-0001a160: 2020 2020 636f 6e64 203d 2028 636f 6e64      cond = (cond
-0001a170: 2c29 0a0a 2020 2020 2320 4d61 6b65 2073  ,)..    # Make s
-0001a180: 7572 6520 7468 6520 636f 6e64 6974 696f  ure the conditio
-0001a190: 6e20 7265 7475 726e 6564 2074 6865 2065  n returned the e
-0001a1a0: 7870 6563 7465 6420 6e75 6d62 6572 206f  xpected number o
-0001a1b0: 6620 6f75 7470 7574 732e 0a20 2020 2061  f outputs..    a
-0001a1c0: 7373 6572 7420 6c65 6e28 636f 6e64 2920  ssert len(cond) 
-0001a1d0: 3d3d 206c 656e 286e 6f64 652e 6f75 7470  == len(node.outp
-0001a1e0: 7574 7329 0a20 2020 2066 6f72 206f 7574  uts).    for out
-0001a1f0: 7075 745f 6e61 6d65 2c20 6f75 7470 7574  put_name, output
-0001a200: 5f76 6172 2069 6e20 7a69 7028 6e6f 6465  _var in zip(node
-0001a210: 2e6f 7574 7075 7473 2c20 636f 6e64 293a  .outputs, cond):
-0001a220: 0a20 2020 2020 2020 2063 6f6e 7465 7874  .        context
-0001a230: 2e61 6464 286f 7574 7075 745f 7661 722c  .add(output_var,
-0001a240: 2074 6f72 6368 5f6e 616d 653d 6f75 7470   torch_name=outp
-0001a250: 7574 5f6e 616d 6529 0a0a 0a40 7265 6769  ut_name)...@regi
-0001a260: 7374 6572 5f74 6f72 6368 5f6f 700a 6465  ster_torch_op.de
-0001a270: 6620 7365 6c65 6374 2863 6f6e 7465 7874  f select(context
-0001a280: 2c20 6e6f 6465 293a 0a20 2020 2069 6e70  , node):.    inp
-0001a290: 7574 7320 3d20 5f67 6574 5f69 6e70 7574  uts = _get_input
-0001a2a0: 7328 636f 6e74 6578 742c 206e 6f64 652c  s(context, node,
-0001a2b0: 2065 7870 6563 7465 643d 3329 0a20 2020   expected=3).   
-0001a2c0: 205f 696e 7075 7420 3d20 696e 7075 7473   _input = inputs
-0001a2d0: 5b30 5d0a 2020 2020 6469 6d20 3d20 696e  [0].    dim = in
-0001a2e0: 7075 7473 5b31 5d2e 7661 6c0a 2020 2020  puts[1].val.    
-0001a2f0: 696e 6465 7820 3d20 696e 7075 7473 5b32  index = inputs[2
-0001a300: 5d2e 7661 6c0a 0a20 2020 2061 7373 6572  ].val..    asser
-0001a310: 7420 6469 6d2e 7368 6170 6520 3d3d 2028  t dim.shape == (
-0001a320: 290a 2020 2020 6173 7365 7274 2069 6e64  ).    assert ind
-0001a330: 6578 2e73 6861 7065 203d 3d20 2829 0a0a  ex.shape == ()..
-0001a340: 2020 2020 2320 4e4f 5445 3a0a 2020 2020      # NOTE:.    
-0001a350: 2320 4561 6368 2069 6e64 6578 2069 6e20  # Each index in 
-0001a360: 4062 6567 696e 5f61 7272 6179 2f40 656e  @begin_array/@en
-0001a370: 645f 6172 7261 7920 636f 7272 6573 706f  d_array correspo
-0001a380: 6e64 7320 746f 2061 2064 696d 656e 7369  nds to a dimensi
-0001a390: 6f6e 206f 6620 405f 696e 7075 740a 2020  on of @_input.  
-0001a3a0: 2020 2320 4561 6368 2076 616c 206f 6620    # Each val of 
-0001a3b0: 7468 6f73 6520 6172 7261 7973 2063 6f72  those arrays cor
-0001a3c0: 7265 7370 6f6e 6473 2074 6f20 7468 6520  responds to the 
-0001a3d0: 7374 6172 742f 656e 6420 696e 6465 7820  start/end index 
-0001a3e0: 746f 2073 6c69 6365 2069 6e20 7468 6174  to slice in that
-0001a3f0: 2064 696d 656e 7369 6f6e 0a20 2020 2072   dimension.    r
-0001a400: 616e 6b20 3d20 5f69 6e70 7574 2e72 616e  ank = _input.ran
-0001a410: 6b0a 2020 2020 6265 6769 6e5f 6172 7261  k.    begin_arra
-0001a420: 7920 3d20 5b30 5d20 2a20 7261 6e6b 0a20  y = [0] * rank. 
-0001a430: 2020 2062 6567 696e 5f61 7272 6179 5b64     begin_array[d
-0001a440: 696d 5d20 3d20 696e 6465 780a 2020 2020  im] = index.    
-0001a450: 656e 645f 6172 7261 7920 3d20 5b73 2069  end_array = [s i
-0001a460: 6620 6973 696e 7374 616e 6365 2873 2c20  f isinstance(s, 
-0001a470: 696e 7429 2065 6c73 6520 3020 666f 7220  int) else 0 for 
-0001a480: 7320 696e 205f 696e 7075 742e 7368 6170  s in _input.shap
-0001a490: 655d 0a20 2020 2065 6e64 5f6d 6173 6b20  e].    end_mask 
-0001a4a0: 3d20 5b54 7275 655d 202a 2072 616e 6b0a  = [True] * rank.
-0001a4b0: 2020 2020 7371 7565 657a 655f 6d61 736b      squeeze_mask
-0001a4c0: 203d 205b 4661 6c73 655d 202a 2072 616e   = [False] * ran
-0001a4d0: 6b0a 2020 2020 7371 7565 657a 655f 6d61  k.    squeeze_ma
-0001a4e0: 736b 5b64 696d 5d20 3d20 5472 7565 0a0a  sk[dim] = True..
-0001a4f0: 2020 2020 6966 2069 6e64 6578 2021 3d20      if index != 
-0001a500: 2d31 3a0a 2020 2020 2020 2020 656e 645f  -1:.        end_
-0001a510: 6172 7261 795b 6469 6d5d 203d 2069 6e64  array[dim] = ind
-0001a520: 6578 202b 2031 0a20 2020 2020 2020 2065  ex + 1.        e
-0001a530: 6e64 5f6d 6173 6b5b 6469 6d5d 203d 2046  nd_mask[dim] = F
-0001a540: 616c 7365 0a0a 2020 2020 736c 6963 655f  alse..    slice_
-0001a550: 6279 5f69 6e64 6578 203d 206d 622e 736c  by_index = mb.sl
-0001a560: 6963 655f 6279 5f69 6e64 6578 280a 2020  ice_by_index(.  
-0001a570: 2020 2020 2020 783d 5f69 6e70 7574 2c0a        x=_input,.
-0001a580: 2020 2020 2020 2020 6265 6769 6e3d 6265          begin=be
-0001a590: 6769 6e5f 6172 7261 792c 0a20 2020 2020  gin_array,.     
-0001a5a0: 2020 2065 6e64 3d65 6e64 5f61 7272 6179     end=end_array
-0001a5b0: 2c0a 2020 2020 2020 2020 656e 645f 6d61  ,.        end_ma
-0001a5c0: 736b 3d65 6e64 5f6d 6173 6b2c 0a20 2020  sk=end_mask,.   
-0001a5d0: 2020 2020 2073 7175 6565 7a65 5f6d 6173       squeeze_mas
-0001a5e0: 6b3d 7371 7565 657a 655f 6d61 736b 2c0a  k=squeeze_mask,.
-0001a5f0: 2020 2020 2020 2020 6e61 6d65 3d6e 6f64          name=nod
-0001a600: 652e 6e61 6d65 2c0a 2020 2020 290a 2020  e.name,.    ).  
-0001a610: 2020 636f 6e74 6578 742e 6164 6428 736c    context.add(sl
-0001a620: 6963 655f 6279 5f69 6e64 6578 290a 0a0a  ice_by_index)...
-0001a630: 4072 6567 6973 7465 725f 746f 7263 685f  @register_torch_
-0001a640: 6f70 0a64 6566 2074 7970 655f 6173 2863  op.def type_as(c
-0001a650: 6f6e 7465 7874 2c20 6e6f 6465 293a 0a20  ontext, node):. 
-0001a660: 2020 2069 6e70 7574 7320 3d20 5f67 6574     inputs = _get
-0001a670: 5f69 6e70 7574 7328 636f 6e74 6578 742c  _inputs(context,
-0001a680: 206e 6f64 652c 2065 7870 6563 7465 643d   node, expected=
-0001a690: 3229 0a0a 2020 2020 6966 2069 6e70 7574  2)..    if input
-0001a6a0: 735b 305d 2e64 7479 7065 203d 3d20 696e  s[0].dtype == in
-0001a6b0: 7075 7473 5b31 5d2e 6474 7970 653a 0a20  puts[1].dtype:. 
-0001a6c0: 2020 2020 2020 2078 203d 206d 622e 6964         x = mb.id
-0001a6d0: 656e 7469 7479 2878 3d69 6e70 7574 735b  entity(x=inputs[
-0001a6e0: 305d 2c20 6e61 6d65 3d6e 6f64 652e 6e61  0], name=node.na
-0001a6f0: 6d65 290a 2020 2020 656c 7365 3a0a 2020  me).    else:.  
-0001a700: 2020 2020 2020 7820 3d20 696e 7075 7473        x = inputs
-0001a710: 5b30 5d0a 2020 2020 2020 2020 6966 2069  [0].        if i
-0001a720: 6e70 7574 735b 315d 2e64 7479 7065 206e  nputs[1].dtype n
-0001a730: 6f74 2069 6e20 5459 5045 5f54 4f5f 4454  ot in TYPE_TO_DT
-0001a740: 5950 455f 5354 5249 4e47 3a0a 2020 2020  YPE_STRING:.    
-0001a750: 2020 2020 2020 2020 7261 6973 6520 4e6f          raise No
-0001a760: 7449 6d70 6c65 6d65 6e74 6564 4572 726f  tImplementedErro
-0001a770: 7228 0a20 2020 2020 2020 2020 2020 2020  r(.             
-0001a780: 2020 2022 5465 6e73 6f72 2074 7970 6520     "Tensor type 
-0001a790: 7b7d 2063 6173 7420 6973 206e 6f74 2073  {} cast is not s
-0001a7a0: 7570 706f 7274 6564 2e22 2e66 6f72 6d61  upported.".forma
-0001a7b0: 7428 696e 7075 7473 5b31 5d2e 6474 7970  t(inputs[1].dtyp
-0001a7c0: 6529 0a20 2020 2020 2020 2020 2020 2029  e).            )
-0001a7d0: 0a20 2020 2020 2020 2078 203d 206d 622e  .        x = mb.
-0001a7e0: 6361 7374 2878 3d78 2c20 6474 7970 653d  cast(x=x, dtype=
-0001a7f0: 5459 5045 5f54 4f5f 4454 5950 455f 5354  TYPE_TO_DTYPE_ST
-0001a800: 5249 4e47 5b69 6e70 7574 735b 315d 2e64  RING[inputs[1].d
-0001a810: 7479 7065 5d2c 206e 616d 653d 6e6f 6465  type], name=node
-0001a820: 2e6e 616d 6529 0a0a 2020 2020 636f 6e74  .name)..    cont
-0001a830: 6578 742e 6164 6428 7829 0a0a 0a40 7265  ext.add(x)...@re
-0001a840: 6769 7374 6572 5f74 6f72 6368 5f6f 700a  gister_torch_op.
-0001a850: 6465 6620 6e6f 6e7a 6572 6f28 636f 6e74  def nonzero(cont
-0001a860: 6578 742c 206e 6f64 6529 3a0a 2020 2020  ext, node):.    
-0001a870: 696e 7075 7473 203d 205f 6765 745f 696e  inputs = _get_in
-0001a880: 7075 7473 2863 6f6e 7465 7874 2c20 6e6f  puts(context, no
-0001a890: 6465 2c20 6578 7065 6374 6564 3d31 290a  de, expected=1).
-0001a8a0: 2020 2020 7820 3d20 696e 7075 7473 5b30      x = inputs[0
-0001a8b0: 5d0a 2020 2020 6e6f 6e7a 6572 6f20 3d20  ].    nonzero = 
-0001a8c0: 6d62 2e6e 6f6e 5f7a 6572 6f28 783d 782c  mb.non_zero(x=x,
-0001a8d0: 206e 616d 653d 6e6f 6465 2e6e 616d 6529   name=node.name)
-0001a8e0: 0a20 2020 2063 6f6e 7465 7874 2e61 6464  .    context.add
-0001a8f0: 286e 6f6e 7a65 726f 290a 0a0a 6465 6620  (nonzero)...def 
-0001a900: 5f67 6574 5f73 6c69 6365 5f70 6172 616d  _get_slice_param
-0001a910: 7328 636f 6e74 6578 742c 2064 6174 612c  s(context, data,
-0001a920: 2069 6e70 7574 7329 3a0a 2020 2020 7261   inputs):.    ra
-0001a930: 6e6b 203d 2064 6174 612e 7261 6e6b 0a20  nk = data.rank. 
-0001a940: 2020 2062 6567 696e 203d 205b 305d 202a     begin = [0] *
-0001a950: 2072 616e 6b0a 2020 2020 656e 6420 3d20   rank.    end = 
-0001a960: 5b30 5d20 2a20 7261 6e6b 0a20 2020 2073  [0] * rank.    s
-0001a970: 7472 6964 6520 3d20 5b31 5d20 2a20 7261  tride = [1] * ra
-0001a980: 6e6b 0a20 2020 2062 6567 696e 5f6d 6173  nk.    begin_mas
-0001a990: 6b20 3d20 5b46 616c 7365 5d20 2a20 7261  k = [False] * ra
-0001a9a0: 6e6b 0a20 2020 2065 6e64 5f6d 6173 6b20  nk.    end_mask 
-0001a9b0: 3d20 5b46 616c 7365 5d20 2a20 7261 6e6b  = [False] * rank
-0001a9c0: 0a20 2020 2073 7175 6565 7a65 5f6d 6173  .    squeeze_mas
-0001a9d0: 6b20 3d20 5b46 616c 7365 5d20 2a20 7261  k = [False] * ra
-0001a9e0: 6e6b 0a0a 2020 2020 6e75 6d5f 6f66 5f73  nk..    num_of_s
-0001a9f0: 6c69 6365 5f73 6574 203d 206c 656e 2869  lice_set = len(i
-0001aa00: 6e70 7574 7329 202f 2f20 330a 0a20 2020  nputs) // 3..   
-0001aa10: 2066 6f72 2069 2069 6e20 7261 6e67 6528   for i in range(
-0001aa20: 6e75 6d5f 6f66 5f73 6c69 6365 5f73 6574  num_of_slice_set
-0001aa30: 293a 0a20 2020 2020 2020 2069 6620 696e  ):.        if in
-0001aa40: 7075 7473 5b33 202a 2069 202b 2031 5d20  puts[3 * i + 1] 
-0001aa50: 6973 204e 6f6e 653a 0a20 2020 2020 2020  is None:.       
-0001aa60: 2020 2020 2023 2054 6869 7320 6973 2070       # This is p
-0001aa70: 7572 6520 696e 6465 7820 7365 6c65 6374  ure index select
-0001aa80: 0a20 2020 2020 2020 2020 2020 2069 6478  .            idx
-0001aa90: 203d 2063 6f6e 7465 7874 5b69 6e70 7574   = context[input
-0001aaa0: 735b 3320 2a20 695d 5d2e 7661 6c0a 2020  s[3 * i]].val.  
-0001aab0: 2020 2020 2020 2020 2020 6265 6769 6e5b            begin[
-0001aac0: 695d 203d 2069 6478 0a20 2020 2020 2020  i] = idx.       
-0001aad0: 2020 2020 2073 7175 6565 7a65 5f6d 6173       squeeze_mas
-0001aae0: 6b5b 695d 203d 2054 7275 650a 2020 2020  k[i] = True.    
-0001aaf0: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
-0001ab00: 2020 2020 2020 2320 5468 6973 2069 7320        # This is 
-0001ab10: 6120 736c 6963 650a 2020 2020 2020 2020  a slice.        
-0001ab20: 2020 2020 6265 6769 6e5f 7661 7220 3d20      begin_var = 
-0001ab30: 636f 6e74 6578 745b 696e 7075 7473 5b33  context[inputs[3
-0001ab40: 202a 2069 5d5d 0a20 2020 2020 2020 2020   * i]].         
-0001ab50: 2020 2065 6e64 5f76 6172 203d 2063 6f6e     end_var = con
-0001ab60: 7465 7874 5b69 6e70 7574 735b 3320 2a20  text[inputs[3 * 
-0001ab70: 6920 2b20 315d 5d0a 2020 2020 2020 2020  i + 1]].        
-0001ab80: 2020 2020 7374 7269 6465 5f76 6172 203d      stride_var =
-0001ab90: 2063 6f6e 7465 7874 5b69 6e70 7574 735b   context[inputs[
-0001aba0: 3320 2a20 6920 2b20 325d 5d0a 0a20 2020  3 * i + 2]]..   
-0001abb0: 2020 2020 2020 2020 2069 6620 6265 6769           if begi
-0001abc0: 6e5f 7661 7220 6973 204e 6f6e 653a 0a20  n_var is None:. 
-0001abd0: 2020 2020 2020 2020 2020 2020 2020 2062                 b
-0001abe0: 6567 696e 5f6d 6173 6b5b 695d 203d 2054  egin_mask[i] = T
-0001abf0: 7275 650a 2020 2020 2020 2020 2020 2020  rue.            
-0001ac00: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
-0001ac10: 2020 2020 2020 6265 6769 6e5b 695d 203d        begin[i] =
-0001ac20: 2062 6567 696e 5f76 6172 0a0a 2020 2020   begin_var..    
-0001ac30: 2020 2020 2020 2020 6966 2065 6e64 5f76          if end_v
-0001ac40: 6172 2069 7320 4e6f 6e65 3a0a 2020 2020  ar is None:.    
-0001ac50: 2020 2020 2020 2020 2020 2020 656e 645f              end_
-0001ac60: 6d61 736b 5b69 5d20 3d20 5472 7565 0a20  mask[i] = True. 
-0001ac70: 2020 2020 2020 2020 2020 2065 6c73 653a             else:
-0001ac80: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001ac90: 2065 6e64 5b69 5d20 3d20 656e 645f 7661   end[i] = end_va
-0001aca0: 720a 0a20 2020 2020 2020 2020 2020 2069  r..            i
-0001acb0: 6620 7374 7269 6465 5f76 6172 2069 7320  f stride_var is 
-0001acc0: 4e6f 6e65 3a0a 2020 2020 2020 2020 2020  None:.          
-0001acd0: 2020 2020 2020 7374 7269 6465 5b69 5d20        stride[i] 
-0001ace0: 3d20 310a 2020 2020 2020 2020 2020 2020  = 1.            
-0001acf0: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
-0001ad00: 2020 2020 2020 7374 7269 6465 5b69 5d20        stride[i] 
-0001ad10: 3d20 7374 7269 6465 5f76 6172 2e76 616c  = stride_var.val
-0001ad20: 0a0a 2020 2020 666f 7220 6920 696e 2072  ..    for i in r
-0001ad30: 616e 6765 286e 756d 5f6f 665f 736c 6963  ange(num_of_slic
-0001ad40: 655f 7365 742c 2072 616e 6b29 3a0a 2020  e_set, rank):.  
-0001ad50: 2020 2020 2020 6265 6769 6e5f 6d61 736b        begin_mask
-0001ad60: 5b69 5d20 3d20 5472 7565 0a20 2020 2020  [i] = True.     
-0001ad70: 2020 2065 6e64 5f6d 6173 6b5b 695d 203d     end_mask[i] =
-0001ad80: 2054 7275 650a 0a20 2020 2062 6567 696e   True..    begin
-0001ad90: 203d 206d 622e 636f 6e63 6174 2876 616c   = mb.concat(val
-0001ada0: 7565 733d 6265 6769 6e2c 2061 7869 733d  ues=begin, axis=
-0001adb0: 3029 0a20 2020 2065 6e64 203d 206d 622e  0).    end = mb.
-0001adc0: 636f 6e63 6174 2876 616c 7565 733d 656e  concat(values=en
-0001add0: 642c 2061 7869 733d 3029 0a0a 2020 2020  d, axis=0)..    
-0001ade0: 7265 7475 726e 2062 6567 696e 2c20 656e  return begin, en
-0001adf0: 642c 2073 7472 6964 652c 2062 6567 696e  d, stride, begin
-0001ae00: 5f6d 6173 6b2c 2065 6e64 5f6d 6173 6b2c  _mask, end_mask,
-0001ae10: 2073 7175 6565 7a65 5f6d 6173 6b0a 0a0a   squeeze_mask...
-0001ae20: 4072 6567 6973 7465 725f 746f 7263 685f  @register_torch_
-0001ae30: 6f70 0a64 6566 205f 696e 7465 726e 616c  op.def _internal
-0001ae40: 5f6f 705f 7465 6e73 6f72 5f69 6e70 6c61  _op_tensor_inpla
-0001ae50: 6365 5f63 6f70 7928 636f 6e74 6578 742c  ce_copy(context,
-0001ae60: 206e 6f64 6529 3a0a 2020 2020 6461 7461   node):.    data
-0001ae70: 203d 2063 6f6e 7465 7874 5b6e 6f64 652e   = context[node.
-0001ae80: 696e 7075 7473 5b30 5d5d 0a20 2020 2075  inputs[0]].    u
-0001ae90: 7064 6174 6573 203d 2063 6f6e 7465 7874  pdates = context
-0001aea0: 5b6e 6f64 652e 696e 7075 7473 5b31 5d5d  [node.inputs[1]]
-0001aeb0: 0a20 2020 2062 6567 696e 2c20 656e 642c  .    begin, end,
-0001aec0: 2073 7472 6964 652c 2062 6567 696e 5f6d   stride, begin_m
-0001aed0: 6173 6b2c 2065 6e64 5f6d 6173 6b2c 2073  ask, end_mask, s
-0001aee0: 7175 6565 7a65 5f6d 6173 6b20 3d20 5f67  queeze_mask = _g
-0001aef0: 6574 5f73 6c69 6365 5f70 6172 616d 7328  et_slice_params(
-0001af00: 0a20 2020 2020 2020 2063 6f6e 7465 7874  .        context
-0001af10: 2c20 6461 7461 2c20 6e6f 6465 2e69 6e70  , data, node.inp
-0001af20: 7574 735b 323a 5d0a 2020 2020 290a 0a20  uts[2:].    ).. 
-0001af30: 2020 2064 6174 612c 2075 7064 6174 6573     data, updates
-0001af40: 203d 2070 726f 6d6f 7465 5f69 6e70 7574   = promote_input
-0001af50: 5f64 7479 7065 7328 5b64 6174 612c 2075  _dtypes([data, u
-0001af60: 7064 6174 6573 5d29 0a20 2020 2075 7064  pdates]).    upd
-0001af70: 6174 6564 5f78 203d 206d 622e 746f 7263  ated_x = mb.torc
-0001af80: 685f 7465 6e73 6f72 5f61 7373 6967 6e28  h_tensor_assign(
-0001af90: 0a20 2020 2020 2020 2064 6174 613d 6461  .        data=da
-0001afa0: 7461 2c0a 2020 2020 2020 2020 7570 6461  ta,.        upda
-0001afb0: 7465 733d 7570 6461 7465 732c 0a20 2020  tes=updates,.   
-0001afc0: 2020 2020 2062 6567 696e 3d62 6567 696e       begin=begin
-0001afd0: 2c0a 2020 2020 2020 2020 656e 643d 656e  ,.        end=en
-0001afe0: 642c 0a20 2020 2020 2020 2073 7472 6964  d,.        strid
-0001aff0: 653d 7374 7269 6465 2c0a 2020 2020 2020  e=stride,.      
-0001b000: 2020 6265 6769 6e5f 6d61 736b 3d62 6567    begin_mask=beg
-0001b010: 696e 5f6d 6173 6b2c 0a20 2020 2020 2020  in_mask,.       
-0001b020: 2065 6e64 5f6d 6173 6b3d 656e 645f 6d61   end_mask=end_ma
-0001b030: 736b 2c0a 2020 2020 2020 2020 7371 7565  sk,.        sque
-0001b040: 657a 655f 6d61 736b 3d73 7175 6565 7a65  eze_mask=squeeze
-0001b050: 5f6d 6173 6b2c 0a20 2020 2020 2020 206e  _mask,.        n
-0001b060: 616d 653d 6e6f 6465 2e6e 616d 652c 0a20  ame=node.name,. 
-0001b070: 2020 2029 0a20 2020 2063 6f6e 7465 7874     ).    context
-0001b080: 2e61 6464 2875 7064 6174 6564 5f78 290a  .add(updated_x).
-0001b090: 0a0a 4072 6567 6973 7465 725f 746f 7263  ..@register_torc
-0001b0a0: 685f 6f70 0a64 6566 205f 696e 7465 726e  h_op.def _intern
-0001b0b0: 616c 5f6f 705f 7465 6e73 6f72 5f69 6e70  al_op_tensor_inp
-0001b0c0: 6c61 6365 5f66 696c 6c28 636f 6e74 6578  lace_fill(contex
-0001b0d0: 742c 206e 6f64 6529 3a0a 2020 2020 6461  t, node):.    da
-0001b0e0: 7461 203d 2063 6f6e 7465 7874 5b6e 6f64  ta = context[nod
-0001b0f0: 652e 696e 7075 7473 5b30 5d5d 0a20 2020  e.inputs[0]].   
-0001b100: 2066 696c 6c5f 7363 616c 6172 203d 2063   fill_scalar = c
-0001b110: 6f6e 7465 7874 5b6e 6f64 652e 696e 7075  ontext[node.inpu
-0001b120: 7473 5b31 5d5d 0a0a 2020 2020 6265 6769  ts[1]]..    begi
-0001b130: 6e2c 2065 6e64 2c20 7374 7269 6465 2c20  n, end, stride, 
-0001b140: 6265 6769 6e5f 6d61 736b 2c20 656e 645f  begin_mask, end_
-0001b150: 6d61 736b 2c20 7371 7565 657a 655f 6d61  mask, squeeze_ma
-0001b160: 736b 203d 205f 6765 745f 736c 6963 655f  sk = _get_slice_
-0001b170: 7061 7261 6d73 280a 2020 2020 2020 2020  params(.        
-0001b180: 636f 6e74 6578 742c 2064 6174 612c 206e  context, data, n
-0001b190: 6f64 652e 696e 7075 7473 5b32 3a5d 0a20  ode.inputs[2:]. 
-0001b1a0: 2020 2029 0a20 2020 2069 6620 6265 6769     ).    if begi
-0001b1b0: 6e2e 7661 6c20 6973 204e 6f6e 6520 6f72  n.val is None or
-0001b1c0: 2065 6e64 2e76 616c 2069 7320 4e6f 6e65   end.val is None
-0001b1d0: 3a0a 2020 2020 2020 2020 7261 6973 6520  :.        raise 
-0001b1e0: 5661 6c75 6545 7272 6f72 2822 5f69 6e74  ValueError("_int
-0001b1f0: 6572 6e61 6c5f 6f70 5f74 656e 736f 725f  ernal_op_tensor_
-0001b200: 696e 706c 6163 655f 6669 6c6c 2064 6f65  inplace_fill doe
-0001b210: 7320 6e6f 7420 7375 7070 6f72 7420 6479  s not support dy
-0001b220: 6e61 6d69 6320 696e 6465 7822 290a 0a20  namic index").. 
-0001b230: 2020 2066 696c 6c5f 7368 6170 6520 3d20     fill_shape = 
-0001b240: 736f 6c76 655f 736c 6963 655f 6279 5f69  solve_slice_by_i
-0001b250: 6e64 6578 5f73 6861 7065 280a 2020 2020  ndex_shape(.    
-0001b260: 2020 2020 6461 7461 2e73 6861 7065 2c20      data.shape, 
-0001b270: 6265 6769 6e2e 7661 6c2c 2065 6e64 2e76  begin.val, end.v
-0001b280: 616c 2c20 7374 7269 6465 2c20 6265 6769  al, stride, begi
-0001b290: 6e5f 6d61 736b 2c20 656e 645f 6d61 736b  n_mask, end_mask
-0001b2a0: 2c20 7371 7565 657a 655f 6d61 736b 0a20  , squeeze_mask. 
-0001b2b0: 2020 2029 0a20 2020 2075 7064 6174 655f     ).    update_
-0001b2c0: 7661 6c75 6573 203d 205f 6e70 2e66 756c  values = _np.ful
-0001b2d0: 6c28 6669 6c6c 5f73 6861 7065 2c20 6669  l(fill_shape, fi
-0001b2e0: 6c6c 5f73 6361 6c61 722e 7661 6c29 0a0a  ll_scalar.val)..
-0001b2f0: 2020 2020 6461 7461 2c20 7570 6461 7465      data, update
-0001b300: 5f76 616c 7565 7320 3d20 7072 6f6d 6f74  _values = promot
-0001b310: 655f 696e 7075 745f 6474 7970 6573 285b  e_input_dtypes([
-0001b320: 6461 7461 2c20 7570 6461 7465 5f76 616c  data, update_val
-0001b330: 7565 735d 290a 2020 2020 7570 6461 7465  ues]).    update
-0001b340: 645f 7820 3d20 6d62 2e74 6f72 6368 5f74  d_x = mb.torch_t
-0001b350: 656e 736f 725f 6173 7369 676e 280a 2020  ensor_assign(.  
-0001b360: 2020 2020 2020 6461 7461 3d64 6174 612c        data=data,
-0001b370: 0a20 2020 2020 2020 2075 7064 6174 6573  .        updates
-0001b380: 3d75 7064 6174 655f 7661 6c75 6573 2c0a  =update_values,.
-0001b390: 2020 2020 2020 2020 6265 6769 6e3d 6265          begin=be
-0001b3a0: 6769 6e2c 0a20 2020 2020 2020 2065 6e64  gin,.        end
-0001b3b0: 3d65 6e64 2c0a 2020 2020 2020 2020 7374  =end,.        st
-0001b3c0: 7269 6465 3d73 7472 6964 652c 0a20 2020  ride=stride,.   
-0001b3d0: 2020 2020 2062 6567 696e 5f6d 6173 6b3d       begin_mask=
-0001b3e0: 6265 6769 6e5f 6d61 736b 2c0a 2020 2020  begin_mask,.    
-0001b3f0: 2020 2020 656e 645f 6d61 736b 3d65 6e64      end_mask=end
-0001b400: 5f6d 6173 6b2c 0a20 2020 2020 2020 2073  _mask,.        s
-0001b410: 7175 6565 7a65 5f6d 6173 6b3d 7371 7565  queeze_mask=sque
-0001b420: 657a 655f 6d61 736b 2c0a 2020 2020 2020  eze_mask,.      
-0001b430: 2020 6e61 6d65 3d6e 6f64 652e 6e61 6d65    name=node.name
-0001b440: 2c0a 2020 2020 290a 2020 2020 636f 6e74  ,.    ).    cont
-0001b450: 6578 742e 6164 6428 7570 6461 7465 645f  ext.add(updated_
-0001b460: 7829 0a0a 0a40 7265 6769 7374 6572 5f74  x)...@register_t
-0001b470: 6f72 6368 5f6f 700a 6465 6620 696e 6465  orch_op.def inde
-0001b480: 785f 7075 7428 636f 6e74 6578 742c 206e  x_put(context, n
-0001b490: 6f64 6529 3a0a 2020 2020 696e 7075 7473  ode):.    inputs
-0001b4a0: 203d 205f 6765 745f 696e 7075 7473 2863   = _get_inputs(c
-0001b4b0: 6f6e 7465 7874 2c20 6e6f 6465 2c20 6578  ontext, node, ex
-0001b4c0: 7065 6374 6564 3d34 290a 2020 2020 7820  pected=4).    x 
-0001b4d0: 3d20 696e 7075 7473 5b30 5d0a 2020 2020  = inputs[0].    
-0001b4e0: 696e 6469 6365 7320 3d20 696e 7075 7473  indices = inputs
-0001b4f0: 5b31 5d0a 2020 2020 7661 6c75 6573 203d  [1].    values =
-0001b500: 2069 6e70 7574 735b 325d 0a20 2020 2061   inputs[2].    a
-0001b510: 6363 756d 756c 6174 6520 3d20 696e 7075  ccumulate = inpu
-0001b520: 7473 5b33 5d2e 7661 6c0a 2020 2020 7261  ts[3].val.    ra
-0001b530: 6e6b 203d 2078 2e72 616e 6b0a 2020 2020  nk = x.rank.    
-0001b540: 6d6f 6465 203d 2022 6164 6422 2069 6620  mode = "add" if 
-0001b550: 6163 6375 6d75 6c61 7465 2065 6c73 6520  accumulate else 
-0001b560: 2275 7064 6174 6522 0a0a 2020 2020 696e  "update"..    in
-0001b570: 6469 6365 735f 7479 7065 203d 2069 6e64  dices_type = ind
-0001b580: 6963 6573 5b30 5d2e 7379 6d5f 7479 7065  ices[0].sym_type
-0001b590: 2e67 6574 5f70 7269 6d69 7469 7665 2829  .get_primitive()
-0001b5a0: 0a0a 2020 2020 6966 2074 7970 6573 2e69  ..    if types.i
-0001b5b0: 735f 626f 6f6c 2869 6e64 6963 6573 5f74  s_bool(indices_t
-0001b5c0: 7970 6529 3a0a 2020 2020 2020 2020 6173  ype):.        as
-0001b5d0: 7365 7274 206c 656e 2869 6e64 6963 6573  sert len(indices
-0001b5e0: 2920 3d3d 2031 2c20 2255 6e73 7570 706f  ) == 1, "Unsuppo
-0001b5f0: 7274 6564 2069 6e64 6578 5f70 7574 5f20  rted index_put_ 
-0001b600: 7573 6167 652e 220a 2020 2020 2020 2020  usage.".        
-0001b610: 696e 6469 6365 7320 3d20 696e 6469 6365  indices = indice
-0001b620: 735b 305d 0a20 2020 2020 2020 2061 7373  s[0].        ass
-0001b630: 6572 7420 696e 6469 6365 732e 7368 6170  ert indices.shap
-0001b640: 6520 3d3d 2078 2e73 6861 7065 2c20 2269  e == x.shape, "i
-0001b650: 6e64 6963 6573 2073 6861 7065 206d 7573  ndices shape mus
-0001b660: 7420 6571 7561 6c20 746f 2069 6e70 7574  t equal to input
-0001b670: 2073 6861 7065 2066 6f72 2069 6e64 6578   shape for index
-0001b680: 2070 7574 206f 7065 7261 7469 6f6e 2e22   put operation."
-0001b690: 0a20 2020 2020 2020 2069 6e64 6963 6573  .        indices
-0001b6a0: 203d 206d 622e 6361 7374 2878 3d69 6e64   = mb.cast(x=ind
-0001b6b0: 6963 6573 2c20 6474 7970 653d 2269 6e74  ices, dtype="int
-0001b6c0: 3332 2229 0a20 2020 2020 2020 2069 6e64  32").        ind
-0001b6d0: 6963 6573 203d 206d 622e 6e6f 6e5f 7a65  ices = mb.non_ze
-0001b6e0: 726f 2878 3d69 6e64 6963 6573 290a 0a20  ro(x=indices).. 
-0001b6f0: 2020 2069 6620 7479 7065 732e 6973 5f69     if types.is_i
-0001b700: 6e74 2869 6e64 6963 6573 5f74 7970 6529  nt(indices_type)
-0001b710: 3a0a 2020 2020 2020 2020 6966 206c 656e  :.        if len
-0001b720: 2869 6e64 6963 6573 2920 3e20 313a 0a20  (indices) > 1:. 
-0001b730: 2020 2020 2020 2020 2020 2069 6e64 6963             indic
-0001b740: 6573 203d 206d 622e 7374 6163 6b28 7661  es = mb.stack(va
-0001b750: 6c75 6573 3d69 6e64 6963 6573 2c20 6178  lues=indices, ax
-0001b760: 6973 3d72 616e 6b20 2d20 3129 0a20 2020  is=rank - 1).   
-0001b770: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
-0001b780: 2020 2020 2020 2069 6e64 6963 6573 203d         indices =
-0001b790: 206d 622e 6578 7061 6e64 5f64 696d 7328   mb.expand_dims(
-0001b7a0: 783d 696e 6469 6365 735b 305d 2c20 6178  x=indices[0], ax
-0001b7b0: 6573 3d5b 2d31 5d29 0a0a 2020 2020 6966  es=[-1])..    if
-0001b7c0: 206c 656e 2876 616c 7565 732e 7368 6170   len(values.shap
-0001b7d0: 6529 203d 3d20 303a 0a20 2020 2020 2020  e) == 0:.       
-0001b7e0: 2076 616c 7565 7320 3d20 6d62 2e65 7870   values = mb.exp
-0001b7f0: 616e 645f 6469 6d73 2878 3d76 616c 7565  and_dims(x=value
-0001b800: 732c 2061 7865 733d 5b30 5d29 0a0a 2020  s, axes=[0])..  
-0001b810: 2020 6966 2076 616c 7565 732e 7261 6e6b    if values.rank
-0001b820: 203d 3d20 3120 616e 6420 7661 6c75 6573   == 1 and values
-0001b830: 2e73 6861 7065 5b30 5d20 3d3d 2031 3a0a  .shape[0] == 1:.
-0001b840: 2020 2020 2020 2020 7265 7073 203d 2076          reps = v
-0001b850: 616c 7565 5f61 7428 6d62 2e73 6861 7065  alue_at(mb.shape
-0001b860: 2878 3d69 6e64 6963 6573 292c 2030 290a  (x=indices), 0).
-0001b870: 2020 2020 2020 2020 7265 7073 203d 206d          reps = m
-0001b880: 622e 6578 7061 6e64 5f64 696d 7328 783d  b.expand_dims(x=
-0001b890: 7265 7073 2c20 6178 6573 3d5b 305d 290a  reps, axes=[0]).
-0001b8a0: 2020 2020 2020 2020 7661 6c75 6573 203d          values =
-0001b8b0: 206d 622e 7469 6c65 2878 3d76 616c 7565   mb.tile(x=value
-0001b8c0: 732c 2072 6570 733d 7265 7073 290a 0a20  s, reps=reps).. 
-0001b8d0: 2020 2072 6573 756c 7420 3d20 6d62 2e73     result = mb.s
-0001b8e0: 6361 7474 6572 5f6e 6428 6461 7461 3d78  catter_nd(data=x
-0001b8f0: 2c20 696e 6469 6365 733d 696e 6469 6365  , indices=indice
-0001b900: 732c 2075 7064 6174 6573 3d76 616c 7565  s, updates=value
-0001b910: 732c 206d 6f64 653d 6d6f 6465 2c20 6e61  s, mode=mode, na
-0001b920: 6d65 3d6e 6f64 652e 6e61 6d65 290a 2020  me=node.name).  
-0001b930: 2020 636f 6e74 6578 742e 6164 6428 7265    context.add(re
-0001b940: 7375 6c74 290a 0a0a 4072 6567 6973 7465  sult)...@registe
-0001b950: 725f 746f 7263 685f 6f70 0a64 6566 2069  r_torch_op.def i
-0001b960: 6e64 6578 2863 6f6e 7465 7874 2c20 6e6f  ndex(context, no
-0001b970: 6465 293a 0a20 2020 2069 6e70 7574 7320  de):.    inputs 
-0001b980: 3d20 5f67 6574 5f69 6e70 7574 7328 636f  = _get_inputs(co
-0001b990: 6e74 6578 742c 206e 6f64 652c 2065 7870  ntext, node, exp
-0001b9a0: 6563 7465 643d 3229 0a20 2020 2078 203d  ected=2).    x =
-0001b9b0: 2069 6e70 7574 735b 305d 0a20 2020 2069   inputs[0].    i
-0001b9c0: 6e64 6963 6573 203d 2069 6e70 7574 735b  ndices = inputs[
-0001b9d0: 315d 0a20 2020 2072 616e 6b20 3d20 782e  1].    rank = x.
-0001b9e0: 7261 6e6b 0a0a 2020 2020 2222 220a 2020  rank..    """.  
-0001b9f0: 2020 4361 7365 2031 3a20 4120 7369 6e67    Case 1: A sing
-0001ba00: 6c65 2062 6f6f 6c65 616e 2069 6e64 6578  le boolean index
-0001ba10: 2073 656c 6563 7469 6f6e 0a20 2020 2045   selection.    E
-0001ba20: 783a 0a20 2020 2020 2020 2061 203d 2074  x:.        a = t
-0001ba30: 6f72 6368 2e72 616e 6428 322c 2033 2c20  orch.rand(2, 3, 
-0001ba40: 3429 0a20 2020 2020 2020 2062 203d 2074  4).        b = t
-0001ba50: 6f72 6368 2e72 616e 6428 332c 2034 290a  orch.rand(3, 4).
-0001ba60: 2020 2020 2020 2020 696e 6465 7820 3d20          index = 
-0001ba70: 6220 3e20 302e 310a 2020 2020 2020 2020  b > 0.1.        
-0001ba80: 6320 3d20 615b 3a2c 2062 5d0a 0a20 2020  c = a[:, b]..   
-0001ba90: 2046 6f72 2074 6869 7320 6361 7365 2c20   For this case, 
-0001baa0: 7468 6520 6f6e 6c79 206e 6f6e 2d4e 6f6e  the only non-Non
-0001bab0: 6520 7465 6e73 6f72 2069 7320 7769 7468  e tensor is with
-0001bac0: 2064 7479 7065 2062 6f6f 6c0a 2020 2020   dtype bool.    
-0001bad0: 5468 6520 7472 7565 2076 616c 7565 2069  The true value i
-0001bae0: 6e64 6963 6174 6573 2077 6865 7468 6572  ndicates whether
-0001baf0: 2074 6865 2065 6c65 6d65 6e74 2073 686f   the element sho
-0001bb00: 756c 6420 6265 2073 656c 6563 7465 6420  uld be selected 
-0001bb10: 616d 6f6e 6720 7468 6520 6d61 736b 6564  among the masked
-0001bb20: 2061 7865 730a 2020 2020 5468 6520 6f75   axes.    The ou
-0001bb30: 7470 7574 2063 2069 7320 6120 7465 6e73  tput c is a tens
-0001bb40: 6f72 2077 6974 6820 7368 6170 6520 2832  or with shape (2
-0001bb50: 2c20 4e29 2c20 7768 6572 6520 4e20 6973  , N), where N is
-0001bb60: 2074 6865 206e 756d 6265 7220 6f66 2065   the number of e
-0001bb70: 6c65 6d65 6e74 7320 6f66 2062 2073 6174  lements of b sat
-0001bb80: 6973 6679 696e 6720 636f 6e64 6974 696f  isfying conditio
-0001bb90: 6e20 3e20 302e 310a 2020 2020 2222 220a  n > 0.1.    """.
-0001bba0: 2020 2020 626f 6f6c 6561 6e5f 696e 6469      boolean_indi
-0001bbb0: 6365 735f 6178 6973 203d 205b 5d0a 2020  ces_axis = [].  
-0001bbc0: 2020 666f 7220 692c 2069 6e64 6578 2069    for i, index i
-0001bbd0: 6e20 656e 756d 6572 6174 6528 696e 6469  n enumerate(indi
-0001bbe0: 6365 7329 3a0a 2020 2020 2020 2020 6966  ces):.        if
-0001bbf0: 2069 6e64 6578 2069 7320 6e6f 7420 4e6f   index is not No
-0001bc00: 6e65 2061 6e64 2074 7970 6573 2e69 735f  ne and types.is_
-0001bc10: 626f 6f6c 2869 6e64 6578 2e64 7479 7065  bool(index.dtype
-0001bc20: 293a 0a20 2020 2020 2020 2020 2020 2062  ):.            b
-0001bc30: 6f6f 6c65 616e 5f69 6e64 6963 6573 5f61  oolean_indices_a
-0001bc40: 7869 732e 6170 7065 6e64 2869 290a 2020  xis.append(i).  
-0001bc50: 2020 6966 206c 656e 2862 6f6f 6c65 616e    if len(boolean
-0001bc60: 5f69 6e64 6963 6573 5f61 7869 7329 203d  _indices_axis) =
-0001bc70: 3d20 313a 0a20 2020 2020 2020 2023 2067  = 1:.        # g
-0001bc80: 6574 2074 6865 2054 7275 6520 656c 656d  et the True elem
-0001bc90: 656e 7420 696e 6469 6365 730a 2020 2020  ent indices.    
-0001bca0: 2020 2020 6178 6973 203d 2062 6f6f 6c65      axis = boole
-0001bcb0: 616e 5f69 6e64 6963 6573 5f61 7869 735b  an_indices_axis[
-0001bcc0: 305d 0a20 2020 2020 2020 2061 7865 7320  0].        axes 
-0001bcd0: 3d20 6c69 7374 2872 616e 6765 2861 7869  = list(range(axi
-0001bce0: 732c 2061 7869 7320 2b20 696e 6465 782e  s, axis + index.
-0001bcf0: 7261 6e6b 2929 0a20 2020 2020 2020 2069  rank)).        i
-0001bd00: 6e64 6578 203d 2069 6e64 6963 6573 5b61  ndex = indices[a
-0001bd10: 7869 735d 0a20 2020 2020 2020 2069 6e64  xis].        ind
-0001bd20: 6578 203d 206d 622e 6e6f 6e5f 7a65 726f  ex = mb.non_zero
-0001bd30: 2878 3d69 6e64 6578 290a 0a20 2020 2020  (x=index)..     
-0001bd40: 2020 2023 2074 7261 6e70 6f73 6520 7468     # tranpose th
-0001bd50: 6520 6d61 736b 6564 2061 7865 7320 746f  e masked axes to
-0001bd60: 2074 6865 2062 6567 696e 6e69 6e67 0a20   the beginning. 
-0001bd70: 2020 2020 2020 2070 6572 6d20 3d20 6178         perm = ax
-0001bd80: 6573 202b 205b 6920 666f 7220 6920 696e  es + [i for i in
-0001bd90: 2072 616e 6765 2872 616e 6b29 2069 6620   range(rank) if 
-0001bda0: 6920 6e6f 7420 696e 2061 7865 735d 0a20  i not in axes]. 
-0001bdb0: 2020 2020 2020 2078 203d 206d 622e 7472         x = mb.tr
-0001bdc0: 616e 7370 6f73 6528 783d 782c 2070 6572  anspose(x=x, per
-0001bdd0: 6d3d 7065 726d 290a 2020 2020 2020 2020  m=perm).        
-0001bde0: 7820 3d20 6d62 2e67 6174 6865 725f 6e64  x = mb.gather_nd
-0001bdf0: 2878 3d78 2c20 696e 6469 6365 733d 696e  (x=x, indices=in
-0001be00: 6465 7829 0a0a 2020 2020 2020 2020 2320  dex)..        # 
-0001be10: 7472 616e 7370 6f73 6520 7468 6520 7465  transpose the te
-0001be20: 6e73 6f72 2062 6163 6b0a 2020 2020 2020  nsor back.      
-0001be30: 2020 7065 726d 5f62 6163 6b20 3d20 6c69    perm_back = li
-0001be40: 7374 2872 616e 6765 2831 2c20 782e 7261  st(range(1, x.ra
-0001be50: 6e6b 2929 0a20 2020 2020 2020 2070 6572  nk)).        per
-0001be60: 6d5f 6261 636b 2e69 6e73 6572 7428 6178  m_back.insert(ax
-0001be70: 6973 2c20 3029 0a20 2020 2020 2020 2072  is, 0).        r
-0001be80: 6573 203d 206d 622e 7472 616e 7370 6f73  es = mb.transpos
-0001be90: 6528 783d 782c 2070 6572 6d3d 7065 726d  e(x=x, perm=perm
-0001bea0: 5f62 6163 6b2c 206e 616d 653d 6e6f 6465  _back, name=node
-0001beb0: 2e6e 616d 6529 0a20 2020 2020 2020 2063  .name).        c
-0001bec0: 6f6e 7465 7874 2e61 6464 2872 6573 290a  ontext.add(res).
-0001bed0: 2020 2020 2020 2020 7265 7475 726e 0a0a          return..
-0001bee0: 2020 2020 2222 220a 2020 2020 4361 7365      """.    Case
-0001bef0: 2032 3a20 5075 7265 2069 6e64 6578 2073   2: Pure index s
-0001bf00: 656c 6563 7469 6f6e 0a20 2020 2045 7820  election.    Ex 
-0001bf10: 2320 3120 5b53 696e 676c 6520 6469 6d65  # 1 [Single dime
-0001bf20: 6e73 696f 6e20 7365 6c65 6374 696f 6e5d  nsion selection]
-0001bf30: 3a0a 2020 2020 2020 2020 6120 3d20 746f  :.        a = to
-0001bf40: 7263 682e 7261 6e64 2831 2c32 2c33 2c34  rch.rand(1,2,3,4
-0001bf50: 290a 2020 2020 2020 2020 696e 6465 7820  ).        index 
-0001bf60: 3d20 746f 7263 682e 7465 6e73 6f72 285b  = torch.tensor([
-0001bf70: 302c 2031 5d29 0a20 2020 2020 2020 2062  0, 1]).        b
-0001bf80: 203d 2061 5b3a 2c3a 2c3a 2c69 6e64 6578   = a[:,:,:,index
-0001bf90: 5d0a 0a20 2020 2020 2020 2049 6e20 7468  ]..        In th
-0001bfa0: 6973 2063 6173 652c 2069 6e64 6963 6573  is case, indices
-0001bfb0: 2069 7320 6120 6c69 7374 205b 4e6f 6e65   is a list [None
-0001bfc0: 2c20 4e6f 6e65 2c20 4e6f 6e65 2c20 5b30  , None, None, [0
-0001bfd0: 2c20 315d 5d5d 2e20 5468 6520 4e6f 6e65  , 1]]]. The None
-0001bfe0: 2065 6c65 6d65 6e74 206d 6561 6e73 2074   element means t
-0001bff0: 6865 2063 6f72 7265 7370 6f6e 6469 6e67  he corresponding
-0001c000: 0a20 2020 2020 2020 2064 696d 656e 7369  .        dimensi
-0001c010: 6f6e 2069 7320 6d61 736b 6564 2e0a 0a20  on is masked... 
-0001c020: 2020 2020 2020 2062 2068 6173 2073 6861         b has sha
-0001c030: 7065 2028 312c 322c 332c 3229 2e0a 0a20  pe (1,2,3,2)... 
-0001c040: 2020 2045 7820 2320 3220 5b4d 756c 7469     Ex # 2 [Multi
-0001c050: 706c 6520 6469 7363 6f6e 6e65 6374 6564  ple disconnected
-0001c060: 2064 696d 656e 7369 6f6e 7320 7365 6c65   dimensions sele
-0001c070: 6374 696f 6e5d 3a0a 2020 2020 2020 2020  ction]:.        
-0001c080: 6120 3d20 746f 7263 682e 7261 6e64 2831  a = torch.rand(1
-0001c090: 2c32 2c33 2c34 290a 2020 2020 2020 2020  ,2,3,4).        
-0001c0a0: 696e 6465 7820 3d20 746f 7263 682e 7465  index = torch.te
-0001c0b0: 6e73 6f72 285b 302c 2031 5d29 0a20 2020  nsor([0, 1]).   
-0001c0c0: 2020 2020 2062 203d 2061 5b3a 2c69 6e64       b = a[:,ind
-0001c0d0: 6578 2c3a 2c69 6e64 6578 5d0a 0a20 2020  ex,:,index]..   
-0001c0e0: 2020 2020 2049 6e20 7468 6973 2063 6173       In this cas
-0001c0f0: 652c 2069 6e64 6963 6573 2069 7320 6120  e, indices is a 
-0001c100: 6c69 7374 205b 4e6f 6e65 2c20 5b30 2c31  list [None, [0,1
-0001c110: 5d2c 204e 6f6e 652c 205b 302c 315d 5d0a  ], None, [0,1]].
-0001c120: 0a20 2020 2020 2020 2062 2068 6173 2073  .        b has s
-0001c130: 6861 7065 2028 322c 312c 3329 2c0a 2020  hape (2,1,3),.  
-0001c140: 2020 2020 2020 7768 6572 6520 625b 302c        where b[0,
-0001c150: 3a2c 3a5d 203d 2061 5b3a 2c30 2c3a 2c30  :,:] = a[:,0,:,0
-0001c160: 5d20 616e 6420 625b 312c 3a2c 3a5d 203d  ] and b[1,:,:] =
-0001c170: 2061 5b3a 2c31 2c3a 2c31 5d0a 0a20 2020   a[:,1,:,1]..   
-0001c180: 2045 7820 2320 3320 5b4d 756c 7469 706c   Ex # 3 [Multipl
-0001c190: 6520 636f 6e6e 6563 7465 6420 6469 6d65  e connected dime
-0001c1a0: 6e73 696f 6e73 2073 656c 6563 7469 6f6e  nsions selection
-0001c1b0: 5d3a 0a20 2020 2020 2020 2061 203d 2074  ]:.        a = t
-0001c1c0: 6f72 6368 2e72 616e 6428 312c 322c 332c  orch.rand(1,2,3,
-0001c1d0: 3429 0a20 2020 2020 2020 2069 6e64 6578  4).        index
-0001c1e0: 5f31 203d 2074 6f72 6368 2e74 656e 736f  _1 = torch.tenso
-0001c1f0: 7228 5b30 2c20 315d 290a 2020 2020 2020  r([0, 1]).      
-0001c200: 2020 696e 6465 785f 3220 3d20 746f 7263    index_2 = torc
-0001c210: 682e 7465 6e73 6f72 285b 302c 2031 5d29  h.tensor([0, 1])
-0001c220: 0a20 2020 2020 2020 2062 203d 2061 5b3a  .        b = a[:
-0001c230: 2c69 6e64 6578 5f31 2c69 6e64 6578 5f32  ,index_1,index_2
-0001c240: 2c3a 5d0a 0a20 2020 2020 2020 2069 6e64  ,:]..        ind
-0001c250: 6963 6573 2069 7320 6120 6c69 7374 205b  ices is a list [
-0001c260: 4e6f 6e65 2c20 5b30 2c20 315d 2c20 5b30  None, [0, 1], [0
-0001c270: 2c20 315d 2c20 4e6f 6e65 5d0a 0a20 2020  , 1], None]..   
-0001c280: 2020 2020 2062 2068 6173 2073 6861 7065       b has shape
-0001c290: 2028 312c 322c 3429 2c0a 2020 2020 2020   (1,2,4),.      
-0001c2a0: 2020 7768 6572 6520 625b 3a2c 302c 3a5d    where b[:,0,:]
-0001c2b0: 203d 2061 5b3a 2c30 2c30 2c3a 5d20 616e   = a[:,0,0,:] an
-0001c2c0: 6420 625b 3a2c 312c 3a5d 203d 2061 5b3a  d b[:,1,:] = a[:
-0001c2d0: 2c31 2c31 2c3a 5d0a 0a20 2020 2045 7820  ,1,1,:]..    Ex 
-0001c2e0: 2320 3420 5b53 656c 6563 7469 6f6e 2077  # 4 [Selection w
-0001c2f0: 6974 6820 626f 6f6c 6561 6e20 6d61 736b  ith boolean mask
-0001c300: 735d 3a0a 2020 2020 2020 2020 6120 3d20  s]:.        a = 
-0001c310: 746f 7263 682e 7261 6e64 2834 2c35 290a  torch.rand(4,5).
-0001c320: 2020 2020 2020 2020 696e 6465 785f 3120          index_1 
-0001c330: 3d20 5b54 7275 652c 2054 7275 652c 2046  = [True, True, F
-0001c340: 616c 7365 2c20 4661 6c73 655d 0a20 2020  alse, False].   
-0001c350: 2020 2020 2069 6e64 6578 5f32 203d 205b       index_2 = [
-0001c360: 4661 6c73 652c 2054 7275 652c 2054 7275  False, True, Tru
-0001c370: 652c 2046 616c 7365 2c20 4661 6c73 655d  e, False, False]
-0001c380: 0a20 2020 2020 2020 2062 203d 2061 5b69  .        b = a[i
-0001c390: 6e64 6578 5f31 2c20 696e 6465 785f 325d  ndex_1, index_2]
-0001c3a0: 0a0a 2020 2020 2020 2020 696e 6469 6365  ..        indice
-0001c3b0: 7320 6973 2061 206c 6973 7420 5b5b 5472  s is a list [[Tr
-0001c3c0: 7565 2c20 5472 7565 2c20 4661 6c73 652c  ue, True, False,
-0001c3d0: 2046 616c 7365 5d2c 205b 4661 6c73 652c   False], [False,
-0001c3e0: 2054 7275 652c 2054 7275 652c 2046 616c   True, True, Fal
-0001c3f0: 7365 2c20 4661 6c73 655d 5d0a 0a20 2020  se, False]]..   
-0001c400: 2020 2020 2049 6e20 7468 6973 2063 6173       In this cas
-0001c410: 652c 2069 6e64 6578 5f31 2061 6e64 2069  e, index_1 and i
-0001c420: 6e64 6578 5f32 2061 7265 2069 6e74 6572  ndex_2 are inter
-0001c430: 7072 6574 6564 2061 7320 6d61 736b 2062  preted as mask b
-0001c440: 7920 696e 6469 6365 7320 6f66 2054 7275  y indices of Tru
-0001c450: 652c 0a20 2020 2020 2020 2069 6e64 6578  e,.        index
-0001c460: 5f31 202d 3e20 5b30 2c20 315d 0a20 2020  _1 -> [0, 1].   
-0001c470: 2020 2020 2069 6e64 6578 5f32 202d 3e20       index_2 -> 
-0001c480: 5b31 2c20 325d 0a0a 2020 2020 2020 2020  [1, 2]..        
-0001c490: 6220 6861 7320 7368 6170 6520 2832 2c29  b has shape (2,)
-0001c4a0: 2c0a 2020 2020 2020 2020 7768 6572 6520  ,.        where 
-0001c4b0: 625b 305d 203d 2061 5b30 2c20 315d 2061  b[0] = a[0, 1] a
-0001c4c0: 6e64 2062 5b31 5d20 3d20 615b 312c 2032  nd b[1] = a[1, 2
-0001c4d0: 5d0a 0a20 2020 2045 7820 2320 3520 5b42  ]..    Ex # 5 [B
-0001c4e0: 726f 6164 6361 7374 2073 656c 6563 7469  roadcast selecti
-0001c4f0: 6f6e 5d3a 0a20 2020 2020 2020 2061 203d  on]:.        a =
-0001c500: 2074 6f72 6368 2e72 616e 6428 312c 322c   torch.rand(1,2,
-0001c510: 332c 3429 0a20 2020 2020 2020 2069 6e64  3,4).        ind
-0001c520: 6578 5f31 203d 2074 6f72 6368 2e74 656e  ex_1 = torch.ten
-0001c530: 736f 7228 5b30 2c20 315d 290a 2020 2020  sor([0, 1]).    
-0001c540: 2020 2020 696e 6465 785f 3220 3d20 746f      index_2 = to
-0001c550: 7263 682e 7465 6e73 6f72 285b 305d 290a  rch.tensor([0]).
-0001c560: 2020 2020 2020 2020 6220 3d20 615b 3a2c          b = a[:,
-0001c570: 696e 6465 785f 312c 696e 6465 785f 322c  index_1,index_2,
-0001c580: 3a5d 0a0a 2020 2020 2020 2020 696e 6469  :]..        indi
-0001c590: 6365 7320 6973 2061 206c 6973 7420 5b4e  ces is a list [N
-0001c5a0: 6f6e 652c 205b 302c 2031 5d2c 205b 305d  one, [0, 1], [0]
-0001c5b0: 2c20 4e6f 6e65 5d0a 0a20 2020 2020 2020  , None]..       
-0001c5c0: 2049 6e20 7468 6973 2063 6173 652c 2069   In this case, i
-0001c5d0: 6e64 6578 5f32 2069 7320 676f 696e 6720  ndex_2 is going 
-0001c5e0: 746f 2062 6520 6272 6f61 6463 6173 7465  to be broadcaste
-0001c5f0: 6420 746f 205b 302c 2030 5d0a 0a20 2020  d to [0, 0]..   
-0001c600: 2020 2020 2062 2068 6173 2073 6861 7065       b has shape
-0001c610: 2028 312c 322c 3429 2c0a 2020 2020 2020   (1,2,4),.      
-0001c620: 2020 7768 6572 6520 625b 3a2c 302c 3a5d    where b[:,0,:]
-0001c630: 203d 2061 5b3a 2c30 2c30 2c3a 5d20 616e   = a[:,0,0,:] an
-0001c640: 6420 625b 3a2c 312c 3a5d 203d 2061 5b3a  d b[:,1,:] = a[:
-0001c650: 2c31 2c30 2c3a 5d0a 0a20 2020 2022 2222  ,1,0,:]..    """
-0001c660: 0a0a 2020 2020 2320 6765 7420 7468 6520  ..    # get the 
-0001c670: 696e 6465 7820 6178 6573 0a20 2020 2069  index axes.    i
-0001c680: 6e64 6963 6573 203d 2069 6e64 6963 6573  ndices = indices
-0001c690: 202b 205b 4e6f 6e65 5d20 2a20 2878 2e72   + [None] * (x.r
-0001c6a0: 616e 6b20 2d20 6c65 6e28 696e 6469 6365  ank - len(indice
-0001c6b0: 7329 290a 2020 2020 696e 6469 6365 735f  s)).    indices_
-0001c6c0: 6178 6573 203d 205b 5d0a 2020 2020 7661  axes = [].    va
-0001c6d0: 6c69 645f 696e 6469 6365 7320 3d20 5b5d  lid_indices = []
-0001c6e0: 0a20 2020 2066 6f72 2069 2c20 696e 6465  .    for i, inde
-0001c6f0: 7820 696e 2065 6e75 6d65 7261 7465 2869  x in enumerate(i
-0001c700: 6e64 6963 6573 293a 0a20 2020 2020 2020  ndices):.       
-0001c710: 2069 6620 696e 6465 7820 6973 206e 6f74   if index is not
-0001c720: 204e 6f6e 653a 0a20 2020 2020 2020 2020   None:.         
-0001c730: 2020 2069 6e64 6963 6573 5f61 7865 732e     indices_axes.
-0001c740: 6170 7065 6e64 2869 290a 2020 2020 2020  append(i).      
-0001c750: 2020 2020 2020 7661 6c69 645f 696e 6469        valid_indi
-0001c760: 6365 732e 6170 7065 6e64 2869 6e64 6578  ces.append(index
-0001c770: 290a 0a20 2020 2023 2049 6620 616c 6c20  )..    # If all 
-0001c780: 656c 656d 656e 7473 2069 6e20 696e 6469  elements in indi
-0001c790: 6365 7320 6973 204e 6f6e 652c 2073 696d  ces is None, sim
-0001c7a0: 7069 6c79 2072 6574 7572 6e20 7468 6520  pily return the 
-0001c7b0: 6f72 6967 696e 616c 2074 656e 736f 722e  original tensor.
-0001c7c0: 0a20 2020 2069 6620 6c65 6e28 696e 6469  .    if len(indi
-0001c7d0: 6365 735f 6178 6573 2920 3d3d 2030 3a0a  ces_axes) == 0:.
-0001c7e0: 2020 2020 2020 2020 7820 3d20 6d62 2e69          x = mb.i
-0001c7f0: 6465 6e74 6974 7928 783d 782c 206e 616d  dentity(x=x, nam
-0001c800: 653d 6e6f 6465 2e6e 616d 6529 0a20 2020  e=node.name).   
-0001c810: 2020 2020 2063 6f6e 7465 7874 2e61 6464       context.add
-0001c820: 2878 290a 2020 2020 2020 2020 7265 7475  (x).        retu
-0001c830: 726e 0a0a 2020 2020 2320 636f 6e76 6572  rn..    # conver
-0001c840: 7420 616c 6c20 696e 6469 6365 7320 746f  t all indices to
-0001c850: 2069 6e74 2074 7970 650a 2020 2020 666f   int type.    fo
-0001c860: 7220 692c 2069 6e64 6963 6520 696e 2065  r i, indice in e
-0001c870: 6e75 6d65 7261 7465 2876 616c 6964 5f69  numerate(valid_i
-0001c880: 6e64 6963 6573 293a 0a20 2020 2020 2020  ndices):.       
-0001c890: 2069 6620 696e 6469 6365 2069 7320 6e6f   if indice is no
-0001c8a0: 7420 4e6f 6e65 2061 6e64 2074 7970 6573  t None and types
-0001c8b0: 2e69 735f 626f 6f6c 2869 6e64 6963 652e  .is_bool(indice.
-0001c8c0: 6474 7970 6529 3a0a 2020 2020 2020 2020  dtype):.        
-0001c8d0: 2020 2020 696e 6469 6365 203d 206d 622e      indice = mb.
-0001c8e0: 6e6f 6e5f 7a65 726f 2878 3d69 6e64 6963  non_zero(x=indic
-0001c8f0: 6529 0a20 2020 2020 2020 2020 2020 2069  e).            i
-0001c900: 6e64 6963 6520 3d20 6d62 2e73 7175 6565  ndice = mb.squee
-0001c910: 7a65 2878 3d69 6e64 6963 652c 2061 7865  ze(x=indice, axe
-0001c920: 733d 5b31 5d29 0a20 2020 2020 2020 2076  s=[1]).        v
-0001c930: 616c 6964 5f69 6e64 6963 6573 5b69 5d20  alid_indices[i] 
-0001c940: 3d20 696e 6469 6365 0a0a 2020 2020 2320  = indice..    # 
-0001c950: 466f 7220 7468 6520 7369 6e67 6c65 2069  For the single i
-0001c960: 6e64 6578 2061 7869 7320 6361 7365 2c20  ndex axis case, 
-0001c970: 7765 2063 616e 2075 7365 206d 622e 6761  we can use mb.ga
-0001c980: 7468 6572 2064 6972 6563 746c 790a 2020  ther directly.  
-0001c990: 2020 6966 206c 656e 2869 6e64 6963 6573    if len(indices
-0001c9a0: 5f61 7865 7329 203d 3d20 313a 0a20 2020  _axes) == 1:.   
-0001c9b0: 2020 2020 2061 7869 7320 3d20 696e 6469       axis = indi
-0001c9c0: 6365 735f 6178 6573 5b30 5d0a 2020 2020  ces_axes[0].    
-0001c9d0: 2020 2020 7820 3d20 6d62 2e67 6174 6865      x = mb.gathe
-0001c9e0: 7228 783d 782c 2069 6e64 6963 6573 3d76  r(x=x, indices=v
-0001c9f0: 616c 6964 5f69 6e64 6963 6573 5b30 5d2c  alid_indices[0],
-0001ca00: 2061 7869 733d 6178 6973 2c20 6e61 6d65   axis=axis, name
-0001ca10: 3d6e 6f64 652e 6e61 6d65 290a 2020 2020  =node.name).    
-0001ca20: 2020 2020 636f 6e74 6578 742e 6164 6428      context.add(
-0001ca30: 7829 0a20 2020 2020 2020 2072 6574 7572  x).        retur
-0001ca40: 6e0a 0a20 2020 2023 2046 6f72 206d 756c  n..    # For mul
-0001ca50: 7469 706c 6520 696e 6465 7820 6178 6573  tiple index axes
-0001ca60: 2063 6173 652c 2077 6520 6465 6c65 6761   case, we delega
-0001ca70: 7465 2062 726f 6164 6361 7374 2074 6f20  te broadcast to 
-0001ca80: 6e70 2069 6620 7468 6572 6520 6973 206e  np if there is n
-0001ca90: 6f20 6479 6e61 6d69 6320 7368 6170 652e  o dynamic shape.
-0001caa0: 0a20 2020 2069 6620 616c 6c28 6e6f 7420  .    if all(not 
-0001cab0: 616e 795f 7379 6d62 6f6c 6963 2869 6478  any_symbolic(idx
-0001cac0: 2e73 6861 7065 2920 666f 7220 6964 7820  .shape) for idx 
-0001cad0: 696e 2076 616c 6964 5f69 6e64 6963 6573  in valid_indices
-0001cae0: 293a 0a20 2020 2020 2020 2062 726f 6164  ):.        broad
-0001caf0: 6361 7374 6564 5f73 6861 7065 203d 205f  casted_shape = _
-0001cb00: 6e70 2e62 726f 6164 6361 7374 5f73 6861  np.broadcast_sha
-0001cb10: 7065 7328 2a5b 6964 782e 7368 6170 6520  pes(*[idx.shape 
-0001cb20: 666f 7220 6964 7820 696e 2076 616c 6964  for idx in valid
-0001cb30: 5f69 6e64 6963 6573 5d29 0a20 2020 2020  _indices]).     
-0001cb40: 2020 2066 6f72 2069 2c20 696e 6465 7820     for i, index 
-0001cb50: 696e 2065 6e75 6d65 7261 7465 2876 616c  in enumerate(val
-0001cb60: 6964 5f69 6e64 6963 6573 293a 0a20 2020  id_indices):.   
-0001cb70: 2020 2020 2020 2020 2069 6620 2869 6e64           if (ind
-0001cb80: 6578 2e73 6861 7065 2021 3d20 6272 6f61  ex.shape != broa
-0001cb90: 6463 6173 7465 645f 7368 6170 6529 2061  dcasted_shape) a
-0001cba0: 6e64 2069 6e64 6578 2e76 616c 2069 7320  nd index.val is 
-0001cbb0: 6e6f 7420 4e6f 6e65 3a0a 2020 2020 2020  not None:.      
-0001cbc0: 2020 2020 2020 2020 2020 6e65 775f 7661            new_va
-0001cbd0: 6c20 3d20 5f6e 702e 6272 6f61 6463 6173  l = _np.broadcas
-0001cbe0: 745f 746f 2869 6e64 6578 2e76 616c 2c20  t_to(index.val, 
-0001cbf0: 6272 6f61 6463 6173 7465 645f 7368 6170  broadcasted_shap
-0001cc00: 6529 0a20 2020 2020 2020 2020 2020 2020  e).             
-0001cc10: 2020 2076 616c 6964 5f69 6e64 6963 6573     valid_indices
-0001cc20: 5b69 5d20 3d20 6d62 2e63 6f6e 7374 280a  [i] = mb.const(.
-0001cc30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001cc40: 2020 2020 7661 6c3d 6e65 775f 7661 6c2c      val=new_val,
-0001cc50: 206e 616d 653d 696e 6465 782e 6e61 6d65   name=index.name
-0001cc60: 202b 2022 5f62 726f 6164 6361 7374 6564   + "_broadcasted
-0001cc70: 220a 2020 2020 2020 2020 2020 2020 2020  ".              
-0001cc80: 2020 290a 2020 2020 7661 6c69 645f 696e    ).    valid_in
-0001cc90: 6469 6365 7320 3d20 5b6d 622e 6361 7374  dices = [mb.cast
-0001cca0: 2878 3d69 6e64 6578 2c20 6474 7970 653d  (x=index, dtype=
-0001ccb0: 2269 6e74 3332 2229 2066 6f72 2069 6e64  "int32") for ind
-0001ccc0: 6578 2069 6e20 7661 6c69 645f 696e 6469  ex in valid_indi
-0001ccd0: 6365 735d 0a0a 2020 2020 2320 4669 7273  ces]..    # Firs
-0001cce0: 7420 7374 6163 6b20 7468 6520 696e 6465  t stack the inde
-0001ccf0: 7820 746f 6765 7468 6572 0a20 2020 2069  x together.    i
-0001cd00: 6e64 6963 6573 5f72 616e 6b20 3d20 7661  ndices_rank = va
-0001cd10: 6c69 645f 696e 6469 6365 735b 305d 2e72  lid_indices[0].r
-0001cd20: 616e 6b0a 2020 2020 696e 6469 6365 7320  ank.    indices 
-0001cd30: 3d20 6d62 2e73 7461 636b 2876 616c 7565  = mb.stack(value
-0001cd40: 733d 7661 6c69 645f 696e 6469 6365 732c  s=valid_indices,
-0001cd50: 2061 7869 733d 696e 6469 6365 735f 7261   axis=indices_ra
-0001cd60: 6e6b 290a 0a20 2020 2023 2074 7261 6e73  nk)..    # trans
-0001cd70: 706f 7365 2074 6865 2069 6e70 7574 2074  pose the input t
-0001cd80: 656e 736f 7220 746f 2067 6174 6865 7220  ensor to gather 
-0001cd90: 7468 6520 736c 6963 696e 6720 696e 6465  the slicing inde
-0001cda0: 7820 696e 2066 726f 6e74 0a20 2020 2069  x in front.    i
-0001cdb0: 735f 636f 6e6e 6563 7465 6420 3d20 5472  s_connected = Tr
-0001cdc0: 7565 0a20 2020 2066 6f72 2069 2069 6e20  ue.    for i in 
-0001cdd0: 7261 6e67 6528 312c 206c 656e 2869 6e64  range(1, len(ind
-0001cde0: 6963 6573 5f61 7865 7329 293a 0a20 2020  ices_axes)):.   
-0001cdf0: 2020 2020 2069 6620 696e 6469 6365 735f       if indices_
-0001ce00: 6178 6573 5b69 5d20 213d 2069 6e64 6963  axes[i] != indic
-0001ce10: 6573 5f61 7865 735b 6920 2d20 315d 202b  es_axes[i - 1] +
-0001ce20: 2031 3a0a 2020 2020 2020 2020 2020 2020   1:.            
-0001ce30: 6973 5f63 6f6e 6e65 6374 6564 203d 2046  is_connected = F
-0001ce40: 616c 7365 0a20 2020 2020 2020 2020 2020  alse.           
-0001ce50: 2062 7265 616b 0a0a 2020 2020 6e61 6d65   break..    name
-0001ce60: 203d 206e 6f64 652e 6e61 6d65 202b 2022   = node.name + "
-0001ce70: 5f74 7261 6e73 706f 7365 2220 6966 2069  _transpose" if i
-0001ce80: 735f 636f 6e6e 6563 7465 6420 656c 7365  s_connected else
-0001ce90: 206e 6f64 652e 6e61 6d65 0a20 2020 2070   node.name.    p
-0001cea0: 6572 6d20 3d20 696e 6469 6365 735f 6178  erm = indices_ax
-0001ceb0: 6573 202b 205b 6178 6973 2066 6f72 2061  es + [axis for a
-0001cec0: 7869 7320 696e 2072 616e 6765 2878 2e72  xis in range(x.r
-0001ced0: 616e 6b29 2069 6620 6178 6973 206e 6f74  ank) if axis not
-0001cee0: 2069 6e20 696e 6469 6365 735f 6178 6573   in indices_axes
-0001cef0: 5d0a 2020 2020 7820 3d20 6d62 2e74 7261  ].    x = mb.tra
-0001cf00: 6e73 706f 7365 2878 3d78 2c20 7065 726d  nspose(x=x, perm
-0001cf10: 3d70 6572 6d29 0a20 2020 2078 203d 206d  =perm).    x = m
-0001cf20: 622e 6761 7468 6572 5f6e 6428 783d 782c  b.gather_nd(x=x,
-0001cf30: 2069 6e64 6963 6573 3d69 6e64 6963 6573   indices=indices
-0001cf40: 2c20 6e61 6d65 3d6e 616d 6529 0a0a 2020  , name=name)..  
-0001cf50: 2020 2320 6966 2074 6865 2069 6e64 6578    # if the index
-0001cf60: 2061 7865 7320 6172 6520 636f 6e6e 6563   axes are connec
-0001cf70: 742c 2077 6520 6e65 6564 2074 6f20 7472  t, we need to tr
-0001cf80: 616e 7370 6f73 6520 6974 2062 6163 6b0a  anspose it back.
-0001cf90: 2020 2020 6966 2069 735f 636f 6e6e 6563      if is_connec
-0001cfa0: 7465 643a 0a20 2020 2020 2020 206e 6577  ted:.        new
-0001cfb0: 5f64 696d 656e 7369 6f6e 7320 3d20 6c69  _dimensions = li
-0001cfc0: 7374 2872 616e 6765 2869 6e64 6963 6573  st(range(indices
-0001cfd0: 5f61 7865 735b 305d 2c20 696e 6469 6365  _axes[0], indice
-0001cfe0: 735f 6178 6573 5b30 5d20 2b20 696e 6469  s_axes[0] + indi
-0001cff0: 6365 735f 7261 6e6b 2929 0a20 2020 2020  ces_rank)).     
-0001d000: 2020 206e 6577 5f70 6572 6d20 3d20 6e65     new_perm = ne
-0001d010: 775f 6469 6d65 6e73 696f 6e73 202b 205b  w_dimensions + [
-0001d020: 0a20 2020 2020 2020 2020 2020 2061 7869  .            axi
-0001d030: 730a 2020 2020 2020 2020 2020 2020 666f  s.            fo
-0001d040: 7220 6178 6973 2069 6e20 7261 6e67 6528  r axis in range(
-0001d050: 7261 6e6b 202b 2069 6e64 6963 6573 5f72  rank + indices_r
-0001d060: 616e 6b20 2d20 6c65 6e28 696e 6469 6365  ank - len(indice
-0001d070: 735f 6178 6573 2929 0a20 2020 2020 2020  s_axes)).       
-0001d080: 2020 2020 2069 6620 6178 6973 206e 6f74       if axis not
-0001d090: 2069 6e20 6e65 775f 6469 6d65 6e73 696f   in new_dimensio
-0001d0a0: 6e73 0a20 2020 2020 2020 205d 0a20 2020  ns.        ].   
-0001d0b0: 2020 2020 2070 6572 6d5f 6261 636b 203d       perm_back =
-0001d0c0: 205b 6e65 775f 7065 726d 2e69 6e64 6578   [new_perm.index
-0001d0d0: 2861 7869 7329 2066 6f72 2061 7869 7320  (axis) for axis 
-0001d0e0: 696e 2072 616e 6765 286c 656e 286e 6577  in range(len(new
-0001d0f0: 5f70 6572 6d29 295d 0a20 2020 2020 2020  _perm))].       
-0001d100: 2078 203d 206d 622e 7472 616e 7370 6f73   x = mb.transpos
-0001d110: 6528 783d 782c 2070 6572 6d3d 7065 726d  e(x=x, perm=perm
-0001d120: 5f62 6163 6b2c 206e 616d 653d 6e6f 6465  _back, name=node
-0001d130: 2e6e 616d 6529 0a20 2020 2063 6f6e 7465  .name).    conte
-0001d140: 7874 2e61 6464 2878 290a 0a0a 4072 6567  xt.add(x)...@reg
-0001d150: 6973 7465 725f 746f 7263 685f 6f70 0a64  ister_torch_op.d
-0001d160: 6566 206f 6e65 7328 636f 6e74 6578 742c  ef ones(context,
-0001d170: 206e 6f64 6529 3a0a 2020 2020 696e 7075   node):.    inpu
-0001d180: 7473 203d 205f 6765 745f 696e 7075 7473  ts = _get_inputs
-0001d190: 2863 6f6e 7465 7874 2c20 6e6f 6465 2c20  (context, node, 
-0001d1a0: 6578 7065 6374 6564 3d5b 352c 2036 5d29  expected=[5, 6])
-0001d1b0: 0a20 2020 2073 697a 6520 3d20 696e 7075  .    size = inpu
-0001d1c0: 7473 5b30 5d0a 2020 2020 2320 6474 7970  ts[0].    # dtyp
-0001d1d0: 6520 3d20 4e55 4d5f 544f 5f54 4f52 4348  e = NUM_TO_TORCH
-0001d1e0: 5f44 5459 5045 5b69 6e70 7574 735b 315d  _DTYPE[inputs[1]
-0001d1f0: 2e76 616c 5d20 756e 7573 6564 0a20 2020  .val] unused.   
-0001d200: 2023 206c 6179 6f75 7420 3d20 696e 7075   # layout = inpu
-0001d210: 7473 5b32 5d20 756e 7573 6564 0a20 2020  ts[2] unused.   
-0001d220: 2023 2064 6576 6963 6520 3d20 696e 7075   # device = inpu
-0001d230: 7473 5b33 5d20 756e 7573 6564 0a20 2020  ts[3] unused.   
-0001d240: 2023 2072 6571 7569 7265 735f 6772 6164   # requires_grad
-0001d250: 203d 2069 6e70 7574 735b 345d 2075 6e75   = inputs[4] unu
-0001d260: 7365 640a 2020 2020 2320 6f75 7420 3d20  sed.    # out = 
-0001d270: 696e 7075 7473 5b35 5d20 756e 7573 6564  inputs[5] unused
-0001d280: 0a20 2020 2069 6620 6973 696e 7374 616e  .    if isinstan
-0001d290: 6365 2873 697a 652c 206c 6973 7429 3a0a  ce(size, list):.
-0001d2a0: 2020 2020 2020 2020 7369 7a65 203d 206d          size = m
-0001d2b0: 622e 636f 6e63 6174 2876 616c 7565 733d  b.concat(values=
-0001d2c0: 7369 7a65 2c20 6178 6973 3d30 290a 2020  size, axis=0).  
-0001d2d0: 2020 6669 6c6c 203d 206d 622e 6669 6c6c    fill = mb.fill
-0001d2e0: 2873 6861 7065 3d73 697a 652c 2076 616c  (shape=size, val
-0001d2f0: 7565 3d31 2e30 2c20 6e61 6d65 3d6e 6f64  ue=1.0, name=nod
-0001d300: 652e 6e61 6d65 290a 2020 2020 636f 6e74  e.name).    cont
-0001d310: 6578 742e 6164 6428 6669 6c6c 290a 0a0a  ext.add(fill)...
-0001d320: 4072 6567 6973 7465 725f 746f 7263 685f  @register_torch_
-0001d330: 6f70 0a64 6566 206f 6e65 735f 6c69 6b65  op.def ones_like
-0001d340: 2863 6f6e 7465 7874 2c20 6e6f 6465 293a  (context, node):
-0001d350: 0a20 2020 2069 6e70 7574 7320 3d20 5f67  .    inputs = _g
-0001d360: 6574 5f69 6e70 7574 7328 636f 6e74 6578  et_inputs(contex
-0001d370: 742c 206e 6f64 652c 2065 7870 6563 7465  t, node, expecte
-0001d380: 643d 3629 0a20 2020 2078 203d 2069 6e70  d=6).    x = inp
-0001d390: 7574 735b 305d 0a20 2020 2069 6620 6973  uts[0].    if is
-0001d3a0: 5f63 7572 7265 6e74 5f6f 7073 6574 5f76  _current_opset_v
-0001d3b0: 6572 7369 6f6e 5f63 6f6d 7061 7469 626c  ersion_compatibl
-0001d3c0: 655f 7769 7468 2874 6172 6765 742e 694f  e_with(target.iO
-0001d3d0: 5331 3629 3a0a 2020 2020 2020 2020 6669  S16):.        fi
-0001d3e0: 6c6c 203d 206d 622e 6669 6c6c 5f6c 696b  ll = mb.fill_lik
-0001d3f0: 6528 7265 665f 7465 6e73 6f72 3d78 2c20  e(ref_tensor=x, 
-0001d400: 7661 6c75 653d 312e 302c 206e 616d 653d  value=1.0, name=
-0001d410: 6e6f 6465 2e6e 616d 6529 0a20 2020 2065  node.name).    e
-0001d420: 6c73 653a 0a20 2020 2020 2020 2073 697a  lse:.        siz
-0001d430: 6520 3d20 6d62 2e73 6861 7065 2878 3d78  e = mb.shape(x=x
-0001d440: 290a 2020 2020 2020 2020 2320 6474 7970  ).        # dtyp
-0001d450: 6520 3d20 4e55 4d5f 544f 5f54 4f52 4348  e = NUM_TO_TORCH
-0001d460: 5f44 5459 5045 5b69 6e70 7574 735b 315d  _DTYPE[inputs[1]
-0001d470: 2e76 616c 5d20 756e 7573 6564 0a20 2020  .val] unused.   
-0001d480: 2020 2020 2023 206c 6179 6f75 7420 3d20       # layout = 
-0001d490: 696e 7075 7473 5b32 5d20 756e 7573 6564  inputs[2] unused
-0001d4a0: 0a20 2020 2020 2020 2023 2064 6576 6963  .        # devic
-0001d4b0: 6520 3d20 696e 7075 7473 5b33 5d20 756e  e = inputs[3] un
-0001d4c0: 7573 6564 0a20 2020 2020 2020 2023 2072  used.        # r
-0001d4d0: 6571 7569 7265 735f 6772 6164 203d 2069  equires_grad = i
-0001d4e0: 6e70 7574 735b 345d 2075 6e75 7365 640a  nputs[4] unused.
-0001d4f0: 2020 2020 2020 2020 2320 6f75 7420 3d20          # out = 
-0001d500: 696e 7075 7473 5b35 5d20 756e 7573 6564  inputs[5] unused
-0001d510: 0a20 2020 2020 2020 2066 696c 6c20 3d20  .        fill = 
-0001d520: 6d62 2e66 696c 6c28 7368 6170 653d 7369  mb.fill(shape=si
-0001d530: 7a65 2c20 7661 6c75 653d 312e 302c 206e  ze, value=1.0, n
-0001d540: 616d 653d 6e6f 6465 2e6e 616d 6529 0a20  ame=node.name). 
-0001d550: 2020 2063 6f6e 7465 7874 2e61 6464 2866     context.add(f
-0001d560: 696c 6c29 0a0a 0a64 6566 205f 6d61 6b65  ill)...def _make
-0001d570: 5f66 696c 6c5f 6f70 2873 697a 652c 2076  _fill_op(size, v
-0001d580: 616c 2c20 6e61 6d65 293a 0a20 2020 2061  al, name):.    a
-0001d590: 7373 6572 7420 7661 6c20 6973 206e 6f74  ssert val is not
-0001d5a0: 204e 6f6e 650a 2020 2020 6966 2069 7369   None.    if isi
-0001d5b0: 6e73 7461 6e63 6528 7369 7a65 2c20 6c69  nstance(size, li
-0001d5c0: 7374 293a 0a20 2020 2020 2020 2073 697a  st):.        siz
-0001d5d0: 6520 3d20 6d62 2e63 6f6e 6361 7428 7661  e = mb.concat(va
-0001d5e0: 6c75 6573 3d73 697a 652c 2061 7869 733d  lues=size, axis=
-0001d5f0: 3029 0a20 2020 2066 696c 6c20 3d20 6d62  0).    fill = mb
-0001d600: 2e66 696c 6c28 7368 6170 653d 7369 7a65  .fill(shape=size
-0001d610: 2c20 7661 6c75 653d 7661 6c2c 206e 616d  , value=val, nam
-0001d620: 653d 6e61 6d65 290a 2020 2020 7265 7475  e=name).    retu
-0001d630: 726e 2066 696c 6c0a 0a0a 4072 6567 6973  rn fill...@regis
-0001d640: 7465 725f 746f 7263 685f 6f70 0a64 6566  ter_torch_op.def
-0001d650: 2066 756c 6c28 636f 6e74 6578 742c 206e   full(context, n
-0001d660: 6f64 6529 3a0a 2020 2020 696e 7075 7473  ode):.    inputs
-0001d670: 203d 205f 6765 745f 696e 7075 7473 2863   = _get_inputs(c
-0001d680: 6f6e 7465 7874 2c20 6e6f 6465 290a 2020  ontext, node).  
-0001d690: 2020 7369 7a65 203d 2069 6e70 7574 735b    size = inputs[
-0001d6a0: 305d 0a20 2020 2076 616c 203d 2069 6e70  0].    val = inp
-0001d6b0: 7574 735b 315d 2e76 616c 0a20 2020 2072  uts[1].val.    r
-0001d6c0: 6573 756c 7420 3d20 5f6d 616b 655f 6669  esult = _make_fi
-0001d6d0: 6c6c 5f6f 7028 7369 7a65 2c20 7661 6c2c  ll_op(size, val,
-0001d6e0: 206e 6f64 652e 6e61 6d65 290a 2020 2020   node.name).    
-0001d6f0: 636f 6e74 6578 742e 6164 6428 7265 7375  context.add(resu
-0001d700: 6c74 290a 0a0a 4072 6567 6973 7465 725f  lt)...@register_
-0001d710: 746f 7263 685f 6f70 0a64 6566 2066 756c  torch_op.def ful
-0001d720: 6c5f 6c69 6b65 2863 6f6e 7465 7874 2c20  l_like(context, 
-0001d730: 6e6f 6465 293a 0a20 2020 2069 6e70 7574  node):.    input
-0001d740: 7320 3d20 5f67 6574 5f69 6e70 7574 7328  s = _get_inputs(
-0001d750: 636f 6e74 6578 742c 206e 6f64 652c 2065  context, node, e
-0001d760: 7870 6563 7465 643d 3729 0a20 2020 2078  xpected=7).    x
-0001d770: 203d 2069 6e70 7574 735b 305d 0a20 2020   = inputs[0].   
-0001d780: 2076 616c 203d 2069 6e70 7574 735b 315d   val = inputs[1]
-0001d790: 2e76 616c 0a20 2020 2069 6620 6973 5f63  .val.    if is_c
-0001d7a0: 7572 7265 6e74 5f6f 7073 6574 5f76 6572  urrent_opset_ver
-0001d7b0: 7369 6f6e 5f63 6f6d 7061 7469 626c 655f  sion_compatible_
-0001d7c0: 7769 7468 2874 6172 6765 742e 694f 5331  with(target.iOS1
-0001d7d0: 3629 3a0a 2020 2020 2020 2020 7265 7375  6):.        resu
-0001d7e0: 6c74 203d 206d 622e 6669 6c6c 5f6c 696b  lt = mb.fill_lik
-0001d7f0: 6528 7265 665f 7465 6e73 6f72 3d78 2c20  e(ref_tensor=x, 
-0001d800: 7661 6c75 653d 7661 6c2c 206e 616d 653d  value=val, name=
-0001d810: 6e6f 6465 2e6e 616d 6529 0a20 2020 2065  node.name).    e
-0001d820: 6c73 653a 0a20 2020 2020 2020 2073 697a  lse:.        siz
-0001d830: 6520 3d20 6d62 2e73 6861 7065 2878 3d69  e = mb.shape(x=i
-0001d840: 6e70 7574 735b 305d 290a 2020 2020 2020  nputs[0]).      
-0001d850: 2020 7265 7375 6c74 203d 205f 6d61 6b65    result = _make
-0001d860: 5f66 696c 6c5f 6f70 2873 697a 652c 2076  _fill_op(size, v
-0001d870: 616c 2c20 6e6f 6465 2e6e 616d 6529 0a20  al, node.name). 
-0001d880: 2020 2063 6f6e 7465 7874 2e61 6464 2872     context.add(r
-0001d890: 6573 756c 7429 0a0a 0a40 7265 6769 7374  esult)...@regist
-0001d8a0: 6572 5f74 6f72 6368 5f6f 700a 6465 6620  er_torch_op.def 
-0001d8b0: 6e65 775f 6675 6c6c 2863 6f6e 7465 7874  new_full(context
-0001d8c0: 2c20 6e6f 6465 293a 0a20 2020 2023 2054  , node):.    # T
-0001d8d0: 6865 2064 6966 6665 7265 6e63 6520 6265  he difference be
-0001d8e0: 7477 6565 6e20 226e 6577 5f66 756c 6c22  tween "new_full"
-0001d8f0: 2061 6e64 2022 6675 6c6c 2220 6973 2074   and "full" is t
-0001d900: 6861 7420 7468 6520 226e 6577 5f66 756c  hat the "new_ful
-0001d910: 6c22 2069 7320 6361 6c6c 6564 2066 726f  l" is called fro
-0001d920: 6d0a 2020 2020 2320 616e 2065 7869 7374  m.    # an exist
-0001d930: 696e 6720 7465 6e73 6f72 3a20 7465 6e73  ing tensor: tens
-0001d940: 6f72 2e6e 6577 5f66 756c 6c28 7369 7a65  or.new_full(size
-0001d950: 2c20 6669 6c6c 5f76 616c 7565 292c 2077  , fill_value), w
-0001d960: 6869 6c65 2074 6865 2022 6675 6c6c 2220  hile the "full" 
-0001d970: 6973 2063 616c 6c65 640a 2020 2020 2320  is called.    # 
-0001d980: 6672 6f6d 2074 6865 2074 6f72 6368 2041  from the torch A
-0001d990: 5049 3a20 746f 7263 682e 6675 6c6c 2873  PI: torch.full(s
-0001d9a0: 697a 652c 2066 696c 6c5f 7661 6c75 6529  ize, fill_value)
-0001d9b0: 2e0a 2020 2020 2320 4275 7420 7468 6579  ..    # But they
-0001d9c0: 2061 7265 2062 6173 6963 616c 6c79 2064   are basically d
-0001d9d0: 6f69 6e67 2074 6865 2073 616d 6520 7468  oing the same th
-0001d9e0: 696e 672e 0a20 2020 2069 6e70 7574 7320  ing..    inputs 
-0001d9f0: 3d20 5f67 6574 5f69 6e70 7574 7328 636f  = _get_inputs(co
-0001da00: 6e74 6578 742c 206e 6f64 6529 0a20 2020  ntext, node).   
-0001da10: 2073 697a 6520 3d20 696e 7075 7473 5b31   size = inputs[1
-0001da20: 5d0a 2020 2020 7661 6c20 3d20 696e 7075  ].    val = inpu
-0001da30: 7473 5b32 5d2e 7661 6c0a 2020 2020 7265  ts[2].val.    re
-0001da40: 7375 6c74 203d 205f 6d61 6b65 5f66 696c  sult = _make_fil
-0001da50: 6c5f 6f70 2873 697a 652c 2076 616c 2c20  l_op(size, val, 
-0001da60: 6e6f 6465 2e6e 616d 6529 0a20 2020 2063  node.name).    c
-0001da70: 6f6e 7465 7874 2e61 6464 2872 6573 756c  ontext.add(resul
-0001da80: 7429 0a0a 4072 6567 6973 7465 725f 746f  t)..@register_to
-0001da90: 7263 685f 6f70 0a64 6566 2072 616e 6469  rch_op.def randi
-0001daa0: 6e74 2863 6f6e 7465 7874 2c20 6e6f 6465  nt(context, node
-0001dab0: 293a 0a20 2020 2069 6e70 7574 7320 3d20  ):.    inputs = 
-0001dac0: 5f67 6574 5f69 6e70 7574 7328 636f 6e74  _get_inputs(cont
-0001dad0: 6578 742c 206e 6f64 652c 2065 7870 6563  ext, node, expec
-0001dae0: 7465 643d 3829 0a20 2020 206c 6f77 203d  ted=8).    low =
-0001daf0: 206d 622e 6361 7374 2878 3d69 6e70 7574   mb.cast(x=input
-0001db00: 735b 305d 2c20 6474 7970 653d 2266 7033  s[0], dtype="fp3
-0001db10: 3222 290a 2020 2020 6869 6768 203d 206d  2").    high = m
-0001db20: 622e 6361 7374 2878 3d69 6e70 7574 735b  b.cast(x=inputs[
-0001db30: 315d 2c20 6474 7970 653d 2266 7033 3222  1], dtype="fp32"
-0001db40: 290a 2020 2020 7368 6170 6520 3d20 696e  ).    shape = in
-0001db50: 7075 7473 5b32 5d0a 2020 2020 7261 6e64  puts[2].    rand
-0001db60: 5f75 6e69 666f 726d 203d 206d 622e 7261  _uniform = mb.ra
-0001db70: 6e64 6f6d 5f75 6e69 666f 726d 2873 6861  ndom_uniform(sha
-0001db80: 7065 3d73 6861 7065 2c20 6c6f 773d 6c6f  pe=shape, low=lo
-0001db90: 772c 2068 6967 683d 6869 6768 290a 2020  w, high=high).  
-0001dba0: 2020 7261 6e64 5f69 6e74 203d 206d 622e    rand_int = mb.
-0001dbb0: 6361 7374 2878 3d72 616e 645f 756e 6966  cast(x=rand_unif
-0001dbc0: 6f72 6d2c 2064 7479 7065 3d22 696e 7433  orm, dtype="int3
-0001dbd0: 3222 2c20 6e61 6d65 3d6e 6f64 652e 6e61  2", name=node.na
-0001dbe0: 6d65 290a 2020 2020 636f 6e74 6578 742e  me).    context.
-0001dbf0: 6164 6428 7261 6e64 5f69 6e74 290a 0a0a  add(rand_int)...
-0001dc00: 4072 6567 6973 7465 725f 746f 7263 685f  @register_torch_
-0001dc10: 6f70 0a64 6566 2062 6974 7769 7365 5f6e  op.def bitwise_n
-0001dc20: 6f74 2863 6f6e 7465 7874 2c20 6e6f 6465  ot(context, node
-0001dc30: 293a 0a20 2020 2069 6e70 7574 7320 3d20  ):.    inputs = 
-0001dc40: 5f67 6574 5f69 6e70 7574 7328 636f 6e74  _get_inputs(cont
-0001dc50: 6578 742c 206e 6f64 6529 0a20 2020 2078  ext, node).    x
-0001dc60: 203d 2069 6e70 7574 735b 305d 0a20 2020   = inputs[0].   
-0001dc70: 2064 7479 7065 203d 2078 2e64 7479 7065   dtype = x.dtype
-0001dc80: 0a20 2020 2069 6620 7479 7065 732e 6973  .    if types.is
-0001dc90: 5f69 6e74 2864 7479 7065 293a 0a20 2020  _int(dtype):.   
-0001dca0: 2020 2020 2078 203d 206d 622e 6164 6428       x = mb.add(
-0001dcb0: 783d 782c 2079 3d31 290a 2020 2020 2020  x=x, y=1).      
-0001dcc0: 2020 7820 3d20 6d62 2e6d 756c 2878 3d78    x = mb.mul(x=x
-0001dcd0: 2c20 793d 2d31 2c20 6e61 6d65 3d6e 6f64  , y=-1, name=nod
-0001dce0: 652e 6e61 6d65 290a 2020 2020 656c 6966  e.name).    elif
-0001dcf0: 2074 7970 6573 2e69 735f 626f 6f6c 2864   types.is_bool(d
-0001dd00: 7479 7065 293a 0a20 2020 2020 2020 2078  type):.        x
-0001dd10: 203d 206d 622e 6c6f 6769 6361 6c5f 6e6f   = mb.logical_no
-0001dd20: 7428 783d 782c 206e 616d 653d 6e6f 6465  t(x=x, name=node
-0001dd30: 2e6e 616d 6529 0a20 2020 2065 6c73 653a  .name).    else:
-0001dd40: 0a20 2020 2020 2020 2072 6169 7365 2056  .        raise V
-0001dd50: 616c 7565 4572 726f 7228 224e 6f74 2073  alueError("Not s
-0001dd60: 7570 706f 7274 6564 2074 7970 6520 7b7d  upported type {}
-0001dd70: 2066 6f75 6e64 2066 6f72 2027 6269 7477   found for 'bitw
-0001dd80: 6973 655f 6e6f 7427 206f 7022 2e66 6f72  ise_not' op".for
-0001dd90: 6d61 7428 6474 7970 6529 290a 2020 2020  mat(dtype)).    
-0001dda0: 636f 6e74 6578 742e 6164 6428 7829 0a0a  context.add(x)..
-0001ddb0: 0a40 7265 6769 7374 6572 5f74 6f72 6368  .@register_torch
-0001ddc0: 5f6f 7028 746f 7263 685f 616c 6961 733d  _op(torch_alias=
-0001ddd0: 5b22 616e 6422 5d29 0a64 6566 2062 6974  ["and"]).def bit
-0001dde0: 7769 7365 5f61 6e64 2863 6f6e 7465 7874  wise_and(context
-0001ddf0: 2c20 6e6f 6465 293a 0a20 2020 2069 6e70  , node):.    inp
-0001de00: 7574 7320 3d20 5f67 6574 5f69 6e70 7574  uts = _get_input
-0001de10: 7328 636f 6e74 6578 742c 206e 6f64 6529  s(context, node)
-0001de20: 0a0a 2020 2020 696e 7075 745f 6474 7970  ..    input_dtyp
-0001de30: 6573 203d 205b 692e 6474 7970 6520 666f  es = [i.dtype fo
-0001de40: 7220 6920 696e 2069 6e70 7574 735d 0a20  r i in inputs]. 
-0001de50: 2020 2069 6620 616c 6c28 7479 7065 732e     if all(types.
-0001de60: 6973 5f62 6f6f 6c28 696e 7075 745f 6474  is_bool(input_dt
-0001de70: 7970 6529 2066 6f72 2069 6e70 7574 5f64  ype) for input_d
-0001de80: 7479 7065 2069 6e20 696e 7075 745f 6474  type in input_dt
-0001de90: 7970 6573 293a 0a20 2020 2020 2020 206c  ypes):.        l
-0001dea0: 6f67 6963 616c 5f61 6e64 2863 6f6e 7465  ogical_and(conte
-0001deb0: 7874 2c20 6e6f 6465 290a 2020 2020 656c  xt, node).    el
-0001dec0: 7365 3a0a 2020 2020 2020 2020 7261 6973  se:.        rais
-0001ded0: 6520 4e6f 7449 6d70 6c65 6d65 6e74 6564  e NotImplemented
-0001dee0: 4572 726f 7228 0a20 2020 2020 2020 2020  Error(.         
-0001def0: 2020 2066 2254 6865 2060 6269 7477 6973     f"The `bitwis
-0001df00: 655f 616e 6460 206f 7020 6f6e 6c79 2073  e_and` op only s
-0001df10: 7570 706f 7274 7320 626f 6f6c 6561 6e20  upports boolean 
-0001df20: 696e 7075 742c 2062 7574 2067 6574 207b  input, but get {
-0001df30: 696e 7075 745f 6474 7970 6573 7d2e 220a  input_dtypes}.".
-0001df40: 2020 2020 2020 2020 290a 0a0a 6465 6620          )...def 
-0001df50: 5f61 7667 5f70 6f6f 6c28 636f 6e74 6578  _avg_pool(contex
-0001df60: 742c 206e 6f64 652c 2069 6e70 7574 7329  t, node, inputs)
-0001df70: 3a0a 2020 2020 7820 3d20 696e 7075 7473  :.    x = inputs
-0001df80: 5b30 5d0a 2020 2020 6b65 726e 656c 5f73  [0].    kernel_s
-0001df90: 697a 6573 203d 2069 6e70 7574 735b 315d  izes = inputs[1]
-0001dfa0: 0a20 2020 2073 7472 6964 6573 203d 2069  .    strides = i
-0001dfb0: 6e70 7574 735b 325d 0a20 2020 2069 6620  nputs[2].    if 
-0001dfc0: 7374 7269 6465 732e 6f70 2e6f 705f 7479  strides.op.op_ty
-0001dfd0: 7065 203d 3d20 2263 6f6e 7374 2220 616e  pe == "const" an
-0001dfe0: 6420 286e 6f74 206c 6973 7428 7374 7269  d (not list(stri
-0001dff0: 6465 732e 7661 6c29 293a 0a20 2020 2020  des.val)):.     
-0001e000: 2020 2073 7472 6964 6573 203d 206d 622e     strides = mb.
-0001e010: 636f 6e73 7428 7661 6c3d 6b65 726e 656c  const(val=kernel
-0001e020: 5f73 697a 6573 2e76 616c 2c20 6e61 6d65  _sizes.val, name
-0001e030: 3d73 7472 6964 6573 2e6e 616d 6529 0a20  =strides.name). 
-0001e040: 2020 2070 6164 5f74 7970 6520 3d20 2263     pad_type = "c
-0001e050: 7573 746f 6d22 0a20 2020 2023 204e 6565  ustom".    # Nee
-0001e060: 6420 746f 2065 7870 6c69 6369 746c 7920  d to explicitly 
-0001e070: 7374 6174 6520 4c2d 522c 2054 2d42 2070  state L-R, T-B p
-0001e080: 6164 0a20 2020 2070 6164 203d 2069 6e70  ad.    pad = inp
-0001e090: 7574 735b 335d 0a20 2020 2070 6164 203d  uts[3].    pad =
-0001e0a0: 205f 6e70 2e72 6570 6561 7428 7061 642e   _np.repeat(pad.
-0001e0b0: 7661 6c2c 2032 290a 2020 2020 6365 696c  val, 2).    ceil
-0001e0c0: 5f6d 6f64 6520 3d20 696e 7075 7473 5b34  _mode = inputs[4
-0001e0d0: 5d2e 7661 6c0a 2020 2020 696e 636c 7564  ].val.    includ
-0001e0e0: 655f 7061 6420 3d20 696e 7075 7473 5b35  e_pad = inputs[5
-0001e0f0: 5d2e 7661 6c0a 0a20 2020 2073 7061 7469  ].val..    spati
-0001e100: 616c 5f72 616e 6b20 3d20 6c65 6e28 7061  al_rank = len(pa
-0001e110: 6429 202f 2f20 320a 2020 2020 6966 2073  d) // 2.    if s
-0001e120: 7061 7469 616c 5f72 616e 6b20 3e20 3220  patial_rank > 2 
-0001e130: 616e 6420 6365 696c 5f6d 6f64 6520 6973  and ceil_mode is
-0001e140: 2054 7275 6520 616e 6420 6c69 7374 2873   True and list(s
-0001e150: 7472 6964 6573 2e76 616c 2920 213d 205b  trides.val) != [
-0001e160: 315d 202a 206c 656e 2873 7472 6964 6573  1] * len(strides
-0001e170: 2e76 616c 293a 0a20 2020 2020 2020 2023  .val):.        #
-0001e180: 2073 696e 6365 204d 494c 2064 6f65 7320   since MIL does 
-0001e190: 6e6f 7420 7375 7070 6f72 7420 6365 696c  not support ceil
-0001e1a0: 5f6d 6f64 6520 666f 7220 3344 2070 6f6f  _mode for 3D poo
-0001e1b0: 6c2c 0a20 2020 2020 2020 2023 206e 6565  l,.        # nee
-0001e1c0: 6420 746f 2061 646a 7573 7420 7061 6464  d to adjust padd
-0001e1d0: 696e 6720 7661 6c75 6573 2069 6620 6365  ing values if ce
-0001e1e0: 696c 5f6d 6f64 6520 6973 2054 7275 650a  il_mode is True.
-0001e1f0: 2020 2020 2020 2020 2320 6365 696c 5f6d          # ceil_m
-0001e200: 6f64 6520 6f6e 6c79 2063 6175 7365 7320  ode only causes 
-0001e210: 616e 7920 6469 6666 6572 656e 6365 2074  any difference t
-0001e220: 686f 7567 682c 2069 6620 7468 6520 7374  hough, if the st
-0001e230: 7269 6465 7320 6172 6520 6e6f 7420 310a  rides are not 1.
-0001e240: 2020 2020 2020 2020 785f 7370 6174 6961          x_spatia
-0001e250: 6c5f 6469 6d65 6e73 696f 6e73 203d 2078  l_dimensions = x
-0001e260: 2e73 6861 7065 5b2d 7370 6174 6961 6c5f  .shape[-spatial_
-0001e270: 7261 6e6b 3a5d 0a20 2020 2020 2020 206e  rank:].        n
-0001e280: 6577 5f70 6164 203d 205f 6164 6a75 7374  ew_pad = _adjust
-0001e290: 5f70 6164 5f66 6f72 5f63 6569 6c5f 6d6f  _pad_for_ceil_mo
-0001e2a0: 6465 280a 2020 2020 2020 2020 2020 2020  de(.            
-0001e2b0: 785f 7370 6174 6961 6c5f 6469 6d65 6e73  x_spatial_dimens
-0001e2c0: 696f 6e73 2c20 6b65 726e 656c 5f73 697a  ions, kernel_siz
-0001e2d0: 6573 2e76 616c 2c20 7374 7269 6465 732e  es.val, strides.
-0001e2e0: 7661 6c2c 2070 6164 0a20 2020 2020 2020  val, pad.       
-0001e2f0: 2029 0a20 2020 2020 2020 2069 6620 5f6e   ).        if _n
-0001e300: 702e 7375 6d28 5f6e 702e 6162 7328 6e65  p.sum(_np.abs(ne
-0001e310: 775f 7061 6420 2d20 7061 6429 2920 3e20  w_pad - pad)) > 
-0001e320: 3165 2d33 3a0a 2020 2020 2020 2020 2020  1e-3:.          
-0001e330: 2020 6966 2069 6e63 6c75 6465 5f70 6164    if include_pad
-0001e340: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-0001e350: 2020 7261 6973 6520 5661 6c75 6545 7272    raise ValueErr
-0001e360: 6f72 2827 706f 6f6c 3344 2077 6974 6820  or('pool3D with 
-0001e370: 6365 696c 206d 6f64 653d 5472 7565 2061  ceil mode=True a
-0001e380: 6e64 2069 6e63 6c75 6465 5f70 6164 3d54  nd include_pad=T
-0001e390: 7275 6520 6e6f 7420 7375 7070 6f72 7465  rue not supporte
-0001e3a0: 6427 290a 2020 2020 2020 2020 7061 6420  d').        pad 
-0001e3b0: 3d20 6e65 775f 7061 640a 0a20 2020 2070  = new_pad..    p
-0001e3c0: 6f6f 6c20 3d20 6d62 2e61 7667 5f70 6f6f  ool = mb.avg_poo
-0001e3d0: 6c28 0a20 2020 2020 2020 2078 3d78 2c0a  l(.        x=x,.
-0001e3e0: 2020 2020 2020 2020 6b65 726e 656c 5f73          kernel_s
-0001e3f0: 697a 6573 3d6b 6572 6e65 6c5f 7369 7a65  izes=kernel_size
-0001e400: 732c 0a20 2020 2020 2020 2073 7472 6964  s,.        strid
-0001e410: 6573 3d73 7472 6964 6573 2c0a 2020 2020  es=strides,.    
-0001e420: 2020 2020 7061 645f 7479 7065 3d70 6164      pad_type=pad
-0001e430: 5f74 7970 652c 0a20 2020 2020 2020 2070  _type,.        p
-0001e440: 6164 3d70 6164 2c0a 2020 2020 2020 2020  ad=pad,.        
-0001e450: 6e61 6d65 3d6e 6f64 652e 6e61 6d65 2c0a  name=node.name,.
-0001e460: 2020 2020 2020 2020 6578 636c 7564 655f          exclude_
-0001e470: 7061 6464 696e 675f 6672 6f6d 5f61 7665  padding_from_ave
-0001e480: 7261 6765 3d6e 6f74 2069 6e63 6c75 6465  rage=not include
-0001e490: 5f70 6164 2c0a 2020 2020 2020 2020 6365  _pad,.        ce
-0001e4a0: 696c 5f6d 6f64 653d 6365 696c 5f6d 6f64  il_mode=ceil_mod
-0001e4b0: 6520 6966 2073 7061 7469 616c 5f72 616e  e if spatial_ran
-0001e4c0: 6b20 3c3d 2032 2065 6c73 6520 4661 6c73  k <= 2 else Fals
-0001e4d0: 652c 0a20 2020 2029 0a20 2020 2063 6f6e  e,.    ).    con
-0001e4e0: 7465 7874 2e61 6464 2870 6f6f 6c29 0a0a  text.add(pool)..
-0001e4f0: 0a40 7265 6769 7374 6572 5f74 6f72 6368  .@register_torch
-0001e500: 5f6f 700a 6465 6620 6176 675f 706f 6f6c  _op.def avg_pool
-0001e510: 3164 2863 6f6e 7465 7874 2c20 6e6f 6465  1d(context, node
-0001e520: 293a 0a20 2020 2069 6e70 7574 7320 3d20  ):.    inputs = 
-0001e530: 5f67 6574 5f69 6e70 7574 7328 636f 6e74  _get_inputs(cont
-0001e540: 6578 742c 206e 6f64 652c 2065 7870 6563  ext, node, expec
-0001e550: 7465 643d 3629 0a20 2020 205f 6176 675f  ted=6).    _avg_
-0001e560: 706f 6f6c 2863 6f6e 7465 7874 2c20 6e6f  pool(context, no
-0001e570: 6465 2c20 696e 7075 7473 290a 0a0a 4072  de, inputs)...@r
-0001e580: 6567 6973 7465 725f 746f 7263 685f 6f70  egister_torch_op
-0001e590: 0a64 6566 2061 7667 5f70 6f6f 6c32 6428  .def avg_pool2d(
-0001e5a0: 636f 6e74 6578 742c 206e 6f64 6529 3a0a  context, node):.
-0001e5b0: 2020 2020 696e 7075 7473 203d 205f 6765      inputs = _ge
-0001e5c0: 745f 696e 7075 7473 2863 6f6e 7465 7874  t_inputs(context
-0001e5d0: 2c20 6e6f 6465 2c20 6578 7065 6374 6564  , node, expected
-0001e5e0: 3d37 290a 2020 2020 6469 7669 736f 725f  =7).    divisor_
-0001e5f0: 6f76 6572 7269 6465 203d 2069 6e70 7574  override = input
-0001e600: 735b 365d 0a20 2020 2069 6620 6469 7669  s[6].    if divi
-0001e610: 736f 725f 6f76 6572 7269 6465 2069 7320  sor_override is 
-0001e620: 6e6f 7420 4e6f 6e65 3a0a 2020 2020 2020  not None:.      
-0001e630: 2020 7261 6973 6520 5661 6c75 6545 7272    raise ValueErr
-0001e640: 6f72 2822 6469 7669 736f 725f 6f76 6572  or("divisor_over
-0001e650: 7269 6465 2069 7320 6e6f 7420 7375 7070  ride is not supp
-0001e660: 6f72 7465 6420 666f 7220 6176 675f 706f  orted for avg_po
-0001e670: 6f6c 3264 2229 0a20 2020 205f 6176 675f  ol2d").    _avg_
-0001e680: 706f 6f6c 2863 6f6e 7465 7874 2c20 6e6f  pool(context, no
-0001e690: 6465 2c20 696e 7075 7473 290a 0a0a 4072  de, inputs)...@r
-0001e6a0: 6567 6973 7465 725f 746f 7263 685f 6f70  egister_torch_op
-0001e6b0: 0a64 6566 2061 7667 5f70 6f6f 6c33 6428  .def avg_pool3d(
-0001e6c0: 636f 6e74 6578 742c 206e 6f64 6529 3a0a  context, node):.
-0001e6d0: 2020 2020 696e 7075 7473 203d 205f 6765      inputs = _ge
-0001e6e0: 745f 696e 7075 7473 2863 6f6e 7465 7874  t_inputs(context
-0001e6f0: 2c20 6e6f 6465 2c20 6578 7065 6374 6564  , node, expected
-0001e700: 3d37 290a 2020 2020 6469 7669 736f 725f  =7).    divisor_
-0001e710: 6f76 6572 7269 6465 203d 2069 6e70 7574  override = input
-0001e720: 735b 365d 0a20 2020 2069 6620 6469 7669  s[6].    if divi
-0001e730: 736f 725f 6f76 6572 7269 6465 2069 7320  sor_override is 
-0001e740: 6e6f 7420 4e6f 6e65 3a0a 2020 2020 2020  not None:.      
-0001e750: 2020 7261 6973 6520 5661 6c75 6545 7272    raise ValueErr
-0001e760: 6f72 2822 6469 7669 736f 725f 6f76 6572  or("divisor_over
-0001e770: 7269 6465 2069 7320 6e6f 7420 7375 7070  ride is not supp
-0001e780: 6f72 7465 6420 666f 7220 6176 675f 706f  orted for avg_po
-0001e790: 6f6c 3364 2229 0a20 2020 205f 6176 675f  ol3d").    _avg_
-0001e7a0: 706f 6f6c 2863 6f6e 7465 7874 2c20 6e6f  pool(context, no
-0001e7b0: 6465 2c20 696e 7075 7473 290a 0a0a 4072  de, inputs)...@r
-0001e7c0: 6567 6973 7465 725f 746f 7263 685f 6f70  egister_torch_op
-0001e7d0: 0a64 6566 206c 6f67 5f73 6f66 746d 6178  .def log_softmax
-0001e7e0: 2863 6f6e 7465 7874 2c20 6e6f 6465 293a  (context, node):
-0001e7f0: 0a20 2020 2069 6e70 7574 7320 3d20 5f67  .    inputs = _g
-0001e800: 6574 5f69 6e70 7574 7328 636f 6e74 6578  et_inputs(contex
-0001e810: 742c 206e 6f64 6529 0a0a 2020 2020 7820  t, node)..    x 
-0001e820: 3d20 696e 7075 7473 5b30 5d0a 2020 2020  = inputs[0].    
-0001e830: 6178 6973 203d 2069 6e70 7574 735b 315d  axis = inputs[1]
-0001e840: 0a20 2020 206f 7574 203d 2069 6e70 7574  .    out = input
-0001e850: 735b 325d 2020 2320 4967 6e6f 7265 642e  s[2]  # Ignored.
-0001e860: 0a20 2020 2061 7373 6572 7420 6f75 7420  .    assert out 
-0001e870: 6973 204e 6f6e 650a 2020 2020 7265 7320  is None.    res 
-0001e880: 3d20 6d62 2e73 6f66 746d 6178 2878 3d78  = mb.softmax(x=x
-0001e890: 2c20 6178 6973 3d61 7869 732c 206e 616d  , axis=axis, nam
-0001e8a0: 653d 6e6f 6465 2e6e 616d 6520 2b20 225f  e=node.name + "_
-0001e8b0: 736f 6674 6d61 7822 290a 2020 2020 7265  softmax").    re
-0001e8c0: 7320 3d20 6d62 2e6c 6f67 2878 3d72 6573  s = mb.log(x=res
-0001e8d0: 2c20 6e61 6d65 3d6e 6f64 652e 6e61 6d65  , name=node.name
-0001e8e0: 290a 2020 2020 636f 6e74 6578 742e 6164  ).    context.ad
-0001e8f0: 6428 7265 7329 0a0a 0a40 7265 6769 7374  d(res)...@regist
-0001e900: 6572 5f74 6f72 6368 5f6f 7028 746f 7263  er_torch_op(torc
-0001e910: 685f 616c 6961 733d 5b22 6e6c 6c5f 6c6f  h_alias=["nll_lo
-0001e920: 7373 5f6e 6422 5d29 0a64 6566 206e 6c6c  ss_nd"]).def nll
-0001e930: 5f6c 6f73 7328 636f 6e74 6578 742c 206e  _loss(context, n
-0001e940: 6f64 6529 3a0a 2020 2020 696e 7075 7473  ode):.    inputs
-0001e950: 203d 205f 6765 745f 696e 7075 7473 2863   = _get_inputs(c
-0001e960: 6f6e 7465 7874 2c20 6e6f 6465 2c20 6578  ontext, node, ex
-0001e970: 7065 6374 6564 3d35 290a 0a20 2020 2078  pected=5)..    x
-0001e980: 203d 2069 6e70 7574 735b 305d 0a20 2020   = inputs[0].   
-0001e990: 2074 6172 6765 7420 3d20 696e 7075 7473   target = inputs
-0001e9a0: 5b31 5d0a 2020 2020 7765 6967 6874 203d  [1].    weight =
-0001e9b0: 2069 6e70 7574 735b 325d 0a20 2020 2072   inputs[2].    r
-0001e9c0: 6564 7563 7469 6f6e 203d 2069 6e70 7574  eduction = input
-0001e9d0: 735b 335d 0a20 2020 2069 676e 6f72 655f  s[3].    ignore_
-0001e9e0: 696e 6465 7820 3d20 696e 7075 7473 5b34  index = inputs[4
-0001e9f0: 5d0a 0a20 2020 2023 206d 6170 7069 6e67  ]..    # mapping
-0001ea00: 2066 6f72 2072 6564 7563 7469 6f6e 0a20   for reduction. 
-0001ea10: 2020 2072 6564 7563 7469 6f6e 5f6d 6170     reduction_map
-0001ea20: 7069 6e67 203d 207b 303a 2022 6e6f 6e65  ping = {0: "none
-0001ea30: 222c 2031 3a20 226d 6561 6e22 2c20 323a  ", 1: "mean", 2:
-0001ea40: 2022 7375 6d22 7d0a 2020 2020 7265 6475   "sum"}.    redu
-0001ea50: 6374 696f 6e20 3d20 7265 6475 6374 696f  ction = reductio
-0001ea60: 6e5f 6d61 7070 696e 675b 7265 6475 6374  n_mapping[reduct
-0001ea70: 696f 6e2e 7661 6c5d 0a0a 2020 2020 2320  ion.val]..    # 
-0001ea80: 636f 6d70 7574 6520 7468 6520 7765 6967  compute the weig
-0001ea90: 6874 7320 6c6f 7373 0a20 2020 2062 6174  hts loss.    bat
-0001eaa0: 6368 5f73 697a 6520 3d20 782e 7368 6170  ch_size = x.shap
-0001eab0: 655b 305d 0a0a 2020 2020 2320 6f6e 6c79  e[0]..    # only
-0001eac0: 2073 7570 706f 7274 2077 6569 6768 7420   support weight 
-0001ead0: 616e 6420 6967 6e6f 7265 5f69 6e64 6578  and ignore_index
-0001eae0: 2062 6f74 6820 4e6f 6e65 0a20 2020 2069   both None.    i
-0001eaf0: 6620 7765 6967 6874 2069 7320 6e6f 7420  f weight is not 
-0001eb00: 4e6f 6e65 3a0a 2020 2020 2020 2020 7261  None:.        ra
-0001eb10: 6973 6520 4e6f 7449 6d70 6c65 6d65 6e74  ise NotImplement
-0001eb20: 6564 4572 726f 7228 224f 6e6c 7920 756e  edError("Only un
-0001eb30: 6974 7920 7765 6967 6874 2069 7320 7375  ity weight is su
-0001eb40: 7070 6f72 7465 6420 666f 7220 4e4c 4c4c  pported for NLLL
-0001eb50: 6f73 732e 2229 0a20 2020 2069 6620 6967  oss.").    if ig
-0001eb60: 6e6f 7265 5f69 6e64 6578 2e76 616c 2021  nore_index.val !
-0001eb70: 3d20 2d31 3030 3a0a 2020 2020 2020 2020  = -100:.        
-0001eb80: 7261 6973 6520 4e6f 7449 6d70 6c65 6d65  raise NotImpleme
-0001eb90: 6e74 6564 4572 726f 7228 2269 676e 6f72  ntedError("ignor
-0001eba0: 6520 696e 6465 7820 6e6f 7420 7375 7070  e index not supp
-0001ebb0: 6f72 7465 6420 666f 7220 4e4c 4c4c 6f73  orted for NLLLos
-0001ebc0: 732e 2229 0a0a 2020 2020 7820 3d20 6d62  s.")..    x = mb
-0001ebd0: 2e63 6173 7428 783d 782c 2064 7479 7065  .cast(x=x, dtype
-0001ebe0: 3d22 6670 3332 2229 0a20 2020 2078 203d  ="fp32").    x =
-0001ebf0: 206d 622e 6d75 6c28 783d 782c 2079 3d2d   mb.mul(x=x, y=-
-0001ec00: 312e 290a 2020 2020 7261 6e67 655f 696e  1.).    range_in
-0001ec10: 6469 6365 7320 3d20 6d62 2e72 616e 6765  dices = mb.range
-0001ec20: 5f31 6428 656e 643d 6261 7463 685f 7369  _1d(end=batch_si
-0001ec30: 7a65 2c20 7374 6172 743d 302c 2073 7465  ze, start=0, ste
-0001ec40: 703d 3129 0a20 2020 2074 6f74 616c 5f69  p=1).    total_i
-0001ec50: 6e64 6963 6573 203d 206d 622e 7374 6163  ndices = mb.stac
-0001ec60: 6b28 7661 6c75 6573 3d5b 7261 6e67 655f  k(values=[range_
-0001ec70: 696e 6469 6365 732c 2074 6172 6765 745d  indices, target]
-0001ec80: 2c20 6178 6973 3d31 290a 2020 2020 6c6f  , axis=1).    lo
-0001ec90: 7373 203d 206d 622e 6761 7468 6572 5f6e  ss = mb.gather_n
-0001eca0: 6428 783d 782c 2069 6e64 6963 6573 3d74  d(x=x, indices=t
-0001ecb0: 6f74 616c 5f69 6e64 6963 6573 290a 0a20  otal_indices).. 
-0001ecc0: 2020 2023 2072 6564 7563 7469 6f6e 2074     # reduction t
-0001ecd0: 7970 650a 2020 2020 6966 2072 6564 7563  ype.    if reduc
-0001ece0: 7469 6f6e 203d 3d20 226e 6f6e 6522 3a0a  tion == "none":.
-0001ecf0: 2020 2020 2020 2020 6f75 7420 3d20 6d62          out = mb
-0001ed00: 2e69 6465 6e74 6974 7928 783d 6c6f 7373  .identity(x=loss
-0001ed10: 2c20 6e61 6d65 3d6e 6f64 652e 6e61 6d65  , name=node.name
-0001ed20: 290a 2020 2020 656c 6966 2072 6564 7563  ).    elif reduc
-0001ed30: 7469 6f6e 203d 3d20 2273 756d 223a 0a20  tion == "sum":. 
-0001ed40: 2020 2020 2020 206f 7574 203d 206d 622e         out = mb.
-0001ed50: 7265 6475 6365 5f73 756d 2878 3d6c 6f73  reduce_sum(x=los
-0001ed60: 732c 2061 7865 733d 5b30 5d2c 206b 6565  s, axes=[0], kee
-0001ed70: 705f 6469 6d73 3d46 616c 7365 2c20 6e61  p_dims=False, na
-0001ed80: 6d65 3d6e 6f64 652e 6e61 6d65 290a 2020  me=node.name).  
-0001ed90: 2020 656c 6966 2072 6564 7563 7469 6f6e    elif reduction
-0001eda0: 203d 3d20 226d 6561 6e22 3a0a 2020 2020   == "mean":.    
-0001edb0: 2020 2020 6f75 7420 3d20 6d62 2e72 6561      out = mb.rea
-0001edc0: 6c5f 6469 7628 783d 6c6f 7373 2c20 793d  l_div(x=loss, y=
-0001edd0: 5f6e 702e 666c 6f61 7433 3228 6261 7463  _np.float32(batc
-0001ede0: 685f 7369 7a65 2929 0a20 2020 2020 2020  h_size)).       
-0001edf0: 206f 7574 203d 206d 622e 7265 6475 6365   out = mb.reduce
-0001ee00: 5f73 756d 2878 3d6f 7574 2c20 6178 6573  _sum(x=out, axes
-0001ee10: 3d5b 305d 2c20 6b65 6570 5f64 696d 733d  =[0], keep_dims=
-0001ee20: 4661 6c73 652c 206e 616d 653d 6e6f 6465  False, name=node
-0001ee30: 2e6e 616d 6529 0a20 2020 2065 6c73 653a  .name).    else:
-0001ee40: 0a20 2020 2020 2020 2072 6169 7365 204e  .        raise N
-0001ee50: 6f74 496d 706c 656d 656e 7465 6445 7272  otImplementedErr
-0001ee60: 6f72 2822 556e 7375 7070 6f72 7465 6420  or("Unsupported 
-0001ee70: 7265 6475 6374 696f 6e20 7479 7065 2066  reduction type f
-0001ee80: 6f72 204e 4c4c 4c6f 7373 2e22 290a 0a20  or NLLLoss.").. 
-0001ee90: 2020 2063 6f6e 7465 7874 2e61 6464 286f     context.add(o
-0001eea0: 7574 290a 0a0a 4072 6567 6973 7465 725f  ut)...@register_
-0001eeb0: 746f 7263 685f 6f70 0a64 6566 2073 6967  torch_op.def sig
-0001eec0: 6d6f 6964 2863 6f6e 7465 7874 2c20 6e6f  moid(context, no
-0001eed0: 6465 293a 0a20 2020 2069 6e70 7574 7320  de):.    inputs 
-0001eee0: 3d20 5f67 6574 5f69 6e70 7574 7328 636f  = _get_inputs(co
-0001eef0: 6e74 6578 742c 206e 6f64 652c 2065 7870  ntext, node, exp
-0001ef00: 6563 7465 643d 3129 0a0a 2020 2020 7265  ected=1)..    re
-0001ef10: 7320 3d20 6d62 2e73 6967 6d6f 6964 2878  s = mb.sigmoid(x
-0001ef20: 3d69 6e70 7574 735b 305d 2c20 6e61 6d65  =inputs[0], name
-0001ef30: 3d6e 6f64 652e 6e61 6d65 290a 2020 2020  =node.name).    
-0001ef40: 636f 6e74 6578 742e 6164 6428 7265 7329  context.add(res)
-0001ef50: 0a0a 0a40 7265 6769 7374 6572 5f74 6f72  ...@register_tor
-0001ef60: 6368 5f6f 700a 6465 6620 6861 7264 7369  ch_op.def hardsi
-0001ef70: 676d 6f69 6428 636f 6e74 6578 742c 206e  gmoid(context, n
-0001ef80: 6f64 6529 3a0a 2020 2020 696e 7075 7473  ode):.    inputs
-0001ef90: 203d 205f 6765 745f 696e 7075 7473 2863   = _get_inputs(c
-0001efa0: 6f6e 7465 7874 2c20 6e6f 6465 2c20 6578  ontext, node, ex
-0001efb0: 7065 6374 6564 3d31 290a 0a20 2020 2072  pected=1)..    r
-0001efc0: 6573 203d 206d 622e 7369 676d 6f69 645f  es = mb.sigmoid_
-0001efd0: 6861 7264 2878 3d69 6e70 7574 735b 305d  hard(x=inputs[0]
-0001efe0: 2c20 616c 7068 613d 312e 3020 2f20 362c  , alpha=1.0 / 6,
-0001eff0: 2062 6574 613d 302e 352c 206e 616d 653d   beta=0.5, name=
-0001f000: 6e6f 6465 2e6e 616d 6529 0a20 2020 2063  node.name).    c
-0001f010: 6f6e 7465 7874 2e61 6464 2872 6573 290a  ontext.add(res).
-0001f020: 0a0a 4072 6567 6973 7465 725f 746f 7263  ..@register_torc
-0001f030: 685f 6f70 0a64 6566 2067 656c 7528 636f  h_op.def gelu(co
-0001f040: 6e74 6578 742c 206e 6f64 6529 3a0a 2020  ntext, node):.  
-0001f050: 2020 696e 7075 7473 203d 205f 6765 745f    inputs = _get_
-0001f060: 696e 7075 7473 2863 6f6e 7465 7874 2c20  inputs(context, 
-0001f070: 6e6f 6465 290a 2020 2020 6173 7365 7274  node).    assert
-0001f080: 206c 656e 2869 6e70 7574 7329 2069 6e20   len(inputs) in 
-0001f090: 2831 2c20 3229 0a20 2020 2069 6620 6c65  (1, 2).    if le
-0001f0a0: 6e28 696e 7075 7473 2920 3d3d 2032 3a0a  n(inputs) == 2:.
-0001f0b0: 2020 2020 2020 2020 6170 7072 6f78 696d          approxim
-0001f0c0: 6174 6520 3d20 696e 7075 7473 5b31 5d2e  ate = inputs[1].
-0001f0d0: 7661 6c0a 2020 2020 2020 2020 6173 7365  val.        asse
-0001f0e0: 7274 2061 7070 726f 7869 6d61 7465 203d  rt approximate =
-0001f0f0: 3d20 276e 6f6e 6527 0a20 2020 2072 6573  = 'none'.    res
-0001f100: 203d 206d 622e 6765 6c75 2878 3d69 6e70   = mb.gelu(x=inp
-0001f110: 7574 735b 305d 2c20 6e61 6d65 3d6e 6f64  uts[0], name=nod
-0001f120: 652e 6e61 6d65 290a 2020 2020 636f 6e74  e.name).    cont
-0001f130: 6578 742e 6164 6428 7265 7329 0a0a 0a40  ext.add(res)...@
-0001f140: 7265 6769 7374 6572 5f74 6f72 6368 5f6f  register_torch_o
-0001f150: 7028 746f 7263 685f 616c 6961 733d 5b22  p(torch_alias=["
-0001f160: 736c 6963 6522 5d29 0a64 6566 205f 736c  slice"]).def _sl
-0001f170: 6963 6528 636f 6e74 6578 742c 206e 6f64  ice(context, nod
-0001f180: 6529 3a0a 2020 2020 696e 7075 7473 203d  e):.    inputs =
-0001f190: 205f 6765 745f 696e 7075 7473 2863 6f6e   _get_inputs(con
-0001f1a0: 7465 7874 2c20 6e6f 6465 2c20 6578 7065  text, node, expe
-0001f1b0: 6374 6564 3d35 290a 2020 2020 7820 3d20  cted=5).    x = 
-0001f1c0: 696e 7075 7473 5b30 5d0a 2020 2020 6469  inputs[0].    di
-0001f1d0: 6d20 3d20 696e 7075 7473 5b31 5d2e 7661  m = inputs[1].va
-0001f1e0: 6c0a 0a20 2020 2069 6620 696e 7075 7473  l..    if inputs
-0001f1f0: 5b32 5d20 616e 6420 696e 7075 7473 5b32  [2] and inputs[2
-0001f200: 5d2e 7661 6c20 6973 206e 6f74 204e 6f6e  ].val is not Non
-0001f210: 653a 0a20 2020 2020 2020 2073 7461 7274  e:.        start
-0001f220: 203d 2069 6e70 7574 735b 325d 2e76 616c   = inputs[2].val
-0001f230: 0a20 2020 2065 6c69 6620 6973 696e 7374  .    elif isinst
-0001f240: 616e 6365 2869 6e70 7574 735b 325d 2c20  ance(inputs[2], 
-0001f250: 5661 7229 3a0a 2020 2020 2020 2020 7374  Var):.        st
-0001f260: 6172 7420 3d20 696e 7075 7473 5b32 5d0a  art = inputs[2].
-0001f270: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
-0001f280: 2020 7374 6172 7420 3d20 300a 0a20 2020    start = 0..   
-0001f290: 2069 6620 696e 7075 7473 5b33 5d20 616e   if inputs[3] an
-0001f2a0: 6420 696e 7075 7473 5b33 5d2e 7661 6c20  d inputs[3].val 
-0001f2b0: 6973 206e 6f74 204e 6f6e 653a 0a20 2020  is not None:.   
-0001f2c0: 2020 2020 2065 6e64 203d 2069 6e70 7574       end = input
-0001f2d0: 735b 335d 2e76 616c 0a20 2020 2065 6c69  s[3].val.    eli
-0001f2e0: 6620 6973 696e 7374 616e 6365 2869 6e70  f isinstance(inp
-0001f2f0: 7574 735b 335d 2c20 5661 7229 3a0a 2020  uts[3], Var):.  
-0001f300: 2020 2020 2020 656e 6420 3d20 696e 7075        end = inpu
-0001f310: 7473 5b33 5d0a 2020 2020 656c 7365 3a0a  ts[3].    else:.
-0001f320: 2020 2020 2020 2020 656e 6420 3d20 4e6f          end = No
-0001f330: 6e65 0a0a 2020 2020 7374 6570 203d 2069  ne..    step = i
-0001f340: 6e70 7574 735b 345d 2e76 616c 0a0a 2020  nputs[4].val..  
-0001f350: 2020 6966 2073 7461 7274 203d 3d20 3020    if start == 0 
-0001f360: 616e 6420 656e 6420 6973 204e 6f6e 6520  and end is None 
-0001f370: 616e 6420 7374 6570 203d 3d20 313a 0a20  and step == 1:. 
-0001f380: 2020 2020 2020 2023 2048 616e 646c 696e         # Handlin
-0001f390: 6720 785b 3a5d 2c20 6a75 7374 2070 6173  g x[:], just pas
-0001f3a0: 7320 7468 726f 7567 6820 7468 6520 7465  s through the te
-0001f3b0: 6e73 6f72 2e0a 2020 2020 2020 2020 636f  nsor..        co
-0001f3c0: 6e74 6578 742e 6164 6428 782c 206e 6f64  ntext.add(x, nod
-0001f3d0: 652e 6e61 6d65 290a 2020 2020 2020 2020  e.name).        
-0001f3e0: 7265 7475 726e 0a0a 2020 2020 6265 6769  return..    begi
-0001f3f0: 6e5f 6172 7261 7920 3d20 5b30 5d20 2a20  n_array = [0] * 
-0001f400: 6c65 6e28 782e 7368 6170 6529 0a20 2020  len(x.shape).   
-0001f410: 2062 6567 696e 5f61 7272 6179 5b64 696d   begin_array[dim
-0001f420: 5d20 3d20 7374 6172 740a 2020 2020 656e  ] = start.    en
-0001f430: 645f 6172 7261 7920 3d20 5b73 2069 6620  d_array = [s if 
-0001f440: 6973 696e 7374 616e 6365 2873 2c20 696e  isinstance(s, in
-0001f450: 7429 2065 6c73 6520 3020 666f 7220 7320  t) else 0 for s 
-0001f460: 696e 2078 2e73 6861 7065 5d0a 2020 2020  in x.shape].    
-0001f470: 656e 645f 6d61 736b 203d 205b 5472 7565  end_mask = [True
-0001f480: 5d20 2a20 6c65 6e28 782e 7368 6170 6529  ] * len(x.shape)
-0001f490: 0a20 2020 2069 6620 656e 6420 6973 206e  .    if end is n
-0001f4a0: 6f74 204e 6f6e 653a 0a20 2020 2020 2020  ot None:.       
-0001f4b0: 2065 6e64 5f61 7272 6179 5b64 696d 5d20   end_array[dim] 
-0001f4c0: 3d20 656e 640a 2020 2020 2020 2020 656e  = end.        en
-0001f4d0: 645f 6d61 736b 5b64 696d 5d20 3d20 4661  d_mask[dim] = Fa
-0001f4e0: 6c73 650a 0a20 2020 2069 6620 6973 696e  lse..    if isin
-0001f4f0: 7374 616e 6365 2873 7461 7274 2c20 5661  stance(start, Va
-0001f500: 7229 3a0a 2020 2020 2020 2020 6265 6769  r):.        begi
-0001f510: 6e5f 6172 7261 7920 3d20 6d62 2e63 6f6e  n_array = mb.con
-0001f520: 6361 7428 7661 6c75 6573 3d62 6567 696e  cat(values=begin
-0001f530: 5f61 7272 6179 2c20 6178 6973 3d30 290a  _array, axis=0).
-0001f540: 0a20 2020 2069 6620 6973 696e 7374 616e  .    if isinstan
-0001f550: 6365 2865 6e64 2c20 5661 7229 3a0a 2020  ce(end, Var):.  
-0001f560: 2020 2020 2020 656e 645f 6172 7261 7920        end_array 
-0001f570: 3d20 6d62 2e63 6f6e 6361 7428 7661 6c75  = mb.concat(valu
-0001f580: 6573 3d65 6e64 5f61 7272 6179 2c20 6178  es=end_array, ax
-0001f590: 6973 3d30 290a 0a20 2020 206b 7761 7267  is=0)..    kwarg
-0001f5a0: 7320 3d20 7b0a 2020 2020 2020 2020 2278  s = {.        "x
-0001f5b0: 223a 2078 2c0a 2020 2020 2020 2020 2262  ": x,.        "b
-0001f5c0: 6567 696e 223a 2062 6567 696e 5f61 7272  egin": begin_arr
-0001f5d0: 6179 2c0a 2020 2020 2020 2020 2265 6e64  ay,.        "end
-0001f5e0: 223a 2065 6e64 5f61 7272 6179 2c0a 2020  ": end_array,.  
-0001f5f0: 2020 2020 2020 2265 6e64 5f6d 6173 6b22        "end_mask"
-0001f600: 3a20 656e 645f 6d61 736b 2c0a 2020 2020  : end_mask,.    
-0001f610: 2020 2020 226e 616d 6522 3a20 6e6f 6465      "name": node
-0001f620: 2e6e 616d 652c 0a20 2020 207d 0a0a 2020  .name,.    }..  
-0001f630: 2020 6966 2073 7465 7020 213d 2031 3a0a    if step != 1:.
-0001f640: 2020 2020 2020 2020 7374 7269 6465 5f61          stride_a
-0001f650: 7272 6179 203d 205f 6e70 2e61 7272 6179  rray = _np.array
-0001f660: 285b 315d 202a 206c 656e 2878 2e73 6861  ([1] * len(x.sha
-0001f670: 7065 2929 0a20 2020 2020 2020 2073 7472  pe)).        str
-0001f680: 6964 655f 6172 7261 795b 6469 6d5d 203d  ide_array[dim] =
-0001f690: 2073 7465 700a 2020 2020 2020 2020 6b77   step.        kw
-0001f6a0: 6172 6773 5b22 7374 7269 6465 225d 203d  args["stride"] =
-0001f6b0: 2073 7472 6964 655f 6172 7261 790a 0a20   stride_array.. 
-0001f6c0: 2020 2072 6573 203d 206d 622e 736c 6963     res = mb.slic
-0001f6d0: 655f 6279 5f69 6e64 6578 282a 2a6b 7761  e_by_index(**kwa
-0001f6e0: 7267 7329 0a20 2020 2063 6f6e 7465 7874  rgs).    context
-0001f6f0: 2e61 6464 2872 6573 290a 0a0a 4072 6567  .add(res)...@reg
-0001f700: 6973 7465 725f 746f 7263 685f 6f70 2874  ister_torch_op(t
-0001f710: 6f72 6368 5f61 6c69 6173 3d5b 2273 706c  orch_alias=["spl
-0001f720: 6974 5f77 6974 685f 7369 7a65 7322 5d29  it_with_sizes"])
-0001f730: 0a64 6566 2073 706c 6974 2863 6f6e 7465  .def split(conte
-0001f740: 7874 2c20 6e6f 6465 293a 0a20 2020 2069  xt, node):.    i
-0001f750: 6e70 7574 7320 3d20 5f67 6574 5f69 6e70  nputs = _get_inp
-0001f760: 7574 7328 636f 6e74 6578 742c 206e 6f64  uts(context, nod
-0001f770: 652c 2065 7870 6563 7465 643d 3329 0a20  e, expected=3). 
-0001f780: 2020 2078 203d 2069 6e70 7574 735b 305d     x = inputs[0]
-0001f790: 0a20 2020 2073 706c 6974 5f73 697a 6573  .    split_sizes
-0001f7a0: 203d 2069 6e70 7574 735b 315d 0a20 2020   = inputs[1].   
-0001f7b0: 2064 696d 203d 2069 6e70 7574 735b 325d   dim = inputs[2]
-0001f7c0: 2e76 616c 0a0a 2020 2020 6966 206e 6f74  .val..    if not
-0001f7d0: 2069 7369 6e73 7461 6e63 6528 7370 6c69   isinstance(spli
-0001f7e0: 745f 7369 7a65 732e 7661 6c2c 205f 6e70  t_sizes.val, _np
-0001f7f0: 2e6e 6461 7272 6179 293a 0a20 2020 2020  .ndarray):.     
-0001f800: 2020 2073 6861 7065 203d 206d 622e 7368     shape = mb.sh
-0001f810: 6170 6528 783d 7829 0a20 2020 2020 2020  ape(x=x).       
-0001f820: 2064 696d 5f73 697a 6520 3d20 5f6c 6973   dim_size = _lis
-0001f830: 745f 7365 6c65 6374 2873 6861 7065 2c20  t_select(shape, 
-0001f840: 6469 6d29 0a20 2020 2020 2020 2023 204d  dim).        # M
-0001f850: 494c 2073 706c 6974 206f 7020 6e65 6564  IL split op need
-0001f860: 7320 7468 6520 7369 7a65 206f 6620 6561  s the size of ea
-0001f870: 6368 2073 706c 6974 2074 6f20 6265 2067  ch split to be g
-0001f880: 6976 656e 2065 7870 6c69 6369 746c 792e  iven explicitly.
-0001f890: 0a20 2020 2020 2020 206e 756d 5f77 686f  .        num_who
-0001f8a0: 6c65 5f73 706c 6974 7320 3d20 6d62 2e66  le_splits = mb.f
-0001f8b0: 6c6f 6f72 5f64 6976 2878 3d64 696d 5f73  loor_div(x=dim_s
-0001f8c0: 697a 652c 2079 3d73 706c 6974 5f73 697a  ize, y=split_siz
-0001f8d0: 6573 290a 2020 2020 2020 2020 7265 6d61  es).        rema
-0001f8e0: 696e 6465 7220 3d20 6d62 2e6d 6f64 2878  inder = mb.mod(x
-0001f8f0: 3d64 696d 5f73 697a 652c 2079 3d73 706c  =dim_size, y=spl
-0001f900: 6974 5f73 697a 6573 290a 0a20 2020 2020  it_sizes)..     
-0001f910: 2020 2023 204d 494c 2064 6f65 736e 2774     # MIL doesn't
-0001f920: 2068 6176 6520 6120 7761 7920 6f66 2074   have a way of t
-0001f930: 7572 6e69 6e67 2061 2073 6361 6c61 7220  urning a scalar 
-0001f940: 696e 746f 2061 2074 656e 736f 7220 286c  into a tensor (l
-0001f950: 6973 7420 7772 6974 650a 2020 2020 2020  ist write.      
-0001f960: 2020 2320 6f6e 6c79 2073 7570 706f 7274    # only support
-0001f970: 7320 7465 6e73 6f72 7329 2e20 4173 2061  s tensors). As a
-0001f980: 2077 6f72 6b61 726f 756e 642c 2077 6520   workaround, we 
-0001f990: 6372 6561 7465 2061 2063 6f6e 7374 616e  create a constan
-0001f9a0: 7420 5b31 5d0a 2020 2020 2020 2020 2320  t [1].        # 
-0001f9b0: 7465 6e73 6f72 2061 6e64 206d 756c 7469  tensor and multi
-0001f9c0: 706c 7920 6974 2062 7920 7468 6520 7363  ply it by the sc
-0001f9d0: 616c 6172 2076 616c 7565 2c20 7468 7573  alar value, thus
-0001f9e0: 2063 7265 6174 696e 6720 6120 7465 6e73   creating a tens
-0001f9f0: 6f72 0a20 2020 2020 2020 2023 2077 6974  or.        # wit
-0001fa00: 6820 7468 6520 7363 616c 6172 2076 616c  h the scalar val
-0001fa10: 7565 2069 6e20 6974 2e0a 2020 2020 2020  ue in it..      
-0001fa20: 2020 746d 7020 3d20 6d62 2e63 6f6e 7374    tmp = mb.const
-0001fa30: 2876 616c 3d5b 315d 290a 2020 2020 2020  (val=[1]).      
-0001fa40: 2020 7768 6f6c 655f 7369 7a65 7320 3d20    whole_sizes = 
-0001fa50: 6d62 2e6d 756c 2878 3d74 6d70 2c20 793d  mb.mul(x=tmp, y=
-0001fa60: 7370 6c69 745f 7369 7a65 7329 0a20 2020  split_sizes).   
-0001fa70: 2020 2020 2072 6570 7320 3d20 6d62 2e6d       reps = mb.m
-0001fa80: 756c 2878 3d74 6d70 2c20 793d 6e75 6d5f  ul(x=tmp, y=num_
-0001fa90: 7768 6f6c 655f 7370 6c69 7473 290a 2020  whole_splits).  
-0001faa0: 2020 2020 2020 7768 6f6c 655f 7369 7a65        whole_size
-0001fab0: 7320 3d20 6d62 2e74 696c 6528 783d 7768  s = mb.tile(x=wh
-0001fac0: 6f6c 655f 7369 7a65 732c 2072 6570 733d  ole_sizes, reps=
-0001fad0: 7265 7073 290a 2020 2020 2020 2020 6966  reps).        if
-0001fae0: 2072 656d 6169 6e64 6572 2e76 616c 203d   remainder.val =
-0001faf0: 3d20 303a 0a20 2020 2020 2020 2020 2020  = 0:.           
-0001fb00: 2073 706c 6974 5f73 697a 6573 203d 2077   split_sizes = w
-0001fb10: 686f 6c65 5f73 697a 6573 0a20 2020 2020  hole_sizes.     
-0001fb20: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
-0001fb30: 2020 2020 2070 6172 7469 616c 5f73 697a       partial_siz
-0001fb40: 6520 3d20 6d62 2e6d 756c 2878 3d74 6d70  e = mb.mul(x=tmp
-0001fb50: 2c20 793d 7265 6d61 696e 6465 7229 0a20  , y=remainder). 
-0001fb60: 2020 2020 2020 2020 2020 2073 706c 6974             split
-0001fb70: 5f73 697a 6573 203d 206d 622e 636f 6e63  _sizes = mb.conc
-0001fb80: 6174 2876 616c 7565 733d 5b77 686f 6c65  at(values=[whole
-0001fb90: 5f73 697a 6573 2c20 7061 7274 6961 6c5f  _sizes, partial_
-0001fba0: 7369 7a65 5d2c 2061 7869 733d 3029 0a20  size], axis=0). 
-0001fbb0: 2020 2072 6573 203d 206d 622e 7370 6c69     res = mb.spli
-0001fbc0: 7428 783d 782c 2073 706c 6974 5f73 697a  t(x=x, split_siz
-0001fbd0: 6573 3d73 706c 6974 5f73 697a 6573 2c20  es=split_sizes, 
-0001fbe0: 6178 6973 3d64 696d 2c20 6e61 6d65 3d6e  axis=dim, name=n
-0001fbf0: 6f64 652e 6e61 6d65 290a 2020 2020 636f  ode.name).    co
-0001fc00: 6e74 6578 742e 6164 6428 7265 732c 2074  ntext.add(res, t
-0001fc10: 6f72 6368 5f6e 616d 653d 6e6f 6465 2e6e  orch_name=node.n
-0001fc20: 616d 6529 0a0a 0a40 7265 6769 7374 6572  ame)...@register
-0001fc30: 5f74 6f72 6368 5f6f 700a 6465 6620 756e  _torch_op.def un
-0001fc40: 6269 6e64 2863 6f6e 7465 7874 2c20 6e6f  bind(context, no
-0001fc50: 6465 293a 0a20 2020 2069 6e70 7574 7320  de):.    inputs 
-0001fc60: 3d20 5f67 6574 5f69 6e70 7574 7328 636f  = _get_inputs(co
-0001fc70: 6e74 6578 742c 206e 6f64 652c 2065 7870  ntext, node, exp
-0001fc80: 6563 7465 643d 3229 0a20 2020 2078 203d  ected=2).    x =
-0001fc90: 2069 6e70 7574 735b 305d 0a20 2020 2064   inputs[0].    d
-0001fca0: 696d 203d 2069 6e70 7574 735b 315d 2e76  im = inputs[1].v
-0001fcb0: 616c 0a20 2020 2073 706c 6974 5f73 697a  al.    split_siz
-0001fcc0: 6573 203d 205b 315d 202a 2078 2e73 6861  es = [1] * x.sha
-0001fcd0: 7065 5b64 696d 5d0a 2020 2020 6966 206c  pe[dim].    if l
-0001fce0: 656e 2873 706c 6974 5f73 697a 6573 2920  en(split_sizes) 
-0001fcf0: 3d3d 2031 3a0a 2020 2020 2020 2020 7265  == 1:.        re
-0001fd00: 7320 3d20 5b6d 622e 7371 7565 657a 6528  s = [mb.squeeze(
-0001fd10: 783d 782c 2061 7865 733d 5b64 696d 5d29  x=x, axes=[dim])
-0001fd20: 5d0a 2020 2020 656c 7365 3a0a 2020 2020  ].    else:.    
-0001fd30: 2020 2020 7265 7320 3d20 6d62 2e73 706c      res = mb.spl
-0001fd40: 6974 2878 3d78 2c20 7370 6c69 745f 7369  it(x=x, split_si
-0001fd50: 7a65 733d 7370 6c69 745f 7369 7a65 732c  zes=split_sizes,
-0001fd60: 2061 7869 733d 6469 6d2c 206e 616d 653d   axis=dim, name=
-0001fd70: 6e6f 6465 2e6e 616d 6529 0a20 2020 2020  node.name).     
-0001fd80: 2020 2072 6573 203d 205b 6d62 2e73 7175     res = [mb.squ
-0001fd90: 6565 7a65 2878 3d78 2c20 6178 6573 3d5b  eeze(x=x, axes=[
-0001fda0: 6469 6d5d 2920 666f 7220 7820 696e 2072  dim]) for x in r
-0001fdb0: 6573 5d0a 2020 2020 636f 6e74 6578 742e  es].    context.
-0001fdc0: 6164 6428 7265 732c 2074 6f72 6368 5f6e  add(res, torch_n
-0001fdd0: 616d 653d 6e6f 6465 2e6e 616d 6529 0a0a  ame=node.name)..
-0001fde0: 0a40 7265 6769 7374 6572 5f74 6f72 6368  .@register_torch
-0001fdf0: 5f6f 700a 6465 6620 746f 2863 6f6e 7465  _op.def to(conte
-0001fe00: 7874 2c20 6e6f 6465 293a 0a20 2020 2069  xt, node):.    i
-0001fe10: 6e70 7574 7320 3d20 5f67 6574 5f69 6e70  nputs = _get_inp
-0001fe20: 7574 7328 636f 6e74 6578 742c 206e 6f64  uts(context, nod
-0001fe30: 6529 0a0a 2020 2020 2320 5468 6572 6520  e)..    # There 
-0001fe40: 6172 6520 6120 6c6f 7420 6f66 2076 6172  are a lot of var
-0001fe50: 6961 6e74 7320 6f66 2060 746f 6020 6f70  iants of `to` op
-0001fe60: 2e0a 2020 2020 2320 2d20 5768 656e 206c  ..    # - When l
-0001fe70: 656e 2869 6e70 7574 7329 2069 7320 3720  en(inputs) is 7 
-0001fe80: 6f72 2038 2c20 7765 206f 6e6c 7920 6361  or 8, we only ca
-0001fe90: 7265 2061 626f 7574 2074 6865 2066 6972  re about the fir
-0001fea0: 7374 2074 776f 2070 6172 616d 7320 2869  st two params (i
-0001feb0: 6e70 7574 2061 6e64 2064 7479 7065 292e  nput and dtype).
-0001fec0: 0a20 2020 2023 202d 2057 6865 6e20 6c65  .    # - When le
-0001fed0: 6e28 696e 7075 7473 2920 3d3d 2036 2c20  n(inputs) == 6, 
-0001fee0: 7468 6520 7061 7261 6d65 7465 7220 6973  the parameter is
-0001fef0: 2028 696e 7075 742c 205f 2c20 6474 7970   (input, _, dtyp
-0001ff00: 652c 206e 6f6e 5f62 6c6f 636b 696e 672c  e, non_blocking,
-0001ff10: 2063 6f70 792c 206d 656d 6f72 795f 666f   copy, memory_fo
-0001ff20: 726d 6174 290a 2020 2020 2320 2d20 5768  rmat).    # - Wh
-0001ff30: 656e 206c 656e 2869 6e70 7574 7329 203d  en len(inputs) =
-0001ff40: 3d20 352c 2074 6865 2070 6172 616d 6574  = 5, the paramet
-0001ff50: 6572 2069 7320 2869 6e70 7574 2c20 6474  er is (input, dt
-0001ff60: 7970 652c 206e 6f6e 5f62 6c6f 636b 696e  ype, non_blockin
-0001ff70: 672c 2063 6f70 792c 206d 656d 6f72 795f  g, copy, memory_
-0001ff80: 666f 726d 6174 290a 2020 2020 2320 2d20  format).    # - 
-0001ff90: 5768 656e 206c 656e 2869 6e70 7574 7329  When len(inputs)
-0001ffa0: 203d 3d20 342c 2074 6865 2070 6172 616d   == 4, the param
-0001ffb0: 6574 6572 2069 7320 2869 6e70 7574 2c20  eter is (input, 
-0001ffc0: 6474 7970 652c 206e 6f6e 5f62 6c6f 636b  dtype, non_block
-0001ffd0: 696e 672c 2063 6f70 7929 0a20 2020 2023  ing, copy).    #
-0001ffe0: 202d 2057 6865 6e20 6c65 6e28 696e 7075   - When len(inpu
-0001fff0: 7473 2920 3d3d 2033 2c20 7468 6520 7061  ts) == 3, the pa
-00020000: 7261 6d65 7465 7220 6973 2028 696e 7075  rameter is (inpu
-00020010: 742c 206e 6f6e 5f62 6c6f 636b 696e 672c  t, non_blocking,
-00020020: 2063 6f70 7929 0a20 2020 2023 2057 6520   copy).    # We 
-00020030: 6f6e 6c79 2075 7365 2060 696e 7075 7460  only use `input`
-00020040: 2061 6e64 2060 6474 7970 6560 2c20 616e   and `dtype`, an
-00020050: 6420 606e 6f6e 5f62 6c6f 636b 696e 6760  d `non_blocking`
-00020060: 2061 6e64 2060 636f 7079 6020 6172 6520   and `copy` are 
-00020070: 756e 7573 6564 2e0a 2020 2020 5f69 6e70  unused..    _inp
-00020080: 7574 203d 2069 6e70 7574 735b 305d 0a20  ut = inputs[0]. 
-00020090: 2020 2074 6172 6765 745f 6474 7970 653a     target_dtype:
-000200a0: 204f 7074 696f 6e61 6c5b 5661 725d 0a20   Optional[Var]. 
-000200b0: 2020 2069 6e70 7574 735f 6c65 6e20 3d20     inputs_len = 
-000200c0: 6c65 6e28 696e 7075 7473 290a 2020 2020  len(inputs).    
-000200d0: 6966 2069 6e70 7574 735f 6c65 6e20 696e  if inputs_len in
-000200e0: 2028 342c 2035 2c20 372c 2038 293a 0a20   (4, 5, 7, 8):. 
-000200f0: 2020 2020 2020 2074 6172 6765 745f 6474         target_dt
-00020100: 7970 6520 3d20 696e 7075 7473 5b31 5d0a  ype = inputs[1].
-00020110: 2020 2020 656c 6966 2069 6e70 7574 735f      elif inputs_
-00020120: 6c65 6e20 3d3d 2036 3a0a 2020 2020 2020  len == 6:.      
-00020130: 2020 7461 7267 6574 5f64 7479 7065 203d    target_dtype =
-00020140: 2069 6e70 7574 735b 325d 0a20 2020 2065   inputs[2].    e
-00020150: 6c69 6620 696e 7075 7473 5f6c 656e 203d  lif inputs_len =
-00020160: 3d20 333a 0a20 2020 2020 2020 2074 6172  = 3:.        tar
-00020170: 6765 745f 6474 7970 6520 3d20 4e6f 6e65  get_dtype = None
-00020180: 0a20 2020 2065 6c73 653a 0a20 2020 2020  .    else:.     
-00020190: 2020 2072 6169 7365 2056 616c 7565 4572     raise ValueEr
-000201a0: 726f 7228 0a20 2020 2020 2020 2020 2020  ror(.           
-000201b0: 2022 5265 6365 6976 6564 2069 6e76 616c   "Received inval
-000201c0: 6964 2061 7267 756d 656e 7473 2066 6f72  id arguments for
-000201d0: 2050 7954 6f72 6368 2063 6f6e 7665 7273   PyTorch convers
-000201e0: 696f 6e20 6f66 206f 7020 7b7d 222e 666f  ion of op {}".fo
-000201f0: 726d 6174 286e 6f64 6529 0a20 2020 2020  rmat(node).     
-00020200: 2020 2029 0a0a 2020 2020 6966 2074 6172     )..    if tar
-00020210: 6765 745f 6474 7970 6520 6973 204e 6f6e  get_dtype is Non
-00020220: 653a 0a20 2020 2020 2020 2023 2057 6865  e:.        # Whe
-00020230: 6e20 7461 7267 6574 5f64 7479 7065 2069  n target_dtype i
-00020240: 7320 4e6f 6e65 2c20 6974 206d 6561 6e73  s None, it means
-00020250: 2074 6865 2069 6e70 7574 2773 2064 7479   the input's dty
-00020260: 7065 2069 7320 616c 7265 6164 7920 7468  pe is already th
-00020270: 6520 7461 7267 6574 2064 7479 7065 2e0a  e target dtype..
-00020280: 2020 2020 2020 2020 636f 6e74 6578 742e          context.
-00020290: 6164 6428 5f69 6e70 7574 2c20 746f 7263  add(_input, torc
-000202a0: 685f 6e61 6d65 3d6e 6f64 652e 6e61 6d65  h_name=node.name
-000202b0: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
-000202c0: 0a20 2020 2065 6c69 6620 7479 7065 732e  .    elif types.
-000202d0: 6973 5f73 6361 6c61 7228 7461 7267 6574  is_scalar(target
-000202e0: 5f64 7479 7065 2e73 796d 5f74 7970 6529  _dtype.sym_type)
-000202f0: 2061 6e64 2074 6172 6765 745f 6474 7970   and target_dtyp
-00020300: 652e 7661 6c20 6973 206e 6f74 204e 6f6e  e.val is not Non
-00020310: 653a 0a20 2020 2020 2020 2064 7479 7065  e:.        dtype
-00020320: 203d 2074 6172 6765 745f 6474 7970 652e   = target_dtype.
-00020330: 7661 6c0a 2020 2020 656c 7365 3a0a 2020  val.    else:.  
-00020340: 2020 2020 2020 2320 5768 656e 2074 6865        # When the
-00020350: 2076 616c 206f 6620 6474 7970 6520 6973   val of dtype is
-00020360: 206e 6f74 2061 7661 696c 6162 6c65 2c20   not available, 
-00020370: 6272 6964 6765 2066 726f 6d20 7468 6520  bridge from the 
-00020380: 6e70 2064 7479 7065 2e0a 2020 2020 2020  np dtype..      
-00020390: 2020 6e70 5f74 7970 6520 3d20 6e70 7479    np_type = npty
-000203a0: 7065 5f66 726f 6d5f 6275 696c 7469 6e28  pe_from_builtin(
-000203b0: 7461 7267 6574 5f64 7479 7065 2e64 7479  target_dtype.dty
-000203c0: 7065 290a 2020 2020 2020 2020 6474 7970  pe).        dtyp
-000203d0: 6520 3d20 4e55 4d50 595f 4454 5950 455f  e = NUMPY_DTYPE_
-000203e0: 544f 5f54 4f52 4348 5f4e 554d 5b6e 705f  TO_TORCH_NUM[np_
-000203f0: 7479 7065 5d0a 0a20 2020 2074 6f72 6368  type]..    torch
-00020400: 5f64 7479 7065 203d 204e 554d 5f54 4f5f  _dtype = NUM_TO_
-00020410: 544f 5243 485f 4454 5950 455b 6474 7970  TORCH_DTYPE[dtyp
-00020420: 655d 0a20 2020 2069 6620 6973 696e 7374  e].    if isinst
-00020430: 616e 6365 285f 696e 7075 742c 2056 6172  ance(_input, Var
-00020440: 2920 616e 6420 5f69 6e70 7574 2e63 616e  ) and _input.can
-00020450: 5f62 655f 666f 6c64 6564 5f74 6f5f 636f  _be_folded_to_co
-00020460: 6e73 7428 293a 0a20 2020 2020 2020 2023  nst():.        #
-00020470: 206e 756d 7079 202d 3e20 746f 7263 6820   numpy -> torch 
-00020480: 2d3e 2074 6f72 6368 2063 6173 7420 2d3e  -> torch cast ->
-00020490: 206e 756d 7079 0a20 2020 2020 2020 2023   numpy.        #
-000204a0: 2054 6869 7320 7061 7468 2069 7320 6e65   This path is ne
-000204b0: 6564 6564 2074 6f20 7573 6520 7468 6520  eded to use the 
-000204c0: 6d61 7070 696e 6720 6f66 2070 6173 7365  mapping of passe
-000204d0: 6420 696e 2064 7479 7065 7320 746f 2074  d in dtypes to t
-000204e0: 6f72 6368 2064 7479 7065 732e 0a20 2020  orch dtypes..   
-000204f0: 2020 2020 2063 6173 7465 645f 696e 7075       casted_inpu
-00020500: 7420 3d20 746f 7263 682e 7465 6e73 6f72  t = torch.tensor
-00020510: 285f 696e 7075 742e 7661 6c29 2e74 7970  (_input.val).typ
-00020520: 6528 746f 7263 685f 6474 7970 6529 2e63  e(torch_dtype).c
-00020530: 7075 2829 2e6e 756d 7079 2829 0a20 2020  pu().numpy().   
-00020540: 2020 2020 2072 6573 203d 206d 622e 636f       res = mb.co
-00020550: 6e73 7428 7661 6c3d 6361 7374 6564 5f69  nst(val=casted_i
-00020560: 6e70 7574 2c20 6e61 6d65 3d6e 6f64 652e  nput, name=node.
-00020570: 6e61 6d65 290a 2020 2020 656c 7365 3a0a  name).    else:.
-00020580: 2020 2020 2020 2020 6966 2064 7479 7065          if dtype
-00020590: 2069 6e20 4e55 4d5f 544f 5f44 5459 5045   in NUM_TO_DTYPE
-000205a0: 5f53 5452 494e 473a 0a20 2020 2020 2020  _STRING:.       
-000205b0: 2020 2020 2072 6573 203d 206d 622e 6361       res = mb.ca
-000205c0: 7374 2878 3d5f 696e 7075 742c 2064 7479  st(x=_input, dty
-000205d0: 7065 3d4e 554d 5f54 4f5f 4454 5950 455f  pe=NUM_TO_DTYPE_
-000205e0: 5354 5249 4e47 5b64 7479 7065 5d2c 206e  STRING[dtype], n
-000205f0: 616d 653d 6e6f 6465 2e6e 616d 6529 0a20  ame=node.name). 
-00020600: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
-00020610: 2020 2020 2020 2020 2023 2046 6f72 2064           # For d
-00020620: 7479 7065 2074 6861 7420 6973 206e 6f74  type that is not
-00020630: 2073 7570 706f 7274 6564 2062 7920 6d62   supported by mb
-00020640: 2e63 6173 742c 2077 6520 646f 2069 7420  .cast, we do it 
-00020650: 696e 2062 6573 742d 6566 666f 7274 2074  in best-effort t
-00020660: 6f20 6361 7374 2069 7420 746f 2069 6e74  o cast it to int
-00020670: 0a20 2020 2020 2020 2020 2020 2023 206f  .            # o
-00020680: 7220 666c 6f61 7420 6261 7365 6420 6f6e  r float based on
-00020690: 2074 6865 2064 7479 7065 2e0a 2020 2020   the dtype..    
-000206a0: 2020 2020 2020 2020 6e70 5f64 7479 7065          np_dtype
-000206b0: 203d 204e 554d 5f54 4f5f 4e55 4d50 595f   = NUM_TO_NUMPY_
-000206c0: 4454 5950 455b 6474 7970 655d 0a20 2020  DTYPE[dtype].   
-000206d0: 2020 2020 2020 2020 2069 6620 5f6e 702e           if _np.
-000206e0: 6973 7375 6264 7479 7065 286e 705f 6474  issubdtype(np_dt
-000206f0: 7970 652c 205f 6e70 2e69 6e74 6567 6572  ype, _np.integer
-00020700: 293a 0a20 2020 2020 2020 2020 2020 2020  ):.             
-00020710: 2020 2072 6573 203d 206d 622e 6361 7374     res = mb.cast
-00020720: 2878 3d5f 696e 7075 742c 2064 7479 7065  (x=_input, dtype
-00020730: 3d22 696e 7433 3222 2c20 6e61 6d65 3d6e  ="int32", name=n
-00020740: 6f64 652e 6e61 6d65 290a 2020 2020 2020  ode.name).      
-00020750: 2020 2020 2020 656c 6966 205f 6e70 2e69        elif _np.i
-00020760: 7373 7562 6474 7970 6528 6e70 5f64 7479  ssubdtype(np_dty
-00020770: 7065 2c20 5f6e 702e 666c 6f61 7469 6e67  pe, _np.floating
-00020780: 293a 0a20 2020 2020 2020 2020 2020 2020  ):.             
-00020790: 2020 2072 6573 203d 206d 622e 6361 7374     res = mb.cast
-000207a0: 2878 3d5f 696e 7075 742c 2064 7479 7065  (x=_input, dtype
-000207b0: 3d22 6670 3332 222c 206e 616d 653d 6e6f  ="fp32", name=no
-000207c0: 6465 2e6e 616d 6529 0a20 2020 2020 2020  de.name).       
-000207d0: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
-000207e0: 2020 2020 2020 2020 2020 2072 6169 7365             raise
-000207f0: 2056 616c 7565 4572 726f 7228 6622 556e   ValueError(f"Un
-00020800: 7375 7070 6f72 7465 6420 6f70 207b 6e6f  supported op {no
-00020810: 6465 7d20 7769 7468 2074 6172 6765 7420  de} with target 
-00020820: 6474 7970 6520 7b6e 705f 6474 7970 657d  dtype {np_dtype}
-00020830: 2229 0a20 2020 2063 6f6e 7465 7874 2e61  ").    context.a
-00020840: 6464 2872 6573 290a 0a0a 4072 6567 6973  dd(res)...@regis
-00020850: 7465 725f 746f 7263 685f 6f70 0a64 6566  ter_torch_op.def
-00020860: 2065 7266 2863 6f6e 7465 7874 2c20 6e6f   erf(context, no
-00020870: 6465 293a 0a20 2020 2069 6e70 7574 7320  de):.    inputs 
-00020880: 3d20 5f67 6574 5f69 6e70 7574 7328 636f  = _get_inputs(co
-00020890: 6e74 6578 742c 206e 6f64 652c 2065 7870  ntext, node, exp
-000208a0: 6563 7465 643d 3129 0a20 2020 205f 696e  ected=1).    _in
-000208b0: 7075 7420 3d20 696e 7075 7473 5b30 5d0a  put = inputs[0].
-000208c0: 2020 2020 6572 6620 3d20 6d62 2e65 7266      erf = mb.erf
-000208d0: 2878 3d5f 696e 7075 742c 206e 616d 653d  (x=_input, name=
-000208e0: 6e6f 6465 2e6e 616d 6529 0a20 2020 2063  node.name).    c
-000208f0: 6f6e 7465 7874 2e61 6464 2865 7266 290a  ontext.add(erf).
-00020900: 0a0a 4072 6567 6973 7465 725f 746f 7263  ..@register_torc
-00020910: 685f 6f70 2874 6f72 6368 5f61 6c69 6173  h_op(torch_alias
-00020920: 3d5b 2273 6361 6c61 7269 6d70 6c69 6369  =["scalarimplici
-00020930: 7422 5d29 0a64 6566 2069 6d70 6c69 6369  t"]).def implici
-00020940: 7474 656e 736f 7274 6f6e 756d 2863 6f6e  ttensortonum(con
-00020950: 7465 7874 2c20 6e6f 6465 293a 0a20 2020  text, node):.   
-00020960: 2069 6e70 7574 7320 3d20 5f67 6574 5f69   inputs = _get_i
-00020970: 6e70 7574 7328 636f 6e74 6578 742c 206e  nputs(context, n
-00020980: 6f64 652c 2065 7870 6563 7465 643d 3129  ode, expected=1)
-00020990: 0a20 2020 205f 696e 7075 7420 3d20 696e  .    _input = in
-000209a0: 7075 7473 5b30 5d0a 0a20 2020 2069 6620  puts[0]..    if 
-000209b0: 5f69 6e70 7574 2e73 6861 7065 203d 3d20  _input.shape == 
-000209c0: 2829 3a20 2023 2061 6c72 6561 6479 2061  ():  # already a
-000209d0: 2073 6361 6c61 720a 2020 2020 2020 2020   scalar.        
-000209e0: 636f 6e74 6578 742e 6164 6428 5f69 6e70  context.add(_inp
-000209f0: 7574 2c20 6e6f 6465 2e6e 616d 6529 0a20  ut, node.name). 
-00020a00: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
-00020a10: 2061 7373 6572 7420 5f69 6e70 7574 2e73   assert _input.s
-00020a20: 6861 7065 203d 3d20 2831 2c29 0a20 2020  hape == (1,).   
-00020a30: 2020 2020 2023 2073 6861 7065 3a20 2831       # shape: (1
-00020a40: 2c29 202d 3e20 2829 0a20 2020 2020 2020  ,) -> ().       
-00020a50: 2073 7175 6565 7a65 203d 206d 622e 7371   squeeze = mb.sq
-00020a60: 7565 657a 6528 783d 5f69 6e70 7574 2c20  ueeze(x=_input, 
-00020a70: 6e61 6d65 3d6e 6f64 652e 6e61 6d65 290a  name=node.name).
-00020a80: 2020 2020 2020 2020 636f 6e74 6578 742e          context.
-00020a90: 6164 6428 7371 7565 657a 6529 0a0a 0a40  add(squeeze)...@
-00020aa0: 7265 6769 7374 6572 5f74 6f72 6368 5f6f  register_torch_o
-00020ab0: 700a 6465 6620 636f 6e73 7461 6e74 6368  p.def constantch
-00020ac0: 756e 6b28 636f 6e74 6578 742c 206e 6f64  unk(context, nod
-00020ad0: 6529 3a0a 2020 2020 696e 7075 7473 203d  e):.    inputs =
-00020ae0: 205f 6765 745f 696e 7075 7473 2863 6f6e   _get_inputs(con
-00020af0: 7465 7874 2c20 6e6f 6465 2c20 6578 7065  text, node, expe
-00020b00: 6374 6564 3d31 290a 2020 2020 7820 3d20  cted=1).    x = 
-00020b10: 696e 7075 7473 5b30 5d0a 2020 2020 2320  inputs[0].    # 
-00020b20: 436f 6e73 7461 6e74 4368 756e 6b20 6765  ConstantChunk ge
-00020b30: 7473 2069 7473 2070 6172 616d 6574 6572  ts its parameter
-00020b40: 7320 6173 2061 7474 7269 6275 7465 7320  s as attributes 
-00020b50: 6f66 2074 6865 206e 6f64 652e 0a20 2020  of the node..   
-00020b60: 2063 6875 6e6b 7320 3d20 6e6f 6465 2e61   chunks = node.a
-00020b70: 7474 725b 2263 6875 6e6b 7322 5d0a 2020  ttr["chunks"].  
-00020b80: 2020 6469 6d20 3d20 6e6f 6465 2e61 7474    dim = node.att
-00020b90: 725b 2264 696d 225d 0a0a 2020 2020 746f  r["dim"]..    to
-00020ba0: 7461 6c20 3d20 782e 7368 6170 655b 6469  tal = x.shape[di
-00020bb0: 6d5d 0a20 2020 2073 697a 6520 3d20 696e  m].    size = in
-00020bc0: 7428 5f6d 6174 682e 6365 696c 2866 6c6f  t(_math.ceil(flo
-00020bd0: 6174 2874 6f74 616c 2920 2f20 666c 6f61  at(total) / floa
-00020be0: 7428 6368 756e 6b73 2929 290a 2020 2020  t(chunks))).    
-00020bf0: 7370 6c69 745f 7369 7a65 7320 3d20 5b73  split_sizes = [s
-00020c00: 697a 655d 202a 2069 6e74 285f 6d61 7468  ize] * int(_math
-00020c10: 2e66 6c6f 6f72 2874 6f74 616c 202f 2073  .floor(total / s
-00020c20: 697a 6529 290a 2020 2020 7265 6d61 696e  ize)).    remain
-00020c30: 6465 7220 3d20 746f 7461 6c20 2d20 7375  der = total - su
-00020c40: 6d28 7370 6c69 745f 7369 7a65 7329 0a20  m(split_sizes). 
-00020c50: 2020 2069 6620 7265 6d61 696e 6465 7220     if remainder 
-00020c60: 3e20 303a 0a20 2020 2020 2020 2073 706c  > 0:.        spl
-00020c70: 6974 5f73 697a 6573 2e61 7070 656e 6428  it_sizes.append(
-00020c80: 7265 6d61 696e 6465 7229 0a0a 2020 2020  remainder)..    
-00020c90: 7265 7320 3d20 6d62 2e73 706c 6974 2878  res = mb.split(x
-00020ca0: 3d78 2c20 7370 6c69 745f 7369 7a65 733d  =x, split_sizes=
-00020cb0: 7370 6c69 745f 7369 7a65 732c 2061 7869  split_sizes, axi
-00020cc0: 733d 6469 6d2c 206e 616d 653d 6e6f 6465  s=dim, name=node
-00020cd0: 2e6e 616d 6529 0a20 2020 2066 6f72 2076  .name).    for v
-00020ce0: 616c 2c20 6e61 6d65 2069 6e20 7a69 7028  al, name in zip(
-00020cf0: 7265 732c 206e 6f64 652e 6f75 7470 7574  res, node.output
-00020d00: 7329 3a0a 2020 2020 2020 2020 636f 6e74  s):.        cont
-00020d10: 6578 742e 6164 6428 7661 6c2c 206e 616d  ext.add(val, nam
-00020d20: 6529 0a0a 0a64 6566 205f 6272 6f61 6463  e)...def _broadc
-00020d30: 6173 7428 6e61 6d65 2c20 7465 6e73 6f72  ast(name, tensor
-00020d40: 2c20 7368 6170 6529 3a0a 2020 2020 6966  , shape):.    if
-00020d50: 206c 656e 2873 6861 7065 2920 3e20 7465   len(shape) > te
-00020d60: 6e73 6f72 2e72 616e 6b3a 0a20 2020 2020  nsor.rank:.     
-00020d70: 2020 206e 6577 5f64 696d 7320 3d20 6c65     new_dims = le
-00020d80: 6e28 7368 6170 6529 202d 2074 656e 736f  n(shape) - tenso
-00020d90: 722e 7261 6e6b 0a20 2020 2020 2020 2074  r.rank.        t
-00020da0: 656e 736f 7220 3d20 6d62 2e65 7870 616e  ensor = mb.expan
-00020db0: 645f 6469 6d73 2878 3d74 656e 736f 722c  d_dims(x=tensor,
-00020dc0: 2061 7865 733d 6c69 7374 2872 616e 6765   axes=list(range
-00020dd0: 286e 6577 5f64 696d 7329 2929 0a0a 2020  (new_dims)))..  
-00020de0: 2020 7265 7073 203d 205b 5d0a 2020 2020    reps = [].    
-00020df0: 666f 7220 7473 2c20 6473 2069 6e20 7a69  for ts, ds in zi
-00020e00: 7028 7465 6e73 6f72 2e73 6861 7065 2c20  p(tensor.shape, 
-00020e10: 7368 6170 6529 3a0a 2020 2020 2020 2020  shape):.        
-00020e20: 6966 206e 6f74 2069 735f 7379 6d62 6f6c  if not is_symbol
-00020e30: 6963 2874 7329 2061 6e64 206e 6f74 2069  ic(ts) and not i
-00020e40: 735f 7379 6d62 6f6c 6963 2864 7329 2061  s_symbolic(ds) a
-00020e50: 6e64 2064 7320 3e20 3020 616e 6420 7473  nd ds > 0 and ts
-00020e60: 203d 3d20 313a 0a20 2020 2020 2020 2020   == 1:.         
-00020e70: 2020 2072 6570 732e 6170 7065 6e64 2864     reps.append(d
-00020e80: 7329 0a20 2020 2020 2020 2065 6c73 653a  s).        else:
-00020e90: 0a20 2020 2020 2020 2020 2020 2072 6570  .            rep
-00020ea0: 732e 6170 7065 6e64 2831 290a 0a20 2020  s.append(1)..   
-00020eb0: 2072 6573 203d 206d 622e 7469 6c65 2878   res = mb.tile(x
-00020ec0: 3d74 656e 736f 722c 2072 6570 733d 7265  =tensor, reps=re
-00020ed0: 7073 2c20 6e61 6d65 3d6e 616d 6529 0a20  ps, name=name). 
-00020ee0: 2020 2072 6574 7572 6e20 7265 730a 0a0a     return res...
-00020ef0: 4072 6567 6973 7465 725f 746f 7263 685f  @register_torch_
-00020f00: 6f70 0a64 6566 2065 7870 616e 6428 636f  op.def expand(co
-00020f10: 6e74 6578 742c 206e 6f64 6529 3a0a 2020  ntext, node):.  
-00020f20: 2020 6465 6620 5f62 726f 6164 6361 7374    def _broadcast
-00020f30: 5f64 796e 616d 6963 286e 616d 652c 2074  _dynamic(name, t
-00020f40: 656e 736f 722c 2073 6861 7065 293a 0a20  ensor, shape):. 
-00020f50: 2020 2020 2020 2023 2041 6464 2061 6e79         # Add any
-00020f60: 2065 7874 7261 2064 696d 656e 7369 6f6e   extra dimension
-00020f70: 730a 2020 2020 2020 2020 6966 206c 656e  s.        if len
-00020f80: 2873 6861 7065 2920 3e20 7465 6e73 6f72  (shape) > tensor
-00020f90: 2e72 616e 6b3a 0a20 2020 2020 2020 2020  .rank:.         
-00020fa0: 2020 206e 6577 5f64 696d 7320 3d20 6c65     new_dims = le
-00020fb0: 6e28 7368 6170 6529 202d 2074 656e 736f  n(shape) - tenso
-00020fc0: 722e 7261 6e6b 0a20 2020 2020 2020 2020  r.rank.         
-00020fd0: 2020 2074 656e 736f 7220 3d20 6d62 2e65     tensor = mb.e
-00020fe0: 7870 616e 645f 6469 6d73 2878 3d74 656e  xpand_dims(x=ten
-00020ff0: 736f 722c 2061 7865 733d 6c69 7374 2872  sor, axes=list(r
-00021000: 616e 6765 286e 6577 5f64 696d 7329 2929  ange(new_dims)))
-00021010: 0a0a 2020 2020 2020 2020 7465 6e73 6f72  ..        tensor
-00021020: 5f73 6861 7065 203d 206d 622e 7368 6170  _shape = mb.shap
-00021030: 6528 783d 7465 6e73 6f72 290a 2020 2020  e(x=tensor).    
-00021040: 2020 2020 7368 6170 6520 3d20 6d62 2e63      shape = mb.c
-00021050: 6f6e 6361 7428 7661 6c75 6573 3d73 6861  oncat(values=sha
-00021060: 7065 2c20 6178 6973 3d30 290a 2020 2020  pe, axis=0).    
-00021070: 2020 2020 7265 7073 203d 206d 622e 7265      reps = mb.re
-00021080: 616c 5f64 6976 2878 3d73 6861 7065 2c20  al_div(x=shape, 
-00021090: 793d 7465 6e73 6f72 5f73 6861 7065 290a  y=tensor_shape).
-000210a0: 2020 2020 2020 2020 7265 7073 203d 206d          reps = m
-000210b0: 622e 6361 7374 2878 3d72 6570 732c 2064  b.cast(x=reps, d
-000210c0: 7479 7065 3d22 696e 7433 3222 290a 2020  type="int32").  
-000210d0: 2020 2020 2020 7265 7320 3d20 6d62 2e74        res = mb.t
-000210e0: 696c 6528 783d 7465 6e73 6f72 2c20 7265  ile(x=tensor, re
-000210f0: 7073 3d72 6570 732c 206e 616d 653d 6e61  ps=reps, name=na
-00021100: 6d65 290a 2020 2020 2020 2020 7265 7475  me).        retu
-00021110: 726e 2072 6573 0a0a 0a20 2020 2023 2050  rn res...    # P
-00021120: 7954 6f72 6368 2031 2e36 2b20 6861 7320  yTorch 1.6+ has 
-00021130: 3320 696e 7075 7473 2077 6869 6c65 206f  3 inputs while o
-00021140: 6c64 6572 2076 6572 7369 6f6e 2068 6173  lder version has
-00021150: 2032 0a20 2020 2069 6e70 7574 7320 3d20   2.    inputs = 
-00021160: 5f67 6574 5f69 6e70 7574 7328 636f 6e74  _get_inputs(cont
-00021170: 6578 742c 206e 6f64 652c 2065 7870 6563  ext, node, expec
-00021180: 7465 643d 5b32 2c20 335d 290a 0a20 2020  ted=[2, 3])..   
-00021190: 2078 203d 2069 6e70 7574 735b 305d 0a20   x = inputs[0]. 
-000211a0: 2020 2073 6861 7065 203d 2069 6e70 7574     shape = input
-000211b0: 735b 315d 0a0a 2020 2020 6966 2069 7369  s[1]..    if isi
-000211c0: 6e73 7461 6e63 6528 7368 6170 652c 206c  nstance(shape, l
-000211d0: 6973 7429 3a0a 2020 2020 2020 2020 7265  ist):.        re
-000211e0: 7320 3d20 5f62 726f 6164 6361 7374 5f64  s = _broadcast_d
-000211f0: 796e 616d 6963 286e 6f64 652e 6e61 6d65  ynamic(node.name
-00021200: 2c20 782c 2073 6861 7065 290a 2020 2020  , x, shape).    
-00021210: 656c 7365 3a0a 2020 2020 2020 2020 7265  else:.        re
-00021220: 7320 3d20 5f62 726f 6164 6361 7374 286e  s = _broadcast(n
-00021230: 6f64 652e 6e61 6d65 2c20 782c 2073 6861  ode.name, x, sha
-00021240: 7065 2e76 616c 290a 2020 2020 636f 6e74  pe.val).    cont
-00021250: 6578 742e 6164 6428 7265 7329 0a0a 0a40  ext.add(res)...@
-00021260: 7265 6769 7374 6572 5f74 6f72 6368 5f6f  register_torch_o
-00021270: 700a 6465 6620 6578 7061 6e64 5f61 7328  p.def expand_as(
-00021280: 636f 6e74 6578 742c 206e 6f64 6529 3a0a  context, node):.
-00021290: 2020 2020 2320 5079 546f 7263 6820 312e      # PyTorch 1.
-000212a0: 362b 2068 6173 2033 2069 6e70 7574 7320  6+ has 3 inputs 
-000212b0: 7768 696c 6520 6f6c 6465 7220 7665 7273  while older vers
-000212c0: 696f 6e20 6861 7320 320a 2020 2020 696e  ion has 2.    in
-000212d0: 7075 7473 203d 205f 6765 745f 696e 7075  puts = _get_inpu
-000212e0: 7473 2863 6f6e 7465 7874 2c20 6e6f 6465  ts(context, node
-000212f0: 2c20 6578 7065 6374 6564 3d5b 322c 2033  , expected=[2, 3
-00021300: 5d29 0a20 2020 2078 203d 2069 6e70 7574  ]).    x = input
-00021310: 735b 305d 0a20 2020 206f 7468 6572 203d  s[0].    other =
-00021320: 2069 6e70 7574 735b 315d 0a0a 2020 2020   inputs[1]..    
-00021330: 7265 7320 3d20 5f62 726f 6164 6361 7374  res = _broadcast
-00021340: 286e 6f64 652e 6e61 6d65 2c20 782c 206f  (node.name, x, o
-00021350: 7468 6572 2e73 6861 7065 290a 2020 2020  ther.shape).    
-00021360: 636f 6e74 6578 742e 6164 6428 7265 7329  context.add(res)
-00021370: 0a0a 0a40 7265 6769 7374 6572 5f74 6f72  ...@register_tor
-00021380: 6368 5f6f 700a 6465 6620 6172 616e 6765  ch_op.def arange
-00021390: 2863 6f6e 7465 7874 2c20 6e6f 6465 293a  (context, node):
-000213a0: 0a20 2020 2069 6e70 7574 7320 3d20 5f67  .    inputs = _g
-000213b0: 6574 5f69 6e70 7574 7328 636f 6e74 6578  et_inputs(contex
-000213c0: 742c 206e 6f64 6529 0a20 2020 2023 2064  t, node).    # d
-000213d0: 7479 7065 203d 2069 6e70 7574 735b 2d34  type = inputs[-4
-000213e0: 5d0a 2020 2020 2320 6c61 796f 7574 203d  ].    # layout =
-000213f0: 2069 6e70 7574 735b 2d33 5d0a 2020 2020   inputs[-3].    
-00021400: 2320 6465 7669 6365 203d 2069 6e70 7574  # device = input
-00021410: 735b 2d32 5d0a 2020 2020 2320 7069 6e5f  s[-2].    # pin_
-00021420: 6d65 6d6f 7279 203d 2069 6e70 7574 735b  memory = inputs[
-00021430: 2d31 5d0a 2020 2020 6966 206c 656e 2869  -1].    if len(i
-00021440: 6e70 7574 7329 203d 3d20 353a 0a20 2020  nputs) == 5:.   
-00021450: 2020 2020 2023 2069 6e70 7574 7320 6172       # inputs ar
-00021460: 6520 5b65 6e64 2c20 6474 7970 652c 206c  e [end, dtype, l
-00021470: 6179 6f75 742c 2064 6576 6963 652c 2070  ayout, device, p
-00021480: 696e 5f6d 656d 6f72 795d 0a20 2020 2020  in_memory].     
-00021490: 2020 2073 7461 7274 203d 2030 0a20 2020     start = 0.   
-000214a0: 2020 2020 2065 6e64 203d 2069 6e70 7574       end = input
-000214b0: 735b 305d 0a20 2020 2020 2020 2073 7465  s[0].        ste
-000214c0: 7020 3d20 310a 2020 2020 656c 6966 206c  p = 1.    elif l
-000214d0: 656e 2869 6e70 7574 7329 203d 3d20 363a  en(inputs) == 6:
-000214e0: 0a20 2020 2020 2020 2023 2069 6e70 7574  .        # input
-000214f0: 7320 6172 6520 5b73 7461 7274 2c20 656e  s are [start, en
-00021500: 642c 2064 7479 7065 2c20 6c61 796f 7574  d, dtype, layout
-00021510: 2c20 6465 7669 6365 2c20 7069 6e5f 6d65  , device, pin_me
-00021520: 6d6f 7279 5d0a 2020 2020 2020 2020 7374  mory].        st
-00021530: 6172 7420 3d20 696e 7075 7473 5b30 5d0a  art = inputs[0].
-00021540: 2020 2020 2020 2020 656e 6420 3d20 696e          end = in
-00021550: 7075 7473 5b31 5d0a 2020 2020 2020 2020  puts[1].        
-00021560: 7374 6570 203d 2031 0a20 2020 2065 6c69  step = 1.    eli
-00021570: 6620 6c65 6e28 696e 7075 7473 2920 3d3d  f len(inputs) ==
-00021580: 2037 3a0a 2020 2020 2020 2020 2320 696e   7:.        # in
-00021590: 7075 7473 2061 7265 205b 7374 6172 742c  puts are [start,
-000215a0: 2065 6e64 2c20 7374 6570 2c20 6474 7970   end, step, dtyp
-000215b0: 652c 206c 6179 6f75 742c 2064 6576 6963  e, layout, devic
-000215c0: 652c 2070 696e 5f6d 656d 6f72 795d 0a20  e, pin_memory]. 
-000215d0: 2020 2020 2020 2073 7461 7274 203d 2069         start = i
-000215e0: 6e70 7574 735b 305d 0a20 2020 2020 2020  nputs[0].       
-000215f0: 2065 6e64 203d 2069 6e70 7574 735b 315d   end = inputs[1]
-00021600: 0a20 2020 2020 2020 2073 7465 7020 3d20  .        step = 
-00021610: 696e 7075 7473 5b32 5d0a 2020 2020 656c  inputs[2].    el
-00021620: 7365 3a0a 2020 2020 2020 2020 7261 6973  se:.        rais
-00021630: 6520 5661 6c75 6545 7272 6f72 280a 2020  e ValueError(.  
-00021640: 2020 2020 2020 2020 2020 2261 7261 6e67            "arang
-00021650: 6520 6d75 7374 2068 6176 6520 6578 6163  e must have exac
-00021660: 746c 7920 352c 2036 2c20 6f72 2037 2069  tly 5, 6, or 7 i
-00021670: 6e70 7574 732c 2067 6f74 207b 7d22 2e66  nputs, got {}".f
-00021680: 6f72 6d61 7428 6c65 6e28 696e 7075 7473  ormat(len(inputs
-00021690: 2929 0a20 2020 2020 2020 2029 0a20 2020  )).        ).   
-000216a0: 2023 2049 6620 7374 6172 742c 2065 6e64   # If start, end
-000216b0: 2c20 616e 6420 7374 6570 2064 6f6e 2774  , and step don't
-000216c0: 2068 6176 6520 7468 6520 7361 6d65 2064   have the same d
-000216d0: 7479 7065 2c20 7765 2063 6173 7420 7468  type, we cast th
-000216e0: 656d 2074 6f20 6670 3332 0a20 2020 2069  em to fp32.    i
-000216f0: 6e74 5f73 7461 7274 203d 2069 7369 6e73  nt_start = isins
-00021700: 7461 6e63 6528 7374 6172 742c 2069 6e74  tance(start, int
-00021710: 2920 6f72 2074 7970 6573 2e69 735f 696e  ) or types.is_in
-00021720: 7428 7374 6172 742e 6474 7970 6529 0a20  t(start.dtype). 
-00021730: 2020 2069 6e74 5f65 6e64 203d 2069 7369     int_end = isi
-00021740: 6e73 7461 6e63 6528 656e 642c 2069 6e74  nstance(end, int
-00021750: 2920 6f72 2074 7970 6573 2e69 735f 696e  ) or types.is_in
-00021760: 7428 656e 642e 6474 7970 6529 0a20 2020  t(end.dtype).   
-00021770: 2069 6e74 5f73 7465 7020 3d20 6973 696e   int_step = isin
-00021780: 7374 616e 6365 2873 7465 702c 2069 6e74  stance(step, int
-00021790: 2920 6f72 2074 7970 6573 2e69 735f 696e  ) or types.is_in
-000217a0: 7428 7374 6570 2e64 7479 7065 290a 0a20  t(step.dtype).. 
-000217b0: 2020 2069 6620 696e 745f 7374 6172 7420     if int_start 
-000217c0: 213d 2069 6e74 5f65 6e64 206f 7220 696e  != int_end or in
-000217d0: 745f 7374 6172 7420 213d 2069 6e74 5f73  t_start != int_s
-000217e0: 7465 703a 0a20 2020 2020 2020 2073 7461  tep:.        sta
-000217f0: 7274 203d 206d 622e 6361 7374 2878 3d73  rt = mb.cast(x=s
-00021800: 7461 7274 2c20 6474 7970 653d 2266 7033  tart, dtype="fp3
-00021810: 3222 290a 2020 2020 2020 2020 656e 6420  2").        end 
-00021820: 3d20 6d62 2e63 6173 7428 783d 656e 642c  = mb.cast(x=end,
-00021830: 2064 7479 7065 3d22 6670 3332 2229 0a20   dtype="fp32"). 
-00021840: 2020 2020 2020 2073 7465 7020 3d20 6d62         step = mb
-00021850: 2e63 6173 7428 783d 7374 6570 2c20 6474  .cast(x=step, dt
-00021860: 7970 653d 2266 7033 3222 290a 2020 2020  ype="fp32").    
-00021870: 7265 7320 3d20 6d62 2e72 616e 6765 5f31  res = mb.range_1
-00021880: 6428 7374 6172 743d 7374 6172 742c 2065  d(start=start, e
-00021890: 6e64 3d65 6e64 2c20 7374 6570 3d73 7465  nd=end, step=ste
-000218a0: 702c 206e 616d 653d 6e6f 6465 2e6e 616d  p, name=node.nam
-000218b0: 6529 0a20 2020 2063 6f6e 7465 7874 2e61  e).    context.a
-000218c0: 6464 2872 6573 290a 0a0a 4072 6567 6973  dd(res)...@regis
-000218d0: 7465 725f 746f 7263 685f 6f70 0a64 6566  ter_torch_op.def
-000218e0: 206d 6173 6b65 645f 6669 6c6c 2863 6f6e   masked_fill(con
-000218f0: 7465 7874 2c20 6e6f 6465 293a 0a20 2020  text, node):.   
-00021900: 2069 6e70 7574 7320 3d20 5f67 6574 5f69   inputs = _get_i
-00021910: 6e70 7574 7328 636f 6e74 6578 742c 206e  nputs(context, n
-00021920: 6f64 652c 2065 7870 6563 7465 643d 3329  ode, expected=3)
-00021930: 0a20 2020 2078 203d 2069 6e70 7574 735b  .    x = inputs[
-00021940: 305d 0a20 2020 206d 6173 6b20 3d20 696e  0].    mask = in
-00021950: 7075 7473 5b31 5d0a 2020 2020 7661 6c75  puts[1].    valu
-00021960: 6520 3d20 696e 7075 7473 5b32 5d0a 2020  e = inputs[2].  
-00021970: 2020 2320 406d 622e 7365 6c65 6374 2064    # @mb.select d
-00021980: 6f65 7320 6e6f 7420 7072 6f70 6572 6c79  oes not properly
-00021990: 2062 726f 6164 6361 7374 2073 6361 6c61   broadcast scala
-000219a0: 7220 696e 7075 742c 2073 6f20 6173 2061  r input, so as a
-000219b0: 2077 6f72 6b61 726f 756e 640a 2020 2020   workaround.    
-000219c0: 2320 7765 2063 7265 6174 6520 6120 6675  # we create a fu
-000219d0: 6c6c 2073 697a 6564 2074 656e 736f 722e  ll sized tensor.
-000219e0: 0a0a 2020 2020 6966 2074 7970 6573 2e69  ..    if types.i
-000219f0: 735f 696e 7428 7661 6c75 652e 6474 7970  s_int(value.dtyp
-00021a00: 6529 3a0a 2020 2020 2020 2020 2320 406d  e):.        # @m
-00021a10: 622e 6669 6c6c 2063 616e 6e6f 7420 6861  b.fill cannot ha
-00021a20: 6e64 6c65 2076 616c 7565 2077 6974 6820  ndle value with 
-00021a30: 6474 7970 6520 696e 7465 6765 720a 2020  dtype integer.  
-00021a40: 2020 2020 2020 2320 736f 2077 6520 6361        # so we ca
-00021a50: 7374 2074 6865 2076 616c 7565 2e0a 2020  st the value..  
-00021a60: 2020 2020 2020 7661 6c75 6520 3d20 6d62        value = mb
-00021a70: 2e63 6173 7428 783d 7661 6c75 652c 2064  .cast(x=value, d
-00021a80: 7479 7065 3d22 6670 3332 2229 0a0a 2020  type="fp32")..  
-00021a90: 2020 6966 206e 6f74 2074 7970 6573 2e69    if not types.i
-00021aa0: 735f 626f 6f6c 286d 6173 6b2e 6474 7970  s_bool(mask.dtyp
-00021ab0: 6529 3a0a 2020 2020 2020 2020 2320 636f  e):.        # co
-00021ac0: 6e64 206d 7573 7420 6265 2062 6f6f 6c20  nd must be bool 
-00021ad0: 7479 7065 0a20 2020 2020 2020 206d 6173  type.        mas
-00021ae0: 6b20 3d20 6d62 2e63 6173 7428 783d 6d61  k = mb.cast(x=ma
-00021af0: 736b 2c20 6474 7970 653d 2262 6f6f 6c22  sk, dtype="bool"
-00021b00: 290a 0a20 2020 2073 6861 7065 203d 206d  )..    shape = m
-00021b10: 622e 7368 6170 6528 783d 782c 206e 616d  b.shape(x=x, nam
-00021b20: 653d 6e6f 6465 2e6e 616d 6520 2b20 225f  e=node.name + "_
-00021b30: 7368 6170 6522 290a 2020 2020 7661 6c75  shape").    valu
-00021b40: 6520 3d20 6d62 2e66 696c 6c28 7368 6170  e = mb.fill(shap
-00021b50: 653d 7368 6170 652c 2076 616c 7565 3d76  e=shape, value=v
-00021b60: 616c 7565 2c20 6e61 6d65 3d6e 6f64 652e  alue, name=node.
-00021b70: 6e61 6d65 202b 2022 5f76 616c 7565 2229  name + "_value")
-00021b80: 0a20 2020 2072 6573 203d 206d 622e 7365  .    res = mb.se
-00021b90: 6c65 6374 2863 6f6e 643d 6d61 736b 2c20  lect(cond=mask, 
-00021ba0: 613d 7661 6c75 652c 2062 3d78 2c20 6e61  a=value, b=x, na
-00021bb0: 6d65 3d6e 6f64 652e 6e61 6d65 290a 2020  me=node.name).  
-00021bc0: 2020 636f 6e74 6578 742e 6164 6428 7265    context.add(re
-00021bd0: 7329 0a0a 0a40 7265 6769 7374 6572 5f74  s)...@register_t
-00021be0: 6f72 6368 5f6f 700a 6465 6620 6d65 7368  orch_op.def mesh
-00021bf0: 6772 6964 2863 6f6e 7465 7874 2c20 6e6f  grid(context, no
-00021c00: 6465 293a 0a20 2020 2022 2222 0a20 2020  de):.    """.   
-00021c10: 2046 6f72 204e 2069 6e70 7574 2074 656e   For N input ten
-00021c20: 736f 7273 2c20 6120 6d65 7368 6772 6964  sors, a meshgrid
-00021c30: 2069 7320 636f 6e73 7472 7563 7465 6420   is constructed 
-00021c40: 6279 2076 6965 7769 6e67 2065 6163 6820  by viewing each 
-00021c50: 7465 6e73 6f72 2061 7320 616e 204e 2d64  tensor as an N-d
-00021c60: 696d 656e 7369 6f6e 2074 656e 736f 720a  imension tensor.
-00021c70: 2020 2020 7769 7468 2076 616c 7565 7320      with values 
-00021c80: 696e 2074 6865 2064 696d 656e 7369 6f6e  in the dimension
-00021c90: 2063 6f72 7265 7370 6f6e 6469 6e67 2069   corresponding i
-00021ca0: 7420 6974 7320 6f72 6465 7220 696e 2074  t its order in t
-00021cb0: 6865 2061 7267 732e 2028 612e 290a 2020  he args. (a.).  
-00021cc0: 2020 5468 656e 2c20 6974 2069 7320 6578    Then, it is ex
-00021cd0: 7061 6e64 6564 2061 6c6f 6e67 2064 696d  panded along dim
-00021ce0: 656e 7369 6f6e 7320 636f 7272 6573 706f  ensions correspo
-00021cf0: 6e64 696e 6720 746f 2074 6865 2064 696d  nding to the dim
-00021d00: 656e 7369 6f6e 7320 6f66 2065 6163 680a  ensions of each.
-00021d10: 2020 2020 3164 2074 656e 736f 7220 696e      1d tensor in
-00021d20: 2074 6865 206f 7264 6572 2074 6861 7420   the order that 
-00021d30: 7468 6579 2077 6572 6520 7061 7373 6564  they were passed
-00021d40: 2069 6e2e 2028 622e 290a 0a20 2020 2045   in. (b.)..    E
-00021d50: 6163 6820 6f75 7470 7574 2074 656e 736f  ach output tenso
-00021d60: 7220 6973 2070 7574 2069 6e74 6f20 6120  r is put into a 
-00021d70: 7475 706c 6520 7468 6174 2069 7320 7265  tuple that is re
-00021d80: 7475 726e 6564 2e20 5468 6573 6520 7475  turned. These tu
-00021d90: 706c 6573 2066 6f72 6d0a 2020 2020 4e2c  ples form.    N,
-00021da0: 204e 2d64 696d 656e 696f 6e61 6c20 6772   N-dimenional gr
-00021db0: 6964 732c 2077 6865 7265 2074 6865 2069  ids, where the i
-00021dc0: 7468 2067 7269 6420 6973 2064 6566 696e  th grid is defin
-00021dd0: 6564 2061 7320 6578 7061 6e64 696e 6720  ed as expanding 
-00021de0: 7468 6520 6974 6820 696e 7075 7420 6f76  the ith input ov
-00021df0: 6572 0a20 2020 2064 696d 656e 7369 6f6e  er.    dimension
-00021e00: 7320 6465 6669 6e65 6420 6279 2074 6865  s defined by the
-00021e10: 206f 7468 6572 2069 6e70 7574 732e 0a20   other inputs.. 
-00021e20: 2020 2022 2222 0a20 2020 2073 7570 706f     """.    suppo
-00021e30: 7274 6564 5f69 6e64 6578 696e 675f 6d6f  rted_indexing_mo
-00021e40: 6465 7320 3d20 2822 696a 222c 2022 7879  des = ("ij", "xy
-00021e50: 2229 0a20 2020 2069 6e64 6578 696e 6720  ").    indexing 
-00021e60: 3d20 2269 6a22 0a20 2020 2069 6e70 7574  = "ij".    input
-00021e70: 7320 3d20 5f67 6574 5f69 6e70 7574 7328  s = _get_inputs(
-00021e80: 636f 6e74 6578 742c 206e 6f64 652c 2065  context, node, e
-00021e90: 7870 6563 7465 643d 5b31 2c20 325d 290a  xpected=[1, 2]).
-00021ea0: 0a20 2020 2069 6620 6c65 6e28 696e 7075  .    if len(inpu
-00021eb0: 7473 2920 3d3d 2032 3a0a 2020 2020 2020  ts) == 2:.      
-00021ec0: 2020 696e 6465 7869 6e67 203d 2069 6e70    indexing = inp
-00021ed0: 7574 735b 315d 2e76 616c 0a20 2020 2020  uts[1].val.     
-00021ee0: 2020 2069 6620 696e 6465 7869 6e67 206e     if indexing n
-00021ef0: 6f74 2069 6e20 7375 7070 6f72 7465 645f  ot in supported_
-00021f00: 696e 6465 7869 6e67 5f6d 6f64 6573 3a0a  indexing_modes:.
-00021f10: 2020 2020 2020 2020 2020 2020 7261 6973              rais
-00021f20: 6520 5661 6c75 6545 7272 6f72 2822 696e  e ValueError("in
-00021f30: 6465 7869 6e67 206d 6f64 6520 7b7d 206e  dexing mode {} n
-00021f40: 6f74 2073 7570 706f 7274 6564 222e 666f  ot supported".fo
-00021f50: 726d 6174 2869 6e64 6578 696e 6729 290a  rmat(indexing)).
-00021f60: 0a20 2020 2074 656e 736f 725f 696e 7075  .    tensor_inpu
-00021f70: 7473 203d 2069 6e70 7574 735b 305d 0a20  ts = inputs[0]. 
-00021f80: 2020 2061 7373 6572 7420 6973 696e 7374     assert isinst
-00021f90: 616e 6365 2874 656e 736f 725f 696e 7075  ance(tensor_inpu
-00021fa0: 7473 2c20 286c 6973 742c 2074 7570 6c65  ts, (list, tuple
-00021fb0: 2929 0a20 2020 2069 6620 6c65 6e28 7465  )).    if len(te
-00021fc0: 6e73 6f72 5f69 6e70 7574 7329 203c 2032  nsor_inputs) < 2
-00021fd0: 3a0a 2020 2020 2020 2020 7261 6973 6520  :.        raise 
-00021fe0: 5661 6c75 6545 7272 6f72 2822 5265 7175  ValueError("Requ
-00021ff0: 6972 6573 203e 3d20 3220 7465 6e73 6f72  ires >= 2 tensor
-00022000: 2069 6e70 7574 732e 2229 0a0a 2020 2020   inputs.")..    
-00022010: 6966 2061 6e79 285b 6c65 6e28 7465 6e73  if any([len(tens
-00022020: 6f72 5f76 6172 2e73 6861 7065 2920 3e20  or_var.shape) > 
-00022030: 3120 666f 7220 7465 6e73 6f72 5f76 6172  1 for tensor_var
-00022040: 2069 6e20 7465 6e73 6f72 5f69 6e70 7574   in tensor_input
-00022050: 735d 293a 0a20 2020 2020 2020 2072 6169  s]):.        rai
-00022060: 7365 2056 616c 7565 4572 726f 7228 226d  se ValueError("m
-00022070: 6573 6867 7269 6420 7265 6369 6576 6564  eshgrid recieved
-00022080: 206e 6f6e 2d31 6420 7465 6e73 6f72 2e22   non-1d tensor."
-00022090: 290a 0a20 2020 2064 696d 5f74 7570 6c65  )..    dim_tuple
-000220a0: 203d 2074 7570 6c65 2874 656e 736f 725f   = tuple(tensor_
-000220b0: 7661 722e 7368 6170 655b 305d 2066 6f72  var.shape[0] for
-000220c0: 2074 656e 736f 725f 7661 7220 696e 2074   tensor_var in t
-000220d0: 656e 736f 725f 696e 7075 7473 290a 0a20  ensor_inputs).. 
-000220e0: 2020 2067 7269 6473 203d 205b 5d0a 2020     grids = [].  
-000220f0: 2020 7369 7a65 203d 206c 656e 2874 656e    size = len(ten
-00022100: 736f 725f 696e 7075 7473 290a 2020 2020  sor_inputs).    
-00022110: 666f 7220 6920 696e 2072 616e 6765 2873  for i in range(s
-00022120: 697a 6529 3a0a 2020 2020 2020 2020 7669  ize):.        vi
-00022130: 6577 5f73 6861 7065 203d 205b 315d 202a  ew_shape = [1] *
-00022140: 2073 697a 650a 2020 2020 2020 2020 7669   size.        vi
-00022150: 6577 5f73 6861 7065 5b69 5d20 3d20 2d31  ew_shape[i] = -1
-00022160: 0a20 2020 2020 2020 2076 6965 775f 7368  .        view_sh
-00022170: 6170 6520 3d20 7475 706c 6528 7669 6577  ape = tuple(view
-00022180: 5f73 6861 7065 290a 2020 2020 2020 2020  _shape).        
-00022190: 2320 2861 2e29 2069 6e20 646f 6373 7472  # (a.) in docstr
-000221a0: 696e 670a 2020 2020 2020 2020 7669 6577  ing.        view
-000221b0: 203d 206d 622e 7265 7368 6170 6528 0a20   = mb.reshape(. 
-000221c0: 2020 2020 2020 2020 2020 2078 3d74 656e             x=ten
-000221d0: 736f 725f 696e 7075 7473 5b69 5d2c 2073  sor_inputs[i], s
-000221e0: 6861 7065 3d76 6965 775f 7368 6170 652c  hape=view_shape,
-000221f0: 206e 616d 653d 6e6f 6465 2e6e 616d 6520   name=node.name 
-00022200: 2b20 225f 7669 6577 5f22 202b 2073 7472  + "_view_" + str
-00022210: 2869 290a 2020 2020 2020 2020 290a 0a20  (i).        ).. 
-00022220: 2020 2020 2020 2023 2028 622e 2920 696e         # (b.) in
-00022230: 2064 6f63 7374 7269 6e67 0a20 2020 2020   docstring.     
-00022240: 2020 2072 6570 7320 3d20 5b0a 2020 2020     reps = [.    
-00022250: 2020 2020 2020 2020 6473 2069 6620 6473          ds if ds
-00022260: 203e 2030 2061 6e64 2074 7320 3d3d 2031   > 0 and ts == 1
-00022270: 2065 6c73 6520 3120 666f 7220 7473 2c20   else 1 for ts, 
-00022280: 6473 2069 6e20 7a69 7028 7669 6577 2e73  ds in zip(view.s
-00022290: 6861 7065 2c20 6469 6d5f 7475 706c 6529  hape, dim_tuple)
-000222a0: 0a20 2020 2020 2020 205d 0a20 2020 2020  .        ].     
-000222b0: 2020 2072 6573 203d 206d 622e 7469 6c65     res = mb.tile
-000222c0: 2878 3d76 6965 772c 2072 6570 733d 7265  (x=view, reps=re
-000222d0: 7073 2c20 6e61 6d65 3d6e 6f64 652e 6e61  ps, name=node.na
-000222e0: 6d65 202b 2022 5f65 7870 616e 645f 2220  me + "_expand_" 
-000222f0: 2b20 7374 7228 6929 290a 0a20 2020 2020  + str(i))..     
-00022300: 2020 2023 2074 7261 6e73 706f 7365 2074     # transpose t
-00022310: 6865 2066 6972 7374 2074 776f 2064 696d  he first two dim
-00022320: 656e 7369 6f6e 7320 666f 7220 2278 7922  ensions for "xy"
-00022330: 2069 6e64 6578 696e 670a 2020 2020 2020   indexing.      
-00022340: 2020 6966 2069 6e64 6578 696e 6720 3d3d    if indexing ==
-00022350: 2022 7879 223a 0a20 2020 2020 2020 2020   "xy":.         
-00022360: 2020 2070 6572 6d20 3d20 5b31 2c20 305d     perm = [1, 0]
-00022370: 202b 206c 6973 7428 7261 6e67 6528 322c   + list(range(2,
-00022380: 2073 697a 6529 290a 2020 2020 2020 2020   size)).        
-00022390: 2020 2020 7265 7320 3d20 6d62 2e74 7261      res = mb.tra
-000223a0: 6e73 706f 7365 2878 3d72 6573 2c20 7065  nspose(x=res, pe
-000223b0: 726d 3d70 6572 6d2c 206e 616d 653d 6e6f  rm=perm, name=no
-000223c0: 6465 2e6e 616d 6520 2b20 225f 7472 616e  de.name + "_tran
-000223d0: 7370 6f73 655f 2220 2b20 7374 7228 6929  spose_" + str(i)
-000223e0: 290a 0a20 2020 2020 2020 2067 7269 6473  )..        grids
-000223f0: 2e61 7070 656e 6428 7265 7329 0a0a 2020  .append(res)..  
-00022400: 2020 636f 6e74 6578 742e 6164 6428 7475    context.add(tu
-00022410: 706c 6528 6772 6964 7329 2c20 6e6f 6465  ple(grids), node
-00022420: 2e6e 616d 6529 0a0a 0a23 2044 6566 696e  .name)...# Defin
-00022430: 6573 2061 6c6c 2074 6865 206e 6f64 6573  es all the nodes
-00022440: 2074 6861 7420 6172 6520 6e6f 4f70 730a   that are noOps.
-00022450: 4072 6567 6973 7465 725f 746f 7263 685f  @register_torch_
-00022460: 6f70 280a 2020 2020 746f 7263 685f 616c  op(.    torch_al
-00022470: 6961 733d 5b0a 2020 2020 2020 2020 2264  ias=[.        "d
-00022480: 726f 706f 7574 222c 0a20 2020 2020 2020  ropout",.       
-00022490: 2022 6472 6f70 6f75 745f 222c 0a20 2020   "dropout_",.   
-000224a0: 2020 2020 2022 6665 6174 7572 655f 6472       "feature_dr
-000224b0: 6f70 6f75 7422 2c0a 2020 2020 2020 2020  opout",.        
-000224c0: 2263 6f6e 7469 6775 6f75 7322 2c0a 2020  "contiguous",.  
-000224d0: 2020 2020 2020 2264 6576 6963 6522 2c0a        "device",.
-000224e0: 2020 2020 2020 2020 2264 6574 6163 6822          "detach"
-000224f0: 2c0a 2020 2020 2020 2020 2263 6c6f 6e65  ,.        "clone
-00022500: 222c 0a20 2020 205d 0a29 0a64 6566 206e  ",.    ].).def n
-00022510: 6f6f 7028 636f 6e74 6578 742c 206e 6f64  oop(context, nod
-00022520: 6529 3a0a 2020 2020 6c6f 6767 6572 2e69  e):.    logger.i
-00022530: 6e66 6f28 2253 6574 7469 6e67 2070 7974  nfo("Setting pyt
-00022540: 6f72 6368 206f 703a 207b 7d20 746f 206e  orch op: {} to n
-00022550: 6f2d 6f70 2e22 2e66 6f72 6d61 7428 6e6f  o-op.".format(no
-00022560: 6465 2929 0a20 2020 2069 6e70 7574 7320  de)).    inputs 
-00022570: 3d20 5f67 6574 5f69 6e70 7574 7328 636f  = _get_inputs(co
-00022580: 6e74 6578 742c 206e 6f64 6529 0a20 2020  ntext, node).   
-00022590: 205f 696e 7075 7420 3d20 696e 7075 7473   _input = inputs
-000225a0: 5b30 5d0a 2020 2020 636f 6e74 6578 742e  [0].    context.
-000225b0: 6164 6428 5f69 6e70 7574 2c20 746f 7263  add(_input, torc
-000225c0: 685f 6e61 6d65 3d6e 6f64 652e 6e61 6d65  h_name=node.name
-000225d0: 290a 0a0a 4072 6567 6973 7465 725f 746f  )...@register_to
-000225e0: 7263 685f 6f70 0a64 6566 2061 7267 6d61  rch_op.def argma
-000225f0: 7828 636f 6e74 6578 742c 206e 6f64 6529  x(context, node)
-00022600: 3a0a 2020 2020 696e 7075 7473 203d 205f  :.    inputs = _
-00022610: 6765 745f 696e 7075 7473 2863 6f6e 7465  get_inputs(conte
-00022620: 7874 2c20 6e6f 6465 290a 2020 2020 7820  xt, node).    x 
-00022630: 3d20 696e 7075 7473 5b30 5d0a 2020 2020  = inputs[0].    
-00022640: 6178 6973 203d 2069 6e70 7574 735b 315d  axis = inputs[1]
-00022650: 0a20 2020 206b 6565 705f 6469 6d73 203d  .    keep_dims =
-00022660: 2069 6e70 7574 735b 325d 0a20 2020 2069   inputs[2].    i
-00022670: 6620 7479 7065 732e 6973 5f69 6e74 2878  f types.is_int(x
-00022680: 2e64 7479 7065 2920 616e 6420 782e 6474  .dtype) and x.dt
-00022690: 7970 652e 5f77 6964 7468 203d 3d20 3634  ype._width == 64
-000226a0: 3a0a 2020 2020 2020 2020 2320 4d49 4c20  :.        # MIL 
-000226b0: 7265 6475 6365 5f61 7267 6d61 7820 646f  reduce_argmax do
-000226c0: 6573 6e27 7420 7375 7070 6f72 7420 696e  esn't support in
-000226d0: 7436 342e 0a20 2020 2020 2020 2078 203d  t64..        x =
-000226e0: 206d 622e 6361 7374 2878 3d78 2c20 6474   mb.cast(x=x, dt
-000226f0: 7970 653d 2269 6e74 3332 2229 0a20 2020  ype="int32").   
-00022700: 2072 6573 203d 206d 622e 7265 6475 6365   res = mb.reduce
-00022710: 5f61 7267 6d61 7828 783d 782c 2061 7869  _argmax(x=x, axi
-00022720: 733d 6178 6973 2c20 6b65 6570 5f64 696d  s=axis, keep_dim
-00022730: 733d 6b65 6570 5f64 696d 732c 206e 616d  s=keep_dims, nam
-00022740: 653d 6e6f 6465 2e6e 616d 6529 0a20 2020  e=node.name).   
-00022750: 2063 6f6e 7465 7874 2e61 6464 2872 6573   context.add(res
-00022760: 290a 0a0a 4072 6567 6973 7465 725f 746f  )...@register_to
-00022770: 7263 685f 6f70 2874 6f72 6368 5f61 6c69  rch_op(torch_ali
-00022780: 6173 3d5b 2265 6d70 7479 5f6c 696b 6522  as=["empty_like"
-00022790: 5d29 0a64 6566 207a 6572 6f73 5f6c 696b  ]).def zeros_lik
-000227a0: 6528 636f 6e74 6578 742c 206e 6f64 6529  e(context, node)
-000227b0: 3a0a 2020 2020 696e 7075 7473 203d 205f  :.    inputs = _
-000227c0: 6765 745f 696e 7075 7473 2863 6f6e 7465  get_inputs(conte
-000227d0: 7874 2c20 6e6f 6465 2c20 6578 7065 6374  xt, node, expect
-000227e0: 6564 3d36 290a 2020 2020 7820 3d20 696e  ed=6).    x = in
-000227f0: 7075 7473 5b30 5d0a 2020 2020 6474 7970  puts[0].    dtyp
-00022800: 6520 3d20 696e 7075 7473 5b31 5d2e 7661  e = inputs[1].va
-00022810: 6c0a 2020 2020 7368 6170 6520 3d20 6d62  l.    shape = mb
-00022820: 2e73 6861 7065 2878 3d78 290a 2020 2020  .shape(x=x).    
-00022830: 6e70 5f74 7970 6520 3d20 4e55 4d5f 544f  np_type = NUM_TO
-00022840: 5f4e 554d 5059 5f44 5459 5045 5b64 7479  _NUMPY_DTYPE[dty
-00022850: 7065 5d0a 0a20 2020 2069 6620 7368 6170  pe]..    if shap
-00022860: 652e 6361 6e5f 6265 5f66 6f6c 6465 645f  e.can_be_folded_
-00022870: 746f 5f63 6f6e 7374 2829 3a0a 2020 2020  to_const():.    
-00022880: 2020 2020 7368 6170 6520 3d20 7368 6170      shape = shap
-00022890: 652e 7661 6c0a 2020 2020 2020 2020 7a65  e.val.        ze
-000228a0: 726f 7320 3d20 5f6e 702e 7a65 726f 7328  ros = _np.zeros(
-000228b0: 7368 6170 6529 2e61 7374 7970 6528 6e70  shape).astype(np
-000228c0: 5f74 7970 6529 0a20 2020 2020 2020 207a  _type).        z
-000228d0: 6572 6f73 5f6c 696b 6520 3d20 6d62 2e63  eros_like = mb.c
-000228e0: 6f6e 7374 2876 616c 3d7a 6572 6f73 2c20  onst(val=zeros, 
-000228f0: 6e61 6d65 3d6e 6f64 652e 6e61 6d65 290a  name=node.name).
-00022900: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
-00022910: 2020 7661 6c75 6520 3d20 6e70 5f74 7970    value = np_typ
-00022920: 6528 3029 0a20 2020 2020 2020 2069 6620  e(0).        if 
-00022930: 6973 5f63 7572 7265 6e74 5f6f 7073 6574  is_current_opset
-00022940: 5f76 6572 7369 6f6e 5f63 6f6d 7061 7469  _version_compati
-00022950: 626c 655f 7769 7468 2874 6172 6765 742e  ble_with(target.
-00022960: 694f 5331 3629 3a0a 2020 2020 2020 2020  iOS16):.        
-00022970: 2020 2020 7a65 726f 735f 6c69 6b65 203d      zeros_like =
-00022980: 206d 622e 6669 6c6c 5f6c 696b 6528 7265   mb.fill_like(re
-00022990: 665f 7465 6e73 6f72 3d78 2c20 7661 6c75  f_tensor=x, valu
-000229a0: 653d 7661 6c75 652c 206e 616d 653d 6e6f  e=value, name=no
-000229b0: 6465 2e6e 616d 6529 0a20 2020 2020 2020  de.name).       
-000229c0: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
-000229d0: 2020 207a 6572 6f73 5f6c 696b 6520 3d20     zeros_like = 
-000229e0: 6d62 2e66 696c 6c28 7368 6170 653d 7368  mb.fill(shape=sh
-000229f0: 6170 652c 2076 616c 7565 3d76 616c 7565  ape, value=value
-00022a00: 2c20 6e61 6d65 3d6e 6f64 652e 6e61 6d65  , name=node.name
-00022a10: 290a 0a20 2020 2063 6f6e 7465 7874 2e61  )..    context.a
-00022a20: 6464 287a 6572 6f73 5f6c 696b 6529 0a0a  dd(zeros_like)..
-00022a30: 0a40 7265 6769 7374 6572 5f74 6f72 6368  .@register_torch
-00022a40: 5f6f 7028 746f 7263 685f 616c 6961 733d  _op(torch_alias=
-00022a50: 5b22 656d 7074 7922 5d29 0a64 6566 207a  ["empty"]).def z
-00022a60: 6572 6f73 2863 6f6e 7465 7874 2c20 6e6f  eros(context, no
-00022a70: 6465 293a 0a20 2020 2069 6e70 7574 7320  de):.    inputs 
-00022a80: 3d20 5f67 6574 5f69 6e70 7574 7328 636f  = _get_inputs(co
-00022a90: 6e74 6578 742c 206e 6f64 6529 0a20 2020  ntext, node).   
-00022aa0: 2073 697a 6520 3d20 696e 7075 7473 5b30   size = inputs[0
-00022ab0: 5d0a 2020 2020 6966 2069 6e70 7574 735b  ].    if inputs[
-00022ac0: 315d 2069 7320 6e6f 7420 4e6f 6e65 3a0a  1] is not None:.
-00022ad0: 2020 2020 2020 2020 6474 7970 6520 3d20          dtype = 
-00022ae0: 696e 7075 7473 5b31 5d2e 7661 6c0a 2020  inputs[1].val.  
-00022af0: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
-00022b00: 6474 7970 6520 3d20 746f 7263 682e 6765  dtype = torch.ge
-00022b10: 745f 6465 6661 756c 745f 6474 7970 6528  t_default_dtype(
-00022b20: 290a 2020 2020 2020 2020 6173 7365 7274  ).        assert
-00022b30: 2064 7479 7065 2069 6e20 2874 6f72 6368   dtype in (torch
-00022b40: 2e66 6c6f 6174 3332 2c20 746f 7263 682e  .float32, torch.
-00022b50: 666c 6f61 7436 3429 0a20 2020 2020 2020  float64).       
-00022b60: 2064 7479 7065 203d 2036 0a0a 2020 2020   dtype = 6..    
-00022b70: 6966 2069 7369 6e73 7461 6e63 6528 7369  if isinstance(si
-00022b80: 7a65 2c20 6c69 7374 2920 6f72 206e 6f74  ze, list) or not
-00022b90: 2073 697a 652e 6361 6e5f 6265 5f66 6f6c   size.can_be_fol
-00022ba0: 6465 645f 746f 5f63 6f6e 7374 2829 3a0a  ded_to_const():.
-00022bb0: 2020 2020 2020 2020 2320 7468 6520 7369          # the si
-00022bc0: 7a65 2069 7320 6479 6e61 6d69 6320 6f72  ze is dynamic or
-00022bd0: 2074 6869 7320 7a65 726f 7320 6f70 2063   this zeros op c
-00022be0: 616e 6e6f 7420 6265 2066 6f6c 6465 6420  annot be folded 
-00022bf0: 696e 746f 2063 6f6e 7374 2e0a 2020 2020  into const..    
-00022c00: 2020 2020 7369 7a65 203d 206d 622e 636f      size = mb.co
-00022c10: 6e63 6174 2876 616c 7565 733d 7369 7a65  ncat(values=size
-00022c20: 2c20 6178 6973 3d30 2920 6966 2069 7369  , axis=0) if isi
-00022c30: 6e73 7461 6e63 6528 7369 7a65 2c20 6c69  nstance(size, li
-00022c40: 7374 2920 656c 7365 2073 697a 650a 2020  st) else size.  
-00022c50: 2020 2020 2020 6e70 5f74 7970 6520 3d20        np_type = 
-00022c60: 4e55 4d5f 544f 5f4e 554d 5059 5f44 5459  NUM_TO_NUMPY_DTY
-00022c70: 5045 5b64 7479 7065 5d0a 2020 2020 2020  PE[dtype].      
-00022c80: 2020 7a65 726f 7320 3d20 6d62 2e66 696c    zeros = mb.fil
-00022c90: 6c28 7368 6170 653d 7369 7a65 2c20 7661  l(shape=size, va
-00022ca0: 6c75 653d 6e70 5f74 7970 6528 3029 2c20  lue=np_type(0), 
-00022cb0: 6e61 6d65 3d6e 6f64 652e 6e61 6d65 290a  name=node.name).
-00022cc0: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
-00022cd0: 2020 2320 7468 6520 7369 7a65 2069 7320    # the size is 
-00022ce0: 7374 6174 6963 2061 6e64 2074 6869 7320  static and this 
-00022cf0: 7a65 726f 7320 6f70 2063 616e 2062 6520  zeros op can be 
-00022d00: 666f 6c64 6564 2069 6e74 6f20 636f 6e73  folded into cons
-00022d10: 742e 0a20 2020 2020 2020 2073 697a 6520  t..        size 
-00022d20: 3d20 7369 7a65 2e76 616c 0a20 2020 2020  = size.val.     
-00022d30: 2020 2023 206c 6179 6f75 7420 3d20 696e     # layout = in
-00022d40: 7075 7473 5b32 5d20 756e 7573 6564 0a20  puts[2] unused. 
-00022d50: 2020 2020 2020 2023 2064 6576 6963 6520         # device 
-00022d60: 3d20 696e 7075 7473 5b33 5d20 756e 7573  = inputs[3] unus
-00022d70: 6564 0a20 2020 2020 2020 2023 2070 696e  ed.        # pin
-00022d80: 5f6d 656d 6f72 7920 3d20 696e 7075 7473  _memory = inputs
-00022d90: 5b34 5d20 756e 7573 6564 0a20 2020 2020  [4] unused.     
-00022da0: 2020 2074 6f72 6368 5f64 7479 7065 203d     torch_dtype =
-00022db0: 204e 554d 5f54 4f5f 544f 5243 485f 4454   NUM_TO_TORCH_DT
-00022dc0: 5950 455b 6474 7970 655d 0a20 2020 2020  YPE[dtype].     
-00022dd0: 2020 207a 6572 6f73 5f61 7272 6179 203d     zeros_array =
-00022de0: 2074 6f72 6368 2e7a 6572 6f73 2874 7570   torch.zeros(tup
-00022df0: 6c65 2873 697a 6529 292e 7479 7065 2874  le(size)).type(t
-00022e00: 6f72 6368 5f64 7479 7065 292e 6e75 6d70  orch_dtype).nump
-00022e10: 7928 290a 2020 2020 2020 2020 7a65 726f  y().        zero
-00022e20: 7320 3d20 6d62 2e63 6f6e 7374 2876 616c  s = mb.const(val
-00022e30: 3d7a 6572 6f73 5f61 7272 6179 2c20 6e61  =zeros_array, na
-00022e40: 6d65 3d6e 6f64 652e 6e61 6d65 290a 0a20  me=node.name).. 
-00022e50: 2020 2063 6f6e 7465 7874 2e61 6464 287a     context.add(z
-00022e60: 6572 6f73 290a 0a0a 4072 6567 6973 7465  eros)...@registe
-00022e70: 725f 746f 7263 685f 6f70 2874 6f72 6368  r_torch_op(torch
-00022e80: 5f61 6c69 6173 3d5b 226e 6577 5f65 6d70  _alias=["new_emp
-00022e90: 7479 225d 290a 6465 6620 6e65 775f 7a65  ty"]).def new_ze
-00022ea0: 726f 7328 636f 6e74 6578 742c 206e 6f64  ros(context, nod
-00022eb0: 6529 3a0a 2020 2020 696e 7075 7473 203d  e):.    inputs =
-00022ec0: 205f 6765 745f 696e 7075 7473 2863 6f6e   _get_inputs(con
-00022ed0: 7465 7874 2c20 6e6f 6465 290a 2020 2020  text, node).    
-00022ee0: 7368 6170 6520 3d20 696e 7075 7473 5b31  shape = inputs[1
-00022ef0: 5d0a 2020 2020 6966 2069 7369 6e73 7461  ].    if isinsta
-00022f00: 6e63 6528 7368 6170 652c 206c 6973 7429  nce(shape, list)
-00022f10: 3a0a 2020 2020 2020 2020 2320 7768 656e  :.        # when
-00022f20: 2074 6865 2073 697a 6520 6973 2064 796e   the size is dyn
-00022f30: 616d 6963 2c20 6974 2069 7320 6120 6c69  amic, it is a li
-00022f40: 7374 206f 6620 7079 6d69 6c20 7363 616c  st of pymil scal
-00022f50: 6172 2c0a 2020 2020 2020 2020 2320 7765  ar,.        # we
-00022f60: 206e 6565 6420 746f 2063 6f6e 6361 7420   need to concat 
-00022f70: 7468 656d 2066 6972 7374 2074 6f20 6765  them first to ge
-00022f80: 7420 6120 7368 6170 652e 0a20 2020 2020  t a shape..     
-00022f90: 2020 2073 6861 7065 203d 206d 622e 636f     shape = mb.co
-00022fa0: 6e63 6174 2876 616c 7565 733d 7368 6170  ncat(values=shap
-00022fb0: 652c 2061 7869 733d 3029 0a20 2020 2063  e, axis=0).    c
-00022fc0: 6f6e 7465 7874 2e61 6464 286d 622e 6669  ontext.add(mb.fi
-00022fd0: 6c6c 2873 6861 7065 3d73 6861 7065 2c20  ll(shape=shape, 
-00022fe0: 7661 6c75 653d 302e 2c20 6e61 6d65 3d6e  value=0., name=n
-00022ff0: 6f64 652e 6e61 6d65 2929 0a0a 0a40 7265  ode.name))...@re
-00023000: 6769 7374 6572 5f74 6f72 6368 5f6f 700a  gister_torch_op.
-00023010: 6465 6620 6469 6d28 636f 6e74 6578 742c  def dim(context,
-00023020: 206e 6f64 6529 3a0a 2020 2020 696e 7075   node):.    inpu
-00023030: 7473 203d 205f 6765 745f 696e 7075 7473  ts = _get_inputs
-00023040: 2863 6f6e 7465 7874 2c20 6e6f 6465 290a  (context, node).
-00023050: 2020 2020 7368 6170 6520 3d20 6d62 2e73      shape = mb.s
-00023060: 6861 7065 2878 3d69 6e70 7574 735b 305d  hape(x=inputs[0]
-00023070: 290a 2020 2020 7261 6e6b 203d 206d 622e  ).    rank = mb.
-00023080: 7368 6170 6528 783d 7368 6170 6529 0a20  shape(x=shape). 
-00023090: 2020 2063 6f6e 7465 7874 2e61 6464 2876     context.add(v
-000230a0: 616c 7565 5f61 7428 7261 6e6b 2c20 302c  alue_at(rank, 0,
-000230b0: 206e 6f64 652e 6e61 6d65 2929 0a0a 0a40   node.name))...@
-000230c0: 7265 6769 7374 6572 5f74 6f72 6368 5f6f  register_torch_o
-000230d0: 700a 6465 6620 6d69 6e28 636f 6e74 6578  p.def min(contex
-000230e0: 742c 206e 6f64 6529 3a0a 2020 2020 696e  t, node):.    in
-000230f0: 7075 7473 203d 205f 6765 745f 696e 7075  puts = _get_inpu
-00023100: 7473 2863 6f6e 7465 7874 2c20 6e6f 6465  ts(context, node
-00023110: 2c20 6578 7065 6374 6564 3d5b 312c 2032  , expected=[1, 2
-00023120: 2c20 335d 290a 0a20 2020 2023 206d 696d  , 3])..    # mim
-00023130: 6963 2066 756e 6374 696f 6e61 6c69 7479  ic functionality
-00023140: 2066 726f 6d20 6874 7470 733a 2f2f 7079   from https://py
-00023150: 746f 7263 682e 6f72 672f 646f 6373 2f73  torch.org/docs/s
-00023160: 7461 626c 652f 6765 6e65 7261 7465 642f  table/generated/
-00023170: 746f 7263 682e 6d69 6e2e 6874 6d6c 0a20  torch.min.html. 
-00023180: 2020 2069 6620 6c65 6e28 696e 7075 7473     if len(inputs
-00023190: 2920 3d3d 2031 3a0a 2020 2020 2020 2020  ) == 1:.        
-000231a0: 7661 6c75 6520 3d20 6d62 2e72 6564 7563  value = mb.reduc
-000231b0: 655f 6d69 6e28 783d 696e 7075 7473 5b30  e_min(x=inputs[0
-000231c0: 5d2c 2061 7865 733d 4e6f 6e65 2c20 6e61  ], axes=None, na
-000231d0: 6d65 3d6e 6f64 652e 6e61 6d65 290a 2020  me=node.name).  
-000231e0: 2020 2020 2020 636f 6e74 6578 742e 6164        context.ad
-000231f0: 6428 7661 6c75 6529 0a20 2020 2065 6c69  d(value).    eli
-00023200: 6620 6c65 6e28 696e 7075 7473 2920 3d3d  f len(inputs) ==
-00023210: 2032 3a0a 2020 2020 2020 2020 7661 6c75   2:.        valu
-00023220: 6520 3d20 6d62 2e6d 696e 696d 756d 2878  e = mb.minimum(x
-00023230: 3d69 6e70 7574 735b 305d 2c20 793d 696e  =inputs[0], y=in
-00023240: 7075 7473 5b31 5d2c 206e 616d 653d 6e6f  puts[1], name=no
-00023250: 6465 2e6e 616d 6529 0a20 2020 2020 2020  de.name).       
-00023260: 2063 6f6e 7465 7874 2e61 6464 2876 616c   context.add(val
-00023270: 7565 290a 2020 2020 656c 6966 206c 656e  ue).    elif len
-00023280: 2869 6e70 7574 7329 203d 3d20 333a 0a20  (inputs) == 3:. 
-00023290: 2020 2020 2020 205f 696e 7075 7420 3d20         _input = 
-000232a0: 696e 7075 7473 5b30 5d0a 2020 2020 2020  inputs[0].      
-000232b0: 2020 6469 6d20 3d20 696e 7075 7473 5b31    dim = inputs[1
-000232c0: 5d2e 7661 6c0a 2020 2020 2020 2020 6b65  ].val.        ke
-000232d0: 6570 6469 6d20 3d20 696e 7075 7473 5b32  epdim = inputs[2
-000232e0: 5d2e 7661 6c0a 0a20 2020 2020 2020 2076  ].val..        v
-000232f0: 616c 7565 7320 3d20 6d62 2e72 6564 7563  alues = mb.reduc
-00023300: 655f 6d69 6e28 783d 5f69 6e70 7574 2c20  e_min(x=_input, 
-00023310: 6178 6573 3d5b 6469 6d5d 2c20 6b65 6570  axes=[dim], keep
-00023320: 5f64 696d 733d 6b65 6570 6469 6d29 0a20  _dims=keepdim). 
-00023330: 2020 2020 2020 2069 6e64 6963 6573 203d         indices =
-00023340: 206d 622e 7265 6475 6365 5f61 7267 6d69   mb.reduce_argmi
-00023350: 6e28 783d 5f69 6e70 7574 2c20 6178 6973  n(x=_input, axis
-00023360: 3d64 696d 2c20 6b65 6570 5f64 696d 733d  =dim, keep_dims=
-00023370: 6b65 6570 6469 6d29 0a20 2020 2020 2020  keepdim).       
-00023380: 2061 7373 6572 7420 6c65 6e28 6e6f 6465   assert len(node
-00023390: 2e6f 7574 7075 7473 2920 3d3d 2032 0a20  .outputs) == 2. 
-000233a0: 2020 2020 2020 2076 616c 7565 735f 6e61         values_na
-000233b0: 6d65 203d 206e 6f64 652e 6f75 7470 7574  me = node.output
-000233c0: 735b 305d 0a20 2020 2020 2020 2069 6e64  s[0].        ind
-000233d0: 6963 6573 5f6e 616d 6520 3d20 6e6f 6465  ices_name = node
-000233e0: 2e6f 7574 7075 7473 5b31 5d0a 2020 2020  .outputs[1].    
-000233f0: 2020 2020 636f 6e74 6578 742e 6164 6428      context.add(
-00023400: 7661 6c75 6573 2c20 746f 7263 685f 6e61  values, torch_na
-00023410: 6d65 3d76 616c 7565 735f 6e61 6d65 290a  me=values_name).
-00023420: 2020 2020 2020 2020 636f 6e74 6578 742e          context.
-00023430: 6164 6428 696e 6469 6365 732c 2074 6f72  add(indices, tor
-00023440: 6368 5f6e 616d 653d 696e 6469 6365 735f  ch_name=indices_
-00023450: 6e61 6d65 290a 0a0a 4072 6567 6973 7465  name)...@registe
-00023460: 725f 746f 7263 685f 6f70 0a64 6566 206d  r_torch_op.def m
-00023470: 6178 2863 6f6e 7465 7874 2c20 6e6f 6465  ax(context, node
-00023480: 293a 0a20 2020 2069 6e70 7574 7320 3d20  ):.    inputs = 
-00023490: 5f67 6574 5f69 6e70 7574 7328 636f 6e74  _get_inputs(cont
-000234a0: 6578 742c 206e 6f64 652c 2065 7870 6563  ext, node, expec
-000234b0: 7465 643d 5b31 2c20 322c 2033 5d29 0a0a  ted=[1, 2, 3])..
-000234c0: 2020 2020 2320 6d69 6d69 6320 6675 6e63      # mimic func
-000234d0: 7469 6f6e 616c 6974 7920 6672 6f6d 2068  tionality from h
-000234e0: 7474 7073 3a2f 2f70 7974 6f72 6368 2e6f  ttps://pytorch.o
-000234f0: 7267 2f64 6f63 732f 7374 6162 6c65 2f67  rg/docs/stable/g
-00023500: 656e 6572 6174 6564 2f74 6f72 6368 2e6d  enerated/torch.m
-00023510: 6178 2e68 746d 6c0a 2020 2020 6966 206c  ax.html.    if l
-00023520: 656e 2869 6e70 7574 7329 203d 3d20 313a  en(inputs) == 1:
-00023530: 0a20 2020 2020 2020 2076 616c 7565 203d  .        value =
-00023540: 206d 622e 7265 6475 6365 5f6d 6178 2878   mb.reduce_max(x
-00023550: 3d69 6e70 7574 735b 305d 2c20 6178 6573  =inputs[0], axes
-00023560: 3d4e 6f6e 652c 206e 616d 653d 6e6f 6465  =None, name=node
-00023570: 2e6e 616d 6529 0a20 2020 2020 2020 2063  .name).        c
-00023580: 6f6e 7465 7874 2e61 6464 2876 616c 7565  ontext.add(value
-00023590: 290a 2020 2020 656c 6966 206c 656e 2869  ).    elif len(i
-000235a0: 6e70 7574 7329 203d 3d20 323a 0a20 2020  nputs) == 2:.   
-000235b0: 2020 2020 2076 616c 7565 203d 206d 622e       value = mb.
-000235c0: 6d61 7869 6d75 6d28 783d 696e 7075 7473  maximum(x=inputs
-000235d0: 5b30 5d2c 2079 3d69 6e70 7574 735b 315d  [0], y=inputs[1]
+00000100: 696d 706f 7274 206e 756d 6265 7273 0a69  import numbers.i
+00000110: 6d70 6f72 7420 7265 0a66 726f 6d20 636f  mport re.from co
+00000120: 6c6c 6563 7469 6f6e 732e 6162 6320 696d  llections.abc im
+00000130: 706f 7274 2049 7465 7261 626c 650a 6672  port Iterable.fr
+00000140: 6f6d 2074 7970 696e 6720 696d 706f 7274  om typing import
+00000150: 204c 6973 742c 204f 7074 696f 6e61 6c0a   List, Optional.
+00000160: 0a69 6d70 6f72 7420 6e75 6d70 7920 6173  .import numpy as
+00000170: 205f 6e70 0a69 6d70 6f72 7420 6e75 6d70   _np.import nump
+00000180: 7920 6173 206e 700a 696d 706f 7274 2074  y as np.import t
+00000190: 6f72 6368 0a66 726f 6d20 7471 646d 2069  orch.from tqdm i
+000001a0: 6d70 6f72 7420 7471 646d 2061 7320 5f74  mport tqdm as _t
+000001b0: 7164 6d0a 0a66 726f 6d20 636f 7265 6d6c  qdm..from coreml
+000001c0: 746f 6f6c 7320 696d 706f 7274 205f 6c6f  tools import _lo
+000001d0: 6767 6572 2061 7320 6c6f 6767 6572 0a66  gger as logger.f
+000001e0: 726f 6d20 636f 7265 6d6c 746f 6f6c 732e  rom coremltools.
+000001f0: 636f 6e76 6572 7465 7273 2e6d 696c 2e5f  converters.mil._
+00000200: 6465 706c 6f79 6d65 6e74 5f63 6f6d 7061  deployment_compa
+00000210: 7469 6269 6c69 7479 2069 6d70 6f72 7420  tibility import 
+00000220: 4176 6169 6c61 626c 6554 6172 6765 7420  AvailableTarget 
+00000230: 6173 2074 6172 6765 740a 6672 6f6d 2063  as target.from c
+00000240: 6f72 656d 6c74 6f6f 6c73 2e63 6f6e 7665  oremltools.conve
+00000250: 7274 6572 732e 6d69 6c2e 6d69 6c20 696d  rters.mil.mil im
+00000260: 706f 7274 2042 7569 6c64 6572 2061 7320  port Builder as 
+00000270: 6d62 0a66 726f 6d20 636f 7265 6d6c 746f  mb.from coremlto
+00000280: 6f6c 732e 636f 6e76 6572 7465 7273 2e6d  ols.converters.m
+00000290: 696c 2e6d 696c 2069 6d70 6f72 7420 5379  il.mil import Sy
+000002a0: 6d62 6f6c 2c20 7479 7065 730a 6672 6f6d  mbol, types.from
+000002b0: 2063 6f72 656d 6c74 6f6f 6c73 2e63 6f6e   coremltools.con
+000002c0: 7665 7274 6572 732e 6d69 6c2e 6d69 6c2e  verters.mil.mil.
+000002d0: 626c 6f63 6b20 696d 706f 7274 2069 735f  block import is_
+000002e0: 6375 7272 656e 745f 6f70 7365 745f 7665  current_opset_ve
+000002f0: 7273 696f 6e5f 636f 6d70 6174 6962 6c65  rsion_compatible
+00000300: 5f77 6974 680a 6672 6f6d 2063 6f72 656d  _with.from corem
+00000310: 6c74 6f6f 6c73 2e63 6f6e 7665 7274 6572  ltools.converter
+00000320: 732e 6d69 6c2e 6d69 6c2e 6f70 732e 6465  s.mil.mil.ops.de
+00000330: 6673 2e5f 7574 696c 7320 696d 706f 7274  fs._utils import
+00000340: 2028 0a20 2020 204d 4158 5f53 495a 455f   (.    MAX_SIZE_
+00000350: 434f 4e53 5441 4e54 5f46 4f4c 4449 4e47  CONSTANT_FOLDING
+00000360: 2c0a 2020 2020 7072 6f6d 6f74 655f 696e  ,.    promote_in
+00000370: 7075 745f 6474 7970 6573 2c0a 2020 2020  put_dtypes,.    
+00000380: 736f 6c76 655f 736c 6963 655f 6279 5f69  solve_slice_by_i
+00000390: 6e64 6578 5f73 6861 7065 2c0a 290a 6672  ndex_shape,.).fr
+000003a0: 6f6d 2063 6f72 656d 6c74 6f6f 6c73 2e63  om coremltools.c
+000003b0: 6f6e 7665 7274 6572 732e 6d69 6c2e 6d69  onverters.mil.mi
+000003c0: 6c2e 7479 7065 7320 696d 706f 7274 2069  l.types import i
+000003d0: 735f 626f 6f6c 2c20 6e70 7479 7065 5f66  s_bool, nptype_f
+000003e0: 726f 6d5f 6275 696c 7469 6e0a 6672 6f6d  rom_builtin.from
+000003f0: 2063 6f72 656d 6c74 6f6f 6c73 2e63 6f6e   coremltools.con
+00000400: 7665 7274 6572 732e 6d69 6c2e 6d69 6c2e  verters.mil.mil.
+00000410: 7479 7065 732e 7379 6d62 6f6c 6963 2069  types.symbolic i
+00000420: 6d70 6f72 7420 616e 795f 7379 6d62 6f6c  mport any_symbol
+00000430: 6963 2c20 6973 5f73 796d 626f 6c69 630a  ic, is_symbolic.
+00000440: 6672 6f6d 2063 6f72 656d 6c74 6f6f 6c73  from coremltools
+00000450: 2e63 6f6e 7665 7274 6572 732e 6d69 6c2e  .converters.mil.
+00000460: 6d69 6c2e 7661 7220 696d 706f 7274 204c  mil.var import L
+00000470: 6973 7456 6172 2c20 5661 720a 0a66 726f  istVar, Var..fro
+00000480: 6d20 2e2e 5f75 7469 6c73 2069 6d70 6f72  m .._utils impor
+00000490: 7420 6275 696c 645f 6569 6e73 756d 5f6d  t build_einsum_m
+000004a0: 696c 2c20 7661 6c75 655f 6174 0a66 726f  il, value_at.fro
+000004b0: 6d20 2e74 6f72 6368 5f6f 705f 7265 6769  m .torch_op_regi
+000004c0: 7374 7279 2069 6d70 6f72 7420 5f54 4f52  stry import _TOR
+000004d0: 4348 5f4f 5053 5f52 4547 4953 5452 592c  CH_OPS_REGISTRY,
+000004e0: 2072 6567 6973 7465 725f 746f 7263 685f   register_torch_
+000004f0: 6f70 0a0a 2320 5468 6520 7079 746f 7263  op..# The pytorc
+00000500: 6820 6172 6773 2066 6f72 206d 616e 7920  h args for many 
+00000510: 6f66 2074 6865 2062 656c 6f77 206f 7073  of the below ops
+00000520: 2077 6572 6520 736f 7572 6365 6420 6672   were sourced fr
+00000530: 6f6d 0a23 2068 7474 7073 3a2f 2f67 6974  om.# https://git
+00000540: 6875 622e 636f 6d2f 7079 746f 7263 682f  hub.com/pytorch/
+00000550: 7079 746f 7263 682f 626c 6f62 2f64 3937  pytorch/blob/d97
+00000560: 3130 3037 6332 3931 6330 6561 6431 3030  1007c291c0ead100
+00000570: 3364 3132 6364 3535 3364 3138 6464 6235  3d12cd553d18ddb5
+00000580: 3832 3230 372f 746f 7263 682f 6373 7263  82207/torch/csrc
+00000590: 2f6a 6974 2f6d 6f62 696c 652f 7265 6769  /jit/mobile/regi
+000005a0: 7374 6572 5f6d 6f62 696c 655f 6f70 732e  ster_mobile_ops.
+000005b0: 6370 7023 4c32 3136 0a0a 0a23 204d 6178  cpp#L216...# Max
+000005c0: 2069 6e74 3634 2076 616c 7565 2e20 5573   int64 value. Us
+000005d0: 6564 2061 7320 6120 6465 6661 756c 7420  ed as a default 
+000005e0: 7661 6c75 6520 696e 206d 616e 7920 5079  value in many Py
+000005f0: 546f 7263 6820 6675 6e63 7469 6f6e 732e  Torch functions.
+00000600: 0a50 5954 4f52 4348 5f44 4546 4155 4c54  .PYTORCH_DEFAULT
+00000610: 5f56 414c 5545 203d 2032 2a2a 3633 202d  _VALUE = 2**63 -
+00000620: 2031 0a0a 5641 4c55 455f 434c 4f53 455f   1..VALUE_CLOSE_
+00000630: 544f 5f49 4e46 494e 4954 5920 3d20 3165  TO_INFINITY = 1e
+00000640: 2b33 380a 0a0a 6465 6620 5f61 6c6c 5f6f  +38...def _all_o
+00000650: 7574 7075 7473 5f70 7265 7365 6e74 2863  utputs_present(c
+00000660: 6f6e 7465 7874 2c20 6772 6170 6829 3a0a  ontext, graph):.
+00000670: 2020 2020 2222 220a 2020 2020 5265 7475      """.    Retu
+00000680: 726e 7320 7472 7565 2069 6620 616c 6c20  rns true if all 
+00000690: 7468 6520 7379 6d62 6f6c 7320 696e 2074  the symbols in t
+000006a0: 6865 2067 7261 7068 2773 206f 7574 7075  he graph's outpu
+000006b0: 7420 6c69 7374 2061 7265 0a20 2020 2070  t list are.    p
+000006c0: 7265 7365 6e74 2069 6e20 636f 6e74 6578  resent in contex
+000006d0: 742e 0a20 2020 2022 2222 0a20 2020 2066  t..    """.    f
+000006e0: 6f72 206f 7574 7020 696e 2067 7261 7068  or outp in graph
+000006f0: 2e6f 7574 7075 7473 3a0a 2020 2020 2020  .outputs:.      
+00000700: 2020 7472 793a 0a20 2020 2020 2020 2020    try:.         
+00000710: 2020 2063 6f6e 7465 7874 5b6f 7574 705d     context[outp]
+00000720: 0a20 2020 2020 2020 2065 7863 6570 7420  .        except 
+00000730: 5661 6c75 6545 7272 6f72 3a0a 2020 2020  ValueError:.    
+00000740: 2020 2020 2020 2020 7265 7475 726e 2046          return F
+00000750: 616c 7365 0a20 2020 2072 6574 7572 6e20  alse.    return 
+00000760: 5472 7565 0a0a 0a64 6566 2063 6f6e 7665  True...def conve
+00000770: 7274 5f6e 6f64 6573 2863 6f6e 7465 7874  rt_nodes(context
+00000780: 2c20 6772 6170 6829 3a0a 2020 2020 2222  , graph):.    ""
+00000790: 220a 2020 2020 4974 6572 6174 6520 6f76  ".    Iterate ov
+000007a0: 6572 2074 6865 206e 6f64 6573 206f 6620  er the nodes of 
+000007b0: 6120 6772 6170 6820 6f72 2062 6c6f 636b  a graph or block
+000007c0: 2061 6e64 2063 6f6e 7665 7274 2074 6f20   and convert to 
+000007d0: 4d49 4c2e 0a0a 2020 2020 4172 6775 6d65  MIL...    Argume
+000007e0: 6e74 733a 0a20 2020 2020 2020 2063 6f6e  nts:.        con
+000007f0: 7465 7874 3a20 4120 5472 616e 7363 7269  text: A Transcri
+00000800: 7074 696f 6e43 6f6e 7465 7874 206f 626a  ptionContext obj
+00000810: 6563 7420 746f 2070 756c 6c20 6e6f 6465  ect to pull node
+00000820: 2069 6e70 7574 7320 616e 640a 2020 2020   inputs and.    
+00000830: 2020 2020 2020 2020 6173 7369 676e 206e          assign n
+00000840: 6f64 6520 6f75 7470 7574 732e 0a20 2020  ode outputs..   
+00000850: 2020 2020 2067 7261 7068 3a20 416e 2049       graph: An I
+00000860: 6e74 6572 6e61 6c54 6f72 6368 4952 4772  nternalTorchIRGr
+00000870: 6170 6820 6f72 2049 6e74 6572 6e61 6c54  aph or InternalT
+00000880: 6f72 6368 4952 426c 6f63 6b20 6f62 6a65  orchIRBlock obje
+00000890: 6374 2e0a 2020 2020 2222 220a 2020 2020  ct..    """.    
+000008a0: 666f 7220 6e6f 6465 2069 6e20 5f74 7164  for node in _tqd
+000008b0: 6d28 6772 6170 682e 6e6f 6465 732c 2064  m(graph.nodes, d
+000008c0: 6573 633d 2243 6f6e 7665 7274 696e 6720  esc="Converting 
+000008d0: 5079 546f 7263 6820 4672 6f6e 7465 6e64  PyTorch Frontend
+000008e0: 203d 3d3e 204d 494c 204f 7073 222c 2075   ==> MIL Ops", u
+000008f0: 6e69 743d 2220 6f70 7322 293a 0a20 2020  nit=" ops"):.   
+00000900: 2020 2020 206f 705f 6c6f 6f6b 7570 203d       op_lookup =
+00000910: 206e 6f64 652e 6b69 6e64 0a20 2020 2020   node.kind.     
+00000920: 2020 2069 6620 6f70 5f6c 6f6f 6b75 702e     if op_lookup.
+00000930: 7374 6172 7473 7769 7468 2822 5f5f 2229  startswith("__")
+00000940: 2061 6e64 206f 705f 6c6f 6f6b 7570 2e65   and op_lookup.e
+00000950: 6e64 7377 6974 6828 225f 5f22 293a 0a20  ndswith("__"):. 
+00000960: 2020 2020 2020 2020 2020 2023 2053 6f6d             # Som
+00000970: 6520 6f70 7320 6d61 7920 6861 7665 2064  e ops may have d
+00000980: 6f75 626c 6520 756e 6465 7273 636f 7265  ouble underscore
+00000990: 2c20 7375 6368 2061 7320 605f 5f61 6e64  , such as `__and
+000009a0: 5f5f 602e 0a20 2020 2020 2020 2020 2020  __`..           
+000009b0: 206f 705f 6c6f 6f6b 7570 203d 206f 705f   op_lookup = op_
+000009c0: 6c6f 6f6b 7570 5b32 3a2d 325d 0a20 2020  lookup[2:-2].   
+000009d0: 2020 2020 2065 6c69 6620 6f70 5f6c 6f6f       elif op_loo
+000009e0: 6b75 702e 656e 6473 7769 7468 2822 5f22  kup.endswith("_"
+000009f0: 293a 0a20 2020 2020 2020 2020 2020 2023  ):.            #
+00000a00: 2054 6869 7320 6973 2061 6e20 2269 6e20   This is an "in 
+00000a10: 706c 6163 6522 206f 702e 0a20 2020 2020  place" op..     
+00000a20: 2020 2020 2020 2023 204c 6f6f 6b20 7570         # Look up
+00000a30: 2074 6865 2073 7461 6e64 6172 6420 6f70   the standard op
+00000a40: 2069 6e73 7465 6164 2062 7920 7265 6d6f   instead by remo
+00000a50: 7669 6e67 2075 6e64 6572 7363 6f72 652e  ving underscore.
+00000a60: 0a20 2020 2020 2020 2020 2020 206f 705f  .            op_
+00000a70: 6c6f 6f6b 7570 203d 206f 705f 6c6f 6f6b  lookup = op_look
+00000a80: 7570 5b3a 2d31 5d0a 2020 2020 2020 2020  up[:-1].        
+00000a90: 6164 645f 6f70 203d 205f 544f 5243 485f  add_op = _TORCH_
+00000aa0: 4f50 535f 5245 4749 5354 5259 2e67 6574  OPS_REGISTRY.get
+00000ab0: 286f 705f 6c6f 6f6b 7570 2c20 4e6f 6e65  (op_lookup, None
+00000ac0: 290a 0a20 2020 2020 2020 206c 6f67 6765  )..        logge
+00000ad0: 722e 696e 666f 2822 436f 6e76 6572 7469  r.info("Converti
+00000ae0: 6e67 206f 7020 7b7d 203a 207b 7d22 2e66  ng op {} : {}".f
+00000af0: 6f72 6d61 7428 6e6f 6465 2e6e 616d 652c  ormat(node.name,
+00000b00: 206e 6f64 652e 6b69 6e64 2929 0a20 2020   node.kind)).   
+00000b10: 2020 2020 2069 6620 6164 645f 6f70 2069       if add_op i
+00000b20: 7320 4e6f 6e65 3a0a 2020 2020 2020 2020  s None:.        
+00000b30: 2020 2020 6966 2072 652e 6d61 7463 6828      if re.match(
+00000b40: 7222 2e2a 5f64 796e 616d 6963 222c 206e  r".*_dynamic", n
+00000b50: 6f64 652e 6b69 6e64 293a 0a20 2020 2020  ode.kind):.     
+00000b60: 2020 2020 2020 2020 2020 2072 6169 7365             raise
+00000b70: 2052 756e 7469 6d65 4572 726f 7228 0a20   RuntimeError(. 
+00000b80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00000b90: 2020 2066 2250 7954 6f72 6368 2063 6f6e     f"PyTorch con
+00000ba0: 7665 7274 2066 756e 6374 696f 6e20 666f  vert function fo
+00000bb0: 7220 6f70 2027 7b6e 6f64 652e 6b69 6e64  r op '{node.kind
+00000bc0: 7d27 206e 6f74 2069 6d70 6c65 6d65 6e74  }' not implement
+00000bd0: 6564 2e5c 6e22 0a20 2020 2020 2020 2020  ed.\n".         
+00000be0: 2020 2020 2020 2020 2020 2022 4479 6e61             "Dyna
+00000bf0: 6d69 6320 7175 616e 7469 7a65 6420 6d6f  mic quantized mo
+00000c00: 6465 6c73 2061 7265 206e 6f74 2073 7570  dels are not sup
+00000c10: 706f 7274 6564 2062 7920 436f 7265 204d  ported by Core M
+00000c20: 4c2e 5c6e 220a 2020 2020 2020 2020 2020  L.\n".          
+00000c30: 2020 2020 2020 2020 2020 2250 6c65 6173            "Pleas
+00000c40: 6520 7573 6520 7374 6174 6963 2071 7561  e use static qua
+00000c50: 6e74 697a 6174 696f 6e20 6f72 2074 6865  ntization or the
+00000c60: 2041 5049 7320 696e 2063 6f72 656d 6c74   APIs in coremlt
+00000c70: 6f6f 6c73 2e6f 7074 696d 697a 6520 746f  ools.optimize to
+00000c80: 2071 7561 6e74 697a 652f 636f 6d70 7265   quantize/compre
+00000c90: 7373 206d 6f64 656c 732e 220a 2020 2020  ss models.".    
+00000ca0: 2020 2020 2020 2020 2020 2020 290a 2020              ).  
+00000cb0: 2020 2020 2020 2020 2020 656c 7365 3a0a            else:.
+00000cc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00000cd0: 7261 6973 6520 5275 6e74 696d 6545 7272  raise RuntimeErr
+00000ce0: 6f72 280a 2020 2020 2020 2020 2020 2020  or(.            
+00000cf0: 2020 2020 2020 2020 6622 5079 546f 7263          f"PyTorc
+00000d00: 6820 636f 6e76 6572 7420 6675 6e63 7469  h convert functi
+00000d10: 6f6e 2066 6f72 206f 7020 277b 6e6f 6465  on for op '{node
+00000d20: 2e6b 696e 647d 2720 6e6f 7420 696d 706c  .kind}' not impl
+00000d30: 656d 656e 7465 642e 220a 2020 2020 2020  emented.".      
+00000d40: 2020 2020 2020 2020 2020 290a 0a20 2020            )..   
+00000d50: 2020 2020 2063 6f6e 7465 7874 2e70 7265       context.pre
+00000d60: 7061 7265 5f66 6f72 5f63 6f6e 7665 7273  pare_for_convers
+00000d70: 696f 6e28 6e6f 6465 290a 2020 2020 2020  ion(node).      
+00000d80: 2020 6164 645f 6f70 2863 6f6e 7465 7874    add_op(context
+00000d90: 2c20 6e6f 6465 290a 0a20 2020 2020 2020  , node)..       
+00000da0: 2023 2057 6527 7665 2067 656e 6572 6174   # We've generat
+00000db0: 6564 2061 6c6c 2074 6865 206f 7574 7075  ed all the outpu
+00000dc0: 7473 2074 6865 2067 7261 7068 206e 6565  ts the graph nee
+00000dd0: 6473 2c20 7465 726d 696e 6174 6520 636f  ds, terminate co
+00000de0: 6e76 6572 7369 6f6e 2e0a 2020 2020 2020  nversion..      
+00000df0: 2020 6966 205f 616c 6c5f 6f75 7470 7574    if _all_output
+00000e00: 735f 7072 6573 656e 7428 636f 6e74 6578  s_present(contex
+00000e10: 742c 2067 7261 7068 293a 0a20 2020 2020  t, graph):.     
+00000e20: 2020 2020 2020 2062 7265 616b 0a0a 0a64         break...d
+00000e30: 6566 2063 6f6e 7665 7274 5f62 6c6f 636b  ef convert_block
+00000e40: 2863 6f6e 7465 7874 2c20 626c 6f63 6b2c  (context, block,
+00000e50: 2069 6e70 7574 7329 3a0a 2020 2020 2222   inputs):.    ""
+00000e60: 2243 6f6e 7665 7274 2061 2062 6c6f 636b  "Convert a block
+00000e70: 2028 7375 622d 6772 6170 6829 2074 6f20   (sub-graph) to 
+00000e80: 4d49 4c2e 2043 6f6e 7665 7273 696f 6e20  MIL. Conversion 
+00000e90: 6861 7070 656e 7320 7769 7468 696e 2061  happens within a
+00000ea0: 206e 6577 0a20 2020 2020 2020 2063 6f6e   new.        con
+00000eb0: 7465 7874 2066 7261 6d65 2e0a 0a20 2020  text frame...   
+00000ec0: 2020 2020 2041 7267 756d 656e 7473 3a0a       Arguments:.
+00000ed0: 2020 2020 2020 2020 2020 2020 636f 6e74              cont
+00000ee0: 6578 743a 2041 2054 7261 6e73 6372 6970  ext: A Transcrip
+00000ef0: 7469 6f6e 436f 6e74 6578 7420 6f62 6a65  tionContext obje
+00000f00: 6374 2074 6f20 7075 6c6c 206e 6f64 6520  ct to pull node 
+00000f10: 696e 7075 7473 2061 6e64 0a20 2020 2020  inputs and.     
+00000f20: 2020 2020 2020 2020 2020 2061 7373 6967             assig
+00000f30: 6e20 6e6f 6465 206f 7574 7075 7473 2e0a  n node outputs..
+00000f40: 2020 2020 2020 2020 2020 2020 626c 6f63              bloc
+00000f50: 6b3a 2041 6e20 496e 7465 726e 616c 546f  k: An InternalTo
+00000f60: 7263 6849 5242 6c6f 636b 206f 626a 6563  rchIRBlock objec
+00000f70: 742e 0a20 2020 2020 2020 2020 2020 2069  t..            i
+00000f80: 6e70 7574 733a 204c 6973 7420 6f66 2056  nputs: List of V
+00000f90: 6172 7320 6672 6f6d 2074 6865 206f 7574  ars from the out
+00000fa0: 6572 2063 6f6e 7465 7874 2074 6861 7420  er context that 
+00000fb0: 6d61 7020 746f 2074 6865 2062 6c6f 636b  map to the block
+00000fc0: 2773 0a20 2020 2020 2020 2020 2020 2020  's.             
+00000fd0: 2020 2065 7870 6563 7465 6420 696e 7075     expected inpu
+00000fe0: 7473 2e20 5468 6520 6e75 6d62 6572 206f  ts. The number o
+00000ff0: 6620 696e 7075 7473 2070 726f 7669 6465  f inputs provide
+00001000: 6420 6d75 7374 206d 6174 6368 2074 6865  d must match the
+00001010: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00001020: 206e 756d 6265 7220 6578 7065 6374 6564   number expected
+00001030: 2062 7920 7468 6520 626c 6f63 6b2e 0a20   by the block.. 
+00001040: 2020 2022 2222 0a0a 2020 2020 6173 7365     """..    asse
+00001050: 7274 206c 656e 2862 6c6f 636b 2e69 6e70  rt len(block.inp
+00001060: 7574 7329 203d 3d20 6c65 6e28 696e 7075  uts) == len(inpu
+00001070: 7473 290a 0a20 2020 2023 2053 7461 7274  ts)..    # Start
+00001080: 2061 206e 6577 2063 6f6e 7465 7874 2066   a new context f
+00001090: 7261 6d65 2e0a 2020 2020 636f 6e74 6578  rame..    contex
+000010a0: 742e 7075 7368 2828 626c 6f63 6b2e 696e  t.push((block.in
+000010b0: 7075 7473 2c20 696e 7075 7473 2929 0a0a  puts, inputs))..
+000010c0: 2020 2020 2320 4164 6420 7468 6520 626c      # Add the bl
+000010d0: 6f63 6b20 6f70 732e 0a20 2020 2063 6f6e  ock ops..    con
+000010e0: 7665 7274 5f6e 6f64 6573 2863 6f6e 7465  vert_nodes(conte
+000010f0: 7874 2c20 626c 6f63 6b29 0a0a 2020 2020  xt, block)..    
+00001100: 2320 436f 6c6c 6563 7420 7468 6520 626c  # Collect the bl
+00001110: 6f63 6b20 6f75 7470 7574 732e 0a20 2020  ock outputs..   
+00001120: 206f 7574 7075 7473 203d 205b 636f 6e74   outputs = [cont
+00001130: 6578 745b 6f75 7470 5d20 666f 7220 6f75  ext[outp] for ou
+00001140: 7470 2069 6e20 626c 6f63 6b2e 6f75 7470  tp in block.outp
+00001150: 7574 735d 0a0a 2020 2020 2320 5265 7475  uts]..    # Retu
+00001160: 726e 2074 6f20 7468 6520 7072 6576 696f  rn to the previo
+00001170: 7573 2063 6f6e 7465 7874 2066 7261 6d65  us context frame
+00001180: 2e0a 2020 2020 636f 6e74 6578 742e 706f  ..    context.po
+00001190: 7028 290a 2020 2020 7265 7475 726e 206f  p().    return o
+000011a0: 7574 7075 7473 0a0a 0a23 2053 6f6d 6520  utputs...# Some 
+000011b0: 6f70 7320 7769 6c6c 2072 6563 6569 7665  ops will receive
+000011c0: 2061 2064 7479 7065 2069 6e70 7574 2061   a dtype input a
+000011d0: 7320 616e 2069 6e74 6567 6572 0a23 2077  s an integer.# w
+000011e0: 6869 6368 206d 6170 7320 746f 2061 2074  hich maps to a t
+000011f0: 6f72 6368 2064 7479 7065 2e20 5468 6520  orch dtype. The 
+00001200: 6265 6c6f 7720 6d61 7070 696e 6720 7761  below mapping wa
+00001210: 7320 666f 756e 6420 6279 0a23 2063 6f6e  s found by.# con
+00001220: 7665 7274 696e 6720 7465 7374 206d 6f64  verting test mod
+00001230: 656c 7320 7769 7468 2064 6966 6665 7265  els with differe
+00001240: 6e74 2064 7479 7065 7320 7061 7373 6564  nt dtypes passed
+00001250: 2074 6f20 6f6e 6573 2e0a 4e55 4d5f 544f   to ones..NUM_TO
+00001260: 5f54 4f52 4348 5f44 5459 5045 203d 207b  _TORCH_DTYPE = {
+00001270: 0a20 2020 2030 3a20 746f 7263 682e 7569  .    0: torch.ui
+00001280: 6e74 382c 0a20 2020 2031 3a20 746f 7263  nt8,.    1: torc
+00001290: 682e 696e 7438 2c0a 2020 2020 323a 2074  h.int8,.    2: t
+000012a0: 6f72 6368 2e69 6e74 3136 2c0a 2020 2020  orch.int16,.    
+000012b0: 333a 2074 6f72 6368 2e69 6e74 3332 2c0a  3: torch.int32,.
+000012c0: 2020 2020 343a 2074 6f72 6368 2e69 6e74      4: torch.int
+000012d0: 3332 2c0a 2020 2020 353a 2074 6f72 6368  32,.    5: torch
+000012e0: 2e66 6c6f 6174 3136 2c0a 2020 2020 363a  .float16,.    6:
+000012f0: 2074 6f72 6368 2e66 6c6f 6174 3332 2c0a   torch.float32,.
+00001300: 2020 2020 373a 2074 6f72 6368 2e66 6c6f      7: torch.flo
+00001310: 6174 3332 2c0a 2020 2020 3131 3a20 746f  at32,.    11: to
+00001320: 7263 682e 626f 6f6c 2c0a 2020 2020 3132  rch.bool,.    12
+00001330: 3a20 746f 7263 682e 7169 6e74 382c 0a20  : torch.qint8,. 
+00001340: 2020 2031 333a 2074 6f72 6368 2e71 7569     13: torch.qui
+00001350: 6e74 382c 0a20 2020 2031 343a 2074 6f72  nt8,.    14: tor
+00001360: 6368 2e71 696e 7433 322c 0a7d 0a0a 4e55  ch.qint32,.}..NU
+00001370: 4d50 595f 4454 5950 455f 544f 5f54 4f52  MPY_DTYPE_TO_TOR
+00001380: 4348 5f4e 554d 203d 207b 0a20 2020 205f  CH_NUM = {.    _
+00001390: 6e70 2e75 696e 7438 3a20 302c 0a20 2020  np.uint8: 0,.   
+000013a0: 205f 6e70 2e69 6e74 383a 2031 2c0a 2020   _np.int8: 1,.  
+000013b0: 2020 5f6e 702e 696e 7431 363a 2032 2c0a    _np.int16: 2,.
+000013c0: 2020 2020 5f6e 702e 696e 7433 323a 2033      _np.int32: 3
+000013d0: 2c0a 2020 2020 5f6e 702e 696e 7436 343a  ,.    _np.int64:
+000013e0: 2034 2c0a 2020 2020 5f6e 702e 666c 6f61   4,.    _np.floa
+000013f0: 7431 363a 2035 2c0a 2020 2020 5f6e 702e  t16: 5,.    _np.
+00001400: 666c 6f61 7433 323a 2036 2c0a 2020 2020  float32: 6,.    
+00001410: 5f6e 702e 666c 6f61 7436 343a 2037 2c0a  _np.float64: 7,.
+00001420: 2020 2020 626f 6f6c 3a20 3131 2c0a 7d0a      bool: 11,.}.
+00001430: 0a4e 554d 5f54 4f5f 4e55 4d50 595f 4454  .NUM_TO_NUMPY_DT
+00001440: 5950 4520 3d20 7b0a 2020 2020 303a 205f  YPE = {.    0: _
+00001450: 6e70 2e75 696e 7438 2c0a 2020 2020 313a  np.uint8,.    1:
+00001460: 205f 6e70 2e69 6e74 382c 0a20 2020 2032   _np.int8,.    2
+00001470: 3a20 5f6e 702e 696e 7431 362c 0a20 2020  : _np.int16,.   
+00001480: 2033 3a20 5f6e 702e 696e 7433 322c 0a20   3: _np.int32,. 
+00001490: 2020 2034 3a20 5f6e 702e 696e 7433 322c     4: _np.int32,
+000014a0: 0a20 2020 2035 3a20 5f6e 702e 666c 6f61  .    5: _np.floa
+000014b0: 7431 362c 0a20 2020 2036 3a20 5f6e 702e  t16,.    6: _np.
+000014c0: 666c 6f61 7433 322c 0a20 2020 2037 3a20  float32,.    7: 
+000014d0: 5f6e 702e 666c 6f61 7433 322c 0a20 2020  _np.float32,.   
+000014e0: 2031 313a 2062 6f6f 6c2c 0a7d 0a0a 4e55   11: bool,.}..NU
+000014f0: 4d5f 544f 5f44 5459 5045 5f53 5452 494e  M_TO_DTYPE_STRIN
+00001500: 4720 3d20 7b0a 2020 2020 323a 2022 696e  G = {.    2: "in
+00001510: 7431 3622 2c0a 2020 2020 333a 2022 696e  t16",.    3: "in
+00001520: 7433 3222 2c0a 2020 2020 343a 2022 696e  t32",.    4: "in
+00001530: 7433 3222 2c0a 2020 2020 353a 2022 6670  t32",.    5: "fp
+00001540: 3136 222c 0a20 2020 2036 3a20 2266 7033  16",.    6: "fp3
+00001550: 3222 2c0a 2020 2020 373a 2022 6670 3332  2",.    7: "fp32
+00001560: 222c 0a20 2020 2031 313a 2022 626f 6f6c  ",.    11: "bool
+00001570: 222c 0a7d 0a0a 5459 5045 5f54 4f5f 4454  ",.}..TYPE_TO_DT
+00001580: 5950 455f 5354 5249 4e47 203d 207b 0a20  YPE_STRING = {. 
+00001590: 2020 2074 7970 6573 2e62 6f6f 6c3a 2022     types.bool: "
+000015a0: 626f 6f6c 222c 0a20 2020 2074 7970 6573  bool",.    types
+000015b0: 2e66 7031 363a 2022 6670 3136 222c 0a20  .fp16: "fp16",. 
+000015c0: 2020 2074 7970 6573 2e66 7033 323a 2022     types.fp32: "
+000015d0: 6670 3332 222c 0a20 2020 2074 7970 6573  fp32",.    types
+000015e0: 2e69 6e74 3332 3a20 2269 6e74 3332 222c  .int32: "int32",
+000015f0: 0a7d 0a0a 0a64 6566 205f 6765 745f 696e  .}...def _get_in
+00001600: 7075 7473 2863 6f6e 7465 7874 2c20 6e6f  puts(context, no
+00001610: 6465 2c20 6578 7065 6374 6564 3d4e 6f6e  de, expected=Non
+00001620: 652c 206d 696e 5f65 7870 6563 7465 643d  e, min_expected=
+00001630: 4e6f 6e65 2920 2d3e 204c 6973 745b 5661  None) -> List[Va
+00001640: 725d 3a0a 2020 2020 2222 220a 2020 2020  r]:.    """.    
+00001650: 4c6f 6f6b 2075 7020 6120 6e6f 6465 2773  Look up a node's
+00001660: 2069 6e70 7574 7320 696e 2040 636f 6e74   inputs in @cont
+00001670: 6578 7420 616e 6420 7265 7475 726e 2074  ext and return t
+00001680: 6865 6d20 6173 2061 206c 6973 742e 2049  hem as a list. I
+00001690: 660a 2020 2020 4065 7870 6563 7465 6420  f.    @expected 
+000016a0: 6973 206e 6f74 204e 6f6e 652c 2061 6c73  is not None, als
+000016b0: 6f20 7665 7269 6669 6573 2074 6865 206e  o verifies the n
+000016c0: 756d 6265 7220 6f66 2069 6e70 7574 7320  umber of inputs 
+000016d0: 6d61 7463 6865 7320 7468 650a 2020 2020  matches the.    
+000016e0: 7661 6c75 6520 6f66 2040 6578 7065 6374  value of @expect
+000016f0: 6564 2e0a 2020 2020 2222 220a 2020 2020  ed..    """.    
+00001700: 696e 7075 7473 203d 205b 636f 6e74 6578  inputs = [contex
+00001710: 745b 6e61 6d65 5d20 666f 7220 6e61 6d65  t[name] for name
+00001720: 2069 6e20 6e6f 6465 2e69 6e70 7574 735d   in node.inputs]
+00001730: 0a20 2020 2069 6620 6578 7065 6374 6564  .    if expected
+00001740: 2069 7320 6e6f 7420 4e6f 6e65 3a0a 2020   is not None:.  
+00001750: 2020 2020 2020 6578 7065 6374 6564 203d        expected =
+00001760: 205b 6578 7065 6374 6564 5d20 6966 206e   [expected] if n
+00001770: 6f74 2069 7369 6e73 7461 6e63 6528 6578  ot isinstance(ex
+00001780: 7065 6374 6564 2c20 286c 6973 742c 2074  pected, (list, t
+00001790: 7570 6c65 2929 2065 6c73 6520 6578 7065  uple)) else expe
+000017a0: 6374 6564 0a0a 2020 2020 2020 2020 6966  cted..        if
+000017b0: 206c 656e 2869 6e70 7574 7329 206e 6f74   len(inputs) not
+000017c0: 2069 6e20 6578 7065 6374 6564 3a0a 2020   in expected:.  
+000017d0: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
+000017e0: 5661 6c75 6545 7272 6f72 280a 2020 2020  ValueError(.    
+000017f0: 2020 2020 2020 2020 2020 2020 226e 6f64              "nod
+00001800: 6520 7b7d 2028 7b7d 2920 676f 7420 7b7d  e {} ({}) got {}
+00001810: 2069 6e70 7574 2873 292c 2065 7870 6563   input(s), expec
+00001820: 7465 6420 7b7d 222e 666f 726d 6174 280a  ted {}".format(.
+00001830: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001840: 2020 2020 6e6f 6465 2e6e 616d 652c 206e      node.name, n
+00001850: 6f64 652e 6b69 6e64 2c20 6c65 6e28 696e  ode.kind, len(in
+00001860: 7075 7473 292c 2065 7870 6563 7465 640a  puts), expected.
+00001870: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001880: 290a 2020 2020 2020 2020 2020 2020 290a  ).            ).
+00001890: 2020 2020 6966 206d 696e 5f65 7870 6563      if min_expec
+000018a0: 7465 6420 6973 206e 6f74 204e 6f6e 653a  ted is not None:
+000018b0: 0a20 2020 2020 2020 2069 6620 6c65 6e28  .        if len(
+000018c0: 696e 7075 7473 2920 3c20 6d69 6e5f 6578  inputs) < min_ex
+000018d0: 7065 6374 6564 3a0a 2020 2020 2020 2020  pected:.        
+000018e0: 2020 2020 7261 6973 6520 5661 6c75 6545      raise ValueE
+000018f0: 7272 6f72 280a 2020 2020 2020 2020 2020  rror(.          
+00001900: 2020 2020 2020 226e 6f64 6520 7b7d 2028        "node {} (
+00001910: 7b7d 2920 676f 7420 7b7d 2069 6e70 7574  {}) got {} input
+00001920: 2873 292c 2065 7870 6563 7465 6420 6d69  (s), expected mi
+00001930: 6e69 6d75 6d20 7b7d 2069 6e70 7574 7322  nimum {} inputs"
+00001940: 2e66 6f72 6d61 7428 0a20 2020 2020 2020  .format(.       
+00001950: 2020 2020 2020 2020 2020 2020 206e 6f64               nod
+00001960: 652e 6e61 6d65 2c20 6e6f 6465 2e6b 696e  e.name, node.kin
+00001970: 642c 206c 656e 2869 6e70 7574 7329 2c20  d, len(inputs), 
+00001980: 6d69 6e5f 6578 7065 6374 6564 0a20 2020  min_expected.   
+00001990: 2020 2020 2020 2020 2020 2020 2029 0a20               ). 
+000019a0: 2020 2020 2020 2020 2020 2029 0a0a 2020             )..  
+000019b0: 2020 7265 7475 726e 2069 6e70 7574 730a    return inputs.
+000019c0: 0a0a 6465 6620 5f6c 6973 745f 7365 6c65  ..def _list_sele
+000019d0: 6374 2873 6861 7065 5f76 6172 2c20 696e  ct(shape_var, in
+000019e0: 6465 7829 3a0a 2020 2020 2222 220a 2020  dex):.    """.  
+000019f0: 2020 536f 6d65 7469 6d65 7320 7765 206e    Sometimes we n
+00001a00: 6565 6420 746f 2073 656c 6563 7420 6120  eed to select a 
+00001a10: 7370 6563 6966 6963 2069 7465 6d20 6672  specific item fr
+00001a20: 6f6d 2061 206c 6973 742e 2049 6620 7468  om a list. If th
+00001a30: 6174 2069 7465 6d0a 2020 2020 6973 206b  at item.    is k
+00001a40: 6e6f 776e 2061 7420 636f 6d70 696c 6520  nown at compile 
+00001a50: 7469 6d65 2c20 6578 7472 6163 7420 6974  time, extract it
+00001a60: 2061 7320 6120 636f 6e73 742e 204f 7468   as a const. Oth
+00001a70: 6572 7769 7365 2c20 6966 2069 7427 730a  erwise, if it's.
+00001a80: 2020 2020 7379 6d62 6f6c 6963 2c20 7573      symbolic, us
+00001a90: 6520 6761 7468 6572 2e0a 2020 2020 2222  e gather..    ""
+00001aa0: 220a 2020 2020 6966 2073 6861 7065 5f76  ".    if shape_v
+00001ab0: 6172 2e63 616e 5f62 655f 666f 6c64 6564  ar.can_be_folded
+00001ac0: 5f74 6f5f 636f 6e73 7428 293a 0a20 2020  _to_const():.   
+00001ad0: 2020 2020 2072 6573 203d 206d 622e 636f       res = mb.co
+00001ae0: 6e73 7428 7661 6c3d 7368 6170 655f 7661  nst(val=shape_va
+00001af0: 722e 7661 6c5b 696e 6465 785d 290a 2020  r.val[index]).  
+00001b00: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
+00001b10: 6966 2069 735f 6375 7272 656e 745f 6f70  if is_current_op
+00001b20: 7365 745f 7665 7273 696f 6e5f 636f 6d70  set_version_comp
+00001b30: 6174 6962 6c65 5f77 6974 6828 7461 7267  atible_with(targ
+00001b40: 6574 2e69 4f53 3137 293a 0a20 2020 2020  et.iOS17):.     
+00001b50: 2020 2020 2020 2023 2049 4f53 3137 2060         # IOS17 `
+00001b60: 6761 7468 6572 6020 7265 7175 6972 6573  gather` requires
+00001b70: 206e 6f6e 2d6e 6567 6174 6976 6520 696e   non-negative in
+00001b80: 6469 6365 732e 0a20 2020 2020 2020 2020  dices..         
+00001b90: 2020 2069 6e64 6578 203d 206d 622e 7365     index = mb.se
+00001ba0: 6c65 6374 280a 2020 2020 2020 2020 2020  lect(.          
+00001bb0: 2020 2020 2020 636f 6e64 3d6d 622e 6772        cond=mb.gr
+00001bc0: 6561 7465 725f 6571 7561 6c28 783d 696e  eater_equal(x=in
+00001bd0: 6465 782c 2079 3d30 292c 0a20 2020 2020  dex, y=0),.     
+00001be0: 2020 2020 2020 2020 2020 2061 3d69 6e64             a=ind
+00001bf0: 6578 2c0a 2020 2020 2020 2020 2020 2020  ex,.            
+00001c00: 2020 2020 623d 6d62 2e61 6464 2878 3d69      b=mb.add(x=i
+00001c10: 6e64 6578 2c20 793d 7661 6c75 655f 6174  ndex, y=value_at
+00001c20: 286d 622e 7368 6170 6528 783d 7368 6170  (mb.shape(x=shap
+00001c30: 655f 7661 7229 2c20 3029 292c 0a20 2020  e_var), 0)),.   
+00001c40: 2020 2020 2020 2020 2029 0a20 2020 2020           ).     
+00001c50: 2020 2072 6573 203d 206d 622e 6761 7468     res = mb.gath
+00001c60: 6572 2878 3d73 6861 7065 5f76 6172 2c20  er(x=shape_var, 
+00001c70: 696e 6469 6365 733d 696e 6465 7829 0a20  indices=index). 
+00001c80: 2020 2072 6574 7572 6e20 7265 730a 0a0a     return res...
+00001c90: 6465 6620 5f63 6f6e 7374 7275 6374 5f63  def _construct_c
+00001ca0: 6f6e 7374 616e 7428 7661 6c2c 206e 616d  onstant(val, nam
+00001cb0: 6529 3a0a 2020 2020 2320 436f 6e76 6572  e):.    # Conver
+00001cc0: 7465 7220 6361 6e6e 6f74 2068 616e 646c  ter cannot handl
+00001cd0: 6520 746f 7263 6820 7465 6e73 6f72 732e  e torch tensors.
+00001ce0: 0a20 2020 2069 6620 6973 696e 7374 616e  .    if isinstan
+00001cf0: 6365 2876 616c 2c20 746f 7263 682e 5465  ce(val, torch.Te
+00001d00: 6e73 6f72 293a 0a20 2020 2020 2020 2076  nsor):.        v
+00001d10: 616c 203d 2076 616c 2e63 7075 2829 2e6e  al = val.cpu().n
+00001d20: 756d 7079 2829 0a0a 2020 2020 2320 4d49  umpy()..    # MI
+00001d30: 4c20 6361 7374 7320 696e 7473 2074 6f20  L casts ints to 
+00001d40: 696e 7433 322c 2077 6869 6368 2063 616e  int32, which can
+00001d50: 2774 2072 6570 7265 7365 6e74 2050 7954  't represent PyT
+00001d60: 6f72 6368 2773 2064 6566 6175 6c74 2076  orch's default v
+00001d70: 616c 7565 2e0a 2020 2020 2320 536f 2077  alue..    # So w
+00001d80: 6520 696e 7374 6561 6420 7265 7072 6573  e instead repres
+00001d90: 656e 7420 6974 2077 6974 6820 4e6f 6e65  ent it with None
+00001da0: 2c20 616e 6420 616e 7920 6f70 7320 7468  , and any ops th
+00001db0: 6174 206d 6967 6874 2067 6574 2074 6865  at might get the
+00001dc0: 0a20 2020 2023 2076 616c 7565 2077 696c  .    # value wil
+00001dd0: 6c20 6368 6563 6b20 666f 7220 4e6f 6e65  l check for None
+00001de0: 2069 6e73 7465 6164 2e0a 2020 2020 6966   instead..    if
+00001df0: 2069 7369 6e73 7461 6e63 6528 7661 6c2c   isinstance(val,
+00001e00: 2069 6e74 2920 616e 6420 7661 6c20 3d3d   int) and val ==
+00001e10: 2050 5954 4f52 4348 5f44 4546 4155 4c54   PYTORCH_DEFAULT
+00001e20: 5f56 414c 5545 3a0a 2020 2020 2020 2020  _VALUE:.        
+00001e30: 7661 6c20 3d20 4e6f 6e65 0a0a 2020 2020  val = None..    
+00001e40: 2320 5079 746f 7263 6820 7573 6573 2069  # Pytorch uses i
+00001e50: 6e66 0a20 2020 2069 6620 7661 6c20 6973  nf.    if val is
+00001e60: 206e 6f74 204e 6f6e 6520 616e 6420 6973   not None and is
+00001e70: 696e 7374 616e 6365 2876 616c 2c20 6e75  instance(val, nu
+00001e80: 6d62 6572 732e 4e75 6d62 6572 2920 616e  mbers.Number) an
+00001e90: 6420 5f6e 702e 6973 696e 6628 7661 6c29  d _np.isinf(val)
+00001ea0: 3a0a 2020 2020 2020 2020 6966 2076 616c  :.        if val
+00001eb0: 203c 2030 3a20 2023 206e 6567 2069 6e66   < 0:  # neg inf
+00001ec0: 0a20 2020 2020 2020 2020 2020 2023 206d  .            # m
+00001ed0: 6f73 7420 6e65 6761 7469 7665 206e 756d  ost negative num
+00001ee0: 6265 7220 696e 2066 7033 320a 2020 2020  ber in fp32.    
+00001ef0: 2020 2020 2020 2020 7661 6c20 3d20 2d33          val = -3
+00001f00: 2e34 652b 3338 0a20 2020 2020 2020 2065  .4e+38.        e
+00001f10: 6c73 653a 2020 2320 706f 7369 7469 7665  lse:  # positive
+00001f20: 2069 6e66 0a20 2020 2020 2020 2020 2020   inf.           
+00001f30: 2076 616c 203d 2033 2e34 652b 3338 0a20   val = 3.4e+38. 
+00001f40: 2020 2069 6620 7661 6c20 6973 204e 6f6e     if val is Non
+00001f50: 653a 0a20 2020 2020 2020 2072 6574 7572  e:.        retur
+00001f60: 6e20 4e6f 6e65 0a20 2020 2065 6c73 653a  n None.    else:
+00001f70: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+00001f80: 6d62 2e63 6f6e 7374 2876 616c 3d76 616c  mb.const(val=val
+00001f90: 2c20 6e61 6d65 3d6e 616d 6529 0a0a 0a40  , name=name)...@
+00001fa0: 7265 6769 7374 6572 5f74 6f72 6368 5f6f  register_torch_o
+00001fb0: 700a 6465 6620 6166 6669 6e65 5f67 7269  p.def affine_gri
+00001fc0: 645f 6765 6e65 7261 746f 7228 636f 6e74  d_generator(cont
+00001fd0: 6578 742c 206e 6f64 6529 3a0a 2020 2020  ext, node):.    
+00001fe0: 2320 7264 6172 3a2f 2f37 3331 3635 3338  # rdar://7316538
+00001ff0: 3620 2849 6d70 726f 7665 2065 7272 6f72  6 (Improve error
+00002000: 2068 616e 646c 696e 6720 6f66 2063 6f72   handling of cor
+00002010: 656d 6c74 6f6f 6c73 2022 6166 6669 6e65  emltools "affine
+00002020: 2220 6f70 2050 7954 6f72 6368 2063 6f6e  " op PyTorch con
+00002030: 7665 7273 696f 6e2e 290a 0a20 2020 2061  version.)..    a
+00002040: 6666 696e 655f 6f70 5f6e 616d 6520 3d20  ffine_op_name = 
+00002050: 6e6f 6465 2e6e 616d 650a 2020 2020 7468  node.name.    th
+00002060: 6574 612c 2073 697a 652c 2061 6c69 676e  eta, size, align
+00002070: 5f63 6f72 6e65 7273 203d 205f 6765 745f  _corners = _get_
+00002080: 696e 7075 7473 2863 6f6e 7465 7874 2c20  inputs(context, 
+00002090: 6e6f 6465 2c20 6578 7065 6374 6564 3d33  node, expected=3
+000020a0: 290a 0a20 2020 2023 206e 6f74 653a 206f  )..    # note: o
+000020b0: 6e6c 7920 6164 6420 636f 6e73 7473 2068  nly add consts h
+000020c0: 6572 6520 6173 2050 7954 6f72 6368 2075  ere as PyTorch u
+000020d0: 7365 7320 6166 6669 6e65 5f67 7269 6420  ses affine_grid 
+000020e0: 2b20 6772 6964 5f73 616d 706c 6572 2074  + grid_sampler t
+000020f0: 6f67 6574 6865 720a 2020 2020 6973 5f74  ogether.    is_t
+00002100: 6865 7461 5f63 6f6e 7374 203d 2074 6865  heta_const = the
+00002110: 7461 2e76 616c 2069 7320 6e6f 7420 4e6f  ta.val is not No
+00002120: 6e65 0a20 2020 2069 6620 6973 5f74 6865  ne.    if is_the
+00002130: 7461 5f63 6f6e 7374 3a0a 2020 2020 2020  ta_const:.      
+00002140: 2020 636f 6e74 6578 742e 6164 6428 6d62    context.add(mb
+00002150: 2e63 6f6e 7374 2876 616c 3d74 6865 7461  .const(val=theta
+00002160: 2e76 616c 2c20 6e61 6d65 3d22 7b7d 5f74  .val, name="{}_t
+00002170: 6865 7461 222e 666f 726d 6174 2861 6666  heta".format(aff
+00002180: 696e 655f 6f70 5f6e 616d 6529 2929 0a20  ine_op_name))). 
+00002190: 2020 2065 6c73 653a 2020 2320 7468 6574     else:  # thet
+000021a0: 6120 6973 2064 796e 616d 6963 2069 6e70  a is dynamic inp
+000021b0: 7574 2c20 6b65 6570 2074 7261 636b 206f  ut, keep track o
+000021c0: 6620 6974 2773 206e 616d 650a 2020 2020  f it's name.    
+000021d0: 2020 2020 636f 6e74 6578 742e 6164 6428      context.add(
+000021e0: 6d62 2e63 6f6e 7374 2876 616c 3d74 6865  mb.const(val=the
+000021f0: 7461 2e6e 616d 652c 206e 616d 653d 227b  ta.name, name="{
+00002200: 7d5f 7468 6574 6122 2e66 6f72 6d61 7428  }_theta".format(
+00002210: 6166 6669 6e65 5f6f 705f 6e61 6d65 2929  affine_op_name))
+00002220: 290a 0a20 2020 2063 6f6e 7465 7874 2e61  )..    context.a
+00002230: 6464 286d 622e 636f 6e73 7428 7661 6c3d  dd(mb.const(val=
+00002240: 7369 7a65 2e76 616c 2c20 6e61 6d65 3d22  size.val, name="
+00002250: 7b7d 5f73 697a 6522 2e66 6f72 6d61 7428  {}_size".format(
+00002260: 6166 6669 6e65 5f6f 705f 6e61 6d65 2929  affine_op_name))
+00002270: 290a 2020 2020 636f 6e74 6578 742e 6164  ).    context.ad
+00002280: 6428 6d62 2e63 6f6e 7374 2876 616c 3d61  d(mb.const(val=a
+00002290: 6c69 676e 5f63 6f72 6e65 7273 2e76 616c  lign_corners.val
+000022a0: 2c20 6e61 6d65 3d22 7b7d 5f61 6c69 676e  , name="{}_align
+000022b0: 5f63 6f72 6e65 7273 222e 666f 726d 6174  _corners".format
+000022c0: 2861 6666 696e 655f 6f70 5f6e 616d 6529  (affine_op_name)
+000022d0: 2929 0a0a 0a40 7265 6769 7374 6572 5f74  ))...@register_t
+000022e0: 6f72 6368 5f6f 700a 6465 6620 6772 6964  orch_op.def grid
+000022f0: 5f73 616d 706c 6572 2863 6f6e 7465 7874  _sampler(context
+00002300: 2c20 6e6f 6465 293a 0a20 2020 2061 6666  , node):.    aff
+00002310: 696e 655f 6f70 5f6e 616d 6520 3d20 6e6f  ine_op_name = no
+00002320: 6465 2e69 6e70 7574 735b 315d 0a20 2020  de.inputs[1].   
+00002330: 2023 2068 7474 7073 3a2f 2f67 6974 6875   # https://githu
+00002340: 622e 636f 6d2f 7079 746f 7263 682f 7079  b.com/pytorch/py
+00002350: 746f 7263 682f 626c 6f62 2f30 3064 3433  torch/blob/00d43
+00002360: 3261 3165 6431 3739 6566 6635 3261 3964  2a1ed179eff52a9d
+00002370: 3836 6130 3633 3066 3632 3362 6632 3061  86a0630f623bf20a
+00002380: 3337 612f 6174 656e 2f73 7263 2f41 5465  37a/aten/src/ATe
+00002390: 6e2f 6e61 7469 7665 2f47 7269 6453 616d  n/native/GridSam
+000023a0: 706c 6572 2e68 234c 3130 2d4c 3131 0a20  pler.h#L10-L11. 
+000023b0: 2020 206d 5f6d 6f64 6520 3d20 7b30 3a20     m_mode = {0: 
+000023c0: 2262 696c 696e 6561 7222 2c20 313a 2022  "bilinear", 1: "
+000023d0: 6e65 6172 6573 7422 7d0a 2020 2020 6d5f  nearest"}.    m_
+000023e0: 7061 6464 696e 675f 6d6f 6465 203d 207b  padding_mode = {
+000023f0: 303a 2022 636f 6e73 7461 6e74 222c 2031  0: "constant", 1
+00002400: 3a20 2262 6f72 6465 7222 2c20 323a 2022  : "border", 2: "
+00002410: 7265 666c 6563 7469 6f6e 227d 0a0a 2020  reflection"}..  
+00002420: 2020 2320 6164 6420 6072 6573 616d 706c    # add `resampl
+00002430: 6560 2069 6620 6772 6964 2f63 6f6f 7264  e` if grid/coord
+00002440: 696e 6174 6573 2069 7320 696e 2069 6e70  inates is in inp
+00002450: 7574 2c20 6f74 6865 7277 6973 652c 0a20  ut, otherwise,. 
+00002460: 2020 2023 2061 6464 2060 6166 6669 6e65     # add `affine
+00002470: 6020 746f 2067 656e 6572 6174 6520 6772  ` to generate gr
+00002480: 6964 2066 726f 6d20 6061 6666 696e 655f  id from `affine_
+00002490: 6772 6964 5f67 656e 6572 6174 6f72 602e  grid_generator`.
+000024a0: 0a20 2020 2069 6620 6166 6669 6e65 5f6f  .    if affine_o
+000024b0: 705f 6e61 6d65 2069 6e20 636f 6e74 6578  p_name in contex
+000024c0: 743a 2020 2320 6164 6420 6072 6573 616d  t:  # add `resam
+000024d0: 706c 6560 206f 700a 2020 2020 2020 2020  ple` op.        
+000024e0: 696e 7075 7473 203d 205f 6765 745f 696e  inputs = _get_in
+000024f0: 7075 7473 2863 6f6e 7465 7874 2c20 6e6f  puts(context, no
+00002500: 6465 2c20 6578 7065 6374 6564 3d35 290a  de, expected=5).
+00002510: 2020 2020 2020 2020 7361 6d70 6c69 6e67          sampling
+00002520: 5f6d 6f64 6520 3d20 6d5f 6d6f 6465 5b69  _mode = m_mode[i
+00002530: 6e70 7574 735b 325d 2e76 616c 5d0a 2020  nputs[2].val].  
+00002540: 2020 2020 2020 7061 6464 696e 675f 6d6f        padding_mo
+00002550: 6465 203d 206d 5f70 6164 6469 6e67 5f6d  de = m_padding_m
+00002560: 6f64 655b 696e 7075 7473 5b33 5d2e 7661  ode[inputs[3].va
+00002570: 6c5d 0a20 2020 2020 2020 2061 6c69 676e  l].        align
+00002580: 5f63 6f72 6e65 7273 203d 2069 6e70 7574  _corners = input
+00002590: 735b 345d 2e76 616c 0a0a 2020 2020 2020  s[4].val..      
+000025a0: 2020 2320 5768 656e 2061 6c69 676e 5f63    # When align_c
+000025b0: 6f72 6e65 7273 3d46 616c 7365 2c20 7061  orners=False, pa
+000025c0: 6464 696e 675f 6d6f 6465 2069 7320 636f  dding_mode is co
+000025d0: 7272 6573 706f 6e64 696e 6720 746f 2043  rresponding to C
+000025e0: 6f72 6520 4d4c 2773 2073 796d 6d65 7472  ore ML's symmetr
+000025f0: 6963 0a20 2020 2020 2020 2069 6620 7061  ic.        if pa
+00002600: 6464 696e 675f 6d6f 6465 203d 3d20 2272  dding_mode == "r
+00002610: 6566 6c65 6374 696f 6e22 2061 6e64 2061  eflection" and a
+00002620: 6c69 676e 5f63 6f72 6e65 7273 2069 7320  lign_corners is 
+00002630: 4661 6c73 653a 0a20 2020 2020 2020 2020  False:.         
+00002640: 2020 2070 6164 6469 6e67 5f6d 6f64 6520     padding_mode 
+00002650: 3d20 2273 796d 6d65 7472 6963 220a 0a20  = "symmetric".. 
+00002660: 2020 2020 2020 2078 203d 206d 622e 7265         x = mb.re
+00002670: 7361 6d70 6c65 280a 2020 2020 2020 2020  sample(.        
+00002680: 2020 2020 783d 696e 7075 7473 5b30 5d2c      x=inputs[0],
+00002690: 0a20 2020 2020 2020 2020 2020 2063 6f6f  .            coo
+000026a0: 7264 696e 6174 6573 3d69 6e70 7574 735b  rdinates=inputs[
+000026b0: 315d 2c0a 2020 2020 2020 2020 2020 2020  1],.            
+000026c0: 7361 6d70 6c69 6e67 5f6d 6f64 653d 7361  sampling_mode=sa
+000026d0: 6d70 6c69 6e67 5f6d 6f64 652c 0a20 2020  mpling_mode,.   
+000026e0: 2020 2020 2020 2020 2070 6164 6469 6e67           padding
+000026f0: 5f6d 6f64 653d 7061 6464 696e 675f 6d6f  _mode=padding_mo
+00002700: 6465 2c0a 2020 2020 2020 2020 2020 2020  de,.            
+00002710: 7061 6464 696e 675f 7661 6c75 653d 302e  padding_value=0.
+00002720: 302c 0a20 2020 2020 2020 2020 2020 2063  0,.            c
+00002730: 6f6f 7264 696e 6174 6573 5f6d 6f64 653d  oordinates_mode=
+00002740: 226e 6f72 6d61 6c69 7a65 645f 6d69 6e75  "normalized_minu
+00002750: 735f 6f6e 655f 746f 5f6f 6e65 222c 0a20  s_one_to_one",. 
+00002760: 2020 2020 2020 2020 2020 2061 6c69 676e             align
+00002770: 5f63 6f72 6e65 7273 3d61 6c69 676e 5f63  _corners=align_c
+00002780: 6f72 6e65 7273 2c0a 2020 2020 2020 2020  orners,.        
+00002790: 2020 2020 6e61 6d65 3d6e 6f64 652e 6e61      name=node.na
+000027a0: 6d65 2c0a 2020 2020 2020 2020 290a 2020  me,.        ).  
+000027b0: 2020 2020 2020 636f 6e74 6578 742e 6164        context.ad
+000027c0: 6428 7829 0a20 2020 2065 6c73 653a 2020  d(x).    else:  
+000027d0: 2320 6164 6420 6061 6666 696e 6560 206f  # add `affine` o
+000027e0: 7020 696e 7374 6561 640a 2020 2020 2020  p instead.      
+000027f0: 2020 7820 3d20 636f 6e74 6578 745b 6e6f    x = context[no
+00002800: 6465 2e69 6e70 7574 735b 305d 5d0a 2020  de.inputs[0]].  
+00002810: 2020 2020 2020 2320 696e 7075 7473 2066        # inputs f
+00002820: 726f 6d20 6061 6666 696e 655f 6772 6964  rom `affine_grid
+00002830: 5f67 656e 6572 6174 6f72 600a 2020 2020  _generator`.    
+00002840: 2020 2020 6166 6669 6e65 5f74 6865 7461      affine_theta
+00002850: 203d 2063 6f6e 7465 7874 5b22 7b7d 5f74   = context["{}_t
+00002860: 6865 7461 222e 666f 726d 6174 2861 6666  heta".format(aff
+00002870: 696e 655f 6f70 5f6e 616d 6529 5d0a 2020  ine_op_name)].  
+00002880: 2020 2020 2020 6166 6669 6e65 5f73 697a        affine_siz
+00002890: 6520 3d20 636f 6e74 6578 745b 227b 7d5f  e = context["{}_
+000028a0: 7369 7a65 222e 666f 726d 6174 2861 6666  size".format(aff
+000028b0: 696e 655f 6f70 5f6e 616d 6529 5d0a 2020  ine_op_name)].  
+000028c0: 2020 2020 2020 6166 6669 6e65 5f61 6c69        affine_ali
+000028d0: 676e 5f63 6f72 6e65 7273 203d 2063 6f6e  gn_corners = con
+000028e0: 7465 7874 5b22 7b7d 5f61 6c69 676e 5f63  text["{}_align_c
+000028f0: 6f72 6e65 7273 222e 666f 726d 6174 2861  orners".format(a
+00002900: 6666 696e 655f 6f70 5f6e 616d 6529 5d0a  ffine_op_name)].
+00002910: 0a20 2020 2020 2020 2023 2061 6666 696e  .        # affin
+00002920: 655f 7468 6574 612e 7661 6c20 6973 2065  e_theta.val is e
+00002930: 6974 6865 7220 6e61 6d65 2073 7472 696e  ither name strin
+00002940: 6720 2864 796e 616d 6963 2069 6e70 7574  g (dynamic input
+00002950: 2920 6f72 206e 702e 6e64 6172 7261 7920  ) or np.ndarray 
+00002960: 2873 7461 7469 6320 7661 6c75 6573 290a  (static values).
+00002970: 2020 2020 2020 2020 2320 7365 6520 6061          # see `a
+00002980: 6666 696e 655f 6772 6964 5f67 656e 6572  ffine_grid_gener
+00002990: 6174 6f72 6020 666f 7220 6465 7461 696c  ator` for detail
+000029a0: 732e 0a20 2020 2020 2020 2069 735f 7468  s..        is_th
+000029b0: 6574 615f 636f 6e73 7420 3d20 6e6f 7420  eta_const = not 
+000029c0: 6973 696e 7374 616e 6365 2861 6666 696e  isinstance(affin
+000029d0: 655f 7468 6574 612e 7661 6c2c 2073 7472  e_theta.val, str
+000029e0: 290a 2020 2020 2020 2020 6966 2069 735f  ).        if is_
+000029f0: 7468 6574 615f 636f 6e73 743a 0a20 2020  theta_const:.   
+00002a00: 2020 2020 2020 2020 2074 7261 6e73 666f           transfo
+00002a10: 726d 5f6d 6174 7269 7820 3d20 5f6e 702e  rm_matrix = _np.
+00002a20: 7265 7368 6170 6528 6166 6669 6e65 5f74  reshape(affine_t
+00002a30: 6865 7461 2e76 616c 2c20 2861 6666 696e  heta.val, (affin
+00002a40: 655f 7468 6574 612e 7368 6170 655b 305d  e_theta.shape[0]
+00002a50: 2c20 3629 290a 2020 2020 2020 2020 656c  , 6)).        el
+00002a60: 7365 3a20 2023 2074 6865 7461 2069 7320  se:  # theta is 
+00002a70: 6479 6e61 6d69 6320 696e 7075 742c 2061  dynamic input, a
+00002a80: 6464 2060 7265 7368 6170 6560 206f 7020  dd `reshape` op 
+00002a90: 746f 2050 794d 494c 0a20 2020 2020 2020  to PyMIL.       
+00002aa0: 2020 2020 2074 7261 6e73 666f 726d 5f6d       transform_m
+00002ab0: 6174 7269 7820 3d20 6d62 2e72 6573 6861  atrix = mb.resha
+00002ac0: 7065 280a 2020 2020 2020 2020 2020 2020  pe(.            
+00002ad0: 2020 2020 783d 636f 6e74 6578 745b 6166      x=context[af
+00002ae0: 6669 6e65 5f74 6865 7461 2e76 616c 5d2c  fine_theta.val],
+00002af0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00002b00: 2073 6861 7065 3d28 2d31 2c20 3629 2c0a   shape=(-1, 6),.
+00002b10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002b20: 6e61 6d65 3d6e 6f64 652e 6e61 6d65 202b  name=node.name +
+00002b30: 2022 5f74 6865 7461 5f72 6573 6861 7065   "_theta_reshape
+00002b40: 222c 0a20 2020 2020 2020 2020 2020 2029  ",.            )
+00002b50: 0a0a 2020 2020 2020 2020 2320 696e 7075  ..        # inpu
+00002b60: 7473 2066 726f 6d20 6067 7269 645f 7361  ts from `grid_sa
+00002b70: 6d70 6c65 7260 0a20 2020 2020 2020 2073  mpler`.        s
+00002b80: 616d 706c 696e 675f 6d6f 6465 203d 206d  ampling_mode = m
+00002b90: 5f6d 6f64 655b 636f 6e74 6578 745b 6e6f  _mode[context[no
+00002ba0: 6465 2e69 6e70 7574 735b 325d 5d2e 7661  de.inputs[2]].va
+00002bb0: 6c5d 0a20 2020 2020 2020 2070 6164 6469  l].        paddi
+00002bc0: 6e67 5f6d 6f64 6520 3d20 6d5f 7061 6464  ng_mode = m_padd
+00002bd0: 696e 675f 6d6f 6465 5b63 6f6e 7465 7874  ing_mode[context
+00002be0: 5b6e 6f64 652e 696e 7075 7473 5b33 5d5d  [node.inputs[3]]
+00002bf0: 2e76 616c 5d0a 2020 2020 2020 2020 616c  .val].        al
+00002c00: 6967 6e5f 636f 726e 6572 7320 3d20 636f  ign_corners = co
+00002c10: 6e74 6578 745b 6e6f 6465 2e69 6e70 7574  ntext[node.input
+00002c20: 735b 345d 5d2e 7661 6c0a 0a20 2020 2020  s[4]].val..     
+00002c30: 2020 2069 6620 7361 6d70 6c69 6e67 5f6d     if sampling_m
+00002c40: 6f64 6520 213d 2022 6269 6c69 6e65 6172  ode != "bilinear
+00002c50: 223a 0a20 2020 2020 2020 2020 2020 2072  ":.            r
+00002c60: 6169 7365 204e 6f74 496d 706c 656d 656e  aise NotImplemen
+00002c70: 7465 6445 7272 6f72 2822 2773 616d 706c  tedError("'sampl
+00002c80: 696e 675f 6d6f 6465 2720 6e6f 7420 7375  ing_mode' not su
+00002c90: 7070 6f72 7465 642e 2229 0a0a 2020 2020  pported.")..    
+00002ca0: 2020 2020 6966 2070 6164 6469 6e67 5f6d      if padding_m
+00002cb0: 6f64 6520 213d 2022 636f 6e73 7461 6e74  ode != "constant
+00002cc0: 223a 0a20 2020 2020 2020 2020 2020 2072  ":.            r
+00002cd0: 6169 7365 204e 6f74 496d 706c 656d 656e  aise NotImplemen
+00002ce0: 7465 6445 7272 6f72 2822 2770 6164 6469  tedError("'paddi
+00002cf0: 6e67 5f6d 6f64 6527 206e 6f74 2073 7570  ng_mode' not sup
+00002d00: 706f 7274 6564 2e22 290a 0a20 2020 2020  ported.")..     
+00002d10: 2020 2069 6620 6166 6669 6e65 5f61 6c69     if affine_ali
+00002d20: 676e 5f63 6f72 6e65 7273 2e76 616c 2021  gn_corners.val !
+00002d30: 3d20 616c 6967 6e5f 636f 726e 6572 733a  = align_corners:
+00002d40: 0a20 2020 2020 2020 2020 2020 2072 6169  .            rai
+00002d50: 7365 2056 616c 7565 4572 726f 7228 0a20  se ValueError(. 
+00002d60: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+00002d70: 4f70 2027 6166 6669 6e65 5f67 7269 645f  Op 'affine_grid_
+00002d80: 6765 6e65 7261 746f 7227 2061 6e64 2027  generator' and '
+00002d90: 6772 6964 5f73 616d 706c 6572 2720 6d75  grid_sampler' mu
+00002da0: 7374 2061 6772 6565 206f 6e20 2761 6c69  st agree on 'ali
+00002db0: 676e 5f63 6f72 6e65 7273 272e 220a 2020  gn_corners'.".  
+00002dc0: 2020 2020 2020 2020 2020 290a 0a20 2020            )..   
+00002dd0: 2020 2020 2078 203d 206d 622e 6166 6669       x = mb.affi
+00002de0: 6e65 280a 2020 2020 2020 2020 2020 2020  ne(.            
+00002df0: 783d 782c 0a20 2020 2020 2020 2020 2020  x=x,.           
+00002e00: 2074 7261 6e73 666f 726d 5f6d 6174 7269   transform_matri
+00002e10: 783d 7472 616e 7366 6f72 6d5f 6d61 7472  x=transform_matr
+00002e20: 6978 2c0a 2020 2020 2020 2020 2020 2020  ix,.            
+00002e30: 6f75 7470 7574 5f68 6569 6768 743d 6166  output_height=af
+00002e40: 6669 6e65 5f73 697a 652e 7661 6c5b 325d  fine_size.val[2]
+00002e50: 2c0a 2020 2020 2020 2020 2020 2020 6f75  ,.            ou
+00002e60: 7470 7574 5f77 6964 7468 3d61 6666 696e  tput_width=affin
+00002e70: 655f 7369 7a65 2e76 616c 5b33 5d2c 0a20  e_size.val[3],. 
+00002e80: 2020 2020 2020 2020 2020 2073 616d 706c             sampl
+00002e90: 696e 675f 6d6f 6465 3d73 616d 706c 696e  ing_mode=samplin
+00002ea0: 675f 6d6f 6465 2c0a 2020 2020 2020 2020  g_mode,.        
+00002eb0: 2020 2020 7061 6464 696e 675f 6d6f 6465      padding_mode
+00002ec0: 3d70 6164 6469 6e67 5f6d 6f64 652c 0a20  =padding_mode,. 
+00002ed0: 2020 2020 2020 2020 2020 2070 6164 6469             paddi
+00002ee0: 6e67 5f76 616c 7565 3d30 2e30 2c0a 2020  ng_value=0.0,.  
+00002ef0: 2020 2020 2020 2020 2020 636f 6f72 6469            coordi
+00002f00: 6e61 7465 735f 6d6f 6465 3d22 6e6f 726d  nates_mode="norm
+00002f10: 616c 697a 6564 5f6d 696e 7573 5f6f 6e65  alized_minus_one
+00002f20: 5f74 6f5f 6f6e 6522 2c0a 2020 2020 2020  _to_one",.      
+00002f30: 2020 2020 2020 616c 6967 6e5f 636f 726e        align_corn
+00002f40: 6572 733d 616c 6967 6e5f 636f 726e 6572  ers=align_corner
+00002f50: 732c 0a20 2020 2020 2020 2020 2020 206e  s,.            n
+00002f60: 616d 653d 6e6f 6465 2e6e 616d 652c 0a20  ame=node.name,. 
+00002f70: 2020 2020 2020 2029 0a20 2020 2020 2020         ).       
+00002f80: 2063 6f6e 7465 7874 2e61 6464 2878 290a   context.add(x).
+00002f90: 0a0a 4072 6567 6973 7465 725f 746f 7263  ..@register_torc
+00002fa0: 685f 6f70 0a64 6566 2073 696c 7528 636f  h_op.def silu(co
+00002fb0: 6e74 6578 742c 206e 6f64 6529 3a0a 2020  ntext, node):.  
+00002fc0: 2020 696e 7075 7473 203d 205f 6765 745f    inputs = _get_
+00002fd0: 696e 7075 7473 2863 6f6e 7465 7874 2c20  inputs(context, 
+00002fe0: 6e6f 6465 2c20 6578 7065 6374 6564 3d31  node, expected=1
+00002ff0: 290a 2020 2020 7820 3d20 6d62 2e73 696c  ).    x = mb.sil
+00003000: 7528 783d 696e 7075 7473 5b30 5d2c 206e  u(x=inputs[0], n
+00003010: 616d 653d 6e6f 6465 2e6e 616d 6529 0a20  ame=node.name). 
+00003020: 2020 2063 6f6e 7465 7874 2e61 6464 2878     context.add(x
+00003030: 290a 0a0a 4072 6567 6973 7465 725f 746f  )...@register_to
+00003040: 7263 685f 6f70 0a64 6566 2063 6f6e 7374  rch_op.def const
+00003050: 616e 7428 636f 6e74 6578 742c 206e 6f64  ant(context, nod
+00003060: 6529 3a0a 2020 2020 6173 7365 7274 206c  e):.    assert l
+00003070: 656e 286e 6f64 652e 696e 7075 7473 2920  en(node.inputs) 
+00003080: 3d3d 2030 0a20 2020 2061 7373 6572 7420  == 0.    assert 
+00003090: 6c65 6e28 6e6f 6465 2e6f 7574 7075 7473  len(node.outputs
+000030a0: 2920 3d3d 2031 0a0a 2020 2020 6e61 6d65  ) == 1..    name
+000030b0: 203d 206e 6f64 652e 6e61 6d65 0a20 2020   = node.name.   
+000030c0: 2076 616c 203d 206e 6f64 652e 6174 7472   val = node.attr
+000030d0: 5b22 7661 6c75 6522 5d0a 0a20 2020 2063  ["value"]..    c
+000030e0: 6f6e 7374 203d 205f 636f 6e73 7472 7563  onst = _construc
+000030f0: 745f 636f 6e73 7461 6e74 2876 616c 2c20  t_constant(val, 
+00003100: 6e61 6d65 290a 2020 2020 636f 6e74 6578  name).    contex
+00003110: 742e 6164 6428 636f 6e73 742c 2074 6f72  t.add(const, tor
+00003120: 6368 5f6e 616d 653d 6e61 6d65 290a 0a0a  ch_name=name)...
+00003130: 4072 6567 6973 7465 725f 746f 7263 685f  @register_torch_
+00003140: 6f70 0a64 6566 2063 6f73 696e 655f 7369  op.def cosine_si
+00003150: 6d69 6c61 7269 7479 2863 6f6e 7465 7874  milarity(context
+00003160: 2c20 6e6f 6465 293a 0a20 2020 2069 6e70  , node):.    inp
+00003170: 7574 7320 3d20 5f67 6574 5f69 6e70 7574  uts = _get_input
+00003180: 7328 636f 6e74 6578 742c 206e 6f64 652c  s(context, node,
+00003190: 2065 7870 6563 7465 643d 3429 0a20 2020   expected=4).   
+000031a0: 2064 696d 203d 2069 6e70 7574 735b 2d32   dim = inputs[-2
+000031b0: 5d2e 7661 6c0a 2020 2020 6570 7320 3d20  ].val.    eps = 
+000031c0: 696e 7075 7473 5b2d 315d 2e76 616c 0a20  inputs[-1].val. 
+000031d0: 2020 2078 7920 3d20 6d62 2e6d 756c 2878     xy = mb.mul(x
+000031e0: 3d69 6e70 7574 735b 305d 2c20 793d 696e  =inputs[0], y=in
+000031f0: 7075 7473 5b31 5d29 0a20 2020 2073 756d  puts[1]).    sum
+00003200: 5f78 7920 3d20 6d62 2e72 6564 7563 655f  _xy = mb.reduce_
+00003210: 7375 6d28 783d 7879 2c20 6178 6573 3d5b  sum(x=xy, axes=[
+00003220: 6469 6d5d 290a 0a20 2020 2078 7820 3d20  dim])..    xx = 
+00003230: 6d62 2e6d 756c 2878 3d69 6e70 7574 735b  mb.mul(x=inputs[
+00003240: 305d 2c20 793d 696e 7075 7473 5b30 5d29  0], y=inputs[0])
+00003250: 0a20 2020 2073 756d 5f78 7820 3d20 6d62  .    sum_xx = mb
+00003260: 2e72 6564 7563 655f 7375 6d28 783d 7878  .reduce_sum(x=xx
+00003270: 2c20 6178 6573 3d5b 6469 6d5d 290a 2020  , axes=[dim]).  
+00003280: 2020 7979 203d 206d 622e 6d75 6c28 783d    yy = mb.mul(x=
+00003290: 696e 7075 7473 5b31 5d2c 2079 3d69 6e70  inputs[1], y=inp
+000032a0: 7574 735b 315d 290a 2020 2020 7375 6d5f  uts[1]).    sum_
+000032b0: 7979 203d 206d 622e 7265 6475 6365 5f73  yy = mb.reduce_s
+000032c0: 756d 2878 3d79 792c 2061 7865 733d 5b64  um(x=yy, axes=[d
+000032d0: 696d 5d29 0a0a 2020 2020 6d75 6c5f 7375  im])..    mul_su
+000032e0: 6d5f 7879 203d 206d 622e 6d75 6c28 783d  m_xy = mb.mul(x=
+000032f0: 7375 6d5f 7878 2c20 793d 7375 6d5f 7979  sum_xx, y=sum_yy
+00003300: 290a 2020 2020 6469 765f 3132 203d 206d  ).    div_12 = m
+00003310: 622e 6d61 7869 6d75 6d28 783d 6d75 6c5f  b.maximum(x=mul_
+00003320: 7375 6d5f 7879 2c20 793d 6570 7320 2a20  sum_xy, y=eps * 
+00003330: 6570 7329 0a20 2020 2064 6976 5f73 7172  eps).    div_sqr
+00003340: 7420 3d20 6d62 2e73 7172 7428 783d 6469  t = mb.sqrt(x=di
+00003350: 765f 3132 290a 0a20 2020 2063 7320 3d20  v_12)..    cs = 
+00003360: 6d62 2e72 6561 6c5f 6469 7628 783d 7375  mb.real_div(x=su
+00003370: 6d5f 7879 2c20 793d 6469 765f 7371 7274  m_xy, y=div_sqrt
+00003380: 2c20 6e61 6d65 3d6e 6f64 652e 6e61 6d65  , name=node.name
+00003390: 290a 2020 2020 636f 6e74 6578 742e 6164  ).    context.ad
+000033a0: 6428 6373 290a 0a0a 4072 6567 6973 7465  d(cs)...@registe
+000033b0: 725f 746f 7263 685f 6f70 0a64 6566 2073  r_torch_op.def s
+000033c0: 656c 7528 636f 6e74 6578 742c 206e 6f64  elu(context, nod
+000033d0: 6529 3a0a 2020 2020 414c 5048 4120 3d20  e):.    ALPHA = 
+000033e0: 312e 3637 3332 3633 3234 3233 3534 3337  1.67326324235437
+000033f0: 3732 0a20 2020 2053 4341 4c45 203d 2031  72.    SCALE = 1
+00003400: 2e30 3530 3730 3039 3837 3335 3534 3830  .050700987355480
+00003410: 350a 0a20 2020 2078 203d 205f 6765 745f  5..    x = _get_
+00003420: 696e 7075 7473 2863 6f6e 7465 7874 2c20  inputs(context, 
+00003430: 6e6f 6465 2c20 6578 7065 6374 6564 3d31  node, expected=1
+00003440: 295b 305d 0a20 2020 2078 203d 206d 622e  )[0].    x = mb.
+00003450: 656c 7528 783d 782c 2061 6c70 6861 3d41  elu(x=x, alpha=A
+00003460: 4c50 4841 290a 2020 2020 7820 3d20 6d62  LPHA).    x = mb
+00003470: 2e6d 756c 2878 3d78 2c20 793d 5343 414c  .mul(x=x, y=SCAL
+00003480: 452c 206e 616d 653d 6e6f 6465 2e6e 616d  E, name=node.nam
+00003490: 6529 0a20 2020 2063 6f6e 7465 7874 2e61  e).    context.a
+000034a0: 6464 2878 290a 0a0a 4072 6567 6973 7465  dd(x)...@registe
+000034b0: 725f 746f 7263 685f 6f70 0a64 6566 2064  r_torch_op.def d
+000034c0: 6f74 2863 6f6e 7465 7874 2c20 6e6f 6465  ot(context, node
+000034d0: 293a 0a20 2020 2069 6e70 7574 7320 3d20  ):.    inputs = 
+000034e0: 5f67 6574 5f69 6e70 7574 7328 636f 6e74  _get_inputs(cont
+000034f0: 6578 742c 206e 6f64 652c 2065 7870 6563  ext, node, expec
+00003500: 7465 643d 3229 0a20 2020 2078 7920 3d20  ted=2).    xy = 
+00003510: 6d62 2e6d 756c 2878 3d69 6e70 7574 735b  mb.mul(x=inputs[
+00003520: 305d 2c20 793d 696e 7075 7473 5b31 5d29  0], y=inputs[1])
+00003530: 0a20 2020 2073 756d 5f78 7920 3d20 6d62  .    sum_xy = mb
+00003540: 2e72 6564 7563 655f 7375 6d28 783d 7879  .reduce_sum(x=xy
+00003550: 2c20 6178 6573 3d5b 305d 290a 2020 2020  , axes=[0]).    
+00003560: 636f 6e74 6578 742e 6164 6428 7375 6d5f  context.add(sum_
+00003570: 7879 2c20 6e6f 6465 2e6e 616d 6529 0a0a  xy, node.name)..
+00003580: 0a40 7265 6769 7374 6572 5f74 6f72 6368  .@register_torch
+00003590: 5f6f 700a 6465 6620 6d76 2863 6f6e 7465  _op.def mv(conte
+000035a0: 7874 2c20 6e6f 6465 293a 0a20 2020 2069  xt, node):.    i
+000035b0: 6e70 7574 7320 3d20 5f67 6574 5f69 6e70  nputs = _get_inp
+000035c0: 7574 7328 636f 6e74 6578 742c 206e 6f64  uts(context, nod
+000035d0: 652c 2065 7870 6563 7465 643d 3229 0a20  e, expected=2). 
+000035e0: 2020 2065 7870 616e 6420 3d20 6d62 2e65     expand = mb.e
+000035f0: 7870 616e 645f 6469 6d73 2878 3d69 6e70  xpand_dims(x=inp
+00003600: 7574 735b 315d 2c20 6178 6573 3d5b 2d31  uts[1], axes=[-1
+00003610: 5d2c 206e 616d 653d 6e6f 6465 2e6e 616d  ], name=node.nam
+00003620: 6520 2b20 225f 6578 7061 6e64 6564 2229  e + "_expanded")
+00003630: 0a20 2020 206d 7620 3d20 6d62 2e6d 6174  .    mv = mb.mat
+00003640: 6d75 6c28 783d 696e 7075 7473 5b30 5d2c  mul(x=inputs[0],
+00003650: 2079 3d65 7870 616e 642c 206e 616d 653d   y=expand, name=
+00003660: 6e6f 6465 2e6e 616d 6520 2b20 225f 6d76  node.name + "_mv
+00003670: 2229 0a20 2020 2072 6573 203d 206d 622e  ").    res = mb.
+00003680: 7371 7565 657a 6528 783d 6d76 2c20 6178  squeeze(x=mv, ax
+00003690: 6573 3d5b 2d31 5d2c 206e 616d 653d 6e6f  es=[-1], name=no
+000036a0: 6465 2e6e 616d 6529 0a20 2020 2063 6f6e  de.name).    con
+000036b0: 7465 7874 2e61 6464 2872 6573 290a 0a0a  text.add(res)...
+000036c0: 4072 6567 6973 7465 725f 746f 7263 685f  @register_torch_
+000036d0: 6f70 0a64 6566 206f 7574 6572 2863 6f6e  op.def outer(con
+000036e0: 7465 7874 2c20 6e6f 6465 293a 0a20 2020  text, node):.   
+000036f0: 2069 6e70 7574 7320 3d20 5f67 6574 5f69   inputs = _get_i
+00003700: 6e70 7574 7328 636f 6e74 6578 742c 206e  nputs(context, n
+00003710: 6f64 652c 2065 7870 6563 7465 643d 3229  ode, expected=2)
+00003720: 0a20 2020 2078 203d 206d 622e 7265 7368  .    x = mb.resh
+00003730: 6170 6528 783d 696e 7075 7473 5b30 5d2c  ape(x=inputs[0],
+00003740: 2073 6861 7065 3d5b 2d31 2c20 315d 290a   shape=[-1, 1]).
+00003750: 2020 2020 7920 3d20 6d62 2e72 6573 6861      y = mb.resha
+00003760: 7065 2878 3d69 6e70 7574 735b 315d 2c20  pe(x=inputs[1], 
+00003770: 7368 6170 653d 5b31 2c20 2d31 5d29 0a20  shape=[1, -1]). 
+00003780: 2020 2072 6573 203d 206d 622e 6d61 746d     res = mb.matm
+00003790: 756c 2878 3d78 2c20 793d 792c 206e 616d  ul(x=x, y=y, nam
+000037a0: 653d 6e6f 6465 2e6e 616d 6529 0a20 2020  e=node.name).   
+000037b0: 2063 6f6e 7465 7874 2e61 6464 2872 6573   context.add(res
+000037c0: 290a 0a0a 4072 6567 6973 7465 725f 746f  )...@register_to
+000037d0: 7263 685f 6f70 0a64 6566 2063 726f 7373  rch_op.def cross
+000037e0: 2863 6f6e 7465 7874 2c20 6e6f 6465 293a  (context, node):
+000037f0: 0a20 2020 2069 6e70 7574 7320 3d20 5f67  .    inputs = _g
+00003800: 6574 5f69 6e70 7574 7328 636f 6e74 6578  et_inputs(contex
+00003810: 742c 206e 6f64 652c 2065 7870 6563 7465  t, node, expecte
+00003820: 643d 3329 0a20 2020 2078 203d 2069 6e70  d=3).    x = inp
+00003830: 7574 735b 305d 0a20 2020 2079 203d 2069  uts[0].    y = i
+00003840: 6e70 7574 735b 315d 0a20 2020 2064 696d  nputs[1].    dim
+00003850: 203d 2069 6e70 7574 735b 325d 0a0a 2020   = inputs[2]..  
+00003860: 2020 7831 203d 206d 622e 6761 7468 6572    x1 = mb.gather
+00003870: 2878 3d78 2c20 696e 6469 6365 733d 5b31  (x=x, indices=[1
+00003880: 2c20 322c 2030 5d2c 2061 7869 733d 6469  , 2, 0], axis=di
+00003890: 6d2c 206e 616d 653d 2278 3122 290a 2020  m, name="x1").  
+000038a0: 2020 7832 203d 206d 622e 6761 7468 6572    x2 = mb.gather
+000038b0: 2878 3d78 2c20 696e 6469 6365 733d 5b32  (x=x, indices=[2
+000038c0: 2c20 302c 2031 5d2c 2061 7869 733d 6469  , 0, 1], axis=di
+000038d0: 6d2c 206e 616d 653d 2278 3222 290a 2020  m, name="x2").  
+000038e0: 2020 7931 203d 206d 622e 6761 7468 6572    y1 = mb.gather
+000038f0: 2878 3d79 2c20 696e 6469 6365 733d 5b31  (x=y, indices=[1
+00003900: 2c20 322c 2030 5d2c 2061 7869 733d 6469  , 2, 0], axis=di
+00003910: 6d2c 206e 616d 653d 2279 3122 290a 2020  m, name="y1").  
+00003920: 2020 7932 203d 206d 622e 6761 7468 6572    y2 = mb.gather
+00003930: 2878 3d79 2c20 696e 6469 6365 733d 5b32  (x=y, indices=[2
+00003940: 2c20 302c 2031 5d2c 2061 7869 733d 6469  , 0, 1], axis=di
+00003950: 6d2c 206e 616d 653d 2279 3222 290a 2020  m, name="y2").  
+00003960: 2020 6d31 203d 206d 622e 6d75 6c28 783d    m1 = mb.mul(x=
+00003970: 7831 2c20 793d 7932 290a 2020 2020 6d32  x1, y=y2).    m2
+00003980: 203d 206d 622e 6d75 6c28 783d 7832 2c20   = mb.mul(x=x2, 
+00003990: 793d 7931 290a 2020 2020 7a20 3d20 6d62  y=y1).    z = mb
+000039a0: 2e73 7562 2878 3d6d 312c 2079 3d6d 322c  .sub(x=m1, y=m2,
+000039b0: 206e 616d 653d 6e6f 6465 2e6e 616d 6529   name=node.name)
+000039c0: 0a20 2020 2063 6f6e 7465 7874 2e61 6464  .    context.add
+000039d0: 287a 290a 0a0a 4072 6567 6973 7465 725f  (z)...@register_
+000039e0: 746f 7263 685f 6f70 0a64 6566 2066 726f  torch_op.def fro
+000039f0: 6265 6e69 7573 5f6e 6f72 6d28 636f 6e74  benius_norm(cont
+00003a00: 6578 742c 206e 6f64 6529 3a0a 2020 2020  ext, node):.    
+00003a10: 782c 2064 696d 2c20 6b65 6570 5f64 696d  x, dim, keep_dim
+00003a20: 7320 3d20 5f67 6574 5f69 6e70 7574 7328  s = _get_inputs(
+00003a30: 636f 6e74 6578 742c 206e 6f64 652c 2065  context, node, e
+00003a40: 7870 6563 7465 643d 3329 0a20 2020 2072  xpected=3).    r
+00003a50: 6573 756c 7420 3d20 6d62 2e72 6564 7563  esult = mb.reduc
+00003a60: 655f 6c32 5f6e 6f72 6d28 783d 782c 2061  e_l2_norm(x=x, a
+00003a70: 7865 733d 6469 6d2c 206b 6565 705f 6469  xes=dim, keep_di
+00003a80: 6d73 3d6b 6565 705f 6469 6d73 2c20 6e61  ms=keep_dims, na
+00003a90: 6d65 3d6e 6f64 652e 6e61 6d65 290a 2020  me=node.name).  
+00003aa0: 2020 636f 6e74 6578 742e 6164 6428 7265    context.add(re
+00003ab0: 7375 6c74 290a 0a0a 4072 6567 6973 7465  sult)...@registe
+00003ac0: 725f 746f 7263 685f 6f70 0a64 6566 206e  r_torch_op.def n
+00003ad0: 6f72 6d28 636f 6e74 6578 742c 206e 6f64  orm(context, nod
+00003ae0: 6529 3a0a 2020 2020 782c 206e 756d 2c20  e):.    x, num, 
+00003af0: 6469 6d2c 206b 6565 705f 6469 6d73 203d  dim, keep_dims =
+00003b00: 205f 6765 745f 696e 7075 7473 2863 6f6e   _get_inputs(con
+00003b10: 7465 7874 2c20 6e6f 6465 2c20 6578 7065  text, node, expe
+00003b20: 6374 6564 3d34 290a 2020 2020 6173 7365  cted=4).    asse
+00003b30: 7274 2078 2069 7320 6e6f 7420 4e6f 6e65  rt x is not None
+00003b40: 2061 6e64 206b 6565 705f 6469 6d73 2069   and keep_dims i
+00003b50: 7320 6e6f 7420 4e6f 6e65 2061 6e64 206e  s not None and n
+00003b60: 756d 2069 7320 6e6f 7420 4e6f 6e65 2061  um is not None a
+00003b70: 6e64 2064 696d 2069 7320 6e6f 7420 4e6f  nd dim is not No
+00003b80: 6e65 0a20 2020 2074 656d 7020 3d20 5f76  ne.    temp = _v
+00003b90: 6563 746f 725f 6e6f 726d 2878 3d78 2c20  ector_norm(x=x, 
+00003ba0: 6f72 6465 723d 6e75 6d2c 2064 696d 3d64  order=num, dim=d
+00003bb0: 696d 2c20 6b65 6570 5f64 696d 733d 6b65  im, keep_dims=ke
+00003bc0: 6570 5f64 696d 732c 206e 616d 653d 6e6f  ep_dims, name=no
+00003bd0: 6465 2e6e 616d 6529 0a20 2020 2063 6f6e  de.name).    con
+00003be0: 7465 7874 2e61 6464 2874 656d 7029 0a0a  text.add(temp)..
+00003bf0: 0a64 6566 205f 7665 6374 6f72 5f6e 6f72  .def _vector_nor
+00003c00: 6d28 782c 206f 7264 6572 2c20 6469 6d2c  m(x, order, dim,
+00003c10: 206b 6565 705f 6469 6d73 2c20 6e61 6d65   keep_dims, name
+00003c20: 293a 0a20 2020 2069 6620 6f72 6465 722e  ):.    if order.
+00003c30: 7661 6c20 3d3d 2030 3a0a 2020 2020 2020  val == 0:.      
+00003c40: 2020 2320 7375 6d28 7821 3d30 290a 2020    # sum(x!=0).  
+00003c50: 2020 2020 2020 7820 3d20 6d62 2e63 6173        x = mb.cas
+00003c60: 7428 783d 782c 2064 7479 7065 3d22 6670  t(x=x, dtype="fp
+00003c70: 3332 2229 0a20 2020 2020 2020 2074 656d  32").        tem
+00003c80: 7020 3d20 6d62 2e6e 6f74 5f65 7175 616c  p = mb.not_equal
+00003c90: 2878 3d78 2c20 793d 302e 290a 2020 2020  (x=x, y=0.).    
+00003ca0: 2020 2020 7465 6d70 203d 206d 622e 6361      temp = mb.ca
+00003cb0: 7374 2878 3d74 656d 702c 2064 7479 7065  st(x=temp, dtype
+00003cc0: 3d27 696e 7433 3227 290a 2020 2020 2020  ='int32').      
+00003cd0: 2020 7465 6d70 203d 206d 622e 7265 6475    temp = mb.redu
+00003ce0: 6365 5f73 756d 2878 3d74 656d 702c 2061  ce_sum(x=temp, a
+00003cf0: 7865 733d 6469 6d2c 206b 6565 705f 6469  xes=dim, keep_di
+00003d00: 6d73 3d6b 6565 705f 6469 6d73 2c20 6e61  ms=keep_dims, na
+00003d10: 6d65 3d6e 616d 6529 0a20 2020 2065 6c69  me=name).    eli
+00003d20: 6620 6f72 6465 722e 7661 6c20 3e20 5641  f order.val > VA
+00003d30: 4c55 455f 434c 4f53 455f 544f 5f49 4e46  LUE_CLOSE_TO_INF
+00003d40: 494e 4954 593a 0a20 2020 2020 2020 2023  INITY:.        #
+00003d50: 206d 6178 2861 6273 2878 2929 0a20 2020   max(abs(x)).   
+00003d60: 2020 2020 2074 656d 7020 3d20 6d62 2e61       temp = mb.a
+00003d70: 6273 2878 3d78 290a 2020 2020 2020 2020  bs(x=x).        
+00003d80: 7465 6d70 203d 206d 622e 7265 6475 6365  temp = mb.reduce
+00003d90: 5f6d 6178 2878 3d74 656d 702c 2061 7865  _max(x=temp, axe
+00003da0: 733d 6469 6d2c 206b 6565 705f 6469 6d73  s=dim, keep_dims
+00003db0: 3d6b 6565 705f 6469 6d73 2c20 6e61 6d65  =keep_dims, name
+00003dc0: 3d6e 616d 6529 0a20 2020 2065 6c69 6620  =name).    elif 
+00003dd0: 6f72 6465 722e 7661 6c20 3c20 2d56 414c  order.val < -VAL
+00003de0: 5545 5f43 4c4f 5345 5f54 4f5f 494e 4649  UE_CLOSE_TO_INFI
+00003df0: 4e49 5459 3a0a 2020 2020 2020 2020 2320  NITY:.        # 
+00003e00: 6d69 6e28 6162 7328 7829 290a 2020 2020  min(abs(x)).    
+00003e10: 2020 2020 7465 6d70 203d 206d 622e 6162      temp = mb.ab
+00003e20: 7328 783d 7829 0a20 2020 2020 2020 2074  s(x=x).        t
+00003e30: 656d 7020 3d20 6d62 2e72 6564 7563 655f  emp = mb.reduce_
+00003e40: 6d69 6e28 783d 7465 6d70 2c20 6178 6573  min(x=temp, axes
+00003e50: 3d64 696d 2c20 6b65 6570 5f64 696d 733d  =dim, keep_dims=
+00003e60: 6b65 6570 5f64 696d 732c 206e 616d 653d  keep_dims, name=
+00003e70: 6e61 6d65 290a 2020 2020 656c 7365 3a0a  name).    else:.
+00003e80: 2020 2020 2020 2020 2320 7375 6d28 6162          # sum(ab
+00003e90: 7328 7829 5e7b 6f72 6465 727d 295e 7b28  s(x)^{order})^{(
+00003ea0: 3120 2f20 6f72 6465 7229 7d0a 2020 2020  1 / order)}.    
+00003eb0: 2020 2020 7465 6d70 203d 206d 622e 6162      temp = mb.ab
+00003ec0: 7328 783d 7829 0a20 2020 2020 2020 2078  s(x=x).        x
+00003ed0: 2c20 7920 3d20 7072 6f6d 6f74 655f 696e  , y = promote_in
+00003ee0: 7075 745f 6474 7970 6573 285b 7465 6d70  put_dtypes([temp
+00003ef0: 2c20 6f72 6465 722e 7661 6c5d 290a 2020  , order.val]).  
+00003f00: 2020 2020 2020 7465 6d70 203d 206d 622e        temp = mb.
+00003f10: 706f 7728 783d 782c 2079 3d79 290a 2020  pow(x=x, y=y).  
+00003f20: 2020 2020 2020 7465 6d70 203d 206d 622e        temp = mb.
+00003f30: 7265 6475 6365 5f73 756d 2878 3d74 656d  reduce_sum(x=tem
+00003f40: 702c 2061 7865 733d 6469 6d2c 206b 6565  p, axes=dim, kee
+00003f50: 705f 6469 6d73 3d6b 6565 705f 6469 6d73  p_dims=keep_dims
+00003f60: 290a 2020 2020 2020 2020 7465 6d70 203d  ).        temp =
+00003f70: 206d 622e 706f 7728 783d 7465 6d70 2c20   mb.pow(x=temp, 
+00003f80: 793d 312e 3020 2f20 6f72 6465 722e 7661  y=1.0 / order.va
+00003f90: 6c2c 206e 616d 653d 6e61 6d65 290a 2020  l, name=name).  
+00003fa0: 2020 7265 7475 726e 2074 656d 700a 0a40    return temp..@
+00003fb0: 7265 6769 7374 6572 5f74 6f72 6368 5f6f  register_torch_o
+00003fc0: 700a 6465 6620 5f77 6569 6768 745f 6e6f  p.def _weight_no
+00003fd0: 726d 2863 6f6e 7465 7874 2c20 6e6f 6465  rm(context, node
+00003fe0: 293a 0a20 2020 2076 2c20 672c 2064 696d  ):.    v, g, dim
+00003ff0: 203d 205f 6765 745f 696e 7075 7473 2863   = _get_inputs(c
+00004000: 6f6e 7465 7874 2c20 6e6f 6465 2c20 6578  ontext, node, ex
+00004010: 7065 6374 6564 3d33 290a 0a20 2020 2023  pected=3)..    #
+00004020: 2044 6574 6572 6d69 6e65 2061 7865 7320   Determine axes 
+00004030: 666f 7220 4c32 206e 6f72 6d0a 2020 2020  for L2 norm.    
+00004040: 6966 2064 696d 2e76 616c 203d 3d20 2d31  if dim.val == -1
+00004050: 3a0a 2020 2020 2020 2020 6178 6573 203d  :.        axes =
+00004060: 204e 6f6e 650a 2020 2020 656c 7365 3a0a   None.    else:.
+00004070: 2020 2020 2020 2020 6178 6573 203d 206c          axes = l
+00004080: 6973 7428 7261 6e67 6528 762e 7261 6e6b  ist(range(v.rank
+00004090: 2929 0a20 2020 2020 2020 2064 696d 203d  )).        dim =
+000040a0: 2064 696d 2e76 616c 0a20 2020 2020 2020   dim.val.       
+000040b0: 2069 6620 6469 6d20 3e3d 2030 3a0a 2020   if dim >= 0:.  
+000040c0: 2020 2020 2020 2020 2020 6178 6573 2e72            axes.r
+000040d0: 656d 6f76 6528 6469 6d29 0a20 2020 2020  emove(dim).     
+000040e0: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
+000040f0: 2020 2020 2061 7865 732e 7265 6d6f 7665       axes.remove
+00004100: 2876 2e72 616e 6b20 2b20 6469 6d29 0a0a  (v.rank + dim)..
+00004110: 2020 2020 2320 4361 6c63 756c 6174 6520      # Calculate 
+00004120: 4c32 206e 6f72 6d20 6f66 2076 0a20 2020  L2 norm of v.   
+00004130: 2074 656d 7020 3d20 6d62 2e70 6f77 2878   temp = mb.pow(x
+00004140: 3d76 2c20 793d 322e 290a 2020 2020 7465  =v, y=2.).    te
+00004150: 6d70 203d 206d 622e 7265 6475 6365 5f73  mp = mb.reduce_s
+00004160: 756d 2878 3d74 656d 702c 2061 7865 733d  um(x=temp, axes=
+00004170: 6178 6573 2c20 6b65 6570 5f64 696d 733d  axes, keep_dims=
+00004180: 5472 7565 290a 2020 2020 6e6f 726d 203d  True).    norm =
+00004190: 206d 622e 706f 7728 783d 7465 6d70 2c20   mb.pow(x=temp, 
+000041a0: 793d 312e 2f32 290a 0a20 2020 2069 6e76  y=1./2)..    inv
+000041b0: 6572 7365 5f6e 6f72 6d20 3d20 6d62 2e69  erse_norm = mb.i
+000041c0: 6e76 6572 7365 2878 3d6e 6f72 6d29 0a20  nverse(x=norm). 
+000041d0: 2020 2064 6972 6563 7469 6f6e 203d 206d     direction = m
+000041e0: 622e 6d75 6c28 783d 762c 2079 3d69 6e76  b.mul(x=v, y=inv
+000041f0: 6572 7365 5f6e 6f72 6d29 0a20 2020 2072  erse_norm).    r
+00004200: 6573 756c 7420 3d20 6d62 2e6d 756c 2878  esult = mb.mul(x
+00004210: 3d67 2c20 793d 6469 7265 6374 696f 6e2c  =g, y=direction,
+00004220: 206e 616d 653d 6e6f 6465 2e6e 616d 6529   name=node.name)
+00004230: 0a20 2020 2063 6f6e 7465 7874 2e61 6464  .    context.add
+00004240: 2872 6573 756c 7429 0a0a 0a0a 6465 6620  (result)....def 
+00004250: 5f6d 6174 7269 785f 6e6f 726d 2878 2c20  _matrix_norm(x, 
+00004260: 6f72 6465 722c 2064 696d 2c20 6b65 6570  order, dim, keep
+00004270: 5f64 696d 732c 206e 616d 6529 3a0a 2020  _dims, name):.  
+00004280: 2020 6966 206f 7264 6572 2e76 616c 203d    if order.val =
+00004290: 3d20 313a 0a20 2020 2020 2020 2023 206d  = 1:.        # m
+000042a0: 696e 2873 756d 2861 6273 2878 292c 2064  in(sum(abs(x), d
+000042b0: 696d 3d30 2929 0a20 2020 2020 2020 2074  im=0)).        t
+000042c0: 656d 7020 3d20 6d62 2e61 6273 2878 3d78  emp = mb.abs(x=x
+000042d0: 290a 2020 2020 2020 2020 7465 6d70 203d  ).        temp =
+000042e0: 206d 622e 7265 6475 6365 5f73 756d 2878   mb.reduce_sum(x
+000042f0: 3d74 656d 702c 2061 7865 733d 5b64 696d  =temp, axes=[dim
+00004300: 5b30 5d5d 2c20 6b65 6570 5f64 696d 733d  [0]], keep_dims=
+00004310: 5472 7565 290a 2020 2020 2020 2020 7465  True).        te
+00004320: 6d70 203d 206d 622e 7265 6475 6365 5f6d  mp = mb.reduce_m
+00004330: 6178 2878 3d74 656d 702c 2061 7865 733d  ax(x=temp, axes=
+00004340: 6469 6d2c 206b 6565 705f 6469 6d73 3d6b  dim, keep_dims=k
+00004350: 6565 705f 6469 6d73 2c20 6e61 6d65 3d6e  eep_dims, name=n
+00004360: 616d 6529 0a20 2020 2065 6c69 6620 6f72  ame).    elif or
+00004370: 6465 722e 7661 6c20 3d3d 202d 313a 0a20  der.val == -1:. 
+00004380: 2020 2020 2020 2023 206d 696e 2873 756d         # min(sum
+00004390: 2861 6273 2878 292c 2064 696d 3d30 2929  (abs(x), dim=0))
+000043a0: 0a20 2020 2020 2020 2074 656d 7020 3d20  .        temp = 
+000043b0: 6d62 2e61 6273 2878 3d78 290a 2020 2020  mb.abs(x=x).    
+000043c0: 2020 2020 7465 6d70 203d 206d 622e 7265      temp = mb.re
+000043d0: 6475 6365 5f73 756d 2878 3d74 656d 702c  duce_sum(x=temp,
+000043e0: 2061 7865 733d 5b64 696d 5b30 5d5d 2c20   axes=[dim[0]], 
+000043f0: 6b65 6570 5f64 696d 733d 5472 7565 290a  keep_dims=True).
+00004400: 2020 2020 2020 2020 7465 6d70 203d 206d          temp = m
+00004410: 622e 7265 6475 6365 5f6d 696e 2878 3d74  b.reduce_min(x=t
+00004420: 656d 702c 2061 7865 733d 6469 6d2c 206b  emp, axes=dim, k
+00004430: 6565 705f 6469 6d73 3d6b 6565 705f 6469  eep_dims=keep_di
+00004440: 6d73 2c20 6e61 6d65 3d6e 616d 6529 0a20  ms, name=name). 
+00004450: 2020 2065 6c69 6620 6f72 6465 722e 7661     elif order.va
+00004460: 6c20 3d3d 2022 6672 6f22 3a0a 2020 2020  l == "fro":.    
+00004470: 2020 2020 2320 7375 6d28 782a 2a32 292a      # sum(x**2)*
+00004480: 2a31 2f32 0a20 2020 2020 2020 2074 656d  *1/2.        tem
+00004490: 7020 3d20 6d62 2e72 6564 7563 655f 6c32  p = mb.reduce_l2
+000044a0: 5f6e 6f72 6d28 783d 782c 2061 7865 733d  _norm(x=x, axes=
+000044b0: 6469 6d2c 206b 6565 705f 6469 6d73 3d6b  dim, keep_dims=k
+000044c0: 6565 705f 6469 6d73 2c20 6e61 6d65 3d6e  eep_dims, name=n
+000044d0: 616d 6529 0a20 2020 2065 6c69 6620 6f72  ame).    elif or
+000044e0: 6465 722e 7661 6c20 3e20 5641 4c55 455f  der.val > VALUE_
+000044f0: 434c 4f53 455f 544f 5f49 4e46 494e 4954  CLOSE_TO_INFINIT
+00004500: 593a 0a20 2020 2020 2020 2023 206d 6178  Y:.        # max
+00004510: 2873 756d 2861 6273 2878 292c 2064 696d  (sum(abs(x), dim
+00004520: 3d31 2929 0a20 2020 2020 2020 2074 656d  =1)).        tem
+00004530: 7020 3d20 6d62 2e61 6273 2878 3d78 290a  p = mb.abs(x=x).
+00004540: 2020 2020 2020 2020 7465 6d70 203d 206d          temp = m
+00004550: 622e 7265 6475 6365 5f73 756d 2878 3d74  b.reduce_sum(x=t
+00004560: 656d 702c 2061 7865 733d 5b64 696d 5b31  emp, axes=[dim[1
+00004570: 5d5d 2c20 6b65 6570 5f64 696d 733d 5472  ]], keep_dims=Tr
+00004580: 7565 290a 2020 2020 2020 2020 7465 6d70  ue).        temp
+00004590: 203d 206d 622e 7265 6475 6365 5f6d 6178   = mb.reduce_max
+000045a0: 2878 3d74 656d 702c 2061 7865 733d 6469  (x=temp, axes=di
+000045b0: 6d2c 206b 6565 705f 6469 6d73 3d6b 6565  m, keep_dims=kee
+000045c0: 705f 6469 6d73 2c20 6e61 6d65 3d6e 616d  p_dims, name=nam
+000045d0: 6529 0a20 2020 2065 6c69 6620 6f72 6465  e).    elif orde
+000045e0: 722e 7661 6c20 3c20 2d56 414c 5545 5f43  r.val < -VALUE_C
+000045f0: 4c4f 5345 5f54 4f5f 494e 4649 4e49 5459  LOSE_TO_INFINITY
+00004600: 3a0a 2020 2020 2020 2020 2320 6d69 6e28  :.        # min(
+00004610: 7375 6d28 6162 7328 7829 2c20 6469 6d3d  sum(abs(x), dim=
+00004620: 3129 290a 2020 2020 2020 2020 7465 6d70  1)).        temp
+00004630: 203d 206d 622e 6162 7328 783d 7829 0a20   = mb.abs(x=x). 
+00004640: 2020 2020 2020 2074 656d 7020 3d20 6d62         temp = mb
+00004650: 2e72 6564 7563 655f 7375 6d28 783d 7465  .reduce_sum(x=te
+00004660: 6d70 2c20 6178 6573 3d5b 6469 6d5b 315d  mp, axes=[dim[1]
+00004670: 5d2c 206b 6565 705f 6469 6d73 3d54 7275  ], keep_dims=Tru
+00004680: 6529 0a20 2020 2020 2020 2074 656d 7020  e).        temp 
+00004690: 3d20 6d62 2e72 6564 7563 655f 6d69 6e28  = mb.reduce_min(
+000046a0: 783d 7465 6d70 2c20 6178 6573 3d64 696d  x=temp, axes=dim
+000046b0: 2c20 6b65 6570 5f64 696d 733d 6b65 6570  , keep_dims=keep
+000046c0: 5f64 696d 732c 206e 616d 653d 6e61 6d65  _dims, name=name
+000046d0: 290a 2020 2020 656c 7365 3a0a 2020 2020  ).    else:.    
+000046e0: 2020 2020 7261 6973 6520 5275 6e74 696d      raise Runtim
+000046f0: 6545 7272 6f72 2822 4d61 7472 6978 206e  eError("Matrix n
+00004700: 6f72 6d20 6973 206e 6f74 2064 6566 696e  orm is not defin
+00004710: 6564 2066 6f72 2074 6865 2063 7572 7265  ed for the curre
+00004720: 6e74 2069 6e70 7574 7322 290a 2020 2020  nt inputs").    
+00004730: 7265 7475 726e 2074 656d 700a 0a0a 4072  return temp...@r
+00004740: 6567 6973 7465 725f 746f 7263 685f 6f70  egister_torch_op
+00004750: 0a64 6566 206c 696e 616c 675f 7665 6374  .def linalg_vect
+00004760: 6f72 5f6e 6f72 6d28 636f 6e74 6578 742c  or_norm(context,
+00004770: 206e 6f64 6529 3a0a 2020 2020 782c 206f   node):.    x, o
+00004780: 7264 6572 2c20 6469 6d2c 206b 6565 705f  rder, dim, keep_
+00004790: 6469 6d73 2c20 5f20 3d20 5f67 6574 5f69  dims, _ = _get_i
+000047a0: 6e70 7574 7328 636f 6e74 6578 742c 206e  nputs(context, n
+000047b0: 6f64 652c 2065 7870 6563 7465 643d 3529  ode, expected=5)
+000047c0: 0a20 2020 2061 7373 6572 7420 7820 6973  .    assert x is
+000047d0: 206e 6f74 204e 6f6e 6520 616e 6420 6b65   not None and ke
+000047e0: 6570 5f64 696d 7320 6973 206e 6f74 204e  ep_dims is not N
+000047f0: 6f6e 6520 616e 6420 6f72 6465 7220 6973  one and order is
+00004800: 206e 6f74 204e 6f6e 650a 2020 2020 7465   not None.    te
+00004810: 6d70 203d 205f 7665 6374 6f72 5f6e 6f72  mp = _vector_nor
+00004820: 6d28 783d 782c 206f 7264 6572 3d6f 7264  m(x=x, order=ord
+00004830: 6572 2c20 6469 6d3d 6469 6d2c 206b 6565  er, dim=dim, kee
+00004840: 705f 6469 6d73 3d6b 6565 705f 6469 6d73  p_dims=keep_dims
+00004850: 2c20 6e61 6d65 3d6e 6f64 652e 6e61 6d65  , name=node.name
+00004860: 290a 2020 2020 636f 6e74 6578 742e 6164  ).    context.ad
+00004870: 6428 7465 6d70 290a 0a0a 4072 6567 6973  d(temp)...@regis
+00004880: 7465 725f 746f 7263 685f 6f70 0a64 6566  ter_torch_op.def
+00004890: 206c 696e 616c 675f 6d61 7472 6978 5f6e   linalg_matrix_n
+000048a0: 6f72 6d28 636f 6e74 6578 742c 206e 6f64  orm(context, nod
+000048b0: 6529 3a0a 2020 2020 782c 206f 7264 6572  e):.    x, order
+000048c0: 2c20 6469 6d2c 206b 6565 705f 6469 6d73  , dim, keep_dims
+000048d0: 2c20 5f20 3d20 5f67 6574 5f69 6e70 7574  , _ = _get_input
+000048e0: 7328 636f 6e74 6578 742c 206e 6f64 652c  s(context, node,
+000048f0: 2065 7870 6563 7465 643d 3529 0a20 2020   expected=5).   
+00004900: 2061 7373 6572 7420 7820 6973 206e 6f74   assert x is not
+00004910: 204e 6f6e 6520 616e 6420 6b65 6570 5f64   None and keep_d
+00004920: 696d 7320 6973 206e 6f74 204e 6f6e 6520  ims is not None 
+00004930: 616e 6420 6f72 6465 7220 6973 206e 6f74  and order is not
+00004940: 204e 6f6e 6520 616e 6420 6469 6d20 6973   None and dim is
+00004950: 206e 6f74 204e 6f6e 650a 2020 2020 6173   not None.    as
+00004960: 7365 7274 206c 656e 2864 696d 2e76 616c  sert len(dim.val
+00004970: 2920 3d3d 2032 0a20 2020 2074 656d 7020  ) == 2.    temp 
+00004980: 3d20 5f6d 6174 7269 785f 6e6f 726d 2878  = _matrix_norm(x
+00004990: 3d78 2c20 6f72 6465 723d 6f72 6465 722c  =x, order=order,
+000049a0: 2064 696d 3d64 696d 2e76 616c 2c20 6b65   dim=dim.val, ke
+000049b0: 6570 5f64 696d 733d 6b65 6570 5f64 696d  ep_dims=keep_dim
+000049c0: 732c 206e 616d 653d 6e6f 6465 2e6e 616d  s, name=node.nam
+000049d0: 6529 0a20 2020 2063 6f6e 7465 7874 2e61  e).    context.a
+000049e0: 6464 2874 656d 7029 0a0a 0a40 7265 6769  dd(temp)...@regi
+000049f0: 7374 6572 5f74 6f72 6368 5f6f 700a 6465  ster_torch_op.de
+00004a00: 6620 6c69 6e61 6c67 5f6e 6f72 6d28 636f  f linalg_norm(co
+00004a10: 6e74 6578 742c 206e 6f64 6529 3a0a 2020  ntext, node):.  
+00004a20: 2020 782c 206f 7264 6572 2c20 6469 6d2c    x, order, dim,
+00004a30: 206b 6565 705f 6469 6d73 2c20 5f20 3d20   keep_dims, _ = 
+00004a40: 5f67 6574 5f69 6e70 7574 7328 636f 6e74  _get_inputs(cont
+00004a50: 6578 742c 206e 6f64 652c 2065 7870 6563  ext, node, expec
+00004a60: 7465 643d 3529 0a20 2020 2061 7373 6572  ted=5).    asser
+00004a70: 7420 7820 6973 206e 6f74 204e 6f6e 6520  t x is not None 
+00004a80: 616e 6420 6b65 6570 5f64 696d 7320 6973  and keep_dims is
+00004a90: 206e 6f74 204e 6f6e 650a 2020 2020 6966   not None.    if
+00004aa0: 2064 696d 2069 7320 4e6f 6e65 3a0a 2020   dim is None:.  
+00004ab0: 2020 2020 2020 6469 6d20 3d20 5f6e 702e        dim = _np.
+00004ac0: 6172 616e 6765 2878 2e72 616e 6b29 0a20  arange(x.rank). 
+00004ad0: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
+00004ae0: 2064 696d 203d 2064 696d 2e76 616c 0a20   dim = dim.val. 
+00004af0: 2020 2069 6620 6f72 6465 7220 6973 204e     if order is N
+00004b00: 6f6e 653a 0a20 2020 2020 2020 2074 656d  one:.        tem
+00004b10: 7020 3d20 6d62 2e72 6564 7563 655f 6c32  p = mb.reduce_l2
+00004b20: 5f6e 6f72 6d28 783d 782c 2061 7865 733d  _norm(x=x, axes=
+00004b30: 6469 6d2c 206b 6565 705f 6469 6d73 3d6b  dim, keep_dims=k
+00004b40: 6565 705f 6469 6d73 2c20 6e61 6d65 3d6e  eep_dims, name=n
+00004b50: 6f64 652e 6e61 6d65 290a 2020 2020 656c  ode.name).    el
+00004b60: 6966 206c 656e 2864 696d 2920 3d3d 2032  if len(dim) == 2
+00004b70: 3a0a 2020 2020 2020 2020 7465 6d70 203d  :.        temp =
+00004b80: 205f 6d61 7472 6978 5f6e 6f72 6d28 0a20   _matrix_norm(. 
+00004b90: 2020 2020 2020 2020 2020 2078 3d78 2c20             x=x, 
+00004ba0: 6f72 6465 723d 6f72 6465 722c 2064 696d  order=order, dim
+00004bb0: 3d64 696d 2c20 6b65 6570 5f64 696d 733d  =dim, keep_dims=
+00004bc0: 6b65 6570 5f64 696d 732c 206e 616d 653d  keep_dims, name=
+00004bd0: 6e6f 6465 2e6e 616d 650a 2020 2020 2020  node.name.      
+00004be0: 2020 290a 2020 2020 656c 7365 3a0a 2020    ).    else:.  
+00004bf0: 2020 2020 2020 7465 6d70 203d 205f 7665        temp = _ve
+00004c00: 6374 6f72 5f6e 6f72 6d28 783d 782c 206f  ctor_norm(x=x, o
+00004c10: 7264 6572 3d6f 7264 6572 2c20 6469 6d3d  rder=order, dim=
+00004c20: 6469 6d2c 206b 6565 705f 6469 6d73 3d6b  dim, keep_dims=k
+00004c30: 6565 705f 6469 6d73 2c20 6e61 6d65 3d6e  eep_dims, name=n
+00004c40: 6f64 652e 6e61 6d65 290a 2020 2020 636f  ode.name).    co
+00004c50: 6e74 6578 742e 6164 6428 7465 6d70 290a  ntext.add(temp).
+00004c60: 0a0a 4072 6567 6973 7465 725f 746f 7263  ..@register_torc
+00004c70: 685f 6f70 0a64 6566 2068 6172 6473 7769  h_op.def hardswi
+00004c80: 7368 2863 6f6e 7465 7874 2c20 6e6f 6465  sh(context, node
+00004c90: 293a 0a20 2020 2069 6e70 7574 7320 3d20  ):.    inputs = 
+00004ca0: 5f67 6574 5f69 6e70 7574 7328 636f 6e74  _get_inputs(cont
+00004cb0: 6578 742c 206e 6f64 652c 2065 7870 6563  ext, node, expec
+00004cc0: 7465 643d 3129 0a20 2020 2078 203d 2069  ted=1).    x = i
+00004cd0: 6e70 7574 735b 305d 0a0a 2020 2020 7720  nputs[0]..    w 
+00004ce0: 3d20 6d62 2e74 6872 6573 686f 6c64 6564  = mb.thresholded
+00004cf0: 5f72 656c 7528 783d 782c 2061 6c70 6861  _relu(x=x, alpha
+00004d00: 3d2d 332e 3029 0a20 2020 2079 203d 206d  =-3.0).    y = m
+00004d10: 622e 7369 676d 6f69 645f 6861 7264 280a  b.sigmoid_hard(.
+00004d20: 2020 2020 2020 2020 783d 772c 2061 6c70          x=w, alp
+00004d30: 6861 3d31 2e30 202f 2036 2c20 6265 7461  ha=1.0 / 6, beta
+00004d40: 3d30 2e35 0a20 2020 2029 2020 2320 6060  =0.5.    )  # ``
+00004d50: 7920 3d20 6d69 6e28 6d61 7828 616c 7068  y = min(max(alph
+00004d60: 6120 2a20 7820 2b20 6265 7461 2c20 2d31  a * x + beta, -1
+00004d70: 292c 2031 290a 2020 2020 7265 7375 6c74  ), 1).    result
+00004d80: 203d 206d 622e 6d75 6c28 783d 772c 2079   = mb.mul(x=w, y
+00004d90: 3d79 2c20 6e61 6d65 3d6e 6f64 652e 6e61  =y, name=node.na
+00004da0: 6d65 290a 0a20 2020 2063 6f6e 7465 7874  me)..    context
+00004db0: 2e61 6464 2872 6573 756c 7429 0a0a 0a40  .add(result)...@
+00004dc0: 7265 6769 7374 6572 5f74 6f72 6368 5f6f  register_torch_o
+00004dd0: 700a 6465 6620 7265 7368 6170 655f 6173  p.def reshape_as
+00004de0: 2863 6f6e 7465 7874 2c20 6e6f 6465 293a  (context, node):
+00004df0: 0a20 2020 2069 6e70 7574 7320 3d20 5f67  .    inputs = _g
+00004e00: 6574 5f69 6e70 7574 7328 636f 6e74 6578  et_inputs(contex
+00004e10: 742c 206e 6f64 652c 2065 7870 6563 7465  t, node, expecte
+00004e20: 643d 3229 0a20 2020 2078 203d 2069 6e70  d=2).    x = inp
+00004e30: 7574 735b 305d 0a20 2020 2072 6566 203d  uts[0].    ref =
+00004e40: 2069 6e70 7574 735b 315d 0a20 2020 2073   inputs[1].    s
+00004e50: 6861 7065 203d 206d 622e 7368 6170 6528  hape = mb.shape(
+00004e60: 783d 7265 6629 0a20 2020 2072 6573 756c  x=ref).    resul
+00004e70: 7420 3d20 6d62 2e72 6573 6861 7065 2878  t = mb.reshape(x
+00004e80: 3d78 2c20 7368 6170 653d 7368 6170 652c  =x, shape=shape,
+00004e90: 206e 616d 653d 6e6f 6465 2e6e 616d 6529   name=node.name)
+00004ea0: 0a20 2020 2063 6f6e 7465 7874 2e61 6464  .    context.add
+00004eb0: 2872 6573 756c 7429 0a0a 0a64 6566 205f  (result)...def _
+00004ec0: 6172 7261 795f 636f 6e73 7472 7563 7428  array_construct(
+00004ed0: 636f 6e74 6578 742c 206e 6f64 652c 2061  context, node, a
+00004ee0: 7272 6179 5f74 7970 6529 3a0a 2020 2020  rray_type):.    
+00004ef0: 6173 7365 7274 206c 656e 286e 6f64 652e  assert len(node.
+00004f00: 6f75 7470 7574 7329 203d 3d20 310a 2020  outputs) == 1.  
+00004f10: 2020 696e 7075 7473 203d 205f 6765 745f    inputs = _get_
+00004f20: 696e 7075 7473 2863 6f6e 7465 7874 2c20  inputs(context, 
+00004f30: 6e6f 6465 290a 2020 2020 7363 616c 6172  node).    scalar
+00004f40: 5f69 6e70 7574 7320 3d20 5b0a 2020 2020  _inputs = [.    
+00004f50: 2020 2020 696e 700a 2020 2020 2020 2020      inp.        
+00004f60: 666f 7220 696e 7020 696e 2069 6e70 7574  for inp in input
+00004f70: 730a 2020 2020 2020 2020 6966 2069 7369  s.        if isi
+00004f80: 6e73 7461 6e63 6528 696e 702c 2056 6172  nstance(inp, Var
+00004f90: 2920 616e 6420 696e 702e 6361 6e5f 6265  ) and inp.can_be
+00004fa0: 5f66 6f6c 6465 645f 746f 5f63 6f6e 7374  _folded_to_const
+00004fb0: 2829 2061 6e64 206c 656e 2869 6e70 2e73  () and len(inp.s
+00004fc0: 6861 7065 2920 3d3d 2030 0a20 2020 205d  hape) == 0.    ]
+00004fd0: 0a0a 2020 2020 6966 206c 656e 2873 6361  ..    if len(sca
+00004fe0: 6c61 725f 696e 7075 7473 2920 3d3d 206c  lar_inputs) == l
+00004ff0: 656e 2869 6e70 7574 7329 3a0a 2020 2020  en(inputs):.    
+00005000: 2020 2020 2320 416c 6c20 7468 6520 6c69      # All the li
+00005010: 7374 2069 7465 6d73 2061 7265 2063 6f6d  st items are com
+00005020: 7069 6c65 2d74 696d 6520 7363 616c 6172  pile-time scalar
+00005030: 2063 6f6e 7374 616e 7473 2c20 736f 206c   constants, so l
+00005040: 6574 2773 2063 7265 6174 650a 2020 2020  et's create.    
+00005050: 2020 2020 2320 6120 6e65 7720 636f 6e73      # a new cons
+00005060: 7420 7468 6174 2063 6f6e 6361 7465 6e61  t that concatena
+00005070: 7465 7320 7468 656d 2e0a 2020 2020 2020  tes them..      
+00005080: 2020 7661 6c20 3d20 6172 7261 795f 7479    val = array_ty
+00005090: 7065 285b 696e 702e 7661 6c20 666f 7220  pe([inp.val for 
+000050a0: 696e 7020 696e 2069 6e70 7574 735d 290a  inp in inputs]).
+000050b0: 2020 2020 2020 2020 636f 6e73 7420 3d20          const = 
+000050c0: 6d62 2e63 6f6e 7374 2876 616c 3d76 616c  mb.const(val=val
+000050d0: 2c20 6e61 6d65 3d6e 6f64 652e 6e61 6d65  , name=node.name
+000050e0: 290a 2020 2020 2020 2020 636f 6e74 6578  ).        contex
+000050f0: 742e 6164 6428 636f 6e73 7429 0a20 2020  t.add(const).   
+00005100: 2065 6c73 653a 0a20 2020 2020 2020 2023   else:.        #
+00005110: 2049 6620 6174 206c 6561 7374 206f 6e65   If at least one
+00005120: 2069 6e70 7574 2074 6f20 7468 6520 636f   input to the co
+00005130: 6e73 7472 7563 7420 6f70 2069 7320 6e6f  nstruct op is no
+00005140: 6e2d 636f 6e73 742c 2063 6f6c 6c65 6374  n-const, collect
+00005150: 0a20 2020 2020 2020 2023 2074 6865 2069  .        # the i
+00005160: 6e70 7574 7320 616e 6420 6164 6420 7468  nputs and add th
+00005170: 656d 2064 6972 6563 746c 7920 746f 2074  em directly to t
+00005180: 6865 2063 6f6e 7465 7874 2e20 4f70 7320  he context. Ops 
+00005190: 7468 6174 2075 7365 2074 6869 730a 2020  that use this.  
+000051a0: 2020 2020 2020 2320 6e6f 6465 2773 206f        # node's o
+000051b0: 7574 7075 7420 7769 6c6c 2074 616b 6520  utput will take 
+000051c0: 7468 6520 6c69 7374 2064 6972 6563 746c  the list directl
+000051d0: 7920 6173 2069 6e70 7574 2e0a 2020 2020  y as input..    
+000051e0: 2020 2020 636f 6e74 6578 742e 6164 6428      context.add(
+000051f0: 6172 7261 795f 7479 7065 2869 6e70 7574  array_type(input
+00005200: 7329 2c20 6e6f 6465 2e6e 616d 6529 0a0a  s), node.name)..
+00005210: 0a40 7265 6769 7374 6572 5f74 6f72 6368  .@register_torch
+00005220: 5f6f 700a 6465 6620 7475 706c 6563 6f6e  _op.def tuplecon
+00005230: 7374 7275 6374 2863 6f6e 7465 7874 2c20  struct(context, 
+00005240: 6e6f 6465 293a 0a20 2020 205f 6172 7261  node):.    _arra
+00005250: 795f 636f 6e73 7472 7563 7428 636f 6e74  y_construct(cont
+00005260: 6578 742c 206e 6f64 652c 2061 7272 6179  ext, node, array
+00005270: 5f74 7970 653d 7475 706c 6529 0a0a 0a40  _type=tuple)...@
+00005280: 7265 6769 7374 6572 5f74 6f72 6368 5f6f  register_torch_o
+00005290: 700a 6465 6620 6c69 7374 636f 6e73 7472  p.def listconstr
+000052a0: 7563 7428 636f 6e74 6578 742c 206e 6f64  uct(context, nod
+000052b0: 6529 3a0a 2020 2020 5f61 7272 6179 5f63  e):.    _array_c
+000052c0: 6f6e 7374 7275 6374 2863 6f6e 7465 7874  onstruct(context
+000052d0: 2c20 6e6f 6465 2c20 6172 7261 795f 7479  , node, array_ty
+000052e0: 7065 3d6c 6973 7429 0a0a 0a40 7265 6769  pe=list)...@regi
+000052f0: 7374 6572 5f74 6f72 6368 5f6f 700a 6465  ster_torch_op.de
+00005300: 6620 6571 2863 6f6e 7465 7874 2c20 6e6f  f eq(context, no
+00005310: 6465 293a 0a20 2020 2069 6e70 7574 7320  de):.    inputs 
+00005320: 3d20 5f67 6574 5f69 6e70 7574 7328 636f  = _get_inputs(co
+00005330: 6e74 6578 742c 206e 6f64 652c 2065 7870  ntext, node, exp
+00005340: 6563 7465 643d 3229 0a20 2020 2078 203d  ected=2).    x =
+00005350: 2069 6e70 7574 735b 305d 0a20 2020 2079   inputs[0].    y
+00005360: 203d 2069 6e70 7574 735b 315d 0a20 2020   = inputs[1].   
+00005370: 2069 6620 6973 5f62 6f6f 6c28 782e 6474   if is_bool(x.dt
+00005380: 7970 6529 3a0a 2020 2020 2020 2020 7820  ype):.        x 
+00005390: 3d20 6d62 2e63 6173 7428 783d 782c 2064  = mb.cast(x=x, d
+000053a0: 7479 7065 3d27 696e 7433 3227 290a 2020  type='int32').  
+000053b0: 2020 6966 2069 735f 626f 6f6c 2879 2e64    if is_bool(y.d
+000053c0: 7479 7065 293a 0a20 2020 2020 2020 2079  type):.        y
+000053d0: 203d 206d 622e 6361 7374 2878 3d79 2c20   = mb.cast(x=y, 
+000053e0: 6474 7970 653d 2769 6e74 3332 2729 0a20  dtype='int32'). 
+000053f0: 2020 2078 2c20 7920 3d20 7072 6f6d 6f74     x, y = promot
+00005400: 655f 696e 7075 745f 6474 7970 6573 285b  e_input_dtypes([
+00005410: 782c 2079 5d29 0a20 2020 2065 7175 616c  x, y]).    equal
+00005420: 5f74 6f20 3d20 6d62 2e65 7175 616c 2878  _to = mb.equal(x
+00005430: 3d78 2c20 793d 792c 206e 616d 653d 6e6f  =x, y=y, name=no
+00005440: 6465 2e6e 616d 6529 0a20 2020 2063 6f6e  de.name).    con
+00005450: 7465 7874 2e61 6464 2865 7175 616c 5f74  text.add(equal_t
+00005460: 6f29 0a0a 0a40 7265 6769 7374 6572 5f74  o)...@register_t
+00005470: 6f72 6368 5f6f 700a 6465 6620 6e65 2863  orch_op.def ne(c
+00005480: 6f6e 7465 7874 2c20 6e6f 6465 293a 0a20  ontext, node):. 
+00005490: 2020 2069 6e70 7574 7320 3d20 5f67 6574     inputs = _get
+000054a0: 5f69 6e70 7574 7328 636f 6e74 6578 742c  _inputs(context,
+000054b0: 206e 6f64 652c 2065 7870 6563 7465 643d   node, expected=
+000054c0: 3229 0a20 2020 2078 203d 2069 6e70 7574  2).    x = input
+000054d0: 735b 305d 0a20 2020 2079 203d 2069 6e70  s[0].    y = inp
+000054e0: 7574 735b 315d 0a20 2020 2069 6620 6973  uts[1].    if is
+000054f0: 5f62 6f6f 6c28 782e 6474 7970 6529 3a0a  _bool(x.dtype):.
+00005500: 2020 2020 2020 2020 7820 3d20 6d62 2e63          x = mb.c
+00005510: 6173 7428 783d 782c 2064 7479 7065 3d27  ast(x=x, dtype='
+00005520: 696e 7433 3227 290a 2020 2020 6966 2069  int32').    if i
+00005530: 735f 626f 6f6c 2879 2e64 7479 7065 293a  s_bool(y.dtype):
+00005540: 0a20 2020 2020 2020 2079 203d 206d 622e  .        y = mb.
+00005550: 6361 7374 2878 3d79 2c20 6474 7970 653d  cast(x=y, dtype=
+00005560: 2769 6e74 3332 2729 0a20 2020 2078 2c20  'int32').    x, 
+00005570: 7920 3d20 7072 6f6d 6f74 655f 696e 7075  y = promote_inpu
+00005580: 745f 6474 7970 6573 285b 782c 2079 5d29  t_dtypes([x, y])
+00005590: 0a20 2020 2065 7175 616c 5f74 6f20 3d20  .    equal_to = 
+000055a0: 6d62 2e6e 6f74 5f65 7175 616c 2878 3d78  mb.not_equal(x=x
+000055b0: 2c20 793d 792c 206e 616d 653d 6e6f 6465  , y=y, name=node
+000055c0: 2e6e 616d 6529 0a20 2020 2063 6f6e 7465  .name).    conte
+000055d0: 7874 2e61 6464 2865 7175 616c 5f74 6f29  xt.add(equal_to)
+000055e0: 0a0a 0a40 7265 6769 7374 6572 5f74 6f72  ...@register_tor
+000055f0: 6368 5f6f 700a 6465 6620 6c65 2863 6f6e  ch_op.def le(con
+00005600: 7465 7874 2c20 6e6f 6465 293a 0a20 2020  text, node):.   
+00005610: 2069 6e70 7574 7320 3d20 5f67 6574 5f69   inputs = _get_i
+00005620: 6e70 7574 7328 636f 6e74 6578 742c 206e  nputs(context, n
+00005630: 6f64 652c 2065 7870 6563 7465 643d 3229  ode, expected=2)
+00005640: 0a20 2020 2078 2c20 7920 3d20 7072 6f6d  .    x, y = prom
+00005650: 6f74 655f 696e 7075 745f 6474 7970 6573  ote_input_dtypes
+00005660: 2869 6e70 7574 7329 0a20 2020 206c 6573  (inputs).    les
+00005670: 735f 6571 7561 6c20 3d20 6d62 2e6c 6573  s_equal = mb.les
+00005680: 735f 6571 7561 6c28 783d 782c 2079 3d79  s_equal(x=x, y=y
+00005690: 2c20 6e61 6d65 3d6e 6f64 652e 6e61 6d65  , name=node.name
+000056a0: 290a 2020 2020 636f 6e74 6578 742e 6164  ).    context.ad
+000056b0: 6428 6c65 7373 5f65 7175 616c 290a 0a0a  d(less_equal)...
+000056c0: 4072 6567 6973 7465 725f 746f 7263 685f  @register_torch_
+000056d0: 6f70 0a64 6566 206c 7428 636f 6e74 6578  op.def lt(contex
+000056e0: 742c 206e 6f64 6529 3a0a 2020 2020 696e  t, node):.    in
+000056f0: 7075 7473 203d 205f 6765 745f 696e 7075  puts = _get_inpu
+00005700: 7473 2863 6f6e 7465 7874 2c20 6e6f 6465  ts(context, node
+00005710: 2c20 6578 7065 6374 6564 3d32 290a 2020  , expected=2).  
+00005720: 2020 782c 2079 203d 2070 726f 6d6f 7465    x, y = promote
+00005730: 5f69 6e70 7574 5f64 7479 7065 7328 696e  _input_dtypes(in
+00005740: 7075 7473 290a 2020 2020 6c65 7373 203d  puts).    less =
+00005750: 206d 622e 6c65 7373 2878 3d78 2c20 793d   mb.less(x=x, y=
+00005760: 792c 206e 616d 653d 6e6f 6465 2e6e 616d  y, name=node.nam
+00005770: 6529 0a20 2020 2063 6f6e 7465 7874 2e61  e).    context.a
+00005780: 6464 286c 6573 7329 0a0a 0a40 7265 6769  dd(less)...@regi
+00005790: 7374 6572 5f74 6f72 6368 5f6f 700a 6465  ster_torch_op.de
+000057a0: 6620 6765 2863 6f6e 7465 7874 2c20 6e6f  f ge(context, no
+000057b0: 6465 293a 0a20 2020 2069 6e70 7574 7320  de):.    inputs 
+000057c0: 3d20 5f67 6574 5f69 6e70 7574 7328 636f  = _get_inputs(co
+000057d0: 6e74 6578 742c 206e 6f64 652c 2065 7870  ntext, node, exp
+000057e0: 6563 7465 643d 3229 0a20 2020 2078 2c20  ected=2).    x, 
+000057f0: 7920 3d20 7072 6f6d 6f74 655f 696e 7075  y = promote_inpu
+00005800: 745f 6474 7970 6573 2869 6e70 7574 7329  t_dtypes(inputs)
+00005810: 0a20 2020 2067 7265 6174 6572 5f65 7175  .    greater_equ
+00005820: 616c 203d 206d 622e 6772 6561 7465 725f  al = mb.greater_
+00005830: 6571 7561 6c28 783d 782c 2079 3d79 2c20  equal(x=x, y=y, 
+00005840: 6e61 6d65 3d6e 6f64 652e 6e61 6d65 290a  name=node.name).
+00005850: 2020 2020 636f 6e74 6578 742e 6164 6428      context.add(
+00005860: 6772 6561 7465 725f 6571 7561 6c29 0a0a  greater_equal)..
+00005870: 0a40 7265 6769 7374 6572 5f74 6f72 6368  .@register_torch
+00005880: 5f6f 700a 6465 6620 6774 2863 6f6e 7465  _op.def gt(conte
+00005890: 7874 2c20 6e6f 6465 293a 0a20 2020 2069  xt, node):.    i
+000058a0: 6e70 7574 7320 3d20 5f67 6574 5f69 6e70  nputs = _get_inp
+000058b0: 7574 7328 636f 6e74 6578 742c 206e 6f64  uts(context, nod
+000058c0: 652c 2065 7870 6563 7465 643d 3229 0a20  e, expected=2). 
+000058d0: 2020 2078 2c20 7920 3d20 7072 6f6d 6f74     x, y = promot
+000058e0: 655f 696e 7075 745f 6474 7970 6573 2869  e_input_dtypes(i
+000058f0: 6e70 7574 735b 3a32 5d29 0a20 2020 2067  nputs[:2]).    g
+00005900: 7265 6174 6572 203d 206d 622e 6772 6561  reater = mb.grea
+00005910: 7465 7228 783d 782c 2079 3d79 2c20 6e61  ter(x=x, y=y, na
+00005920: 6d65 3d6e 6f64 652e 6e61 6d65 290a 2020  me=node.name).  
+00005930: 2020 636f 6e74 6578 742e 6164 6428 6772    context.add(gr
+00005940: 6561 7465 7229 0a0a 0a40 7265 6769 7374  eater)...@regist
+00005950: 6572 5f74 6f72 6368 5f6f 7028 746f 7263  er_torch_op(torc
+00005960: 685f 616c 6961 733d 5b22 7422 5d29 0a64  h_alias=["t"]).d
+00005970: 6566 2074 7261 6e73 706f 7365 2863 6f6e  ef transpose(con
+00005980: 7465 7874 2c20 6e6f 6465 293a 0a20 2020  text, node):.   
+00005990: 2061 7373 6572 7420 6c65 6e28 6e6f 6465   assert len(node
+000059a0: 2e6f 7574 7075 7473 2920 3d3d 2031 0a20  .outputs) == 1. 
+000059b0: 2020 2069 6e70 7574 7320 3d20 5f67 6574     inputs = _get
+000059c0: 5f69 6e70 7574 7328 636f 6e74 6578 742c  _inputs(context,
+000059d0: 206e 6f64 6529 0a20 2020 2078 203d 2069   node).    x = i
+000059e0: 6e70 7574 735b 305d 0a0a 2020 2020 6966  nputs[0]..    if
+000059f0: 206c 656e 286e 6f64 652e 696e 7075 7473   len(node.inputs
+00005a00: 2920 3d3d 2031 3a0a 2020 2020 2020 2020  ) == 1:.        
+00005a10: 2320 5079 546f 7263 6820 6861 7320 7365  # PyTorch has se
+00005a20: 7665 7261 6c20 7472 616e 7370 6f73 6520  veral transpose 
+00005a30: 6f70 7320 7468 6174 2063 616e 2062 6520  ops that can be 
+00005a40: 656d 6974 7465 642e 2054 6869 7320 6f6e  emitted. This on
+00005a50: 6520 6973 206f 6e6c 790a 2020 2020 2020  e is only.      
+00005a60: 2020 2320 656d 6974 7465 6420 7768 656e    # emitted when
+00005a70: 202e 7428 2920 6973 2063 616c 6c65 6420   .t() is called 
+00005a80: 6f6e 2061 2074 656e 736f 722c 2077 6869  on a tensor, whi
+00005a90: 6368 206d 6561 6e73 2069 7420 6361 6e20  ch means it can 
+00005aa0: 6f6e 6c79 2062 650a 2020 2020 2020 2020  only be.        
+00005ab0: 2320 6361 6c6c 6564 206f 6e20 6120 6d61  # called on a ma
+00005ac0: 7472 6978 2e0a 2020 2020 2020 2020 6966  trix..        if
+00005ad0: 206c 656e 2878 2e73 6861 7065 2920 3e20   len(x.shape) > 
+00005ae0: 323a 0a20 2020 2020 2020 2020 2020 2072  2:.            r
+00005af0: 6169 7365 2056 616c 7565 4572 726f 7228  aise ValueError(
+00005b00: 2274 7261 6e73 706f 7365 2077 6974 686f  "transpose witho
+00005b10: 7574 2064 696d 7320 666f 7220 7261 6e6b  ut dims for rank
+00005b20: 203e 2032 2069 7320 756e 7375 7070 6f72   > 2 is unsuppor
+00005b30: 7465 6422 290a 2020 2020 2020 2020 7265  ted").        re
+00005b40: 7320 3d20 6d62 2e74 7261 6e73 706f 7365  s = mb.transpose
+00005b50: 2878 3d78 2c20 7065 726d 3d5b 312c 2030  (x=x, perm=[1, 0
+00005b60: 5d2c 206e 616d 653d 6e6f 6465 2e6e 616d  ], name=node.nam
+00005b70: 6529 0a20 2020 2065 6c73 653a 0a20 2020  e).    else:.   
+00005b80: 2020 2020 2061 7373 6572 7420 6c65 6e28       assert len(
+00005b90: 696e 7075 7473 2920 3d3d 2033 0a20 2020  inputs) == 3.   
+00005ba0: 2020 2020 2061 7830 203d 2069 6e70 7574       ax0 = input
+00005bb0: 735b 315d 2e76 616c 0a20 2020 2020 2020  s[1].val.       
+00005bc0: 2061 7831 203d 2069 6e70 7574 735b 325d   ax1 = inputs[2]
+00005bd0: 2e76 616c 0a0a 2020 2020 2020 2020 7065  .val..        pe
+00005be0: 726d 203d 206c 6973 7428 7261 6e67 6528  rm = list(range(
+00005bf0: 6c65 6e28 782e 7368 6170 6529 2929 0a20  len(x.shape))). 
+00005c00: 2020 2020 2020 2070 6572 6d5b 6178 305d         perm[ax0]
+00005c10: 203d 2061 7831 0a20 2020 2020 2020 2070   = ax1.        p
+00005c20: 6572 6d5b 6178 315d 203d 2061 7830 0a0a  erm[ax1] = ax0..
+00005c30: 2020 2020 2020 2020 7265 7320 3d20 6d62          res = mb
+00005c40: 2e74 7261 6e73 706f 7365 2878 3d78 2c20  .transpose(x=x, 
+00005c50: 7065 726d 3d70 6572 6d2c 206e 616d 653d  perm=perm, name=
+00005c60: 6e6f 6465 2e6e 616d 6529 0a20 2020 2063  node.name).    c
+00005c70: 6f6e 7465 7874 2e61 6464 2872 6573 290a  ontext.add(res).
+00005c80: 0a0a 4072 6567 6973 7465 725f 746f 7263  ..@register_torc
+00005c90: 685f 6f70 0a64 6566 2070 6572 6d75 7465  h_op.def permute
+00005ca0: 2863 6f6e 7465 7874 2c20 6e6f 6465 293a  (context, node):
+00005cb0: 0a20 2020 2069 6e70 7574 7320 3d20 5f67  .    inputs = _g
+00005cc0: 6574 5f69 6e70 7574 7328 636f 6e74 6578  et_inputs(contex
+00005cd0: 742c 206e 6f64 652c 2065 7870 6563 7465  t, node, expecte
+00005ce0: 643d 3229 0a20 2020 2070 6572 6d20 3d20  d=2).    perm = 
+00005cf0: 6d62 2e74 7261 6e73 706f 7365 2878 3d69  mb.transpose(x=i
+00005d00: 6e70 7574 735b 305d 2c20 7065 726d 3d69  nputs[0], perm=i
+00005d10: 6e70 7574 735b 315d 2c20 6e61 6d65 3d6e  nputs[1], name=n
+00005d20: 6f64 652e 6e61 6d65 290a 2020 2020 636f  ode.name).    co
+00005d30: 6e74 6578 742e 6164 6428 7065 726d 290a  ntext.add(perm).
+00005d40: 0a0a 4072 6567 6973 7465 725f 746f 7263  ..@register_torc
+00005d50: 685f 6f70 0a64 6566 2066 7261 6328 636f  h_op.def frac(co
+00005d60: 6e74 6578 742c 206e 6f64 6529 3a0a 2020  ntext, node):.  
+00005d70: 2020 2320 4672 6163 2878 2920 3d20 7820    # Frac(x) = x 
+00005d80: 2d20 666c 6f6f 7228 6162 7328 7829 2920  - floor(abs(x)) 
+00005d90: 2a20 7369 676e 2878 290a 0a20 2020 2078  * sign(x)..    x
+00005da0: 203d 205f 6765 745f 696e 7075 7473 2863   = _get_inputs(c
+00005db0: 6f6e 7465 7874 2c20 6e6f 6465 2c20 6578  ontext, node, ex
+00005dc0: 7065 6374 6564 3d31 295b 305d 0a20 2020  pected=1)[0].   
+00005dd0: 2066 6c6f 6f72 5f61 6273 203d 206d 622e   floor_abs = mb.
+00005de0: 666c 6f6f 7228 783d 6d62 2e61 6273 2878  floor(x=mb.abs(x
+00005df0: 3d78 2929 0a20 2020 2073 6967 6e5f 6162  =x)).    sign_ab
+00005e00: 735f 666c 6f6f 7220 3d20 6d62 2e6d 756c  s_floor = mb.mul
+00005e10: 2878 3d66 6c6f 6f72 5f61 6273 2c20 793d  (x=floor_abs, y=
+00005e20: 6d62 2e73 6967 6e28 783d 7829 290a 2020  mb.sign(x=x)).  
+00005e30: 2020 7265 7320 3d20 6d62 2e73 7562 2878    res = mb.sub(x
+00005e40: 3d78 2c20 793d 7369 676e 5f61 6273 5f66  =x, y=sign_abs_f
+00005e50: 6c6f 6f72 290a 2020 2020 636f 6e74 6578  loor).    contex
+00005e60: 742e 6164 6428 7265 732c 2074 6f72 6368  t.add(res, torch
+00005e70: 5f6e 616d 653d 6e6f 6465 2e6e 616d 6529  _name=node.name)
+00005e80: 0a0a 0a40 7265 6769 7374 6572 5f74 6f72  ...@register_tor
+00005e90: 6368 5f6f 700a 6465 6620 7069 7865 6c5f  ch_op.def pixel_
+00005ea0: 7368 7566 666c 6528 636f 6e74 6578 742c  shuffle(context,
+00005eb0: 206e 6f64 6529 3a0a 2020 2020 696e 7075   node):.    inpu
+00005ec0: 7473 203d 205f 6765 745f 696e 7075 7473  ts = _get_inputs
+00005ed0: 2863 6f6e 7465 7874 2c20 6e6f 6465 2c20  (context, node, 
+00005ee0: 6578 7065 6374 6564 3d32 290a 2020 2020  expected=2).    
+00005ef0: 7065 726d 203d 206d 622e 7069 7865 6c5f  perm = mb.pixel_
+00005f00: 7368 7566 666c 6528 783d 696e 7075 7473  shuffle(x=inputs
+00005f10: 5b30 5d2c 2075 7073 6361 6c65 5f66 6163  [0], upscale_fac
+00005f20: 746f 723d 696e 7075 7473 5b31 5d2c 206e  tor=inputs[1], n
+00005f30: 616d 653d 6e6f 6465 2e6e 616d 6529 0a20  ame=node.name). 
+00005f40: 2020 2063 6f6e 7465 7874 2e61 6464 2870     context.add(p
+00005f50: 6572 6d29 0a0a 0a40 7265 6769 7374 6572  erm)...@register
+00005f60: 5f74 6f72 6368 5f6f 700a 6465 6620 7069  _torch_op.def pi
+00005f70: 7865 6c5f 756e 7368 7566 666c 6528 636f  xel_unshuffle(co
+00005f80: 6e74 6578 742c 206e 6f64 6529 3a0a 2020  ntext, node):.  
+00005f90: 2020 696e 7075 7473 203d 205f 6765 745f    inputs = _get_
+00005fa0: 696e 7075 7473 2863 6f6e 7465 7874 2c20  inputs(context, 
+00005fb0: 6e6f 6465 2c20 6578 7065 6374 6564 3d32  node, expected=2
+00005fc0: 290a 2020 2020 646f 776e 7363 616c 655f  ).    downscale_
+00005fd0: 6661 6374 6f72 203d 205f 6e70 2e75 696e  factor = _np.uin
+00005fe0: 7433 3228 696e 7075 7473 5b31 5d2e 7661  t32(inputs[1].va
+00005ff0: 6c29 0a20 2020 2070 6572 6d20 3d20 6d62  l).    perm = mb
+00006000: 2e70 6978 656c 5f75 6e73 6875 6666 6c65  .pixel_unshuffle
+00006010: 2878 3d69 6e70 7574 735b 305d 2c20 646f  (x=inputs[0], do
+00006020: 776e 7363 616c 655f 6661 6374 6f72 3d64  wnscale_factor=d
+00006030: 6f77 6e73 6361 6c65 5f66 6163 746f 722c  ownscale_factor,
+00006040: 206e 616d 653d 6e6f 6465 2e6e 616d 6529   name=node.name)
+00006050: 0a20 2020 2063 6f6e 7465 7874 2e61 6464  .    context.add
+00006060: 2870 6572 6d29 0a0a 0a40 7265 6769 7374  (perm)...@regist
+00006070: 6572 5f74 6f72 6368 5f6f 7028 746f 7263  er_torch_op(torc
+00006080: 685f 616c 6961 733d 5b22 626d 6d22 5d29  h_alias=["bmm"])
+00006090: 0a64 6566 206d 6174 6d75 6c28 636f 6e74  .def matmul(cont
+000060a0: 6578 742c 206e 6f64 6529 3a0a 2020 2020  ext, node):.    
+000060b0: 696e 7075 7473 203d 205f 6765 745f 696e  inputs = _get_in
+000060c0: 7075 7473 2863 6f6e 7465 7874 2c20 6e6f  puts(context, no
+000060d0: 6465 2c20 6578 7065 6374 6564 3d32 290a  de, expected=2).
+000060e0: 2020 2020 6966 2069 6e70 7574 735b 315d      if inputs[1]
+000060f0: 2e76 616c 2069 7320 6e6f 7420 4e6f 6e65  .val is not None
+00006100: 2061 6e64 205c 0a20 2020 2020 2020 2020   and \.         
+00006110: 2020 206c 656e 2869 6e70 7574 735b 315d     len(inputs[1]
+00006120: 2e73 6861 7065 2920 3d3d 2032 2061 6e64  .shape) == 2 and
+00006130: 206c 656e 2869 6e70 7574 735b 305d 2e73   len(inputs[0].s
+00006140: 6861 7065 2920 3c3d 2033 3a0a 2020 2020  hape) <= 3:.    
+00006150: 2020 2020 7265 7320 3d20 6d62 2e6c 696e      res = mb.lin
+00006160: 6561 7228 783d 696e 7075 7473 5b30 5d2c  ear(x=inputs[0],
+00006170: 2077 6569 6768 743d 5f6e 702e 7472 616e   weight=_np.tran
+00006180: 7370 6f73 6528 696e 7075 7473 5b31 5d2e  spose(inputs[1].
+00006190: 7661 6c29 2c20 6e61 6d65 3d6e 6f64 652e  val), name=node.
+000061a0: 6e61 6d65 290a 2020 2020 656c 7365 3a0a  name).    else:.
+000061b0: 2020 2020 2020 2020 7265 7320 3d20 6d62          res = mb
+000061c0: 2e6d 6174 6d75 6c28 783d 696e 7075 7473  .matmul(x=inputs
+000061d0: 5b30 5d2c 2079 3d69 6e70 7574 735b 315d  [0], y=inputs[1]
+000061e0: 2c20 6e61 6d65 3d6e 6f64 652e 6e61 6d65  , name=node.name
+000061f0: 290a 2020 2020 636f 6e74 6578 742e 6164  ).    context.ad
+00006200: 6428 7265 7329 0a0a 0a40 7265 6769 7374  d(res)...@regist
+00006210: 6572 5f74 6f72 6368 5f6f 700a 6465 6620  er_torch_op.def 
+00006220: 6164 6428 636f 6e74 6578 742c 206e 6f64  add(context, nod
+00006230: 6529 3a0a 2020 2020 6164 645f 696e 7075  e):.    add_inpu
+00006240: 7473 203d 205f 6765 745f 696e 7075 7473  ts = _get_inputs
+00006250: 2863 6f6e 7465 7874 2c20 6e6f 6465 290a  (context, node).
+00006260: 2020 2020 6173 7365 7274 206c 656e 286e      assert len(n
+00006270: 6f64 652e 6f75 7470 7574 7329 203d 3d20  ode.outputs) == 
+00006280: 310a 0a20 2020 2023 2054 4f44 4f20 2873  1..    # TODO (s
+00006290: 6265 7261 7264 6929 3a20 3372 6420 7061  berardi): 3rd pa
+000062a0: 7261 6d20 746f 2061 7465 6e3a 3a61 6464  ram to aten::add
+000062b0: 2069 7320 6120 7363 616c 6520 6661 6374   is a scale fact
+000062c0: 6f72 2c20 6e65 6564 2074 6f20 6861 6e64  or, need to hand
+000062d0: 6c65 2074 6861 742e 0a20 2020 2023 206f  le that..    # o
+000062e0: 7574 3d69 6e70 7574 2b61 6c70 6861 2078  ut=input+alpha x
+000062f0: 206f 7468 6572 0a20 2020 2023 2072 6461   other.    # rda
+00006300: 723a 2f2f 3630 3137 3537 3336 0a20 2020  r://60175736.   
+00006310: 2069 6620 6c65 6e28 6164 645f 696e 7075   if len(add_inpu
+00006320: 7473 2920 3e20 3220 616e 6420 6164 645f  ts) > 2 and add_
+00006330: 696e 7075 7473 5b32 5d2e 7661 6c20 213d  inputs[2].val !=
+00006340: 2031 3a0a 2020 2020 2020 2020 7261 6973   1:.        rais
+00006350: 6520 5661 6c75 6545 7272 6f72 2822 4144  e ValueError("AD
+00006360: 4420 646f 6573 206e 6f74 2073 7570 706f  D does not suppo
+00006370: 7274 2073 6361 6c65 2066 6163 746f 7220  rt scale factor 
+00006380: 7061 7261 6d22 290a 2020 2020 782c 2079  param").    x, y
+00006390: 203d 2070 726f 6d6f 7465 5f69 6e70 7574   = promote_input
+000063a0: 5f64 7479 7065 7328 6164 645f 696e 7075  _dtypes(add_inpu
+000063b0: 7473 5b3a 325d 290a 2020 2020 6164 645f  ts[:2]).    add_
+000063c0: 6e6f 6465 203d 206d 622e 6164 6428 783d  node = mb.add(x=
+000063d0: 782c 2079 3d79 2c20 6e61 6d65 3d6e 6f64  x, y=y, name=nod
+000063e0: 652e 6e61 6d65 290a 2020 2020 636f 6e74  e.name).    cont
+000063f0: 6578 742e 6164 6428 6164 645f 6e6f 6465  ext.add(add_node
+00006400: 290a 0a0a 4072 6567 6973 7465 725f 746f  )...@register_to
+00006410: 7263 685f 6f70 0a64 6566 2063 756d 7375  rch_op.def cumsu
+00006420: 6d28 636f 6e74 6578 742c 206e 6f64 6529  m(context, node)
+00006430: 3a0a 2020 2020 696e 7075 7473 203d 205f  :.    inputs = _
+00006440: 6765 745f 696e 7075 7473 2863 6f6e 7465  get_inputs(conte
+00006450: 7874 2c20 6e6f 6465 2c20 6578 7065 6374  xt, node, expect
+00006460: 6564 3d33 290a 2020 2020 7820 3d20 696e  ed=3).    x = in
+00006470: 7075 7473 5b30 5d0a 2020 2020 6966 2069  puts[0].    if i
+00006480: 735f 626f 6f6c 2878 2e64 7479 7065 293a  s_bool(x.dtype):
+00006490: 0a20 2020 2020 2020 2078 203d 206d 622e  .        x = mb.
+000064a0: 6361 7374 2878 3d78 2c20 6474 7970 653d  cast(x=x, dtype=
+000064b0: 2769 6e74 3332 2729 0a20 2020 2072 6573  'int32').    res
+000064c0: 203d 206d 622e 6375 6d73 756d 2878 3d78   = mb.cumsum(x=x
+000064d0: 2c20 6178 6973 3d69 6e70 7574 735b 315d  , axis=inputs[1]
+000064e0: 2c20 6e61 6d65 3d6e 6f64 652e 6e61 6d65  , name=node.name
+000064f0: 290a 2020 2020 636f 6e74 6578 742e 6164  ).    context.ad
+00006500: 6428 7265 7329 0a0a 0a40 7265 6769 7374  d(res)...@regist
+00006510: 6572 5f74 6f72 6368 5f6f 700a 6465 6620  er_torch_op.def 
+00006520: 6164 646d 6d28 636f 6e74 6578 742c 206e  addmm(context, n
+00006530: 6f64 6529 3a0a 2020 2020 2320 6164 646d  ode):.    # addm
+00006540: 6d28 5465 6e73 6f72 2069 6e70 7574 2c20  m(Tensor input, 
+00006550: 5465 6e73 6f72 206d 6174 312c 2054 656e  Tensor mat1, Ten
+00006560: 736f 7220 6d61 7432 2c20 5363 616c 6172  sor mat2, Scalar
+00006570: 2062 6574 613d 312c 2053 6361 6c61 7220   beta=1, Scalar 
+00006580: 616c 7068 613d 3129 0a20 2020 2023 206f  alpha=1).    # o
+00006590: 7574 7075 7420 3d20 6265 7461 202a 2069  utput = beta * i
+000065a0: 6e70 7574 202b 2061 6c70 6861 202a 206d  nput + alpha * m
+000065b0: 6174 3120 2a20 6d61 7432 0a0a 2020 2020  at1 * mat2..    
+000065c0: 6173 7365 7274 206c 656e 286e 6f64 652e  assert len(node.
+000065d0: 6f75 7470 7574 7329 203d 3d20 310a 2020  outputs) == 1.  
+000065e0: 2020 696e 7075 7473 203d 205f 6765 745f    inputs = _get_
+000065f0: 696e 7075 7473 2863 6f6e 7465 7874 2c20  inputs(context, 
+00006600: 6e6f 6465 2c20 6578 7065 6374 6564 3d35  node, expected=5
+00006610: 290a 2020 2020 6269 6173 203d 2069 6e70  ).    bias = inp
+00006620: 7574 735b 305d 0a20 2020 206d 6174 3120  uts[0].    mat1 
+00006630: 3d20 696e 7075 7473 5b31 5d0a 2020 2020  = inputs[1].    
+00006640: 6d61 7432 203d 2069 6e70 7574 735b 325d  mat2 = inputs[2]
+00006650: 0a20 2020 2062 6574 6120 3d20 696e 7075  .    beta = inpu
+00006660: 7473 5b33 5d0a 2020 2020 616c 7068 6120  ts[3].    alpha 
+00006670: 3d20 696e 7075 7473 5b34 5d0a 0a20 2020  = inputs[4]..   
+00006680: 2069 6620 6265 7461 2e76 616c 2021 3d20   if beta.val != 
+00006690: 312e 303a 0a20 2020 2020 2020 2023 2041  1.0:.        # A
+000066a0: 7070 6c79 2073 6361 6c69 6e67 2066 6163  pply scaling fac
+000066b0: 746f 7220 6265 7461 2074 6f20 7468 6520  tor beta to the 
+000066c0: 6269 6173 2e0a 2020 2020 2020 2020 6269  bias..        bi
+000066d0: 6173 203d 206d 622e 6d75 6c28 783d 6265  as = mb.mul(x=be
+000066e0: 7461 2c20 793d 6269 6173 2c20 6e61 6d65  ta, y=bias, name
+000066f0: 3d62 6961 732e 6e61 6d65 202b 2022 5f73  =bias.name + "_s
+00006700: 6361 6c65 6422 290a 2020 2020 2020 2020  caled").        
+00006710: 636f 6e74 6578 742e 6164 6428 6269 6173  context.add(bias
+00006720: 290a 0a20 2020 2069 6620 616c 7068 612e  )..    if alpha.
+00006730: 7661 6c20 213d 2031 2e30 3a0a 2020 2020  val != 1.0:.    
+00006740: 2020 2020 2320 4170 706c 7920 7363 616c      # Apply scal
+00006750: 696e 6720 6661 6374 6f72 2061 6c70 6861  ing factor alpha
+00006760: 2074 6f20 7468 6520 696e 7075 742e 0a20   to the input.. 
+00006770: 2020 2020 2020 206d 6174 3120 3d20 6d62         mat1 = mb
+00006780: 2e6d 756c 2878 3d61 6c70 6861 2c20 793d  .mul(x=alpha, y=
+00006790: 6d61 7431 2c20 6e61 6d65 3d6d 6174 312e  mat1, name=mat1.
+000067a0: 6e61 6d65 202b 2022 5f73 6361 6c65 6422  name + "_scaled"
+000067b0: 290a 2020 2020 2020 2020 636f 6e74 6578  ).        contex
+000067c0: 742e 6164 6428 6d61 7431 290a 0a20 2020  t.add(mat1)..   
+000067d0: 2023 204d 494c 206c 696e 6561 7220 7769   # MIL linear wi
+000067e0: 6c6c 2074 7261 6e73 706f 7365 206d 6174  ll transpose mat
+000067f0: 322c 2062 7574 2061 6464 6d6d 2065 7870  2, but addmm exp
+00006800: 6563 7473 2074 6861 7420 6d61 7431 2061  ects that mat1 a
+00006810: 6e64 206d 6174 320a 2020 2020 2320 6361  nd mat2.    # ca
+00006820: 6e20 6d75 6c74 6970 6c79 2061 7320 6973  n multiply as is
+00006830: 2e20 536f 2077 6520 6164 6420 6120 7472  . So we add a tr
+00006840: 616e 706f 7365 2e0a 2020 2020 6d61 7432  anpose..    mat2
+00006850: 203d 206d 622e 7472 616e 7370 6f73 6528   = mb.transpose(
+00006860: 783d 6d61 7432 2c20 7065 726d 3d5b 312c  x=mat2, perm=[1,
+00006870: 2030 5d2c 206e 616d 653d 6d61 7432 2e6e   0], name=mat2.n
+00006880: 616d 6520 2b20 225f 7472 616e 7370 6f73  ame + "_transpos
+00006890: 6564 2229 0a20 2020 2063 6f6e 7465 7874  ed").    context
+000068a0: 2e61 6464 286d 6174 3229 0a0a 2020 2020  .add(mat2)..    
+000068b0: 6164 646d 6d5f 6e6f 6465 203d 206d 622e  addmm_node = mb.
+000068c0: 6c69 6e65 6172 2878 3d6d 6174 312c 2077  linear(x=mat1, w
+000068d0: 6569 6768 743d 6d61 7432 2c20 6269 6173  eight=mat2, bias
+000068e0: 3d62 6961 732c 206e 616d 653d 6e6f 6465  =bias, name=node
+000068f0: 2e6e 616d 6529 0a20 2020 2063 6f6e 7465  .name).    conte
+00006900: 7874 2e61 6464 2861 6464 6d6d 5f6e 6f64  xt.add(addmm_nod
+00006910: 6529 0a0a 0a40 7265 6769 7374 6572 5f74  e)...@register_t
+00006920: 6f72 6368 5f6f 700a 6465 6620 6c69 6e65  orch_op.def line
+00006930: 6172 2863 6f6e 7465 7874 2c20 6e6f 6465  ar(context, node
+00006940: 293a 0a20 2020 2069 6e70 7574 7320 3d20  ):.    inputs = 
+00006950: 5f67 6574 5f69 6e70 7574 7328 636f 6e74  _get_inputs(cont
+00006960: 6578 742c 206e 6f64 652c 2065 7870 6563  ext, node, expec
+00006970: 7465 643d 5b32 2c20 335d 290a 2020 2020  ted=[2, 3]).    
+00006980: 7820 3d20 696e 7075 7473 5b30 5d0a 2020  x = inputs[0].  
+00006990: 2020 5720 3d20 696e 7075 7473 5b31 5d0a    W = inputs[1].
+000069a0: 2020 2020 6269 6173 203d 2069 6e70 7574      bias = input
+000069b0: 735b 325d 2069 6620 6c65 6e28 6e6f 6465  s[2] if len(node
+000069c0: 2e69 6e70 7574 7329 203d 3d20 3320 656c  .inputs) == 3 el
+000069d0: 7365 204e 6f6e 650a 2020 2020 7265 7320  se None.    res 
+000069e0: 3d20 6d62 2e6c 696e 6561 7228 783d 782c  = mb.linear(x=x,
+000069f0: 2077 6569 6768 743d 572c 2062 6961 733d   weight=W, bias=
+00006a00: 6269 6173 2c20 6e61 6d65 3d6e 6f64 652e  bias, name=node.
+00006a10: 6e61 6d65 290a 2020 2020 636f 6e74 6578  name).    contex
+00006a20: 742e 6164 6428 7265 7329 0a0a 0a40 7265  t.add(res)...@re
+00006a30: 6769 7374 6572 5f74 6f72 6368 5f6f 7028  gister_torch_op(
+00006a40: 746f 7263 685f 616c 6961 733d 5b22 636f  torch_alias=["co
+00006a50: 6e76 3264 225d 290a 6465 6620 5f63 6f6e  nv2d"]).def _con
+00006a60: 766f 6c75 7469 6f6e 2863 6f6e 7465 7874  volution(context
+00006a70: 2c20 6e6f 6465 293a 0a20 2020 2069 6e70  , node):.    inp
+00006a80: 7574 7320 3d20 5f67 6574 5f69 6e70 7574  uts = _get_input
+00006a90: 7328 636f 6e74 6578 742c 206e 6f64 6529  s(context, node)
+00006aa0: 0a0a 2020 2020 7820 3d20 696e 7075 7473  ..    x = inputs
+00006ab0: 5b30 5d0a 2020 2020 2320 5079 546f 7263  [0].    # PyTorc
+00006ac0: 6820 616e 6420 4d49 4c20 6861 7320 7361  h and MIL has sa
+00006ad0: 6d65 2077 6569 6768 7420 6c61 796f 7574  me weight layout
+00006ae0: 0a20 2020 2023 2043 6f6e 763a 205b 436f  .    # Conv: [Co
+00006af0: 7574 2c20 4369 6e2c 202a 445d 0a20 2020  ut, Cin, *D].   
+00006b00: 2023 2043 6f6e 7654 7261 6e73 706f 7365   # ConvTranspose
+00006b10: 3a20 5b43 696e 2c20 436f 7574 2c20 2a44  : [Cin, Cout, *D
+00006b20: 5d0a 2020 2020 7765 6967 6874 203d 2069  ].    weight = i
+00006b30: 6e70 7574 735b 315d 0a20 2020 2062 6961  nputs[1].    bia
+00006b40: 7320 3d20 696e 7075 7473 5b32 5d0a 2020  s = inputs[2].  
+00006b50: 2020 7374 7269 6465 7320 3d20 696e 7075    strides = inpu
+00006b60: 7473 5b33 5d0a 0a20 2020 2078 2c20 7765  ts[3]..    x, we
+00006b70: 6967 6874 203d 2070 726f 6d6f 7465 5f69  ight = promote_i
+00006b80: 6e70 7574 5f64 7479 7065 7328 5b78 2c20  nput_dtypes([x, 
+00006b90: 7765 6967 6874 5d29 0a0a 2020 2020 2320  weight])..    # 
+00006ba0: 4578 7061 6e64 2070 6164 6469 6e67 2e20  Expand padding. 
+00006bb0: 546f 7263 6820 6163 6365 7074 7320 6569  Torch accepts ei
+00006bc0: 7468 6572 2061 6e20 696e 7420 2866 6f72  ther an int (for
+00006bd0: 2061 6c6c 2064 696d 656e 7369 6f6e 7329   all dimensions)
+00006be0: 206f 7220 616e 206e 2d74 7570 6c65 206f   or an n-tuple o
+00006bf0: 6620 696e 7473 2028 6f6e 6520 7065 7220  f ints (one per 
+00006c00: 6469 6d65 6e73 696f 6e29 2c20 6275 740a  dimension), but.
+00006c10: 2020 2020 2320 7765 2072 6571 7569 7265      # we require
+00006c20: 2061 2028 3220 2a20 6e29 2d74 7570 6c65   a (2 * n)-tuple
+00006c30: 2c20 7768 6572 6520 6e20 6973 2074 6865  , where n is the
+00006c40: 206e 756d 6265 7220 6f66 2073 7061 7469   number of spati
+00006c50: 616c 2064 696d 656e 7369 6f6e 732c 2073  al dimensions, s
+00006c60: 7461 7274 2061 6e64 2065 6e64 2066 6f72  tart and end for
+00006c70: 2065 6163 6820 7370 6174 6961 6c20 6469   each spatial di
+00006c80: 6d65 6e73 696f 6e0a 2020 2020 7061 6420  mension.    pad 
+00006c90: 3d20 696e 7075 7473 5b34 5d2e 7661 6c0a  = inputs[4].val.
+00006ca0: 0a20 2020 2069 6620 6c65 6e28 7765 6967  .    if len(weig
+00006cb0: 6874 2e73 6861 7065 2920 696e 2028 332c  ht.shape) in (3,
+00006cc0: 2034 293a 0a20 2020 2020 2020 2023 2031   4):.        # 1
+00006cd0: 4420 616e 6420 3244 3a20 4e65 6564 2074  D and 2D: Need t
+00006ce0: 6f20 6578 706c 6963 6974 6c79 2073 7461  o explicitly sta
+00006cf0: 7465 204c 2d52 2c20 542d 4220 7061 640a  te L-R, T-B pad.
+00006d00: 2020 2020 2020 2020 7061 6420 3d20 5f6e          pad = _n
+00006d10: 702e 7265 7065 6174 2870 6164 2c20 3229  p.repeat(pad, 2)
+00006d20: 0a20 2020 2065 6c69 6620 6c65 6e28 7765  .    elif len(we
+00006d30: 6967 6874 2e73 6861 7065 2920 3d3d 2035  ight.shape) == 5
+00006d40: 3a0a 2020 2020 2020 2020 2320 3344 3a20  :.        # 3D: 
+00006d50: 4e65 6564 2074 6f20 6578 706c 6963 6974  Need to explicit
+00006d60: 6c79 2073 7461 7465 2046 2d42 6b2c 204c  ly state F-Bk, L
+00006d70: 2d52 2c20 542d 4220 7061 640a 2020 2020  -R, T-B pad.    
+00006d80: 2020 2020 6966 2074 7970 6528 7061 6429      if type(pad)
+00006d90: 203d 3d20 696e 743a 0a20 2020 2020 2020   == int:.       
+00006da0: 2020 2020 2070 6164 203d 205f 6e70 2e72       pad = _np.r
+00006db0: 6570 6561 7428 7061 642c 2036 290a 2020  epeat(pad, 6).  
+00006dc0: 2020 2020 2020 656c 6966 206c 656e 2870        elif len(p
+00006dd0: 6164 2920 3d3d 2033 3a0a 2020 2020 2020  ad) == 3:.      
+00006de0: 2020 2020 2020 7061 6420 3d20 5f6e 702e        pad = _np.
+00006df0: 7265 7065 6174 2870 6164 2c20 3229 0a20  repeat(pad, 2). 
+00006e00: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
+00006e10: 2072 6169 7365 2056 616c 7565 4572 726f   raise ValueErro
+00006e20: 7228 0a20 2020 2020 2020 2020 2020 2022  r(.            "
+00006e30: 496e 7661 6c69 6420 7765 6967 6874 2064  Invalid weight d
+00006e40: 696d 656e 7369 6f6e 2e20 4d75 7374 2062  imension. Must b
+00006e50: 6520 332c 2034 2c20 6f72 2035 2066 6f72  e 3, 4, or 5 for
+00006e60: 2031 442c 2032 442c 206f 7220 3344 2063   1D, 2D, or 3D c
+00006e70: 6f6e 766f 6c75 7469 6f6e 2c20 7265 7370  onvolution, resp
+00006e80: 6563 7469 7665 6c79 2e22 0a20 2020 2020  ectively.".     
+00006e90: 2020 2029 0a0a 2020 2020 6469 6c61 7469     )..    dilati
+00006ea0: 6f6e 7320 3d20 696e 7075 7473 5b35 5d0a  ons = inputs[5].
+00006eb0: 2020 2020 6f75 745f 7061 6420 3d20 4e6f      out_pad = No
+00006ec0: 6e65 0a20 2020 2069 6620 6c65 6e28 696e  ne.    if len(in
+00006ed0: 7075 7473 2920 3e3d 2031 323a 0a20 2020  puts) >= 12:.   
+00006ee0: 2020 2020 2074 7261 6e73 706f 7365 6420       transposed 
+00006ef0: 3d20 696e 7075 7473 5b36 5d2e 7661 6c0a  = inputs[6].val.
+00006f00: 2020 2020 2020 2020 6f75 745f 7061 6420          out_pad 
+00006f10: 3d20 696e 7075 7473 5b37 5d2e 7661 6c0a  = inputs[7].val.
+00006f20: 2020 2020 2020 2020 6772 6f75 7020 3d20          group = 
+00006f30: 696e 7075 7473 5b38 5d0a 2020 2020 656c  inputs[8].    el
+00006f40: 6966 206c 656e 2869 6e70 7574 7329 203d  if len(inputs) =
+00006f50: 3d20 373a 0a20 2020 2020 2020 2074 7261  = 7:.        tra
+00006f60: 6e73 706f 7365 6420 3d20 4661 6c73 650a  nsposed = False.
+00006f70: 2020 2020 2020 2020 6772 6f75 7020 3d20          group = 
+00006f80: 696e 7075 7473 5b36 5d0a 2020 2020 656c  inputs[6].    el
+00006f90: 7365 3a0a 2020 2020 2020 2020 7261 6973  se:.        rais
+00006fa0: 6520 5661 6c75 6545 7272 6f72 280a 2020  e ValueError(.  
+00006fb0: 2020 2020 2020 2020 2020 2275 6e65 7870            "unexp
+00006fc0: 6563 7465 6420 6e75 6d62 6572 206f 6620  ected number of 
+00006fd0: 696e 7075 7473 2066 6f72 206e 6f64 6520  inputs for node 
+00006fe0: 7b7d 2028 7b7d 293a 207b 7d22 2e66 6f72  {} ({}): {}".for
+00006ff0: 6d61 7428 0a20 2020 2020 2020 2020 2020  mat(.           
+00007000: 2020 2020 206e 6f64 652e 6e61 6d65 2c20       node.name, 
+00007010: 6e6f 6465 2e6b 696e 642c 206c 656e 2869  node.kind, len(i
+00007020: 6e70 7574 7329 0a20 2020 2020 2020 2020  nputs).         
+00007030: 2020 2029 0a20 2020 2020 2020 2029 0a0a     ).        )..
+00007040: 2020 2020 6b77 6172 6773 203d 207b 0a20      kwargs = {. 
+00007050: 2020 2020 2020 2022 7822 3a20 782c 0a20         "x": x,. 
+00007060: 2020 2020 2020 2022 7765 6967 6874 223a         "weight":
+00007070: 2077 6569 6768 742c 0a20 2020 2020 2020   weight,.       
+00007080: 2022 7374 7269 6465 7322 3a20 7374 7269   "strides": stri
+00007090: 6465 732c 0a20 2020 2020 2020 2022 7061  des,.        "pa
+000070a0: 645f 7479 7065 223a 2022 6375 7374 6f6d  d_type": "custom
+000070b0: 222c 0a20 2020 2020 2020 2022 7061 6422  ",.        "pad"
+000070c0: 3a20 7061 642c 0a20 2020 2020 2020 2022  : pad,.        "
+000070d0: 6469 6c61 7469 6f6e 7322 3a20 6469 6c61  dilations": dila
+000070e0: 7469 6f6e 732c 0a20 2020 2020 2020 2022  tions,.        "
+000070f0: 6772 6f75 7073 223a 2067 726f 7570 2c0a  groups": group,.
+00007100: 2020 2020 2020 2020 226e 616d 6522 3a20          "name": 
+00007110: 6e6f 6465 2e6e 616d 652c 0a20 2020 207d  node.name,.    }
+00007120: 0a20 2020 2023 2042 6961 7320 6973 206f  .    # Bias is o
+00007130: 7074 696f 6e61 6c20 696e 2050 7954 6f72  ptional in PyTor
+00007140: 6368 2773 2063 6f6e 766f 6c75 7469 6f6e  ch's convolution
+00007150: 2e0a 2020 2020 6966 2062 6961 7320 6973  ..    if bias is
+00007160: 206e 6f74 204e 6f6e 653a 0a20 2020 2020   not None:.     
+00007170: 2020 206b 7761 7267 735b 2262 6961 7322     kwargs["bias"
+00007180: 5d20 3d20 6269 6173 0a0a 2020 2020 6966  ] = bias..    if
+00007190: 2074 7261 6e73 706f 7365 6420 6973 2054   transposed is T
+000071a0: 7275 653a 0a20 2020 2020 2020 2023 2054  rue:.        # T
+000071b0: 7261 6e73 706f 7365 6420 636f 6e76 6f6c  ransposed convol
+000071c0: 7574 696f 6e0a 2020 2020 2020 2020 2320  ution.        # 
+000071d0: 4861 6e64 6c65 206f 7574 7075 745f 7061  Handle output_pa
+000071e0: 6464 696e 6720 7573 696e 6720 7072 652d  dding using pre-
+000071f0: 7061 6420 6f72 2070 6f73 742d 6372 6f70  pad or post-crop
+00007200: 0a20 2020 2020 2020 2070 7265 5f70 6164  .        pre_pad
+00007210: 203d 205b 305d 202a 206c 656e 2870 6164   = [0] * len(pad
+00007220: 290a 2020 2020 2020 2020 706f 7374 5f63  ).        post_c
+00007230: 726f 7020 3d20 5b30 5d20 2a20 6c65 6e28  rop = [0] * len(
+00007240: 7061 6429 0a0a 2020 2020 2020 2020 6966  pad)..        if
+00007250: 206f 7574 5f70 6164 2069 7320 6e6f 7420   out_pad is not 
+00007260: 4e6f 6e65 2061 6e64 2061 6e79 286f 7574  None and any(out
+00007270: 5f70 6164 293a 0a20 2020 2020 2020 2020  _pad):.         
+00007280: 2020 206f 7574 7075 745f 7061 6464 696e     output_paddin
+00007290: 6720 3d20 5b30 5d20 2a20 6c65 6e28 7061  g = [0] * len(pa
+000072a0: 6429 0a20 2020 2020 2020 2020 2020 2023  d).            #
+000072b0: 206f 7574 7075 7420 7061 6464 696e 6720   output padding 
+000072c0: 6164 6473 2061 6464 6974 696f 6e61 6c20  adds additional 
+000072d0: 7061 6464 696e 6720 6f6e 206f 6e65 206f  padding on one o
+000072e0: 6620 7468 6520 7369 6465 206f 6620 6469  f the side of di
+000072f0: 6d65 6e73 696f 6e0a 2020 2020 2020 2020  mension.        
+00007300: 2020 2020 2320 692e 652e 2062 6f74 746f      # i.e. botto
+00007310: 6d20 6672 6f6d 2074 6f70 2d62 6f74 746f  m from top-botto
+00007320: 6d2c 0a20 2020 2020 2020 2020 2020 2023  m,.            #
+00007330: 2020 2020 2020 7269 6768 7420 2066 726f        right  fro
+00007340: 6d20 6c65 6674 2d72 6967 6874 0a20 2020  m left-right.   
+00007350: 2020 2020 2020 2020 2023 2020 2020 2020           #      
+00007360: 6261 636b 2020 2066 726f 6d20 6672 6f6e  back   from fron
+00007370: 742d 6261 636b 0a20 2020 2020 2020 2020  t-back.         
+00007380: 2020 2023 2043 6f72 6520 4d4c 2070 6164     # Core ML pad
+00007390: 6469 6e67 2073 7472 7563 7475 7265 2069  ding structure i
+000073a0: 7320 7369 6d69 6c61 7220 5b74 6f70 2c20  s similar [top, 
+000073b0: 626f 7474 6f6d 2c20 6c65 6674 2c20 7269  bottom, left, ri
+000073c0: 6768 745d 0a20 2020 2020 2020 2020 2020  ght].           
+000073d0: 2023 206d 6170 7069 6e67 206f 7574 7075   # mapping outpu
+000073e0: 745f 7061 6464 696e 6720 746f 2073 696d  t_padding to sim
+000073f0: 706c 6966 7920 6675 7274 6865 7220 7072  plify further pr
+00007400: 6f63 6573 7369 6e67 210a 2020 2020 2020  ocessing!.      
+00007410: 2020 2020 2020 230a 2020 2020 2020 2020        #.        
+00007420: 2020 2020 2320 466f 7220 436f 6e76 5472      # For ConvTr
+00007430: 616e 7370 6f73 6532 643a 205b 626f 7474  anspose2d: [bott
+00007440: 6f6d 2c20 7269 6768 745d 202d 3e20 5b30  om, right] -> [0
+00007450: 2c20 622c 2030 2c20 725d 0a20 2020 2020  , b, 0, r].     
+00007460: 2020 2020 2020 206f 7574 7075 745f 7061         output_pa
+00007470: 6464 696e 6720 3d20 5b0a 2020 2020 2020  dding = [.      
+00007480: 2020 2020 2020 2020 2020 3020 6966 2069            0 if i
+00007490: 2025 2032 203d 3d20 3020 656c 7365 206f   % 2 == 0 else o
+000074a0: 7574 5f70 6164 5b69 202f 2f20 325d 2066  ut_pad[i // 2] f
+000074b0: 6f72 2069 2069 6e20 7261 6e67 6528 6c65  or i in range(le
+000074c0: 6e28 7061 6429 290a 2020 2020 2020 2020  n(pad)).        
+000074d0: 2020 2020 5d0a 2020 2020 2020 2020 2020      ].          
+000074e0: 2020 6966 2073 756d 2870 6164 2920 3d3d    if sum(pad) ==
+000074f0: 2030 2061 6e64 2061 6e79 286f 7574 7075   0 and any(outpu
+00007500: 745f 7061 6464 696e 6729 3a0a 2020 2020  t_padding):.    
+00007510: 2020 2020 2020 2020 2020 2020 7261 6973              rais
+00007520: 6520 5661 6c75 6545 7272 6f72 280a 2020  e ValueError(.  
+00007530: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007540: 2020 2243 6f6e 7654 7261 6e73 706f 7365    "ConvTranspose
+00007550: 2063 6f6e 6669 6775 7261 7469 6f6e 206f   configuration o
+00007560: 6620 7061 6464 696e 673d 3020 616e 6420  f padding=0 and 
+00007570: 6f75 7470 7574 5f70 6164 6469 6e67 203e  output_padding >
+00007580: 2030 206e 6f74 2073 7570 706f 7274 6564   0 not supported
+00007590: 2122 0a20 2020 2020 2020 2020 2020 2020  !".             
+000075a0: 2020 2029 0a20 2020 2020 2020 2020 2020     ).           
+000075b0: 2070 6f73 745f 6372 6f70 203d 2070 6164   post_crop = pad
+000075c0: 2e63 6f70 7928 290a 2020 2020 2020 2020  .copy().        
+000075d0: 2020 2020 7061 6420 2a3d 2030 0a20 2020      pad *= 0.   
+000075e0: 2020 2020 2020 2020 2066 6f72 2069 2069           for i i
+000075f0: 6e20 7261 6e67 6528 302c 206c 656e 2870  n range(0, len(p
+00007600: 6164 2929 3a0a 2020 2020 2020 2020 2020  ad)):.          
+00007610: 2020 2020 2020 6966 2070 6f73 745f 6372        if post_cr
+00007620: 6f70 5b69 5d20 3e3d 206f 7574 7075 745f  op[i] >= output_
+00007630: 7061 6464 696e 675b 695d 3a0a 2020 2020  padding[i]:.    
+00007640: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007650: 706f 7374 5f63 726f 705b 695d 202d 3d20  post_crop[i] -= 
+00007660: 6f75 7470 7574 5f70 6164 6469 6e67 5b69  output_padding[i
+00007670: 5d0a 2020 2020 2020 2020 2020 2020 2020  ].              
+00007680: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
+00007690: 2020 2020 2020 2020 2020 2020 7072 655f              pre_
+000076a0: 7061 645b 695d 203d 206f 7574 7075 745f  pad[i] = output_
+000076b0: 7061 6464 696e 675b 695d 202d 2070 6f73  padding[i] - pos
+000076c0: 745f 6372 6f70 5b69 5d0a 2020 2020 2020  t_crop[i].      
+000076d0: 2020 2020 2020 6b77 6172 6773 5b22 7061        kwargs["pa
+000076e0: 6422 5d20 3d20 7072 655f 7061 640a 2020  d"] = pre_pad.  
+000076f0: 2020 2020 2020 2020 2020 6966 2061 6e79            if any
+00007700: 2870 7265 5f70 6164 293a 0a20 2020 2020  (pre_pad):.     
+00007710: 2020 2020 2020 2020 2020 2023 2043 6f6e             # Con
+00007720: 7374 616e 7420 7061 6420 7265 7175 6972  stant pad requir
+00007730: 6573 2070 6164 2074 6f20 6265 206f 6620  es pad to be of 
+00007740: 6c65 6e67 7468 2032 2a69 6e70 7574 5f72  length 2*input_r
+00007750: 616e 6b0a 2020 2020 2020 2020 2020 2020  ank.            
+00007760: 2020 2020 7072 655f 7061 6420 3d20 5b30      pre_pad = [0
+00007770: 5d20 2a20 3220 2a20 286c 656e 2878 2e73  ] * 2 * (len(x.s
+00007780: 6861 7065 2920 2d20 3229 202b 2070 7265  hape) - 2) + pre
+00007790: 5f70 6164 0a20 2020 2020 2020 2020 2020  _pad.           
+000077a0: 2020 2020 2078 203d 206d 622e 7061 6428       x = mb.pad(
+000077b0: 783d 782c 2070 6164 3d70 7265 5f70 6164  x=x, pad=pre_pad
+000077c0: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
+000077d0: 2020 6b77 6172 6773 5b22 7822 5d20 3d20    kwargs["x"] = 
+000077e0: 780a 2020 2020 2020 2020 2020 2020 6966  x.            if
+000077f0: 2061 6e79 2870 6f73 745f 6372 6f70 293a   any(post_crop):
+00007800: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00007810: 2064 656c 206b 7761 7267 735b 226e 616d   del kwargs["nam
+00007820: 6522 5d0a 0a20 2020 2020 2020 2063 6f6e  e"]..        con
+00007830: 7620 3d20 6d62 2e63 6f6e 765f 7472 616e  v = mb.conv_tran
+00007840: 7370 6f73 6528 2a2a 6b77 6172 6773 290a  spose(**kwargs).
+00007850: 2020 2020 2020 2020 6966 2061 6e79 2870          if any(p
+00007860: 6f73 745f 6372 6f70 293a 0a20 2020 2020  ost_crop):.     
+00007870: 2020 2020 2020 2023 2054 4f44 4f3a 2072         # TODO: r
+00007880: 6461 723a 2f2f 3635 3537 3538 3236 2028  dar://65575826 (
+00007890: 5079 546f 7263 6820 636f 6e76 6572 7465  PyTorch converte
+000078a0: 723a 206f 7574 7075 745f 7061 6464 696e  r: output_paddin
+000078b0: 6720 6d61 7070 696e 6720 746f 2073 6c69  g mapping to sli
+000078c0: 6365 0a20 2020 2020 2020 2020 2020 2023  ce.            #
+000078d0: 2069 6e73 7465 6164 206f 6620 6372 6f70   instead of crop
+000078e0: 206c 6179 6572 2066 6f72 2031 2061 6e64   layer for 1 and
+000078f0: 2033 4420 436f 6e76 5472 616e 7370 6f73   3D ConvTranspos
+00007900: 6529 0a20 2020 2020 2020 2020 2020 2069  e).            i
+00007910: 6620 6c65 6e28 706f 7374 5f63 726f 7029  f len(post_crop)
+00007920: 203d 3d20 3220 616e 6420 636f 6e76 2e72   == 2 and conv.r
+00007930: 616e 6b20 3d3d 2033 3a0a 2020 2020 2020  ank == 3:.      
+00007940: 2020 2020 2020 2020 2020 2320 4e75 6d62            # Numb
+00007950: 6572 206f 6620 656c 656d 656e 7473 2074  er of elements t
+00007960: 6f20 6372 6f70 2066 726f 6d20 7269 6768  o crop from righ
+00007970: 7420 3d20 706f 7374 5f63 726f 705b 2d31  t = post_crop[-1
+00007980: 5d2e 0a20 2020 2020 2020 2020 2020 2020  ]..             
+00007990: 2020 2023 2053 696e 6365 2073 6c69 6369     # Since slici
+000079a0: 6e67 2073 7570 706f 7274 7320 6e65 6761  ng supports nega
+000079b0: 7469 7665 2069 6e64 6578 696e 672c 2065  tive indexing, e
+000079c0: 6e64 5f69 6420 3d20 2d31 202a 2070 6f73  nd_id = -1 * pos
+000079d0: 745f 6372 6f70 5b2d 315d 0a20 2020 2020  t_crop[-1].     
+000079e0: 2020 2020 2020 2020 2020 2063 6f6e 7620             conv 
+000079f0: 3d20 6d62 2e73 6c69 6365 5f62 795f 696e  = mb.slice_by_in
+00007a00: 6465 7828 0a20 2020 2020 2020 2020 2020  dex(.           
+00007a10: 2020 2020 2020 2020 2078 3d63 6f6e 762c           x=conv,
+00007a20: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00007a30: 2020 2020 2062 6567 696e 3d5b 302c 2030       begin=[0, 0
+00007a40: 2c20 706f 7374 5f63 726f 705b 305d 5d2c  , post_crop[0]],
+00007a50: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00007a60: 2020 2020 2065 6e64 3d5b 302c 2030 2c20       end=[0, 0, 
+00007a70: 2d31 202a 2070 6f73 745f 6372 6f70 5b2d  -1 * post_crop[-
+00007a80: 315d 5d2c 0a20 2020 2020 2020 2020 2020  1]],.           
+00007a90: 2020 2020 2020 2020 2062 6567 696e 5f6d           begin_m
+00007aa0: 6173 6b3d 5b54 7275 652c 2054 7275 652c  ask=[True, True,
+00007ab0: 2046 616c 7365 5d2c 0a20 2020 2020 2020   False],.       
+00007ac0: 2020 2020 2020 2020 2020 2020 2065 6e64               end
+00007ad0: 5f6d 6173 6b3d 5b54 7275 652c 2054 7275  _mask=[True, Tru
+00007ae0: 652c 2046 616c 7365 5d2c 0a20 2020 2020  e, False],.     
+00007af0: 2020 2020 2020 2020 2020 2020 2020 206e                 n
+00007b00: 616d 653d 6e6f 6465 2e6e 616d 652c 0a20  ame=node.name,. 
+00007b10: 2020 2020 2020 2020 2020 2020 2020 2029                 )
+00007b20: 0a20 2020 2020 2020 2020 2020 2065 6c69  .            eli
+00007b30: 6620 6c65 6e28 706f 7374 5f63 726f 7029  f len(post_crop)
+00007b40: 203d 3d20 3420 616e 6420 636f 6e76 2e72   == 4 and conv.r
+00007b50: 616e 6b20 3d3d 2034 3a0a 2020 2020 2020  ank == 4:.      
+00007b60: 2020 2020 2020 2020 2020 636f 6e76 203d            conv =
+00007b70: 206d 622e 6372 6f70 280a 2020 2020 2020   mb.crop(.      
+00007b80: 2020 2020 2020 2020 2020 2020 2020 783d                x=
+00007b90: 636f 6e76 2c0a 2020 2020 2020 2020 2020  conv,.          
+00007ba0: 2020 2020 2020 2020 2020 6372 6f70 5f68            crop_h
+00007bb0: 6569 6768 743d 706f 7374 5f63 726f 705b  eight=post_crop[
+00007bc0: 3a32 5d2c 0a20 2020 2020 2020 2020 2020  :2],.           
+00007bd0: 2020 2020 2020 2020 2063 726f 705f 7769           crop_wi
+00007be0: 6474 683d 706f 7374 5f63 726f 705b 323a  dth=post_crop[2:
+00007bf0: 345d 2c0a 2020 2020 2020 2020 2020 2020  4],.            
+00007c00: 2020 2020 2020 2020 6e61 6d65 3d6e 6f64          name=nod
+00007c10: 652e 6e61 6d65 2c0a 2020 2020 2020 2020  e.name,.        
+00007c20: 2020 2020 2020 2020 290a 2020 2020 2020          ).      
+00007c30: 2020 2020 2020 656c 7365 3a0a 2020 2020        else:.    
+00007c40: 2020 2020 2020 2020 2020 2020 7261 6973              rais
+00007c50: 6520 5661 6c75 6545 7272 6f72 280a 2020  e ValueError(.  
+00007c60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007c70: 2020 226f 7574 7075 745f 7061 6464 696e    "output_paddin
+00007c80: 6720 6973 2073 7570 706f 7274 6564 206f  g is supported o
+00007c90: 6e6c 7920 666f 7220 436f 6e76 5472 616e  nly for ConvTran
+00007ca0: 7370 6f73 6531 4420 6f72 2043 6f6e 7654  spose1D or ConvT
+00007cb0: 7261 6e73 706f 7365 3244 2122 0a20 2020  ranspose2D!".   
+00007cc0: 2020 2020 2020 2020 2020 2020 2029 0a20               ). 
+00007cd0: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
+00007ce0: 2023 204e 6f72 6d61 6c20 636f 6e76 6f6c   # Normal convol
+00007cf0: 7574 696f 6e0a 2020 2020 2020 2020 636f  ution.        co
+00007d00: 6e76 203d 206d 622e 636f 6e76 282a 2a6b  nv = mb.conv(**k
+00007d10: 7761 7267 7329 0a20 2020 2063 6f6e 7465  wargs).    conte
+00007d20: 7874 2e61 6464 2863 6f6e 7629 0a0a 0a23  xt.add(conv)...#
+00007d30: 2043 6f6e 766f 6c75 7469 6f6e 2077 6974   Convolution wit
+00007d40: 6820 2273 616d 652c 2076 616c 6964 2220  h "same, valid" 
+00007d50: 7061 6464 696e 670a 4072 6567 6973 7465  padding.@registe
+00007d60: 725f 746f 7263 685f 6f70 0a64 6566 205f  r_torch_op.def _
+00007d70: 636f 6e76 6f6c 7574 696f 6e5f 6d6f 6465  convolution_mode
+00007d80: 2863 6f6e 7465 7874 2c20 6e6f 6465 293a  (context, node):
+00007d90: 0a20 2020 2069 6e70 7574 7320 3d20 5f67  .    inputs = _g
+00007da0: 6574 5f69 6e70 7574 7328 636f 6e74 6578  et_inputs(contex
+00007db0: 742c 206e 6f64 652c 2065 7870 6563 7465  t, node, expecte
+00007dc0: 643d 3729 0a20 2020 206d 6f64 6520 3d20  d=7).    mode = 
+00007dd0: 696e 7075 7473 5b34 5d2e 7661 6c0a 0a20  inputs[4].val.. 
+00007de0: 2020 2063 6f6e 7465 7874 2e61 6464 280a     context.add(.
+00007df0: 2020 2020 2020 2020 6d62 2e63 6f6e 7628          mb.conv(
+00007e00: 0a20 2020 2020 2020 2020 2020 2078 3d69  .            x=i
+00007e10: 6e70 7574 735b 305d 2c0a 2020 2020 2020  nputs[0],.      
+00007e20: 2020 2020 2020 7765 6967 6874 3d69 6e70        weight=inp
+00007e30: 7574 735b 315d 2c0a 2020 2020 2020 2020  uts[1],.        
+00007e40: 2020 2020 6269 6173 3d69 6e70 7574 735b      bias=inputs[
+00007e50: 325d 2c0a 2020 2020 2020 2020 2020 2020  2],.            
+00007e60: 7374 7269 6465 733d 696e 7075 7473 5b33  strides=inputs[3
+00007e70: 5d2c 0a20 2020 2020 2020 2020 2020 2070  ],.            p
+00007e80: 6164 5f74 7970 653d 6d6f 6465 2c0a 2020  ad_type=mode,.  
+00007e90: 2020 2020 2020 2020 2020 6469 6c61 7469            dilati
+00007ea0: 6f6e 733d 696e 7075 7473 5b35 5d2c 0a20  ons=inputs[5],. 
+00007eb0: 2020 2020 2020 2020 2020 2067 726f 7570             group
+00007ec0: 733d 696e 7075 7473 5b36 5d2c 0a20 2020  s=inputs[6],.   
+00007ed0: 2020 2020 2020 2020 206e 616d 653d 6e6f           name=no
+00007ee0: 6465 2e6e 616d 652c 0a20 2020 2020 2020  de.name,.       
+00007ef0: 2029 0a20 2020 2029 0a0a 0a40 7265 6769   ).    )...@regi
+00007f00: 7374 6572 5f74 6f72 6368 5f6f 700a 6465  ster_torch_op.de
+00007f10: 6620 736f 6674 6d61 7828 636f 6e74 6578  f softmax(contex
+00007f20: 742c 206e 6f64 6529 3a0a 2020 2020 696e  t, node):.    in
+00007f30: 7075 7473 203d 205f 6765 745f 696e 7075  puts = _get_inpu
+00007f40: 7473 2863 6f6e 7465 7874 2c20 6e6f 6465  ts(context, node
+00007f50: 290a 0a20 2020 2078 203d 2069 6e70 7574  )..    x = input
+00007f60: 735b 305d 0a20 2020 2061 7869 7320 3d20  s[0].    axis = 
+00007f70: 696e 7075 7473 5b31 5d0a 2020 2020 7265  inputs[1].    re
+00007f80: 7320 3d20 6d62 2e73 6f66 746d 6178 2878  s = mb.softmax(x
+00007f90: 3d78 2c20 6178 6973 3d61 7869 732c 206e  =x, axis=axis, n
+00007fa0: 616d 653d 6e6f 6465 2e6e 616d 6529 0a20  ame=node.name). 
+00007fb0: 2020 2063 6f6e 7465 7874 2e61 6464 2872     context.add(r
+00007fc0: 6573 290a 0a0a 4072 6567 6973 7465 725f  es)...@register_
+00007fd0: 746f 7263 685f 6f70 0a64 6566 2066 6c61  torch_op.def fla
+00007fe0: 7474 656e 2863 6f6e 7465 7874 2c20 6e6f  tten(context, no
+00007ff0: 6465 293a 0a20 2020 2069 6e70 7574 7320  de):.    inputs 
+00008000: 3d20 5f67 6574 5f69 6e70 7574 7328 636f  = _get_inputs(co
+00008010: 6e74 6578 742c 206e 6f64 6529 0a0a 2020  ntext, node)..  
+00008020: 2020 7820 3d20 696e 7075 7473 5b30 5d0a    x = inputs[0].
+00008030: 2020 2020 6469 6d73 203d 206c 6973 7428      dims = list(
+00008040: 782e 7368 6170 6529 0a20 2020 2073 7461  x.shape).    sta
+00008050: 7274 5f76 616c 203d 2069 6e70 7574 735b  rt_val = inputs[
+00008060: 315d 2e76 616c 0a20 2020 2065 6e64 5f76  1].val.    end_v
+00008070: 616c 203d 2069 6e70 7574 735b 325d 2e76  al = inputs[2].v
+00008080: 616c 0a0a 2020 2020 7374 6172 7420 3d20  al..    start = 
+00008090: 6c65 6e28 6469 6d73 2920 2b20 7374 6172  len(dims) + star
+000080a0: 745f 7661 6c20 6966 2073 7461 7274 5f76  t_val if start_v
+000080b0: 616c 203c 2030 2065 6c73 6520 7374 6172  al < 0 else star
+000080c0: 745f 7661 6c0a 2020 2020 656e 6420 3d20  t_val.    end = 
+000080d0: 6c65 6e28 6469 6d73 2920 2b20 656e 645f  len(dims) + end_
+000080e0: 7661 6c20 6966 2065 6e64 5f76 616c 203c  val if end_val <
+000080f0: 2030 2065 6c73 6520 656e 645f 7661 6c0a   0 else end_val.
+00008100: 0a20 2020 2069 6620 7374 6172 7420 3e20  .    if start > 
+00008110: 6c65 6e28 6469 6d73 2920 6f72 2065 6e64  len(dims) or end
+00008120: 203e 206c 656e 2864 696d 7329 206f 7220   > len(dims) or 
+00008130: 7374 6172 7420 3c20 3020 6f72 2065 6e64  start < 0 or end
+00008140: 203c 2030 3a0a 2020 2020 2020 2020 7261   < 0:.        ra
+00008150: 6973 6520 5661 6c75 6545 7272 6f72 280a  ise ValueError(.
+00008160: 2020 2020 2020 2020 2020 2020 2249 6e76              "Inv
+00008170: 616c 6964 2073 7461 7274 2061 6e64 2065  alid start and e
+00008180: 6e64 2e20 2873 7461 7274 2c20 656e 6429  nd. (start, end)
+00008190: 203d 3d20 287b 7d2c 207b 7d29 222e 666f   == ({}, {})".fo
+000081a0: 726d 6174 2873 7461 7274 2c20 656e 645f  rmat(start, end_
+000081b0: 7661 6c29 0a20 2020 2020 2020 2029 0a20  val).        ). 
+000081c0: 2020 2069 6620 7374 6172 7420 3e20 656e     if start > en
+000081d0: 643a 0a20 2020 2020 2020 2072 6169 7365  d:.        raise
+000081e0: 2056 616c 7565 4572 726f 7228 0a20 2020   ValueError(.   
+000081f0: 2020 2020 2020 2020 2022 5374 6172 7420           "Start 
+00008200: 6d75 7374 2062 6520 6265 666f 7265 2065  must be before e
+00008210: 6e64 2e20 2873 7461 7274 2c20 656e 6429  nd. (start, end)
+00008220: 203d 3d20 287b 7d2c 207b 7d29 222e 666f   == ({}, {})".fo
+00008230: 726d 6174 2873 7461 7274 2c20 656e 645f  rmat(start, end_
+00008240: 7661 6c29 0a20 2020 2020 2020 2029 0a20  val).        ). 
+00008250: 2020 2078 5f73 6861 7065 203d 206d 622e     x_shape = mb.
+00008260: 7368 6170 6528 783d 7829 0a0a 2020 2020  shape(x=x)..    
+00008270: 7368 6170 6531 203d 206d 622e 736c 6963  shape1 = mb.slic
+00008280: 655f 6279 5f69 6e64 6578 2878 3d78 5f73  e_by_index(x=x_s
+00008290: 6861 7065 2c20 6265 6769 6e3d 5b30 5d2c  hape, begin=[0],
+000082a0: 2065 6e64 3d5b 7374 6172 745d 290a 2020   end=[start]).  
+000082b0: 2020 7368 6170 6532 203d 206d 622e 736c    shape2 = mb.sl
+000082c0: 6963 655f 6279 5f69 6e64 6578 2878 3d78  ice_by_index(x=x
+000082d0: 5f73 6861 7065 2c20 6265 6769 6e3d 5b65  _shape, begin=[e
+000082e0: 6e64 202b 2031 5d2c 2065 6e64 3d5b 6c65  nd + 1], end=[le
+000082f0: 6e28 6469 6d73 295d 290a 0a20 2020 2066  n(dims)])..    f
+00008300: 6c61 7474 656e 5f64 696d 203d 202d 310a  latten_dim = -1.
+00008310: 2020 2020 6966 206e 6f74 2061 6e79 5f73      if not any_s
+00008320: 796d 626f 6c69 6328 782e 7368 6170 6529  ymbolic(x.shape)
+00008330: 3a0a 2020 2020 2020 2020 666c 6174 7465  :.        flatte
+00008340: 6e5f 6469 6d20 3d20 310a 2020 2020 2020  n_dim = 1.      
+00008350: 2020 666f 7220 6469 6d20 696e 2064 696d    for dim in dim
+00008360: 735b 7374 6172 743a 2065 6e64 202b 2031  s[start: end + 1
+00008370: 5d3a 0a20 2020 2020 2020 2020 2020 2066  ]:.            f
+00008380: 6c61 7474 656e 5f64 696d 202a 3d20 6469  latten_dim *= di
+00008390: 6d0a 0a20 2020 2073 6861 7065 203d 206d  m..    shape = m
+000083a0: 622e 636f 6e63 6174 2876 616c 7565 733d  b.concat(values=
+000083b0: 2873 6861 7065 312c 205b 666c 6174 7465  (shape1, [flatte
+000083c0: 6e5f 6469 6d5d 2c20 7368 6170 6532 292c  n_dim], shape2),
+000083d0: 2061 7869 733d 3029 0a20 2020 2073 6861   axis=0).    sha
+000083e0: 7065 203d 206d 622e 6361 7374 2878 3d73  pe = mb.cast(x=s
+000083f0: 6861 7065 2c20 6474 7970 653d 2269 6e74  hape, dtype="int
+00008400: 3332 2229 0a20 2020 2072 6573 6861 7065  32").    reshape
+00008410: 203d 206d 622e 7265 7368 6170 6528 783d   = mb.reshape(x=
+00008420: 782c 2073 6861 7065 3d73 6861 7065 2c20  x, shape=shape, 
+00008430: 6e61 6d65 3d6e 6f64 652e 6e61 6d65 290a  name=node.name).
+00008440: 2020 2020 636f 6e74 6578 742e 6164 6428      context.add(
+00008450: 7265 7368 6170 6529 0a0a 0a40 7265 6769  reshape)...@regi
+00008460: 7374 6572 5f74 6f72 6368 5f6f 700a 6465  ster_torch_op.de
+00008470: 6620 5f72 6573 6861 7065 5f66 726f 6d5f  f _reshape_from_
+00008480: 7465 6e73 6f72 2863 6f6e 7465 7874 2c20  tensor(context, 
+00008490: 6e6f 6465 293a 0a20 2020 2069 6e70 7574  node):.    input
+000084a0: 7320 3d20 5f67 6574 5f69 6e70 7574 7328  s = _get_inputs(
+000084b0: 636f 6e74 6578 742c 206e 6f64 652c 2065  context, node, e
+000084c0: 7870 6563 7465 643d 3229 0a0a 2020 2020  xpected=2)..    
+000084d0: 7265 7368 6170 6520 3d20 6d62 2e72 6573  reshape = mb.res
+000084e0: 6861 7065 2878 3d69 6e70 7574 735b 305d  hape(x=inputs[0]
+000084f0: 2c20 7368 6170 653d 696e 7075 7473 5b31  , shape=inputs[1
+00008500: 5d2c 206e 616d 653d 6e6f 6465 2e6e 616d  ], name=node.nam
+00008510: 6529 0a20 2020 2063 6f6e 7465 7874 2e61  e).    context.a
+00008520: 6464 2872 6573 6861 7065 290a 0a0a 4072  dd(reshape)...@r
+00008530: 6567 6973 7465 725f 746f 7263 685f 6f70  egister_torch_op
+00008540: 0a64 6566 2073 6f66 7473 6967 6e28 636f  .def softsign(co
+00008550: 6e74 6578 742c 206e 6f64 6529 3a0a 2020  ntext, node):.  
+00008560: 2020 696e 7075 7473 203d 205f 6765 745f    inputs = _get_
+00008570: 696e 7075 7473 2863 6f6e 7465 7874 2c20  inputs(context, 
+00008580: 6e6f 6465 2c20 6578 7065 6374 6564 3d31  node, expected=1
+00008590: 290a 0a20 2020 2072 6573 203d 206d 622e  )..    res = mb.
+000085a0: 736f 6674 7369 676e 2878 3d69 6e70 7574  softsign(x=input
+000085b0: 735b 305d 2c20 6e61 6d65 3d6e 6f64 652e  s[0], name=node.
+000085c0: 6e61 6d65 290a 2020 2020 636f 6e74 6578  name).    contex
+000085d0: 742e 6164 6428 7265 7329 0a0a 0a40 7265  t.add(res)...@re
+000085e0: 6769 7374 6572 5f74 6f72 6368 5f6f 700a  gister_torch_op.
+000085f0: 6465 6620 7265 6c75 2863 6f6e 7465 7874  def relu(context
+00008600: 2c20 6e6f 6465 293a 0a20 2020 2069 6e70  , node):.    inp
+00008610: 7574 7320 3d20 5f67 6574 5f69 6e70 7574  uts = _get_input
+00008620: 7328 636f 6e74 6578 742c 206e 6f64 652c  s(context, node,
+00008630: 2065 7870 6563 7465 643d 3129 0a0a 2020   expected=1)..  
+00008640: 2020 7265 7320 3d20 6d62 2e72 656c 7528    res = mb.relu(
+00008650: 783d 696e 7075 7473 5b30 5d2c 206e 616d  x=inputs[0], nam
+00008660: 653d 6e6f 6465 2e6e 616d 6529 0a20 2020  e=node.name).   
+00008670: 2063 6f6e 7465 7874 2e61 6464 2872 6573   context.add(res
+00008680: 290a 0a0a 4072 6567 6973 7465 725f 746f  )...@register_to
+00008690: 7263 685f 6f70 0a64 6566 2070 7265 6c75  rch_op.def prelu
+000086a0: 2863 6f6e 7465 7874 2c20 6e6f 6465 293a  (context, node):
+000086b0: 0a20 2020 2069 6e70 7574 7320 3d20 5f67  .    inputs = _g
+000086c0: 6574 5f69 6e70 7574 7328 636f 6e74 6578  et_inputs(contex
+000086d0: 742c 206e 6f64 652c 2065 7870 6563 7465  t, node, expecte
+000086e0: 643d 3229 0a20 2020 2078 203d 2069 6e70  d=2).    x = inp
+000086f0: 7574 735b 305d 0a20 2020 2061 6c70 6861  uts[0].    alpha
+00008700: 203d 2069 6e70 7574 735b 315d 0a20 2020   = inputs[1].   
+00008710: 2023 2049 6e20 7468 6520 4d49 4c20 6261   # In the MIL ba
+00008720: 636b 656e 642c 2069 7420 6173 7375 6d65  ckend, it assume
+00008730: 7320 7468 6174 2074 6865 2069 6e70 7574  s that the input
+00008740: 7320 6f66 2070 7265 6c75 2073 686f 756c  s of prelu shoul
+00008750: 6420 6861 7665 0a20 2020 2023 2061 7420  d have.    # at 
+00008760: 6c65 6173 7420 7261 6e6b 2033 2c20 692e  least rank 3, i.
+00008770: 652e 205b 6261 7463 682c 2063 6861 6e6e  e. [batch, chann
+00008780: 656c 2c20 7370 6174 6961 6c5f 6469 6d73  el, spatial_dims
+00008790: 2a5d 2e0a 2020 2020 6966 2078 2e72 616e  *]..    if x.ran
+000087a0: 6b20 3e3d 2032 3a0a 2020 2020 2020 2020  k >= 2:.        
+000087b0: 616c 7068 6120 3d20 616c 7068 612e 7661  alpha = alpha.va
+000087c0: 6c0a 2020 2020 2020 2020 616c 7068 6120  l.        alpha 
+000087d0: 3d20 5f6e 702e 6f6e 6573 2828 782e 7368  = _np.ones((x.sh
+000087e0: 6170 655b 315d 2c29 2920 2a20 616c 7068  ape[1],)) * alph
+000087f0: 610a 0a20 2020 2069 6620 782e 7261 6e6b  a..    if x.rank
+00008800: 203c 3d20 323a 0a20 2020 2020 2020 2061   <= 2:.        a
+00008810: 7865 7320 3d20 5b31 2c20 325d 2069 6620  xes = [1, 2] if 
+00008820: 782e 7261 6e6b 203d 3d20 3120 656c 7365  x.rank == 1 else
+00008830: 205b 325d 0a20 2020 2020 2020 2078 203d   [2].        x =
+00008840: 206d 622e 6578 7061 6e64 5f64 696d 7328   mb.expand_dims(
+00008850: 783d 782c 2061 7865 733d 6178 6573 290a  x=x, axes=axes).
+00008860: 2020 2020 2020 2020 7820 3d20 6d62 2e70          x = mb.p
+00008870: 7265 6c75 2878 3d78 2c20 616c 7068 613d  relu(x=x, alpha=
+00008880: 616c 7068 6129 0a20 2020 2020 2020 2072  alpha).        r
+00008890: 6573 203d 206d 622e 7371 7565 657a 6528  es = mb.squeeze(
+000088a0: 783d 782c 2061 7865 733d 6178 6573 2c20  x=x, axes=axes, 
+000088b0: 6e61 6d65 3d6e 6f64 652e 6e61 6d65 290a  name=node.name).
+000088c0: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
+000088d0: 2020 7265 7320 3d20 6d62 2e70 7265 6c75    res = mb.prelu
+000088e0: 2878 3d78 2c20 616c 7068 613d 616c 7068  (x=x, alpha=alph
+000088f0: 612c 206e 616d 653d 6e6f 6465 2e6e 616d  a, name=node.nam
+00008900: 6529 0a0a 2020 2020 636f 6e74 6578 742e  e)..    context.
+00008910: 6164 6428 7265 7329 0a0a 0a40 7265 6769  add(res)...@regi
+00008920: 7374 6572 5f74 6f72 6368 5f6f 700a 6465  ster_torch_op.de
+00008930: 6620 6c69 6e73 7061 6365 2863 6f6e 7465  f linspace(conte
+00008940: 7874 2c20 6e6f 6465 293a 0a20 2020 2069  xt, node):.    i
+00008950: 6e70 7574 7320 3d20 5f67 6574 5f69 6e70  nputs = _get_inp
+00008960: 7574 7328 636f 6e74 6578 742c 206e 6f64  uts(context, nod
+00008970: 652c 206d 696e 5f65 7870 6563 7465 643d  e, min_expected=
+00008980: 3329 0a0a 2020 2020 7374 6172 7420 3d20  3)..    start = 
+00008990: 696e 7075 7473 5b30 5d0a 2020 2020 656e  inputs[0].    en
+000089a0: 6420 3d20 696e 7075 7473 5b31 5d0a 2020  d = inputs[1].  
+000089b0: 2020 6e75 6d73 203d 2069 6e70 7574 735b    nums = inputs[
+000089c0: 325d 0a20 2020 2073 7461 7274 203d 206d  2].    start = m
+000089d0: 622e 6361 7374 2878 3d73 7461 7274 2c20  b.cast(x=start, 
+000089e0: 6474 7970 653d 2266 7033 3222 290a 2020  dtype="fp32").  
+000089f0: 2020 656e 6420 3d20 6d62 2e63 6173 7428    end = mb.cast(
+00008a00: 783d 656e 642c 2064 7479 7065 3d22 6670  x=end, dtype="fp
+00008a10: 3332 2229 0a0a 2020 2020 6966 2073 7461  32")..    if sta
+00008a20: 7274 2e63 616e 5f62 655f 666f 6c64 6564  rt.can_be_folded
+00008a30: 5f74 6f5f 636f 6e73 7428 2920 616e 6420  _to_const() and 
+00008a40: 656e 642e 6361 6e5f 6265 5f66 6f6c 6465  end.can_be_folde
+00008a50: 645f 746f 5f63 6f6e 7374 2829 2061 6e64  d_to_const() and
+00008a60: 206e 756d 732e 6361 6e5f 6265 5f66 6f6c   nums.can_be_fol
+00008a70: 6465 645f 746f 5f63 6f6e 7374 2829 3a0a  ded_to_const():.
+00008a80: 2020 2020 2020 2020 7374 6172 745f 7661          start_va
+00008a90: 6c20 3d20 7374 6172 742e 7661 6c0a 2020  l = start.val.  
+00008aa0: 2020 2020 2020 656e 645f 7661 6c20 3d20        end_val = 
+00008ab0: 656e 642e 7661 6c0a 2020 2020 2020 2020  end.val.        
+00008ac0: 6e75 6d73 5f76 616c 203d 206e 756d 732e  nums_val = nums.
+00008ad0: 7661 6c0a 2020 2020 2020 2020 6966 206e  val.        if n
+00008ae0: 756d 735f 7661 6c20 3c20 4d41 585f 5349  ums_val < MAX_SI
+00008af0: 5a45 5f43 4f4e 5354 414e 545f 464f 4c44  ZE_CONSTANT_FOLD
+00008b00: 494e 473a 0a20 2020 2020 2020 2020 2020  ING:.           
+00008b10: 2072 6573 203d 206d 622e 636f 6e73 7428   res = mb.const(
+00008b20: 7661 6c3d 5f6e 702e 6c69 6e73 7061 6365  val=_np.linspace
+00008b30: 2873 7461 7274 5f76 616c 2c20 656e 645f  (start_val, end_
+00008b40: 7661 6c2c 206e 756d 735f 7661 6c29 2c20  val, nums_val), 
+00008b50: 6e61 6d65 3d6e 6f64 652e 6e61 6d65 290a  name=node.name).
+00008b60: 2020 2020 2020 2020 2020 2020 636f 6e74              cont
+00008b70: 6578 742e 6164 6428 7265 7329 0a20 2020  ext.add(res).   
+00008b80: 2020 2020 2020 2020 2072 6574 7572 6e0a           return.
+00008b90: 0a20 2020 2069 6620 6e75 6d73 2e76 616c  .    if nums.val
+00008ba0: 2069 7320 4e6f 6e65 3a0a 2020 2020 2020   is None:.      
+00008bb0: 2020 6d73 6720 3d20 2244 796e 616d 6963    msg = "Dynamic
+00008bc0: 2073 7465 7073 2069 6e70 7574 2066 6f72   steps input for
+00008bd0: 2074 6f72 6368 2e6c 696e 7370 6163 6520   torch.linspace 
+00008be0: 6973 206e 6f74 2073 7570 706f 7274 6564  is not supported
+00008bf0: 2e20 506c 6561 7365 2075 7365 2074 6f72  . Please use tor
+00008c00: 6368 2e61 7261 6e67 6520 696e 7374 6561  ch.arange instea
+00008c10: 6422 0a20 2020 2020 2020 2072 6169 7365  d".        raise
+00008c20: 204e 6f74 496d 706c 656d 656e 7465 6445   NotImplementedE
+00008c30: 7272 6f72 286d 7367 290a 2020 2020 656c  rror(msg).    el
+00008c40: 7365 3a0a 2020 2020 2020 2020 6966 206e  se:.        if n
+00008c50: 756d 732e 7661 6c20 3d3d 2031 3a0a 2020  ums.val == 1:.  
+00008c60: 2020 2020 2020 2020 2020 7265 7320 3d20            res = 
+00008c70: 6d62 2e65 7870 616e 645f 6469 6d73 2878  mb.expand_dims(x
+00008c80: 3d73 7461 7274 2c20 6178 6573 3d5b 305d  =start, axes=[0]
+00008c90: 2c20 6e61 6d65 3d6e 6f64 652e 6e61 6d65  , name=node.name
+00008ca0: 290a 2020 2020 2020 2020 656c 7365 3a0a  ).        else:.
+00008cb0: 2020 2020 2020 2020 2020 2020 2320 7374              # st
+00008cc0: 6570 203d 2028 656e 6420 2d20 7374 6172  ep = (end - star
+00008cd0: 7429 202f 2028 6e75 6d73 202d 2031 290a  t) / (nums - 1).
+00008ce0: 2020 2020 2020 2020 2020 2020 7820 3d20              x = 
+00008cf0: 6d62 2e73 7562 2878 3d65 6e64 2c20 793d  mb.sub(x=end, y=
+00008d00: 7374 6172 7429 0a20 2020 2020 2020 2020  start).         
+00008d10: 2020 2079 203d 206d 622e 7375 6228 783d     y = mb.sub(x=
+00008d20: 6e75 6d73 2c20 793d 3129 0a20 2020 2020  nums, y=1).     
+00008d30: 2020 2020 2020 2078 203d 206d 622e 6361         x = mb.ca
+00008d40: 7374 2878 3d78 2c20 6474 7970 653d 2266  st(x=x, dtype="f
+00008d50: 7033 3222 290a 2020 2020 2020 2020 2020  p32").          
+00008d60: 2020 7920 3d20 6d62 2e63 6173 7428 783d    y = mb.cast(x=
+00008d70: 792c 2064 7479 7065 3d22 6670 3332 2229  y, dtype="fp32")
+00008d80: 0a20 2020 2020 2020 2020 2020 2073 7465  .            ste
+00008d90: 7020 3d20 6d62 2e72 6561 6c5f 6469 7628  p = mb.real_div(
+00008da0: 783d 782c 2079 3d79 290a 0a20 2020 2020  x=x, y=y)..     
+00008db0: 2020 2020 2020 2023 204e 6f74 6520 7468         # Note th
+00008dc0: 6174 2074 6865 2072 616e 6765 5f31 6420  at the range_1d 
+00008dd0: 6f70 2065 7863 6c75 6465 6420 7468 6520  op excluded the 
+00008de0: 656e 6420 706f 696e 742c 0a20 2020 2020  end point,.     
+00008df0: 2020 2020 2020 2023 2073 6f20 7765 2068         # so we h
+00008e00: 6176 6520 746f 2061 6464 2074 6865 2065  ave to add the e
+00008e10: 6e64 2062 6163 6b20 746f 2074 6865 2072  nd back to the r
+00008e20: 6573 756c 7469 6e67 2061 7272 6179 2e0a  esulting array..
+00008e30: 2020 2020 2020 2020 2020 2020 6172 616e              aran
+00008e40: 6765 203d 206d 622e 7261 6e67 655f 3164  ge = mb.range_1d
+00008e50: 2865 6e64 3d65 6e64 2c20 7374 6172 743d  (end=end, start=
+00008e60: 7374 6172 742c 2073 7465 703d 7374 6570  start, step=step
+00008e70: 290a 2020 2020 2020 2020 2020 2020 6e65  ).            ne
+00008e80: 775f 656e 6420 3d20 6d62 2e65 7870 616e  w_end = mb.expan
+00008e90: 645f 6469 6d73 2878 3d65 6e64 2c20 6178  d_dims(x=end, ax
+00008ea0: 6573 3d5b 305d 290a 2020 2020 2020 2020  es=[0]).        
+00008eb0: 2020 2020 7265 7320 3d20 6d62 2e63 6f6e      res = mb.con
+00008ec0: 6361 7428 7661 6c75 6573 3d5b 6172 616e  cat(values=[aran
+00008ed0: 6765 2c20 6e65 775f 656e 645d 2c20 6178  ge, new_end], ax
+00008ee0: 6973 3d30 2c20 6e61 6d65 3d6e 6f64 652e  is=0, name=node.
+00008ef0: 6e61 6d65 290a 2020 2020 636f 6e74 6578  name).    contex
+00008f00: 742e 6164 6428 7265 7329 0a0a 0a40 7265  t.add(res)...@re
+00008f10: 6769 7374 6572 5f74 6f72 6368 5f6f 700a  gister_torch_op.
+00008f20: 6465 6620 7265 6c75 3628 636f 6e74 6578  def relu6(contex
+00008f30: 742c 206e 6f64 6529 3a0a 2020 2020 696e  t, node):.    in
+00008f40: 7075 7473 203d 205f 6765 745f 696e 7075  puts = _get_inpu
+00008f50: 7473 2863 6f6e 7465 7874 2c20 6e6f 6465  ts(context, node
+00008f60: 2c20 6578 7065 6374 6564 3d31 290a 0a20  , expected=1).. 
+00008f70: 2020 2072 6573 203d 206d 622e 7265 6c75     res = mb.relu
+00008f80: 3628 783d 696e 7075 7473 5b30 5d2c 206e  6(x=inputs[0], n
+00008f90: 616d 653d 6e6f 6465 2e6e 616d 6529 0a20  ame=node.name). 
+00008fa0: 2020 2063 6f6e 7465 7874 2e61 6464 2872     context.add(r
+00008fb0: 6573 290a 0a0a 4072 6567 6973 7465 725f  es)...@register_
+00008fc0: 746f 7263 685f 6f70 0a64 6566 2065 696e  torch_op.def ein
+00008fd0: 7375 6d28 636f 6e74 6578 742c 206e 6f64  sum(context, nod
+00008fe0: 6529 3a0a 2020 2020 6120 3d20 636f 6e74  e):.    a = cont
+00008ff0: 6578 745b 6e6f 6465 2e69 6e70 7574 735b  ext[node.inputs[
+00009000: 315d 5d5b 305d 0a20 2020 2062 203d 2063  1]][0].    b = c
+00009010: 6f6e 7465 7874 5b6e 6f64 652e 696e 7075  ontext[node.inpu
+00009020: 7473 5b31 5d5d 5b31 5d0a 2020 2020 6571  ts[1]][1].    eq
+00009030: 7561 7469 6f6e 203d 2063 6f6e 7465 7874  uation = context
+00009040: 5b6e 6f64 652e 696e 7075 7473 5b30 5d5d  [node.inputs[0]]
+00009050: 2e76 616c 0a20 2020 2078 203d 2062 7569  .val.    x = bui
+00009060: 6c64 5f65 696e 7375 6d5f 6d69 6c28 612c  ld_einsum_mil(a,
+00009070: 2062 2c20 6571 7561 7469 6f6e 2c20 6e6f   b, equation, no
+00009080: 6465 2e6e 616d 6529 0a20 2020 2063 6f6e  de.name).    con
+00009090: 7465 7874 2e61 6464 2878 290a 0a0a 4072  text.add(x)...@r
+000090a0: 6567 6973 7465 725f 746f 7263 685f 6f70  egister_torch_op
+000090b0: 0a64 6566 2065 7965 2863 6f6e 7465 7874  .def eye(context
+000090c0: 2c20 6e6f 6465 293a 0a20 2020 2023 2054  , node):.    # T
+000090d0: 4f44 4f3a 2072 6461 723a 2f2f 3130 3434  ODO: rdar://1044
+000090e0: 3030 3536 3820 285b 5079 546f 7263 685d  00568 ([PyTorch]
+000090f0: 2055 7365 204d 494c 206f 7073 2074 6f20   Use MIL ops to 
+00009100: 636f 6e73 7472 7563 7420 7468 6520 6579  construct the ey
+00009110: 6520 6d61 7472 6978 2069 6e20 6f72 6465  e matrix in orde
+00009120: 7220 746f 2061 766f 6964 2064 6972 6563  r to avoid direc
+00009130: 746c 7920 666f 6c64 696e 6720 7468 6520  tly folding the 
+00009140: 696e 7075 7420 696e 746f 2061 2063 6f6e  input into a con
+00009150: 7374 290a 2020 2020 696e 7075 7473 203d  st).    inputs =
+00009160: 205f 6765 745f 696e 7075 7473 2863 6f6e   _get_inputs(con
+00009170: 7465 7874 2c20 6e6f 6465 2c20 6578 7065  text, node, expe
+00009180: 6374 6564 3d5b 352c 2036 5d29 0a20 2020  cted=[5, 6]).   
+00009190: 2069 6620 6c65 6e28 696e 7075 7473 2920   if len(inputs) 
+000091a0: 3d3d 2035 3a0a 2020 2020 2020 2020 6579  == 5:.        ey
+000091b0: 6520 3d20 5f6e 702e 6579 6528 696e 7075  e = _np.eye(inpu
+000091c0: 7473 5b30 5d2e 7661 6c29 0a20 2020 2069  ts[0].val).    i
+000091d0: 6620 6c65 6e28 696e 7075 7473 2920 3d3d  f len(inputs) ==
+000091e0: 2036 3a0a 2020 2020 2020 2020 6579 6520   6:.        eye 
+000091f0: 3d20 5f6e 702e 6579 6528 696e 7075 7473  = _np.eye(inputs
+00009200: 5b30 5d2e 7661 6c2c 2069 6e70 7574 735b  [0].val, inputs[
+00009210: 315d 2e76 616c 290a 2020 2020 6579 6520  1].val).    eye 
+00009220: 3d20 6d62 2e63 6f6e 7374 2876 616c 3d65  = mb.const(val=e
+00009230: 7965 2c20 6e61 6d65 3d6e 6f64 652e 6e61  ye, name=node.na
+00009240: 6d65 290a 2020 2020 636f 6e74 6578 742e  me).    context.
+00009250: 6164 6428 6579 6529 0a0a 0a40 7265 6769  add(eye)...@regi
+00009260: 7374 6572 5f74 6f72 6368 5f6f 700a 6465  ster_torch_op.de
+00009270: 6620 656c 7528 636f 6e74 6578 742c 206e  f elu(context, n
+00009280: 6f64 6529 3a0a 2020 2020 2323 2054 6f72  ode):.    ## Tor
+00009290: 6368 2070 6f72 7420 746f 2041 5465 6e20  ch port to ATen 
+000092a0: 6164 6473 2073 6361 6c65 2061 6e64 2069  adds scale and i
+000092b0: 6e70 7574 5f73 6361 6c65 2077 6869 6368  nput_scale which
+000092c0: 2069 7320 7365 7420 746f 2031 0a20 2020   is set to 1.   
+000092d0: 2069 6e70 7574 7320 3d20 5f67 6574 5f69   inputs = _get_i
+000092e0: 6e70 7574 7328 636f 6e74 6578 742c 206e  nputs(context, n
+000092f0: 6f64 652c 2065 7870 6563 7465 643d 3429  ode, expected=4)
+00009300: 0a0a 2020 2020 7265 7320 3d20 6d62 2e65  ..    res = mb.e
+00009310: 6c75 2878 3d69 6e70 7574 735b 305d 2c20  lu(x=inputs[0], 
+00009320: 616c 7068 613d 696e 7075 7473 5b31 5d2c  alpha=inputs[1],
+00009330: 206e 616d 653d 6e6f 6465 2e6e 616d 6529   name=node.name)
+00009340: 0a20 2020 2063 6f6e 7465 7874 2e61 6464  .    context.add
+00009350: 2872 6573 290a 0a0a 4072 6567 6973 7465  (res)...@registe
+00009360: 725f 746f 7263 685f 6f70 0a64 6566 206c  r_torch_op.def l
+00009370: 6561 6b79 5f72 656c 7528 636f 6e74 6578  eaky_relu(contex
+00009380: 742c 206e 6f64 6529 3a0a 2020 2020 696e  t, node):.    in
+00009390: 7075 7473 203d 205f 6765 745f 696e 7075  puts = _get_inpu
+000093a0: 7473 2863 6f6e 7465 7874 2c20 6e6f 6465  ts(context, node
+000093b0: 2c20 6578 7065 6374 6564 3d32 290a 0a20  , expected=2).. 
+000093c0: 2020 2072 6573 203d 206d 622e 6c65 616b     res = mb.leak
+000093d0: 795f 7265 6c75 2878 3d69 6e70 7574 735b  y_relu(x=inputs[
+000093e0: 305d 2c20 616c 7068 613d 696e 7075 7473  0], alpha=inputs
+000093f0: 5b31 5d2c 206e 616d 653d 6e6f 6465 2e6e  [1], name=node.n
+00009400: 616d 6529 0a20 2020 2063 6f6e 7465 7874  ame).    context
+00009410: 2e61 6464 2872 6573 290a 0a0a 4072 6567  .add(res)...@reg
+00009420: 6973 7465 725f 746f 7263 685f 6f70 0a64  ister_torch_op.d
+00009430: 6566 2072 7265 6c75 2863 6f6e 7465 7874  ef rrelu(context
+00009440: 2c20 6e6f 6465 293a 0a20 2020 2069 6e70  , node):.    inp
+00009450: 7574 7320 3d20 5f67 6574 5f69 6e70 7574  uts = _get_input
+00009460: 7328 636f 6e74 6578 742c 206e 6f64 652c  s(context, node,
+00009470: 2065 7870 6563 7465 643d 3529 0a0a 2020   expected=5)..  
+00009480: 2020 2320 416c 7068 6120 696e 2065 7661    # Alpha in eva
+00009490: 6c75 6174 696f 6e20 6d6f 6465 2069 7320  luation mode is 
+000094a0: 6a75 7374 2074 6865 2061 7665 7261 6765  just the average
+000094b0: 2062 6574 7765 656e 2075 7070 6572 2061   between upper a
+000094c0: 6e64 206c 6f77 6572 2e0a 2020 2020 6c6f  nd lower..    lo
+000094d0: 7765 725f 616c 7068 6120 3d20 696e 7075  wer_alpha = inpu
+000094e0: 7473 5b31 5d0a 2020 2020 7570 7065 725f  ts[1].    upper_
+000094f0: 616c 7068 6120 3d20 696e 7075 7473 5b32  alpha = inputs[2
+00009500: 5d0a 2020 2020 616c 7068 6120 3d20 286c  ].    alpha = (l
+00009510: 6f77 6572 5f61 6c70 6861 2e76 616c 202b  ower_alpha.val +
+00009520: 2075 7070 6572 5f61 6c70 6861 2e76 616c   upper_alpha.val
+00009530: 2920 2f20 320a 0a20 2020 2072 6573 203d  ) / 2..    res =
+00009540: 206d 622e 6c65 616b 795f 7265 6c75 2878   mb.leaky_relu(x
+00009550: 3d69 6e70 7574 735b 305d 2c20 616c 7068  =inputs[0], alph
+00009560: 613d 616c 7068 612c 206e 616d 653d 6e6f  a=alpha, name=no
+00009570: 6465 2e6e 616d 6529 0a20 2020 2063 6f6e  de.name).    con
+00009580: 7465 7874 2e61 6464 2872 6573 290a 0a0a  text.add(res)...
+00009590: 4072 6567 6973 7465 725f 746f 7263 685f  @register_torch_
+000095a0: 6f70 0a64 6566 2073 6f66 7470 6c75 7328  op.def softplus(
+000095b0: 636f 6e74 6578 742c 206e 6f64 6529 3a0a  context, node):.
+000095c0: 2020 2020 696e 7075 7473 203d 205f 6765      inputs = _ge
+000095d0: 745f 696e 7075 7473 2863 6f6e 7465 7874  t_inputs(context
+000095e0: 2c20 6e6f 6465 2c20 6578 7065 6374 6564  , node, expected
+000095f0: 3d33 290a 2020 2020 7820 3d20 696e 7075  =3).    x = inpu
+00009600: 7473 5b30 5d0a 2020 2020 6265 7461 5f20  ts[0].    beta_ 
+00009610: 3d20 696e 7075 7473 5b31 5d2e 7661 6c0a  = inputs[1].val.
+00009620: 2020 2020 4320 3d20 782e 7368 6170 655b      C = x.shape[
+00009630: 315d 0a20 2020 2061 6c70 6861 5f62 7220  1].    alpha_br 
+00009640: 3d20 5f6e 702e 7265 7065 6174 2831 2e30  = _np.repeat(1.0
+00009650: 202f 2062 6574 615f 2c20 4329 2e61 7374   / beta_, C).ast
+00009660: 7970 6528 2766 6c6f 6174 3332 2729 0a20  ype('float32'). 
+00009670: 2020 2062 6574 615f 6272 203d 205f 6e70     beta_br = _np
+00009680: 2e72 6570 6561 7428 6265 7461 5f2c 2043  .repeat(beta_, C
+00009690: 292e 6173 7479 7065 2827 666c 6f61 7433  ).astype('float3
+000096a0: 3227 290a 0a20 2020 2072 6573 203d 206d  2')..    res = m
+000096b0: 622e 736f 6674 706c 7573 5f70 6172 616d  b.softplus_param
+000096c0: 6574 7269 6328 783d 782c 2061 6c70 6861  etric(x=x, alpha
+000096d0: 3d61 6c70 6861 5f62 722c 2062 6574 613d  =alpha_br, beta=
+000096e0: 6265 7461 5f62 722c 206e 616d 653d 6e6f  beta_br, name=no
+000096f0: 6465 2e6e 616d 6529 0a20 2020 2063 6f6e  de.name).    con
+00009700: 7465 7874 2e61 6464 2872 6573 290a 0a0a  text.add(res)...
+00009710: 4072 6567 6973 7465 725f 746f 7263 685f  @register_torch_
+00009720: 6f70 0a64 6566 206d 6973 6828 636f 6e74  op.def mish(cont
+00009730: 6578 742c 206e 6f64 6529 3a0a 2020 2020  ext, node):.    
+00009740: 696e 7075 7473 203d 205f 6765 745f 696e  inputs = _get_in
+00009750: 7075 7473 2863 6f6e 7465 7874 2c20 6e6f  puts(context, no
+00009760: 6465 2c20 6578 7065 6374 6564 3d31 290a  de, expected=1).
+00009770: 2020 2020 7820 3d20 696e 7075 7473 5b30      x = inputs[0
+00009780: 5d0a 0a20 2020 2073 6f66 7470 6c75 7320  ]..    softplus 
+00009790: 3d20 6d62 2e73 6f66 7470 6c75 7328 783d  = mb.softplus(x=
+000097a0: 7829 0a20 2020 2074 616e 6820 3d20 6d62  x).    tanh = mb
+000097b0: 2e74 616e 6828 783d 736f 6674 706c 7573  .tanh(x=softplus
+000097c0: 290a 2020 2020 7265 7320 3d20 6d62 2e6d  ).    res = mb.m
+000097d0: 756c 2878 3d78 2c20 793d 7461 6e68 2c20  ul(x=x, y=tanh, 
+000097e0: 6e61 6d65 3d6e 6f64 652e 6e61 6d65 290a  name=node.name).
+000097f0: 2020 2020 636f 6e74 6578 742e 6164 6428      context.add(
+00009800: 7265 7329 0a0a 0a64 6566 205f 6164 6a75  res)...def _adju
+00009810: 7374 5f70 6164 5f66 6f72 5f63 6569 6c5f  st_pad_for_ceil_
+00009820: 6d6f 6465 2869 6e70 7574 5f73 6861 7065  mode(input_shape
+00009830: 2c20 6b65 726e 656c 5f73 697a 652c 2073  , kernel_size, s
+00009840: 7472 6964 655f 7369 7a65 732c 2070 6164  tride_sizes, pad
+00009850: 5f73 697a 6573 293a 0a20 2020 2022 2222  _sizes):.    """
+00009860: 2047 6976 656e 2061 6e20 696e 7075 7420   Given an input 
+00009870: 7465 6e73 6f72 2061 6e64 2070 6f6f 6c69  tensor and pooli
+00009880: 6e67 2070 6172 616d 6574 6572 732c 2061  ng parameters, a
+00009890: 6464 2074 6865 2065 7874 7261 2069 6e70  dd the extra inp
+000098a0: 7574 0a20 2020 2020 2020 2070 6164 6469  ut.        paddi
+000098b0: 6e67 206e 6565 6465 6420 746f 2072 6570  ng needed to rep
+000098c0: 6c69 6361 7465 2063 6569 6c5f 6d6f 6465  licate ceil_mode
+000098d0: 2e0a 2020 2020 2020 2020 4d49 4c20 3344  ..        MIL 3D
+000098e0: 2070 6f6f 6c69 6e67 2064 6f65 7320 6e6f   pooling does no
+000098f0: 7420 7375 7070 6f72 7420 6365 696c 5f6d  t support ceil_m
+00009900: 6f64 6520 6e61 7469 7665 6c79 2c20 6275  ode natively, bu
+00009910: 7420 7765 2063 616e 0a20 2020 2020 2020  t we can.       
+00009920: 2077 6f72 6b61 726f 756e 6420 6279 2070   workaround by p
+00009930: 6164 6469 6e67 2074 6865 2069 6e70 7574  adding the input
+00009940: 2061 7070 726f 7072 6961 7465 6c79 2e0a   appropriately..
+00009950: 0a20 2020 2020 2020 2050 7954 6f72 6368  .        PyTorch
+00009960: 206f 7574 7075 7420 7369 7a65 2066 6f72   output size for
+00009970: 6d75 6c61 2066 6f72 2070 6f6f 6c69 6e67  mula for pooling
+00009980: 3a0a 2020 2020 2020 2020 2872 6566 6572  :.        (refer
+00009990: 656e 6365 3a20 6874 7470 733a 2f2f 6769  ence: https://gi
+000099a0: 7468 7562 2e63 6f6d 2f70 7974 6f72 6368  thub.com/pytorch
+000099b0: 2f70 7974 6f72 6368 2f62 6c6f 622f 3337  /pytorch/blob/37
+000099c0: 3563 3330 6137 3137 3734 3432 6662 3964  5c30a7177442fb9d
+000099d0: 3664 6537 3531 3661 3961 6534 3033 3161  6de7516a9ae4031a
+000099e0: 6533 3234 6334 2f61 7465 6e2f 7372 632f  e324c4/aten/src/
+000099f0: 4154 656e 2f6e 6174 6976 652f 506f 6f6c  ATen/native/Pool
+00009a00: 2e68 234c 3238 290a 0a20 2020 2020 2020  .h#L28)..       
+00009a10: 2057 6865 6e20 6365 696c 206d 6f64 6520   When ceil mode 
+00009a20: 6973 2054 7275 653a 0a20 2020 2020 2020  is True:.       
+00009a30: 2020 2020 206f 7574 5f64 696d 203d 2066       out_dim = f
+00009a40: 6c6f 6f72 2828 696e 5f64 696d 202b 2070  loor((in_dim + p
+00009a50: 6164 5f6c 202b 2070 6164 5f72 202d 206b  ad_l + pad_r - k
+00009a60: 6572 6e65 6c5f 7369 7a65 202b 2028 7374  ernel_size + (st
+00009a70: 7269 6465 2d31 2929 202f 2073 7472 6964  ride-1)) / strid
+00009a80: 6529 202b 2031 0a20 2020 2020 2020 2020  e) + 1.         
+00009a90: 2020 2069 6620 286f 7574 5f64 696d 2d31     if (out_dim-1
+00009aa0: 2920 2a20 7374 7269 6465 203e 3d20 696e  ) * stride >= in
+00009ab0: 5f64 696d 202b 2070 6164 5f6c 2061 6e64  _dim + pad_l and
+00009ac0: 2028 7061 645f 6c20 3e20 3020 6f72 2070   (pad_l > 0 or p
+00009ad0: 6164 5f72 203e 2030 293a 0a20 2020 2020  ad_r > 0):.     
+00009ae0: 2020 2020 2020 2020 2020 206f 7574 5f64             out_d
+00009af0: 696d 203d 206f 7574 5f64 696d 202d 2031  im = out_dim - 1
+00009b00: 0a20 2020 2020 2020 2057 6865 6e20 6365  .        When ce
+00009b10: 696c 206d 6f64 6520 6973 2046 616c 7365  il mode is False
+00009b20: 3a0a 2020 2020 2020 2020 2020 2020 6f75  :.            ou
+00009b30: 745f 6469 6d20 3d20 666c 6f6f 7228 2869  t_dim = floor((i
+00009b40: 6e5f 6469 6d20 2b20 7061 645f 6c20 2b20  n_dim + pad_l + 
+00009b50: 7061 645f 7220 2d20 6b65 726e 656c 5f73  pad_r - kernel_s
+00009b60: 697a 6529 202f 2073 7472 6964 6529 202b  ize) / stride) +
+00009b70: 2031 0a0a 0a20 2020 2020 2020 2023 2066   1...        # f
+00009b80: 6f6c 6c6f 7720 7468 6520 6170 7072 6f61  ollow the approa
+00009b90: 6368 2068 6572 6520 746f 2063 616c 6375  ch here to calcu
+00009ba0: 6c61 7465 2070 6164 6469 6e67 3a0a 2020  late padding:.  
+00009bb0: 2020 2020 2020 2320 6874 7470 733a 2f2f        # https://
+00009bc0: 6769 7468 7562 2e63 6f6d 2f70 7974 6f72  github.com/pytor
+00009bd0: 6368 2f70 7974 6f72 6368 2f62 6c6f 622f  ch/pytorch/blob/
+00009be0: 6564 6637 3531 6361 3266 6564 6564 6563  edf751ca2fededec
+00009bf0: 6464 3933 3636 3837 3463 3736 3134 3331  dd9366874c761431
+00009c00: 6330 6636 3166 3031 2f61 7465 6e2f 7372  c0f61f01/aten/sr
+00009c10: 632f 4154 656e 2f6e 6174 6976 652f 6d6b  c/ATen/native/mk
+00009c20: 6c64 6e6e 2f50 6f6f 6c69 6e67 2e63 7070  ldnn/Pooling.cpp
+00009c30: 234c 3132 310a 2020 2020 2020 2020 2320  #L121.        # 
+00009c40: 7768 6963 6820 6b65 6570 7320 696e 6372  which keeps incr
+00009c50: 6561 7369 6e67 2074 6865 2070 6164 5f72  easing the pad_r
+00009c60: 2076 616c 7565 2075 6e74 696c 2074 6865   value until the
+00009c70: 206f 7574 7075 7420 7369 7a65 2077 6974   output size wit
+00009c80: 686f 7574 2074 6865 2063 6569 6c20 6d6f  hout the ceil mo
+00009c90: 6465 206d 6174 6368 6573 2074 6861 7420  de matches that 
+00009ca0: 6f66 2074 6865 2063 6569 6c20 6d6f 6465  of the ceil mode
+00009cb0: 0a20 2020 2022 2222 0a0a 2020 2020 6465  .    """..    de
+00009cc0: 6620 5f63 616c 6375 6c61 7465 5f70 6f6f  f _calculate_poo
+00009cd0: 6c5f 6f75 7470 7574 5f73 697a 6528 696e  l_output_size(in
+00009ce0: 5f64 696d 2c20 6b65 726e 656c 2c20 7374  _dim, kernel, st
+00009cf0: 7269 6465 2c20 7061 645f 6c2c 2070 6164  ride, pad_l, pad
+00009d00: 5f72 2c20 6365 696c 5f6d 6f64 6529 3a0a  _r, ceil_mode):.
+00009d10: 2020 2020 2020 2020 6966 2063 6569 6c5f          if ceil_
+00009d20: 6d6f 6465 3a0a 2020 2020 2020 2020 2020  mode:.          
+00009d30: 2020 6f75 745f 6469 6d20 3d20 5f6d 6174    out_dim = _mat
+00009d40: 682e 666c 6f6f 7228 2869 6e5f 6469 6d20  h.floor((in_dim 
+00009d50: 2b20 7061 645f 7220 2b20 7061 645f 6c20  + pad_r + pad_l 
+00009d60: 2d20 6b65 726e 656c 202b 2073 7472 6964  - kernel + strid
+00009d70: 6520 2d20 3129 202f 2073 7472 6964 6529  e - 1) / stride)
+00009d80: 202b 2031 0a20 2020 2020 2020 2020 2020   + 1.           
+00009d90: 2069 6620 286f 7574 5f64 696d 202d 2031   if (out_dim - 1
+00009da0: 2920 2a20 7374 7269 6465 203e 3d20 696e  ) * stride >= in
+00009db0: 5f64 696d 202b 2070 6164 5f6c 2061 6e64  _dim + pad_l and
+00009dc0: 2028 7061 645f 6c20 3e20 3020 6f72 2070   (pad_l > 0 or p
+00009dd0: 6164 5f72 203e 2030 293a 0a20 2020 2020  ad_r > 0):.     
+00009de0: 2020 2020 2020 2020 2020 206f 7574 5f64             out_d
+00009df0: 696d 203d 206f 7574 5f64 696d 202d 2031  im = out_dim - 1
+00009e00: 0a20 2020 2020 2020 2065 6c73 653a 0a20  .        else:. 
+00009e10: 2020 2020 2020 2020 2020 206f 7574 5f64             out_d
+00009e20: 696d 203d 205f 6d61 7468 2e66 6c6f 6f72  im = _math.floor
+00009e30: 2828 696e 5f64 696d 202b 2070 6164 5f72  ((in_dim + pad_r
+00009e40: 202b 2070 6164 5f6c 202d 206b 6572 6e65   + pad_l - kerne
+00009e50: 6c29 202f 2073 7472 6964 6529 202b 2031  l) / stride) + 1
+00009e60: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+00009e70: 6f75 745f 6469 6d0a 0a20 2020 206e 6577  out_dim..    new
+00009e80: 5f70 6164 203d 2070 6164 5f73 697a 6573  _pad = pad_sizes
+00009e90: 2e63 6f70 7928 290a 2020 2020 666f 7220  .copy().    for 
+00009ea0: 6964 7820 696e 2072 616e 6765 286c 656e  idx in range(len
+00009eb0: 2869 6e70 7574 5f73 6861 7065 2929 3a0a  (input_shape)):.
+00009ec0: 2020 2020 2020 2020 6966 2069 735f 7379          if is_sy
+00009ed0: 6d62 6f6c 6963 2869 6e70 7574 5f73 6861  mbolic(input_sha
+00009ee0: 7065 5b69 6478 5d29 3a0a 2020 2020 2020  pe[idx]):.      
+00009ef0: 2020 2020 2020 6c6f 6767 6572 2e77 6172        logger.war
+00009f00: 6e69 6e67 280a 2020 2020 2020 2020 2020  ning(.          
+00009f10: 2020 2020 2020 2270 6f6f 6c69 6e67 2070        "pooling p
+00009f20: 6164 6469 6e67 2061 646a 7573 7465 6420  adding adjusted 
+00009f30: 746f 2073 7570 706f 7274 2063 6569 6c5f  to support ceil_
+00009f40: 6d6f 6465 3d54 7275 652c 2066 6f72 2073  mode=True, for s
+00009f50: 796d 626f 6c69 6320 6469 6d65 6e73 696f  ymbolic dimensio
+00009f60: 6e2e 220a 2020 2020 2020 2020 2020 2020  n.".            
+00009f70: 2020 2020 224f 7574 7075 7420 7368 6170      "Output shap
+00009f80: 6520 6f66 2074 6865 2070 6f6f 6c20 6f70  e of the pool op
+00009f90: 206d 6179 6265 2062 6520 7772 6f6e 6720   maybe be wrong 
+00009fa0: 666f 7220 6365 7274 6169 6e20 696e 7075  for certain inpu
+00009fb0: 7420 7368 6170 6573 2e22 0a20 2020 2020  t shapes.".     
+00009fc0: 2020 2020 2020 2029 0a20 2020 2020 2020         ).       
+00009fd0: 2020 2020 206e 6577 5f70 6164 5b32 202a       new_pad[2 *
+00009fe0: 2069 6478 202b 2031 5d20 2b3d 2073 7472   idx + 1] += str
+00009ff0: 6964 655f 7369 7a65 735b 6964 785d 202d  ide_sizes[idx] -
+0000a000: 2031 0a20 2020 2020 2020 2065 6c73 653a   1.        else:
+0000a010: 0a20 2020 2020 2020 2020 2020 206f 7574  .            out
+0000a020: 5f64 696d 5f77 6974 685f 6365 696c 5f6d  _dim_with_ceil_m
+0000a030: 6f64 6520 3d20 5f63 616c 6375 6c61 7465  ode = _calculate
+0000a040: 5f70 6f6f 6c5f 6f75 7470 7574 5f73 697a  _pool_output_siz
+0000a050: 6528 0a20 2020 2020 2020 2020 2020 2020  e(.             
+0000a060: 2020 2069 6e70 7574 5f73 6861 7065 5b69     input_shape[i
+0000a070: 6478 5d2c 0a20 2020 2020 2020 2020 2020  dx],.           
+0000a080: 2020 2020 206b 6572 6e65 6c5f 7369 7a65       kernel_size
+0000a090: 5b69 6478 5d2c 0a20 2020 2020 2020 2020  [idx],.         
+0000a0a0: 2020 2020 2020 2073 7472 6964 655f 7369         stride_si
+0000a0b0: 7a65 735b 6964 785d 2c0a 2020 2020 2020  zes[idx],.      
+0000a0c0: 2020 2020 2020 2020 2020 7061 645f 7369            pad_si
+0000a0d0: 7a65 735b 3220 2a20 6964 785d 2c0a 2020  zes[2 * idx],.  
+0000a0e0: 2020 2020 2020 2020 2020 2020 2020 7061                pa
+0000a0f0: 645f 7369 7a65 735b 3220 2a20 6964 7820  d_sizes[2 * idx 
+0000a100: 2b20 315d 2c0a 2020 2020 2020 2020 2020  + 1],.          
+0000a110: 2020 2020 2020 5472 7565 2c0a 2020 2020        True,.    
+0000a120: 2020 2020 2020 2020 290a 2020 2020 2020          ).      
+0000a130: 2020 2020 2020 6973 5f65 7175 616c 203d        is_equal =
+0000a140: 2046 616c 7365 0a20 2020 2020 2020 2020   False.         
+0000a150: 2020 2077 6869 6c65 206e 6f74 2069 735f     while not is_
+0000a160: 6571 7561 6c3a 0a20 2020 2020 2020 2020  equal:.         
+0000a170: 2020 2020 2020 206f 7574 5f64 696d 5f77         out_dim_w
+0000a180: 6974 686f 7574 5f63 6569 6c5f 6d6f 6465  ithout_ceil_mode
+0000a190: 203d 205f 6361 6c63 756c 6174 655f 706f   = _calculate_po
+0000a1a0: 6f6c 5f6f 7574 7075 745f 7369 7a65 280a  ol_output_size(.
+0000a1b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a1c0: 2020 2020 696e 7075 745f 7368 6170 655b      input_shape[
+0000a1d0: 6964 785d 2c0a 2020 2020 2020 2020 2020  idx],.          
+0000a1e0: 2020 2020 2020 2020 2020 6b65 726e 656c            kernel
+0000a1f0: 5f73 697a 655b 6964 785d 2c0a 2020 2020  _size[idx],.    
+0000a200: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a210: 7374 7269 6465 5f73 697a 6573 5b69 6478  stride_sizes[idx
+0000a220: 5d2c 0a20 2020 2020 2020 2020 2020 2020  ],.             
+0000a230: 2020 2020 2020 206e 6577 5f70 6164 5b32         new_pad[2
+0000a240: 202a 2069 6478 5d2c 0a20 2020 2020 2020   * idx],.       
+0000a250: 2020 2020 2020 2020 2020 2020 206e 6577               new
+0000a260: 5f70 6164 5b32 202a 2069 6478 202b 2031  _pad[2 * idx + 1
+0000a270: 5d2c 0a20 2020 2020 2020 2020 2020 2020  ],.             
+0000a280: 2020 2020 2020 2046 616c 7365 2c0a 2020         False,.  
+0000a290: 2020 2020 2020 2020 2020 2020 2020 290a                ).
+0000a2a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a2b0: 6973 5f65 7175 616c 203d 2054 7275 650a  is_equal = True.
+0000a2c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a2d0: 6966 206f 7574 5f64 696d 5f77 6974 686f  if out_dim_witho
+0000a2e0: 7574 5f63 6569 6c5f 6d6f 6465 203c 206f  ut_ceil_mode < o
+0000a2f0: 7574 5f64 696d 5f77 6974 685f 6365 696c  ut_dim_with_ceil
+0000a300: 5f6d 6f64 653a 0a20 2020 2020 2020 2020  _mode:.         
+0000a310: 2020 2020 2020 2020 2020 206e 6577 5f70             new_p
+0000a320: 6164 5b32 202a 2069 6478 202b 2031 5d20  ad[2 * idx + 1] 
+0000a330: 2b3d 2031 0a20 2020 2020 2020 2020 2020  += 1.           
+0000a340: 2020 2020 2020 2020 2069 735f 6571 7561           is_equa
+0000a350: 6c20 3d20 4661 6c73 650a 0a20 2020 2072  l = False..    r
+0000a360: 6574 7572 6e20 6e65 775f 7061 640a 0a0a  eturn new_pad...
+0000a370: 6465 6620 5f6d 6178 5f70 6f6f 6c28 636f  def _max_pool(co
+0000a380: 6e74 6578 742c 206e 6f64 652c 2069 6e70  ntext, node, inp
+0000a390: 7574 7329 3a0a 2020 2020 7820 3d20 696e  uts):.    x = in
+0000a3a0: 7075 7473 5b30 5d0a 2020 2020 6b65 726e  puts[0].    kern
+0000a3b0: 656c 5f73 697a 6573 203d 2069 6e70 7574  el_sizes = input
+0000a3c0: 735b 315d 0a20 2020 2073 7472 6964 6573  s[1].    strides
+0000a3d0: 203d 2069 6e70 7574 735b 325d 0a20 2020   = inputs[2].   
+0000a3e0: 2069 6620 7374 7269 6465 732e 6f70 2e6f   if strides.op.o
+0000a3f0: 705f 7479 7065 203d 3d20 2263 6f6e 7374  p_type == "const
+0000a400: 2220 616e 6420 286e 6f74 206c 6973 7428  " and (not list(
+0000a410: 7374 7269 6465 732e 7661 6c29 293a 0a20  strides.val)):. 
+0000a420: 2020 2020 2020 2073 7472 6964 6573 203d         strides =
+0000a430: 206d 622e 636f 6e73 7428 7661 6c3d 6b65   mb.const(val=ke
+0000a440: 726e 656c 5f73 697a 6573 2e76 616c 2c20  rnel_sizes.val, 
+0000a450: 6e61 6d65 3d73 7472 6964 6573 2e6e 616d  name=strides.nam
+0000a460: 6529 0a0a 2020 2020 7061 645f 7479 7065  e)..    pad_type
+0000a470: 203d 2022 6375 7374 6f6d 220a 2020 2020   = "custom".    
+0000a480: 2320 4e65 6564 2074 6f20 6578 706c 6963  # Need to explic
+0000a490: 6974 6c79 2073 7461 7465 204c 2d52 2c20  itly state L-R, 
+0000a4a0: 542d 4220 7061 640a 2020 2020 7061 6420  T-B pad.    pad 
+0000a4b0: 3d20 696e 7075 7473 5b33 5d0a 2020 2020  = inputs[3].    
+0000a4c0: 7061 6420 3d20 5f6e 702e 7265 7065 6174  pad = _np.repeat
+0000a4d0: 2870 6164 2e76 616c 2c20 3229 0a20 2020  (pad.val, 2).   
+0000a4e0: 2064 696c 6174 696f 6e20 3d20 696e 7075   dilation = inpu
+0000a4f0: 7473 5b34 5d2e 7661 6c0a 2020 2020 6365  ts[4].val.    ce
+0000a500: 696c 5f6d 6f64 6520 3d20 696e 7075 7473  il_mode = inputs
+0000a510: 5b35 5d2e 7661 6c0a 2020 2020 6966 205f  [5].val.    if _
+0000a520: 6e70 2e61 6e79 2864 696c 6174 696f 6e20  np.any(dilation 
+0000a530: 3e20 3129 3a0a 2020 2020 2020 2020 2320  > 1):.        # 
+0000a540: 5365 653a 2072 6461 723a 2f2f 3630 3633  See: rdar://6063
+0000a550: 3337 3336 2028 496d 706c 656d 656e 7420  3736 (Implement 
+0000a560: 6469 6c61 7469 6f6e 2066 6f72 206d 696c  dilation for mil
+0000a570: 206f 7020 6d61 785f 706f 6f6c 290a 2020   op max_pool).  
+0000a580: 2020 2020 2020 7261 6973 6520 5661 6c75        raise Valu
+0000a590: 6545 7272 6f72 2822 406d 6178 5f70 6f6f  eError("@max_poo
+0000a5a0: 6c20 646f 6573 206e 6f74 2073 7570 706f  l does not suppo
+0000a5b0: 7274 2064 696c 6174 696f 6e20 3e20 3122  rt dilation > 1"
+0000a5c0: 290a 2020 2020 7370 6174 6961 6c5f 7261  ).    spatial_ra
+0000a5d0: 6e6b 203d 206c 656e 2870 6164 2920 2f2f  nk = len(pad) //
+0000a5e0: 2032 0a20 2020 2069 6620 7370 6174 6961   2.    if spatia
+0000a5f0: 6c5f 7261 6e6b 203e 2032 2061 6e64 2063  l_rank > 2 and c
+0000a600: 6569 6c5f 6d6f 6465 2069 7320 5472 7565  eil_mode is True
+0000a610: 2061 6e64 206c 6973 7428 7374 7269 6465   and list(stride
+0000a620: 732e 7661 6c29 2021 3d20 5b31 5d20 2a20  s.val) != [1] * 
+0000a630: 6c65 6e28 7374 7269 6465 732e 7661 6c29  len(strides.val)
+0000a640: 3a0a 2020 2020 2020 2020 2320 7369 6e63  :.        # sinc
+0000a650: 6520 4d49 4c20 646f 6573 206e 6f74 2073  e MIL does not s
+0000a660: 7570 706f 7274 2063 6569 6c5f 6d6f 6465  upport ceil_mode
+0000a670: 2066 6f72 2033 4420 706f 6f6c 2c0a 2020   for 3D pool,.  
+0000a680: 2020 2020 2020 2320 6e65 6564 2074 6f20        # need to 
+0000a690: 6164 6a75 7374 2070 6164 6469 6e67 2076  adjust padding v
+0000a6a0: 616c 7565 7320 6966 2063 6569 6c5f 6d6f  alues if ceil_mo
+0000a6b0: 6465 2069 7320 5472 7565 0a20 2020 2020  de is True.     
+0000a6c0: 2020 2023 2063 6569 6c5f 6d6f 6465 206f     # ceil_mode o
+0000a6d0: 6e6c 7920 6361 7573 6573 2061 6e79 2064  nly causes any d
+0000a6e0: 6966 6665 7265 6e63 6520 7468 6f75 6768  ifference though
+0000a6f0: 2c20 6966 2074 6865 2073 7472 6964 6573  , if the strides
+0000a700: 2061 7265 206e 6f74 2031 0a20 2020 2020   are not 1.     
+0000a710: 2020 2078 5f73 7061 7469 616c 5f64 696d     x_spatial_dim
+0000a720: 656e 7369 6f6e 7320 3d20 782e 7368 6170  ensions = x.shap
+0000a730: 655b 2d73 7061 7469 616c 5f72 616e 6b3a  e[-spatial_rank:
+0000a740: 5d0a 2020 2020 2020 2020 7061 6420 3d20  ].        pad = 
+0000a750: 5f61 646a 7573 745f 7061 645f 666f 725f  _adjust_pad_for_
+0000a760: 6365 696c 5f6d 6f64 6528 785f 7370 6174  ceil_mode(x_spat
+0000a770: 6961 6c5f 6469 6d65 6e73 696f 6e73 2c20  ial_dimensions, 
+0000a780: 6b65 726e 656c 5f73 697a 6573 2e76 616c  kernel_sizes.val
+0000a790: 2c20 7374 7269 6465 732e 7661 6c2c 2070  , strides.val, p
+0000a7a0: 6164 290a 0a20 2020 2070 6f6f 6c20 3d20  ad)..    pool = 
+0000a7b0: 6d62 2e6d 6178 5f70 6f6f 6c28 0a20 2020  mb.max_pool(.   
+0000a7c0: 2020 2020 2078 3d78 2c0a 2020 2020 2020       x=x,.      
+0000a7d0: 2020 6b65 726e 656c 5f73 697a 6573 3d6b    kernel_sizes=k
+0000a7e0: 6572 6e65 6c5f 7369 7a65 732c 0a20 2020  ernel_sizes,.   
+0000a7f0: 2020 2020 2073 7472 6964 6573 3d73 7472       strides=str
+0000a800: 6964 6573 2c0a 2020 2020 2020 2020 7061  ides,.        pa
+0000a810: 645f 7479 7065 3d70 6164 5f74 7970 652c  d_type=pad_type,
+0000a820: 0a20 2020 2020 2020 2070 6164 3d70 6164  .        pad=pad
+0000a830: 2c0a 2020 2020 2020 2020 6e61 6d65 3d6e  ,.        name=n
+0000a840: 6f64 652e 6e61 6d65 2c0a 2020 2020 2020  ode.name,.      
+0000a850: 2020 6365 696c 5f6d 6f64 653d 6365 696c    ceil_mode=ceil
+0000a860: 5f6d 6f64 6520 6966 2073 7061 7469 616c  _mode if spatial
+0000a870: 5f72 616e 6b20 3c3d 2032 2065 6c73 6520  _rank <= 2 else 
+0000a880: 4661 6c73 652c 0a20 2020 2029 0a20 2020  False,.    ).   
+0000a890: 2063 6f6e 7465 7874 2e61 6464 2870 6f6f   context.add(poo
+0000a8a0: 6c29 0a0a 0a40 7265 6769 7374 6572 5f74  l)...@register_t
+0000a8b0: 6f72 6368 5f6f 700a 6465 6620 6d61 785f  orch_op.def max_
+0000a8c0: 706f 6f6c 3164 2863 6f6e 7465 7874 2c20  pool1d(context, 
+0000a8d0: 6e6f 6465 293a 0a20 2020 2069 6e70 7574  node):.    input
+0000a8e0: 7320 3d20 5f67 6574 5f69 6e70 7574 7328  s = _get_inputs(
+0000a8f0: 636f 6e74 6578 742c 206e 6f64 652c 2065  context, node, e
+0000a900: 7870 6563 7465 643d 3629 0a20 2020 205f  xpected=6).    _
+0000a910: 6d61 785f 706f 6f6c 2863 6f6e 7465 7874  max_pool(context
+0000a920: 2c20 6e6f 6465 2c20 696e 7075 7473 290a  , node, inputs).
+0000a930: 0a0a 4072 6567 6973 7465 725f 746f 7263  ..@register_torc
+0000a940: 685f 6f70 0a64 6566 206d 6178 5f70 6f6f  h_op.def max_poo
+0000a950: 6c32 6428 636f 6e74 6578 742c 206e 6f64  l2d(context, nod
+0000a960: 6529 3a0a 2020 2020 696e 7075 7473 203d  e):.    inputs =
+0000a970: 205f 6765 745f 696e 7075 7473 2863 6f6e   _get_inputs(con
+0000a980: 7465 7874 2c20 6e6f 6465 2c20 6578 7065  text, node, expe
+0000a990: 6374 6564 3d36 290a 2020 2020 5f6d 6178  cted=6).    _max
+0000a9a0: 5f70 6f6f 6c28 636f 6e74 6578 742c 206e  _pool(context, n
+0000a9b0: 6f64 652c 2069 6e70 7574 7329 0a0a 0a40  ode, inputs)...@
+0000a9c0: 7265 6769 7374 6572 5f74 6f72 6368 5f6f  register_torch_o
+0000a9d0: 700a 6465 6620 6d61 785f 706f 6f6c 3364  p.def max_pool3d
+0000a9e0: 2863 6f6e 7465 7874 2c20 6e6f 6465 293a  (context, node):
+0000a9f0: 0a20 2020 2069 6e70 7574 7320 3d20 5f67  .    inputs = _g
+0000aa00: 6574 5f69 6e70 7574 7328 636f 6e74 6578  et_inputs(contex
+0000aa10: 742c 206e 6f64 652c 2065 7870 6563 7465  t, node, expecte
+0000aa20: 643d 3629 0a20 2020 205f 6d61 785f 706f  d=6).    _max_po
+0000aa30: 6f6c 2863 6f6e 7465 7874 2c20 6e6f 6465  ol(context, node
+0000aa40: 2c20 696e 7075 7473 290a 0a0a 4072 6567  , inputs)...@reg
+0000aa50: 6973 7465 725f 746f 7263 685f 6f70 0a64  ister_torch_op.d
+0000aa60: 6566 206d 696e 696d 756d 2863 6f6e 7465  ef minimum(conte
+0000aa70: 7874 2c20 6e6f 6465 293a 0a20 2020 2069  xt, node):.    i
+0000aa80: 6e70 7574 7320 3d20 5f67 6574 5f69 6e70  nputs = _get_inp
+0000aa90: 7574 7328 636f 6e74 6578 742c 206e 6f64  uts(context, nod
+0000aaa0: 652c 2065 7870 6563 7465 643d 3229 0a20  e, expected=2). 
+0000aab0: 2020 2061 7373 6572 7420 6c65 6e28 6e6f     assert len(no
+0000aac0: 6465 2e6f 7574 7075 7473 2920 3d3d 2031  de.outputs) == 1
+0000aad0: 0a20 2020 2078 203d 2063 6f6e 7465 7874  .    x = context
+0000aae0: 5b6e 6f64 652e 696e 7075 7473 5b30 5d5d  [node.inputs[0]]
+0000aaf0: 0a20 2020 2079 203d 2063 6f6e 7465 7874  .    y = context
+0000ab00: 5b6e 6f64 652e 696e 7075 7473 5b31 5d5d  [node.inputs[1]]
+0000ab10: 0a20 2020 206f 7574 203d 206d 622e 6d69  .    out = mb.mi
+0000ab20: 6e69 6d75 6d28 783d 782c 2079 3d79 2c20  nimum(x=x, y=y, 
+0000ab30: 6e61 6d65 3d6e 6f64 652e 6e61 6d65 290a  name=node.name).
+0000ab40: 2020 2020 636f 6e74 6578 742e 6164 6428      context.add(
+0000ab50: 6f75 7429 0a0a 0a40 7265 6769 7374 6572  out)...@register
+0000ab60: 5f74 6f72 6368 5f6f 700a 6465 6620 636c  _torch_op.def cl
+0000ab70: 616d 705f 6d69 6e28 636f 6e74 6578 742c  amp_min(context,
+0000ab80: 206e 6f64 6529 3a0a 2020 2020 7820 3d20   node):.    x = 
+0000ab90: 5f67 6574 5f69 6e70 7574 7328 636f 6e74  _get_inputs(cont
+0000aba0: 6578 742c 206e 6f64 652c 2065 7870 6563  ext, node, expec
+0000abb0: 7465 643d 3229 0a20 2020 2078 203d 206d  ted=2).    x = m
+0000abc0: 622e 636c 6970 2878 3d78 5b30 5d2c 2061  b.clip(x=x[0], a
+0000abd0: 6c70 6861 3d78 5b31 5d2c 2062 6574 613d  lpha=x[1], beta=
+0000abe0: 5f6e 702e 696e 662c 206e 616d 653d 6e6f  _np.inf, name=no
+0000abf0: 6465 2e6e 616d 6529 0a20 2020 2063 6f6e  de.name).    con
+0000ac00: 7465 7874 2e61 6464 2878 290a 0a0a 4072  text.add(x)...@r
+0000ac10: 6567 6973 7465 725f 746f 7263 685f 6f70  egister_torch_op
+0000ac20: 0a64 6566 206d 6178 696d 756d 2863 6f6e  .def maximum(con
+0000ac30: 7465 7874 2c20 6e6f 6465 293a 0a20 2020  text, node):.   
+0000ac40: 2069 6e70 7574 7320 3d20 5f67 6574 5f69   inputs = _get_i
+0000ac50: 6e70 7574 7328 636f 6e74 6578 742c 206e  nputs(context, n
+0000ac60: 6f64 652c 2065 7870 6563 7465 643d 3229  ode, expected=2)
+0000ac70: 0a20 2020 2061 7373 6572 7420 6c65 6e28  .    assert len(
+0000ac80: 6e6f 6465 2e6f 7574 7075 7473 2920 3d3d  node.outputs) ==
+0000ac90: 2031 0a20 2020 2078 203d 2063 6f6e 7465   1.    x = conte
+0000aca0: 7874 5b6e 6f64 652e 696e 7075 7473 5b30  xt[node.inputs[0
+0000acb0: 5d5d 0a20 2020 2079 203d 2063 6f6e 7465  ]].    y = conte
+0000acc0: 7874 5b6e 6f64 652e 696e 7075 7473 5b31  xt[node.inputs[1
+0000acd0: 5d5d 0a20 2020 206f 7574 203d 206d 622e  ]].    out = mb.
+0000ace0: 6d61 7869 6d75 6d28 783d 782c 2079 3d79  maximum(x=x, y=y
+0000acf0: 2c20 6e61 6d65 3d6e 6f64 652e 6e61 6d65  , name=node.name
+0000ad00: 290a 2020 2020 636f 6e74 6578 742e 6164  ).    context.ad
+0000ad10: 6428 6f75 7429 0a0a 0a40 7265 6769 7374  d(out)...@regist
+0000ad20: 6572 5f74 6f72 6368 5f6f 700a 6465 6620  er_torch_op.def 
+0000ad30: 6469 7628 636f 6e74 6578 742c 206e 6f64  div(context, nod
+0000ad40: 6529 3a0a 2020 2020 696e 7075 7473 203d  e):.    inputs =
+0000ad50: 205f 6765 745f 696e 7075 7473 2863 6f6e   _get_inputs(con
+0000ad60: 7465 7874 2c20 6e6f 6465 2c20 6578 7065  text, node, expe
+0000ad70: 6374 6564 3d5b 322c 2033 5d29 0a20 2020  cted=[2, 3]).   
+0000ad80: 2078 203d 206d 622e 6361 7374 2878 3d69   x = mb.cast(x=i
+0000ad90: 6e70 7574 735b 305d 2c20 6474 7970 653d  nputs[0], dtype=
+0000ada0: 2266 7033 3222 290a 2020 2020 7920 3d20  "fp32").    y = 
+0000adb0: 6d62 2e63 6173 7428 783d 696e 7075 7473  mb.cast(x=inputs
+0000adc0: 5b31 5d2c 2064 7479 7065 3d22 6670 3332  [1], dtype="fp32
+0000add0: 2229 0a0a 2020 2020 6966 206c 656e 2869  ")..    if len(i
+0000ade0: 6e70 7574 7329 203e 2032 2061 6e64 2069  nputs) > 2 and i
+0000adf0: 6e70 7574 735b 325d 2069 7320 6e6f 7420  nputs[2] is not 
+0000ae00: 4e6f 6e65 3a0a 2020 2020 2020 2020 726f  None:.        ro
+0000ae10: 756e 6469 6e67 5f6d 6f64 6520 3d20 696e  unding_mode = in
+0000ae20: 7075 7473 5b32 5d2e 7661 6c0a 2020 2020  puts[2].val.    
+0000ae30: 2020 2020 6966 2072 6f75 6e64 696e 675f      if rounding_
+0000ae40: 6d6f 6465 203d 3d20 2266 6c6f 6f72 223a  mode == "floor":
+0000ae50: 0a20 2020 2020 2020 2020 2020 2023 2072  .            # r
+0000ae60: 6f75 6e64 2074 6f77 6172 6473 206e 6567  ound towards neg
+0000ae70: 6174 6976 6520 696e 6669 6e69 7479 0a20  ative infinity. 
+0000ae80: 2020 2020 2020 2020 2020 2023 2065 2e67             # e.g
+0000ae90: 2e3a 0a20 2020 2020 2020 2020 2020 2023  .:.            #
+0000aea0: 2076 616c 7565 7320 6265 666f 7265 2066   values before f
+0000aeb0: 6c6f 6f72 3a20 5b32 2e36 2c20 2d33 2e34  loor: [2.6, -3.4
+0000aec0: 2c20 2d33 2e36 5d0a 2020 2020 2020 2020  , -3.6].        
+0000aed0: 2020 2020 2320 7661 6c75 6573 2061 6674      # values aft
+0000aee0: 6572 2066 6c6f 6f72 3a20 5b32 2c20 2d34  er floor: [2, -4
+0000aef0: 2c20 2d34 5d0a 2020 2020 2020 2020 2020  , -4].          
+0000af00: 2020 7265 7320 3d20 6d62 2e66 6c6f 6f72    res = mb.floor
+0000af10: 5f64 6976 2878 3d78 2c20 793d 792c 206e  _div(x=x, y=y, n
+0000af20: 616d 653d 6e6f 6465 2e6e 616d 6529 0a20  ame=node.name). 
+0000af30: 2020 2020 2020 2065 6c69 6620 726f 756e         elif roun
+0000af40: 6469 6e67 5f6d 6f64 6520 3d3d 2022 7472  ding_mode == "tr
+0000af50: 756e 6322 3a0a 2020 2020 2020 2020 2020  unc":.          
+0000af60: 2020 2320 726f 756e 6420 746f 7761 7264    # round toward
+0000af70: 7320 300a 2020 2020 2020 2020 2020 2020  s 0.            
+0000af80: 2320 652e 672e 3a0a 2020 2020 2020 2020  # e.g.:.        
+0000af90: 2020 2020 2320 7661 6c75 6573 2062 6566      # values bef
+0000afa0: 6f72 6520 7472 756e 633a 205b 322e 362c  ore trunc: [2.6,
+0000afb0: 202d 332e 342c 202d 332e 365d 0a20 2020   -3.4, -3.6].   
+0000afc0: 2020 2020 2020 2020 2023 2076 616c 7565           # value
+0000afd0: 7320 6166 7465 7220 7472 756e 633a 205b  s after trunc: [
+0000afe0: 322c 202d 332c 202d 335d 0a20 2020 2020  2, -3, -3].     
+0000aff0: 2020 2020 2020 207a 203d 206d 622e 7265         z = mb.re
+0000b000: 616c 5f64 6976 2878 3d78 2c20 793d 7929  al_div(x=x, y=y)
+0000b010: 0a20 2020 2020 2020 2020 2020 2073 203d  .            s =
+0000b020: 206d 622e 7369 676e 2878 3d7a 290a 2020   mb.sign(x=z).  
+0000b030: 2020 2020 2020 2020 2020 616c 6c5f 706f            all_po
+0000b040: 7369 7469 7665 203d 206d 622e 6d75 6c28  sitive = mb.mul(
+0000b050: 783d 7a2c 2079 3d73 290a 2020 2020 2020  x=z, y=s).      
+0000b060: 2020 2020 2020 616c 6c5f 706f 7369 7469        all_positi
+0000b070: 7665 5f66 6c6f 6f72 203d 206d 622e 666c  ve_floor = mb.fl
+0000b080: 6f6f 7228 783d 616c 6c5f 706f 7369 7469  oor(x=all_positi
+0000b090: 7665 290a 2020 2020 2020 2020 2020 2020  ve).            
+0000b0a0: 7265 7320 3d20 6d62 2e6d 756c 2878 3d61  res = mb.mul(x=a
+0000b0b0: 6c6c 5f70 6f73 6974 6976 655f 666c 6f6f  ll_positive_floo
+0000b0c0: 722c 2079 3d73 2c20 6e61 6d65 3d6e 6f64  r, y=s, name=nod
+0000b0d0: 652e 6e61 6d65 290a 2020 2020 2020 2020  e.name).        
+0000b0e0: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
+0000b0f0: 2020 7261 6973 6520 4e6f 7449 6d70 6c65    raise NotImple
+0000b100: 6d65 6e74 6564 4572 726f 7228 0a20 2020  mentedError(.   
+0000b110: 2020 2020 2020 2020 2020 2020 2027 726f               'ro
+0000b120: 756e 6469 6e67 206d 6f64 6520 227b 7d22  unding mode "{}"
+0000b130: 206e 6f74 2073 7570 706f 7274 6564 2069   not supported i
+0000b140: 6e20 7468 6520 2264 6976 2220 6f70 272e  n the "div" op'.
+0000b150: 666f 726d 6174 2872 6f75 6e64 696e 675f  format(rounding_
+0000b160: 6d6f 6465 290a 2020 2020 2020 2020 2020  mode).          
+0000b170: 2020 290a 2020 2020 656c 7365 3a0a 2020    ).    else:.  
+0000b180: 2020 2020 2020 7265 7320 3d20 6d62 2e72        res = mb.r
+0000b190: 6561 6c5f 6469 7628 783d 782c 2079 3d79  eal_div(x=x, y=y
+0000b1a0: 2c20 6e61 6d65 3d6e 6f64 652e 6e61 6d65  , name=node.name
+0000b1b0: 290a 0a20 2020 2063 6f6e 7465 7874 2e61  )..    context.a
+0000b1c0: 6464 2872 6573 290a 0a0a 4072 6567 6973  dd(res)...@regis
+0000b1d0: 7465 725f 746f 7263 685f 6f70 2874 6f72  ter_torch_op(tor
+0000b1e0: 6368 5f61 6c69 6173 3d5b 2266 6c6f 6f72  ch_alias=["floor
+0000b1f0: 6469 7622 5d29 0a64 6566 2066 6c6f 6f72  div"]).def floor
+0000b200: 5f64 6976 6964 6528 636f 6e74 6578 742c  _divide(context,
+0000b210: 206e 6f64 6529 3a0a 2020 2020 696e 7075   node):.    inpu
+0000b220: 7473 203d 205f 6765 745f 696e 7075 7473  ts = _get_inputs
+0000b230: 2863 6f6e 7465 7874 2c20 6e6f 6465 2c20  (context, node, 
+0000b240: 6578 7065 6374 6564 3d32 290a 2020 2020  expected=2).    
+0000b250: 696e 7075 7473 203d 2070 726f 6d6f 7465  inputs = promote
+0000b260: 5f69 6e70 7574 5f64 7479 7065 7328 696e  _input_dtypes(in
+0000b270: 7075 7473 290a 2020 2020 6469 765f 7265  puts).    div_re
+0000b280: 7320 3d20 6d62 2e66 6c6f 6f72 5f64 6976  s = mb.floor_div
+0000b290: 2878 3d69 6e70 7574 735b 305d 2c20 793d  (x=inputs[0], y=
+0000b2a0: 696e 7075 7473 5b31 5d29 0a20 2020 2023  inputs[1]).    #
+0000b2b0: 2050 7974 6f72 6368 2773 2066 6c6f 6f72   Pytorch's floor
+0000b2c0: 5f64 6976 6964 6520 616c 7761 7973 2072  _divide always r
+0000b2d0: 6574 7572 6e73 2066 7033 322c 2065 7665  eturns fp32, eve
+0000b2e0: 6e20 6966 2074 6865 2069 6e70 7574 7320  n if the inputs 
+0000b2f0: 6172 6520 696e 740a 2020 2020 7265 7320  are int.    res 
+0000b300: 3d20 6d62 2e63 6173 7428 783d 6469 765f  = mb.cast(x=div_
+0000b310: 7265 732c 2064 7479 7065 3d27 6670 3332  res, dtype='fp32
+0000b320: 272c 206e 616d 653d 6e6f 6465 2e6e 616d  ', name=node.nam
+0000b330: 6529 0a20 2020 2063 6f6e 7465 7874 2e61  e).    context.a
+0000b340: 6464 2872 6573 290a 0a0a 4072 6567 6973  dd(res)...@regis
+0000b350: 7465 725f 746f 7263 685f 6f70 0a64 6566  ter_torch_op.def
+0000b360: 2074 7275 655f 6469 7669 6465 2863 6f6e   true_divide(con
+0000b370: 7465 7874 2c20 6e6f 6465 293a 0a20 2020  text, node):.   
+0000b380: 2069 6e70 7574 7320 3d20 5f67 6574 5f69   inputs = _get_i
+0000b390: 6e70 7574 7328 636f 6e74 6578 742c 206e  nputs(context, n
+0000b3a0: 6f64 652c 2065 7870 6563 7465 643d 3229  ode, expected=2)
+0000b3b0: 0a20 2020 2072 6573 203d 206d 622e 7265  .    res = mb.re
+0000b3c0: 616c 5f64 6976 2878 3d69 6e70 7574 735b  al_div(x=inputs[
+0000b3d0: 305d 2c20 793d 696e 7075 7473 5b31 5d2c  0], y=inputs[1],
+0000b3e0: 206e 616d 653d 6e6f 6465 2e6e 616d 6529   name=node.name)
+0000b3f0: 0a20 2020 2063 6f6e 7465 7874 2e61 6464  .    context.add
+0000b400: 2872 6573 290a 0a0a 4072 6567 6973 7465  (res)...@registe
+0000b410: 725f 746f 7263 685f 6f70 0a64 6566 206d  r_torch_op.def m
+0000b420: 756c 2863 6f6e 7465 7874 2c20 6e6f 6465  ul(context, node
+0000b430: 293a 0a20 2020 2069 6e70 7574 7320 3d20  ):.    inputs = 
+0000b440: 5f67 6574 5f69 6e70 7574 7328 636f 6e74  _get_inputs(cont
+0000b450: 6578 742c 206e 6f64 652c 2065 7870 6563  ext, node, expec
+0000b460: 7465 643d 3229 0a20 2020 2078 2c20 7920  ted=2).    x, y 
+0000b470: 3d20 7072 6f6d 6f74 655f 696e 7075 745f  = promote_input_
+0000b480: 6474 7970 6573 2869 6e70 7574 7329 0a20  dtypes(inputs). 
+0000b490: 2020 2072 6573 203d 206d 622e 6d75 6c28     res = mb.mul(
+0000b4a0: 783d 782c 2079 3d79 2c20 6e61 6d65 3d6e  x=x, y=y, name=n
+0000b4b0: 6f64 652e 6e61 6d65 290a 2020 2020 636f  ode.name).    co
+0000b4c0: 6e74 6578 742e 6164 6428 7265 7329 0a0a  ntext.add(res)..
+0000b4d0: 0a40 7265 6769 7374 6572 5f74 6f72 6368  .@register_torch
+0000b4e0: 5f6f 700a 6465 6620 706f 7728 636f 6e74  _op.def pow(cont
+0000b4f0: 6578 742c 206e 6f64 6529 3a0a 2020 2020  ext, node):.    
+0000b500: 696e 7075 7473 203d 205f 6765 745f 696e  inputs = _get_in
+0000b510: 7075 7473 2863 6f6e 7465 7874 2c20 6e6f  puts(context, no
+0000b520: 6465 2c20 6578 7065 6374 6564 3d32 290a  de, expected=2).
+0000b530: 2020 2020 782c 2079 203d 2070 726f 6d6f      x, y = promo
+0000b540: 7465 5f69 6e70 7574 5f64 7479 7065 7328  te_input_dtypes(
+0000b550: 696e 7075 7473 290a 2020 2020 7265 7320  inputs).    res 
+0000b560: 3d20 6d62 2e70 6f77 2878 3d78 2c20 793d  = mb.pow(x=x, y=
+0000b570: 792c 206e 616d 653d 6e6f 6465 2e6e 616d  y, name=node.nam
+0000b580: 6529 0a20 2020 2063 6f6e 7465 7874 2e61  e).    context.a
+0000b590: 6464 2872 6573 290a 0a0a 4072 6567 6973  dd(res)...@regis
+0000b5a0: 7465 725f 746f 7263 685f 6f70 2874 6f72  ter_torch_op(tor
+0000b5b0: 6368 5f61 6c69 6173 3d5b 2272 7375 6222  ch_alias=["rsub"
+0000b5c0: 5d29 0a64 6566 2073 7562 2863 6f6e 7465  ]).def sub(conte
+0000b5d0: 7874 2c20 6e6f 6465 293a 0a20 2020 2069  xt, node):.    i
+0000b5e0: 6e70 7574 7320 3d20 5f67 6574 5f69 6e70  nputs = _get_inp
+0000b5f0: 7574 7328 636f 6e74 6578 742c 206e 6f64  uts(context, nod
+0000b600: 652c 2065 7870 6563 7465 643d 5b32 2c20  e, expected=[2, 
+0000b610: 335d 290a 2020 2020 6173 7365 7274 206c  3]).    assert l
+0000b620: 656e 286e 6f64 652e 6f75 7470 7574 7329  en(node.outputs)
+0000b630: 203d 3d20 310a 0a20 2020 2069 6620 6e6f   == 1..    if no
+0000b640: 6465 2e6b 696e 6420 3d3d 2022 7273 7562  de.kind == "rsub
+0000b650: 223a 0a20 2020 2020 2020 2023 2072 7375  ":.        # rsu
+0000b660: 6220 7265 7665 7273 6573 2074 6865 206f  b reverses the o
+0000b670: 7264 6572 206f 6620 6172 6775 6d65 6e74  rder of argument
+0000b680: 730a 2020 2020 2020 2020 7920 3d20 696e  s.        y = in
+0000b690: 7075 7473 5b30 5d0a 2020 2020 2020 2020  puts[0].        
+0000b6a0: 7820 3d20 696e 7075 7473 5b31 5d0a 2020  x = inputs[1].  
+0000b6b0: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
+0000b6c0: 7820 3d20 696e 7075 7473 5b30 5d0a 2020  x = inputs[0].  
+0000b6d0: 2020 2020 2020 7920 3d20 696e 7075 7473        y = inputs
+0000b6e0: 5b31 5d0a 0a20 2020 2069 6620 6c65 6e28  [1]..    if len(
+0000b6f0: 696e 7075 7473 2920 3e20 323a 0a20 2020  inputs) > 2:.   
+0000b700: 2020 2020 2061 6c70 6861 203d 2069 6e70       alpha = inp
+0000b710: 7574 735b 325d 2e76 616c 0a0a 2020 2020  uts[2].val..    
+0000b720: 2020 2020 2320 544f 444f 2028 7362 6572      # TODO (sber
+0000b730: 6172 6469 293a 2033 7264 2070 6172 616d  ardi): 3rd param
+0000b740: 2074 6f20 6174 656e 3a3a 7375 6220 6973   to aten::sub is
+0000b750: 2061 2073 6361 6c65 2066 6163 746f 722c   a scale factor,
+0000b760: 206e 6565 6420 746f 2068 616e 646c 6520   need to handle 
+0000b770: 7468 6174 2e0a 2020 2020 2020 2020 2320  that..        # 
+0000b780: 6f75 743d 696e 7075 742d 616c 7068 6120  out=input-alpha 
+0000b790: 7820 6f74 6865 720a 2020 2020 2020 2020  x other.        
+0000b7a0: 2320 7264 6172 3a2f 2f36 3031 3735 3733  # rdar://6017573
+0000b7b0: 360a 2020 2020 2020 2020 6966 2061 6c70  6.        if alp
+0000b7c0: 6861 2021 3d20 313a 0a20 2020 2020 2020  ha != 1:.       
+0000b7d0: 2020 2020 2072 6169 7365 2056 616c 7565       raise Value
+0000b7e0: 4572 726f 7228 2253 5542 2064 6f65 7320  Error("SUB does 
+0000b7f0: 6e6f 7420 7375 7070 6f72 7420 7363 616c  not support scal
+0000b800: 6520 6661 6374 6f72 2070 6172 616d 2229  e factor param")
+0000b810: 0a0a 2020 2020 782c 2079 203d 2070 726f  ..    x, y = pro
+0000b820: 6d6f 7465 5f69 6e70 7574 5f64 7479 7065  mote_input_dtype
+0000b830: 7328 5b78 2c20 795d 290a 2020 2020 7265  s([x, y]).    re
+0000b840: 7320 3d20 6d62 2e73 7562 2878 3d78 2c20  s = mb.sub(x=x, 
+0000b850: 793d 792c 206e 616d 653d 6e6f 6465 2e6e  y=y, name=node.n
+0000b860: 616d 6529 0a20 2020 2063 6f6e 7465 7874  ame).    context
+0000b870: 2e61 6464 2872 6573 290a 0a0a 4072 6567  .add(res)...@reg
+0000b880: 6973 7465 725f 746f 7263 685f 6f70 280a  ister_torch_op(.
+0000b890: 2020 2020 746f 7263 685f 616c 6961 733d      torch_alias=
+0000b8a0: 5b0a 2020 2020 2020 2020 2273 756d 222c  [.        "sum",
+0000b8b0: 0a20 2020 2020 2020 2022 6c6f 6773 756d  .        "logsum
+0000b8c0: 6578 7022 2c0a 2020 2020 5d29 0a64 6566  exp",.    ]).def
+0000b8d0: 206d 6561 6e28 636f 6e74 6578 742c 206e   mean(context, n
+0000b8e0: 6f64 6529 3a0a 2020 2020 696e 7075 7473  ode):.    inputs
+0000b8f0: 203d 205f 6765 745f 696e 7075 7473 2863   = _get_inputs(c
+0000b900: 6f6e 7465 7874 2c20 6e6f 6465 290a 0a20  ontext, node).. 
+0000b910: 2020 2078 203d 2069 6e70 7574 735b 305d     x = inputs[0]
+0000b920: 0a20 2020 2069 6620 7479 7065 732e 6973  .    if types.is
+0000b930: 5f62 6f6f 6c28 782e 6474 7970 6529 3a0a  _bool(x.dtype):.
+0000b940: 2020 2020 2020 2020 2320 544f 444f 3a20          # TODO: 
+0000b950: 496e 2074 6865 2066 7574 7572 6520 7768  In the future wh
+0000b960: 656e 204d 494c 206f 7020 7375 7070 6f72  en MIL op suppor
+0000b970: 7473 2062 6f6f 6c2c 2077 6520 6e65 6564  ts bool, we need
+0000b980: 2074 6f20 7573 6520 6375 7272 5f6f 7073   to use curr_ops
+0000b990: 6574 5f76 6572 7369 6f6e 2074 6f20 6465  et_version to de
+0000b9a0: 6369 6465 0a20 2020 2020 2020 2023 2069  cide.        # i
+0000b9b0: 6620 7765 2077 616e 7420 746f 2063 6173  f we want to cas
+0000b9c0: 7420 6f72 206e 6f74 2e0a 2020 2020 2020  t or not..      
+0000b9d0: 2020 7820 3d20 6d62 2e63 6173 7428 783d    x = mb.cast(x=
+0000b9e0: 782c 2064 7479 7065 3d22 6670 3332 2229  x, dtype="fp32")
+0000b9f0: 0a20 2020 206b 7761 7267 7320 3d20 7b22  .    kwargs = {"
+0000ba00: 7822 3a20 782c 2022 6e61 6d65 223a 206e  x": x, "name": n
+0000ba10: 6f64 652e 6e61 6d65 7d0a 0a20 2020 2023  ode.name}..    #
+0000ba20: 2040 6178 6573 2069 7320 6f70 7469 6f6e   @axes is option
+0000ba30: 616c 2c20 736f 206f 6d69 7420 6966 204e  al, so omit if N
+0000ba40: 6f6e 652e 0a20 2020 2061 7865 7320 3d20  one..    axes = 
+0000ba50: 696e 7075 7473 5b31 5d0a 2020 2020 6966  inputs[1].    if
+0000ba60: 2061 7865 7320 6973 206e 6f74 204e 6f6e   axes is not Non
+0000ba70: 653a 0a20 2020 2020 2020 2023 2040 6178  e:.        # @ax
+0000ba80: 6573 206e 6565 6473 2074 6f20 6265 2061  es needs to be a
+0000ba90: 206c 6973 742c 2062 7574 2069 6620 6f6e   list, but if on
+0000baa0: 6c79 206f 6e65 2061 7869 7320 7761 7320  ly one axis was 
+0000bab0: 7370 6563 6966 6965 6420 696e 2074 6865  specified in the
+0000bac0: 0a20 2020 2020 2020 2023 206d 6f64 656c  .        # model
+0000bad0: 2c20 6974 2077 696c 6c20 6265 2063 6f6e  , it will be con
+0000bae0: 7374 7275 6374 6564 2061 7320 616e 2069  structed as an i
+0000baf0: 6e74 2e20 436f 6e73 7472 7563 7420 6120  nt. Construct a 
+0000bb00: 6e65 7720 636f 6e73 7461 6e74 2061 7320  new constant as 
+0000bb10: 610a 2020 2020 2020 2020 2320 6c69 7374  a.        # list
+0000bb20: 2e0a 2020 2020 2020 2020 6966 206e 6f74  ..        if not
+0000bb30: 2069 7369 6e73 7461 6e63 6528 6178 6573   isinstance(axes
+0000bb40: 2e76 616c 2c20 5f6e 702e 6e64 6172 7261  .val, _np.ndarra
+0000bb50: 7929 3a0a 2020 2020 2020 2020 2020 2020  y):.            
+0000bb60: 6178 6573 203d 206d 622e 636f 6e73 7428  axes = mb.const(
+0000bb70: 7661 6c3d 5b61 7865 732e 7661 6c5d 2c20  val=[axes.val], 
+0000bb80: 6e61 6d65 3d61 7865 732e 6e61 6d65 202b  name=axes.name +
+0000bb90: 2022 5f6c 6973 7422 290a 2020 2020 2020   "_list").      
+0000bba0: 2020 2020 2020 636f 6e74 6578 742e 6164        context.ad
+0000bbb0: 6428 6178 6573 290a 2020 2020 2020 2020  d(axes).        
+0000bbc0: 6b77 6172 6773 5b22 6178 6573 225d 203d  kwargs["axes"] =
+0000bbd0: 2061 7865 730a 0a20 2020 2023 2040 6b65   axes..    # @ke
+0000bbe0: 6570 5f64 696d 7320 6973 206f 7074 696f  ep_dims is optio
+0000bbf0: 6e61 6c2e 0a20 2020 2069 6620 6c65 6e28  nal..    if len(
+0000bc00: 696e 7075 7473 2920 3e3d 2033 3a0a 2020  inputs) >= 3:.  
+0000bc10: 2020 2020 2020 6b65 6570 5f64 696d 7320        keep_dims 
+0000bc20: 3d20 696e 7075 7473 5b32 5d0a 2020 2020  = inputs[2].    
+0000bc30: 2020 2020 6b77 6172 6773 5b22 6b65 6570      kwargs["keep
+0000bc40: 5f64 696d 7322 5d20 3d20 6b65 6570 5f64  _dims"] = keep_d
+0000bc50: 696d 730a 0a20 2020 2023 204c 6173 7420  ims..    # Last 
+0000bc60: 696e 7075 7420 746f 206d 6561 6e20 6973  input to mean is
+0000bc70: 2061 6e20 6f70 7469 6f6e 616c 206f 7574   an optional out
+0000bc80: 7075 7420 7465 6e73 6f72 2e20 5765 2061  put tensor. We a
+0000bc90: 6c77 6179 7320 6578 7065 6374 2074 6869  lways expect thi
+0000bca0: 7320 746f 0a20 2020 2023 2062 6520 4e6f  s to.    # be No
+0000bcb0: 6e65 206f 7220 6162 7365 6e74 2e0a 2020  ne or absent..  
+0000bcc0: 2020 6173 7365 7274 206c 656e 2869 6e70    assert len(inp
+0000bcd0: 7574 7329 203c 3d20 3320 6f72 2069 6e70  uts) <= 3 or inp
+0000bce0: 7574 735b 335d 2069 7320 4e6f 6e65 0a20  uts[3] is None. 
+0000bcf0: 2020 2069 6620 6e6f 6465 2e6b 696e 6420     if node.kind 
+0000bd00: 3d3d 2022 7375 6d22 3a0a 2020 2020 2020  == "sum":.      
+0000bd10: 2020 7265 7320 3d20 6d62 2e72 6564 7563    res = mb.reduc
+0000bd20: 655f 7375 6d28 2a2a 6b77 6172 6773 290a  e_sum(**kwargs).
+0000bd30: 2020 2020 656c 6966 206e 6f64 652e 6b69      elif node.ki
+0000bd40: 6e64 203d 3d20 226c 6f67 7375 6d65 7870  nd == "logsumexp
+0000bd50: 223a 0a20 2020 2020 2020 2072 6573 203d  ":.        res =
+0000bd60: 206d 622e 7265 6475 6365 5f6c 6f67 5f73   mb.reduce_log_s
+0000bd70: 756d 5f65 7870 282a 2a6b 7761 7267 7329  um_exp(**kwargs)
+0000bd80: 0a20 2020 2065 6c73 653a 0a20 2020 2020  .    else:.     
+0000bd90: 2020 2072 6573 203d 206d 622e 7265 6475     res = mb.redu
+0000bda0: 6365 5f6d 6561 6e28 2a2a 6b77 6172 6773  ce_mean(**kwargs
+0000bdb0: 290a 2020 2020 636f 6e74 6578 742e 6164  ).    context.ad
+0000bdc0: 6428 7265 7329 0a0a 0a40 7265 6769 7374  d(res)...@regist
+0000bdd0: 6572 5f74 6f72 6368 5f6f 700a 6465 6620  er_torch_op.def 
+0000bde0: 7371 7565 657a 6528 636f 6e74 6578 742c  squeeze(context,
+0000bdf0: 206e 6f64 6529 3a0a 2020 2020 696e 7075   node):.    inpu
+0000be00: 7473 203d 205f 6765 745f 696e 7075 7473  ts = _get_inputs
+0000be10: 2863 6f6e 7465 7874 2c20 6e6f 6465 290a  (context, node).
+0000be20: 2020 2020 6966 206c 656e 2869 6e70 7574      if len(input
+0000be30: 7329 203d 3d20 313a 0a20 2020 2020 2020  s) == 1:.       
+0000be40: 2072 6573 203d 206d 622e 7371 7565 657a   res = mb.squeez
+0000be50: 6528 783d 696e 7075 7473 5b30 5d2c 206e  e(x=inputs[0], n
+0000be60: 616d 653d 6e6f 6465 2e6e 616d 6529 0a20  ame=node.name). 
+0000be70: 2020 2065 6c69 6620 6c65 6e28 696e 7075     elif len(inpu
+0000be80: 7473 2920 3d3d 2032 3a0a 2020 2020 2020  ts) == 2:.      
+0000be90: 2020 7371 7565 657a 655f 6469 6d20 3d20    squeeze_dim = 
+0000bea0: 696e 7075 7473 5b31 5d2e 7661 6c0a 2020  inputs[1].val.  
+0000beb0: 2020 2020 2020 7265 7320 3d20 6d62 2e73        res = mb.s
+0000bec0: 7175 6565 7a65 2878 3d69 6e70 7574 735b  queeze(x=inputs[
+0000bed0: 305d 2c20 6178 6573 3d28 7371 7565 657a  0], axes=(squeez
+0000bee0: 655f 6469 6d2c 292c 206e 616d 653d 6e6f  e_dim,), name=no
+0000bef0: 6465 2e6e 616d 6529 0a20 2020 2063 6f6e  de.name).    con
+0000bf00: 7465 7874 2e61 6464 2872 6573 290a 0a0a  text.add(res)...
+0000bf10: 4072 6567 6973 7465 725f 746f 7263 685f  @register_torch_
+0000bf20: 6f70 0a64 6566 2075 6e73 7175 6565 7a65  op.def unsqueeze
+0000bf30: 2863 6f6e 7465 7874 2c20 6e6f 6465 293a  (context, node):
+0000bf40: 0a20 2020 2069 6e70 7574 7320 3d20 5f67  .    inputs = _g
+0000bf50: 6574 5f69 6e70 7574 7328 636f 6e74 6578  et_inputs(contex
+0000bf60: 742c 206e 6f64 652c 2065 7870 6563 7465  t, node, expecte
+0000bf70: 643d 3229 0a20 2020 2075 6e73 7175 6565  d=2).    unsquee
+0000bf80: 7a65 203d 206d 622e 6578 7061 6e64 5f64  ze = mb.expand_d
+0000bf90: 696d 7328 783d 696e 7075 7473 5b30 5d2c  ims(x=inputs[0],
+0000bfa0: 2061 7865 733d 5b69 6e70 7574 735b 315d   axes=[inputs[1]
+0000bfb0: 2e76 616c 5d2c 206e 616d 653d 6e6f 6465  .val], name=node
+0000bfc0: 2e6e 616d 6529 0a20 2020 2063 6f6e 7465  .name).    conte
+0000bfd0: 7874 2e61 6464 2875 6e73 7175 6565 7a65  xt.add(unsqueeze
+0000bfe0: 290a 0a0a 4072 6567 6973 7465 725f 746f  )...@register_to
+0000bff0: 7263 685f 6f70 0a64 6566 2073 697a 6528  rch_op.def size(
+0000c000: 636f 6e74 6578 742c 206e 6f64 6529 3a0a  context, node):.
+0000c010: 2020 2020 696e 7075 7473 203d 205f 6765      inputs = _ge
+0000c020: 745f 696e 7075 7473 2863 6f6e 7465 7874  t_inputs(context
+0000c030: 2c20 6e6f 6465 2c20 6578 7065 6374 6564  , node, expected
+0000c040: 3d5b 312c 2032 5d29 0a20 2020 2078 203d  =[1, 2]).    x =
+0000c050: 2069 6e70 7574 735b 305d 0a0a 2020 2020   inputs[0]..    
+0000c060: 2320 4765 7420 7468 6520 7368 6170 6520  # Get the shape 
+0000c070: 6f66 2074 6865 2074 656e 736f 722e 0a20  of the tensor.. 
+0000c080: 2020 2069 6620 7479 7065 732e 6973 5f63     if types.is_c
+0000c090: 6f6d 706c 6578 2878 2e64 7479 7065 293a  omplex(x.dtype):
+0000c0a0: 0a20 2020 2020 2020 2073 697a 655f 6e6f  .        size_no
+0000c0b0: 6465 203d 206d 622e 636f 6d70 6c65 785f  de = mb.complex_
+0000c0c0: 7368 6170 6528 783d 696e 7075 7473 5b30  shape(x=inputs[0
+0000c0d0: 5d2c 206e 616d 653d 6e6f 6465 2e6e 616d  ], name=node.nam
+0000c0e0: 6520 2b20 225f 7368 6170 6522 290a 2020  e + "_shape").  
+0000c0f0: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
+0000c100: 7369 7a65 5f6e 6f64 6520 3d20 6d62 2e73  size_node = mb.s
+0000c110: 6861 7065 2878 3d69 6e70 7574 735b 305d  hape(x=inputs[0]
+0000c120: 2c20 6e61 6d65 3d6e 6f64 652e 6e61 6d65  , name=node.name
+0000c130: 202b 2022 5f73 6861 7065 2229 0a0a 2020   + "_shape")..  
+0000c140: 2020 2320 4765 7420 7468 6520 7369 7a65    # Get the size
+0000c150: 206f 6620 7468 6520 7465 6e73 6f72 2061   of the tensor a
+0000c160: 6c6f 6e67 2074 6865 2069 6e70 7574 2064  long the input d
+0000c170: 696d 656e 7369 6f6e 2e0a 2020 2020 6966  imension..    if
+0000c180: 206c 656e 286e 6f64 652e 696e 7075 7473   len(node.inputs
+0000c190: 2920 3d3d 2032 3a0a 2020 2020 2020 2020  ) == 2:.        
+0000c1a0: 6469 6d20 3d20 696e 7075 7473 5b31 5d2e  dim = inputs[1].
+0000c1b0: 7661 6c0a 2020 2020 2020 2020 7369 7a65  val.        size
+0000c1c0: 5f6e 6f64 6520 3d20 5f6c 6973 745f 7365  _node = _list_se
+0000c1d0: 6c65 6374 2873 697a 655f 6e6f 6465 2c20  lect(size_node, 
+0000c1e0: 6469 6d29 0a20 2020 2063 6f6e 7465 7874  dim).    context
+0000c1f0: 2e61 6464 2873 697a 655f 6e6f 6465 2c20  .add(size_node, 
+0000c200: 6e6f 6465 2e6e 616d 6529 0a0a 0a40 7265  node.name)...@re
+0000c210: 6769 7374 6572 5f74 6f72 6368 5f6f 700a  gister_torch_op.
+0000c220: 6465 6620 5f73 6861 7065 5f61 735f 7465  def _shape_as_te
+0000c230: 6e73 6f72 2863 6f6e 7465 7874 2c20 6e6f  nsor(context, no
+0000c240: 6465 293a 0a20 2020 2069 6e70 7574 7320  de):.    inputs 
+0000c250: 3d20 5f67 6574 5f69 6e70 7574 7328 636f  = _get_inputs(co
+0000c260: 6e74 6578 742c 206e 6f64 652c 2065 7870  ntext, node, exp
+0000c270: 6563 7465 643d 3129 0a0a 2020 2020 2320  ected=1)..    # 
+0000c280: 4765 7420 7468 6520 7368 6170 6520 6f66  Get the shape of
+0000c290: 2074 6865 2074 656e 736f 722e 0a20 2020   the tensor..   
+0000c2a0: 2073 6861 7065 5f6e 6f64 6520 3d20 6d62   shape_node = mb
+0000c2b0: 2e73 6861 7065 2878 3d69 6e70 7574 735b  .shape(x=inputs[
+0000c2c0: 305d 2c20 6e61 6d65 3d6e 6f64 652e 6e61  0], name=node.na
+0000c2d0: 6d65 290a 2020 2020 636f 6e74 6578 742e  me).    context.
+0000c2e0: 6164 6428 7368 6170 655f 6e6f 6465 2c20  add(shape_node, 
+0000c2f0: 6e6f 6465 2e6e 616d 6529 0a0a 0a40 7265  node.name)...@re
+0000c300: 6769 7374 6572 5f74 6f72 6368 5f6f 7028  gister_torch_op(
+0000c310: 746f 7263 685f 616c 6961 733d 5b22 7265  torch_alias=["re
+0000c320: 7368 6170 6522 5d29 0a64 6566 2076 6965  shape"]).def vie
+0000c330: 7728 636f 6e74 6578 742c 206e 6f64 6529  w(context, node)
+0000c340: 3a0a 2020 2020 696e 7075 7473 203d 205f  :.    inputs = _
+0000c350: 6765 745f 696e 7075 7473 2863 6f6e 7465  get_inputs(conte
+0000c360: 7874 2c20 6e6f 6465 2c20 6578 7065 6374  xt, node, expect
+0000c370: 6564 3d32 290a 2020 2020 7820 3d20 696e  ed=2).    x = in
+0000c380: 7075 7473 5b30 5d0a 2020 2020 7368 6170  puts[0].    shap
+0000c390: 6520 3d20 696e 7075 7473 5b31 5d0a 0a20  e = inputs[1].. 
+0000c3a0: 2020 2069 6620 6973 696e 7374 616e 6365     if isinstance
+0000c3b0: 2873 6861 7065 2c20 4c69 7374 5661 7229  (shape, ListVar)
+0000c3c0: 3a0a 2020 2020 2020 2020 6c65 6e67 7468  :.        length
+0000c3d0: 203d 206d 622e 6c69 7374 5f6c 656e 6774   = mb.list_lengt
+0000c3e0: 6828 6c73 3d73 6861 7065 290a 2020 2020  h(ls=shape).    
+0000c3f0: 2020 2020 696e 6469 6365 7320 3d20 6d62      indices = mb
+0000c400: 2e72 616e 6765 5f31 6428 7374 6172 743d  .range_1d(start=
+0000c410: 302c 2065 6e64 3d6c 656e 6774 682c 2073  0, end=length, s
+0000c420: 7465 703d 3129 0a20 2020 2020 2020 2073  tep=1).        s
+0000c430: 6861 7065 203d 206d 622e 6c69 7374 5f67  hape = mb.list_g
+0000c440: 6174 6865 7228 6c73 3d73 6861 7065 2c20  ather(ls=shape, 
+0000c450: 696e 6469 6365 733d 696e 6469 6365 7329  indices=indices)
+0000c460: 0a0a 2020 2020 6966 2028 0a20 2020 2020  ..    if (.     
+0000c470: 2020 2069 7369 6e73 7461 6e63 6528 7368     isinstance(sh
+0000c480: 6170 652c 206c 6973 7429 0a20 2020 2020  ape, list).     
+0000c490: 2020 2061 6e64 2061 6c6c 285b 6973 696e     and all([isin
+0000c4a0: 7374 616e 6365 2864 696d 2c20 5661 7229  stance(dim, Var)
+0000c4b0: 2061 6e64 206c 656e 2864 696d 2e73 6861   and len(dim.sha
+0000c4c0: 7065 2920 3d3d 2030 2066 6f72 2064 696d  pe) == 0 for dim
+0000c4d0: 2069 6e20 7368 6170 655d 290a 2020 2020   in shape]).    
+0000c4e0: 2020 2020 616e 6420 616e 7928 5b64 696d      and any([dim
+0000c4f0: 2e76 616c 2069 7320 4e6f 6e65 2066 6f72  .val is None for
+0000c500: 2064 696d 2069 6e20 7368 6170 655d 290a   dim in shape]).
+0000c510: 2020 2020 293a 0a20 2020 2020 2020 2073      ):.        s
+0000c520: 6861 7065 203d 206d 622e 636f 6e63 6174  hape = mb.concat
+0000c530: 2876 616c 7565 733d 7368 6170 652c 2061  (values=shape, a
+0000c540: 7869 733d 3029 0a0a 2020 2020 7368 6170  xis=0)..    shap
+0000c550: 6520 3d20 6d62 2e63 6173 7428 783d 7368  e = mb.cast(x=sh
+0000c560: 6170 652c 2064 7479 7065 3d22 696e 7433  ape, dtype="int3
+0000c570: 3222 290a 0a20 2020 2069 6620 7479 7065  2")..    if type
+0000c580: 732e 6973 5f63 6f6d 706c 6578 2878 2e64  s.is_complex(x.d
+0000c590: 7479 7065 293a 0a20 2020 2020 2020 2072  type):.        r
+0000c5a0: 6561 6c2c 2069 6d61 6720 3d20 286d 622e  eal, imag = (mb.
+0000c5b0: 7265 7368 6170 6528 783d 782c 2073 6861  reshape(x=x, sha
+0000c5c0: 7065 3d73 6861 7065 2c20 6e61 6d65 3d6e  pe=shape, name=n
+0000c5d0: 6f64 652e 6e61 6d65 2920 666f 7220 7820  ode.name) for x 
+0000c5e0: 696e 2028 6d62 2e63 6f6d 706c 6578 5f72  in (mb.complex_r
+0000c5f0: 6561 6c28 6461 7461 3d78 292c 206d 622e  eal(data=x), mb.
+0000c600: 636f 6d70 6c65 785f 696d 6167 2864 6174  complex_imag(dat
+0000c610: 613d 7829 2929 0a20 2020 2020 2020 2076  a=x))).        v
+0000c620: 6965 7720 3d20 6d62 2e63 6f6d 706c 6578  iew = mb.complex
+0000c630: 2872 6561 6c5f 6461 7461 3d72 6561 6c2c  (real_data=real,
+0000c640: 2069 6d61 675f 6461 7461 3d69 6d61 672c   imag_data=imag,
+0000c650: 206e 616d 653d 6e6f 6465 2e6e 616d 6529   name=node.name)
+0000c660: 0a20 2020 2065 6c73 653a 0a20 2020 2020  .    else:.     
+0000c670: 2020 2076 6965 7720 3d20 6d62 2e72 6573     view = mb.res
+0000c680: 6861 7065 2878 3d78 2c20 7368 6170 653d  hape(x=x, shape=
+0000c690: 7368 6170 652c 206e 616d 653d 6e6f 6465  shape, name=node
+0000c6a0: 2e6e 616d 6529 0a20 2020 2020 2020 200a  .name).        .
+0000c6b0: 2020 2020 636f 6e74 6578 742e 6164 6428      context.add(
+0000c6c0: 7669 6577 290a 0a0a 4072 6567 6973 7465  view)...@registe
+0000c6d0: 725f 746f 7263 685f 6f70 2874 6f72 6368  r_torch_op(torch
+0000c6e0: 5f61 6c69 6173 3d5b 2763 6f6e 7374 616e  _alias=['constan
+0000c6f0: 745f 7061 645f 6e64 275d 290a 6465 6620  t_pad_nd']).def 
+0000c700: 7061 6428 636f 6e74 6578 742c 206e 6f64  pad(context, nod
+0000c710: 6529 3a0a 2020 2020 696e 7075 7473 203d  e):.    inputs =
+0000c720: 205f 6765 745f 696e 7075 7473 2863 6f6e   _get_inputs(con
+0000c730: 7465 7874 2c20 6e6f 6465 290a 2020 2020  text, node).    
+0000c740: 7820 3d20 696e 7075 7473 5b30 5d0a 0a20  x = inputs[0].. 
+0000c750: 2020 2070 6164 203d 2069 6e70 7574 735b     pad = inputs[
+0000c760: 315d 0a20 2020 2069 6620 7061 642e 7661  1].    if pad.va
+0000c770: 6c20 6973 206e 6f74 204e 6f6e 653a 0a20  l is not None:. 
+0000c780: 2020 2020 2020 2070 6164 203d 2070 6164         pad = pad
+0000c790: 2e76 616c 2e72 6573 6861 7065 2828 2d31  .val.reshape((-1
+0000c7a0: 2c20 3229 295b 3a3a 2d31 5d2e 7265 7368  , 2))[::-1].resh
+0000c7b0: 6170 6528 2d31 292e 746f 6c69 7374 2829  ape(-1).tolist()
+0000c7c0: 0a20 2020 2020 2020 206d 6973 7369 6e67  .        missing
+0000c7d0: 5f64 696d 7320 3d20 782e 7261 6e6b 202d  _dims = x.rank -
+0000c7e0: 2028 6c65 6e28 7061 6429 202f 2f20 3229   (len(pad) // 2)
+0000c7f0: 0a20 2020 2020 2020 2070 6164 203d 205b  .        pad = [
+0000c800: 302c 2030 5d20 2a20 6d69 7373 696e 675f  0, 0] * missing_
+0000c810: 6469 6d73 202b 2070 6164 0a0a 2020 2020  dims + pad..    
+0000c820: 6966 206c 656e 2869 6e70 7574 7329 203d  if len(inputs) =
+0000c830: 3d20 343a 0a20 2020 2020 2020 206d 6f64  = 4:.        mod
+0000c840: 6520 3d20 696e 7075 7473 5b32 5d2e 7661  e = inputs[2].va
+0000c850: 6c0a 2020 2020 2020 2020 6173 7365 7274  l.        assert
+0000c860: 206d 6f64 6520 696e 2028 2763 6f6e 7374   mode in ('const
+0000c870: 616e 7427 2c20 2772 6566 6c65 6374 272c  ant', 'reflect',
+0000c880: 2027 7265 706c 6963 6174 6527 290a 2020   'replicate').  
+0000c890: 2020 2020 2020 7661 6c5f 696e 6465 7820        val_index 
+0000c8a0: 3d20 330a 2020 2020 656c 7365 3a0a 2020  = 3.    else:.  
+0000c8b0: 2020 2020 2020 6d6f 6465 203d 2027 636f        mode = 'co
+0000c8c0: 6e73 7461 6e74 270a 2020 2020 2020 2020  nstant'.        
+0000c8d0: 7661 6c5f 696e 6465 7820 3d20 320a 0a20  val_index = 2.. 
+0000c8e0: 2020 2073 6361 6c61 725f 7661 6c20 3d20     scalar_val = 
+0000c8f0: 696e 7075 7473 5b76 616c 5f69 6e64 6578  inputs[val_index
+0000c900: 5d20 6966 2069 6e70 7574 735b 7661 6c5f  ] if inputs[val_
+0000c910: 696e 6465 785d 2065 6c73 6520 302e 300a  index] else 0.0.
+0000c920: 2020 2020 6966 2069 6e70 7574 735b 7661      if inputs[va
+0000c930: 6c5f 696e 6465 785d 2061 6e64 2069 6e70  l_index] and inp
+0000c940: 7574 735b 7661 6c5f 696e 6465 785d 2e6f  uts[val_index].o
+0000c950: 702e 6f70 5f74 7970 6520 3d3d 2022 636f  p.op_type == "co
+0000c960: 6e73 7422 3a0a 2020 2020 2020 2020 7363  nst":.        sc
+0000c970: 616c 6172 5f76 616c 203d 2066 6c6f 6174  alar_val = float
+0000c980: 2873 6361 6c61 725f 7661 6c2e 7661 6c29  (scalar_val.val)
+0000c990: 0a0a 2020 2020 6966 2074 7970 6573 2e69  ..    if types.i
+0000c9a0: 735f 636f 6d70 6c65 7828 782e 6474 7970  s_complex(x.dtyp
+0000c9b0: 6529 3a0a 2020 2020 2020 2020 7265 616c  e):.        real
+0000c9c0: 2c20 696d 6167 203d 2028 6d62 2e70 6164  , imag = (mb.pad
+0000c9d0: 2878 3d78 2c20 7061 643d 7061 642c 206d  (x=x, pad=pad, m
+0000c9e0: 6f64 653d 6d6f 6465 2c20 636f 6e73 7461  ode=mode, consta
+0000c9f0: 6e74 5f76 616c 3d73 6361 6c61 725f 7661  nt_val=scalar_va
+0000ca00: 6c2c 206e 616d 653d 6e6f 6465 2e6e 616d  l, name=node.nam
+0000ca10: 6529 2066 6f72 2078 2069 6e20 286d 622e  e) for x in (mb.
+0000ca20: 636f 6d70 6c65 785f 7265 616c 2864 6174  complex_real(dat
+0000ca30: 613d 7829 2c20 6d62 2e63 6f6d 706c 6578  a=x), mb.complex
+0000ca40: 5f69 6d61 6728 6461 7461 3d78 2929 290a  _imag(data=x))).
+0000ca50: 2020 2020 2020 2020 7265 7320 3d20 6d62          res = mb
+0000ca60: 2e63 6f6d 706c 6578 2872 6561 6c5f 6461  .complex(real_da
+0000ca70: 7461 3d72 6561 6c2c 2069 6d61 675f 6461  ta=real, imag_da
+0000ca80: 7461 3d69 6d61 672c 206e 616d 653d 6e6f  ta=imag, name=no
+0000ca90: 6465 2e6e 616d 6529 0a20 2020 2065 6c73  de.name).    els
+0000caa0: 653a 0a20 2020 2020 2020 2072 6573 203d  e:.        res =
+0000cab0: 206d 622e 7061 6428 783d 782c 2070 6164   mb.pad(x=x, pad
+0000cac0: 3d70 6164 2c20 6d6f 6465 3d6d 6f64 652c  =pad, mode=mode,
+0000cad0: 2063 6f6e 7374 616e 745f 7661 6c3d 7363   constant_val=sc
+0000cae0: 616c 6172 5f76 616c 2c20 6e61 6d65 3d6e  alar_val, name=n
+0000caf0: 6f64 652e 6e61 6d65 290a 2020 2020 636f  ode.name).    co
+0000cb00: 6e74 6578 742e 6164 6428 7265 7329 0a0a  ntext.add(res)..
+0000cb10: 0a40 7265 6769 7374 6572 5f74 6f72 6368  .@register_torch
+0000cb20: 5f6f 700a 6465 6620 6164 6170 7469 7665  _op.def adaptive
+0000cb30: 5f61 7667 5f70 6f6f 6c32 6428 636f 6e74  _avg_pool2d(cont
+0000cb40: 6578 742c 206e 6f64 6529 3a0a 2020 2020  ext, node):.    
+0000cb50: 5f61 6461 7074 6976 655f 706f 6f6c 3264  _adaptive_pool2d
+0000cb60: 2863 6f6e 7465 7874 2c20 6e6f 6465 2c20  (context, node, 
+0000cb70: 6d62 2e61 7667 5f70 6f6f 6c2c 206d 622e  mb.avg_pool, mb.
+0000cb80: 7265 6475 6365 5f6d 6561 6e29 0a0a 0a40  reduce_mean)...@
+0000cb90: 7265 6769 7374 6572 5f74 6f72 6368 5f6f  register_torch_o
+0000cba0: 700a 6465 6620 6164 6170 7469 7665 5f6d  p.def adaptive_m
+0000cbb0: 6178 5f70 6f6f 6c32 6428 636f 6e74 6578  ax_pool2d(contex
+0000cbc0: 742c 206e 6f64 6529 3a0a 2020 2020 5f61  t, node):.    _a
+0000cbd0: 6461 7074 6976 655f 706f 6f6c 3264 2863  daptive_pool2d(c
+0000cbe0: 6f6e 7465 7874 2c20 6e6f 6465 2c20 6d62  ontext, node, mb
+0000cbf0: 2e6d 6178 5f70 6f6f 6c2c 206d 622e 7265  .max_pool, mb.re
+0000cc00: 6475 6365 5f6d 6178 290a 0a0a 6465 6620  duce_max)...def 
+0000cc10: 5f61 6461 7074 6976 655f 706f 6f6c 3264  _adaptive_pool2d
+0000cc20: 5f6e 6f6e 5f66 6978 6564 5f6b 6572 6e65  _non_fixed_kerne
+0000cc30: 6c5f 7369 7a65 5f61 6e64 5f73 7472 6964  l_size_and_strid
+0000cc40: 6528 782c 206f 7574 7075 745f 7368 6170  e(x, output_shap
+0000cc50: 652c 206e 616d 652c 2072 6564 7563 655f  e, name, reduce_
+0000cc60: 6f70 293a 0a20 2020 2027 2727 0a20 2020  op):.    '''.   
+0000cc70: 2049 6620 7468 6520 696e 7075 7420 6469   If the input di
+0000cc80: 6d65 6e73 696f 6e20 6973 206e 6f74 2065  mension is not e
+0000cc90: 7665 6e6c 7920 6469 7669 7369 626c 6520  venly divisible 
+0000cca0: 6279 2074 6865 206f 7574 7075 7420 6469  by the output di
+0000ccb0: 6d65 6e73 696f 6e2c 2074 6865 6e20 7468  mension, then th
+0000ccc0: 650a 2020 2020 7374 7269 6465 2061 6e64  e.    stride and
+0000ccd0: 206b 6572 6e65 6c20 7369 7a65 2075 7365   kernel size use
+0000cce0: 6420 6279 2050 7954 6f72 6368 2069 7320  d by PyTorch is 
+0000ccf0: 6e6f 7420 6669 7865 642e 2054 6869 7320  not fixed. This 
+0000cd00: 6973 2074 7275 6520 666f 7220 626f 7468  is true for both
+0000cd10: 2074 6865 0a20 2020 2068 6569 6768 7420   the.    height 
+0000cd20: 616e 6420 7769 6474 6820 6469 6d65 6e73  and width dimens
+0000cd30: 696f 6e2e 0a20 2020 2027 2727 0a0a 2020  ion..    '''..  
+0000cd40: 2020 6465 6620 6765 745f 6b65 726e 656c    def get_kernel
+0000cd50: 5f69 6e64 6578 6573 5f31 6428 696e 5f64  _indexes_1d(in_d
+0000cd60: 696d 656e 7369 6f6e 2c20 6f75 745f 6469  imension, out_di
+0000cd70: 6d65 6e73 696f 6e29 3a0a 2020 2020 2020  mension):.      
+0000cd80: 2020 7265 7375 6c74 7320 3d20 5b5d 0a20    results = []. 
+0000cd90: 2020 2020 2020 2066 6f72 2069 2069 6e20         for i in 
+0000cda0: 7261 6e67 6528 6f75 745f 6469 6d65 6e73  range(out_dimens
+0000cdb0: 696f 6e29 3a0a 2020 2020 2020 2020 2020  ion):.          
+0000cdc0: 2020 7374 6172 7420 3d20 5f6d 6174 682e    start = _math.
+0000cdd0: 666c 6f6f 7228 6920 2a20 696e 5f64 696d  floor(i * in_dim
+0000cde0: 656e 7369 6f6e 202f 206f 7574 5f64 696d  ension / out_dim
+0000cdf0: 656e 7369 6f6e 290a 2020 2020 2020 2020  ension).        
+0000ce00: 2020 2020 656e 6420 3d20 5f6d 6174 682e      end = _math.
+0000ce10: 6365 696c 2828 6920 2b20 3129 202a 2069  ceil((i + 1) * i
+0000ce20: 6e5f 6469 6d65 6e73 696f 6e20 2f20 6f75  n_dimension / ou
+0000ce30: 745f 6469 6d65 6e73 696f 6e29 0a20 2020  t_dimension).   
+0000ce40: 2020 2020 2020 2020 2072 6573 756c 7473           results
+0000ce50: 2e61 7070 656e 6428 2873 7461 7274 2c20  .append((start, 
+0000ce60: 656e 6429 290a 0a20 2020 2020 2020 2072  end))..        r
+0000ce70: 6574 7572 6e20 7265 7375 6c74 730a 0a20  eturn results.. 
+0000ce80: 2020 2070 6f6f 6c5f 7265 7375 6c74 7320     pool_results 
+0000ce90: 3d20 5b5d 0a0a 2020 2020 666f 7220 7332  = []..    for s2
+0000cea0: 2c20 6532 2069 6e20 6765 745f 6b65 726e  , e2 in get_kern
+0000ceb0: 656c 5f69 6e64 6578 6573 5f31 6428 782e  el_indexes_1d(x.
+0000cec0: 7368 6170 655b 325d 2c20 6f75 7470 7574  shape[2], output
+0000ced0: 5f73 6861 7065 5b30 5d29 3a0a 2020 2020  _shape[0]):.    
+0000cee0: 2020 2020 666f 7220 7333 2c20 6533 2069      for s3, e3 i
+0000cef0: 6e20 6765 745f 6b65 726e 656c 5f69 6e64  n get_kernel_ind
+0000cf00: 6578 6573 5f31 6428 782e 7368 6170 655b  exes_1d(x.shape[
+0000cf10: 335d 2c20 6f75 7470 7574 5f73 6861 7065  3], output_shape
+0000cf20: 5b31 5d29 3a0a 2020 2020 2020 2020 2020  [1]):.          
+0000cf30: 2020 6375 725f 6b65 726e 656c 203d 206d    cur_kernel = m
+0000cf40: 622e 736c 6963 655f 6279 5f69 6e64 6578  b.slice_by_index
+0000cf50: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
+0000cf60: 2020 783d 782c 0a20 2020 2020 2020 2020    x=x,.         
+0000cf70: 2020 2020 2020 2062 6567 696e 3d5b 302c         begin=[0,
+0000cf80: 2030 2c20 7332 2c20 7333 5d2c 0a20 2020   0, s2, s3],.   
+0000cf90: 2020 2020 2020 2020 2020 2020 2065 6e64               end
+0000cfa0: 3d5b 782e 7368 6170 655b 305d 2c20 782e  =[x.shape[0], x.
+0000cfb0: 7368 6170 655b 315d 2c20 6532 2c20 6533  shape[1], e2, e3
+0000cfc0: 5d2c 0a20 2020 2020 2020 2020 2020 2029  ],.            )
+0000cfd0: 0a20 2020 2020 2020 2020 2020 2063 7572  .            cur
+0000cfe0: 5f72 6573 756c 7420 3d20 7265 6475 6365  _result = reduce
+0000cff0: 5f6f 7028 0a20 2020 2020 2020 2020 2020  _op(.           
+0000d000: 2020 2020 2078 3d63 7572 5f6b 6572 6e65       x=cur_kerne
+0000d010: 6c2c 0a20 2020 2020 2020 2020 2020 2020  l,.             
+0000d020: 2020 2061 7865 733d 5b2d 322c 202d 315d     axes=[-2, -1]
+0000d030: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+0000d040: 2020 6b65 6570 5f64 696d 733d 5472 7565    keep_dims=True
+0000d050: 0a20 2020 2020 2020 2020 2020 2029 0a20  .            ). 
+0000d060: 2020 2020 2020 2020 2020 2070 6f6f 6c5f             pool_
+0000d070: 7265 7375 6c74 732e 6170 7065 6e64 2863  results.append(c
+0000d080: 7572 5f72 6573 756c 7429 0a0a 2020 2020  ur_result)..    
+0000d090: 7265 7475 726e 206d 622e 7265 7368 6170  return mb.reshap
+0000d0a0: 6528 0a20 2020 2020 2020 2078 3d6d 622e  e(.        x=mb.
+0000d0b0: 636f 6e63 6174 2876 616c 7565 733d 706f  concat(values=po
+0000d0c0: 6f6c 5f72 6573 756c 7473 2c20 6178 6973  ol_results, axis
+0000d0d0: 3d2d 3129 2c0a 2020 2020 2020 2020 7368  =-1),.        sh
+0000d0e0: 6170 653d 5b78 2e73 6861 7065 5b30 5d2c  ape=[x.shape[0],
+0000d0f0: 2078 2e73 6861 7065 5b31 5d2c 206f 7574   x.shape[1], out
+0000d100: 7075 745f 7368 6170 655b 305d 2c20 6f75  put_shape[0], ou
+0000d110: 7470 7574 5f73 6861 7065 5b31 5d5d 2c0a  tput_shape[1]],.
+0000d120: 2020 2020 2020 2020 6e61 6d65 3d6e 616d          name=nam
+0000d130: 652c 0a20 2020 2029 0a0a 0a64 6566 205f  e,.    )...def _
+0000d140: 6164 6170 7469 7665 5f70 6f6f 6c32 6428  adaptive_pool2d(
+0000d150: 636f 6e74 6578 742c 206e 6f64 652c 2070  context, node, p
+0000d160: 6f6f 6c5f 6f70 2c20 7265 6475 6365 5f6f  ool_op, reduce_o
+0000d170: 7029 3a0a 2020 2020 2320 4765 7420 696e  p):.    # Get in
+0000d180: 7075 7420 7465 6e73 6f72 2061 6e64 206f  put tensor and o
+0000d190: 7574 7075 7420 7368 6170 650a 2020 2020  utput shape.    
+0000d1a0: 696e 7075 7473 203d 205f 6765 745f 696e  inputs = _get_in
+0000d1b0: 7075 7473 2863 6f6e 7465 7874 2c20 6e6f  puts(context, no
+0000d1c0: 6465 2c20 6578 7065 6374 6564 3d32 290a  de, expected=2).
+0000d1d0: 2020 2020 7820 3d20 696e 7075 7473 5b30      x = inputs[0
+0000d1e0: 5d0a 2020 2020 6f75 7470 7574 5f73 6861  ].    output_sha
+0000d1f0: 7065 203d 2069 6e70 7574 735b 315d 2e76  pe = inputs[1].v
+0000d200: 616c 0a20 2020 2061 7373 6572 7420 6973  al.    assert is
+0000d210: 696e 7374 616e 6365 286f 7574 7075 745f  instance(output_
+0000d220: 7368 6170 652c 205f 6e70 2e6e 6461 7272  shape, _np.ndarr
+0000d230: 6179 2920 616e 6420 6c65 6e28 6f75 7470  ay) and len(outp
+0000d240: 7574 5f73 6861 7065 2920 3d3d 2032 0a20  ut_shape) == 2. 
+0000d250: 2020 206f 7574 7075 745f 7368 6170 6520     output_shape 
+0000d260: 3d20 7475 706c 6528 6f75 7470 7574 5f73  = tuple(output_s
+0000d270: 6861 7065 290a 0a20 2020 2069 6620 6f75  hape)..    if ou
+0000d280: 7470 7574 5f73 6861 7065 203d 3d20 2831  tput_shape == (1
+0000d290: 2c20 3129 3a0a 2020 2020 2020 2020 2320  , 1):.        # 
+0000d2a0: 5265 7072 6573 656e 7420 2831 2c31 2920  Represent (1,1) 
+0000d2b0: 6f75 7470 7574 2073 697a 6520 7769 7468  output size with
+0000d2c0: 2067 6c6f 6261 6c20 7265 6475 6365 206f   global reduce o
+0000d2d0: 700a 2020 2020 2020 2020 7265 7375 6c74  p.        result
+0000d2e0: 203d 2072 6564 7563 655f 6f70 2878 3d78   = reduce_op(x=x
+0000d2f0: 2c20 6178 6573 3d5b 2d32 2c20 2d31 5d2c  , axes=[-2, -1],
+0000d300: 206b 6565 705f 6469 6d73 3d54 7275 652c   keep_dims=True,
+0000d310: 206e 616d 653d 6e6f 6465 2e6e 616d 6529   name=node.name)
+0000d320: 0a20 2020 2065 6c69 6620 782e 7368 6170  .    elif x.shap
+0000d330: 6520 6973 204e 6f6e 6520 6f72 2061 6e79  e is None or any
+0000d340: 5f73 796d 626f 6c69 6328 782e 7368 6170  _symbolic(x.shap
+0000d350: 6529 3a0a 2020 2020 2020 2020 7261 6973  e):.        rais
+0000d360: 6520 5661 6c75 6545 7272 6f72 280a 2020  e ValueError(.  
+0000d370: 2020 2020 2020 2020 2020 2241 6461 7074            "Adapt
+0000d380: 6976 6520 706f 6f6c 696e 6720 6973 206f  ive pooling is o
+0000d390: 6e6c 7920 7375 7070 6f72 7465 6420 7768  nly supported wh
+0000d3a0: 656e 2069 6e70 7574 2074 656e 736f 7220  en input tensor 
+0000d3b0: 7369 7a65 2069 7320 6b6e 6f77 6e20 6f72  size is known or
+0000d3c0: 206f 7574 7075 7420 7369 7a65 203d 3d20   output size == 
+0000d3d0: 2831 2c31 292e 2022 0a20 2020 2020 2020  (1,1). ".       
+0000d3e0: 2020 2020 2022 5265 6365 6976 6564 3a20       "Received: 
+0000d3f0: 696e 7075 7420 7369 7a65 203d 3d20 7b7d  input size == {}
+0000d400: 2c20 6f75 7470 7574 2073 697a 6520 3d3d  , output size ==
+0000d410: 207b 7d22 2e66 6f72 6d61 7428 0a20 2020   {}".format(.   
+0000d420: 2020 2020 2020 2020 2020 2020 2078 2e73               x.s
+0000d430: 6861 7065 5f73 7472 2829 2c20 6f75 7470  hape_str(), outp
+0000d440: 7574 5f73 6861 7065 2c0a 2020 2020 2020  ut_shape,.      
+0000d450: 2020 2020 2020 290a 2020 2020 2020 2020        ).        
+0000d460: 290a 2020 2020 656c 6966 2078 2e73 6861  ).    elif x.sha
+0000d470: 7065 5b2d 325d 2025 206f 7574 7075 745f  pe[-2] % output_
+0000d480: 7368 6170 655b 2d32 5d20 3d3d 2030 2061  shape[-2] == 0 a
+0000d490: 6e64 2078 2e73 6861 7065 5b2d 315d 2025  nd x.shape[-1] %
+0000d4a0: 206f 7574 7075 745f 7368 6170 655b 2d31   output_shape[-1
+0000d4b0: 5d20 3d3d 2030 3a0a 2020 2020 2020 2020  ] == 0:.        
+0000d4c0: 2320 5374 7269 6465 2061 6e64 2061 6e64  # Stride and and
+0000d4d0: 206b 6572 6e65 6c20 7369 7a65 2069 7320   kernel size is 
+0000d4e0: 6669 7865 640a 2020 2020 2020 2020 7374  fixed.        st
+0000d4f0: 7269 6465 7320 3d20 5b69 6e64 202f 2f20  rides = [ind // 
+0000d500: 6f75 7464 2066 6f72 2069 6e64 2c20 6f75  outd for ind, ou
+0000d510: 7464 2069 6e20 7a69 7028 782e 7368 6170  td in zip(x.shap
+0000d520: 655b 2d32 3a5d 2c20 6f75 7470 7574 5f73  e[-2:], output_s
+0000d530: 6861 7065 295d 0a20 2020 2020 2020 206b  hape)].        k
+0000d540: 6572 6e65 6c5f 7369 7a65 7320 3d20 5b0a  ernel_sizes = [.
+0000d550: 2020 2020 2020 2020 2020 2020 696e 6420              ind 
+0000d560: 2d20 7320 2a20 286f 7574 6420 2d20 3129  - s * (outd - 1)
+0000d570: 0a20 2020 2020 2020 2020 2020 2066 6f72  .            for
+0000d580: 2069 6e64 2c20 6f75 7464 2c20 7320 696e   ind, outd, s in
+0000d590: 207a 6970 2878 2e73 6861 7065 5b2d 323a   zip(x.shape[-2:
+0000d5a0: 5d2c 206f 7574 7075 745f 7368 6170 652c  ], output_shape,
+0000d5b0: 2073 7472 6964 6573 290a 2020 2020 2020   strides).      
+0000d5c0: 2020 5d0a 2020 2020 2020 2020 7265 7375    ].        resu
+0000d5d0: 6c74 203d 2070 6f6f 6c5f 6f70 280a 2020  lt = pool_op(.  
+0000d5e0: 2020 2020 2020 2020 2020 783d 782c 0a20            x=x,. 
+0000d5f0: 2020 2020 2020 2020 2020 206b 6572 6e65             kerne
+0000d600: 6c5f 7369 7a65 733d 6b65 726e 656c 5f73  l_sizes=kernel_s
+0000d610: 697a 6573 2c0a 2020 2020 2020 2020 2020  izes,.          
+0000d620: 2020 7374 7269 6465 733d 7374 7269 6465    strides=stride
+0000d630: 732c 0a20 2020 2020 2020 2020 2020 2070  s,.            p
+0000d640: 6164 5f74 7970 653d 2276 616c 6964 222c  ad_type="valid",
+0000d650: 0a20 2020 2020 2020 2020 2020 206e 616d  .            nam
+0000d660: 653d 6e6f 6465 2e6e 616d 652c 0a20 2020  e=node.name,.   
+0000d670: 2020 2020 2029 0a20 2020 2065 6c73 653a       ).    else:
+0000d680: 0a20 2020 2020 2020 2072 6573 756c 7420  .        result 
+0000d690: 3d20 5f61 6461 7074 6976 655f 706f 6f6c  = _adaptive_pool
+0000d6a0: 3264 5f6e 6f6e 5f66 6978 6564 5f6b 6572  2d_non_fixed_ker
+0000d6b0: 6e65 6c5f 7369 7a65 5f61 6e64 5f73 7472  nel_size_and_str
+0000d6c0: 6964 6528 0a20 2020 2020 2020 2020 2020  ide(.           
+0000d6d0: 2078 2c20 6f75 7470 7574 5f73 6861 7065   x, output_shape
+0000d6e0: 2c20 6e6f 6465 2e6e 616d 652c 2072 6564  , node.name, red
+0000d6f0: 7563 655f 6f70 0a20 2020 2020 2020 2029  uce_op.        )
+0000d700: 0a0a 2020 2020 636f 6e74 6578 742e 6164  ..    context.ad
+0000d710: 6428 7265 7375 6c74 290a 0a0a 4072 6567  d(result)...@reg
+0000d720: 6973 7465 725f 746f 7263 685f 6f70 0a64  ister_torch_op.d
+0000d730: 6566 2062 6174 6368 5f6e 6f72 6d28 636f  ef batch_norm(co
+0000d740: 6e74 6578 742c 206e 6f64 6529 3a0a 2020  ntext, node):.  
+0000d750: 2020 696e 7075 7473 203d 205f 6765 745f    inputs = _get_
+0000d760: 696e 7075 7473 2863 6f6e 7465 7874 2c20  inputs(context, 
+0000d770: 6e6f 6465 2c20 6578 7065 6374 6564 3d39  node, expected=9
+0000d780: 290a 2020 2020 2320 696e 7075 7473 2073  ).    # inputs s
+0000d790: 6b69 7070 6564 3a0a 2020 2020 2320 2020  kipped:.    #   
+0000d7a0: 666c 6f61 7420 6d6f 6d65 6e74 756d 2028  float momentum (
+0000d7b0: 3629 0a20 2020 2023 2020 2062 6f6f 6c20  6).    #   bool 
+0000d7c0: 6375 646e 6e5f 656e 6162 6c65 6420 2838  cudnn_enabled (8
+0000d7d0: 290a 2020 2020 696e 7075 745f 7261 6e6b  ).    input_rank
+0000d7e0: 203d 2069 6e70 7574 735b 305d 2e72 616e   = inputs[0].ran
+0000d7f0: 6b0a 2020 2020 6966 2069 6e70 7574 5f72  k.    if input_r
+0000d800: 616e 6b20 3c20 3220 6f72 2069 6e70 7574  ank < 2 or input
+0000d810: 5f72 616e 6b20 3e20 353a 0a20 2020 2020  _rank > 5:.     
+0000d820: 2020 2072 6169 7365 2056 616c 7565 4572     raise ValueEr
+0000d830: 726f 7228 0a20 2020 2020 2020 2020 2020  ror(.           
+0000d840: 2022 4261 7463 684e 6f72 6d3a 2045 6e63   "BatchNorm: Enc
+0000d850: 6f75 6e74 6572 6564 2069 6e76 616c 6964  ountered invalid
+0000d860: 2069 6e70 7574 2072 616e 6b20 6475 7269   input rank duri
+0000d870: 6e67 2074 7261 6e73 6c61 7469 6f6e 2069  ng translation i
+0000d880: 6e20 746f 7263 6820 6672 6f6e 7465 6e64  n torch frontend
+0000d890: 2e22 0a20 2020 2020 2020 2029 0a0a 2020  .".        )..  
+0000d8a0: 2020 5f69 6e70 7574 203d 2069 6e70 7574    _input = input
+0000d8b0: 735b 305d 0a20 2020 2077 6569 6768 7420  s[0].    weight 
+0000d8c0: 3d20 696e 7075 7473 5b31 5d0a 2020 2020  = inputs[1].    
+0000d8d0: 6269 6173 203d 2069 6e70 7574 735b 325d  bias = inputs[2]
+0000d8e0: 0a20 2020 2072 756e 6e69 6e67 5f6d 6561  .    running_mea
+0000d8f0: 6e20 3d20 696e 7075 7473 5b33 5d0a 2020  n = inputs[3].  
+0000d900: 2020 7275 6e6e 696e 675f 7661 7220 3d20    running_var = 
+0000d910: 696e 7075 7473 5b34 5d0a 2020 2020 7472  inputs[4].    tr
+0000d920: 6169 6e69 6e67 203d 2069 6e70 7574 735b  aining = inputs[
+0000d930: 355d 2e76 616c 0a20 2020 2065 7073 203d  5].val.    eps =
+0000d940: 2069 6e70 7574 735b 375d 0a0a 2020 2020   inputs[7]..    
+0000d950: 2320 4966 2074 7261 696e 696e 6720 3d20  # If training = 
+0000d960: 5472 7565 2c20 7468 6520 6d65 616e 2061  True, the mean a
+0000d970: 6e64 2076 6172 6961 6e63 6520 6f66 2074  nd variance of t
+0000d980: 6865 2063 7572 7265 6e74 2062 6174 6368  he current batch
+0000d990: 206f 6620 6461 7461 2061 7265 2075 7365   of data are use
+0000d9a0: 6420 746f 206e 6f72 6d61 6c69 7a65 2074  d to normalize t
+0000d9b0: 6865 2069 6e70 7574 2064 6174 612e 0a20  he input data.. 
+0000d9c0: 2020 2023 2049 6620 7472 6169 6e69 6e67     # If training
+0000d9d0: 203d 2046 616c 7365 2c20 6461 7461 2073   = False, data s
+0000d9e0: 7461 7469 7374 6963 7320 7275 6e6e 696e  tatistics runnin
+0000d9f0: 675f 6d65 616e 2061 6e64 2072 756e 6e69  g_mean and runni
+0000da00: 6e67 5f76 6172 2061 7265 2075 7365 6420  ng_var are used 
+0000da10: 696e 7374 6561 642e 0a20 2020 2023 204e  instead..    # N
+0000da20: 6f74 6520 7468 6174 2c20 6576 656e 2069  ote that, even i
+0000da30: 6e20 7468 6520 6576 616c 7561 7469 6f6e  n the evaluation
+0000da40: 206d 6f64 6520 2861 6674 6572 2063 616c   mode (after cal
+0000da50: 6c69 6e67 206d 6f64 656c 2e65 7661 6c28  ling model.eval(
+0000da60: 2929 2c20 7468 6520 7472 6169 6e69 6e67  )), the training
+0000da70: 2070 6172 616d 6574 6572 2063 616e 2073   parameter can s
+0000da80: 7469 6c6c 2062 6520 7472 7565 0a20 2020  till be true.   
+0000da90: 2023 2061 6e64 2069 7420 6a75 7374 2072   # and it just r
+0000daa0: 6566 6572 7320 746f 2061 2064 6966 6665  efers to a diffe
+0000dab0: 7265 6e74 2063 6f6d 7075 7461 7469 6f6e  rent computation
+0000dac0: 2061 7320 6d65 6e74 696f 6e65 6420 6162   as mentioned ab
+0000dad0: 6f76 652e 0a0a 2020 2020 2320 6865 6c70  ove...    # help
+0000dae0: 6572 2066 756e 6374 696f 6e73 2066 6f72  er functions for
+0000daf0: 2064 6966 6665 7265 6e74 2074 7970 6520   different type 
+0000db00: 6f66 2062 6174 6368 206e 6f72 6d0a 2020  of batch norm.  
+0000db10: 2020 6465 6620 5f61 6464 5f62 6174 6368    def _add_batch
+0000db20: 5f6e 6f72 6d5f 6479 6e61 6d69 6328 293a  _norm_dynamic():
+0000db30: 0a20 2020 2020 2020 2078 203d 205f 696e  .        x = _in
+0000db40: 7075 740a 0a20 2020 2020 2020 2069 6620  put..        if 
+0000db50: 7472 6169 6e69 6e67 206f 7220 2872 756e  training or (run
+0000db60: 6e69 6e67 5f6d 6561 6e20 6973 204e 6f6e  ning_mean is Non
+0000db70: 6529 206f 7220 2872 756e 6e69 6e67 5f76  e) or (running_v
+0000db80: 6172 2069 7320 4e6f 6e65 293a 0a20 2020  ar is None):.   
+0000db90: 2020 2020 2020 2020 2061 7865 7320 3d20           axes = 
+0000dba0: 5b61 7869 7320 666f 7220 6178 6973 2069  [axis for axis i
+0000dbb0: 6e20 7261 6e67 6528 782e 7261 6e6b 2920  n range(x.rank) 
+0000dbc0: 6966 2061 7869 7320 213d 2031 5d0a 2020  if axis != 1].  
+0000dbd0: 2020 2020 2020 2020 2020 6d65 616e 203d            mean =
+0000dbe0: 206d 622e 7265 6475 6365 5f6d 6561 6e28   mb.reduce_mean(
+0000dbf0: 783d 782c 2061 7865 733d 6178 6573 2c20  x=x, axes=axes, 
+0000dc00: 6b65 6570 5f64 696d 733d 5472 7565 290a  keep_dims=True).
+0000dc10: 2020 2020 2020 2020 2020 2020 6e75 6d20              num 
+0000dc20: 3d20 6d62 2e73 7562 2878 3d78 2c20 793d  = mb.sub(x=x, y=
+0000dc30: 6d65 616e 290a 2020 2020 2020 2020 2020  mean).          
+0000dc40: 2020 7371 7561 7265 203d 206d 622e 6d75    square = mb.mu
+0000dc50: 6c28 783d 6e75 6d2c 2079 3d6e 756d 290a  l(x=num, y=num).
+0000dc60: 2020 2020 2020 2020 2020 2020 7661 7269              vari
+0000dc70: 616e 6365 203d 206d 622e 7265 6475 6365  ance = mb.reduce
+0000dc80: 5f6d 6561 6e28 783d 7371 7561 7265 2c20  _mean(x=square, 
+0000dc90: 6178 6573 3d61 7865 732c 206b 6565 705f  axes=axes, keep_
+0000dca0: 6469 6d73 3d54 7275 6529 0a20 2020 2020  dims=True).     
+0000dcb0: 2020 2020 2020 2073 6861 7065 203d 206d         shape = m
+0000dcc0: 622e 7368 6170 6528 783d 7661 7269 616e  b.shape(x=varian
+0000dcd0: 6365 290a 2020 2020 2020 2020 656c 7365  ce).        else
+0000dce0: 3a0a 2020 2020 2020 2020 2020 2020 7368  :.            sh
+0000dcf0: 6170 6520 3d20 5b31 5d20 2a20 782e 7261  ape = [1] * x.ra
+0000dd00: 6e6b 0a20 2020 2020 2020 2020 2020 2073  nk.            s
+0000dd10: 6861 7065 5b31 5d20 3d20 2d31 2069 6620  hape[1] = -1 if 
+0000dd20: 616e 795f 7379 6d62 6f6c 6963 2872 756e  any_symbolic(run
+0000dd30: 6e69 6e67 5f6d 6561 6e2e 7368 6170 6529  ning_mean.shape)
+0000dd40: 2065 6c73 6520 7275 6e6e 696e 675f 6d65   else running_me
+0000dd50: 616e 2e73 6861 7065 5b30 5d0a 2020 2020  an.shape[0].    
+0000dd60: 2020 2020 2020 2020 6d65 616e 203d 206d          mean = m
+0000dd70: 622e 7265 7368 6170 6528 783d 7275 6e6e  b.reshape(x=runn
+0000dd80: 696e 675f 6d65 616e 2c20 7368 6170 653d  ing_mean, shape=
+0000dd90: 7368 6170 6529 0a20 2020 2020 2020 2020  shape).         
+0000dda0: 2020 206e 756d 203d 206d 622e 7375 6228     num = mb.sub(
+0000ddb0: 783d 782c 2079 3d6d 6561 6e29 0a20 2020  x=x, y=mean).   
+0000ddc0: 2020 2020 2020 2020 2076 6172 6961 6e63           varianc
+0000ddd0: 6520 3d20 6d62 2e72 6573 6861 7065 2878  e = mb.reshape(x
+0000dde0: 3d72 756e 6e69 6e67 5f76 6172 2c20 7368  =running_var, sh
+0000ddf0: 6170 653d 7368 6170 6529 0a0a 2020 2020  ape=shape)..    
+0000de00: 2020 2020 7661 7269 616e 6365 5f61 6464      variance_add
+0000de10: 5f65 7073 696c 6f6e 203d 206d 622e 6164  _epsilon = mb.ad
+0000de20: 6428 783d 7661 7269 616e 6365 2c20 793d  d(x=variance, y=
+0000de30: 6570 7329 0a20 2020 2020 2020 2073 7172  eps).        sqr
+0000de40: 7420 3d20 6d62 2e73 7172 7428 783d 7661  t = mb.sqrt(x=va
+0000de50: 7269 616e 6365 5f61 6464 5f65 7073 696c  riance_add_epsil
+0000de60: 6f6e 290a 0a20 2020 2020 2020 206e 616d  on)..        nam
+0000de70: 6520 3d20 6e6f 6465 2e6e 616d 6520 6966  e = node.name if
+0000de80: 2077 6569 6768 7420 6973 204e 6f6e 6520   weight is None 
+0000de90: 616e 6420 6269 6173 2069 7320 4e6f 6e65  and bias is None
+0000dea0: 2065 6c73 6520 6e6f 6465 2e6e 616d 6520   else node.name 
+0000deb0: 2b20 225f 6469 7622 0a20 2020 2020 2020  + "_div".       
+0000dec0: 2078 203d 206d 622e 7265 616c 5f64 6976   x = mb.real_div
+0000ded0: 2878 3d6e 756d 2c20 793d 7371 7274 2c20  (x=num, y=sqrt, 
+0000dee0: 6e61 6d65 3d6e 616d 6529 0a0a 2020 2020  name=name)..    
+0000def0: 2020 2020 6966 2077 6569 6768 7420 6973      if weight is
+0000df00: 206e 6f74 204e 6f6e 653a 0a20 2020 2020   not None:.     
+0000df10: 2020 2020 2020 2077 6569 6768 745f 7265         weight_re
+0000df20: 7368 6170 6520 3d20 6d62 2e72 6573 6861  shape = mb.resha
+0000df30: 7065 2878 3d77 6569 6768 742c 2073 6861  pe(x=weight, sha
+0000df40: 7065 3d73 6861 7065 290a 2020 2020 2020  pe=shape).      
+0000df50: 2020 2020 2020 6e61 6d65 203d 206e 6f64        name = nod
+0000df60: 652e 6e61 6d65 2069 6620 6269 6173 2069  e.name if bias i
+0000df70: 7320 4e6f 6e65 2065 6c73 6520 6e6f 6465  s None else node
+0000df80: 2e6e 616d 6520 2b20 225f 6d75 6c22 0a20  .name + "_mul". 
+0000df90: 2020 2020 2020 2020 2020 2078 203d 206d             x = m
+0000dfa0: 622e 6d75 6c28 783d 782c 2079 3d77 6569  b.mul(x=x, y=wei
+0000dfb0: 6768 745f 7265 7368 6170 652c 206e 616d  ght_reshape, nam
+0000dfc0: 653d 6e61 6d65 290a 0a20 2020 2020 2020  e=name)..       
+0000dfd0: 2069 6620 6269 6173 2069 7320 6e6f 7420   if bias is not 
+0000dfe0: 4e6f 6e65 3a0a 2020 2020 2020 2020 2020  None:.          
+0000dff0: 2020 6269 6173 5f72 6573 6861 7065 203d    bias_reshape =
+0000e000: 206d 622e 7265 7368 6170 6528 783d 6269   mb.reshape(x=bi
+0000e010: 6173 2c20 7368 6170 653d 7368 6170 6529  as, shape=shape)
+0000e020: 0a20 2020 2020 2020 2020 2020 2078 203d  .            x =
+0000e030: 206d 622e 6164 6428 783d 782c 2079 3d62   mb.add(x=x, y=b
+0000e040: 6961 735f 7265 7368 6170 652c 206e 616d  ias_reshape, nam
+0000e050: 653d 6e6f 6465 2e6e 616d 6529 0a0a 2020  e=node.name)..  
+0000e060: 2020 2020 2020 636f 6e74 6578 742e 6164        context.ad
+0000e070: 6428 7829 0a0a 2020 2020 6465 6620 5f61  d(x)..    def _a
+0000e080: 6464 5f62 6174 6368 5f6e 6f72 6d5f 3164  dd_batch_norm_1d
+0000e090: 2829 3a0a 2020 2020 2020 2020 2320 6669  ():.        # fi
+0000e0a0: 7273 7420 6578 7061 6e64 2074 6865 2033  rst expand the 3
+0000e0b0: 6420 7465 6e73 6f72 2074 6f20 3464 2c20  d tensor to 4d, 
+0000e0c0: 616e 6420 6361 6c6c 2074 6865 2073 7461  and call the sta
+0000e0d0: 6e64 6172 6420 6d62 2e62 6174 6368 5f6e  ndard mb.batch_n
+0000e0e0: 6f72 6d0a 2020 2020 2020 2020 7820 3d20  orm.        x = 
+0000e0f0: 6d62 2e65 7870 616e 645f 6469 6d73 2878  mb.expand_dims(x
+0000e100: 3d5f 696e 7075 742c 2061 7865 733d 5b2d  =_input, axes=[-
+0000e110: 315d 2c20 6e61 6d65 3d6e 6f64 652e 6e61  1], name=node.na
+0000e120: 6d65 202b 2022 5f72 616e 6b32 5f65 7870  me + "_rank2_exp
+0000e130: 616e 7369 6f6e 2229 0a20 2020 2020 2020  ansion").       
+0000e140: 2062 6e20 3d20 6d62 2e62 6174 6368 5f6e   bn = mb.batch_n
+0000e150: 6f72 6d28 0a20 2020 2020 2020 2020 2020  orm(.           
+0000e160: 2078 3d78 2c0a 2020 2020 2020 2020 2020   x=x,.          
+0000e170: 2020 6d65 616e 3d72 756e 6e69 6e67 5f6d    mean=running_m
+0000e180: 6561 6e2c 0a20 2020 2020 2020 2020 2020  ean,.           
+0000e190: 2076 6172 6961 6e63 653d 7275 6e6e 696e   variance=runnin
+0000e1a0: 675f 7661 722c 0a20 2020 2020 2020 2020  g_var,.         
+0000e1b0: 2020 2067 616d 6d61 3d77 6569 6768 742c     gamma=weight,
+0000e1c0: 0a20 2020 2020 2020 2020 2020 2062 6574  .            bet
+0000e1d0: 613d 6269 6173 2c0a 2020 2020 2020 2020  a=bias,.        
+0000e1e0: 2020 2020 6570 7369 6c6f 6e3d 6570 732c      epsilon=eps,
+0000e1f0: 0a20 2020 2020 2020 2020 2020 206e 616d  .            nam
+0000e200: 653d 6e6f 6465 2e6e 616d 6520 2b20 225f  e=node.name + "_
+0000e210: 6261 7463 685f 6e6f 726d 5f31 6422 2c0a  batch_norm_1d",.
+0000e220: 2020 2020 2020 2020 290a 2020 2020 2020          ).      
+0000e230: 2020 626e 203d 206d 622e 7371 7565 657a    bn = mb.squeez
+0000e240: 6528 783d 626e 2c20 6e61 6d65 3d6e 6f64  e(x=bn, name=nod
+0000e250: 652e 6e61 6d65 2c20 6178 6573 3d5b 2d31  e.name, axes=[-1
+0000e260: 5d29 0a20 2020 2020 2020 2063 6f6e 7465  ]).        conte
+0000e270: 7874 2e61 6464 2862 6e29 0a0a 2020 2020  xt.add(bn)..    
+0000e280: 6465 6620 5f61 6464 5f62 6174 6368 5f6e  def _add_batch_n
+0000e290: 6f72 6d28 293a 0a20 2020 2020 2020 2062  orm():.        b
+0000e2a0: 6e20 3d20 6d62 2e62 6174 6368 5f6e 6f72  n = mb.batch_nor
+0000e2b0: 6d28 0a20 2020 2020 2020 2020 2020 2078  m(.            x
+0000e2c0: 3d5f 696e 7075 742c 0a20 2020 2020 2020  =_input,.       
+0000e2d0: 2020 2020 206d 6561 6e3d 7275 6e6e 696e       mean=runnin
+0000e2e0: 675f 6d65 616e 2c0a 2020 2020 2020 2020  g_mean,.        
+0000e2f0: 2020 2020 7661 7269 616e 6365 3d72 756e      variance=run
+0000e300: 6e69 6e67 5f76 6172 2c0a 2020 2020 2020  ning_var,.      
+0000e310: 2020 2020 2020 6761 6d6d 613d 7765 6967        gamma=weig
+0000e320: 6874 2c0a 2020 2020 2020 2020 2020 2020  ht,.            
+0000e330: 6265 7461 3d62 6961 732c 0a20 2020 2020  beta=bias,.     
+0000e340: 2020 2020 2020 2065 7073 696c 6f6e 3d65         epsilon=e
+0000e350: 7073 2c0a 2020 2020 2020 2020 2020 2020  ps,.            
+0000e360: 6e61 6d65 3d6e 6f64 652e 6e61 6d65 2c0a  name=node.name,.
+0000e370: 2020 2020 2020 2020 290a 2020 2020 2020          ).      
+0000e380: 2020 636f 6e74 6578 742e 6164 6428 626e    context.add(bn
+0000e390: 290a 0a20 2020 2069 735f 6261 7463 685f  )..    is_batch_
+0000e3a0: 6e6f 726d 5f31 645f 7261 6e6b 5f32 203d  norm_1d_rank_2 =
+0000e3b0: 2069 6e70 7574 5f72 616e 6b20 3d3d 2032   input_rank == 2
+0000e3c0: 0a0a 2020 2020 6966 2074 7261 696e 696e  ..    if trainin
+0000e3d0: 6720 6f72 2072 756e 6e69 6e67 5f6d 6561  g or running_mea
+0000e3e0: 6e2e 7661 6c20 6973 204e 6f6e 6520 6f72  n.val is None or
+0000e3f0: 2072 756e 6e69 6e67 5f76 6172 2e76 616c   running_var.val
+0000e400: 2069 7320 4e6f 6e65 206f 7220 7765 6967   is None or weig
+0000e410: 6874 2069 7320 4e6f 6e65 206f 7220 6269  ht is None or bi
+0000e420: 6173 2069 7320 4e6f 6e65 3a0a 2020 2020  as is None:.    
+0000e430: 2020 2020 5f61 6464 5f62 6174 6368 5f6e      _add_batch_n
+0000e440: 6f72 6d5f 6479 6e61 6d69 6328 290a 2020  orm_dynamic().  
+0000e450: 2020 656c 6966 2069 735f 6261 7463 685f    elif is_batch_
+0000e460: 6e6f 726d 5f31 645f 7261 6e6b 5f32 3a0a  norm_1d_rank_2:.
+0000e470: 2020 2020 2020 2020 5f61 6464 5f62 6174          _add_bat
+0000e480: 6368 5f6e 6f72 6d5f 3164 2829 0a20 2020  ch_norm_1d().   
+0000e490: 2065 6c73 653a 0a20 2020 2020 2020 205f   else:.        _
+0000e4a0: 6164 645f 6261 7463 685f 6e6f 726d 2829  add_batch_norm()
+0000e4b0: 0a0a 0a40 7265 6769 7374 6572 5f74 6f72  ...@register_tor
+0000e4c0: 6368 5f6f 700a 6465 6620 696e 7374 616e  ch_op.def instan
+0000e4d0: 6365 5f6e 6f72 6d28 636f 6e74 6578 742c  ce_norm(context,
+0000e4e0: 206e 6f64 6529 3a0a 2020 2020 696e 7075   node):.    inpu
+0000e4f0: 7473 203d 205f 6765 745f 696e 7075 7473  ts = _get_inputs
+0000e500: 2863 6f6e 7465 7874 2c20 6e6f 6465 2c20  (context, node, 
+0000e510: 6578 7065 6374 6564 3d39 290a 2020 2020  expected=9).    
+0000e520: 7820 3d20 696e 7075 7473 5b30 5d0a 2020  x = inputs[0].  
+0000e530: 2020 7765 6967 6874 203d 2069 6e70 7574    weight = input
+0000e540: 735b 315d 0a20 2020 2062 6961 7320 3d20  s[1].    bias = 
+0000e550: 696e 7075 7473 5b32 5d0a 2020 2020 6570  inputs[2].    ep
+0000e560: 7320 3d20 696e 7075 7473 5b37 5d0a 2020  s = inputs[7].  
+0000e570: 2020 7820 3d20 6d62 2e69 6e73 7461 6e63    x = mb.instanc
+0000e580: 655f 6e6f 726d 280a 2020 2020 2020 2020  e_norm(.        
+0000e590: 783d 782c 0a20 2020 2020 2020 2067 616d  x=x,.        gam
+0000e5a0: 6d61 3d77 6569 6768 742c 0a20 2020 2020  ma=weight,.     
+0000e5b0: 2020 2062 6574 613d 6269 6173 2c0a 2020     beta=bias,.  
+0000e5c0: 2020 2020 2020 6570 7369 6c6f 6e3d 6570        epsilon=ep
+0000e5d0: 732c 0a20 2020 2020 2020 206e 616d 653d  s,.        name=
+0000e5e0: 6e6f 6465 2e6e 616d 652c 0a20 2020 2029  node.name,.    )
+0000e5f0: 0a20 2020 2063 6f6e 7465 7874 2e61 6464  .    context.add
+0000e600: 2878 290a 0a0a 4072 6567 6973 7465 725f  (x)...@register_
+0000e610: 746f 7263 685f 6f70 0a64 6566 2067 726f  torch_op.def gro
+0000e620: 7570 5f6e 6f72 6d28 636f 6e74 6578 742c  up_norm(context,
+0000e630: 206e 6f64 6529 3a0a 2020 2020 696e 7075   node):.    inpu
+0000e640: 7473 203d 205f 6765 745f 696e 7075 7473  ts = _get_inputs
+0000e650: 2863 6f6e 7465 7874 2c20 6e6f 6465 2c20  (context, node, 
+0000e660: 6578 7065 6374 6564 3d36 290a 2020 2020  expected=6).    
+0000e670: 7820 3d20 696e 7075 7473 5b30 5d0a 2020  x = inputs[0].  
+0000e680: 2020 6e75 6d5f 6772 6f75 7073 203d 2069    num_groups = i
+0000e690: 6e70 7574 735b 315d 2e76 616c 0a20 2020  nputs[1].val.   
+0000e6a0: 2077 6569 6768 7420 3d20 696e 7075 7473   weight = inputs
+0000e6b0: 5b32 5d0a 2020 2020 6269 6173 203d 2069  [2].    bias = i
+0000e6c0: 6e70 7574 735b 335d 0a20 2020 2065 7073  nputs[3].    eps
+0000e6d0: 203d 2069 6e70 7574 735b 345d 0a20 2020   = inputs[4].   
+0000e6e0: 206e 2c63 203d 2078 2e73 6861 7065 5b30   n,c = x.shape[0
+0000e6f0: 5d2c 782e 7368 6170 655b 315d 2023 2061  ],x.shape[1] # a
+0000e700: 7420 6d69 6e69 6d75 6d20 284e 2c20 4329  t minimum (N, C)
+0000e710: 2072 6571 7569 7265 640a 2020 2020 696e   required.    in
+0000e720: 7075 745f 7368 6170 6520 3d20 5b2a 782e  put_shape = [*x.
+0000e730: 7368 6170 655d 2023 206e 2c20 632c 202a  shape] # n, c, *
+0000e740: 0a20 2020 206e 756d 5f67 726f 7570 7320  .    num_groups 
+0000e750: 3d20 6275 696c 7469 6e73 2e6d 696e 286e  = builtins.min(n
+0000e760: 756d 5f67 726f 7570 732c 6329 0a20 2020  um_groups,c).   
+0000e770: 206e 6577 5f73 6861 7065 203d 205b 6e2c   new_shape = [n,
+0000e780: 206e 756d 5f67 726f 7570 732c 2063 2f2f   num_groups, c//
+0000e790: 6e75 6d5f 6772 6f75 7073 5d0a 2020 2020  num_groups].    
+0000e7a0: 6e65 775f 7368 6170 6520 2b3d 205b 2a78  new_shape += [*x
+0000e7b0: 2e73 6861 7065 5b32 3a5d 5d20 2320 6164  .shape[2:]] # ad
+0000e7c0: 6473 2072 656d 6169 6e69 6e67 2064 696d  ds remaining dim
+0000e7d0: 730a 2020 2020 6e75 6d5f 6578 7472 615f  s.    num_extra_
+0000e7e0: 6178 6573 203d 206c 656e 2878 2e73 6861  axes = len(x.sha
+0000e7f0: 7065 5b32 3a5d 290a 2020 2020 6178 6573  pe[2:]).    axes
+0000e800: 5f20 3d20 5b69 6e74 2869 2920 666f 7220  _ = [int(i) for 
+0000e810: 6920 696e 2072 616e 6765 2832 2c20 3220  i in range(2, 2 
+0000e820: 2b20 6e75 6d5f 6578 7472 615f 6178 6573  + num_extra_axes
+0000e830: 202b 2031 295d 0a20 2020 2077 6569 6768   + 1)].    weigh
+0000e840: 745f 7368 6170 652c 2062 6961 735f 7368  t_shape, bias_sh
+0000e850: 6170 6520 3d20 5b31 2c63 5d2c 205b 312c  ape = [1,c], [1,
+0000e860: 635d 0a20 2020 2077 6569 6768 745f 7368  c].    weight_sh
+0000e870: 6170 6520 2b3d 205b 3120 666f 7220 5f20  ape += [1 for _ 
+0000e880: 696e 2072 616e 6765 286e 756d 5f65 7874  in range(num_ext
+0000e890: 7261 5f61 7865 7329 5d0a 2020 2020 6269  ra_axes)].    bi
+0000e8a0: 6173 5f73 6861 7065 202b 3d20 5b31 2066  as_shape += [1 f
+0000e8b0: 6f72 205f 2069 6e20 7261 6e67 6528 6e75  or _ in range(nu
+0000e8c0: 6d5f 6578 7472 615f 6178 6573 295d 0a0a  m_extra_axes)]..
+0000e8d0: 2020 2020 7820 3d20 6d62 2e72 6573 6861      x = mb.resha
+0000e8e0: 7065 2878 3d78 2c20 7368 6170 653d 6e65  pe(x=x, shape=ne
+0000e8f0: 775f 7368 6170 6529 0a20 2020 206d 6561  w_shape).    mea
+0000e900: 6e20 3d20 6d62 2e72 6564 7563 655f 6d65  n = mb.reduce_me
+0000e910: 616e 2878 3d78 2c20 6178 6573 3d61 7865  an(x=x, axes=axe
+0000e920: 735f 2c20 6b65 6570 5f64 696d 733d 5472  s_, keep_dims=Tr
+0000e930: 7565 290a 2020 2020 7661 7220 3d20 5f73  ue).    var = _s
+0000e940: 7464 2878 2c61 7865 735f 2c54 7275 652c  td(x,axes_,True,
+0000e950: 4661 6c73 652c 6570 732e 7661 6c29 0a20  False,eps.val). 
+0000e960: 2020 2078 203d 206d 622e 7375 6228 783d     x = mb.sub(x=
+0000e970: 782c 793d 6d65 616e 290a 2020 2020 7820  x,y=mean).    x 
+0000e980: 3d20 6d62 2e72 6561 6c5f 6469 7628 783d  = mb.real_div(x=
+0000e990: 782c 793d 7661 7229 0a20 2020 2078 203d  x,y=var).    x =
+0000e9a0: 206d 622e 7265 7368 6170 6528 783d 782c   mb.reshape(x=x,
+0000e9b0: 2073 6861 7065 3d69 6e70 7574 5f73 6861   shape=input_sha
+0000e9c0: 7065 290a 2020 2020 6966 2077 6569 6768  pe).    if weigh
+0000e9d0: 7420 6973 206e 6f74 204e 6f6e 653a 0a20  t is not None:. 
+0000e9e0: 2020 2020 2020 2077 6569 6768 7420 3d20         weight = 
+0000e9f0: 6d62 2e72 6573 6861 7065 2878 3d77 6569  mb.reshape(x=wei
+0000ea00: 6768 742c 2073 6861 7065 3d77 6569 6768  ght, shape=weigh
+0000ea10: 745f 7368 6170 6529 0a20 2020 2020 2020  t_shape).       
+0000ea20: 2078 203d 206d 622e 6d75 6c28 783d 782c   x = mb.mul(x=x,
+0000ea30: 793d 7765 6967 6874 290a 2020 2020 6966  y=weight).    if
+0000ea40: 2062 6961 7320 6973 206e 6f74 204e 6f6e   bias is not Non
+0000ea50: 653a 0a20 2020 2020 2020 2062 6961 7320  e:.        bias 
+0000ea60: 3d20 6d62 2e72 6573 6861 7065 2878 3d62  = mb.reshape(x=b
+0000ea70: 6961 732c 2073 6861 7065 3d62 6961 735f  ias, shape=bias_
+0000ea80: 7368 6170 6529 0a20 2020 2020 2020 2078  shape).        x
+0000ea90: 203d 206d 622e 6164 6428 783d 782c 793d   = mb.add(x=x,y=
+0000eaa0: 6269 6173 290a 2020 2020 636f 6e74 6578  bias).    contex
+0000eab0: 742e 6164 6428 782c 6e6f 6465 2e6e 616d  t.add(x,node.nam
+0000eac0: 6529 0a0a 0a40 7265 6769 7374 6572 5f74  e)...@register_t
+0000ead0: 6f72 6368 5f6f 700a 6465 6620 656d 6265  orch_op.def embe
+0000eae0: 6464 696e 6728 636f 6e74 6578 742c 206e  dding(context, n
+0000eaf0: 6f64 6529 3a0a 2020 2020 696e 7075 7473  ode):.    inputs
+0000eb00: 203d 205f 6765 745f 696e 7075 7473 2863   = _get_inputs(c
+0000eb10: 6f6e 7465 7874 2c20 6e6f 6465 290a 2020  ontext, node).  
+0000eb20: 2020 5f69 6e70 7574 203d 2069 6e70 7574    _input = input
+0000eb30: 735b 305d 0a20 2020 2069 6e64 6963 6573  s[0].    indices
+0000eb40: 203d 2069 6e70 7574 735b 315d 0a0a 2020   = inputs[1]..  
+0000eb50: 2020 7061 6464 696e 675f 6964 7820 3d20    padding_idx = 
+0000eb60: 2d31 0a20 2020 2073 6361 6c65 5f67 7261  -1.    scale_gra
+0000eb70: 645f 6279 5f66 7265 7120 3d20 4661 6c73  d_by_freq = Fals
+0000eb80: 650a 2020 2020 7370 6172 7365 203d 2046  e.    sparse = F
+0000eb90: 616c 7365 0a20 2020 2069 6620 6c65 6e28  alse.    if len(
+0000eba0: 696e 7075 7473 2920 3e3d 2033 3a0a 2020  inputs) >= 3:.  
+0000ebb0: 2020 2020 2020 7061 6464 696e 675f 6964        padding_id
+0000ebc0: 7820 3d20 696e 7075 7473 5b32 5d2e 7661  x = inputs[2].va
+0000ebd0: 6c0a 2020 2020 6966 206c 656e 2869 6e70  l.    if len(inp
+0000ebe0: 7574 7329 203e 3d20 343a 0a20 2020 2020  uts) >= 4:.     
+0000ebf0: 2020 2073 6361 6c65 5f67 7261 645f 6279     scale_grad_by
+0000ec00: 5f66 7265 7120 3d20 696e 7075 7473 5b33  _freq = inputs[3
+0000ec10: 5d2e 7661 6c0a 2020 2020 6966 206c 656e  ].val.    if len
+0000ec20: 2869 6e70 7574 7329 203e 3d20 353a 0a20  (inputs) >= 5:. 
+0000ec30: 2020 2020 2020 2073 7061 7273 6520 3d20         sparse = 
+0000ec40: 696e 7075 7473 5b34 5d2e 7661 6c0a 0a20  inputs[4].val.. 
+0000ec50: 2020 2069 6620 7061 6464 696e 675f 6964     if padding_id
+0000ec60: 7820 213d 202d 3120 6f72 2073 6361 6c65  x != -1 or scale
+0000ec70: 5f67 7261 645f 6279 5f66 7265 7120 6f72  _grad_by_freq or
+0000ec80: 2073 7061 7273 653a 0a20 2020 2020 2020   sparse:.       
+0000ec90: 206c 6f67 6765 722e 7761 726e 696e 6728   logger.warning(
+0000eca0: 0a20 2020 2020 2020 2020 2020 2022 436f  .            "Co
+0000ecb0: 7265 204d 4c20 656d 6265 6464 696e 6720  re ML embedding 
+0000ecc0: 2867 6174 6865 7229 206c 6179 6572 2064  (gather) layer d
+0000ecd0: 6f65 7320 6e6f 7420 7375 7070 6f72 7420  oes not support 
+0000ece0: 616e 7920 220a 2020 2020 2020 2020 2020  any ".          
+0000ecf0: 2020 2269 6e70 7574 7320 6265 7369 6465    "inputs beside
+0000ed00: 7320 7468 6520 7765 6967 6874 7320 616e  s the weights an
+0000ed10: 6420 696e 6469 6365 732e 2054 686f 7365  d indices. Those
+0000ed20: 2067 6976 656e 2022 0a20 2020 2020 2020   given ".       
+0000ed30: 2020 2020 2022 7769 6c6c 2062 6520 6967       "will be ig
+0000ed40: 6e6f 7265 642e 220a 2020 2020 2020 2020  nored.".        
+0000ed50: 290a 0a20 2020 2069 6e64 6963 6573 203d  )..    indices =
+0000ed60: 206d 622e 6361 7374 2878 3d69 6e64 6963   mb.cast(x=indic
+0000ed70: 6573 2c20 6474 7970 653d 2269 6e74 3332  es, dtype="int32
+0000ed80: 2229 0a0a 2020 2020 2320 2043 6861 6e67  ")..    #  Chang
+0000ed90: 696e 6720 7468 6520 6178 6973 2066 726f  ing the axis fro
+0000eda0: 6d20 3020 6973 206e 6f74 2061 6e20 6f70  m 0 is not an op
+0000edb0: 7469 6f6e 2069 6e20 746f 7263 682c 2073  tion in torch, s
+0000edc0: 6f20 7765 2064 6f6e 2774 2065 7870 6f73  o we don't expos
+0000edd0: 6520 6974 0a20 2020 2067 6174 6865 7220  e it.    gather 
+0000ede0: 3d20 6d62 2e67 6174 6865 7228 783d 5f69  = mb.gather(x=_i
+0000edf0: 6e70 7574 2c20 696e 6469 6365 733d 696e  nput, indices=in
+0000ee00: 6469 6365 732c 206e 616d 653d 6e6f 6465  dices, name=node
+0000ee10: 2e6e 616d 6529 0a20 2020 2063 6f6e 7465  .name).    conte
+0000ee20: 7874 2e61 6464 2867 6174 6865 7229 0a0a  xt.add(gather)..
+0000ee30: 0a40 7265 6769 7374 6572 5f74 6f72 6368  .@register_torch
+0000ee40: 5f6f 700a 6465 6620 6861 7264 7461 6e68  _op.def hardtanh
+0000ee50: 2863 6f6e 7465 7874 2c20 6e6f 6465 293a  (context, node):
+0000ee60: 0a20 2020 2069 6e70 7574 7320 3d20 5f67  .    inputs = _g
+0000ee70: 6574 5f69 6e70 7574 7328 636f 6e74 6578  et_inputs(contex
+0000ee80: 742c 206e 6f64 652c 2065 7870 6563 7465  t, node, expecte
+0000ee90: 643d 3329 0a20 2020 205f 696e 7075 7420  d=3).    _input 
+0000eea0: 3d20 696e 7075 7473 5b30 5d0a 2020 2020  = inputs[0].    
+0000eeb0: 6d69 6e5f 7661 6c20 3d20 696e 7075 7473  min_val = inputs
+0000eec0: 5b31 5d2e 7661 6c0a 2020 2020 6d61 785f  [1].val.    max_
+0000eed0: 7661 6c20 3d20 696e 7075 7473 5b32 5d2e  val = inputs[2].
+0000eee0: 7661 6c0a 0a20 2020 2072 6573 203d 206d  val..    res = m
+0000eef0: 622e 636c 6970 2878 3d5f 696e 7075 742c  b.clip(x=_input,
+0000ef00: 2061 6c70 6861 3d6d 696e 5f76 616c 2c20   alpha=min_val, 
+0000ef10: 6265 7461 3d6d 6178 5f76 616c 2c20 6e61  beta=max_val, na
+0000ef20: 6d65 3d6e 6f64 652e 6e61 6d65 290a 2020  me=node.name).  
+0000ef30: 2020 636f 6e74 6578 742e 6164 6428 7265    context.add(re
+0000ef40: 7329 0a0a 0a40 7265 6769 7374 6572 5f74  s)...@register_t
+0000ef50: 6f72 6368 5f6f 7028 746f 7263 685f 616c  orch_op(torch_al
+0000ef60: 6961 733d 5b27 636f 6e63 6174 275d 290a  ias=['concat']).
+0000ef70: 6465 6620 6361 7428 636f 6e74 6578 742c  def cat(context,
+0000ef80: 206e 6f64 6529 3a0a 2020 2020 696e 7075   node):.    inpu
+0000ef90: 7473 203d 205f 6765 745f 696e 7075 7473  ts = _get_inputs
+0000efa0: 2863 6f6e 7465 7874 2c20 6e6f 6465 290a  (context, node).
+0000efb0: 2020 2020 6178 6973 203d 2030 2069 6620      axis = 0 if 
+0000efc0: 6c65 6e28 696e 7075 7473 2920 3d3d 2031  len(inputs) == 1
+0000efd0: 2065 6c73 6520 696e 7075 7473 5b31 5d0a   else inputs[1].
+0000efe0: 2020 2020 636f 6e63 6174 203d 206d 622e      concat = mb.
+0000eff0: 636f 6e63 6174 280a 2020 2020 2020 2020  concat(.        
+0000f000: 7661 6c75 6573 3d70 726f 6d6f 7465 5f69  values=promote_i
+0000f010: 6e70 7574 5f64 7479 7065 7328 696e 7075  nput_dtypes(inpu
+0000f020: 7473 5b30 5d29 2c20 6178 6973 3d61 7869  ts[0]), axis=axi
+0000f030: 732c 206e 616d 653d 6e6f 6465 2e6e 616d  s, name=node.nam
+0000f040: 650a 2020 2020 290a 2020 2020 636f 6e74  e.    ).    cont
+0000f050: 6578 742e 6164 6428 636f 6e63 6174 290a  ext.add(concat).
+0000f060: 0a0a 4072 6567 6973 7465 725f 746f 7263  ..@register_torc
+0000f070: 685f 6f70 0a64 6566 2073 7461 636b 2863  h_op.def stack(c
+0000f080: 6f6e 7465 7874 2c20 6e6f 6465 293a 0a20  ontext, node):. 
+0000f090: 2020 2069 6e70 7574 7320 3d20 5f67 6574     inputs = _get
+0000f0a0: 5f69 6e70 7574 7328 636f 6e74 6578 742c  _inputs(context,
+0000f0b0: 206e 6f64 6529 0a0a 2020 2020 7661 6c75   node)..    valu
+0000f0c0: 6573 203d 2069 6e70 7574 735b 305d 0a0a  es = inputs[0]..
+0000f0d0: 2020 2020 6966 206c 656e 2869 6e70 7574      if len(input
+0000f0e0: 7329 203c 2032 3a0a 2020 2020 2020 2020  s) < 2:.        
+0000f0f0: 6178 6973 203d 2030 0a20 2020 2065 6c73  axis = 0.    els
+0000f100: 653a 0a20 2020 2020 2020 2061 7869 7320  e:.        axis 
+0000f110: 3d20 696e 7075 7473 5b31 5d0a 0a20 2020  = inputs[1]..   
+0000f120: 2069 6620 6c65 6e28 7661 6c75 6573 2920   if len(values) 
+0000f130: 3d3d 2031 3a0a 2020 2020 2020 2020 7265  == 1:.        re
+0000f140: 7320 3d20 6d62 2e65 7870 616e 645f 6469  s = mb.expand_di
+0000f150: 6d73 2878 3d76 616c 7565 735b 305d 2c20  ms(x=values[0], 
+0000f160: 6178 6573 3d5b 6178 6973 2e76 616c 5d2c  axes=[axis.val],
+0000f170: 206e 616d 653d 6e6f 6465 2e6e 616d 6529   name=node.name)
+0000f180: 0a20 2020 2065 6c73 653a 0a20 2020 2020  .    else:.     
+0000f190: 2020 2072 6573 203d 206d 622e 7374 6163     res = mb.stac
+0000f1a0: 6b28 7661 6c75 6573 3d76 616c 7565 732c  k(values=values,
+0000f1b0: 2061 7869 733d 6178 6973 2c20 6e61 6d65   axis=axis, name
+0000f1c0: 3d6e 6f64 652e 6e61 6d65 290a 2020 2020  =node.name).    
+0000f1d0: 636f 6e74 6578 742e 6164 6428 7265 7329  context.add(res)
+0000f1e0: 0a0a 0a40 7265 6769 7374 6572 5f74 6f72  ...@register_tor
+0000f1f0: 6368 5f6f 700a 6465 6620 7469 6c65 2863  ch_op.def tile(c
+0000f200: 6f6e 7465 7874 2c20 6e6f 6465 293a 0a20  ontext, node):. 
+0000f210: 2020 2078 2c20 6469 6d73 203d 205f 6765     x, dims = _ge
+0000f220: 745f 696e 7075 7473 2863 6f6e 7465 7874  t_inputs(context
+0000f230: 2c20 6e6f 6465 2c20 6578 7065 6374 6564  , node, expected
+0000f240: 3d32 290a 0a20 2020 2023 2054 6865 2074  =2)..    # The t
+0000f250: 6f72 6368 2e74 696c 6520 6f6e 6c79 2073  orch.tile only s
+0000f260: 7570 706f 7274 7320 7475 706c 6520 6f66  upports tuple of
+0000f270: 2069 6e74 7320 666f 7220 2264 696d 7322   ints for "dims"
+0000f280: 2c20 6e6f 7420 5465 6e73 6f72 2e20 536f  , not Tensor. So
+0000f290: 2069 7420 7769 6c6c 206e 6f74 2062 6520   it will not be 
+0000f2a0: 6479 6e61 6d69 632e 0a20 2020 2069 6620  dynamic..    if 
+0000f2b0: 6469 6d73 2069 7320 4e6f 6e65 206f 7220  dims is None or 
+0000f2c0: 6469 6d73 2e76 616c 2069 7320 4e6f 6e65  dims.val is None
+0000f2d0: 3a0a 2020 2020 2020 2020 7261 6973 6520  :.        raise 
+0000f2e0: 5661 6c75 6545 7272 6f72 2822 5468 6520  ValueError("The 
+0000f2f0: 6064 696d 7360 2069 6e70 7574 2066 6f72  `dims` input for
+0000f300: 2074 6f72 6368 2e74 696c 6520 6d75 7374   torch.tile must
+0000f310: 2062 6520 7374 6174 6963 2028 7475 706c   be static (tupl
+0000f320: 6520 6f66 2069 6e74 7329 2e22 290a 0a20  e of ints).").. 
+0000f330: 2020 2064 696d 735f 6e75 6d20 3d20 6469     dims_num = di
+0000f340: 6d73 2e73 6861 7065 5b30 5d0a 2020 2020  ms.shape[0].    
+0000f350: 6966 2064 696d 735f 6e75 6d20 3c20 782e  if dims_num < x.
+0000f360: 7261 6e6b 3a0a 2020 2020 2020 2020 2320  rank:.        # 
+0000f370: 5768 656e 2074 6865 206e 756d 6265 7220  When the number 
+0000f380: 6f66 2065 6c65 6d65 6e74 7320 696e 2064  of elements in d
+0000f390: 696d 7320 6973 2073 6d61 6c6c 6572 2074  ims is smaller t
+0000f3a0: 6861 6e20 7261 6e6b 206f 6620 782c 206f  han rank of x, o
+0000f3b0: 6e65 7320 6172 6520 7072 6570 656e 6465  nes are prepende
+0000f3c0: 642e 0a20 2020 2020 2020 2070 7265 7065  d..        prepe
+0000f3d0: 6e64 5f6f 6e65 7320 3d20 6e70 2e61 7272  nd_ones = np.arr
+0000f3e0: 6179 285b 315d 202a 2028 782e 7261 6e6b  ay([1] * (x.rank
+0000f3f0: 202d 2064 696d 735f 6e75 6d29 290a 2020   - dims_num)).  
+0000f400: 2020 2020 2020 6469 6d73 203d 206d 622e        dims = mb.
+0000f410: 636f 6e63 6174 2876 616c 7565 733d 2870  concat(values=(p
+0000f420: 7265 7065 6e64 5f6f 6e65 732c 2064 696d  repend_ones, dim
+0000f430: 7329 2c20 6178 6973 3d30 290a 0a20 2020  s), axis=0)..   
+0000f440: 2072 6573 203d 206d 622e 7469 6c65 2878   res = mb.tile(x
+0000f450: 3d78 2c20 7265 7073 3d64 696d 732c 206e  =x, reps=dims, n
+0000f460: 616d 653d 6e6f 6465 2e6e 616d 6529 0a20  ame=node.name). 
+0000f470: 2020 2063 6f6e 7465 7874 2e61 6464 2872     context.add(r
+0000f480: 6573 290a 0a0a 4072 6567 6973 7465 725f  es)...@register_
+0000f490: 746f 7263 685f 6f70 0a64 6566 2069 7465  torch_op.def ite
+0000f4a0: 6d28 636f 6e74 6578 742c 206e 6f64 6529  m(context, node)
+0000f4b0: 3a0a 2020 2020 696e 7075 7473 203d 205f  :.    inputs = _
+0000f4c0: 6765 745f 696e 7075 7473 2863 6f6e 7465  get_inputs(conte
+0000f4d0: 7874 2c20 6e6f 6465 2c20 6578 7065 6374  xt, node, expect
+0000f4e0: 6564 3d31 290a 0a20 2020 2069 6620 696e  ed=1)..    if in
+0000f4f0: 7075 7473 5b30 5d2e 7368 6170 6520 3d3d  puts[0].shape ==
+0000f500: 2028 293a 0a20 2020 2020 2020 2023 204d   ():.        # M
+0000f510: 494c 206f 7073 2074 6861 7420 7265 6475  IL ops that redu
+0000f520: 6365 2061 6c72 6561 6479 206f 7574 7075  ce already outpu
+0000f530: 7420 6120 7363 616c 6172 2c20 736f 206e  t a scalar, so n
+0000f540: 6f20 6e65 6564 2074 6f20 646f 0a20 2020  o need to do.   
+0000f550: 2020 2020 2023 2061 6e79 7468 696e 672e       # anything.
+0000f560: 0a20 2020 2020 2020 2072 6573 203d 2069  .        res = i
+0000f570: 6e70 7574 735b 305d 0a20 2020 2065 6c69  nputs[0].    eli
+0000f580: 6620 5f6e 702e 616c 6c28 5b64 203d 3d20  f _np.all([d == 
+0000f590: 3120 666f 7220 6420 696e 2069 6e70 7574  1 for d in input
+0000f5a0: 735b 305d 2e73 6861 7065 5d29 3a0a 2020  s[0].shape]):.  
+0000f5b0: 2020 2020 2020 2320 4974 656d 206f 6e6c        # Item onl
+0000f5c0: 7920 6d61 6b65 7320 7365 6e73 6520 7768  y makes sense wh
+0000f5d0: 656e 2063 616c 6c65 6420 6f6e 2061 206c  en called on a l
+0000f5e0: 656e 6774 6820 3120 7465 6e73 6f72 2e20  ength 1 tensor. 
+0000f5f0: 5765 2075 7365 0a20 2020 2020 2020 2023  We use.        #
+0000f600: 2072 6564 7563 655f 6d61 7820 6173 2061   reduce_max as a
+0000f610: 2077 6f72 6b61 726f 756e 6420 666f 7220   workaround for 
+0000f620: 6e6f 7420 6861 7669 6e67 2061 2077 6179  not having a way
+0000f630: 2074 6f20 6578 7472 6163 7420 6120 7363   to extract a sc
+0000f640: 616c 6172 0a20 2020 2020 2020 2023 2066  alar.        # f
+0000f650: 726f 6d20 6120 7379 6d62 6f6c 6963 2074  rom a symbolic t
+0000f660: 656e 736f 722e 0a20 2020 2020 2020 2072  ensor..        r
+0000f670: 6573 203d 206d 622e 7265 6475 6365 5f6d  es = mb.reduce_m
+0000f680: 6178 2878 3d69 6e70 7574 735b 305d 2c20  ax(x=inputs[0], 
+0000f690: 6e61 6d65 3d6e 6f64 652e 6e61 6d65 290a  name=node.name).
+0000f6a0: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
+0000f6b0: 2020 7261 6973 6520 5661 6c75 6545 7272    raise ValueErr
+0000f6c0: 6f72 2822 6578 7065 6374 6564 2069 6e70  or("expected inp
+0000f6d0: 7574 2074 6f20 6265 2061 2073 6361 6c61  ut to be a scala
+0000f6e0: 7220 6f72 2061 206c 656e 6774 6820 3120  r or a length 1 
+0000f6f0: 7465 6e73 6f72 2229 0a20 2020 2063 6f6e  tensor").    con
+0000f700: 7465 7874 2e61 6464 2872 6573 2c20 6e6f  text.add(res, no
+0000f710: 6465 2e6e 616d 6529 0a0a 0a64 6566 205f  de.name)...def _
+0000f720: 6361 7374 2863 6f6e 7465 7874 2c20 6e6f  cast(context, no
+0000f730: 6465 2c20 6474 7970 652c 2064 7479 7065  de, dtype, dtype
+0000f740: 5f6e 616d 6529 3a0a 2020 2020 696e 7075  _name):.    inpu
+0000f750: 7473 203d 205f 6765 745f 696e 7075 7473  ts = _get_inputs
+0000f760: 2863 6f6e 7465 7874 2c20 6e6f 6465 2c20  (context, node, 
+0000f770: 6578 7065 6374 6564 3d31 290a 2020 2020  expected=1).    
+0000f780: 7820 3d20 696e 7075 7473 5b30 5d0a 2020  x = inputs[0].  
+0000f790: 2020 2320 496e 7075 7420 6d75 7374 2065    # Input must e
+0000f7a0: 6974 6865 7220 6265 2061 2073 6361 6c61  ither be a scala
+0000f7b0: 7220 6f72 2061 2028 3120 7820 3120 7820  r or a (1 x 1 x 
+0000f7c0: 2e2e 2e20 7820 3129 2074 656e 736f 720a  ... x 1) tensor.
+0000f7d0: 2020 2020 6966 206e 6f74 2028 6c65 6e28      if not (len(
+0000f7e0: 782e 7368 6170 6529 203d 3d20 3020 6f72  x.shape) == 0 or
+0000f7f0: 205f 6e70 2e61 6c6c 285b 6420 3d3d 2031   _np.all([d == 1
+0000f800: 2066 6f72 2064 2069 6e20 782e 7368 6170   for d in x.shap
+0000f810: 655d 2929 3a0a 2020 2020 2020 2020 7261  e])):.        ra
+0000f820: 6973 6520 5661 6c75 6545 7272 6f72 2822  ise ValueError("
+0000f830: 696e 7075 7420 746f 2063 6173 7420 6d75  input to cast mu
+0000f840: 7374 2062 6520 6569 7468 6572 2061 2073  st be either a s
+0000f850: 6361 6c61 7220 6f72 2061 206c 656e 6774  calar or a lengt
+0000f860: 6820 3120 7465 6e73 6f72 2229 0a0a 2020  h 1 tensor")..  
+0000f870: 2020 6966 2078 2e63 616e 5f62 655f 666f    if x.can_be_fo
+0000f880: 6c64 6564 5f74 6f5f 636f 6e73 7428 293a  lded_to_const():
+0000f890: 0a20 2020 2020 2020 2023 2049 6620 7820  .        # If x 
+0000f8a0: 6973 2061 2063 6f6d 7069 6c65 2d74 696d  is a compile-tim
+0000f8b0: 6520 636f 6e73 7461 6e74 2c20 6469 7265  e constant, dire
+0000f8c0: 6374 6c79 2063 6173 7420 6974 2074 6f20  ctly cast it to 
+0000f8d0: 4064 7479 7065 2069 6620 6974 2773 0a20  @dtype if it's. 
+0000f8e0: 2020 2020 2020 2023 206e 6f74 206f 6e65         # not one
+0000f8f0: 2061 6c72 6561 6479 2e0a 2020 2020 2020   already..      
+0000f900: 2020 6966 206e 6f74 2069 7369 6e73 7461    if not isinsta
+0000f910: 6e63 6528 782e 7661 6c2c 2064 7479 7065  nce(x.val, dtype
+0000f920: 293a 0a20 2020 2020 2020 2020 2020 2072  ):.            r
+0000f930: 6573 203d 206d 622e 636f 6e73 7428 7661  es = mb.const(va
+0000f940: 6c3d 6474 7970 6528 782e 7661 6c29 2c20  l=dtype(x.val), 
+0000f950: 6e61 6d65 3d6e 6f64 652e 6e61 6d65 290a  name=node.name).
+0000f960: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
+0000f970: 2020 2020 2020 2020 2020 7265 7320 3d20            res = 
+0000f980: 780a 2020 2020 656c 6966 2078 2e73 6861  x.    elif x.sha
+0000f990: 7065 203d 3d20 2831 2c29 3a0a 2020 2020  pe == (1,):.    
+0000f9a0: 2020 2020 7820 3d20 6d62 2e73 7175 6565      x = mb.squee
+0000f9b0: 7a65 2878 3d78 2c20 6e61 6d65 3d6e 6f64  ze(x=x, name=nod
+0000f9c0: 652e 6e61 6d65 202b 2022 5f69 7465 6d22  e.name + "_item"
+0000f9d0: 290a 2020 2020 2020 2020 7265 7320 3d20  ).        res = 
+0000f9e0: 6d62 2e63 6173 7428 783d 782c 2064 7479  mb.cast(x=x, dty
+0000f9f0: 7065 3d64 7479 7065 5f6e 616d 652c 206e  pe=dtype_name, n
+0000fa00: 616d 653d 6e6f 6465 2e6e 616d 6529 0a20  ame=node.name). 
+0000fa10: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
+0000fa20: 2069 6620 6c65 6e28 782e 7368 6170 6529   if len(x.shape)
+0000fa30: 203e 2030 3a0a 2020 2020 2020 2020 2020   > 0:.          
+0000fa40: 2020 2320 544f 444f 3a20 5468 6572 6527    # TODO: There'
+0000fa50: 7320 6e6f 204d 494c 206f 7020 746f 2065  s no MIL op to e
+0000fa60: 7874 7261 6374 2061 2076 616c 7565 2066  xtract a value f
+0000fa70: 726f 6d20 6120 7379 6d62 6f6c 6963 2074  rom a symbolic t
+0000fa80: 656e 736f 722c 0a20 2020 2020 2020 2020  ensor,.         
+0000fa90: 2020 2023 2073 6f20 6173 2061 2077 6f72     # so as a wor
+0000faa0: 6b61 726f 756e 6420 7765 2075 7365 2072  karound we use r
+0000fab0: 6564 7563 655f 6d61 7820 746f 2063 6f6e  educe_max to con
+0000fac0: 7665 7274 2069 7420 746f 2061 2073 6361  vert it to a sca
+0000fad0: 6c61 722e 0a20 2020 2020 2020 2020 2020  lar..           
+0000fae0: 2078 203d 206d 622e 7265 6475 6365 5f6d   x = mb.reduce_m
+0000faf0: 6178 2878 3d78 2c20 6e61 6d65 3d6e 6f64  ax(x=x, name=nod
+0000fb00: 652e 6e61 6d65 202b 2022 5f69 7465 6d22  e.name + "_item"
+0000fb10: 290a 2020 2020 2020 2020 7265 7320 3d20  ).        res = 
+0000fb20: 6d62 2e63 6173 7428 783d 782c 2064 7479  mb.cast(x=x, dty
+0000fb30: 7065 3d64 7479 7065 5f6e 616d 652c 206e  pe=dtype_name, n
+0000fb40: 616d 653d 6e6f 6465 2e6e 616d 6529 0a20  ame=node.name). 
+0000fb50: 2020 2063 6f6e 7465 7874 2e61 6464 2872     context.add(r
+0000fb60: 6573 2c20 6e6f 6465 2e6e 616d 6529 0a0a  es, node.name)..
+0000fb70: 0a40 7265 6769 7374 6572 5f74 6f72 6368  .@register_torch
+0000fb80: 5f6f 7028 746f 7263 685f 616c 6961 733d  _op(torch_alias=
+0000fb90: 5b22 626f 6f6c 225d 290a 6465 6620 5f62  ["bool"]).def _b
+0000fba0: 6f6f 6c28 636f 6e74 6578 742c 206e 6f64  ool(context, nod
+0000fbb0: 6529 3a0a 2020 2020 5f63 6173 7428 636f  e):.    _cast(co
+0000fbc0: 6e74 6578 742c 206e 6f64 652c 2062 6f6f  ntext, node, boo
+0000fbd0: 6c2c 2022 626f 6f6c 2229 0a0a 0a40 7265  l, "bool")...@re
+0000fbe0: 6769 7374 6572 5f74 6f72 6368 5f6f 7028  gister_torch_op(
+0000fbf0: 746f 7263 685f 616c 6961 733d 5b22 696e  torch_alias=["in
+0000fc00: 7422 5d29 0a64 6566 205f 696e 7428 636f  t"]).def _int(co
+0000fc10: 6e74 6578 742c 206e 6f64 6529 3a0a 2020  ntext, node):.  
+0000fc20: 2020 5f63 6173 7428 636f 6e74 6578 742c    _cast(context,
+0000fc30: 206e 6f64 652c 2069 6e74 2c20 2269 6e74   node, int, "int
+0000fc40: 3332 2229 0a0a 0a40 7265 6769 7374 6572  32")...@register
+0000fc50: 5f74 6f72 6368 5f6f 700a 6465 6620 6c61  _torch_op.def la
+0000fc60: 7965 725f 6e6f 726d 2863 6f6e 7465 7874  yer_norm(context
+0000fc70: 2c20 6e6f 6465 293a 0a20 2020 2069 6e70  , node):.    inp
+0000fc80: 7574 7320 3d20 5f67 6574 5f69 6e70 7574  uts = _get_input
+0000fc90: 7328 636f 6e74 6578 742c 206e 6f64 652c  s(context, node,
+0000fca0: 2065 7870 6563 7465 643d 3629 0a20 2020   expected=6).   
+0000fcb0: 205f 696e 7075 7420 3d20 696e 7075 7473   _input = inputs
+0000fcc0: 5b30 5d0a 2020 2020 6e6f 726d 616c 697a  [0].    normaliz
+0000fcd0: 6564 5f73 6861 7065 203d 2069 6e70 7574  ed_shape = input
+0000fce0: 735b 315d 0a20 2020 2077 6569 6768 7420  s[1].    weight 
+0000fcf0: 3d20 696e 7075 7473 5b32 5d0a 2020 2020  = inputs[2].    
+0000fd00: 6269 6173 203d 2069 6e70 7574 735b 335d  bias = inputs[3]
+0000fd10: 0a20 2020 2065 7073 203d 2069 6e70 7574  .    eps = input
+0000fd20: 735b 345d 0a20 2020 2023 2063 7564 6e6e  s[4].    # cudnn
+0000fd30: 5f65 6e61 626c 6520 3d20 696e 7075 7473  _enable = inputs
+0000fd40: 5b35 5d20 756e 7573 6564 0a0a 2020 2020  [5] unused..    
+0000fd50: 6c61 7965 725f 6e6f 726d 203d 206d 622e  layer_norm = mb.
+0000fd60: 6c61 7965 725f 6e6f 726d 280a 2020 2020  layer_norm(.    
+0000fd70: 2020 2020 783d 5f69 6e70 7574 2c0a 2020      x=_input,.  
+0000fd80: 2020 2020 2020 6178 6573 3d6c 6973 7428        axes=list(
+0000fd90: 7261 6e67 6528 2d6c 656e 286e 6f72 6d61  range(-len(norma
+0000fda0: 6c69 7a65 645f 7368 6170 652e 7661 6c29  lized_shape.val)
+0000fdb0: 2c20 3029 292c 0a20 2020 2020 2020 2067  , 0)),.        g
+0000fdc0: 616d 6d61 3d77 6569 6768 742c 0a20 2020  amma=weight,.   
+0000fdd0: 2020 2020 2062 6574 613d 6269 6173 2c0a       beta=bias,.
+0000fde0: 2020 2020 2020 2020 6570 7369 6c6f 6e3d          epsilon=
+0000fdf0: 6570 732c 0a20 2020 2020 2020 206e 616d  eps,.        nam
+0000fe00: 653d 6e6f 6465 2e6e 616d 652c 0a20 2020  e=node.name,.   
+0000fe10: 2029 0a20 2020 2063 6f6e 7465 7874 2e61   ).    context.a
+0000fe20: 6464 286c 6179 6572 5f6e 6f72 6d29 0a0a  dd(layer_norm)..
+0000fe30: 0a40 7265 6769 7374 6572 5f74 6f72 6368  .@register_torch
+0000fe40: 5f6f 700a 6465 6620 6e75 6d74 6f74 656e  _op.def numtoten
+0000fe50: 736f 7228 636f 6e74 6578 742c 206e 6f64  sor(context, nod
+0000fe60: 6529 3a0a 2020 2020 696e 7075 7473 203d  e):.    inputs =
+0000fe70: 205f 6765 745f 696e 7075 7473 2863 6f6e   _get_inputs(con
+0000fe80: 7465 7874 2c20 6e6f 6465 2c20 6578 7065  text, node, expe
+0000fe90: 6374 6564 3d31 290a 2020 2020 7820 3d20  cted=1).    x = 
+0000fea0: 696e 7075 7473 5b30 5d0a 2020 2020 6966  inputs[0].    if
+0000feb0: 2078 2e73 6861 7065 2021 3d20 2829 3a0a   x.shape != ():.
+0000fec0: 2020 2020 2020 2020 7261 6973 6520 5661          raise Va
+0000fed0: 6c75 6545 7272 6f72 280a 2020 2020 2020  lueError(.      
+0000fee0: 2020 2020 2020 226e 756d 746f 7465 6e73        "numtotens
+0000fef0: 6f72 2065 7870 6563 7465 6420 7363 616c  or expected scal
+0000ff00: 6172 2069 6e70 7574 2c20 676f 7420 7465  ar input, got te
+0000ff10: 6e73 6f72 2077 6974 6820 7368 6170 6520  nsor with shape 
+0000ff20: 7b7d 222e 666f 726d 6174 280a 2020 2020  {}".format(.    
+0000ff30: 2020 2020 2020 2020 2020 2020 782e 7368              x.sh
+0000ff40: 6170 650a 2020 2020 2020 2020 2020 2020  ape.            
+0000ff50: 290a 2020 2020 2020 2020 290a 0a20 2020  ).        )..   
+0000ff60: 2069 6620 782e 6361 6e5f 6265 5f66 6f6c   if x.can_be_fol
+0000ff70: 6465 645f 746f 5f63 6f6e 7374 2829 3a0a  ded_to_const():.
+0000ff80: 2020 2020 2020 2020 7265 7320 3d20 6d62          res = mb
+0000ff90: 2e63 6f6e 7374 2876 616c 3d5b 782e 7661  .const(val=[x.va
+0000ffa0: 6c5d 2c20 6e61 6d65 3d6e 6f64 652e 6e61  l], name=node.na
+0000ffb0: 6d65 290a 2020 2020 2020 2020 636f 6e74  me).        cont
+0000ffc0: 6578 742e 6164 6428 7265 7329 0a20 2020  ext.add(res).   
+0000ffd0: 2065 6c73 653a 0a20 2020 2020 2020 2063   else:.        c
+0000ffe0: 6f6e 7465 7874 2e61 6464 2878 2c20 6e6f  ontext.add(x, no
+0000fff0: 6465 2e6e 616d 6529 0a0a 0a64 6566 205f  de.name)...def _
+00010000: 6966 7a6f 5f74 6f5f 6966 6f7a 2877 6569  ifzo_to_ifoz(wei
+00010010: 6768 7473 2c20 6e61 6d65 293a 0a20 2020  ghts, name):.   
+00010020: 2022 2222 0a20 2020 2069 2c20 662c 207a   """.    i, f, z
+00010030: 2c20 6f20 2d3e 2069 2c20 662c 206f 2c20  , o -> i, f, o, 
+00010040: 7a0a 2020 2020 7768 6572 6520 7765 6967  z.    where weig
+00010050: 6874 735f 7370 6c69 745b 305d 203d 3d20  hts_split[0] == 
+00010060: 692c 2065 7463 2e0a 2020 2020 5573 6564  i, etc..    Used
+00010070: 2074 6f20 7472 616e 7366 6f72 6d20 6c73   to transform ls
+00010080: 746d 2077 6569 6768 7473 2066 726f 6d20  tm weights from 
+00010090: 7079 746f 7263 680a 2020 2020 746f 2043  pytorch.    to C
+000100a0: 6f72 6520 4d4c 2066 6f72 6d61 740a 2020  ore ML format.  
+000100b0: 2020 2222 220a 2020 2020 7370 6c69 745f    """.    split_
+000100c0: 7369 7a65 203d 2077 6569 6768 7473 2e73  size = weights.s
+000100d0: 6861 7065 5b30 5d20 2f2f 2034 0a20 2020  hape[0] // 4.   
+000100e0: 2077 6569 6768 7473 5f73 706c 6974 203d   weights_split =
+000100f0: 206d 622e 7370 6c69 7428 783d 7765 6967   mb.split(x=weig
+00010100: 6874 732c 2073 706c 6974 5f73 697a 6573  hts, split_sizes
+00010110: 3d5f 6e70 2e61 7272 6179 285b 7370 6c69  =_np.array([spli
+00010120: 745f 7369 7a65 5d20 2a20 3429 2c20 6178  t_size] * 4), ax
+00010130: 6973 3d30 290a 2020 2020 7265 7475 726e  is=0).    return
+00010140: 206d 622e 636f 6e63 6174 280a 2020 2020   mb.concat(.    
+00010150: 2020 2020 7661 6c75 6573 3d5b 7765 6967      values=[weig
+00010160: 6874 735f 7370 6c69 745b 305d 2c20 7765  hts_split[0], we
+00010170: 6967 6874 735f 7370 6c69 745b 315d 2c20  ights_split[1], 
+00010180: 7765 6967 6874 735f 7370 6c69 745b 335d  weights_split[3]
+00010190: 2c20 7765 6967 6874 735f 7370 6c69 745b  , weights_split[
+000101a0: 325d 5d2c 0a20 2020 2020 2020 2061 7869  2]],.        axi
+000101b0: 733d 302c 0a20 2020 2029 0a0a 0a64 6566  s=0,.    )...def
+000101c0: 205f 7079 746f 7263 685f 6869 6464 656e   _pytorch_hidden
+000101d0: 5f74 6f5f 636f 7265 6d6c 5f6d 696c 6f70  _to_coreml_milop
+000101e0: 7328 782c 206e 616d 6529 3a0a 2020 2020  s(x, name):.    
+000101f0: 2222 220a 2020 2020 5573 6564 2074 6f20  """.    Used to 
+00010200: 7472 616e 7366 6f72 6d20 6c73 746d 2073  transform lstm s
+00010210: 7461 7465 2076 616c 7565 7320 2868 6e2c  tate values (hn,
+00010220: 2063 6e29 0a20 2020 2066 726f 6d20 7079   cn).    from py
+00010230: 746f 7263 6820 746f 2043 6f72 6520 4d4c  torch to Core ML
+00010240: 2066 6f72 6d61 742e 0a20 2020 2022 2222   format..    """
+00010250: 0a20 2020 2073 706c 6974 5f73 697a 6520  .    split_size 
+00010260: 3d20 782e 7368 6170 655b 305d 202f 2f20  = x.shape[0] // 
+00010270: 320a 2020 2020 785f 7370 6c69 7420 3d20  2.    x_split = 
+00010280: 6d62 2e73 706c 6974 2878 3d78 2c20 7370  mb.split(x=x, sp
+00010290: 6c69 745f 7369 7a65 733d 5f6e 702e 6172  lit_sizes=_np.ar
+000102a0: 7261 7928 5b73 706c 6974 5f73 697a 655d  ray([split_size]
+000102b0: 202a 2032 292c 2061 7869 733d 3029 0a20   * 2), axis=0). 
+000102c0: 2020 2078 5f63 6f6e 6361 7420 3d20 6d62     x_concat = mb
+000102d0: 2e63 6f6e 6361 7428 0a20 2020 2020 2020  .concat(.       
+000102e0: 2076 616c 7565 733d 5b78 5f73 706c 6974   values=[x_split
+000102f0: 5b30 5d2c 2078 5f73 706c 6974 5b31 5d5d  [0], x_split[1]]
+00010300: 2c0a 2020 2020 2020 2020 6178 6973 3d32  ,.        axis=2
+00010310: 2c0a 2020 2020 290a 2020 2020 2320 2834  ,.    ).    # (4
+00010320: 2e29 2053 6565 2064 6f63 7374 7269 6e67  .) See docstring
+00010330: 2074 6f20 406c 7374 6d0a 2020 2020 7265   to @lstm.    re
+00010340: 7475 726e 206d 622e 7371 7565 657a 6528  turn mb.squeeze(
+00010350: 783d 785f 636f 6e63 6174 2c20 6178 6573  x=x_concat, axes
+00010360: 3d5f 6e70 2e61 7272 6179 285b 305d 292c  =_np.array([0]),
+00010370: 206e 616d 653d 6e61 6d65 290a 0a0a 6465   name=name)...de
+00010380: 6620 5f61 6464 5f67 7275 5f6c 6179 6572  f _add_gru_layer
+00010390: 285f 696e 7075 742c 2068 302c 2077 692c  (_input, h0, wi,
+000103a0: 2077 682c 2062 692c 2062 682c 2068 5f6c   wh, bi, bh, h_l
+000103b0: 6973 745f 6e61 6d65 2c20 685f 6e61 6d65  ist_name, h_name
+000103c0: 293a 0a20 2020 2022 2222 0a20 2020 2041  ):.    """.    A
+000103d0: 6464 2061 2073 696e 676c 6520 4752 5520  dd a single GRU 
+000103e0: 6c61 7965 722e 0a20 2020 2050 6c65 6173  layer..    Pleas
+000103f0: 6520 6e6f 7465 2074 6861 7420 7468 6520  e note that the 
+00010400: 436f 7265 204d 4c20 4752 5520 6861 7320  Core ML GRU has 
+00010410: 6469 6666 6572 656e 7420 6465 6669 6e69  different defini
+00010420: 7469 6f6e 2066 726f 6d20 546f 7263 682c  tion from Torch,
+00010430: 0a20 2020 2073 6f20 7765 2063 616e 6e6f  .    so we canno
+00010440: 7420 7573 6520 6d62 2e67 7275 2c20 616e  t use mb.gru, an
+00010450: 6420 6e65 6564 2074 6f20 696d 706c 656d  d need to implem
+00010460: 656e 7420 6974 2077 6974 6820 7768 696c  ent it with whil
+00010470: 6520 6c6f 6f70 2e0a 2020 2020 546f 2062  e loop..    To b
+00010480: 6520 6d6f 7265 2073 7065 6369 6669 632c  e more specific,
+00010490: 2069 6e20 436f 7265 204d 4c3a 0a0a 2020   in Core ML:..  
+000104a0: 2020 6f5f 7420 3d20 6163 7469 7661 7469    o_t = activati
+000104b0: 6f6e 2857 5f7b 696f 7d20 785f 7420 2b20  on(W_{io} x_t + 
+000104c0: 725f 7420 2a20 575f 7b68 6f7d 2068 5f28  r_t * W_{ho} h_(
+000104d0: 74e2 8892 3129 202b 2062 5f7b 6f7d 290a  t...1) + b_{o}).
+000104e0: 0a20 2020 2077 6869 6c65 2074 6f72 6368  .    while torch
+000104f0: 2068 6173 0a20 2020 206f 5f74 203d 2061   has.    o_t = a
+00010500: 6374 6976 6174 696f 6e28 575f 7b69 6f7d  ctivation(W_{io}
+00010510: 2078 5f74 202b 2062 5f7b 696f 7d20 2b20   x_t + b_{io} + 
+00010520: 725f 7420 2a20 2857 5f7b 686f 7d20 685f  r_t * (W_{ho} h_
+00010530: 2874 e288 9231 2920 2b20 625f 7b68 6f7d  (t...1) + b_{ho}
+00010540: 2929 0a0a 2020 2020 496e 7075 7473 3a0a  ))..    Inputs:.
+00010550: 2020 2020 2020 2020 5f69 6e70 7574 203a          _input :
+00010560: 2028 7365 715f 6c65 6e2c 2062 6174 6368   (seq_len, batch
+00010570: 5f73 697a 652c 2069 6e70 7574 5f64 696d  _size, input_dim
+00010580: 290a 2020 2020 2020 2020 6830 203a 2028  ).        h0 : (
+00010590: 312c 2062 6174 6368 5f73 697a 652c 2068  1, batch_size, h
+000105a0: 6964 6465 6e5f 6469 6d29 0a20 2020 2020  idden_dim).     
+000105b0: 2020 2077 6920 3a20 2833 2a68 6964 6465     wi : (3*hidde
+000105c0: 6e5f 6469 6d2c 2069 6e70 7574 5f64 696d  n_dim, input_dim
+000105d0: 2920 666f 7220 7468 6520 6669 7273 7420  ) for the first 
+000105e0: 6c61 7965 722c 2065 6c73 6520 2833 2a68  layer, else (3*h
+000105f0: 6964 6465 6e5f 6469 6d2c 2068 6964 6465  idden_dim, hidde
+00010600: 6e5f 6469 6d29 0a20 2020 2020 2020 2077  n_dim).        w
+00010610: 6820 3a20 2833 2a68 6964 6465 6e5f 6469  h : (3*hidden_di
+00010620: 6d2c 2068 6964 6465 6e5f 6469 6d29 0a20  m, hidden_dim). 
+00010630: 2020 2020 2020 2062 6920 3a20 2833 2a68         bi : (3*h
+00010640: 6964 6465 6e5f 6469 6d29 0a20 2020 2020  idden_dim).     
+00010650: 2020 2062 6820 3a20 2833 2a68 6964 6465     bh : (3*hidde
+00010660: 6e5f 6469 6d29 0a0a 2020 2020 5265 7475  n_dim)..    Retu
+00010670: 726e 3a0a 2020 2020 2020 2020 685f 6c69  rn:.        h_li
+00010680: 7374 203a 2074 6865 206c 6973 7420 636f  st : the list co
+00010690: 6e74 6169 6e73 2061 6c6c 2068 6964 6465  ntains all hidde
+000106a0: 6e20 7374 6174 6573 2066 6f72 2065 6163  n states for eac
+000106b0: 6820 7469 6d65 2073 7465 700a 2020 2020  h time step.    
+000106c0: 2020 2020 2020 2020 2020 2020 2077 6974               wit
+000106d0: 6820 7368 6170 6520 2873 6571 5f6c 656e  h shape (seq_len
+000106e0: 2c20 6261 7463 685f 7369 7a65 2c20 6869  , batch_size, hi
+000106f0: 6464 656e 5f64 696d 290a 2020 2020 2020  dden_dim).      
+00010700: 2020 6820 3a20 7468 6520 6c61 7374 2068    h : the last h
+00010710: 6964 6465 6e20 7374 6174 652c 2077 6974  idden state, wit
+00010720: 6820 7368 6170 6520 2831 2c20 6261 7463  h shape (1, batc
+00010730: 685f 7369 7a65 2c20 6869 6464 656e 5f64  h_size, hidden_d
+00010740: 696d 0a20 2020 2022 2222 0a0a 2020 2020  im.    """..    
+00010750: 2320 7370 6c69 7420 7468 6520 7765 6967  # split the weig
+00010760: 6874 7320 616e 6420 6269 6173 0a20 2020  hts and bias.   
+00010770: 2077 5f69 722c 2077 5f69 7a2c 2077 5f69   w_ir, w_iz, w_i
+00010780: 6e20 3d20 5f6e 702e 7370 6c69 7428 7769  n = _np.split(wi
+00010790: 2c20 3329 0a20 2020 2077 5f68 722c 2077  , 3).    w_hr, w
+000107a0: 5f68 7a2c 2077 5f68 6e20 3d20 5f6e 702e  _hz, w_hn = _np.
+000107b0: 7370 6c69 7428 7768 2c20 3329 0a20 2020  split(wh, 3).   
+000107c0: 2062 5f69 722c 2062 5f69 7a2c 2062 5f69   b_ir, b_iz, b_i
+000107d0: 6e20 3d20 5f6e 702e 7370 6c69 7428 6269  n = _np.split(bi
+000107e0: 2c20 3329 0a20 2020 2062 5f68 722c 2062  , 3).    b_hr, b
+000107f0: 5f68 7a2c 2062 5f68 6e20 3d20 5f6e 702e  _hz, b_hn = _np.
+00010800: 7370 6c69 7428 6268 2c20 3329 0a0a 2020  split(bh, 3)..  
+00010810: 2020 2320 616c 6c6f 6361 7465 2068 6c69    # allocate hli
+00010820: 7374 0a20 2020 2023 2068 6c69 7374 203a  st.    # hlist :
+00010830: 2028 7365 715f 6c65 6e2c 2062 6174 6368   (seq_len, batch
+00010840: 5f73 697a 652c 2068 6964 6465 6e5f 6469  _size, hidden_di
+00010850: 6d29 0a20 2020 2078 5f73 6861 7065 203d  m).    x_shape =
+00010860: 206d 622e 7368 6170 6528 783d 5f69 6e70   mb.shape(x=_inp
+00010870: 7574 290a 2020 2020 7365 715f 6c65 6e20  ut).    seq_len 
+00010880: 3d20 6d62 2e73 6c69 6365 5f62 795f 696e  = mb.slice_by_in
+00010890: 6465 7828 783d 785f 7368 6170 652c 2062  dex(x=x_shape, b
+000108a0: 6567 696e 3d5b 305d 2c20 656e 643d 5b31  egin=[0], end=[1
+000108b0: 5d29 0a20 2020 2068 5f73 6861 7065 203d  ]).    h_shape =
+000108c0: 206d 622e 7368 6170 6528 783d 6830 290a   mb.shape(x=h0).
+000108d0: 2020 2020 685f 7368 6170 6520 3d20 6d62      h_shape = mb
+000108e0: 2e73 6c69 6365 5f62 795f 696e 6465 7828  .slice_by_index(
+000108f0: 783d 685f 7368 6170 652c 2062 6567 696e  x=h_shape, begin
+00010900: 3d5b 315d 2c20 656e 643d 5b33 5d29 0a20  =[1], end=[3]). 
+00010910: 2020 2068 5f6c 6973 745f 7368 6170 6520     h_list_shape 
+00010920: 3d20 6d62 2e63 6f6e 6361 7428 7661 6c75  = mb.concat(valu
+00010930: 6573 3d5b 7365 715f 6c65 6e2c 2068 5f73  es=[seq_len, h_s
+00010940: 6861 7065 5d2c 2061 7869 733d 3029 0a20  hape], axis=0). 
+00010950: 2020 2068 5f6c 6973 7420 3d20 6d62 2e66     h_list = mb.f
+00010960: 696c 6c28 7368 6170 653d 685f 6c69 7374  ill(shape=h_list
+00010970: 5f73 6861 7065 290a 0a20 2020 2023 2063  _shape)..    # c
+00010980: 6f6e 6361 7465 2068 3020 746f 2068 5f6c  oncate h0 to h_l
+00010990: 6973 740a 2020 2020 2320 685f 6c69 7374  ist.    # h_list
+000109a0: 3a20 2873 6571 5f6c 656e 202b 2031 2c20  : (seq_len + 1, 
+000109b0: 6261 7463 685f 7369 7a65 2c20 6869 6464  batch_size, hidd
+000109c0: 656e 5f64 696d 290a 2020 2020 685f 6c69  en_dim).    h_li
+000109d0: 7374 203d 206d 622e 636f 6e63 6174 2876  st = mb.concat(v
+000109e0: 616c 7565 733d 5b68 302c 2068 5f6c 6973  alues=[h0, h_lis
+000109f0: 745d 2c20 6178 6973 3d30 290a 0a20 2020  t], axis=0)..   
+00010a00: 2064 6566 2063 6f6e 6428 692c 2068 5f6c   def cond(i, h_l
+00010a10: 6973 7429 3a0a 2020 2020 2020 2020 7265  ist):.        re
+00010a20: 7475 726e 206d 622e 6c65 7373 2878 3d69  turn mb.less(x=i
+00010a30: 2c20 793d 7365 715f 6c65 6e29 0a0a 2020  , y=seq_len)..  
+00010a40: 2020 6465 6620 626f 6479 2869 2c20 685f    def body(i, h_
+00010a50: 6c69 7374 293a 0a20 2020 2020 2020 2023  list):.        #
+00010a60: 2073 6c69 6365 2066 6f72 2074 6865 2078   slice for the x
+00010a70: 2061 6e64 2073 7461 7465 2066 6f72 2074   and state for t
+00010a80: 696d 6520 7374 6570 2069 0a20 2020 2020  ime step i.     
+00010a90: 2020 2023 2074 6865 2072 6573 756c 7469     # the resulti
+00010aa0: 6e67 2073 6861 7065 3a0a 2020 2020 2020  ng shape:.      
+00010ab0: 2020 2320 7874 203a 2028 6261 7463 685f    # xt : (batch_
+00010ac0: 7369 7a65 2c20 696e 7075 745f 6469 6d29  size, input_dim)
+00010ad0: 0a20 2020 2020 2020 2023 2068 5f70 7265  .        # h_pre
+00010ae0: 7620 3a20 2862 6174 6368 5f73 697a 652c  v : (batch_size,
+00010af0: 2068 6964 6465 6e5f 6469 6d29 0a0a 2020   hidden_dim)..  
+00010b00: 2020 2020 2020 7874 203d 206d 622e 6761        xt = mb.ga
+00010b10: 7468 6572 2878 3d5f 696e 7075 742c 2069  ther(x=_input, i
+00010b20: 6e64 6963 6573 3d69 2c20 6178 6973 3d30  ndices=i, axis=0
+00010b30: 290a 2020 2020 2020 2020 685f 7072 6576  ).        h_prev
+00010b40: 203d 206d 622e 6761 7468 6572 2878 3d68   = mb.gather(x=h
+00010b50: 5f6c 6973 742c 2069 6e64 6963 6573 3d69  _list, indices=i
+00010b60: 2c20 6178 6973 3d30 290a 0a20 2020 2020  , axis=0)..     
+00010b70: 2020 2078 7420 3d20 6d62 2e73 7175 6565     xt = mb.squee
+00010b80: 7a65 2878 3d78 742c 2061 7865 733d 5b30  ze(x=xt, axes=[0
+00010b90: 5d29 0a20 2020 2020 2020 2068 5f70 7265  ]).        h_pre
+00010ba0: 7620 3d20 6d62 2e73 7175 6565 7a65 2878  v = mb.squeeze(x
+00010bb0: 3d68 5f70 7265 762c 2061 7865 733d 5b30  =h_prev, axes=[0
+00010bc0: 5d29 0a0a 2020 2020 2020 2020 2320 7274  ])..        # rt
+00010bd0: 203d 2073 6967 6d6f 6964 2877 6972 202a   = sigmoid(wir *
+00010be0: 2078 7420 2b20 7768 7220 2a20 685f 7072   xt + whr * h_pr
+00010bf0: 6576 202b 2062 6972 202b 2062 6872 290a  ev + bir + bhr).
+00010c00: 2020 2020 2020 2020 2320 7274 203a 2028          # rt : (
+00010c10: 6261 7463 685f 7369 7a65 2c20 6869 6464  batch_size, hidd
+00010c20: 656e 5f64 696d 290a 2020 2020 2020 2020  en_dim).        
+00010c30: 7274 5f31 203d 206d 622e 6c69 6e65 6172  rt_1 = mb.linear
+00010c40: 2878 3d78 742c 2077 6569 6768 743d 775f  (x=xt, weight=w_
+00010c50: 6972 2c20 6269 6173 3d62 5f69 7229 0a20  ir, bias=b_ir). 
+00010c60: 2020 2020 2020 2072 745f 3220 3d20 6d62         rt_2 = mb
+00010c70: 2e6c 696e 6561 7228 783d 685f 7072 6576  .linear(x=h_prev
+00010c80: 2c20 7765 6967 6874 3d77 5f68 722c 2062  , weight=w_hr, b
+00010c90: 6961 733d 625f 6872 290a 2020 2020 2020  ias=b_hr).      
+00010ca0: 2020 7274 203d 206d 622e 6164 6428 783d    rt = mb.add(x=
+00010cb0: 7274 5f31 2c20 793d 7274 5f32 290a 2020  rt_1, y=rt_2).  
+00010cc0: 2020 2020 2020 7274 203d 206d 622e 7369        rt = mb.si
+00010cd0: 676d 6f69 6428 783d 7274 290a 0a20 2020  gmoid(x=rt)..   
+00010ce0: 2020 2020 2023 207a 7420 3d20 7369 676d       # zt = sigm
+00010cf0: 6f69 6428 7769 7a20 2a20 7874 202b 2077  oid(wiz * xt + w
+00010d00: 687a 202a 2068 5f70 7265 7620 2b20 6269  hz * h_prev + bi
+00010d10: 7a20 2b20 6268 7a29 0a20 2020 2020 2020  z + bhz).       
+00010d20: 2023 207a 7420 3a20 2862 6174 6368 5f73   # zt : (batch_s
+00010d30: 697a 652c 2068 6964 6465 6e5f 6469 6d29  ize, hidden_dim)
+00010d40: 0a20 2020 2020 2020 207a 745f 3120 3d20  .        zt_1 = 
+00010d50: 6d62 2e6c 696e 6561 7228 783d 7874 2c20  mb.linear(x=xt, 
+00010d60: 7765 6967 6874 3d77 5f69 7a2c 2062 6961  weight=w_iz, bia
+00010d70: 733d 625f 697a 290a 2020 2020 2020 2020  s=b_iz).        
+00010d80: 7a74 5f32 203d 206d 622e 6c69 6e65 6172  zt_2 = mb.linear
+00010d90: 2878 3d68 5f70 7265 762c 2077 6569 6768  (x=h_prev, weigh
+00010da0: 743d 775f 687a 2c20 6269 6173 3d62 5f68  t=w_hz, bias=b_h
+00010db0: 7a29 0a20 2020 2020 2020 207a 7420 3d20  z).        zt = 
+00010dc0: 6d62 2e61 6464 2878 3d7a 745f 312c 2079  mb.add(x=zt_1, y
+00010dd0: 3d7a 745f 3229 0a20 2020 2020 2020 207a  =zt_2).        z
+00010de0: 7420 3d20 6d62 2e73 6967 6d6f 6964 2878  t = mb.sigmoid(x
+00010df0: 3d7a 7429 0a0a 2020 2020 2020 2020 2320  =zt)..        # 
+00010e00: 6e74 203d 2074 616e 6828 7769 6e20 2a20  nt = tanh(win * 
+00010e10: 7874 202b 2062 696e 202b 2072 7428 7768  xt + bin + rt(wh
+00010e20: 6e20 2a20 685f 7072 6576 202b 2062 686e  n * h_prev + bhn
+00010e30: 2929 0a20 2020 2020 2020 2023 206e 7420  )).        # nt 
+00010e40: 3a20 2862 6174 6368 5f73 697a 652c 2068  : (batch_size, h
+00010e50: 6964 6465 6e5f 6469 6d29 0a20 2020 2020  idden_dim).     
+00010e60: 2020 206e 745f 3120 3d20 6d62 2e6c 696e     nt_1 = mb.lin
+00010e70: 6561 7228 783d 7874 2c20 7765 6967 6874  ear(x=xt, weight
+00010e80: 3d77 5f69 6e2c 2062 6961 733d 625f 696e  =w_in, bias=b_in
+00010e90: 290a 2020 2020 2020 2020 6e74 5f32 203d  ).        nt_2 =
+00010ea0: 206d 622e 6c69 6e65 6172 2878 3d68 5f70   mb.linear(x=h_p
+00010eb0: 7265 762c 2077 6569 6768 743d 775f 686e  rev, weight=w_hn
+00010ec0: 2c20 6269 6173 3d62 5f68 6e29 0a20 2020  , bias=b_hn).   
+00010ed0: 2020 2020 206e 745f 3220 3d20 6d62 2e6d       nt_2 = mb.m
+00010ee0: 756c 2878 3d72 742c 2079 3d6e 745f 3229  ul(x=rt, y=nt_2)
+00010ef0: 0a20 2020 2020 2020 206e 7420 3d20 6d62  .        nt = mb
+00010f00: 2e61 6464 2878 3d6e 745f 312c 2079 3d6e  .add(x=nt_1, y=n
+00010f10: 745f 3229 0a20 2020 2020 2020 206e 7420  t_2).        nt 
+00010f20: 3d20 6d62 2e74 616e 6828 783d 6e74 290a  = mb.tanh(x=nt).
+00010f30: 0a20 2020 2020 2020 2023 2068 203d 2028  .        # h = (
+00010f40: 312d 7a74 2920 2a20 6e74 202b 207a 742a  1-zt) * nt + zt*
+00010f50: 2068 5f70 7265 760a 2020 2020 2020 2020   h_prev.        
+00010f60: 2320 6820 3a20 2862 6174 6368 5f73 697a  # h : (batch_siz
+00010f70: 652c 2068 6964 6465 6e5f 6469 6d29 0a20  e, hidden_dim). 
+00010f80: 2020 2020 2020 2068 5f31 203d 206d 622e         h_1 = mb.
+00010f90: 7375 6228 783d 312e 2c20 793d 7a74 290a  sub(x=1., y=zt).
+00010fa0: 2020 2020 2020 2020 685f 3120 3d20 6d62          h_1 = mb
+00010fb0: 2e6d 756c 2878 3d68 5f31 2c20 793d 6e74  .mul(x=h_1, y=nt
+00010fc0: 290a 2020 2020 2020 2020 685f 3220 3d20  ).        h_2 = 
+00010fd0: 6d62 2e6d 756c 2878 3d7a 742c 2079 3d68  mb.mul(x=zt, y=h
+00010fe0: 5f70 7265 7629 0a20 2020 2020 2020 2068  _prev).        h
+00010ff0: 203d 206d 622e 6164 6428 783d 685f 312c   = mb.add(x=h_1,
+00011000: 2079 3d68 5f32 290a 0a20 2020 2020 2020   y=h_2)..       
+00011010: 2023 2075 7064 6174 6520 636f 756e 7465   # update counte
+00011020: 720a 2020 2020 2020 2020 636f 756e 7465  r.        counte
+00011030: 7220 3d20 6d62 2e61 6464 2878 3d69 2c20  r = mb.add(x=i, 
+00011040: 793d 3129 0a0a 2020 2020 2020 2020 2320  y=1)..        # 
+00011050: 7570 6461 7465 2068 2061 6e64 2068 5f6c  update h and h_l
+00011060: 6973 740a 2020 2020 2020 2020 6820 3d20  ist.        h = 
+00011070: 6d62 2e65 7870 616e 645f 6469 6d73 2878  mb.expand_dims(x
+00011080: 3d68 2c20 6178 6573 3d5b 305d 290a 2020  =h, axes=[0]).  
+00011090: 2020 2020 2020 685f 6c69 7374 203d 206d        h_list = m
+000110a0: 622e 7363 6174 7465 7228 6461 7461 3d68  b.scatter(data=h
+000110b0: 5f6c 6973 742c 2069 6e64 6963 6573 3d63  _list, indices=c
+000110c0: 6f75 6e74 6572 2c20 7570 6461 7465 733d  ounter, updates=
+000110d0: 6829 0a0a 2020 2020 2020 2020 7265 7475  h)..        retu
+000110e0: 726e 2028 0a20 2020 2020 2020 2020 2020  rn (.           
+000110f0: 2063 6f75 6e74 6572 2c0a 2020 2020 2020   counter,.      
+00011100: 2020 2020 2020 685f 6c69 7374 2c0a 2020        h_list,.  
+00011110: 2020 2020 2020 290a 0a20 2020 205f 2c20        )..    _, 
+00011120: 685f 6c69 7374 203d 206d 622e 7768 696c  h_list = mb.whil
+00011130: 655f 6c6f 6f70 280a 2020 2020 2020 2020  e_loop(.        
+00011140: 5f63 6f6e 643d 636f 6e64 2c20 5f62 6f64  _cond=cond, _bod
+00011150: 793d 626f 6479 2c20 6c6f 6f70 5f76 6172  y=body, loop_var
+00011160: 733d 285b 305d 2c20 685f 6c69 7374 292c  s=([0], h_list),
+00011170: 0a20 2020 2029 0a0a 2020 2020 2320 736c  .    )..    # sl
+00011180: 6963 6520 6830 206f 7574 206f 6620 685f  ice h0 out of h_
+00011190: 6c69 7374 0a20 2020 2068 5f6c 6973 7420  list.    h_list 
+000111a0: 3d20 6d62 2e73 6c69 6365 5f62 795f 696e  = mb.slice_by_in
+000111b0: 6465 7828 0a20 2020 2020 2020 2078 3d68  dex(.        x=h
+000111c0: 5f6c 6973 742c 0a20 2020 2020 2020 2062  _list,.        b
+000111d0: 6567 696e 3d5b 312c 2030 2c20 305d 2c0a  egin=[1, 0, 0],.
+000111e0: 2020 2020 2020 2020 656e 643d 5b30 2c20          end=[0, 
+000111f0: 302c 2030 5d2c 0a20 2020 2020 2020 2062  0, 0],.        b
+00011200: 6567 696e 5f6d 6173 6b3d 5b46 616c 7365  egin_mask=[False
+00011210: 2c20 5472 7565 2c20 5472 7565 5d2c 0a20  , True, True],. 
+00011220: 2020 2020 2020 2065 6e64 5f6d 6173 6b3d         end_mask=
+00011230: 5b54 7275 652c 2054 7275 652c 2054 7275  [True, True, Tru
+00011240: 655d 2c0a 2020 2020 2020 2020 6e61 6d65  e],.        name
+00011250: 3d68 5f6c 6973 745f 6e61 6d65 2c0a 2020  =h_list_name,.  
+00011260: 2020 290a 0a20 2020 2023 2067 6574 2074    )..    # get t
+00011270: 6865 206c 6173 7420 7374 6174 6520 6f66  he last state of
+00011280: 2068 5f6c 6973 740a 2020 2020 6966 2073   h_list.    if s
+00011290: 6571 5f6c 656e 2e76 616c 2069 7320 4e6f  eq_len.val is No
+000112a0: 6e65 206f 7220 7365 715f 6c65 6e2e 7661  ne or seq_len.va
+000112b0: 6c20 3e20 313a 0a20 2020 2020 2020 2068  l > 1:.        h
+000112c0: 203d 206d 622e 736c 6963 655f 6279 5f69   = mb.slice_by_i
+000112d0: 6e64 6578 280a 2020 2020 2020 2020 2020  ndex(.          
+000112e0: 2020 783d 685f 6c69 7374 2c0a 2020 2020    x=h_list,.    
+000112f0: 2020 2020 2020 2020 6265 6769 6e3d 5b2d          begin=[-
+00011300: 312c 2030 2c20 305d 2c0a 2020 2020 2020  1, 0, 0],.      
+00011310: 2020 2020 2020 656e 643d 5b2d 322c 2030        end=[-2, 0
+00011320: 2c20 305d 2c0a 2020 2020 2020 2020 2020  , 0],.          
+00011330: 2020 6265 6769 6e5f 6d61 736b 3d5b 4661    begin_mask=[Fa
+00011340: 6c73 652c 2054 7275 652c 2054 7275 655d  lse, True, True]
+00011350: 2c0a 2020 2020 2020 2020 2020 2020 656e  ,.            en
+00011360: 645f 6d61 736b 3d5b 4661 6c73 652c 2054  d_mask=[False, T
+00011370: 7275 652c 2054 7275 655d 2c0a 2020 2020  rue, True],.    
+00011380: 2020 2020 2020 2020 7374 7269 6465 3d5b          stride=[
+00011390: 2d31 2c20 312c 2031 5d2c 0a20 2020 2020  -1, 1, 1],.     
+000113a0: 2020 2020 2020 206e 616d 653d 685f 6e61         name=h_na
+000113b0: 6d65 2c0a 2020 2020 2020 2020 290a 2020  me,.        ).  
+000113c0: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
+000113d0: 6820 3d20 685f 6c69 7374 0a0a 2020 2020  h = h_list..    
+000113e0: 7265 7475 726e 2068 5f6c 6973 742c 2068  return h_list, h
+000113f0: 0a0a 0a40 7265 6769 7374 6572 5f74 6f72  ...@register_tor
+00011400: 6368 5f6f 700a 6465 6620 6772 7528 636f  ch_op.def gru(co
+00011410: 6e74 6578 742c 206e 6f64 6529 3a0a 2020  ntext, node):.  
+00011420: 2020 696e 7075 7473 203d 205f 6765 745f    inputs = _get_
+00011430: 696e 7075 7473 2863 6f6e 7465 7874 2c20  inputs(context, 
+00011440: 6e6f 6465 2c20 6578 7065 6374 6564 3d39  node, expected=9
+00011450: 290a 0a20 2020 205f 696e 7075 7420 3d20  )..    _input = 
+00011460: 696e 7075 7473 5b30 5d0a 2020 2020 6830  inputs[0].    h0
+00011470: 203d 2069 6e70 7574 735b 315d 0a20 2020   = inputs[1].   
+00011480: 2077 6569 6768 7473 5f6c 6973 7420 3d20   weights_list = 
+00011490: 696e 7075 7473 5b32 5d0a 2020 2020 6861  inputs[2].    ha
+000114a0: 735f 6269 6173 203d 2069 6e70 7574 735b  s_bias = inputs[
+000114b0: 335d 2e76 616c 0a20 2020 206e 756d 5f6c  3].val.    num_l
+000114c0: 6179 6572 7320 3d20 696e 7075 7473 5b34  ayers = inputs[4
+000114d0: 5d2e 7661 6c0a 2020 2020 6472 6f70 6f75  ].val.    dropou
+000114e0: 7420 3d20 696e 7075 7473 5b35 5d0a 2020  t = inputs[5].  
+000114f0: 2020 6269 6469 7265 6374 696f 6e61 6c20    bidirectional 
+00011500: 3d20 696e 7075 7473 5b37 5d2e 7661 6c0a  = inputs[7].val.
+00011510: 2020 2020 6261 7463 685f 6669 7273 7420      batch_first 
+00011520: 3d20 696e 7075 7473 5b38 5d2e 7661 6c0a  = inputs[8].val.
+00011530: 0a20 2020 2023 2046 6f72 2065 6163 6820  .    # For each 
+00011540: 6c61 7965 7220 6f66 2047 5255 2c20 7468  layer of GRU, th
+00011550: 6520 6c61 796f 7574 206f 6620 7468 6520  e layout of the 
+00011560: 7765 6967 6874 7320 6c69 7374 2069 7320  weights list is 
+00011570: 5b57 692c 2057 682c 2062 692c 2062 685d  [Wi, Wh, bi, bh]
+00011580: 2077 6974 6820 6861 735f 6269 6173 203d   with has_bias =
+00011590: 3d20 5472 7565 2c0a 2020 2020 2320 616e  = True,.    # an
+000115a0: 6420 6973 205b 5769 2c20 5768 5d20 7769  d is [Wi, Wh] wi
+000115b0: 7468 2062 6961 7320 3d3d 2046 616c 7365  th bias == False
+000115c0: 2e0a 2020 2020 2320 4966 2062 6964 6972  ..    # If bidir
+000115d0: 6563 7469 6f6e 616c 203d 3d20 5472 7565  ectional == True
+000115e0: 2c20 7468 6520 6c69 7374 2069 7320 646f  , the list is do
+000115f0: 7562 6c65 2075 702c 2063 6f72 7265 7370  uble up, corresp
+00011600: 6f6e 6469 6e67 2074 6f20 666f 7277 6172  onding to forwar
+00011610: 6420 616e 6420 6261 636b 7761 7264 2064  d and backward d
+00011620: 6972 6563 7469 6f6e 2e0a 2020 2020 6578  irection..    ex
+00011630: 7065 6374 6564 5f6e 756d 5f77 6569 6768  pected_num_weigh
+00011640: 7473 203d 2032 202a 206e 756d 5f6c 6179  ts = 2 * num_lay
+00011650: 6572 7320 2a20 2869 6e74 2868 6173 5f62  ers * (int(has_b
+00011660: 6961 7329 202b 2031 2920 2a20 2869 6e74  ias) + 1) * (int
+00011670: 2862 6964 6972 6563 7469 6f6e 616c 2920  (bidirectional) 
+00011680: 2b20 3129 0a20 2020 2069 6620 6c65 6e28  + 1).    if len(
+00011690: 7765 6967 6874 735f 6c69 7374 2920 213d  weights_list) !=
+000116a0: 2065 7870 6563 7465 645f 6e75 6d5f 7765   expected_num_we
+000116b0: 6967 6874 733a 0a20 2020 2020 2020 2072  ights:.        r
+000116c0: 6169 7365 2056 616c 7565 4572 726f 7228  aise ValueError(
+000116d0: 0a20 2020 2020 2020 2020 2020 2022 496e  .            "In
+000116e0: 636f 7272 6563 7420 7765 6967 6874 7320  correct weights 
+000116f0: 7368 6170 6520 666f 7220 6772 7520 6c61  shape for gru la
+00011700: 7965 723a 2045 7870 6563 7465 643a 207b  yer: Expected: {
+00011710: 7d2e 2052 6563 6965 7665 6420 7b7d 222e  }. Recieved {}".
+00011720: 666f 726d 6174 280a 2020 2020 2020 2020  format(.        
+00011730: 2020 2020 2020 2020 6578 7065 6374 6564          expected
+00011740: 5f6e 756d 5f77 6569 6768 7473 2c20 6c65  _num_weights, le
+00011750: 6e28 7765 6967 6874 735f 6c69 7374 290a  n(weights_list).
+00011760: 2020 2020 2020 2020 2020 2020 290a 2020              ).  
+00011770: 2020 2020 2020 290a 0a20 2020 2023 2054        )..    # T
+00011780: 7261 6e73 706f 7365 2074 6865 2069 6e70  ranspose the inp
+00011790: 7574 2064 6174 6120 746f 2028 7365 715f  ut data to (seq_
+000117a0: 6c65 6e2c 2062 6174 6368 5f73 697a 652c  len, batch_size,
+000117b0: 2069 6e70 7574 5f64 696d 2920 6966 2062   input_dim) if b
+000117c0: 6174 6368 5f66 6972 7374 203d 3d20 5472  atch_first == Tr
+000117d0: 7565 0a20 2020 2069 6620 6261 7463 685f  ue.    if batch_
+000117e0: 6669 7273 743a 0a20 2020 2020 2020 205f  first:.        _
+000117f0: 696e 7075 7420 3d20 6d62 2e74 7261 6e73  input = mb.trans
+00011800: 706f 7365 2878 3d5f 696e 7075 742c 2070  pose(x=_input, p
+00011810: 6572 6d3d 5b31 2c20 302c 2032 5d29 0a0a  erm=[1, 0, 2])..
+00011820: 2020 2020 2320 6974 6572 6174 6520 7468      # iterate th
+00011830: 726f 7567 6820 616c 6c20 7468 6520 6c61  rough all the la
+00011840: 7965 7273 0a20 2020 2078 203d 205f 696e  yers.    x = _in
+00011850: 7075 740a 2020 2020 7374 6174 655f 6f75  put.    state_ou
+00011860: 745f 6c69 7374 203d 205b 5d0a 0a20 2020  t_list = []..   
+00011870: 2064 6566 205f 6765 745f 7765 6967 6874   def _get_weight
+00011880: 735f 616e 645f 6269 6173 2877 6569 6768  s_and_bias(weigh
+00011890: 7473 5f6c 6973 742c 2069 6e64 6578 2c20  ts_list, index, 
+000118a0: 6e75 6d5f 6c61 7965 7273 2c20 6861 735f  num_layers, has_
+000118b0: 6269 6173 2c20 6269 6469 7265 6374 696f  bias, bidirectio
+000118c0: 6e61 6c2c 206d 6f64 6529 3a0a 2020 2020  nal, mode):.    
+000118d0: 2020 2020 6e75 6d5f 7765 6967 6874 735f      num_weights_
+000118e0: 7065 725f 6c61 7965 7220 3d20 6c65 6e28  per_layer = len(
+000118f0: 7765 6967 6874 735f 6c69 7374 2920 2f2f  weights_list) //
+00011900: 206e 756d 5f6c 6179 6572 730a 2020 2020   num_layers.    
+00011910: 2020 2020 7765 6967 6874 7320 3d20 7765      weights = we
+00011920: 6967 6874 735f 6c69 7374 5b0a 2020 2020  ights_list[.    
+00011930: 2020 2020 2020 2020 6e75 6d5f 7765 6967          num_weig
+00011940: 6874 735f 7065 725f 6c61 7965 7220 2a20  hts_per_layer * 
+00011950: 696e 6465 7820 3a20 6e75 6d5f 7765 6967  index : num_weig
+00011960: 6874 735f 7065 725f 6c61 7965 7220 2a20  hts_per_layer * 
+00011970: 2869 6e64 6578 202b 2031 290a 2020 2020  (index + 1).    
+00011980: 2020 2020 5d0a 0a20 2020 2020 2020 2069      ]..        i
+00011990: 6620 6269 6469 7265 6374 696f 6e61 6c3a  f bidirectional:
+000119a0: 0a20 2020 2020 2020 2020 2020 2077 6569  .            wei
+000119b0: 6768 7473 5f66 2c20 7765 6967 6874 735f  ghts_f, weights_
+000119c0: 7220 3d20 280a 2020 2020 2020 2020 2020  r = (.          
+000119d0: 2020 2020 2020 7765 6967 6874 735b 3a20        weights[: 
+000119e0: 6e75 6d5f 7765 6967 6874 735f 7065 725f  num_weights_per_
+000119f0: 6c61 7965 7220 2f2f 2032 5d2c 0a20 2020  layer // 2],.   
+00011a00: 2020 2020 2020 2020 2020 2020 2077 6569               wei
+00011a10: 6768 7473 5b6e 756d 5f77 6569 6768 7473  ghts[num_weights
+00011a20: 5f70 6572 5f6c 6179 6572 202f 2f20 3220  _per_layer // 2 
+00011a30: 3a5d 2c0a 2020 2020 2020 2020 2020 2020  :],.            
+00011a40: 290a 2020 2020 2020 2020 2020 2020 6173  ).            as
+00011a50: 7365 7274 206c 656e 2877 6569 6768 7473  sert len(weights
+00011a60: 5f66 2920 3d3d 206c 656e 2877 6569 6768  _f) == len(weigh
+00011a70: 7473 5f72 290a 2020 2020 2020 2020 656c  ts_r).        el
+00011a80: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
+00011a90: 7765 6967 6874 735f 662c 2077 6569 6768  weights_f, weigh
+00011aa0: 7473 5f72 203d 2077 6569 6768 7473 2c20  ts_r = weights, 
+00011ab0: 5b5d 0a0a 2020 2020 2020 2020 6966 206d  []..        if m
+00011ac0: 6f64 6520 3d3d 2022 666f 7277 6172 6422  ode == "forward"
+00011ad0: 3a0a 2020 2020 2020 2020 2020 2020 7765  :.            we
+00011ae0: 6967 6874 7320 3d20 7765 6967 6874 735f  ights = weights_
+00011af0: 660a 2020 2020 2020 2020 656c 6966 206d  f.        elif m
+00011b00: 6f64 6520 3d3d 2022 7265 7665 7273 6522  ode == "reverse"
+00011b10: 3a0a 2020 2020 2020 2020 2020 2020 7765  :.            we
+00011b20: 6967 6874 7320 3d20 7765 6967 6874 735f  ights = weights_
+00011b30: 720a 0a20 2020 2020 2020 2077 692c 2077  r..        wi, w
+00011b40: 6820 3d20 7765 6967 6874 735b 305d 2e76  h = weights[0].v
+00011b50: 616c 2c20 7765 6967 6874 735b 315d 2e76  al, weights[1].v
+00011b60: 616c 0a0a 2020 2020 2020 2020 6966 2068  al..        if h
+00011b70: 6173 5f62 6961 733a 0a20 2020 2020 2020  as_bias:.       
+00011b80: 2020 2020 2062 692c 2062 6820 3d20 7765       bi, bh = we
+00011b90: 6967 6874 735b 325d 2e76 616c 2c20 7765  ights[2].val, we
+00011ba0: 6967 6874 735b 335d 2e76 616c 0a20 2020  ights[3].val.   
+00011bb0: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
+00011bc0: 2020 2020 2020 2068 6964 6465 6e5f 6469         hidden_di
+00011bd0: 6d20 3d20 7768 2e73 6861 7065 5b31 5d0a  m = wh.shape[1].
+00011be0: 2020 2020 2020 2020 2020 2020 6269 2c20              bi, 
+00011bf0: 6268 203d 205f 6e70 2e7a 6572 6f73 2833  bh = _np.zeros(3
+00011c00: 202a 2068 6964 6465 6e5f 6469 6d29 2c20   * hidden_dim), 
+00011c10: 5f6e 702e 7a65 726f 7328 3320 2a20 6869  _np.zeros(3 * hi
+00011c20: 6464 656e 5f64 696d 290a 0a20 2020 2020  dden_dim)..     
+00011c30: 2020 2072 6574 7572 6e20 7769 2c20 7768     return wi, wh
+00011c40: 2c20 6269 2c20 6268 0a0a 2020 2020 6465  , bi, bh..    de
+00011c50: 6620 5f67 6574 5f69 6e69 7469 616c 5f73  f _get_initial_s
+00011c60: 7461 7465 2868 302c 2069 2c20 6269 6469  tate(h0, i, bidi
+00011c70: 7265 6374 696f 6e61 6c2c 206d 6f64 6529  rectional, mode)
+00011c80: 3a0a 0a20 2020 2020 2020 2069 6620 6d6f  :..        if mo
+00011c90: 6465 203d 3d20 2266 6f72 7761 7264 223a  de == "forward":
+00011ca0: 0a20 2020 2020 2020 2020 2020 2072 6574  .            ret
+00011cb0: 7572 6e20 6d62 2e73 6c69 6365 5f62 795f  urn mb.slice_by_
+00011cc0: 696e 6465 7828 0a20 2020 2020 2020 2020  index(.         
+00011cd0: 2020 2020 2020 2078 3d68 302c 0a20 2020         x=h0,.   
+00011ce0: 2020 2020 2020 2020 2020 2020 2062 6567               beg
+00011cf0: 696e 3d5b 2831 202b 2069 6e74 2862 6964  in=[(1 + int(bid
+00011d00: 6972 6563 7469 6f6e 616c 2929 202a 2069  irectional)) * i
+00011d10: 2c20 302c 2030 5d2c 0a20 2020 2020 2020  , 0, 0],.       
+00011d20: 2020 2020 2020 2020 2065 6e64 3d5b 2831           end=[(1
+00011d30: 202b 2069 6e74 2862 6964 6972 6563 7469   + int(bidirecti
+00011d40: 6f6e 616c 2929 202a 2069 202b 2031 2c20  onal)) * i + 1, 
+00011d50: 302c 2030 5d2c 0a20 2020 2020 2020 2020  0, 0],.         
+00011d60: 2020 2020 2020 2062 6567 696e 5f6d 6173         begin_mas
+00011d70: 6b3d 5b46 616c 7365 2c20 5472 7565 2c20  k=[False, True, 
+00011d80: 5472 7565 5d2c 0a20 2020 2020 2020 2020  True],.         
+00011d90: 2020 2020 2020 2065 6e64 5f6d 6173 6b3d         end_mask=
+00011da0: 5b46 616c 7365 2c20 5472 7565 2c20 5472  [False, True, Tr
+00011db0: 7565 5d2c 0a20 2020 2020 2020 2020 2020  ue],.           
+00011dc0: 2029 0a20 2020 2020 2020 2069 6620 6d6f   ).        if mo
+00011dd0: 6465 203d 3d20 2272 6576 6572 7365 223a  de == "reverse":
+00011de0: 0a20 2020 2020 2020 2020 2020 2061 7373  .            ass
+00011df0: 6572 7420 6269 6469 7265 6374 696f 6e61  ert bidirectiona
+00011e00: 6c0a 2020 2020 2020 2020 2020 2020 7265  l.            re
+00011e10: 7475 726e 206d 622e 736c 6963 655f 6279  turn mb.slice_by
+00011e20: 5f69 6e64 6578 280a 2020 2020 2020 2020  _index(.        
+00011e30: 2020 2020 2020 2020 783d 6830 2c0a 2020          x=h0,.  
+00011e40: 2020 2020 2020 2020 2020 2020 2020 6265                be
+00011e50: 6769 6e3d 5b32 202a 2069 202b 2031 2c20  gin=[2 * i + 1, 
+00011e60: 302c 2030 5d2c 0a20 2020 2020 2020 2020  0, 0],.         
+00011e70: 2020 2020 2020 2065 6e64 3d5b 3220 2a20         end=[2 * 
+00011e80: 2869 202b 2031 292c 2030 2c20 305d 2c0a  (i + 1), 0, 0],.
+00011e90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011ea0: 6265 6769 6e5f 6d61 736b 3d5b 4661 6c73  begin_mask=[Fals
+00011eb0: 652c 2054 7275 652c 2054 7275 655d 2c0a  e, True, True],.
+00011ec0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011ed0: 656e 645f 6d61 736b 3d5b 4661 6c73 652c  end_mask=[False,
+00011ee0: 2054 7275 652c 2054 7275 655d 2c0a 2020   True, True],.  
+00011ef0: 2020 2020 2020 2020 2020 290a 0a20 2020            )..   
+00011f00: 2073 6571 5f6f 7574 7075 745f 6e61 6d65   seq_output_name
+00011f10: 203d 206e 6f64 652e 6f75 7470 7574 735b   = node.outputs[
+00011f20: 305d 2020 2320 6f75 7470 7574 2073 6571  0]  # output seq
+00011f30: 7565 6e63 6520 6e61 6d65 0a20 2020 2073  uence name.    s
+00011f40: 7461 7465 5f6f 7574 7075 745f 6e61 6d65  tate_output_name
+00011f50: 203d 206e 6f64 652e 6f75 7470 7574 735b   = node.outputs[
+00011f60: 315d 2020 2320 6f75 7470 7574 2073 7461  1]  # output sta
+00011f70: 7465 206e 616d 650a 0a20 2020 2066 6f72  te name..    for
+00011f80: 2069 2069 6e20 7261 6e67 6528 6e75 6d5f   i in range(num_
+00011f90: 6c61 7965 7273 293a 0a20 2020 2020 2020  layers):.       
+00011fa0: 2023 2067 6574 206c 6179 6572 206e 616d   # get layer nam
+00011fb0: 6573 0a20 2020 2020 2020 2078 5f6e 616d  es.        x_nam
+00011fc0: 6520 3d20 7365 715f 6f75 7470 7574 5f6e  e = seq_output_n
+00011fd0: 616d 6520 2b20 225f 6c61 7965 725f 2220  ame + "_layer_" 
+00011fe0: 2b20 7374 7228 6929 2069 6620 6920 3c20  + str(i) if i < 
+00011ff0: 6e75 6d5f 6c61 7965 7273 202d 2031 2065  num_layers - 1 e
+00012000: 6c73 6520 7365 715f 6f75 7470 7574 5f6e  lse seq_output_n
+00012010: 616d 650a 2020 2020 2020 2020 685f 6e61  ame.        h_na
+00012020: 6d65 203d 2073 7461 7465 5f6f 7574 7075  me = state_outpu
+00012030: 745f 6e61 6d65 202b 2027 5f6c 6179 6572  t_name + '_layer
+00012040: 5f27 202b 2073 7472 2869 2920 6966 206e  _' + str(i) if n
+00012050: 756d 5f6c 6179 6572 7320 3e20 3020 656c  um_layers > 0 el
+00012060: 7365 2073 7461 7465 5f6f 7574 7075 745f  se state_output_
+00012070: 6e61 6d65 0a0a 2020 2020 2020 2020 6966  name..        if
+00012080: 2062 6174 6368 5f66 6972 7374 3a0a 2020   batch_first:.  
+00012090: 2020 2020 2020 2020 2020 785f 6e61 6d65            x_name
+000120a0: 202b 3d20 225f 746d 7022 0a0a 2020 2020   += "_tmp"..    
+000120b0: 2020 2020 6966 2062 6964 6972 6563 7469      if bidirecti
+000120c0: 6f6e 616c 3a0a 2020 2020 2020 2020 2020  onal:.          
+000120d0: 2020 785f 665f 6e61 6d65 203d 2078 5f6e    x_f_name = x_n
+000120e0: 616d 6520 2b20 275f 666f 7277 6172 6427  ame + '_forward'
+000120f0: 0a20 2020 2020 2020 2020 2020 2068 5f66  .            h_f
+00012100: 5f6e 616d 6520 3d20 685f 6e61 6d65 202b  _name = h_name +
+00012110: 2027 5f66 6f72 7761 7264 270a 2020 2020   '_forward'.    
+00012120: 2020 2020 2020 2020 785f 725f 6e61 6d65          x_r_name
+00012130: 203d 2078 5f6e 616d 6520 2b20 275f 6261   = x_name + '_ba
+00012140: 636b 7761 7264 270a 2020 2020 2020 2020  ckward'.        
+00012150: 2020 2020 685f 725f 6e61 6d65 203d 2068      h_r_name = h
+00012160: 5f6e 616d 6520 2b20 275f 6261 636b 7761  _name + '_backwa
+00012170: 7264 270a 2020 2020 2020 2020 656c 7365  rd'.        else
+00012180: 3a0a 2020 2020 2020 2020 2020 2020 785f  :.            x_
+00012190: 665f 6e61 6d65 203d 2078 5f6e 616d 650a  f_name = x_name.
+000121a0: 2020 2020 2020 2020 2020 2020 685f 665f              h_f_
+000121b0: 6e61 6d65 203d 2068 5f6e 616d 650a 0a20  name = h_name.. 
+000121c0: 2020 2020 2020 2023 2066 6f72 7761 7264         # forward
+000121d0: 2064 6972 6563 7469 6f6e 0a20 2020 2020   direction.     
+000121e0: 2020 2078 5f66 203d 2078 0a20 2020 2020     x_f = x.     
+000121f0: 2020 2077 695f 662c 2077 685f 662c 2062     wi_f, wh_f, b
+00012200: 695f 662c 2062 685f 6620 3d20 5f67 6574  i_f, bh_f = _get
+00012210: 5f77 6569 6768 7473 5f61 6e64 5f62 6961  _weights_and_bia
+00012220: 7328 0a20 2020 2020 2020 2020 2020 2077  s(.            w
+00012230: 6569 6768 7473 5f6c 6973 742c 2069 2c20  eights_list, i, 
+00012240: 6e75 6d5f 6c61 7965 7273 2c20 6861 735f  num_layers, has_
+00012250: 6269 6173 2c20 6269 6469 7265 6374 696f  bias, bidirectio
+00012260: 6e61 6c2c 2022 666f 7277 6172 6422 0a20  nal, "forward". 
+00012270: 2020 2020 2020 2029 0a20 2020 2020 2020         ).       
+00012280: 2069 6e69 7469 616c 5f68 5f66 203d 205f   initial_h_f = _
+00012290: 6765 745f 696e 6974 6961 6c5f 7374 6174  get_initial_stat
+000122a0: 6528 6830 2c20 692c 2062 6964 6972 6563  e(h0, i, bidirec
+000122b0: 7469 6f6e 616c 2c20 2266 6f72 7761 7264  tional, "forward
+000122c0: 2229 0a20 2020 2020 2020 2078 5f66 2c20  ").        x_f, 
+000122d0: 685f 6620 3d20 5f61 6464 5f67 7275 5f6c  h_f = _add_gru_l
+000122e0: 6179 6572 2878 5f66 2c20 696e 6974 6961  ayer(x_f, initia
+000122f0: 6c5f 685f 662c 2077 695f 662c 2077 685f  l_h_f, wi_f, wh_
+00012300: 662c 2062 695f 662c 2062 685f 662c 2078  f, bi_f, bh_f, x
+00012310: 5f66 5f6e 616d 652c 2068 5f66 5f6e 616d  _f_name, h_f_nam
+00012320: 6529 0a0a 2020 2020 2020 2020 2320 7265  e)..        # re
+00012330: 7665 7273 6520 6469 7265 6374 696f 6e0a  verse direction.
+00012340: 2020 2020 2020 2020 6966 2062 6964 6972          if bidir
+00012350: 6563 7469 6f6e 616c 3a0a 2020 2020 2020  ectional:.      
+00012360: 2020 2020 2020 785f 7220 3d20 6d62 2e72        x_r = mb.r
+00012370: 6576 6572 7365 2878 3d78 2c20 6178 6573  everse(x=x, axes
+00012380: 3d5b 305d 290a 2020 2020 2020 2020 2020  =[0]).          
+00012390: 2020 7769 5f72 2c20 7768 5f72 2c20 6269    wi_r, wh_r, bi
+000123a0: 5f72 2c20 6268 5f72 203d 205f 6765 745f  _r, bh_r = _get_
+000123b0: 7765 6967 6874 735f 616e 645f 6269 6173  weights_and_bias
+000123c0: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
+000123d0: 2020 7765 6967 6874 735f 6c69 7374 2c20    weights_list, 
+000123e0: 692c 206e 756d 5f6c 6179 6572 732c 2068  i, num_layers, h
+000123f0: 6173 5f62 6961 732c 2062 6964 6972 6563  as_bias, bidirec
+00012400: 7469 6f6e 616c 2c20 2272 6576 6572 7365  tional, "reverse
+00012410: 220a 2020 2020 2020 2020 2020 2020 290a  ".            ).
+00012420: 2020 2020 2020 2020 2020 2020 696e 6974              init
+00012430: 6961 6c5f 685f 7220 3d20 5f67 6574 5f69  ial_h_r = _get_i
+00012440: 6e69 7469 616c 5f73 7461 7465 2868 302c  nitial_state(h0,
+00012450: 2069 2c20 6269 6469 7265 6374 696f 6e61   i, bidirectiona
+00012460: 6c2c 2022 7265 7665 7273 6522 290a 2020  l, "reverse").  
+00012470: 2020 2020 2020 2020 2020 785f 722c 2068            x_r, h
+00012480: 5f72 203d 205f 6164 645f 6772 755f 6c61  _r = _add_gru_la
+00012490: 7965 7228 0a20 2020 2020 2020 2020 2020  yer(.           
+000124a0: 2020 2020 2078 5f72 2c0a 2020 2020 2020       x_r,.      
+000124b0: 2020 2020 2020 2020 2020 696e 6974 6961            initia
+000124c0: 6c5f 685f 722c 0a20 2020 2020 2020 2020  l_h_r,.         
+000124d0: 2020 2020 2020 2077 695f 722c 0a20 2020         wi_r,.   
+000124e0: 2020 2020 2020 2020 2020 2020 2077 685f               wh_
+000124f0: 722c 0a20 2020 2020 2020 2020 2020 2020  r,.             
+00012500: 2020 2062 695f 722c 0a20 2020 2020 2020     bi_r,.       
+00012510: 2020 2020 2020 2020 2062 685f 722c 0a20           bh_r,. 
+00012520: 2020 2020 2020 2020 2020 2020 2020 2078                 x
+00012530: 5f72 5f6e 616d 6520 2b20 225f 7265 7665  _r_name + "_reve
+00012540: 7273 6522 2c0a 2020 2020 2020 2020 2020  rse",.          
+00012550: 2020 2020 2020 685f 725f 6e61 6d65 2c0a        h_r_name,.
+00012560: 2020 2020 2020 2020 2020 2020 290a 2020              ).  
+00012570: 2020 2020 2020 2020 2020 785f 7220 3d20            x_r = 
+00012580: 6d62 2e72 6576 6572 7365 2878 3d78 5f72  mb.reverse(x=x_r
+00012590: 2c20 6178 6573 3d5b 305d 2c20 6e61 6d65  , axes=[0], name
+000125a0: 3d78 5f72 5f6e 616d 6529 0a0a 2020 2020  =x_r_name)..    
+000125b0: 2020 2020 2020 2020 2320 636f 6e63 6174          # concat
+000125c0: 6520 6f75 7470 7574 2066 726f 6d20 666f  e output from fo
+000125d0: 7277 6172 6420 616e 6420 7265 7665 7273  rward and revers
+000125e0: 6520 6469 7265 6374 696f 6e0a 2020 2020  e direction.    
+000125f0: 2020 2020 2020 2020 7820 3d20 6d62 2e63          x = mb.c
+00012600: 6f6e 6361 7428 7661 6c75 6573 3d5b 785f  oncat(values=[x_
+00012610: 662c 2078 5f72 5d2c 2061 7869 733d 322c  f, x_r], axis=2,
+00012620: 206e 616d 653d 785f 6e61 6d65 290a 2020   name=x_name).  
+00012630: 2020 2020 2020 2020 2020 6820 3d20 6d62            h = mb
+00012640: 2e63 6f6e 6361 7428 7661 6c75 6573 3d5b  .concat(values=[
+00012650: 685f 662c 2068 5f72 5d2c 2061 7869 733d  h_f, h_r], axis=
+00012660: 302c 206e 616d 653d 685f 6e61 6d65 290a  0, name=h_name).
+00012670: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
+00012680: 2020 2020 2020 2020 2020 7820 3d20 785f            x = x_
+00012690: 660a 2020 2020 2020 2020 2020 2020 6820  f.            h 
+000126a0: 3d20 685f 660a 0a20 2020 2020 2020 2073  = h_f..        s
+000126b0: 7461 7465 5f6f 7574 5f6c 6973 742e 6170  tate_out_list.ap
+000126c0: 7065 6e64 2868 290a 0a20 2020 2023 2072  pend(h)..    # r
+000126d0: 6e6e 206f 7574 7075 740a 2020 2020 6966  nn output.    if
+000126e0: 2062 6174 6368 5f66 6972 7374 3a0a 2020   batch_first:.  
+000126f0: 2020 2020 2020 7820 3d20 6d62 2e74 7261        x = mb.tra
+00012700: 6e73 706f 7365 2878 3d78 2c20 7065 726d  nspose(x=x, perm
+00012710: 3d5b 312c 2030 2c20 325d 2c20 6e61 6d65  =[1, 0, 2], name
+00012720: 3d73 6571 5f6f 7574 7075 745f 6e61 6d65  =seq_output_name
+00012730: 290a 2020 2020 636f 6e74 6578 742e 6164  ).    context.ad
+00012740: 6428 782c 2073 6571 5f6f 7574 7075 745f  d(x, seq_output_
+00012750: 6e61 6d65 290a 0a20 2020 2023 2073 7461  name)..    # sta
+00012760: 7465 206f 7574 7075 740a 2020 2020 6966  te output.    if
+00012770: 206c 656e 2873 7461 7465 5f6f 7574 5f6c   len(state_out_l
+00012780: 6973 7429 203e 2031 3a0a 2020 2020 2020  ist) > 1:.      
+00012790: 2020 6820 3d20 6d62 2e63 6f6e 6361 7428    h = mb.concat(
+000127a0: 7661 6c75 6573 3d73 7461 7465 5f6f 7574  values=state_out
+000127b0: 5f6c 6973 742c 2061 7869 733d 302c 206e  _list, axis=0, n
+000127c0: 616d 653d 7374 6174 655f 6f75 7470 7574  ame=state_output
+000127d0: 5f6e 616d 6529 0a20 2020 2063 6f6e 7465  _name).    conte
+000127e0: 7874 2e61 6464 2868 2c20 7374 6174 655f  xt.add(h, state_
+000127f0: 6f75 7470 7574 5f6e 616d 6529 0a0a 0a64  output_name)...d
+00012800: 6566 205f 6164 645f 7369 6d70 6c65 5f72  ef _add_simple_r
+00012810: 6e6e 2863 6f6e 7465 7874 2c20 6e6f 6465  nn(context, node
+00012820: 2c20 6163 7469 7661 7469 6f6e 293a 0a20  , activation):. 
+00012830: 2020 2069 6e70 7574 7320 3d20 5f67 6574     inputs = _get
+00012840: 5f69 6e70 7574 7328 636f 6e74 6578 742c  _inputs(context,
+00012850: 206e 6f64 652c 2065 7870 6563 7465 643d   node, expected=
+00012860: 3929 0a0a 2020 2020 2727 270a 2020 2020  9)..    '''.    
+00012870: 4261 7463 6820 7369 7a65 3a20 420a 2020  Batch size: B.  
+00012880: 2020 5365 7175 656e 6365 206c 656e 6774    Sequence lengt
+00012890: 683a 2053 0a20 2020 2049 6e70 7574 2064  h: S.    Input d
+000128a0: 696d 656e 7369 6f6e 3a20 430a 2020 2020  imension: C.    
+000128b0: 4869 6464 656e 2064 696d 656e 7369 6f6e  Hidden dimension
+000128c0: 3a20 480a 0a20 2020 2028 3129 205f 696e  : H..    (1) _in
+000128d0: 7075 7420 3a20 2842 2c20 532c 2043 2920  put : (B, S, C) 
+000128e0: 6966 2062 6174 6368 5f66 6972 7374 203d  if batch_first =
+000128f0: 3d20 5472 7565 2c20 656c 7365 2028 532c  = True, else (S,
+00012900: 2042 2c20 4329 0a20 2020 2028 3229 2068   B, C).    (2) h
+00012910: 303a 2028 6e75 6d5f 6c61 7965 7273 2c20  0: (num_layers, 
+00012920: 422c 2048 290a 2020 2020 2727 270a 2020  B, H).    '''.  
+00012930: 2020 5f69 6e70 7574 203d 2069 6e70 7574    _input = input
+00012940: 735b 305d 0a20 2020 2068 3020 3d20 696e  s[0].    h0 = in
+00012950: 7075 7473 5b31 5d0a 2020 2020 7765 6967  puts[1].    weig
+00012960: 6874 735f 6c69 7374 203d 2069 6e70 7574  hts_list = input
+00012970: 735b 325d 0a20 2020 2068 6173 5f62 6961  s[2].    has_bia
+00012980: 7320 3d20 696e 7075 7473 5b33 5d2e 7661  s = inputs[3].va
+00012990: 6c0a 2020 2020 6e75 6d5f 6c61 7965 7273  l.    num_layers
+000129a0: 203d 2069 6e70 7574 735b 345d 2e76 616c   = inputs[4].val
+000129b0: 0a20 2020 2064 726f 706f 7574 203d 2069  .    dropout = i
+000129c0: 6e70 7574 735b 355d 0a20 2020 2062 6964  nputs[5].    bid
+000129d0: 6972 6563 7469 6f6e 616c 203d 2069 6e70  irectional = inp
+000129e0: 7574 735b 375d 2e76 616c 0a20 2020 2062  uts[7].val.    b
+000129f0: 6174 6368 5f66 6972 7374 203d 2069 6e70  atch_first = inp
+00012a00: 7574 735b 385d 2e76 616c 0a0a 2020 2020  uts[8].val..    
+00012a10: 2320 5765 206f 6e6c 7920 7375 7070 6f72  # We only suppor
+00012a20: 7420 756e 692d 6469 7265 6374 696f 6e61  t uni-directiona
+00012a30: 6c20 7369 6d70 6c65 2052 4e4e 206e 6f77  l simple RNN now
+00012a40: 0a20 2020 2069 6620 6269 6469 7265 6374  .    if bidirect
+00012a50: 696f 6e61 6c3a 0a20 2020 2020 2020 2072  ional:.        r
+00012a60: 6169 7365 204e 6f74 496d 706c 656d 656e  aise NotImplemen
+00012a70: 7465 6445 7272 6f72 2822 4269 6469 7265  tedError("Bidire
+00012a80: 6374 696f 6e61 6c20 7369 6d70 6c65 2052  ctional simple R
+00012a90: 4e4e 206e 6f74 2073 7570 706f 7274 6564  NN not supported
+00012aa0: 2e22 290a 0a20 2020 2065 7870 6563 7465  .")..    expecte
+00012ab0: 645f 6e75 6d5f 7765 6967 6874 7320 3d20  d_num_weights = 
+00012ac0: 3220 2a20 6e75 6d5f 6c61 7965 7273 202a  2 * num_layers *
+00012ad0: 2028 696e 7428 6861 735f 6269 6173 2920   (int(has_bias) 
+00012ae0: 2b20 3129 0a20 2020 2069 6620 6c65 6e28  + 1).    if len(
+00012af0: 7765 6967 6874 735f 6c69 7374 2920 213d  weights_list) !=
+00012b00: 2065 7870 6563 7465 645f 6e75 6d5f 7765   expected_num_we
+00012b10: 6967 6874 733a 0a20 2020 2020 2020 2072  ights:.        r
+00012b20: 6169 7365 2056 616c 7565 4572 726f 7228  aise ValueError(
+00012b30: 0a20 2020 2020 2020 2020 2020 2022 496e  .            "In
+00012b40: 636f 7272 6563 7420 7765 6967 6874 7320  correct weights 
+00012b50: 7368 6170 6520 666f 7220 6c73 746d 206c  shape for lstm l
+00012b60: 6179 6572 3a20 4578 7065 6374 6564 3a20  ayer: Expected: 
+00012b70: 7b7d 2e20 5265 6369 6576 6564 207b 7d22  {}. Recieved {}"
+00012b80: 2e66 6f72 6d61 7428 0a20 2020 2020 2020  .format(.       
+00012b90: 2020 2020 2020 2020 2065 7870 6563 7465           expecte
+00012ba0: 645f 6e75 6d5f 7765 6967 6874 732c 206c  d_num_weights, l
+00012bb0: 656e 2877 6569 6768 7473 5f6c 6973 7429  en(weights_list)
+00012bc0: 0a20 2020 2020 2020 2020 2020 2029 0a20  .            ). 
+00012bd0: 2020 2020 2020 2029 0a0a 2020 2020 2320         )..    # 
+00012be0: 5472 616e 7370 6f73 6520 7468 6520 696e  Transpose the in
+00012bf0: 7075 7420 6461 7461 2074 6f20 2853 2c20  put data to (S, 
+00012c00: 422c 2043 2920 6966 2062 6174 6368 5f66  B, C) if batch_f
+00012c10: 6972 7374 203d 3d20 5472 7565 0a20 2020  irst == True.   
+00012c20: 2069 6620 6261 7463 685f 6669 7273 743a   if batch_first:
+00012c30: 0a20 2020 2020 2020 205f 696e 7075 7420  .        _input 
+00012c40: 3d20 6d62 2e74 7261 6e73 706f 7365 2878  = mb.transpose(x
+00012c50: 3d5f 696e 7075 742c 2070 6572 6d3d 5b31  =_input, perm=[1
+00012c60: 2c20 302c 2032 5d29 0a0a 2020 2020 7374  , 0, 2])..    st
+00012c70: 6174 655f 6f75 745f 6c69 7374 203d 205b  ate_out_list = [
+00012c80: 5d0a 2020 2020 6f75 7420 3d20 5f69 6e70  ].    out = _inp
+00012c90: 7574 0a0a 2020 2020 666f 7220 6920 696e  ut..    for i in
+00012ca0: 2072 616e 6765 286e 756d 5f6c 6179 6572   range(num_layer
+00012cb0: 7329 3a0a 2020 2020 2020 2020 6966 2068  s):.        if h
+00012cc0: 6173 5f62 6961 733a 0a20 2020 2020 2020  as_bias:.       
+00012cd0: 2020 2020 2077 6569 6768 745f 6968 203d       weight_ih =
+00012ce0: 2077 6569 6768 7473 5f6c 6973 745b 3420   weights_list[4 
+00012cf0: 2a20 695d 0a20 2020 2020 2020 2020 2020  * i].           
+00012d00: 2077 6569 6768 745f 6868 203d 2077 6569   weight_hh = wei
+00012d10: 6768 7473 5f6c 6973 745b 3420 2a20 6920  ghts_list[4 * i 
+00012d20: 2b20 315d 0a20 2020 2020 2020 2020 2020  + 1].           
+00012d30: 2062 6961 7320 3d20 6d62 2e61 6464 2878   bias = mb.add(x
+00012d40: 3d77 6569 6768 7473 5f6c 6973 745b 3420  =weights_list[4 
+00012d50: 2a20 6920 2b20 325d 2c20 793d 7765 6967  * i + 2], y=weig
+00012d60: 6874 735f 6c69 7374 5b34 202a 2069 202b  hts_list[4 * i +
+00012d70: 2033 5d29 0a20 2020 2020 2020 2065 6c73   3]).        els
+00012d80: 653a 0a20 2020 2020 2020 2020 2020 2077  e:.            w
+00012d90: 6569 6768 745f 6968 203d 2077 6569 6768  eight_ih = weigh
+00012da0: 7473 5f6c 6973 745b 3220 2a20 695d 0a20  ts_list[2 * i]. 
+00012db0: 2020 2020 2020 2020 2020 2077 6569 6768             weigh
+00012dc0: 745f 6868 203d 2077 6569 6768 7473 5f6c  t_hh = weights_l
+00012dd0: 6973 745b 3220 2a20 6920 2b20 315d 0a20  ist[2 * i + 1]. 
+00012de0: 2020 2020 2020 2020 2020 2062 6961 7320             bias 
+00012df0: 3d20 4e6f 6e65 0a0a 2020 2020 2020 2020  = None..        
+00012e00: 2320 6765 7420 7468 6520 696e 6974 6961  # get the initia
+00012e10: 6c20 7374 6174 650a 2020 2020 2020 2020  l state.        
+00012e20: 696e 6974 6961 6c5f 6820 3d20 6d62 2e73  initial_h = mb.s
+00012e30: 6c69 6365 5f62 795f 696e 6465 7828 0a20  lice_by_index(. 
+00012e40: 2020 2020 2020 2020 2020 2078 3d68 302c             x=h0,
+00012e50: 0a20 2020 2020 2020 2020 2020 2062 6567  .            beg
+00012e60: 696e 3d5b 692c 2030 2c20 305d 2c0a 2020  in=[i, 0, 0],.  
+00012e70: 2020 2020 2020 2020 2020 656e 643d 5b30            end=[0
+00012e80: 2c20 302c 2030 5d2c 0a20 2020 2020 2020  , 0, 0],.       
+00012e90: 2020 2020 2073 7472 6964 653d 5b31 2c20       stride=[1, 
+00012ea0: 312c 2031 5d2c 0a20 2020 2020 2020 2020  1, 1],.         
+00012eb0: 2020 2062 6567 696e 5f6d 6173 6b3d 5b46     begin_mask=[F
+00012ec0: 616c 7365 2c20 5472 7565 2c20 5472 7565  alse, True, True
+00012ed0: 5d2c 0a20 2020 2020 2020 2020 2020 2065  ],.            e
+00012ee0: 6e64 5f6d 6173 6b3d 5b46 616c 7365 2c20  nd_mask=[False, 
+00012ef0: 5472 7565 2c20 5472 7565 5d2c 0a20 2020  True, True],.   
+00012f00: 2020 2020 2020 2020 2073 7175 6565 7a65           squeeze
+00012f10: 5f6d 6173 6b3d 5b54 7275 652c 2046 616c  _mask=[True, Fal
+00012f20: 7365 2c20 4661 6c73 655d 2c0a 2020 2020  se, False],.    
+00012f30: 2020 2020 290a 0a20 2020 2020 2020 2023      )..        #
+00012f40: 2067 6574 2074 6865 2052 4e4e 206f 7574   get the RNN out
+00012f50: 7075 7420 666f 7220 6561 6368 2075 6e69  put for each uni
+00012f60: 740a 2020 2020 2020 2020 6f75 742c 2073  t.        out, s
+00012f70: 7461 7465 203d 206d 622e 726e 6e28 0a20  tate = mb.rnn(. 
+00012f80: 2020 2020 2020 2020 2020 2078 3d6f 7574             x=out
+00012f90: 2c0a 2020 2020 2020 2020 2020 2020 696e  ,.            in
+00012fa0: 6974 6961 6c5f 683d 696e 6974 6961 6c5f  itial_h=initial_
+00012fb0: 682c 0a20 2020 2020 2020 2020 2020 2077  h,.            w
+00012fc0: 6569 6768 745f 6968 3d77 6569 6768 745f  eight_ih=weight_
+00012fd0: 6968 2c0a 2020 2020 2020 2020 2020 2020  ih,.            
+00012fe0: 7765 6967 6874 5f68 683d 7765 6967 6874  weight_hh=weight
+00012ff0: 5f68 682c 0a20 2020 2020 2020 2020 2020  _hh,.           
+00013000: 2062 6961 733d 6269 6173 2c0a 2020 2020   bias=bias,.    
+00013010: 2020 2020 2020 2020 6f75 7470 7574 5f73          output_s
+00013020: 6571 7565 6e63 653d 5472 7565 2c0a 2020  equence=True,.  
+00013030: 2020 2020 2020 2020 2020 6163 7469 7661            activa
+00013040: 7469 6f6e 3d61 6374 6976 6174 696f 6e2c  tion=activation,
+00013050: 0a20 2020 2020 2020 2029 0a0a 2020 2020  .        )..    
+00013060: 2020 2020 2320 6170 7065 6e64 2073 7461      # append sta
+00013070: 7465 2074 6f20 6c69 7374 7320 7768 6963  te to lists whic
+00013080: 6820 7769 6c6c 2073 7461 636b 206c 6174  h will stack lat
+00013090: 6572 0a20 2020 2020 2020 2073 7461 7465  er.        state
+000130a0: 5f6f 7574 5f6c 6973 742e 6170 7065 6e64  _out_list.append
+000130b0: 2873 7461 7465 290a 0a20 2020 2023 2072  (state)..    # r
+000130c0: 6e6e 206f 7574 7075 740a 2020 2020 6f75  nn output.    ou
+000130d0: 7470 7574 5f6e 616d 6520 3d20 6e6f 6465  tput_name = node
+000130e0: 2e6f 7574 7075 7473 5b30 5d0a 2020 2020  .outputs[0].    
+000130f0: 6966 2062 6174 6368 5f66 6972 7374 3a0a  if batch_first:.
+00013100: 2020 2020 2020 2020 6f75 7420 3d20 6d62          out = mb
+00013110: 2e74 7261 6e73 706f 7365 2878 3d6f 7574  .transpose(x=out
+00013120: 2c20 7065 726d 3d5b 312c 2030 2c20 325d  , perm=[1, 0, 2]
+00013130: 2c20 6e61 6d65 3d6f 7574 7075 745f 6e61  , name=output_na
+00013140: 6d65 290a 2020 2020 656c 7365 3a0a 2020  me).    else:.  
+00013150: 2020 2020 2020 6f75 7420 3d20 6d62 2e69        out = mb.i
+00013160: 6465 6e74 6974 7928 783d 6f75 742c 206e  dentity(x=out, n
+00013170: 616d 653d 6f75 7470 7574 5f6e 616d 6529  ame=output_name)
+00013180: 0a20 2020 2063 6f6e 7465 7874 2e61 6464  .    context.add
+00013190: 286f 7574 2c20 6f75 7470 7574 5f6e 616d  (out, output_nam
+000131a0: 6529 0a0a 2020 2020 2320 7374 6163 6b20  e)..    # stack 
+000131b0: 7468 6520 7374 6174 6573 2069 6e74 6f20  the states into 
+000131c0: 6120 7369 6e67 6c65 2074 656e 736f 720a  a single tensor.
+000131d0: 2020 2020 7374 6174 655f 6f75 7470 7574      state_output
+000131e0: 5f6e 616d 6520 3d20 6e6f 6465 2e6f 7574  _name = node.out
+000131f0: 7075 7473 5b31 5d0a 2020 2020 6966 206e  puts[1].    if n
+00013200: 756d 5f6c 6179 6572 7320 3d3d 2031 3a0a  um_layers == 1:.
+00013210: 2020 2020 2020 2020 7374 6174 6520 3d20          state = 
+00013220: 6d62 2e65 7870 616e 645f 6469 6d73 2878  mb.expand_dims(x
+00013230: 3d73 7461 7465 5f6f 7574 5f6c 6973 745b  =state_out_list[
+00013240: 305d 2c20 6178 6573 3d5b 305d 2c20 6e61  0], axes=[0], na
+00013250: 6d65 3d73 7461 7465 5f6f 7574 7075 745f  me=state_output_
+00013260: 6e61 6d65 290a 2020 2020 656c 7365 3a0a  name).    else:.
+00013270: 2020 2020 2020 2020 7374 6174 6520 3d20          state = 
+00013280: 6d62 2e73 7461 636b 2876 616c 7565 733d  mb.stack(values=
+00013290: 7374 6174 655f 6f75 745f 6c69 7374 2c20  state_out_list, 
+000132a0: 6178 6973 3d30 2c20 6e61 6d65 3d73 7461  axis=0, name=sta
+000132b0: 7465 5f6f 7574 7075 745f 6e61 6d65 290a  te_output_name).
+000132c0: 2020 2020 636f 6e74 6578 742e 6164 6428      context.add(
+000132d0: 7374 6174 652c 2073 7461 7465 5f6f 7574  state, state_out
+000132e0: 7075 745f 6e61 6d65 290a 0a0a 4072 6567  put_name)...@reg
+000132f0: 6973 7465 725f 746f 7263 685f 6f70 0a64  ister_torch_op.d
+00013300: 6566 2072 6e6e 5f74 616e 6828 636f 6e74  ef rnn_tanh(cont
+00013310: 6578 742c 206e 6f64 6529 3a0a 2020 2020  ext, node):.    
+00013320: 5f61 6464 5f73 696d 706c 655f 726e 6e28  _add_simple_rnn(
+00013330: 636f 6e74 6578 742c 206e 6f64 652c 2022  context, node, "
+00013340: 7461 6e68 2229 0a0a 0a40 7265 6769 7374  tanh")...@regist
+00013350: 6572 5f74 6f72 6368 5f6f 700a 6465 6620  er_torch_op.def 
+00013360: 726e 6e5f 7265 6c75 2863 6f6e 7465 7874  rnn_relu(context
+00013370: 2c20 6e6f 6465 293a 0a20 2020 205f 6164  , node):.    _ad
+00013380: 645f 7369 6d70 6c65 5f72 6e6e 2863 6f6e  d_simple_rnn(con
+00013390: 7465 7874 2c20 6e6f 6465 2c20 2272 656c  text, node, "rel
+000133a0: 7522 290a 0a0a 6465 6620 5f61 6464 5f6d  u")...def _add_m
+000133b0: 696c 5f6c 7374 6d28 696e 7075 742c 2069  il_lstm(input, i
+000133c0: 6e69 7469 616c 5f68 2c20 696e 6974 6961  nitial_h, initia
+000133d0: 6c5f 632c 2077 6569 6768 7473 2c20 6861  l_c, weights, ha
+000133e0: 735f 6269 6173 2c20 6269 6469 7265 6374  s_bias, bidirect
+000133f0: 696f 6e61 6c2c 206e 616d 6529 3a0a 2020  ional, name):.  
+00013400: 2020 2222 220a 2020 2020 4d6f 7374 206f    """.    Most o
+00013410: 6620 7468 6973 2063 6f64 6520 6973 2074  f this code is t
+00013420: 6f20 7472 616e 7366 6f72 6d20 7468 6520  o transform the 
+00013430: 7465 6e73 6f72 7320 696e 746f 0a20 2020  tensors into.   
+00013440: 2061 2073 6861 7065 2061 6363 6570 7461   a shape accepta
+00013450: 626c 6520 6279 2074 6865 2043 6f72 6520  ble by the Core 
+00013460: 4d4c 2069 6d70 6c65 6d65 6e74 6174 696f  ML implementatio
+00013470: 6e20 6f66 204c 5354 4d2e 0a0a 2020 2020  n of LSTM...    
+00013480: 466f 7220 7765 6967 6874 732c 2062 6961  For weights, bia
+00013490: 7365 732c 2020 7065 7220 6469 7265 6374  ses,  per direct
+000134a0: 696f 6e2c 2070 7974 6f72 6368 2075 7365  ion, pytorch use
+000134b0: 7320 7477 6f20 7465 6e73 6f72 733a 0a20  s two tensors:. 
+000134c0: 2020 2028 6969 2c20 6966 2c20 6967 2c20     (ii, if, ig, 
+000134d0: 696f 2920 7374 6163 6b65 6420 6f6e 2074  io) stacked on t
+000134e0: 6f70 206f 6620 6561 6368 206f 7468 6572  op of each other
+000134f0: 2066 6f72 2065 6163 6820 6c61 7965 7220   for each layer 
+00013500: 2874 656e 736f 7220 3129 0a20 2020 2061  (tensor 1).    a
+00013510: 6e64 2028 6869 2c20 6866 2c20 6867 2c20  nd (hi, hf, hg, 
+00013520: 686f 2920 7374 6163 6b65 6420 6f6e 2074  ho) stacked on t
+00013530: 6f70 206f 6620 6561 6368 206f 7468 6572  op of each other
+00013540: 2066 6f72 2065 6163 6820 6c61 7965 7220   for each layer 
+00013550: 2874 656e 736f 7220 3229 2e0a 2020 2020  (tensor 2)..    
+00013560: 5468 6174 2069 732c 2020 2857 5f69 697c  That is,  (W_ii|
+00013570: 575f 6966 7c57 5f69 677c 575f 696f 292c  W_if|W_ig|W_io),
+00013580: 206f 6620 7368 6170 6520 2834 2a68 6964   of shape (4*hid
+00013590: 6465 6e5f 7369 7a65 2c20 696e 7075 745f  den_size, input_
+000135a0: 7369 7a65 2920 616e 640a 2020 2020 2857  size) and.    (W
+000135b0: 5f68 697c 575f 6866 7c57 5f68 677c 575f  _hi|W_hf|W_hg|W_
+000135c0: 686f 292c 206f 6620 7368 6170 6520 2834  ho), of shape (4
+000135d0: 2a68 6964 6465 6e5f 7369 7a65 2c20 6869  *hidden_size, hi
+000135e0: 6464 656e 5f73 697a 6529 2e0a 0a0a 2020  dden_size)....  
+000135f0: 2020 5468 6520 436f 7265 204d 4c20 4c53    The Core ML LS
+00013600: 544d 206f 7020 6578 7065 6374 7320 7477  TM op expects tw
+00013610: 6f20 7465 6e73 6f72 732c 2077 6569 6768  o tensors, weigh
+00013620: 7420 616e 6420 6269 6173 2e20 536f 0a20  t and bias. So. 
+00013630: 2020 2074 6865 2074 656e 736f 7273 2066     the tensors f
+00013640: 6f72 2077 6569 6768 7420 616e 6420 6269  or weight and bi
+00013650: 6173 2061 7265 2073 6570 6572 6174 6564  as are seperated
+00013660: 2066 726f 6d20 7079 746f 7263 6827 7320   from pytorch's 
+00013670: 4077 6569 6768 7473 206c 6973 7420 2831  @weights list (1
+00013680: 2e29 2e0a 2020 2020 466f 7220 6269 6173  .)..    For bias
+00013690: 2074 656e 736f 722c 2074 6865 2043 6f72   tensor, the Cor
+000136a0: 6520 4d4c 204c 5354 4d20 6f70 2065 7870  e ML LSTM op exp
+000136b0: 6563 7473 2074 6865 2066 6f72 6d20 6969  ects the form ii
+000136c0: 2c20 6966 2c20 696f 2c20 6967 2061 6e64  , if, io, ig and
+000136d0: 2068 692c 2068 662c 2068 6f2c 2068 672c   hi, hf, ho, hg,
+000136e0: 0a20 2020 2072 6571 7569 7269 6e67 2074  .    requiring t
+000136f0: 6865 2069 667a 6f5f 746f 5f69 666f 7a20  he ifzo_to_ifoz 
+00013700: 6675 6e63 7469 6f6e 2e20 4675 7274 6865  function. Furthe
+00013710: 7220 6164 6469 6e67 2069 6e70 7574 2061  r adding input a
+00013720: 6e64 2068 6964 6465 6e20 6269 6173 2069  nd hidden bias i
+00013730: 6e74 6f20 6f6e 6520 2832 2e29 2e0a 2020  nto one (2.)..  
+00013740: 2020 5369 6d69 6c61 7220 746f 2062 6961    Similar to bia
+00013750: 732c 2069 6e70 7574 2061 6e64 2068 6964  s, input and hid
+00013760: 6465 6e20 7765 6967 6874 2072 6571 7569  den weight requi
+00013770: 7265 7320 6469 6666 6572 656e 7420 6c61  res different la
+00013780: 796f 7574 2e20 2833 2e29 0a0a 2020 2020  yout. (3.)..    
+00013790: 696e 6974 6961 6c5f 6820 616e 6420 696e  initial_h and in
+000137a0: 6974 6961 6c5f 6320 6172 6520 6c69 7374  itial_c are list
+000137b0: 206f 6620 226e 756d 5f6c 6179 6572 7322   of "num_layers"
+000137c0: 2074 656e 736f 7273 2c20 6561 6368 206f   tensors, each o
+000137d0: 6620 7368 6170 6520 5b6e 5f64 6972 6563  f shape [n_direc
+000137e0: 7469 6f6e 732c 2042 2c20 485d 2c0a 2020  tions, B, H],.  
+000137f0: 2020 7768 6572 6520 6e5f 6469 7265 6374    where n_direct
+00013800: 696f 6e73 203d 2031 206f 7220 320a 2020  ions = 1 or 2.  
+00013810: 2020 7768 6572 6561 7320 7468 6520 7368    whereas the sh
+00013820: 6170 6573 206f 6620 7468 6520 696e 6974  apes of the init
+00013830: 6961 6c20 7374 6174 6573 2074 6f20 4d49  ial states to MI
+00013840: 4c27 7320 4c53 544d 2c20 4269 4c53 544d  L's LSTM, BiLSTM
+00013850: 206d 7573 7420 6265 205b 422c 2048 5d20   must be [B, H] 
+00013860: 616e 6420 5b42 2c20 322a 485d 2072 6573  and [B, 2*H] res
+00013870: 7065 6374 6976 656c 792e 0a20 2020 2054  pectively..    T
+00013880: 6869 7320 6d65 616e 7320 7765 206e 6565  his means we nee
+00013890: 6420 746f 2064 6f20 7468 6520 666f 6c6c  d to do the foll
+000138a0: 6f77 696e 6720 7472 616e 7366 6f72 6d61  owing transforma
+000138b0: 7469 6f6e 733a 0a20 2020 202d 2069 6620  tions:.    - if 
+000138c0: 6974 7320 616e 204c 5354 4d20 286e 5f64  its an LSTM (n_d
+000138d0: 6972 6563 7469 6f6e 733d 3129 3a0a 2020  irections=1):.  
+000138e0: 2020 2020 2020 2020 2020 7371 7565 657a            squeez
+000138f0: 6520 7468 6520 6669 7273 7420 6469 6d65  e the first dime
+00013900: 6e73 696f 6e20 6f66 2069 6e69 7469 616c  nsion of initial
+00013910: 5f68 2f69 6e69 7469 616c 5f63 202c 2062  _h/initial_c , b
+00013920: 6566 6f72 6520 6665 6564 696e 6720 6974  efore feeding it
+00013930: 2074 6f20 4d49 4c27 7320 4c53 544d 0a20   to MIL's LSTM. 
+00013940: 2020 202d 2069 6620 6974 7320 6120 4269     - if its a Bi
+00013950: 4c53 544d 2028 6e5f 6469 7265 6374 696f  LSTM (n_directio
+00013960: 6e73 3d32 293a 0a20 2020 2020 2020 2020  ns=2):.         
+00013970: 2020 202d 2073 706c 6974 2074 6865 2069     - split the i
+00013980: 6e70 7574 2c20 7368 6170 653d 2832 2c20  nput, shape=(2, 
+00013990: 422c 2048 292c 2074 6f20 6765 7420 2831  B, H), to get (1
+000139a0: 2c42 2c48 2920 616e 6420 2831 2c42 2c48  ,B,H) and (1,B,H
+000139b0: 290a 2020 2020 2020 2020 2020 2020 2d20  ).            - 
+000139c0: 636f 6e63 6174 656e 6174 6520 746f 2067  concatenate to g
+000139d0: 6574 2028 312c 422c 322a 4829 0a20 2020  et (1,B,2*H).   
+000139e0: 2020 2020 2020 2020 202d 2073 7175 6565           - squee
+000139f0: 7a65 2074 6f20 6765 7420 2842 2c32 2a48  ze to get (B,2*H
+00013a00: 290a 2020 2020 2222 220a 0a20 2020 2069  ).    """..    i
+00013a10: 6620 6269 6469 7265 6374 696f 6e61 6c3a  f bidirectional:
+00013a20: 0a20 2020 2020 2020 2069 6620 6861 735f  .        if has_
+00013a30: 6269 6173 3a0a 2020 2020 2020 2020 2020  bias:.          
+00013a40: 2020 2320 2831 2e29 0a20 2020 2020 2020    # (1.).       
+00013a50: 2020 2020 2062 6961 7365 7320 3d20 7765       biases = we
+00013a60: 6967 6874 735b 323a 345d 202b 2077 6569  ights[2:4] + wei
+00013a70: 6768 7473 5b36 3a38 5d0a 2020 2020 2020  ghts[6:8].      
+00013a80: 2020 2020 2020 7765 6967 6874 7320 3d20        weights = 
+00013a90: 7765 6967 6874 735b 303a 325d 202b 2077  weights[0:2] + w
+00013aa0: 6569 6768 7473 5b34 3a36 5d0a 0a20 2020  eights[4:6]..   
+00013ab0: 2020 2020 2020 2020 2023 2028 322e 290a           # (2.).
+00013ac0: 2020 2020 2020 2020 2020 2020 6173 7365              asse
+00013ad0: 7274 206c 656e 2862 6961 7365 7329 203d  rt len(biases) =
+00013ae0: 3d20 340a 2020 2020 2020 2020 2020 2020  = 4.            
+00013af0: 666f 7220 696e 6465 7820 696e 2072 616e  for index in ran
+00013b00: 6765 286c 656e 2862 6961 7365 7329 293a  ge(len(biases)):
+00013b10: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00013b20: 2062 6961 7365 735b 696e 6465 785d 203d   biases[index] =
+00013b30: 205f 6966 7a6f 5f74 6f5f 6966 6f7a 280a   _ifzo_to_ifoz(.
+00013b40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013b50: 2020 2020 6269 6173 6573 5b69 6e64 6578      biases[index
+00013b60: 5d2c 0a20 2020 2020 2020 2020 2020 2020  ],.             
+00013b70: 2020 2020 2020 206e 616d 653d 227b 7d5f         name="{}_
+00013b80: 6c73 746d 5f62 6961 735f 7265 7368 6170  lstm_bias_reshap
+00013b90: 655f 7b7d 222e 666f 726d 6174 286e 616d  e_{}".format(nam
+00013ba0: 652c 2069 6e64 6578 292c 0a20 2020 2020  e, index),.     
+00013bb0: 2020 2020 2020 2020 2020 2029 0a20 2020             ).   
+00013bc0: 2020 2020 2020 2020 2066 5f62 203d 206d           f_b = m
+00013bd0: 622e 6164 6428 783d 6269 6173 6573 5b30  b.add(x=biases[0
+00013be0: 5d2c 2079 3d62 6961 7365 735b 315d 2c20  ], y=biases[1], 
+00013bf0: 290a 2020 2020 2020 2020 2020 2020 725f  ).            r_
+00013c00: 6220 3d20 6d62 2e61 6464 2878 3d62 6961  b = mb.add(x=bia
+00013c10: 7365 735b 325d 2c20 793d 6269 6173 6573  ses[2], y=biases
+00013c20: 5b33 5d2c 2029 0a0a 2020 2020 2020 2020  [3], )..        
+00013c30: 2320 2833 2e29 0a20 2020 2020 2020 2066  # (3.).        f
+00013c40: 5f69 685f 7720 3d20 5f69 667a 6f5f 746f  _ih_w = _ifzo_to
+00013c50: 5f69 666f 7a28 0a20 2020 2020 2020 2020  _ifoz(.         
+00013c60: 2020 2077 6569 6768 7473 5b30 5d2c 206e     weights[0], n
+00013c70: 616d 653d 6e61 6d65 202b 2022 5f6c 7374  ame=name + "_lst
+00013c80: 6d5f 666f 7277 6172 645f 6968 5f77 6569  m_forward_ih_wei
+00013c90: 6768 7473 5f69 666f 7a5f 746f 5f69 667a  ghts_ifoz_to_ifz
+00013ca0: 6f22 2c0a 2020 2020 2020 2020 290a 2020  o",.        ).  
+00013cb0: 2020 2020 2020 665f 6868 5f77 203d 205f        f_hh_w = _
+00013cc0: 6966 7a6f 5f74 6f5f 6966 6f7a 280a 2020  ifzo_to_ifoz(.  
+00013cd0: 2020 2020 2020 2020 2020 7765 6967 6874            weight
+00013ce0: 735b 315d 2c20 6e61 6d65 3d6e 616d 6520  s[1], name=name 
+00013cf0: 2b20 225f 6c73 746d 5f66 6f72 7761 7264  + "_lstm_forward
+00013d00: 5f68 685f 7765 6967 6874 735f 6966 6f7a  _hh_weights_ifoz
+00013d10: 5f74 6f5f 6966 7a6f 222c 0a20 2020 2020  _to_ifzo",.     
+00013d20: 2020 2029 0a20 2020 2020 2020 2072 5f69     ).        r_i
+00013d30: 685f 7720 3d20 5f69 667a 6f5f 746f 5f69  h_w = _ifzo_to_i
+00013d40: 666f 7a28 0a20 2020 2020 2020 2020 2020  foz(.           
+00013d50: 2077 6569 6768 7473 5b32 5d2c 206e 616d   weights[2], nam
+00013d60: 653d 6e61 6d65 202b 2022 5f6c 7374 6d5f  e=name + "_lstm_
+00013d70: 7265 7665 7273 655f 6968 5f77 6569 6768  reverse_ih_weigh
+00013d80: 7473 5f69 666f 7a5f 746f 5f69 667a 6f22  ts_ifoz_to_ifzo"
+00013d90: 2c0a 2020 2020 2020 2020 290a 2020 2020  ,.        ).    
+00013da0: 2020 2020 725f 6868 5f77 203d 205f 6966      r_hh_w = _if
+00013db0: 7a6f 5f74 6f5f 6966 6f7a 280a 2020 2020  zo_to_ifoz(.    
+00013dc0: 2020 2020 2020 2020 7765 6967 6874 735b          weights[
+00013dd0: 335d 2c20 6e61 6d65 3d6e 616d 6520 2b20  3], name=name + 
+00013de0: 225f 6c73 746d 5f72 6576 6572 7365 5f68  "_lstm_reverse_h
+00013df0: 685f 7765 6967 6874 735f 6966 6f7a 5f74  h_weights_ifoz_t
+00013e00: 6f5f 6966 7a6f 222c 0a20 2020 2020 2020  o_ifzo",.       
+00013e10: 2029 0a0a 2020 2020 2020 2020 6820 3d20   )..        h = 
+00013e20: 5f70 7974 6f72 6368 5f68 6964 6465 6e5f  _pytorch_hidden_
+00013e30: 746f 5f63 6f72 656d 6c5f 6d69 6c6f 7073  to_coreml_milops
+00013e40: 2869 6e69 7469 616c 5f68 2c20 6e61 6d65  (initial_h, name
+00013e50: 3d6e 616d 6520 2b20 225f 6c73 746d 5f68  =name + "_lstm_h
+00013e60: 305f 7265 7368 6170 6564 2229 0a20 2020  0_reshaped").   
+00013e70: 2020 2020 2063 203d 205f 7079 746f 7263       c = _pytorc
+00013e80: 685f 6869 6464 656e 5f74 6f5f 636f 7265  h_hidden_to_core
+00013e90: 6d6c 5f6d 696c 6f70 7328 696e 6974 6961  ml_milops(initia
+00013ea0: 6c5f 632c 206e 616d 653d 6e61 6d65 202b  l_c, name=name +
+00013eb0: 2022 5f6c 7374 6d5f 6330 5f72 6573 6861   "_lstm_c0_resha
+00013ec0: 7065 6422 290a 2020 2020 2020 2020 7265  ped").        re
+00013ed0: 7475 726e 206d 622e 6c73 746d 2878 3d69  turn mb.lstm(x=i
+00013ee0: 6e70 7574 2c0a 2020 2020 2020 2020 2020  nput,.          
+00013ef0: 2020 2020 2020 2020 2020 2020 2069 6e69               ini
+00013f00: 7469 616c 5f68 3d68 2c0a 2020 2020 2020  tial_h=h,.      
+00013f10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013f20: 2069 6e69 7469 616c 5f63 3d63 2c0a 2020   initial_c=c,.  
+00013f30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013f40: 2020 2020 2077 6569 6768 745f 6968 3d66       weight_ih=f
+00013f50: 5f69 685f 772c 0a20 2020 2020 2020 2020  _ih_w,.         
+00013f60: 2020 2020 2020 2020 2020 2020 2020 7765                we
+00013f70: 6967 6874 5f68 683d 665f 6868 5f77 2c0a  ight_hh=f_hh_w,.
+00013f80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013f90: 2020 2020 2020 2077 6569 6768 745f 6968         weight_ih
+00013fa0: 5f62 6163 6b3d 725f 6968 5f77 2c0a 2020  _back=r_ih_w,.  
+00013fb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013fc0: 2020 2020 2077 6569 6768 745f 6868 5f62       weight_hh_b
+00013fd0: 6163 6b3d 725f 6868 5f77 2c0a 2020 2020  ack=r_hh_w,.    
+00013fe0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013ff0: 2020 2062 6961 733d 2866 5f62 2069 6620     bias=(f_b if 
+00014000: 6861 735f 6269 6173 2065 6c73 6520 4e6f  has_bias else No
+00014010: 6e65 292c 0a20 2020 2020 2020 2020 2020  ne),.           
+00014020: 2020 2020 2020 2020 2020 2020 6269 6173              bias
+00014030: 5f62 6163 6b3d 2872 5f62 2069 6620 6861  _back=(r_b if ha
+00014040: 735f 6269 6173 2065 6c73 6520 4e6f 6e65  s_bias else None
+00014050: 292c 0a20 2020 2020 2020 2020 2020 2020  ),.             
+00014060: 2020 2020 2020 2020 2020 6469 7265 6374            direct
+00014070: 696f 6e3d 2262 6964 6972 6563 7469 6f6e  ion="bidirection
+00014080: 616c 222c 0a20 2020 2020 2020 2020 2020  al",.           
+00014090: 2020 2020 2020 2020 2020 2020 6f75 7470              outp
+000140a0: 7574 5f73 6571 7565 6e63 653d 5472 7565  ut_sequence=True
+000140b0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+000140c0: 2020 2020 2020 2020 206e 616d 653d 6e61           name=na
+000140d0: 6d65 290a 2020 2020 656c 7365 3a0a 2020  me).    else:.  
+000140e0: 2020 2020 2020 6966 2068 6173 5f62 6961        if has_bia
+000140f0: 733a 0a20 2020 2020 2020 2020 2020 2023  s:.            #
+00014100: 2028 312e 290a 2020 2020 2020 2020 2020   (1.).          
+00014110: 2020 6269 6173 6573 203d 2077 6569 6768    biases = weigh
+00014120: 7473 5b6c 656e 2877 6569 6768 7473 2920  ts[len(weights) 
+00014130: 2f2f 2032 3a5d 0a20 2020 2020 2020 2020  // 2:].         
+00014140: 2020 2077 6569 6768 7473 203d 2077 6569     weights = wei
+00014150: 6768 7473 5b3a 206c 656e 2877 6569 6768  ghts[: len(weigh
+00014160: 7473 2920 2f2f 2032 5d0a 2020 2020 2020  ts) // 2].      
+00014170: 2020 2020 2020 2320 2832 2e29 0a20 2020        # (2.).   
+00014180: 2020 2020 2020 2020 2062 203d 206d 622e           b = mb.
+00014190: 6164 6428 783d 6269 6173 6573 5b30 5d2c  add(x=biases[0],
+000141a0: 2079 3d62 6961 7365 735b 315d 2c20 290a   y=biases[1], ).
+000141b0: 2020 2020 2020 2020 2020 2020 6220 3d20              b = 
+000141c0: 5f69 667a 6f5f 746f 5f69 666f 7a28 0a20  _ifzo_to_ifoz(. 
+000141d0: 2020 2020 2020 2020 2020 2020 2020 2062                 b
+000141e0: 2c20 6e61 6d65 3d6e 616d 6520 2b20 225f  , name=name + "_
+000141f0: 6c73 746d 5f62 6961 735f 7472 616e 7366  lstm_bias_transf
+00014200: 6f72 6d65 6422 2c0a 2020 2020 2020 2020  ormed",.        
+00014210: 2020 2020 290a 2020 2020 2020 2020 2320      ).        # 
+00014220: 2833 2e29 0a20 2020 2020 2020 2066 5f69  (3.).        f_i
+00014230: 685f 7720 3d20 5f69 667a 6f5f 746f 5f69  h_w = _ifzo_to_i
+00014240: 666f 7a28 0a20 2020 2020 2020 2020 2020  foz(.           
+00014250: 2077 6569 6768 7473 5b30 5d2c 206e 616d   weights[0], nam
+00014260: 653d 6e61 6d65 202b 2022 5f6c 7374 6d5f  e=name + "_lstm_
+00014270: 6968 5f77 6569 6768 7473 5f69 666f 7a5f  ih_weights_ifoz_
+00014280: 746f 5f69 667a 6f22 2c0a 2020 2020 2020  to_ifzo",.      
+00014290: 2020 290a 2020 2020 2020 2020 665f 6868    ).        f_hh
+000142a0: 5f77 203d 205f 6966 7a6f 5f74 6f5f 6966  _w = _ifzo_to_if
+000142b0: 6f7a 280a 2020 2020 2020 2020 2020 2020  oz(.            
+000142c0: 7765 6967 6874 735b 315d 2c20 6e61 6d65  weights[1], name
+000142d0: 3d6e 616d 6520 2b20 225f 6c73 746d 5f68  =name + "_lstm_h
+000142e0: 685f 7765 6967 6874 735f 6966 6f7a 5f74  h_weights_ifoz_t
+000142f0: 6f5f 6966 7a6f 222c 0a20 2020 2020 2020  o_ifzo",.       
+00014300: 2029 0a0a 2020 2020 2020 2020 6820 3d20   )..        h = 
+00014310: 6d62 2e73 7175 6565 7a65 2878 3d69 6e69  mb.squeeze(x=ini
+00014320: 7469 616c 5f68 2c20 6178 6573 3d5f 6e70  tial_h, axes=_np
+00014330: 2e61 7272 6179 285b 305d 292c 206e 616d  .array([0]), nam
+00014340: 653d 6e61 6d65 202b 2022 5f6c 7374 6d5f  e=name + "_lstm_
+00014350: 6830 5f73 7175 6565 7a65 2229 0a20 2020  h0_squeeze").   
+00014360: 2020 2020 2063 203d 206d 622e 7371 7565       c = mb.sque
+00014370: 657a 6528 783d 696e 6974 6961 6c5f 632c  eze(x=initial_c,
+00014380: 2061 7865 733d 5f6e 702e 6172 7261 7928   axes=_np.array(
+00014390: 5b30 5d29 2c20 6e61 6d65 3d6e 616d 6520  [0]), name=name 
+000143a0: 2b20 225f 6c73 746d 5f63 305f 7371 7565  + "_lstm_c0_sque
+000143b0: 657a 6522 290a 0a20 2020 2020 2020 2072  eze")..        r
+000143c0: 6574 7572 6e20 6d62 2e6c 7374 6d28 783d  eturn mb.lstm(x=
+000143d0: 696e 7075 742c 0a20 2020 2020 2020 2020  input,.         
+000143e0: 2020 2020 2020 2020 2020 2020 2020 696e                in
+000143f0: 6974 6961 6c5f 683d 682c 0a20 2020 2020  itial_h=h,.     
+00014400: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014410: 2020 696e 6974 6961 6c5f 633d 632c 0a20    initial_c=c,. 
+00014420: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014430: 2020 2020 2020 7765 6967 6874 5f69 683d        weight_ih=
+00014440: 665f 6968 5f77 2c0a 2020 2020 2020 2020  f_ih_w,.        
+00014450: 2020 2020 2020 2020 2020 2020 2020 2077                 w
+00014460: 6569 6768 745f 6868 3d66 5f68 685f 772c  eight_hh=f_hh_w,
+00014470: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00014480: 2020 2020 2020 2020 6269 6173 3d28 6220          bias=(b 
+00014490: 6966 2068 6173 5f62 6961 7320 656c 7365  if has_bias else
+000144a0: 204e 6f6e 6529 2c0a 2020 2020 2020 2020   None),.        
+000144b0: 2020 2020 2020 2020 2020 2020 2020 2064                 d
+000144c0: 6972 6563 7469 6f6e 3d22 666f 7277 6172  irection="forwar
+000144d0: 6422 2c0a 2020 2020 2020 2020 2020 2020  d",.            
+000144e0: 2020 2020 2020 2020 2020 206f 7574 7075             outpu
+000144f0: 745f 7365 7175 656e 6365 3d54 7275 652c  t_sequence=True,
+00014500: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00014510: 2020 2020 2020 2020 6e61 6d65 3d6e 616d          name=nam
+00014520: 6529 0a0a 0a40 7265 6769 7374 6572 5f74  e)...@register_t
+00014530: 6f72 6368 5f6f 700a 6465 6620 6c73 746d  orch_op.def lstm
+00014540: 2863 6f6e 7465 7874 2c20 6e6f 6465 293a  (context, node):
+00014550: 0a20 2020 2069 6e70 7574 7320 3d20 5f67  .    inputs = _g
+00014560: 6574 5f69 6e70 7574 7328 636f 6e74 6578  et_inputs(contex
+00014570: 742c 206e 6f64 652c 2065 7870 6563 7465  t, node, expecte
+00014580: 643d 3929 0a0a 2020 2020 5f69 6e70 7574  d=9)..    _input
+00014590: 203d 2069 6e70 7574 735b 305d 0a0a 2020   = inputs[0]..  
+000145a0: 2020 2320 7468 6572 6520 6172 6520 7477    # there are tw
+000145b0: 6f20 6361 7365 7320 6865 7265 2c0a 2020  o cases here,.  
+000145c0: 2020 2320 2831 2920 7468 6520 696e 7075    # (1) the inpu
+000145d0: 7420 7465 6e73 6f72 2069 7320 6120 5061  t tensor is a Pa
+000145e0: 636b 6564 5365 7175 656e 6365 206f 626a  ckedSequence obj
+000145f0: 6563 742c 0a20 2020 2023 2069 6e20 7468  ect,.    # in th
+00014600: 6973 2063 6173 652c 2074 6865 2073 6563  is case, the sec
+00014610: 6f6e 6420 696e 7075 7420 6f66 2074 6865  ond input of the
+00014620: 206c 7374 6d20 6c61 7965 7220 6973 2074   lstm layer is t
+00014630: 6865 2062 6174 6368 5f73 697a 6520 284d  he batch_size (M
+00014640: 494c 2056 6172 292e 0a20 2020 2023 2028  IL Var)..    # (
+00014650: 3229 2074 6865 2069 6e70 7574 2074 656e  2) the input ten
+00014660: 736f 7220 6973 2061 206e 6f72 6d61 6c20  sor is a normal 
+00014670: 7465 6e73 6f72 2c0a 2020 2020 2320 696e  tensor,.    # in
+00014680: 2074 6869 7320 6361 7365 2c20 7468 6520   this case, the 
+00014690: 7365 636f 6e64 2069 6e70 7574 2069 7320  second input is 
+000146a0: 616e 2061 7272 6179 2e0a 2020 2020 2320  an array..    # 
+000146b0: 4173 2074 6865 2072 6573 756c 742c 2077  As the result, w
+000146c0: 6520 6361 6e20 7573 6520 7468 6520 7365  e can use the se
+000146d0: 636f 6e64 2069 6e70 7574 2074 6f20 6964  cond input to id
+000146e0: 656e 7469 6679 2077 6869 6368 2063 6174  entify which cat
+000146f0: 6567 6f72 7920 7468 6520 6772 6170 6820  egory the graph 
+00014700: 6973 2e0a 0a20 2020 2068 6173 5f62 6174  is...    has_bat
+00014710: 6368 5f73 697a 6573 203d 206e 6f74 2069  ch_sizes = not i
+00014720: 7369 6e73 7461 6e63 6528 696e 7075 7473  sinstance(inputs
+00014730: 5b31 5d2c 2049 7465 7261 626c 6529 0a20  [1], Iterable). 
+00014740: 2020 2069 6620 6861 735f 6261 7463 685f     if has_batch_
+00014750: 7369 7a65 733a 0a20 2020 2020 2020 2062  sizes:.        b
+00014760: 6174 6368 5f73 697a 6573 203d 2069 6e70  atch_sizes = inp
+00014770: 7574 735b 315d 0a20 2020 2020 2020 2068  uts[1].        h
+00014780: 302c 2063 3020 3d20 696e 7075 7473 5b32  0, c0 = inputs[2
+00014790: 5d0a 2020 2020 2020 2020 7765 6967 6874  ].        weight
+000147a0: 735f 6c69 7374 203d 2069 6e70 7574 735b  s_list = inputs[
+000147b0: 335d 0a20 2020 2020 2020 2068 6173 5f62  3].        has_b
+000147c0: 6961 7320 3d20 696e 7075 7473 5b34 5d2e  ias = inputs[4].
+000147d0: 7661 6c0a 2020 2020 2020 2020 6e75 6d5f  val.        num_
+000147e0: 6c61 7965 7273 203d 2069 6e70 7574 735b  layers = inputs[
+000147f0: 355d 2e76 616c 0a20 2020 2020 2020 2064  5].val.        d
+00014800: 726f 706f 7574 203d 2069 6e70 7574 735b  ropout = inputs[
+00014810: 365d 0a20 2020 2020 2020 2062 6964 6972  6].        bidir
+00014820: 6563 7469 6f6e 616c 203d 2069 6e70 7574  ectional = input
+00014830: 735b 385d 2e76 616c 0a20 2020 2020 2020  s[8].val.       
+00014840: 2023 2074 6865 206f 7574 7075 7420 6f66   # the output of
+00014850: 2074 6865 205f 7061 636b 5f70 6164 6465   the _pack_padde
+00014860: 645f 7365 7175 656e 6365 2069 7320 616c  d_sequence is al
+00014870: 7761 7973 2069 6e20 7468 6520 6c61 796f  ways in the layo
+00014880: 7574 206f 6620 6261 7463 6820 6669 7273  ut of batch firs
+00014890: 740a 2020 2020 2020 2020 6261 7463 685f  t.        batch_
+000148a0: 6669 7273 7420 3d20 5472 7565 0a20 2020  first = True.   
+000148b0: 2065 6c73 653a 0a20 2020 2020 2020 2068   else:.        h
+000148c0: 302c 2063 3020 3d20 696e 7075 7473 5b31  0, c0 = inputs[1
+000148d0: 5d0a 2020 2020 2020 2020 7765 6967 6874  ].        weight
+000148e0: 735f 6c69 7374 203d 2069 6e70 7574 735b  s_list = inputs[
+000148f0: 325d 0a20 2020 2020 2020 2068 6173 5f62  2].        has_b
+00014900: 6961 7320 3d20 696e 7075 7473 5b33 5d2e  ias = inputs[3].
+00014910: 7661 6c0a 2020 2020 2020 2020 6e75 6d5f  val.        num_
+00014920: 6c61 7965 7273 203d 2069 6e70 7574 735b  layers = inputs[
+00014930: 345d 2e76 616c 0a20 2020 2020 2020 2064  4].val.        d
+00014940: 726f 706f 7574 203d 2069 6e70 7574 735b  ropout = inputs[
+00014950: 355d 0a20 2020 2020 2020 2062 6964 6972  5].        bidir
+00014960: 6563 7469 6f6e 616c 203d 2069 6e70 7574  ectional = input
+00014970: 735b 375d 2e76 616c 0a20 2020 2020 2020  s[7].val.       
+00014980: 2062 6174 6368 5f66 6972 7374 203d 2069   batch_first = i
+00014990: 6e70 7574 735b 385d 2e76 616c 0a0a 2020  nputs[8].val..  
+000149a0: 2020 2727 270a 2020 2020 546f 7263 6820    '''.    Torch 
+000149b0: 4c53 544d 206c 6179 6572 2773 2069 6e70  LSTM layer's inp
+000149c0: 7574 2073 6861 7065 733a 0a0a 2020 2020  ut shapes:..    
+000149d0: 2831 2920 6669 7273 7420 696e 7075 740a  (1) first input.
+000149e0: 2020 2020 2020 2020 2853 6571 2c20 422c          (Seq, B,
+000149f0: 2043 2920 3a20 6966 2062 6174 6368 5f66   C) : if batch_f
+00014a00: 6972 7374 203d 2046 616c 7365 0a20 2020  irst = False.   
+00014a10: 2020 2020 2028 422c 2053 6571 2c20 4329       (B, Seq, C)
+00014a20: 203a 2069 6620 6261 7463 685f 6669 7273   : if batch_firs
+00014a30: 7420 3d20 5472 7565 0a0a 2020 2020 2832  t = True..    (2
+00014a40: 2920 2620 2833 2920 696e 6974 6961 6c69  ) & (3) initiali
+00014a50: 7a61 7469 6f6e 2073 7461 7465 730a 2020  zation states.  
+00014a60: 2020 2020 2020 286e 756d 5f6c 6179 6572        (num_layer
+00014a70: 732c 2042 2c20 4829 203a 2069 6620 6269  s, B, H) : if bi
+00014a80: 6469 7265 6374 696f 6e61 6c20 3d20 4661  directional = Fa
+00014a90: 6c73 650a 2020 2020 2020 2020 286e 756d  lse.        (num
+00014aa0: 5f6c 6179 6572 7320 2a20 322c 2042 2c20  _layers * 2, B, 
+00014ab0: 4829 203a 2069 6620 6269 6469 7265 6374  H) : if bidirect
+00014ac0: 696f 6e61 6c20 3d20 5472 7565 0a0a 0a20  ional = True... 
+00014ad0: 2020 2046 6f72 2074 6865 204d 494c 204c     For the MIL L
+00014ae0: 5354 4d20 6c61 7965 722c 2074 6865 7365  STM layer, these
+00014af0: 2061 7265 2074 6865 2069 6e70 7574 2073   are the input s
+00014b00: 6861 7065 733a 0a0a 2020 2020 2831 2920  hapes:..    (1) 
+00014b10: 6669 7273 7420 696e 7075 743a 2028 5365  first input: (Se
+00014b20: 712c 2042 2c20 4329 0a20 2020 2020 2020  q, B, C).       
+00014b30: 2020 2020 7468 6973 206d 6561 6e73 2c20      this means, 
+00014b40: 6966 2062 6174 6368 5f66 6972 7374 3d54  if batch_first=T
+00014b50: 7275 652c 2077 6520 6e65 6564 2074 6f20  rue, we need to 
+00014b60: 696e 7365 7274 2061 2074 7261 6e73 706f  insert a transpo
+00014b70: 7365 206f 7020 6669 7273 740a 0a20 2020  se op first..   
+00014b80: 2028 3229 2026 2028 3329 2069 6e69 7469   (2) & (3) initi
+00014b90: 616c 697a 6174 696f 6e20 7374 6174 6573  alization states
+00014ba0: 0a20 2020 2020 2020 204d 494c 2773 204c  .        MIL's L
+00014bb0: 5354 4d20 6c61 7965 7220 646f 6573 206e  STM layer does n
+00014bc0: 6f74 206e 6174 6976 656c 7920 7375 7070  ot natively supp
+00014bd0: 6f72 7420 7468 6520 226e 756d 5f6c 6179  ort the "num_lay
+00014be0: 6572 7322 2070 6172 616d 6574 6572 732e  ers" parameters.
+00014bf0: 0a20 2020 2020 2020 2053 6f2c 2077 6865  .        So, whe
+00014c00: 6e20 6e75 6d5f 6c61 7965 7273 203e 2031  n num_layers > 1
+00014c10: 2c20 7765 2061 6464 206d 756c 7469 706c  , we add multipl
+00014c20: 6520 4d49 4c20 4c53 544d 206f 7073 2069  e MIL LSTM ops i
+00014c30: 6e20 6120 7365 7175 656e 6365 2e0a 2020  n a sequence..  
+00014c40: 2020 2020 2020 4561 6368 206f 6620 7468        Each of th
+00014c50: 6573 6520 4c53 544d 206f 7073 2077 696c  ese LSTM ops wil
+00014c60: 6c20 7461 6b65 2069 6e20 696e 6974 6961  l take in initia
+00014c70: 6c69 7a61 7469 6f6e 2073 7461 7465 7320  lization states 
+00014c80: 696e 2074 6865 2066 6f6c 6c6f 7769 6e67  in the following
+00014c90: 2073 6861 7065 3a0a 2020 2020 2020 2020   shape:.        
+00014ca0: 2842 2c20 4829 2069 6620 6269 6469 7265  (B, H) if bidire
+00014cb0: 6374 696f 6e61 6c20 3d20 4661 6c73 650a  ctional = False.
+00014cc0: 2020 2020 2020 2020 2842 2c20 322a 4829          (B, 2*H)
+00014cd0: 2069 6620 6269 6469 7265 6374 696f 6e61   if bidirectiona
+00014ce0: 6c20 3d20 5472 7565 0a20 2020 2027 2727  l = True.    '''
+00014cf0: 0a0a 2020 2020 6966 2062 6174 6368 5f66  ..    if batch_f
+00014d00: 6972 7374 3a0a 2020 2020 2020 2020 5f69  irst:.        _i
+00014d10: 6e70 7574 203d 206d 622e 7472 616e 7370  nput = mb.transp
+00014d20: 6f73 6528 783d 5f69 6e70 7574 2c20 7065  ose(x=_input, pe
+00014d30: 726d 3d5b 312c 2030 2c20 325d 2c20 6e61  rm=[1, 0, 2], na
+00014d40: 6d65 3d5f 696e 7075 742e 6e61 6d65 202b  me=_input.name +
+00014d50: 2022 5f62 6174 6368 5f66 6972 7374 5f74   "_batch_first_t
+00014d60: 7261 6e73 706f 7365 2229 0a0a 2020 2020  ranspose")..    
+00014d70: 6578 7065 6374 6564 5f6e 756d 5f77 6569  expected_num_wei
+00014d80: 6768 7473 203d 2032 202a 206e 756d 5f6c  ghts = 2 * num_l
+00014d90: 6179 6572 7320 2a20 2869 6e74 2862 6964  ayers * (int(bid
+00014da0: 6972 6563 7469 6f6e 616c 2920 2b20 3129  irectional) + 1)
+00014db0: 202a 2028 696e 7428 6861 735f 6269 6173   * (int(has_bias
+00014dc0: 2920 2b20 3129 0a20 2020 2069 6620 6c65  ) + 1).    if le
+00014dd0: 6e28 7765 6967 6874 735f 6c69 7374 2920  n(weights_list) 
+00014de0: 213d 2065 7870 6563 7465 645f 6e75 6d5f  != expected_num_
+00014df0: 7765 6967 6874 733a 0a20 2020 2020 2020  weights:.       
+00014e00: 2072 6169 7365 2056 616c 7565 4572 726f   raise ValueErro
+00014e10: 7228 0a20 2020 2020 2020 2020 2020 2022  r(.            "
+00014e20: 496e 636f 7272 6563 7420 7765 6967 6874  Incorrect weight
+00014e30: 7320 7368 6170 6520 666f 7220 6c73 746d  s shape for lstm
+00014e40: 206c 6179 6572 3a20 4578 7065 6374 6564   layer: Expected
+00014e50: 3a20 7b7d 2e20 5265 6369 6576 6564 207b  : {}. Recieved {
+00014e60: 7d22 2e66 6f72 6d61 7428 0a20 2020 2020  }".format(.     
+00014e70: 2020 2020 2020 2020 2020 2065 7870 6563             expec
+00014e80: 7465 645f 6e75 6d5f 7765 6967 6874 732c  ted_num_weights,
+00014e90: 206c 656e 2877 6569 6768 7473 5f6c 6973   len(weights_lis
+00014ea0: 7429 0a20 2020 2020 2020 2020 2020 2029  t).            )
+00014eb0: 0a20 2020 2020 2020 2029 0a0a 2020 2020  .        )..    
+00014ec0: 2320 7368 6170 6520 6f66 2068 3020 616e  # shape of h0 an
+00014ed0: 6420 6330 2061 7265 2028 6e75 6d5f 6c61  d c0 are (num_la
+00014ee0: 7965 7273 202a 206e 5f64 6972 6563 7469  yers * n_directi
+00014ef0: 6f6e 732c 2042 2c20 4829 0a20 2020 2069  ons, B, H).    i
+00014f00: 6620 6e75 6d5f 6c61 7965 7273 203d 3d20  f num_layers == 
+00014f10: 313a 0a20 2020 2020 2020 2061 6c6c 5f69  1:.        all_i
+00014f20: 6e69 7469 616c 5f68 203d 205b 6830 5d20  nitial_h = [h0] 
+00014f30: 2023 205b 286e 5f64 6972 6563 7469 6f6e   # [(n_direction
+00014f40: 732c 2042 2c20 4829 5d0a 2020 2020 2020  s, B, H)].      
+00014f50: 2020 616c 6c5f 696e 6974 6961 6c5f 6320    all_initial_c 
+00014f60: 3d20 5b63 305d 2020 2320 5b28 6e5f 6469  = [c0]  # [(n_di
+00014f70: 7265 6374 696f 6e73 2c20 422c 2048 295d  rections, B, H)]
+00014f80: 0a20 2020 2065 6c73 653a 0a20 2020 2020  .    else:.     
+00014f90: 2020 2061 6c6c 5f69 6e69 7469 616c 5f68     all_initial_h
+00014fa0: 203d 206d 622e 7370 6c69 7428 0a20 2020   = mb.split(.   
+00014fb0: 2020 2020 2020 2020 2078 3d68 302c 206e           x=h0, n
+00014fc0: 756d 5f73 706c 6974 733d 6e75 6d5f 6c61  um_splits=num_la
+00014fd0: 7965 7273 2c20 6178 6973 3d30 0a20 2020  yers, axis=0.   
+00014fe0: 2020 2020 2029 2020 2320 5b28 6e5f 6469       )  # [(n_di
+00014ff0: 7265 6374 696f 6e73 2c20 422c 2048 295d  rections, B, H)]
+00015000: 0a20 2020 2020 2020 2061 6c6c 5f69 6e69  .        all_ini
+00015010: 7469 616c 5f63 203d 206d 622e 7370 6c69  tial_c = mb.spli
+00015020: 7428 0a20 2020 2020 2020 2020 2020 2078  t(.            x
+00015030: 3d63 302c 206e 756d 5f73 706c 6974 733d  =c0, num_splits=
+00015040: 6e75 6d5f 6c61 7965 7273 2c20 6178 6973  num_layers, axis
+00015050: 3d30 0a20 2020 2020 2020 2029 2020 2320  =0.        )  # 
+00015060: 5b28 6e5f 6469 7265 6374 696f 6e73 2c20  [(n_directions, 
+00015070: 422c 2048 295d 0a0a 2020 2020 6e5f 7765  B, H)]..    n_we
+00015080: 6967 6874 735f 7065 725f 6c61 7965 7220  ights_per_layer 
+00015090: 3d20 696e 7428 6c65 6e28 7765 6967 6874  = int(len(weight
+000150a0: 735f 6c69 7374 2920 2f20 6e75 6d5f 6c61  s_list) / num_la
+000150b0: 7965 7273 290a 2020 2020 7820 3d20 5f69  yers).    x = _i
+000150c0: 6e70 7574 0a20 2020 2068 5f6f 7574 5f6c  nput.    h_out_l
+000150d0: 6973 7420 3d20 5b5d 0a20 2020 2063 5f6f  ist = [].    c_o
+000150e0: 7574 5f6c 6973 7420 3d20 5b5d 0a20 2020  ut_list = [].   
+000150f0: 2066 6f72 2069 2069 6e20 7261 6e67 6528   for i in range(
+00015100: 6e75 6d5f 6c61 7965 7273 293a 0a20 2020  num_layers):.   
+00015110: 2020 2020 2069 6620 6920 3c20 6e75 6d5f       if i < num_
+00015120: 6c61 7965 7273 202d 2031 3a0a 2020 2020  layers - 1:.    
+00015130: 2020 2020 2020 2020 6f70 5f6e 616d 6520          op_name 
+00015140: 3d20 6e6f 6465 2e6e 616d 6520 2b20 225f  = node.name + "_
+00015150: 6c73 746d 5f6c 6179 6572 5f7b 7d22 2e66  lstm_layer_{}".f
+00015160: 6f72 6d61 7428 6929 0a20 2020 2020 2020  ormat(i).       
+00015170: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
+00015180: 2020 2069 6620 6261 7463 685f 6669 7273     if batch_firs
+00015190: 743a 0a20 2020 2020 2020 2020 2020 2020  t:.             
+000151a0: 2020 206f 705f 6e61 6d65 203d 206e 6f64     op_name = nod
+000151b0: 652e 6e61 6d65 202b 2022 5f62 6174 6368  e.name + "_batch
+000151c0: 5f66 6972 7374 220a 2020 2020 2020 2020  _first".        
+000151d0: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
+000151e0: 2020 2020 2020 2020 2020 6f70 5f6e 616d            op_nam
+000151f0: 6520 3d20 6e6f 6465 2e6e 616d 650a 0a20  e = node.name.. 
+00015200: 2020 2020 2020 206c 7374 6d5f 6f75 7420         lstm_out 
+00015210: 3d20 5f61 6464 5f6d 696c 5f6c 7374 6d28  = _add_mil_lstm(
+00015220: 0a20 2020 2020 2020 2020 2020 2069 6e70  .            inp
+00015230: 7574 3d78 2c0a 2020 2020 2020 2020 2020  ut=x,.          
+00015240: 2020 696e 6974 6961 6c5f 683d 616c 6c5f    initial_h=all_
+00015250: 696e 6974 6961 6c5f 685b 695d 2c0a 2020  initial_h[i],.  
+00015260: 2020 2020 2020 2020 2020 696e 6974 6961            initia
+00015270: 6c5f 633d 616c 6c5f 696e 6974 6961 6c5f  l_c=all_initial_
+00015280: 635b 695d 2c0a 2020 2020 2020 2020 2020  c[i],.          
+00015290: 2020 7765 6967 6874 733d 7765 6967 6874    weights=weight
+000152a0: 735f 6c69 7374 5b0a 2020 2020 2020 2020  s_list[.        
+000152b0: 2020 2020 2020 2020 6920 2a20 6e5f 7765          i * n_we
+000152c0: 6967 6874 735f 7065 725f 6c61 7965 7220  ights_per_layer 
+000152d0: 3a20 2869 202b 2031 2920 2a20 6e5f 7765  : (i + 1) * n_we
+000152e0: 6967 6874 735f 7065 725f 6c61 7965 720a  ights_per_layer.
+000152f0: 2020 2020 2020 2020 2020 2020 5d2c 0a20              ],. 
+00015300: 2020 2020 2020 2020 2020 2068 6173 5f62             has_b
+00015310: 6961 733d 6861 735f 6269 6173 2c0a 2020  ias=has_bias,.  
+00015320: 2020 2020 2020 2020 2020 6269 6469 7265            bidire
+00015330: 6374 696f 6e61 6c3d 6269 6469 7265 6374  ctional=bidirect
+00015340: 696f 6e61 6c2c 0a20 2020 2020 2020 2020  ional,.         
+00015350: 2020 206e 616d 653d 6f70 5f6e 616d 652c     name=op_name,
+00015360: 0a20 2020 2020 2020 2029 0a20 2020 2020  .        ).     
+00015370: 2020 2023 2073 6861 7065 206f 6620 6c73     # shape of ls
+00015380: 746d 5f6f 7574 5b30 5d20 3d3d 2028 532c  tm_out[0] == (S,
+00015390: 422c 4829 2069 6620 6269 6469 7265 6374  B,H) if bidirect
+000153a0: 696f 6e61 6c20 3d20 5472 7565 2065 6c73  ional = True els
+000153b0: 6520 2853 2c20 422c 2032 2a48 290a 2020  e (S, B, 2*H).  
+000153c0: 2020 2020 2020 7820 3d20 6c73 746d 5f6f        x = lstm_o
+000153d0: 7574 5b30 5d0a 2020 2020 2020 2020 2320  ut[0].        # 
+000153e0: 7368 6170 6520 6f66 206c 7374 6d5f 6f75  shape of lstm_ou
+000153f0: 745b 315d 203d 3d20 2842 2c48 2920 6966  t[1] == (B,H) if
+00015400: 2062 6964 6972 6563 7469 6f6e 616c 203d   bidirectional =
+00015410: 2046 616c 7365 2065 6c73 6520 2842 2c20   False else (B, 
+00015420: 322a 4829 0a20 2020 2020 2020 2068 5f6f  2*H).        h_o
+00015430: 7574 5f6c 6973 742e 6170 7065 6e64 286c  ut_list.append(l
+00015440: 7374 6d5f 6f75 745b 315d 290a 2020 2020  stm_out[1]).    
+00015450: 2020 2020 2320 7368 6170 6520 6f66 206c      # shape of l
+00015460: 7374 6d5f 6f75 745b 325d 203d 3d20 2842  stm_out[2] == (B
+00015470: 2c48 2920 6966 2062 6964 6972 6563 7469  ,H) if bidirecti
+00015480: 6f6e 616c 203d 2046 616c 7365 2065 6c73  onal = False els
+00015490: 6520 2842 2c20 322a 4829 0a20 2020 2020  e (B, 2*H).     
+000154a0: 2020 2063 5f6f 7574 5f6c 6973 742e 6170     c_out_list.ap
+000154b0: 7065 6e64 286c 7374 6d5f 6f75 745b 325d  pend(lstm_out[2]
+000154c0: 290a 0a20 2020 2027 2727 0a20 2020 2046  )..    '''.    F
+000154d0: 6f72 2074 6f72 6368 2c20 7468 6573 6520  or torch, these 
+000154e0: 6172 6520 7468 6520 6469 6d65 6e73 696f  are the dimensio
+000154f0: 6e73 206f 6620 7468 6520 3320 6f75 7470  ns of the 3 outp
+00015500: 7574 2074 656e 736f 7273 3a0a 2020 2020  ut tensors:.    
+00015510: 2831 2920 6f75 7470 7574 5b30 5d20 3a0a  (1) output[0] :.
+00015520: 2020 2020 2020 2020 2020 2020 2853 6571              (Seq
+00015530: 2c20 422c 2048 2920 6966 2062 6174 6368  , B, H) if batch
+00015540: 5f66 6972 7374 203d 2046 616c 7365 2c20  _first = False, 
+00015550: 6269 6469 7265 6374 696f 6e61 6c20 3d20  bidirectional = 
+00015560: 4661 6c73 650a 2020 2020 2020 2020 2020  False.          
+00015570: 2020 2853 6571 2c20 422c 2032 2a48 2920    (Seq, B, 2*H) 
+00015580: 6966 2062 6174 6368 5f66 6972 7374 203d  if batch_first =
+00015590: 2046 616c 7365 2c20 6269 6469 7265 6374   False, bidirect
+000155a0: 696f 6e61 6c20 3d20 5472 7565 0a20 2020  ional = True.   
+000155b0: 2020 2020 2020 2020 2028 422c 2053 6571           (B, Seq
+000155c0: 2c20 4829 2069 6620 6261 7463 685f 6669  , H) if batch_fi
+000155d0: 7273 7420 3d20 5472 7565 2c20 6269 6469  rst = True, bidi
+000155e0: 7265 6374 696f 6e61 6c20 3d20 4661 6c73  rectional = Fals
+000155f0: 650a 2020 2020 2020 2020 2020 2020 2842  e.            (B
+00015600: 2c20 5365 712c 2032 2a48 2920 6966 2062  , Seq, 2*H) if b
+00015610: 6174 6368 5f66 6972 7374 203d 2054 7275  atch_first = Tru
+00015620: 652c 2062 6964 6972 6563 7469 6f6e 616c  e, bidirectional
+00015630: 203d 2054 7275 650a 0a20 2020 2028 3229   = True..    (2)
+00015640: 2026 2028 3329 2074 6865 7365 2061 7265   & (3) these are
+00015650: 2074 6865 2073 7461 7465 206f 7574 7075   the state outpu
+00015660: 7473 3a0a 2020 2020 2020 2020 2020 2020  ts:.            
+00015670: 286e 756d 5f6c 6179 6572 732c 2042 2c20  (num_layers, B, 
+00015680: 4829 2069 6620 6269 6469 7265 6374 696f  H) if bidirectio
+00015690: 6e61 6c20 3d20 4661 6c73 650a 2020 2020  nal = False.    
+000156a0: 2020 2020 2020 2020 286e 756d 5f6c 6179          (num_lay
+000156b0: 6572 7320 2a20 322c 2042 2c20 4829 2069  ers * 2, B, H) i
+000156c0: 6620 6269 6469 7265 6374 696f 6e61 6c20  f bidirectional 
+000156d0: 3d20 5472 7565 0a0a 2020 2020 4d49 4c20  = True..    MIL 
+000156e0: 6c73 746d 206c 6179 6572 2773 206f 7574  lstm layer's out
+000156f0: 7075 7420 7368 6170 6573 3a0a 2020 2020  put shapes:.    
+00015700: 2831 2920 6f75 7470 7574 5b30 5d3a 0a20  (1) output[0]:. 
+00015710: 2020 2020 2020 2028 5365 712c 2042 2c20         (Seq, B, 
+00015720: 4829 2069 6620 6269 6469 7265 6374 696f  H) if bidirectio
+00015730: 6e61 6c20 3d20 4661 6c73 650a 2020 2020  nal = False.    
+00015740: 2020 2020 2853 6571 2c20 422c 2032 2a48      (Seq, B, 2*H
+00015750: 2920 6966 2062 6964 6972 6563 7469 6f6e  ) if bidirection
+00015760: 616c 203d 2054 7275 650a 2020 2020 2020  al = True.      
+00015770: 2020 5468 6973 206d 6561 6e73 2077 6520    This means we 
+00015780: 6e65 6564 2061 2074 7261 6e73 706f 7365  need a transpose
+00015790: 206f 7020 6966 2062 6174 6368 5f66 6972   op if batch_fir
+000157a0: 7374 2069 7320 5472 7565 0a0a 2020 2020  st is True..    
+000157b0: 2832 2920 2620 2833 2920 7368 6170 6573  (2) & (3) shapes
+000157c0: 206f 6620 7468 6520 7374 6174 6520 6f75   of the state ou
+000157d0: 7470 7574 733a 0a20 2020 2020 2020 2065  tputs:.        e
+000157e0: 6163 6820 4d49 4c20 4c53 544d 206f 7020  ach MIL LSTM op 
+000157f0: 7769 6c6c 2070 726f 6475 6365 2066 696e  will produce fin
+00015800: 616c 2073 7461 7465 2074 656e 736f 7273  al state tensors
+00015810: 2077 6974 6820 7468 6520 666f 6c6c 6f77   with the follow
+00015820: 696e 6720 7368 6170 653a 0a20 2020 2020  ing shape:.     
+00015830: 2020 2028 422c 2048 2920 6966 2062 6964     (B, H) if bid
+00015840: 6972 6563 7469 6f6e 616c 203d 2046 616c  irectional = Fal
+00015850: 7365 0a20 2020 2020 2020 2028 422c 2032  se.        (B, 2
+00015860: 2a48 2920 6966 2062 6964 6972 6563 7469  *H) if bidirecti
+00015870: 6f6e 616c 203d 2054 7275 650a 0a20 2020  onal = True..   
+00015880: 2020 2020 2073 7461 636b 2f65 7870 616e       stack/expan
+00015890: 6420 7468 6520 6669 6e61 6c20 7374 6174  d the final stat
+000158a0: 6520 7465 6e73 6f72 7320 746f 206d 6174  e tensors to mat
+000158b0: 6368 2074 6865 2054 6f72 6368 206f 7574  ch the Torch out
+000158c0: 7075 740a 2020 2020 2727 270a 2020 2020  put.    '''.    
+000158d0: 666f 7220 696e 6465 782c 2028 6e61 6d65  for index, (name
+000158e0: 2c20 6f75 7470 7574 2920 696e 2065 6e75  , output) in enu
+000158f0: 6d65 7261 7465 287a 6970 286e 6f64 652e  merate(zip(node.
+00015900: 6f75 7470 7574 732c 206c 7374 6d5f 6f75  outputs, lstm_ou
+00015910: 7429 293a 0a20 2020 2020 2020 2069 6620  t)):.        if 
+00015920: 696e 6465 7820 3e20 303a 0a20 2020 2020  index > 0:.     
+00015930: 2020 2020 2020 2023 2069 6e64 6578 203e         # index >
+00015940: 2030 203d 3d3d 3e20 6974 7320 6f6e 6520   0 ===> its one 
+00015950: 6f66 2074 6865 2073 7461 7465 206f 7574  of the state out
+00015960: 7075 7473 2028 6820 6f72 2063 290a 2020  puts (h or c).  
+00015970: 2020 2020 2020 2020 2020 6966 2062 6964            if bid
+00015980: 6972 6563 7469 6f6e 616c 3a0a 2020 2020  irectional:.    
+00015990: 2020 2020 2020 2020 2020 2020 6966 206e              if n
+000159a0: 756d 5f6c 6179 6572 7320 3d3d 2031 3a0a  um_layers == 1:.
+000159b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000159c0: 2020 2020 6f75 7431 2c20 6f75 7432 203d      out1, out2 =
+000159d0: 206d 622e 7370 6c69 7428 0a20 2020 2020   mb.split(.     
+000159e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000159f0: 2020 2078 3d6f 7574 7075 742c 206e 756d     x=output, num
+00015a00: 5f73 706c 6974 733d 322c 2061 7869 733d  _splits=2, axis=
+00015a10: 310a 2020 2020 2020 2020 2020 2020 2020  1.              
+00015a20: 2020 2020 2020 2920 2023 2065 6163 6820        )  # each 
+00015a30: 6f75 7470 7574 206f 6620 7368 6170 6520  output of shape 
+00015a40: 5b42 2c20 485d 2061 6674 6572 2074 6865  [B, H] after the
+00015a50: 2073 706c 6974 0a20 2020 2020 2020 2020   split.         
+00015a60: 2020 2020 2020 2020 2020 2066 696e 616c             final
+00015a70: 5f6f 7574 203d 206d 622e 7374 6163 6b28  _out = mb.stack(
+00015a80: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00015a90: 2020 2020 2020 2020 2076 616c 7565 733d           values=
+00015aa0: 5b6f 7574 312c 206f 7574 325d 2c20 6178  [out1, out2], ax
+00015ab0: 6973 3d30 2c20 6e61 6d65 3d6e 616d 650a  is=0, name=name.
+00015ac0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015ad0: 2020 2020 2920 2023 205b 322c 2042 2c20      )  # [2, B, 
+00015ae0: 485d 0a20 2020 2020 2020 2020 2020 2020  H].             
+00015af0: 2020 2020 2020 2063 6f6e 7465 7874 2e61         context.a
+00015b00: 6464 2866 696e 616c 5f6f 7574 2c20 6e61  dd(final_out, na
+00015b10: 6d65 290a 2020 2020 2020 2020 2020 2020  me).            
+00015b20: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
+00015b30: 2020 2020 2020 2020 2020 2020 2020 6f75                ou
+00015b40: 745f 7374 6174 655f 7465 6e73 6f72 735f  t_state_tensors_
+00015b50: 6c69 7374 203d 2028 0a20 2020 2020 2020  list = (.       
+00015b60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015b70: 2068 5f6f 7574 5f6c 6973 7420 6966 2069   h_out_list if i
+00015b80: 6e64 6578 203d 3d20 3120 656c 7365 2063  ndex == 1 else c
+00015b90: 5f6f 7574 5f6c 6973 740a 2020 2020 2020  _out_list.      
+00015ba0: 2020 2020 2020 2020 2020 2020 2020 2920                ) 
+00015bb0: 2023 2065 6163 6820 7465 6e73 6f72 2069   # each tensor i
+00015bc0: 6e20 7468 6520 6c69 7374 2069 7320 6f66  n the list is of
+00015bd0: 2073 6861 7065 2028 422c 2032 2a48 290a   shape (B, 2*H).
+00015be0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015bf0: 2020 2020 6c69 7374 5f6f 665f 7465 6e73      list_of_tens
+00015c00: 6f72 735f 746f 5f73 7461 636b 203d 205b  ors_to_stack = [
+00015c10: 5d0a 2020 2020 2020 2020 2020 2020 2020  ].              
+00015c20: 2020 2020 2020 666f 7220 6920 696e 2072        for i in r
+00015c30: 616e 6765 286e 756d 5f6c 6179 6572 7329  ange(num_layers)
+00015c40: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+00015c50: 2020 2020 2020 2020 2020 6f75 7431 2c20            out1, 
+00015c60: 6f75 7432 203d 206d 622e 7370 6c69 7428  out2 = mb.split(
+00015c70: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00015c80: 2020 2020 2020 2020 2020 2020 2078 3d6f               x=o
+00015c90: 7574 5f73 7461 7465 5f74 656e 736f 7273  ut_state_tensors
+00015ca0: 5f6c 6973 745b 695d 2c20 6e75 6d5f 7370  _list[i], num_sp
+00015cb0: 6c69 7473 3d32 2c20 6178 6973 3d31 0a20  lits=2, axis=1. 
+00015cc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015cd0: 2020 2020 2020 2029 2020 2320 6561 6368         )  # each
+00015ce0: 206f 7574 7075 7420 6f66 2073 6861 7065   output of shape
+00015cf0: 205b 422c 2048 5d20 6166 7465 7220 7468   [B, H] after th
+00015d00: 6520 7370 6c69 740a 2020 2020 2020 2020  e split.        
+00015d10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015d20: 6f75 7420 3d20 6d62 2e73 7461 636b 2876  out = mb.stack(v
+00015d30: 616c 7565 733d 5b6f 7574 312c 206f 7574  alues=[out1, out
+00015d40: 325d 2c20 6178 6973 3d30 2920 2023 205b  2], axis=0)  # [
+00015d50: 322c 2042 2c20 485d 0a20 2020 2020 2020  2, B, H].       
+00015d60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015d70: 206c 6973 745f 6f66 5f74 656e 736f 7273   list_of_tensors
+00015d80: 5f74 6f5f 7374 6163 6b2e 6170 7065 6e64  _to_stack.append
+00015d90: 286f 7574 290a 2020 2020 2020 2020 2020  (out).          
+00015da0: 2020 2020 2020 2020 2020 6669 6e61 6c5f            final_
+00015db0: 6f75 7420 3d20 6d62 2e63 6f6e 6361 7428  out = mb.concat(
+00015dc0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00015dd0: 2020 2020 2020 2020 2076 616c 7565 733d           values=
+00015de0: 6c69 7374 5f6f 665f 7465 6e73 6f72 735f  list_of_tensors_
+00015df0: 746f 5f73 7461 636b 2c20 6178 6973 3d30  to_stack, axis=0
+00015e00: 2c20 6e61 6d65 3d6e 616d 650a 2020 2020  , name=name.    
+00015e10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015e20: 2920 2023 206f 7574 7075 7420 6f66 2073  )  # output of s
+00015e30: 6861 7065 2028 6e75 6d5f 6c61 7965 7273  hape (num_layers
+00015e40: 202a 2032 2c20 422c 2048 290a 2020 2020   * 2, B, H).    
+00015e50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015e60: 636f 6e74 6578 742e 6164 6428 6669 6e61  context.add(fina
+00015e70: 6c5f 6f75 742c 206e 616d 6529 0a20 2020  l_out, name).   
+00015e80: 2020 2020 2020 2020 2065 6c73 653a 0a20           else:. 
+00015e90: 2020 2020 2020 2020 2020 2020 2020 2069                 i
+00015ea0: 6620 6e75 6d5f 6c61 7965 7273 203d 3d20  f num_layers == 
+00015eb0: 313a 0a20 2020 2020 2020 2020 2020 2020  1:.             
+00015ec0: 2020 2020 2020 2075 6e73 7175 6565 7a65         unsqueeze
+00015ed0: 203d 206d 622e 6578 7061 6e64 5f64 696d   = mb.expand_dim
+00015ee0: 7328 783d 6f75 7470 7574 2c20 6178 6573  s(x=output, axes
+00015ef0: 3d5b 305d 2c20 6e61 6d65 3d6e 616d 6529  =[0], name=name)
+00015f00: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00015f10: 2020 2020 2063 6f6e 7465 7874 2e61 6464       context.add
+00015f20: 2875 6e73 7175 6565 7a65 2c20 6e61 6d65  (unsqueeze, name
+00015f30: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
+00015f40: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
+00015f50: 2020 2020 2020 2020 2020 2020 6f75 7420              out 
+00015f60: 3d20 6d62 2e73 7461 636b 280a 2020 2020  = mb.stack(.    
+00015f70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015f80: 2020 2020 7661 6c75 6573 3d68 5f6f 7574      values=h_out
+00015f90: 5f6c 6973 7420 6966 2069 6e64 6578 203d  _list if index =
+00015fa0: 3d20 3120 656c 7365 2063 5f6f 7574 5f6c  = 1 else c_out_l
+00015fb0: 6973 742c 0a20 2020 2020 2020 2020 2020  ist,.           
+00015fc0: 2020 2020 2020 2020 2020 2020 2061 7869               axi
+00015fd0: 733d 302c 0a20 2020 2020 2020 2020 2020  s=0,.           
+00015fe0: 2020 2020 2020 2020 2020 2020 206e 616d               nam
+00015ff0: 653d 6e61 6d65 2c0a 2020 2020 2020 2020  e=name,.        
+00016000: 2020 2020 2020 2020 2020 2020 290a 2020              ).  
+00016010: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016020: 2020 636f 6e74 6578 742e 6164 6428 6f75    context.add(ou
+00016030: 742c 206e 616d 6529 0a20 2020 2020 2020  t, name).       
+00016040: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
+00016050: 2020 2069 6620 6261 7463 685f 6669 7273     if batch_firs
+00016060: 743a 0a20 2020 2020 2020 2020 2020 2020  t:.             
+00016070: 2020 206f 7574 7075 7420 3d20 6d62 2e74     output = mb.t
+00016080: 7261 6e73 706f 7365 2878 3d6f 7574 7075  ranspose(x=outpu
+00016090: 742c 2070 6572 6d3d 5b31 2c20 302c 2032  t, perm=[1, 0, 2
+000160a0: 5d2c 206e 616d 653d 6e61 6d65 290a 2020  ], name=name).  
+000160b0: 2020 2020 2020 2020 2020 636f 6e74 6578            contex
+000160c0: 742e 6164 6428 6f75 7470 7574 2c20 6e61  t.add(output, na
+000160d0: 6d65 290a 0a0a 6465 6620 5f67 6574 5f73  me)...def _get_s
+000160e0: 6361 6c65 735f 6672 6f6d 5f6f 7574 7075  cales_from_outpu
+000160f0: 745f 7369 7a65 286f 7574 7075 745f 7369  t_size(output_si
+00016100: 7a65 2c20 696e 7075 745f 7368 6170 6529  ze, input_shape)
+00016110: 3a0a 2020 2020 7363 616c 6573 203d 205b  :.    scales = [
+00016120: 5d0a 2020 2020 6966 206f 7574 7075 745f  ].    if output_
+00016130: 7369 7a65 2069 7320 6e6f 7420 4e6f 6e65  size is not None
+00016140: 3a0a 2020 2020 2020 2020 2320 6f75 7470  :.        # outp
+00016150: 7574 5f73 697a 6520 7769 6c6c 2062 6520  ut_size will be 
+00016160: 6569 7468 6572 0a20 2020 2020 2020 2023  either.        #
+00016170: 2028 3129 2041 206c 6973 7420 6f66 2056   (1) A list of V
+00016180: 6172 2c20 616e 6420 6561 6368 2056 6172  ar, and each Var
+00016190: 2069 6e64 6963 6174 6573 2074 6865 206f   indicates the o
+000161a0: 7574 7075 7420 7369 7a65 2066 6f72 2074  utput size for t
+000161b0: 6861 7420 6469 6d65 6e73 696f 6e0a 2020  hat dimension.  
+000161c0: 2020 2020 2020 2320 2832 2920 4120 7369        # (2) A si
+000161d0: 6e67 6c65 2056 6172 2077 6869 6368 2069  ngle Var which i
+000161e0: 6e64 6963 6174 6573 2074 6865 2077 686f  ndicates the who
+000161f0: 6c65 206f 7574 7075 7420 7369 7a65 0a20  le output size. 
+00016200: 2020 2020 2020 2023 2028 3329 2041 206e         # (3) A n
+00016210: 756d 7079 2061 7272 6179 0a0a 2020 2020  umpy array..    
+00016220: 2020 2020 6966 2069 7369 6e73 7461 6e63      if isinstanc
+00016230: 6528 6f75 7470 7574 5f73 697a 652c 206c  e(output_size, l
+00016240: 6973 7429 3a0a 2020 2020 2020 2020 2020  ist):.          
+00016250: 2020 6f75 7470 7574 5f73 697a 6520 3d20    output_size = 
+00016260: 5b78 2e76 616c 2066 6f72 2078 2069 6e20  [x.val for x in 
+00016270: 6f75 7470 7574 5f73 697a 655d 0a20 2020  output_size].   
+00016280: 2020 2020 2069 6620 6973 696e 7374 616e       if isinstan
+00016290: 6365 286f 7574 7075 745f 7369 7a65 2c20  ce(output_size, 
+000162a0: 5661 7229 3a0a 2020 2020 2020 2020 2020  Var):.          
+000162b0: 2020 6f75 7470 7574 5f73 697a 6520 3d20    output_size = 
+000162c0: 5b78 2066 6f72 2078 2069 6e20 6f75 7470  [x for x in outp
+000162d0: 7574 5f73 697a 652e 7661 6c5d 0a20 2020  ut_size.val].   
+000162e0: 2020 2020 2069 6620 6973 696e 7374 616e       if isinstan
+000162f0: 6365 286f 7574 7075 745f 7369 7a65 2c20  ce(output_size, 
+00016300: 5f6e 702e 6e64 6172 7261 7929 3a0a 2020  _np.ndarray):.  
+00016310: 2020 2020 2020 2020 2020 6f75 7470 7574            output
+00016320: 5f73 697a 6520 3d20 6f75 7470 7574 5f73  _size = output_s
+00016330: 697a 652e 746f 6c69 7374 2829 0a0a 2020  ize.tolist()..  
+00016340: 2020 2020 2020 2320 6f75 7470 7574 2073        # output s
+00016350: 697a 6520 6973 2063 6f6d 7075 7465 6420  ize is computed 
+00016360: 7573 696e 6720 7468 6520 666f 726d 756c  using the formul
+00016370: 6120 666c 6f6f 7220 2873 6361 6c65 202a  a floor (scale *
+00016380: 2069 6e70 7574 5f73 697a 6529 2069 6e20   input_size) in 
+00016390: 436f 7265 204d 4c20 2861 6e64 2050 7954  Core ML (and PyT
+000163a0: 6f72 6368 292e 0a20 2020 2020 2020 2023  orch)..        #
+000163b0: 2054 6875 732c 2077 6865 6e20 636f 6d70   Thus, when comp
+000163c0: 7574 696e 6720 7468 6520 7363 616c 6573  uting the scales
+000163d0: 2066 726f 6d20 7468 6520 6f75 7470 7574   from the output
+000163e0: 2073 697a 652c 2077 6520 6164 6420 6120   size, we add a 
+000163f0: 736d 616c 6c20 706f 7369 7469 7665 2063  small positive c
+00016400: 6f6e 7374 616e 7420 746f 2074 6865 206f  onstant to the o
+00016410: 7574 7075 7420 7369 7a65 0a20 2020 2020  utput size.     
+00016420: 2020 2023 2074 6f20 6d61 6b65 2073 7572     # to make sur
+00016430: 6520 7468 6174 2074 6865 2066 6c6f 6f72  e that the floor
+00016440: 2066 6f72 6d75 6c61 2072 6573 756c 7473   formula results
+00016450: 2069 6e20 7468 6520 636f 7272 6563 7420   in the correct 
+00016460: 6f75 7470 7574 2073 697a 6520 616e 6420  output size and 
+00016470: 6e6f 7420 3120 756e 6974 2073 6d61 6c6c  not 1 unit small
+00016480: 6572 2e0a 2020 2020 2020 2020 2320 466f  er..        # Fo
+00016490: 7220 696e 7374 616e 6365 2c20 6966 206f  r instance, if o
+000164a0: 7574 7075 7420 7369 7a65 203d 2035 2061  utput size = 5 a
+000164b0: 6e64 2069 6e70 7574 2073 697a 6520 3d20  nd input size = 
+000164c0: 322c 2074 6865 6e20 7363 616c 6520 7769  2, then scale wi
+000164d0: 6c6c 2062 6520 322e 352c 2077 6869 6368  ll be 2.5, which
+000164e0: 2063 616e 2067 6574 0a20 2020 2020 2020   can get.       
+000164f0: 2023 2072 6570 7265 7365 6e74 6564 2061   # represented a
+00016500: 7320 322e 3439 3939 3920 6475 6520 746f  s 2.49999 due to
+00016510: 2066 6c6f 6174 2070 7265 6369 7369 6f6e   float precision
+00016520: 2069 7373 7565 732c 2061 6e64 2074 6869   issues, and thi
+00016530: 7320 6d69 6768 7420 7265 7375 6c74 696e  s might resultin
+00016540: 2061 6e20 6f75 7470 7574 2073 697a 6520   an output size 
+00016550: 6f66 2034 0a20 2020 2020 2020 2023 2069  of 4.        # i
+00016560: 6e73 7465 6164 206f 6620 352c 2077 6974  nstead of 5, wit
+00016570: 686f 7574 2074 6865 2065 7073 696c 6f6e  hout the epsilon
+00016580: 2063 6f72 7265 6374 696f 6e2e 0a0a 2020   correction...  
+00016590: 2020 2020 2020 6966 206c 656e 286f 7574        if len(out
+000165a0: 7075 745f 7369 7a65 2920 3d3d 2031 3a0a  put_size) == 1:.
+000165b0: 2020 2020 2020 2020 2020 2020 2320 3164              # 1d
+000165c0: 2075 7073 616d 706c 696e 670a 2020 2020   upsampling.    
+000165d0: 2020 2020 2020 2020 486f 7574 203d 206f          Hout = o
+000165e0: 7574 7075 745f 7369 7a65 5b30 5d0a 2020  utput_size[0].  
+000165f0: 2020 2020 2020 2020 2020 4869 6e20 3d20            Hin = 
+00016600: 696e 7075 745f 7368 6170 655b 2d31 5d0a  input_shape[-1].
+00016610: 2020 2020 2020 2020 2020 2020 7363 616c              scal
+00016620: 6573 5f68 203d 2048 6f75 7420 2f20 4869  es_h = Hout / Hi
+00016630: 6e20 6966 2048 6f75 7420 2520 4869 6e20  n if Hout % Hin 
+00016640: 3d3d 2030 2065 6c73 6520 2848 6f75 7420  == 0 else (Hout 
+00016650: 2b20 3165 2d34 2920 2f20 4869 6e0a 2020  + 1e-4) / Hin.  
+00016660: 2020 2020 2020 2020 2020 7363 616c 6573            scales
+00016670: 203d 2073 6361 6c65 735f 680a 2020 2020   = scales_h.    
+00016680: 2020 2020 656c 6966 206c 656e 286f 7574      elif len(out
+00016690: 7075 745f 7369 7a65 2920 3d3d 2032 3a0a  put_size) == 2:.
+000166a0: 2020 2020 2020 2020 2020 2020 2320 3264              # 2d
+000166b0: 2075 7073 616d 706c 696e 670a 2020 2020   upsampling.    
+000166c0: 2020 2020 2020 2020 486f 7574 2c20 576f          Hout, Wo
+000166d0: 7574 203d 206f 7574 7075 745f 7369 7a65  ut = output_size
+000166e0: 5b30 5d2c 206f 7574 7075 745f 7369 7a65  [0], output_size
+000166f0: 5b31 5d0a 2020 2020 2020 2020 2020 2020  [1].            
+00016700: 4869 6e2c 2057 696e 203d 2069 6e70 7574  Hin, Win = input
+00016710: 5f73 6861 7065 5b2d 325d 2c20 696e 7075  _shape[-2], inpu
+00016720: 745f 7368 6170 655b 2d31 5d0a 2020 2020  t_shape[-1].    
+00016730: 2020 2020 2020 2020 7363 616c 6573 5f68          scales_h
+00016740: 203d 2048 6f75 7420 2f20 4869 6e20 6966   = Hout / Hin if
+00016750: 2048 6f75 7420 2520 4869 6e20 3d3d 2030   Hout % Hin == 0
+00016760: 2065 6c73 6520 2848 6f75 7420 2b20 3165   else (Hout + 1e
+00016770: 2d34 2920 2f20 4869 6e0a 2020 2020 2020  -4) / Hin.      
+00016780: 2020 2020 2020 7363 616c 6573 5f77 203d        scales_w =
+00016790: 2057 6f75 7420 2f20 5769 6e20 6966 2057   Wout / Win if W
+000167a0: 6f75 7420 2520 5769 6e20 3d3d 2030 2065  out % Win == 0 e
+000167b0: 6c73 6520 2857 6f75 7420 2b20 3165 2d34  lse (Wout + 1e-4
+000167c0: 2920 2f20 5769 6e0a 2020 2020 2020 2020  ) / Win.        
+000167d0: 2020 2020 7363 616c 6573 203d 205b 7363      scales = [sc
+000167e0: 616c 6573 5f68 2c20 7363 616c 6573 5f77  ales_h, scales_w
+000167f0: 5d0a 2020 2020 2020 2020 656c 7365 3a0a  ].        else:.
+00016800: 2020 2020 2020 2020 2020 2020 6d73 6720              msg 
+00016810: 3d20 224f 6e6c 7920 3164 2061 6e64 2032  = "Only 1d and 2
+00016820: 6420 756e 7361 6d70 6c69 6e67 2061 7265  d unsampling are
+00016830: 2073 7570 706f 7274 6564 2e22 0a20 2020   supported.".   
+00016840: 2020 2020 2020 2020 2072 6169 7365 204e           raise N
+00016850: 6f74 496d 706c 656d 656e 7465 6445 7272  otImplementedErr
+00016860: 6f72 286d 7367 290a 0a20 2020 2072 6574  or(msg)..    ret
+00016870: 7572 6e20 7363 616c 6573 0a0a 0a64 6566  urn scales...def
+00016880: 205f 6973 5f66 6c6f 6174 5f76 616c 7565   _is_float_value
+00016890: 2878 2c20 7468 7265 7368 6f6c 643d 302e  (x, threshold=0.
+000168a0: 3030 3129 3a0a 2020 2020 7265 7475 726e  001):.    return
+000168b0: 2078 202d 205f 6d61 7468 2e66 6c6f 6f72   x - _math.floor
+000168c0: 2878 2920 3e20 7468 7265 7368 6f6c 640a  (x) > threshold.
+000168d0: 0a0a 4072 6567 6973 7465 725f 746f 7263  ..@register_torc
+000168e0: 685f 6f70 0a64 6566 2075 7073 616d 706c  h_op.def upsampl
+000168f0: 655f 6c69 6e65 6172 3164 2863 6f6e 7465  e_linear1d(conte
+00016900: 7874 2c20 6e6f 6465 293a 0a20 2020 2069  xt, node):.    i
+00016910: 6e70 7574 7320 3d20 5f67 6574 5f69 6e70  nputs = _get_inp
+00016920: 7574 7328 636f 6e74 6578 742c 206e 6f64  uts(context, nod
+00016930: 6529 0a20 2020 2078 203d 2069 6e70 7574  e).    x = input
+00016940: 735b 305d 0a20 2020 206f 7574 7075 745f  s[0].    output_
+00016950: 7369 7a65 203d 2069 6e70 7574 735b 315d  size = inputs[1]
+00016960: 0a20 2020 2061 6c69 676e 5f63 6f72 6e65  .    align_corne
+00016970: 7273 203d 2062 6f6f 6c28 696e 7075 7473  rs = bool(inputs
+00016980: 5b32 5d2e 7661 6c29 0a20 2020 2073 6361  [2].val).    sca
+00016990: 6c65 203d 2069 6e70 7574 735b 335d 0a0a  le = inputs[3]..
+000169a0: 2020 2020 7363 616c 655f 6661 6374 6f72      scale_factor
+000169b0: 203d 204e 6f6e 650a 0a20 2020 2069 6620   = None..    if 
+000169c0: 7363 616c 6520 6973 206e 6f74 204e 6f6e  scale is not Non
+000169d0: 6520 616e 6420 7363 616c 652e 7661 6c20  e and scale.val 
+000169e0: 6973 206e 6f74 204e 6f6e 6520 616e 6420  is not None and 
+000169f0: 7363 616c 652e 7368 6170 6520 3d3d 2028  scale.shape == (
+00016a00: 312c 293a 0a20 2020 2020 2020 2023 2047  1,):.        # G
+00016a10: 6574 2074 6865 2073 6361 6c65 2066 6163  et the scale fac
+00016a20: 746f 7220 6672 6f6d 2070 726f 7669 6465  tor from provide
+00016a30: 6420 696e 7075 7473 0a20 2020 2020 2020  d inputs.       
+00016a40: 2023 2054 6869 7320 6861 7070 656e 7320   # This happens 
+00016a50: 7768 656e 2072 6563 6f6d 7075 7465 5f73  when recompute_s
+00016a60: 6361 6c65 5f66 6163 746f 7220 3d20 4661  cale_factor = Fa
+00016a70: 6c73 650a 2020 2020 2020 2020 7363 616c  lse.        scal
+00016a80: 655f 6661 6374 6f72 203d 2073 6361 6c65  e_factor = scale
+00016a90: 2e76 616c 5b30 5d0a 0a20 2020 2020 2020  .val[0]..       
+00016aa0: 2023 2043 7572 7265 6e74 6c79 2c20 7765   # Currently, we
+00016ab0: 2061 7265 206e 6f74 2073 7570 706f 7274   are not support
+00016ac0: 696e 6720 7265 636f 6d70 7574 655f 7363  ing recompute_sc
+00016ad0: 616c 655f 6661 6374 6f72 203d 2046 616c  ale_factor = Fal
+00016ae0: 7365 2c20 616c 6967 6e5f 636f 726e 6572  se, align_corner
+00016af0: 7320 3d20 4661 6c73 6520 7769 7468 2066  s = False with f
+00016b00: 6c6f 6174 206f 7574 7075 7420 7369 7a65  loat output size
+00016b10: 0a20 2020 2020 2020 205f 2c20 5f2c 2068  .        _, _, h
+00016b20: 203d 2078 2e73 6861 7065 0a20 2020 2020   = x.shape.     
+00016b30: 2020 2069 6620 6e6f 7420 6973 5f73 796d     if not is_sym
+00016b40: 626f 6c69 6328 6829 3a0a 2020 2020 2020  bolic(h):.      
+00016b50: 2020 2020 2020 2320 466f 7220 7468 6520        # For the 
+00016b60: 7374 6174 6963 2069 6e70 7574 2073 6861  static input sha
+00016b70: 7065 2c20 7765 2063 616e 2063 6f6d 7075  pe, we can compu
+00016b80: 7465 2074 6865 206f 7574 7075 7420 7369  te the output si
+00016b90: 7a65 2062 6566 6f72 6568 616e 642c 2061  ze beforehand, a
+00016ba0: 6e64 2063 6865 636b 2069 6620 6974 2069  nd check if it i
+00016bb0: 7320 6120 666c 6f61 7420 7661 6c75 650a  s a float value.
+00016bc0: 2020 2020 2020 2020 2020 2020 6f75 7470              outp
+00016bd0: 7574 5f73 697a 6520 3d20 6820 2a20 7363  ut_size = h * sc
+00016be0: 616c 655f 6661 6374 6f72 0a20 2020 2020  ale_factor.     
+00016bf0: 2020 2020 2020 2069 735f 666c 6f61 7420         is_float 
+00016c00: 3d20 5f69 735f 666c 6f61 745f 7661 6c75  = _is_float_valu
+00016c10: 6528 6f75 7470 7574 5f73 697a 6529 0a20  e(output_size). 
+00016c20: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
+00016c30: 2020 2020 2020 2020 2023 2046 6f72 2074           # For t
+00016c40: 6865 2064 796e 616d 6963 2069 6e70 7574  he dynamic input
+00016c50: 2073 6861 7065 2c20 7765 2063 6865 636b   shape, we check
+00016c60: 2069 6620 7468 6520 7363 616c 6520 6661   if the scale fa
+00016c70: 6374 6f72 2069 7473 656c 6620 6973 2066  ctor itself is f
+00016c80: 6c6f 6174 0a20 2020 2020 2020 2020 2020  loat.           
+00016c90: 2069 735f 666c 6f61 7420 3d20 5f69 735f   is_float = _is_
+00016ca0: 666c 6f61 745f 7661 6c75 6528 7363 616c  float_value(scal
+00016cb0: 655f 6661 6374 6f72 290a 0a20 2020 2020  e_factor)..     
+00016cc0: 2020 2069 6620 6973 5f66 6c6f 6174 2061     if is_float a
+00016cd0: 6e64 206e 6f74 2061 6c69 676e 5f63 6f72  nd not align_cor
+00016ce0: 6e65 7273 3a0a 2020 2020 2020 2020 2020  ners:.          
+00016cf0: 2020 6d73 6720 3d20 280a 2020 2020 2020    msg = (.      
+00016d00: 2020 2020 2020 2020 2020 2272 6563 6f6d            "recom
+00016d10: 7075 7465 5f73 6361 6c65 5f66 6163 746f  pute_scale_facto
+00016d20: 7220 3d20 4661 6c73 652c 2061 6c69 676e  r = False, align
+00016d30: 5f63 6f72 6e65 7273 203d 2046 616c 7365  _corners = False
+00016d40: 2077 6974 6820 666c 6f61 7420 6f75 7470   with float outp
+00016d50: 7574 2073 697a 6520 6973 2022 0a20 2020  ut size is ".   
+00016d60: 2020 2020 2020 2020 2020 2020 202b 2022               + "
+00016d70: 6e6f 7420 7375 7070 6f72 7465 6420 666f  not supported fo
+00016d80: 7220 7468 6520 7570 7361 6d70 6c65 206f  r the upsample o
+00016d90: 7020 7b7d 222e 666f 726d 6174 286e 6f64  p {}".format(nod
+00016da0: 652e 6e61 6d65 290a 2020 2020 2020 2020  e.name).        
+00016db0: 2020 2020 290a 2020 2020 2020 2020 2020      ).          
+00016dc0: 2020 7261 6973 6520 4e6f 7449 6d70 6c65    raise NotImple
+00016dd0: 6d65 6e74 6564 4572 726f 7228 6d73 6729  mentedError(msg)
+00016de0: 0a0a 2020 2020 656c 6966 2069 7369 6e73  ..    elif isins
+00016df0: 7461 6e63 6528 6f75 7470 7574 5f73 697a  tance(output_siz
+00016e00: 652c 206c 6973 7429 3a0a 2020 2020 2020  e, list):.      
+00016e10: 2020 2320 5768 656e 2074 6865 2069 6e70    # When the inp
+00016e20: 7574 2073 6861 7065 2069 7320 6479 6e61  ut shape is dyna
+00016e30: 6d69 6320 616e 6420 7265 636f 6d70 7574  mic and recomput
+00016e40: 655f 7363 616c 655f 6661 6374 6f72 203d  e_scale_factor =
+00016e50: 2054 7275 652c 0a20 2020 2020 2020 2023   True,.        #
+00016e60: 2077 6520 6e65 6564 2074 6f20 7472 6163   we need to trac
+00016e70: 6520 7468 6520 6772 6170 6820 746f 2066  e the graph to f
+00016e80: 696e 6420 7468 6520 7363 616c 6520 6661  ind the scale fa
+00016e90: 6374 6f72 2e0a 2020 2020 2020 2020 7820  ctor..        x 
+00016ea0: 3d20 6d62 2e65 7870 616e 645f 6469 6d73  = mb.expand_dims
+00016eb0: 2878 3d78 2c20 6178 6573 3d5b 335d 290a  (x=x, axes=[3]).
+00016ec0: 2020 2020 2020 2020 7820 3d20 6d62 2e74          x = mb.t
+00016ed0: 6f72 6368 5f75 7073 616d 706c 655f 6269  orch_upsample_bi
+00016ee0: 6c69 6e65 6172 280a 2020 2020 2020 2020  linear(.        
+00016ef0: 2020 2020 783d 782c 0a20 2020 2020 2020      x=x,.       
+00016f00: 2020 2020 206f 7574 7075 745f 6865 6967       output_heig
+00016f10: 6874 3d6f 7574 7075 745f 7369 7a65 5b30  ht=output_size[0
+00016f20: 5d2c 0a20 2020 2020 2020 2020 2020 206f  ],.            o
+00016f30: 7574 7075 745f 7769 6474 683d 312c 0a20  utput_width=1,. 
+00016f40: 2020 2020 2020 2020 2020 2061 6c69 676e             align
+00016f50: 5f63 6f72 6e65 7273 3d61 6c69 676e 5f63  _corners=align_c
+00016f60: 6f72 6e65 7273 2c0a 2020 2020 2020 2020  orners,.        
+00016f70: 290a 2020 2020 2020 2020 7820 3d20 6d62  ).        x = mb
+00016f80: 2e73 7175 6565 7a65 2878 3d78 2c20 6178  .squeeze(x=x, ax
+00016f90: 6573 3d5b 335d 2c20 6e61 6d65 3d6e 6f64  es=[3], name=nod
+00016fa0: 652e 6e61 6d65 290a 2020 2020 2020 2020  e.name).        
+00016fb0: 636f 6e74 6578 742e 6164 6428 7829 0a20  context.add(x). 
+00016fc0: 2020 2020 2020 2072 6574 7572 6e0a 0a20         return.. 
+00016fd0: 2020 2065 6c69 6620 6f75 7470 7574 5f73     elif output_s
+00016fe0: 697a 652e 7661 6c20 6973 206e 6f74 204e  ize.val is not N
+00016ff0: 6f6e 653a 0a20 2020 2020 2020 2023 2049  one:.        # I
+00017000: 6e66 6572 2074 6865 2073 6361 6c65 2066  nfer the scale f
+00017010: 6163 746f 7220 6672 6f6d 2074 6865 2070  actor from the p
+00017020: 726f 7669 6465 6420 6f75 7470 7574 2073  rovided output s
+00017030: 697a 650a 2020 2020 2020 2020 7363 616c  ize.        scal
+00017040: 655f 6661 6374 6f72 203d 205f 6765 745f  e_factor = _get_
+00017050: 7363 616c 6573 5f66 726f 6d5f 6f75 7470  scales_from_outp
+00017060: 7574 5f73 697a 6528 6f75 7470 7574 5f73  ut_size(output_s
+00017070: 697a 652c 2078 2e73 6861 7065 290a 0a20  ize, x.shape).. 
+00017080: 2020 2023 2045 7870 616e 6420 7468 6520     # Expand the 
+00017090: 696e 7075 7420 746f 2061 2034 6420 7465  input to a 4d te
+000170a0: 6e73 6f72 2c20 616e 6420 7573 6520 4d49  nsor, and use MI
+000170b0: 4c27 7320 7570 7361 6d70 6c65 5f62 696c  L's upsample_bil
+000170c0: 696e 6561 7220 6f70 0a20 2020 2078 203d  inear op.    x =
+000170d0: 206d 622e 6578 7061 6e64 5f64 696d 7328   mb.expand_dims(
+000170e0: 783d 782c 2061 7865 733d 5b33 5d29 0a20  x=x, axes=[3]). 
+000170f0: 2020 2078 203d 206d 622e 7570 7361 6d70     x = mb.upsamp
+00017100: 6c65 5f62 696c 696e 6561 7228 0a20 2020  le_bilinear(.   
+00017110: 2020 2020 2078 3d78 2c0a 2020 2020 2020       x=x,.      
+00017120: 2020 7363 616c 655f 6661 6374 6f72 5f68    scale_factor_h
+00017130: 6569 6768 743d 7363 616c 655f 6661 6374  eight=scale_fact
+00017140: 6f72 2c0a 2020 2020 2020 2020 7363 616c  or,.        scal
+00017150: 655f 6661 6374 6f72 5f77 6964 7468 3d31  e_factor_width=1
+00017160: 2e2c 0a20 2020 2020 2020 2061 6c69 676e  .,.        align
+00017170: 5f63 6f72 6e65 7273 3d61 6c69 676e 5f63  _corners=align_c
+00017180: 6f72 6e65 7273 2c0a 2020 2020 290a 2020  orners,.    ).  
+00017190: 2020 7820 3d20 6d62 2e73 7175 6565 7a65    x = mb.squeeze
+000171a0: 2878 3d78 2c20 6178 6573 3d5b 335d 2c20  (x=x, axes=[3], 
+000171b0: 6e61 6d65 3d6e 6f64 652e 6e61 6d65 290a  name=node.name).
+000171c0: 2020 2020 636f 6e74 6578 742e 6164 6428      context.add(
+000171d0: 7829 0a0a 0a40 7265 6769 7374 6572 5f74  x)...@register_t
+000171e0: 6f72 6368 5f6f 700a 6465 6620 7570 7361  orch_op.def upsa
+000171f0: 6d70 6c65 5f62 696c 696e 6561 7232 6428  mple_bilinear2d(
+00017200: 636f 6e74 6578 742c 206e 6f64 6529 3a0a  context, node):.
+00017210: 2020 2020 696e 7075 7473 203d 205f 6765      inputs = _ge
+00017220: 745f 696e 7075 7473 2863 6f6e 7465 7874  t_inputs(context
+00017230: 2c20 6e6f 6465 290a 2020 2020 5f69 6e70  , node).    _inp
+00017240: 7574 203d 2069 6e70 7574 735b 305d 0a20  ut = inputs[0]. 
+00017250: 2020 206f 7574 7075 745f 7369 7a65 203d     output_size =
+00017260: 2069 6e70 7574 735b 315d 0a20 2020 2061   inputs[1].    a
+00017270: 6c69 676e 5f63 6f72 6e65 7273 203d 2062  lign_corners = b
+00017280: 6f6f 6c28 696e 7075 7473 5b32 5d2e 7661  ool(inputs[2].va
+00017290: 6c29 0a20 2020 2073 6361 6c65 5f66 6163  l).    scale_fac
+000172a0: 746f 7273 203d 2069 6e70 7574 735b 335d  tors = inputs[3]
+000172b0: 0a0a 2020 2020 7363 616c 6573 5f68 2c20  ..    scales_h, 
+000172c0: 7363 616c 6573 5f77 203d 204e 6f6e 652c  scales_w = None,
+000172d0: 204e 6f6e 650a 0a20 2020 2069 6620 280a   None..    if (.
+000172e0: 2020 2020 2020 2020 7363 616c 655f 6661          scale_fa
+000172f0: 6374 6f72 7320 6973 206e 6f74 204e 6f6e  ctors is not Non
+00017300: 650a 2020 2020 2020 2020 616e 6420 7363  e.        and sc
+00017310: 616c 655f 6661 6374 6f72 732e 7661 6c20  ale_factors.val 
+00017320: 6973 206e 6f74 204e 6f6e 650a 2020 2020  is not None.    
+00017330: 2020 2020 616e 6420 7363 616c 655f 6661      and scale_fa
+00017340: 6374 6f72 732e 7261 6e6b 203d 3d20 310a  ctors.rank == 1.
+00017350: 2020 2020 2020 2020 616e 6420 7363 616c          and scal
+00017360: 655f 6661 6374 6f72 732e 7368 6170 655b  e_factors.shape[
+00017370: 305d 203d 3d20 320a 2020 2020 293a 0a20  0] == 2.    ):. 
+00017380: 2020 2020 2020 2023 2067 6574 2073 6361         # get sca
+00017390: 6c65 2066 6163 746f 7273 2066 726f 6d20  le factors from 
+000173a0: 7072 6f76 6964 6564 2069 6e70 7574 730a  provided inputs.
+000173b0: 2020 2020 2020 2020 2320 7468 6973 2068          # this h
+000173c0: 6170 7065 6e73 2077 6865 6e20 7265 636f  appens when reco
+000173d0: 6d70 7574 655f 7363 616c 655f 6661 6374  mpute_scale_fact
+000173e0: 6f72 203d 2046 616c 7365 0a20 2020 2020  or = False.     
+000173f0: 2020 2073 6361 6c65 5f66 6163 746f 7273     scale_factors
+00017400: 203d 2073 6361 6c65 5f66 6163 746f 7273   = scale_factors
+00017410: 2e76 616c 0a20 2020 2020 2020 2073 6361  .val.        sca
+00017420: 6c65 735f 6820 3d20 7363 616c 655f 6661  les_h = scale_fa
+00017430: 6374 6f72 735b 305d 0a20 2020 2020 2020  ctors[0].       
+00017440: 2073 6361 6c65 735f 7720 3d20 7363 616c   scales_w = scal
+00017450: 655f 6661 6374 6f72 735b 315d 0a0a 2020  e_factors[1]..  
+00017460: 2020 2020 2020 2320 6375 7272 656e 746c        # currentl
+00017470: 792c 2077 6520 6172 6520 6e6f 7420 7375  y, we are not su
+00017480: 7070 6f72 7469 6e67 2072 6563 6f6d 7075  pporting recompu
+00017490: 7465 5f73 6361 6c65 5f66 6163 746f 7220  te_scale_factor 
+000174a0: 3d20 4661 6c73 652c 2061 6c69 676e 5f63  = False, align_c
+000174b0: 6f72 6e65 7273 203d 2046 616c 7365 2077  orners = False w
+000174c0: 6974 6820 666c 6f61 7420 6f75 7470 7574  ith float output
+000174d0: 2073 697a 650a 2020 2020 2020 2020 5f2c   size.        _,
+000174e0: 205f 2c20 682c 2077 203d 205f 696e 7075   _, h, w = _inpu
+000174f0: 742e 7368 6170 650a 2020 2020 2020 2020  t.shape.        
+00017500: 6966 206e 6f74 2069 735f 7379 6d62 6f6c  if not is_symbol
+00017510: 6963 2868 2920 616e 6420 6e6f 7420 6973  ic(h) and not is
+00017520: 5f73 796d 626f 6c69 6328 7729 3a0a 2020  _symbolic(w):.  
+00017530: 2020 2020 2020 2020 2020 2320 466f 7220            # For 
+00017540: 7468 6520 7374 6174 6963 2069 6e70 7574  the static input
+00017550: 2073 6861 7065 2c20 7765 2063 616e 2063   shape, we can c
+00017560: 6f6d 7075 7465 2074 6865 206f 7574 7075  ompute the outpu
+00017570: 7420 7369 7a65 2062 6566 6f72 6568 616e  t size beforehan
+00017580: 640a 2020 2020 2020 2020 2020 2020 6f75  d.            ou
+00017590: 7470 7574 5f68 203d 2068 202a 2073 6361  tput_h = h * sca
+000175a0: 6c65 735f 680a 2020 2020 2020 2020 2020  les_h.          
+000175b0: 2020 6f75 7470 7574 5f77 203d 2077 202a    output_w = w *
+000175c0: 2073 6361 6c65 735f 770a 2020 2020 2020   scales_w.      
+000175d0: 2020 2020 2020 6973 5f68 5f66 6c6f 6174        is_h_float
+000175e0: 203d 205f 6973 5f66 6c6f 6174 5f76 616c   = _is_float_val
+000175f0: 7565 286f 7574 7075 745f 6829 0a20 2020  ue(output_h).   
+00017600: 2020 2020 2020 2020 2069 735f 775f 666c           is_w_fl
+00017610: 6f61 7420 3d20 5f69 735f 666c 6f61 745f  oat = _is_float_
+00017620: 7661 6c75 6528 6f75 7470 7574 5f77 290a  value(output_w).
+00017630: 0a20 2020 2020 2020 2065 6c73 653a 0a20  .        else:. 
+00017640: 2020 2020 2020 2020 2020 2023 2046 6f72             # For
+00017650: 2074 6865 2064 796e 616d 6963 2069 6e70   the dynamic inp
+00017660: 7574 2073 6861 7065 2c20 7765 2063 6865  ut shape, we che
+00017670: 636b 2069 6620 7468 6520 7363 616c 6520  ck if the scale 
+00017680: 6661 6374 6f72 2069 7473 656c 6620 6973  factor itself is
+00017690: 2066 6c6f 6174 0a20 2020 2020 2020 2020   float.         
+000176a0: 2020 2069 735f 685f 666c 6f61 7420 3d20     is_h_float = 
+000176b0: 5f69 735f 666c 6f61 745f 7661 6c75 6528  _is_float_value(
+000176c0: 7363 616c 6573 5f68 290a 2020 2020 2020  scales_h).      
+000176d0: 2020 2020 2020 6973 5f77 5f66 6c6f 6174        is_w_float
+000176e0: 203d 205f 6973 5f66 6c6f 6174 5f76 616c   = _is_float_val
+000176f0: 7565 2873 6361 6c65 735f 7729 0a0a 2020  ue(scales_w)..  
+00017700: 2020 2020 2020 6966 2028 6973 5f68 5f66        if (is_h_f
+00017710: 6c6f 6174 206f 7220 6973 5f77 5f66 6c6f  loat or is_w_flo
+00017720: 6174 2920 616e 6420 6e6f 7420 616c 6967  at) and not alig
+00017730: 6e5f 636f 726e 6572 733a 0a20 2020 2020  n_corners:.     
+00017740: 2020 2020 2020 206d 7367 203d 2028 0a20         msg = (. 
+00017750: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+00017760: 7265 636f 6d70 7574 655f 7363 616c 655f  recompute_scale_
+00017770: 6661 6374 6f72 203d 2046 616c 7365 2c20  factor = False, 
+00017780: 616c 6967 6e5f 636f 726e 6572 7320 3d20  align_corners = 
+00017790: 4661 6c73 6520 7769 7468 2066 6c6f 6174  False with float
+000177a0: 206f 7574 7075 7420 7369 7a65 2069 7320   output size is 
+000177b0: 220a 2020 2020 2020 2020 2020 2020 2020  ".              
+000177c0: 2020 2b20 226e 6f74 2073 7570 706f 7274    + "not support
+000177d0: 6564 2066 6f72 2074 6865 2075 7073 616d  ed for the upsam
+000177e0: 706c 6520 6f70 207b 7d22 2e66 6f72 6d61  ple op {}".forma
+000177f0: 7428 6e6f 6465 2e6e 616d 6529 0a20 2020  t(node.name).   
+00017800: 2020 2020 2020 2020 2029 0a20 2020 2020           ).     
+00017810: 2020 2020 2020 2072 6169 7365 204e 6f74         raise Not
+00017820: 496d 706c 656d 656e 7465 6445 7272 6f72  ImplementedError
+00017830: 286d 7367 290a 0a20 2020 2065 6c69 6620  (msg)..    elif 
+00017840: 280a 2020 2020 2020 2020 6973 696e 7374  (.        isinst
+00017850: 616e 6365 286f 7574 7075 745f 7369 7a65  ance(output_size
+00017860: 2c20 6c69 7374 290a 2020 2020 2020 2020  , list).        
+00017870: 616e 6420 6f75 7470 7574 5f73 697a 655b  and output_size[
+00017880: 305d 2e76 616c 2069 7320 4e6f 6e65 0a20  0].val is None. 
+00017890: 2020 2020 2020 2061 6e64 206f 7574 7075         and outpu
+000178a0: 745f 7369 7a65 5b31 5d2e 7661 6c20 6973  t_size[1].val is
+000178b0: 204e 6f6e 650a 2020 2020 293a 0a20 2020   None.    ):.   
+000178c0: 2020 2020 2023 2074 6865 2069 6e70 7574       # the input
+000178d0: 2073 6861 7065 2069 7320 6479 6e61 6d69   shape is dynami
+000178e0: 6320 616e 6420 7265 636f 6d70 7574 655f  c and recompute_
+000178f0: 7363 616c 655f 6661 6374 6f72 203d 2054  scale_factor = T
+00017900: 7275 650a 2020 2020 2020 2020 2320 6e65  rue.        # ne
+00017910: 6564 2074 6f20 7472 6163 6520 7468 6520  ed to trace the 
+00017920: 6772 6170 6820 746f 2066 696e 6420 7468  graph to find th
+00017930: 6520 7363 616c 6520 6661 6374 6f72 0a20  e scale factor. 
+00017940: 2020 2020 2020 2023 2077 6520 6465 6669         # we defi
+00017950: 6e65 2061 2074 6f72 6368 2066 726f 6e74  ne a torch front
+00017960: 2065 6e64 206f 7020 6d62 2e74 6f72 6368   end op mb.torch
+00017970: 5f75 7073 616d 706c 655f 6269 6c69 6e65  _upsample_biline
+00017980: 6172 2074 6f20 7265 736f 6c76 6520 7468  ar to resolve th
+00017990: 6520 636f 6e73 7420 7363 616c 696e 6720  e const scaling 
+000179a0: 6661 6374 6f72 0a20 2020 2020 2020 2074  factor.        t
+000179b0: 6f72 6368 5f75 7073 616d 706c 655f 6269  orch_upsample_bi
+000179c0: 6c69 6e65 6172 203d 206d 622e 746f 7263  linear = mb.torc
+000179d0: 685f 7570 7361 6d70 6c65 5f62 696c 696e  h_upsample_bilin
+000179e0: 6561 7228 0a20 2020 2020 2020 2020 2020  ear(.           
+000179f0: 2078 3d5f 696e 7075 742c 0a20 2020 2020   x=_input,.     
+00017a00: 2020 2020 2020 206f 7574 7075 745f 6865         output_he
+00017a10: 6967 6874 3d6f 7574 7075 745f 7369 7a65  ight=output_size
+00017a20: 5b30 5d2c 0a20 2020 2020 2020 2020 2020  [0],.           
+00017a30: 206f 7574 7075 745f 7769 6474 683d 6f75   output_width=ou
+00017a40: 7470 7574 5f73 697a 655b 315d 2c0a 2020  tput_size[1],.  
+00017a50: 2020 2020 2020 2020 2020 616c 6967 6e5f            align_
+00017a60: 636f 726e 6572 733d 616c 6967 6e5f 636f  corners=align_co
+00017a70: 726e 6572 732c 0a20 2020 2020 2020 2020  rners,.         
+00017a80: 2020 206e 616d 653d 6e6f 6465 2e6e 616d     name=node.nam
+00017a90: 652c 0a20 2020 2020 2020 2029 0a20 2020  e,.        ).   
+00017aa0: 2020 2020 2063 6f6e 7465 7874 2e61 6464       context.add
+00017ab0: 2874 6f72 6368 5f75 7073 616d 706c 655f  (torch_upsample_
+00017ac0: 6269 6c69 6e65 6172 290a 2020 2020 2020  bilinear).      
+00017ad0: 2020 7265 7475 726e 0a20 2020 2065 6c73    return.    els
+00017ae0: 653a 0a20 2020 2020 2020 2023 2069 6e66  e:.        # inf
+00017af0: 6572 2073 6361 6c65 2066 6163 746f 7273  er scale factors
+00017b00: 2066 726f 6d20 6f75 7470 7574 2073 697a   from output siz
+00017b10: 6573 0a20 2020 2020 2020 2023 2054 6869  es.        # Thi
+00017b20: 7320 6861 7070 656e 7320 7768 656e 2072  s happens when r
+00017b30: 6563 6f6d 7075 7465 5f73 6361 6c65 5f66  ecompute_scale_f
+00017b40: 6163 746f 7220 3d20 5472 7565 206f 7220  actor = True or 
+00017b50: 7468 6520 6f75 7470 7574 5f73 697a 6520  the output_size 
+00017b60: 6973 2073 7065 6369 6669 6564 0a20 2020  is specified.   
+00017b70: 2020 2020 2073 6361 6c65 7320 3d20 5f67       scales = _g
+00017b80: 6574 5f73 6361 6c65 735f 6672 6f6d 5f6f  et_scales_from_o
+00017b90: 7574 7075 745f 7369 7a65 286f 7574 7075  utput_size(outpu
+00017ba0: 745f 7369 7a65 2c20 5f69 6e70 7574 2e73  t_size, _input.s
+00017bb0: 6861 7065 290a 2020 2020 2020 2020 6966  hape).        if
+00017bc0: 2073 6361 6c65 733a 0a20 2020 2020 2020   scales:.       
+00017bd0: 2020 2020 2073 6361 6c65 735f 682c 2073       scales_h, s
+00017be0: 6361 6c65 735f 7720 3d20 7363 616c 6573  cales_w = scales
+00017bf0: 0a0a 2020 2020 6966 2073 6361 6c65 735f  ..    if scales_
+00017c00: 6820 6973 204e 6f6e 6520 6f72 2073 6361  h is None or sca
+00017c10: 6c65 735f 7720 6973 204e 6f6e 653a 0a20  les_w is None:. 
+00017c20: 2020 2020 2020 2069 6620 6c65 6e28 696e         if len(in
+00017c30: 7075 7473 2920 3d3d 2035 3a0a 2020 2020  puts) == 5:.    
+00017c40: 2020 2020 2020 2020 2320 466f 7220 746f          # For to
+00017c50: 7263 683d 3d31 2e35 2e30 2c20 7570 7361  rch==1.5.0, upsa
+00017c60: 6d70 6c65 5f62 696c 696e 6561 7232 6420  mple_bilinear2d 
+00017c70: 6861 7320 3520 696e 7075 7473 2e0a 2020  has 5 inputs..  
+00017c80: 2020 2020 2020 2020 2020 7363 616c 6573            scales
+00017c90: 5f68 203d 2069 6e70 7574 735b 335d 0a20  _h = inputs[3]. 
+00017ca0: 2020 2020 2020 2020 2020 2073 6361 6c65             scale
+00017cb0: 735f 7720 3d20 696e 7075 7473 5b34 5d0a  s_w = inputs[4].
+00017cc0: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
+00017cd0: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
+00017ce0: 5661 6c75 6545 7272 6f72 2822 4661 696c  ValueError("Fail
+00017cf0: 6564 2074 6f20 696e 6665 7220 7363 616c  ed to infer scal
+00017d00: 6520 6661 6374 6f72 7320 6672 6f6d 2069  e factors from i
+00017d10: 6e70 7574 732e 2229 0a0a 2020 2020 7570  nputs.")..    up
+00017d20: 7361 6d70 6c65 5f62 696c 696e 6561 7220  sample_bilinear 
+00017d30: 3d20 6d62 2e75 7073 616d 706c 655f 6269  = mb.upsample_bi
+00017d40: 6c69 6e65 6172 280a 2020 2020 2020 2020  linear(.        
+00017d50: 783d 5f69 6e70 7574 2c0a 2020 2020 2020  x=_input,.      
+00017d60: 2020 7363 616c 655f 6661 6374 6f72 5f68    scale_factor_h
+00017d70: 6569 6768 743d 7363 616c 6573 5f68 2c0a  eight=scales_h,.
+00017d80: 2020 2020 2020 2020 7363 616c 655f 6661          scale_fa
+00017d90: 6374 6f72 5f77 6964 7468 3d73 6361 6c65  ctor_width=scale
+00017da0: 735f 772c 0a20 2020 2020 2020 2061 6c69  s_w,.        ali
+00017db0: 676e 5f63 6f72 6e65 7273 3d61 6c69 676e  gn_corners=align
+00017dc0: 5f63 6f72 6e65 7273 2c0a 2020 2020 2020  _corners,.      
+00017dd0: 2020 6e61 6d65 3d6e 6f64 652e 6e61 6d65    name=node.name
+00017de0: 2c0a 2020 2020 290a 2020 2020 636f 6e74  ,.    ).    cont
+00017df0: 6578 742e 6164 6428 7570 7361 6d70 6c65  ext.add(upsample
+00017e00: 5f62 696c 696e 6561 7229 0a0a 0a40 7265  _bilinear)...@re
+00017e10: 6769 7374 6572 5f74 6f72 6368 5f6f 700a  gister_torch_op.
+00017e20: 6465 6620 7570 7361 6d70 6c65 5f6e 6561  def upsample_nea
+00017e30: 7265 7374 3164 2863 6f6e 7465 7874 2c20  rest1d(context, 
+00017e40: 6e6f 6465 293a 0a20 2020 2069 6e70 7574  node):.    input
+00017e50: 7320 3d20 5f67 6574 5f69 6e70 7574 7328  s = _get_inputs(
+00017e60: 636f 6e74 6578 742c 206e 6f64 6529 0a20  context, node). 
+00017e70: 2020 2078 203d 2069 6e70 7574 735b 305d     x = inputs[0]
+00017e80: 0a20 2020 206f 7574 7075 745f 7369 7a65  .    output_size
+00017e90: 203d 2069 6e70 7574 735b 315d 0a20 2020   = inputs[1].   
+00017ea0: 2073 6361 6c65 203d 2069 6e70 7574 735b   scale = inputs[
+00017eb0: 325d 0a0a 2020 2020 7363 616c 655f 6661  2]..    scale_fa
+00017ec0: 6374 6f72 203d 204e 6f6e 650a 0a20 2020  ctor = None..   
+00017ed0: 2069 6620 7363 616c 6520 6973 206e 6f74   if scale is not
+00017ee0: 204e 6f6e 6520 616e 6420 7363 616c 652e   None and scale.
+00017ef0: 7661 6c20 6973 206e 6f74 204e 6f6e 6520  val is not None 
+00017f00: 616e 6420 7363 616c 652e 7368 6170 6520  and scale.shape 
+00017f10: 3d3d 2028 312c 293a 0a20 2020 2020 2020  == (1,):.       
+00017f20: 2023 2047 6574 2074 6865 2073 6361 6c65   # Get the scale
+00017f30: 2066 6163 746f 7220 6672 6f6d 2070 726f   factor from pro
+00017f40: 7669 6465 6420 696e 7075 7473 0a20 2020  vided inputs.   
+00017f50: 2020 2020 2023 2054 6869 7320 6861 7070       # This happ
+00017f60: 656e 7320 7768 656e 2072 6563 6f6d 7075  ens when recompu
+00017f70: 7465 5f73 6361 6c65 5f66 6163 746f 7220  te_scale_factor 
+00017f80: 3d20 4661 6c73 650a 2020 2020 2020 2020  = False.        
+00017f90: 7363 616c 655f 6661 6374 6f72 203d 2073  scale_factor = s
+00017fa0: 6361 6c65 2e76 616c 5b30 5d0a 0a20 2020  cale.val[0]..   
+00017fb0: 2065 6c69 6620 6973 696e 7374 616e 6365   elif isinstance
+00017fc0: 286f 7574 7075 745f 7369 7a65 2c20 6c69  (output_size, li
+00017fd0: 7374 293a 0a20 2020 2020 2020 2023 2057  st):.        # W
+00017fe0: 6865 6e20 7468 6520 696e 7075 7420 7368  hen the input sh
+00017ff0: 6170 6520 6973 2064 796e 616d 6963 2061  ape is dynamic a
+00018000: 6e64 2072 6563 6f6d 7075 7465 5f73 6361  nd recompute_sca
+00018010: 6c65 5f66 6163 746f 7220 3d20 5472 7565  le_factor = True
+00018020: 2c0a 2020 2020 2020 2020 2320 7765 206e  ,.        # we n
+00018030: 6565 6420 746f 2074 7261 6365 2074 6865  eed to trace the
+00018040: 2067 7261 7068 2074 6f20 6669 6e64 2074   graph to find t
+00018050: 6865 2073 6361 6c65 2066 6163 746f 722e  he scale factor.
+00018060: 0a20 2020 2020 2020 2078 203d 206d 622e  .        x = mb.
+00018070: 6578 7061 6e64 5f64 696d 7328 783d 782c  expand_dims(x=x,
+00018080: 2061 7865 733d 5b33 5d29 0a20 2020 2020   axes=[3]).     
+00018090: 2020 2078 203d 206d 622e 746f 7263 685f     x = mb.torch_
+000180a0: 7570 7361 6d70 6c65 5f6e 6561 7265 7374  upsample_nearest
+000180b0: 5f6e 6569 6768 626f 7228 0a20 2020 2020  _neighbor(.     
+000180c0: 2020 2020 2020 2078 3d78 2c0a 2020 2020         x=x,.    
+000180d0: 2020 2020 2020 2020 6f75 7470 7574 5f68          output_h
+000180e0: 6569 6768 743d 6f75 7470 7574 5f73 697a  eight=output_siz
+000180f0: 655b 305d 2c0a 2020 2020 2020 2020 2020  e[0],.          
+00018100: 2020 6f75 7470 7574 5f77 6964 7468 3d31    output_width=1
+00018110: 2c0a 2020 2020 2020 2020 290a 2020 2020  ,.        ).    
+00018120: 2020 2020 7820 3d20 6d62 2e73 7175 6565      x = mb.squee
+00018130: 7a65 2878 3d78 2c20 6178 6573 3d5b 335d  ze(x=x, axes=[3]
+00018140: 2c20 6e61 6d65 3d6e 6f64 652e 6e61 6d65  , name=node.name
+00018150: 290a 2020 2020 2020 2020 636f 6e74 6578  ).        contex
+00018160: 742e 6164 6428 7829 0a20 2020 2020 2020  t.add(x).       
+00018170: 2072 6574 7572 6e0a 2020 2020 656c 7365   return.    else
+00018180: 3a0a 2020 2020 2020 2020 2320 496e 6665  :.        # Infe
+00018190: 7220 7363 616c 6520 6661 6374 6f72 7320  r scale factors 
+000181a0: 6672 6f6d 206f 7574 7075 7420 7369 7a65  from output size
+000181b0: 730a 2020 2020 2020 2020 7363 616c 655f  s.        scale_
+000181c0: 6661 6374 6f72 203d 205f 6765 745f 7363  factor = _get_sc
+000181d0: 616c 6573 5f66 726f 6d5f 6f75 7470 7574  ales_from_output
+000181e0: 5f73 697a 6528 6f75 7470 7574 5f73 697a  _size(output_siz
+000181f0: 652c 2078 2e73 6861 7065 290a 0a20 2020  e, x.shape)..   
+00018200: 2078 203d 206d 622e 6578 7061 6e64 5f64   x = mb.expand_d
+00018210: 696d 7328 783d 782c 2061 7865 733d 5b33  ims(x=x, axes=[3
+00018220: 5d29 0a20 2020 2078 203d 206d 622e 7570  ]).    x = mb.up
+00018230: 7361 6d70 6c65 5f6e 6561 7265 7374 5f6e  sample_nearest_n
+00018240: 6569 6768 626f 7228 0a20 2020 2020 2020  eighbor(.       
+00018250: 2078 3d78 2c0a 2020 2020 2020 2020 7363   x=x,.        sc
+00018260: 616c 655f 6661 6374 6f72 5f68 6569 6768  ale_factor_heigh
+00018270: 743d 7363 616c 655f 6661 6374 6f72 2c0a  t=scale_factor,.
+00018280: 2020 2020 2020 2020 7363 616c 655f 6661          scale_fa
+00018290: 6374 6f72 5f77 6964 7468 3d31 2e2c 0a20  ctor_width=1.,. 
+000182a0: 2020 2029 0a20 2020 2078 203d 206d 622e     ).    x = mb.
+000182b0: 7371 7565 657a 6528 783d 782c 2061 7865  squeeze(x=x, axe
+000182c0: 733d 5b33 5d2c 206e 616d 653d 6e6f 6465  s=[3], name=node
+000182d0: 2e6e 616d 6529 0a20 2020 2063 6f6e 7465  .name).    conte
+000182e0: 7874 2e61 6464 2878 290a 0a0a 4072 6567  xt.add(x)...@reg
+000182f0: 6973 7465 725f 746f 7263 685f 6f70 0a64  ister_torch_op.d
+00018300: 6566 2075 7073 616d 706c 655f 6e65 6172  ef upsample_near
+00018310: 6573 7432 6428 636f 6e74 6578 742c 206e  est2d(context, n
+00018320: 6f64 6529 3a0a 2020 2020 696e 7075 7473  ode):.    inputs
+00018330: 203d 205f 6765 745f 696e 7075 7473 2863   = _get_inputs(c
+00018340: 6f6e 7465 7874 2c20 6e6f 6465 290a 2020  ontext, node).  
+00018350: 2020 5f69 6e70 7574 203d 2069 6e70 7574    _input = input
+00018360: 735b 305d 0a20 2020 2073 6361 6c65 735f  s[0].    scales_
+00018370: 682c 2073 6361 6c65 735f 7720 3d20 4e6f  h, scales_w = No
+00018380: 6e65 2c20 4e6f 6e65 0a0a 2020 2020 6f75  ne, None..    ou
+00018390: 7470 7574 5f73 697a 6520 3d20 696e 7075  tput_size = inpu
+000183a0: 7473 5b31 5d0a 2020 2020 7363 616c 655f  ts[1].    scale_
+000183b0: 6661 6374 6f72 7320 3d20 696e 7075 7473  factors = inputs
+000183c0: 5b32 5d0a 0a20 2020 2069 6620 280a 2020  [2]..    if (.  
+000183d0: 2020 2020 2020 7363 616c 655f 6661 6374        scale_fact
+000183e0: 6f72 7320 6973 206e 6f74 204e 6f6e 650a  ors is not None.
+000183f0: 2020 2020 2020 2020 616e 6420 7363 616c          and scal
+00018400: 655f 6661 6374 6f72 732e 7661 6c20 6973  e_factors.val is
+00018410: 206e 6f74 204e 6f6e 650a 2020 2020 2020   not None.      
+00018420: 2020 616e 6420 7363 616c 655f 6661 6374    and scale_fact
+00018430: 6f72 732e 7261 6e6b 203d 3d20 310a 2020  ors.rank == 1.  
+00018440: 2020 2020 2020 616e 6420 7363 616c 655f        and scale_
+00018450: 6661 6374 6f72 732e 7368 6170 655b 305d  factors.shape[0]
+00018460: 203d 3d20 320a 2020 2020 293a 0a20 2020   == 2.    ):.   
+00018470: 2020 2020 2023 2067 6574 2073 6361 6c65       # get scale
+00018480: 2066 6163 746f 7273 2066 726f 6d20 7072   factors from pr
+00018490: 6f76 6964 6564 2069 6e70 7574 730a 2020  ovided inputs.  
+000184a0: 2020 2020 2020 7363 616c 655f 6661 6374        scale_fact
+000184b0: 6f72 7320 3d20 7363 616c 655f 6661 6374  ors = scale_fact
+000184c0: 6f72 732e 7661 6c0a 2020 2020 2020 2020  ors.val.        
+000184d0: 7363 616c 6573 5f68 203d 2073 6361 6c65  scales_h = scale
+000184e0: 5f66 6163 746f 7273 5b30 5d0a 2020 2020  _factors[0].    
+000184f0: 2020 2020 7363 616c 6573 5f77 203d 2073      scales_w = s
+00018500: 6361 6c65 5f66 6163 746f 7273 5b31 5d0a  cale_factors[1].
+00018510: 2020 2020 656c 6966 2028 0a20 2020 2020      elif (.     
+00018520: 2020 2069 7369 6e73 7461 6e63 6528 6f75     isinstance(ou
+00018530: 7470 7574 5f73 697a 652c 206c 6973 7429  tput_size, list)
+00018540: 0a20 2020 2020 2020 2061 6e64 206f 7574  .        and out
+00018550: 7075 745f 7369 7a65 5b30 5d2e 7661 6c20  put_size[0].val 
+00018560: 6973 204e 6f6e 650a 2020 2020 2020 2020  is None.        
+00018570: 616e 6420 6f75 7470 7574 5f73 697a 655b  and output_size[
+00018580: 315d 2e76 616c 2069 7320 4e6f 6e65 0a20  1].val is None. 
+00018590: 2020 2029 3a0a 2020 2020 2020 2020 2320     ):.        # 
+000185a0: 7468 6520 696e 7075 7420 7368 6170 6520  the input shape 
+000185b0: 6973 2064 796e 616d 6963 2061 6e64 2072  is dynamic and r
+000185c0: 6563 6f6d 7075 7465 5f73 6361 6c65 5f66  ecompute_scale_f
+000185d0: 6163 746f 7220 3d20 5472 7565 0a20 2020  actor = True.   
+000185e0: 2020 2020 2023 206e 6565 6420 746f 2074       # need to t
+000185f0: 7261 6365 2074 6865 2067 7261 7068 2074  race the graph t
+00018600: 6f20 6669 6e64 2074 6865 2073 6361 6c65  o find the scale
+00018610: 2066 6163 746f 720a 2020 2020 2020 2020   factor.        
+00018620: 2320 7765 2064 6566 696e 6520 6120 746f  # we define a to
+00018630: 7263 6820 6672 6f6e 7420 656e 6420 6f70  rch front end op
+00018640: 206d 622e 746f 7263 685f 7570 7361 6d70   mb.torch_upsamp
+00018650: 6c65 5f6e 6561 7265 7374 5f6e 6569 6768  le_nearest_neigh
+00018660: 626f 7220 746f 2072 6573 6f6c 7665 2074  bor to resolve t
+00018670: 6865 2063 6f6e 7374 2073 6361 6c69 6e67  he const scaling
+00018680: 2066 6163 746f 720a 2020 2020 2020 2020   factor.        
+00018690: 746f 7263 685f 7570 7361 6d70 6c65 5f6e  torch_upsample_n
+000186a0: 6561 7265 7374 3264 203d 206d 622e 746f  earest2d = mb.to
+000186b0: 7263 685f 7570 7361 6d70 6c65 5f6e 6561  rch_upsample_nea
+000186c0: 7265 7374 5f6e 6569 6768 626f 7228 0a20  rest_neighbor(. 
+000186d0: 2020 2020 2020 2020 2020 2078 3d5f 696e             x=_in
+000186e0: 7075 742c 0a20 2020 2020 2020 2020 2020  put,.           
+000186f0: 206f 7574 7075 745f 6865 6967 6874 3d6f   output_height=o
+00018700: 7574 7075 745f 7369 7a65 5b30 5d2c 0a20  utput_size[0],. 
+00018710: 2020 2020 2020 2020 2020 206f 7574 7075             outpu
+00018720: 745f 7769 6474 683d 6f75 7470 7574 5f73  t_width=output_s
+00018730: 697a 655b 315d 2c0a 2020 2020 2020 2020  ize[1],.        
+00018740: 2020 2020 6e61 6d65 3d6e 6f64 652e 6e61      name=node.na
+00018750: 6d65 2c0a 2020 2020 2020 2020 290a 2020  me,.        ).  
+00018760: 2020 2020 2020 636f 6e74 6578 742e 6164        context.ad
+00018770: 6428 746f 7263 685f 7570 7361 6d70 6c65  d(torch_upsample
+00018780: 5f6e 6561 7265 7374 3264 290a 2020 2020  _nearest2d).    
+00018790: 2020 2020 7265 7475 726e 0a20 2020 2065      return.    e
+000187a0: 6c73 653a 0a20 2020 2020 2020 2023 2069  lse:.        # i
+000187b0: 6e66 6572 2073 6361 6c65 2066 6163 746f  nfer scale facto
+000187c0: 7273 2066 726f 6d20 6f75 7470 7574 2073  rs from output s
+000187d0: 697a 6573 0a20 2020 2020 2020 2073 6361  izes.        sca
+000187e0: 6c65 7320 3d20 5f67 6574 5f73 6361 6c65  les = _get_scale
+000187f0: 735f 6672 6f6d 5f6f 7574 7075 745f 7369  s_from_output_si
+00018800: 7a65 286f 7574 7075 745f 7369 7a65 2c20  ze(output_size, 
+00018810: 5f69 6e70 7574 2e73 6861 7065 290a 2020  _input.shape).  
+00018820: 2020 2020 2020 6966 2073 6361 6c65 733a        if scales:
+00018830: 0a20 2020 2020 2020 2020 2020 2073 6361  .            sca
+00018840: 6c65 735f 682c 2073 6361 6c65 735f 7720  les_h, scales_w 
+00018850: 3d20 7363 616c 6573 0a0a 2020 2020 6966  = scales..    if
+00018860: 2073 6361 6c65 735f 6820 6973 204e 6f6e   scales_h is Non
+00018870: 6520 6f72 2073 6361 6c65 735f 7720 6973  e or scales_w is
+00018880: 204e 6f6e 653a 0a20 2020 2020 2020 2069   None:.        i
+00018890: 6620 6c65 6e28 696e 7075 7473 2920 3d3d  f len(inputs) ==
+000188a0: 2035 3a0a 2020 2020 2020 2020 2020 2020   5:.            
+000188b0: 2320 466f 7220 746f 7263 683d 3d31 2e35  # For torch==1.5
+000188c0: 2e30 2c20 7570 7361 6d70 6c65 5f62 696c  .0, upsample_bil
+000188d0: 696e 6561 7232 6420 6861 7320 3520 696e  inear2d has 5 in
+000188e0: 7075 7473 2e0a 2020 2020 2020 2020 2020  puts..          
+000188f0: 2020 7363 616c 6573 5f68 203d 2069 6e70    scales_h = inp
+00018900: 7574 735b 335d 0a20 2020 2020 2020 2020  uts[3].         
+00018910: 2020 2073 6361 6c65 735f 7720 3d20 696e     scales_w = in
+00018920: 7075 7473 5b34 5d0a 2020 2020 2020 2020  puts[4].        
+00018930: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
+00018940: 2020 7261 6973 6520 5661 6c75 6545 7272    raise ValueErr
+00018950: 6f72 2822 4661 696c 6564 2074 6f20 696e  or("Failed to in
+00018960: 6665 7220 7363 616c 6520 6661 6374 6f72  fer scale factor
+00018970: 7320 6672 6f6d 2069 6e70 7574 732e 2229  s from inputs.")
+00018980: 0a0a 2020 2020 7570 7361 6d70 6c65 5f6e  ..    upsample_n
+00018990: 6561 7265 7374 3264 203d 206d 622e 7570  earest2d = mb.up
+000189a0: 7361 6d70 6c65 5f6e 6561 7265 7374 5f6e  sample_nearest_n
+000189b0: 6569 6768 626f 7228 0a20 2020 2020 2020  eighbor(.       
+000189c0: 2078 3d5f 696e 7075 742c 0a20 2020 2020   x=_input,.     
+000189d0: 2020 2073 6361 6c65 5f66 6163 746f 725f     scale_factor_
+000189e0: 6865 6967 6874 3d73 6361 6c65 735f 682c  height=scales_h,
+000189f0: 0a20 2020 2020 2020 2073 6361 6c65 5f66  .        scale_f
+00018a00: 6163 746f 725f 7769 6474 683d 7363 616c  actor_width=scal
+00018a10: 6573 5f77 2c0a 2020 2020 2020 2020 6e61  es_w,.        na
+00018a20: 6d65 3d6e 6f64 652e 6e61 6d65 2c0a 2020  me=node.name,.  
+00018a30: 2020 290a 2020 2020 636f 6e74 6578 742e    ).    context.
+00018a40: 6164 6428 7570 7361 6d70 6c65 5f6e 6561  add(upsample_nea
+00018a50: 7265 7374 3264 290a 0a0a 4072 6567 6973  rest2d)...@regis
+00018a60: 7465 725f 746f 7263 685f 6f70 2874 6f72  ter_torch_op(tor
+00018a70: 6368 5f61 6c69 6173 3d5b 226c 6973 7475  ch_alias=["listu
+00018a80: 6e70 6163 6b22 5d29 0a64 6566 2074 7570  npack"]).def tup
+00018a90: 6c65 756e 7061 636b 2863 6f6e 7465 7874  leunpack(context
+00018aa0: 2c20 6e6f 6465 293a 0a20 2020 2069 6e70  , node):.    inp
+00018ab0: 7574 7320 3d20 5f67 6574 5f69 6e70 7574  uts = _get_input
+00018ac0: 7328 636f 6e74 6578 742c 206e 6f64 652c  s(context, node,
+00018ad0: 2065 7870 6563 7465 643d 3129 0a20 2020   expected=1).   
+00018ae0: 2076 616c 7565 7320 3d20 696e 7075 7473   values = inputs
+00018af0: 5b30 5d0a 0a20 2020 2023 204e 6f64 6520  [0]..    # Node 
+00018b00: 696e 7075 7420 636f 756c 6420 6861 7665  input could have
+00018b10: 2062 6565 6e20 7475 726e 6564 2069 6e74   been turned int
+00018b20: 6f20 636f 6e73 7461 6e74 2061 7272 6179  o constant array
+00018b30: 2069 6e20 4074 7570 6c65 636f 6e73 7472   in @tupleconstr
+00018b40: 7563 740a 2020 2020 6966 206e 6f74 2069  uct.    if not i
+00018b50: 7369 6e73 7461 6e63 6528 7661 6c75 6573  sinstance(values
+00018b60: 2c20 2874 7570 6c65 2c20 6c69 7374 2929  , (tuple, list))
+00018b70: 3a0a 2020 2020 2020 2020 6966 2076 616c  :.        if val
+00018b80: 7565 732e 7661 6c20 6973 206e 6f74 204e  ues.val is not N
+00018b90: 6f6e 653a 0a20 2020 2020 2020 2020 2020  one:.           
+00018ba0: 2076 616c 7565 7320 3d20 7661 6c75 6573   values = values
+00018bb0: 2e76 616c 0a20 2020 2020 2020 2065 6c73  .val.        els
+00018bc0: 653a 0a20 2020 2020 2020 2020 2020 2023  e:.            #
+00018bd0: 2054 6865 2060 7661 6c75 6573 6020 636f   The `values` co
+00018be0: 756c 6420 6265 2061 2073 696e 676c 6520  uld be a single 
+00018bf0: 5661 7220 7769 7468 2073 796d 626f 6c69  Var with symboli
+00018c00: 6320 7661 6c2e 0a20 2020 2020 2020 2020  c val..         
+00018c10: 2020 2076 616c 7565 7320 3d20 5b76 616c     values = [val
+00018c20: 7565 735d 0a0a 2020 2020 6966 206c 656e  ues]..    if len
+00018c30: 2876 616c 7565 7329 2021 3d20 6c65 6e28  (values) != len(
+00018c40: 6e6f 6465 2e6f 7574 7075 7473 293a 0a20  node.outputs):. 
+00018c50: 2020 2020 2020 2072 6169 7365 2056 616c         raise Val
+00018c60: 7565 4572 726f 7228 6622 756e 7061 636b  ueError(f"unpack
+00018c70: 206e 6f64 6520 6578 7065 6374 6564 207b   node expected {
+00018c80: 6c65 6e28 6e6f 6465 2e6f 7574 7075 7473  len(node.outputs
+00018c90: 297d 206f 7574 7075 7473 2c20 676f 7420  )} outputs, got 
+00018ca0: 7b6c 656e 2876 616c 7565 7329 7d22 290a  {len(values)}").
+00018cb0: 0a20 2020 2023 2040 7661 6c75 6520 6973  .    # @value is
+00018cc0: 2065 6974 6865 7220 6120 6e75 6d70 7920   either a numpy 
+00018cd0: 7072 696d 6974 6976 6520 6f72 2061 2056  primitive or a V
+00018ce0: 6172 206f 626a 6563 740a 2020 2020 666f  ar object.    fo
+00018cf0: 7220 7661 6c75 652c 206f 7574 7075 7420  r value, output 
+00018d00: 696e 207a 6970 2876 616c 7565 732c 206e  in zip(values, n
+00018d10: 6f64 652e 6f75 7470 7574 7329 3a0a 2020  ode.outputs):.  
+00018d20: 2020 2020 2020 6966 206e 6f74 2069 7369        if not isi
+00018d30: 6e73 7461 6e63 6528 7661 6c75 652c 2056  nstance(value, V
+00018d40: 6172 293a 0a20 2020 2020 2020 2020 2020  ar):.           
+00018d50: 2076 616c 7565 203d 205f 636f 6e73 7472   value = _constr
+00018d60: 7563 745f 636f 6e73 7461 6e74 2876 616c  uct_constant(val
+00018d70: 7565 2c20 6e61 6d65 3d6f 7574 7075 7429  ue, name=output)
+00018d80: 0a20 2020 2020 2020 2061 7373 6572 7420  .        assert 
+00018d90: 6973 696e 7374 616e 6365 2876 616c 7565  isinstance(value
+00018da0: 2c20 5661 7229 0a20 2020 2020 2020 2063  , Var).        c
+00018db0: 6f6e 7465 7874 2e61 6464 2876 616c 7565  ontext.add(value
+00018dc0: 2c20 6f75 7470 7574 290a 0a0a 4072 6567  , output)...@reg
+00018dd0: 6973 7465 725f 746f 7263 685f 6f70 0a64  ister_torch_op.d
+00018de0: 6566 206c 6f6f 7028 636f 6e74 6578 742c  ef loop(context,
+00018df0: 206e 6f64 6529 3a0a 2020 2020 2222 2220   node):.    """ 
+00018e00: 496e 2054 6f72 6368 4952 2c20 6120 6c6f  In TorchIR, a lo
+00018e10: 6f70 206c 6f6f 6b73 206c 696b 653a 0a20  op looks like:. 
+00018e20: 2020 2020 2020 2020 2020 2025 795f 312c             %y_1,
+00018e30: 202e 2e2e 2c20 2579 5f72 203d 2070 7269   ..., %y_r = pri
+00018e40: 6d3a 3a4c 6f6f 7028 256d 6178 5f74 7269  m::Loop(%max_tri
+00018e50: 705f 636f 756e 742c 2025 696e 6974 6961  p_count, %initia
+00018e60: 6c5f 636f 6e64 6974 696f 6e2c 2025 785f  l_condition, %x_
+00018e70: 312c 202e 2e2e 2c20 2578 5f72 290a 2020  1, ..., %x_r).  
+00018e80: 2020 2020 2020 2020 2020 626c 6f63 6b30            block0
+00018e90: 2825 692c 2025 615f 312c 202e 2e2e 2c20  (%i, %a_1, ..., 
+00018ea0: 2561 5f72 293a 0a20 2020 2020 2020 2020  %a_r):.         
+00018eb0: 2020 2020 2020 2025 625f 312c 202e 2e2e         %b_1, ...
+00018ec0: 2c20 2562 5f6d 203d 2073 6f6d 653a 3a6e  , %b_m = some::n
+00018ed0: 6f64 6528 2561 5f76 616c 7565 5f66 726f  ode(%a_value_fro
+00018ee0: 6d5f 6f75 7465 725f 626c 6f63 6b2c 2025  m_outer_block, %
+00018ef0: 615f 3129 0a20 2020 2020 2020 2020 2020  a_1).           
+00018f00: 2020 2020 2025 6974 6572 5f63 6f6e 6469       %iter_condi
+00018f10: 7469 6f6e 203d 2073 6f6d 653a 3a6f 7468  tion = some::oth
+00018f20: 6572 5f6e 6f64 6528 2561 5f32 290a 2020  er_node(%a_2).  
+00018f30: 2020 2020 2020 2020 2020 2020 2020 2d3e                ->
+00018f40: 2028 2569 7465 725f 636f 6e64 6974 696f   (%iter_conditio
+00018f50: 6e2c 2025 625f 312c 202e 2e2e 2c20 2562  n, %b_1, ..., %b
+00018f60: 5f72 290a 0a20 2020 2020 2020 2054 6869  _r)..        Thi
+00018f70: 7320 7472 616e 736c 6174 6573 2074 6f20  s translates to 
+00018f80: 7073 6575 646f 2063 6f64 6520 6173 3a0a  pseudo code as:.
+00018f90: 2020 2020 2020 2020 2020 2020 795f 312c              y_1,
+00018fa0: 202e 2e2e 2c20 795f 7220 3d20 785f 312c   ..., y_r = x_1,
+00018fb0: 202e 2e2e 2c20 785f 720a 2020 2020 2020   ..., x_r.      
+00018fc0: 2020 2020 2020 636f 6e64 6974 696f 6e20        condition 
+00018fd0: 3d20 696e 6974 6961 6c5f 636f 6e64 6974  = initial_condit
+00018fe0: 696f 6e0a 2020 2020 2020 2020 2020 2020  ion.            
+00018ff0: 6920 3d20 300a 2020 2020 2020 2020 2020  i = 0.          
+00019000: 2020 7768 696c 6520 636f 6e64 6974 696f    while conditio
+00019010: 6e20 616e 6420 6920 3c20 6d61 785f 7472  n and i < max_tr
+00019020: 6970 5f63 6f75 6e74 3a0a 2020 2020 2020  ip_count:.      
+00019030: 2020 2020 2020 2020 2020 615f 312c 202e            a_1, .
+00019040: 2e2e 2c20 615f 7220 3d20 795f 312c 202e  .., a_r = y_1, .
+00019050: 2e2e 2c20 795f 720a 0a20 2020 2020 2020  .., y_r..       
+00019060: 2020 2020 2020 2020 2023 2323 2323 2323           #######
+00019070: 2323 2323 2323 2323 2323 2323 2323 2323  ################
+00019080: 2323 2323 2323 2323 2323 2323 2323 2323  ################
+00019090: 2323 2323 2323 2323 2323 2323 2323 2323  ################
+000190a0: 2323 2323 230a 2020 2020 2020 2020 2020  #####.          
+000190b0: 2020 2020 2020 2320 4163 7475 616c 2062        # Actual b
+000190c0: 6f64 7920 6f66 2074 6865 206c 6f6f 700a  ody of the loop.
+000190d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000190e0: 625f 312c 202e 2e2e 2c20 625f 6d20 3d20  b_1, ..., b_m = 
+000190f0: 736f 6d65 3a3a 6e6f 6465 2861 5f76 616c  some::node(a_val
+00019100: 7565 5f66 726f 6d5f 6f75 7473 6964 655f  ue_from_outside_
+00019110: 6f66 5f74 6865 5f6c 6f6f 702c 2061 5f31  of_the_loop, a_1
+00019120: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
+00019130: 2020 6974 6572 5f63 6f6e 6469 7469 6f6e    iter_condition
+00019140: 203d 2073 6f6d 653a 3a6e 6f64 6528 615f   = some::node(a_
+00019150: 3229 0a20 2020 2020 2020 2020 2020 2020  2).             
+00019160: 2020 2023 2323 2323 2323 2323 2323 2323     #############
+00019170: 2323 2323 2323 2323 2323 2323 2323 2323  ################
+00019180: 2323 2323 2323 2323 2323 2323 2323 2323  ################
+00019190: 2323 2323 2323 2323 2323 2323 2323 230a  ###############.
+000191a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000191b0: 2079 5f31 2c20 2e2e 2e2c 2079 5f72 203d   y_1, ..., y_r =
+000191c0: 2062 5f31 2c20 2e2e 2e2c 2062 5f72 0a20   b_1, ..., b_r. 
+000191d0: 2020 2020 2020 2020 2020 2020 2020 2063                 c
+000191e0: 6f6e 6469 7469 6f6e 203d 2069 7465 725f  ondition = iter_
+000191f0: 636f 6e64 6974 696f 6e0a 2020 2020 2020  condition.      
+00019200: 2020 2020 2020 2020 2020 6920 2b3d 2031            i += 1
+00019210: 0a0a 2020 2020 2020 2020 5768 6963 6820  ..        Which 
+00019220: 6675 7274 6865 7220 7472 616e 736c 6174  further translat
+00019230: 6573 2074 6f20 4d49 4c20 7768 696c 655f  es to MIL while_
+00019240: 6c6f 6f70 2061 733a 0a20 2020 2020 2020  loop as:.       
+00019250: 2020 2020 206c 6f6f 705f 7661 7273 203d       loop_vars =
+00019260: 2028 302c 2069 6e69 7469 616c 5f63 6f6e   (0, initial_con
+00019270: 6469 7469 6f6e 2c20 785f 312c 202e 2e2e  dition, x_1, ...
+00019280: 2c20 785f 7229 0a20 2020 2020 2020 2020  , x_r).         
+00019290: 2020 205f 636f 6e64 203d 207b 0a20 2020     _cond = {.   
+000192a0: 2020 2020 2020 2020 2020 2020 2072 6574               ret
+000192b0: 7572 6e20 286c 6f6f 705f 7661 7273 5b31  urn (loop_vars[1
+000192c0: 5d20 616e 6420 6c6f 6f70 5f76 6172 735b  ] and loop_vars[
+000192d0: 305d 203c 206d 6178 5f74 7269 705f 636f  0] < max_trip_co
+000192e0: 756e 7429 0a20 2020 2020 2020 2020 2020  unt).           
+000192f0: 207d 0a20 2020 2020 2020 2020 2020 205f   }.            _
+00019300: 626f 6479 203d 207b 0a20 2020 2020 2020  body = {.       
+00019310: 2020 2020 2020 2020 2061 5f31 2c20 2e2e           a_1, ..
+00019320: 2e2c 2061 5f72 203d 206c 6f6f 705f 7661  ., a_r = loop_va
+00019330: 7273 5b32 5d2c 202e 2e2e 2c20 6c6f 6f70  rs[2], ..., loop
+00019340: 5f76 6172 735b 2d31 5d0a 2020 2020 2020  _vars[-1].      
+00019350: 2020 2020 2020 2020 2020 625f 312c 202e            b_1, .
+00019360: 2e2e 2c20 625f 6d20 3d20 736f 6d65 3a3a  .., b_m = some::
+00019370: 6e6f 6465 2861 5f76 616c 7565 5f66 726f  node(a_value_fro
+00019380: 6d5f 6f75 7473 6964 655f 6f66 5f74 6865  m_outside_of_the
+00019390: 5f6c 6f6f 702c 2061 5f31 290a 2020 2020  _loop, a_1).    
+000193a0: 2020 2020 2020 2020 2020 2020 6974 6572              iter
+000193b0: 5f63 6f6e 6469 7469 6f6e 203d 2073 6f6d  _condition = som
+000193c0: 653a 3a6e 6f64 6528 615f 3229 0a20 2020  e::node(a_2).   
+000193d0: 2020 2020 2020 2020 2020 2020 2072 6574               ret
+000193e0: 7572 6e20 286c 6f6f 705f 7661 7273 5b30  urn (loop_vars[0
+000193f0: 5d20 2b20 312c 2069 7465 725f 636f 6e64  ] + 1, iter_cond
+00019400: 6974 696f 6e2c 2062 5f31 2c20 2e2e 2e2c  ition, b_1, ...,
+00019410: 2062 5f72 290a 2020 2020 2020 2020 2020   b_r).          
+00019420: 2020 7d0a 0a20 2020 2020 2020 2046 6f72    }..        For
+00019430: 206c 6f6f 7073 2070 6173 7320 5472 7565   loops pass True
+00019440: 2066 6f72 2025 696e 6974 6961 6c5f 636f   for %initial_co
+00019450: 6e64 6974 696f 6e20 616e 6420 2569 7465  ndition and %ite
+00019460: 725f 636f 6e64 6974 696f 6e0a 2020 2020  r_condition.    
+00019470: 2020 2020 5768 696c 6520 6c6f 6f70 7320      While loops 
+00019480: 7365 7420 256d 6178 5f74 7269 705f 636f  set %max_trip_co
+00019490: 756e 7420 746f 2049 4e54 5f4d 4158 2061  unt to INT_MAX a
+000194a0: 6e64 2025 6920 6973 2075 6e75 7365 640a  nd %i is unused.
+000194b0: 2020 2020 2222 220a 2020 2020 6e61 6d65      """.    name
+000194c0: 203d 206e 6f64 652e 6e61 6d65 0a20 2020   = node.name.   
+000194d0: 2023 2069 6e70 7574 735b 305d 3a20 6d61   # inputs[0]: ma
+000194e0: 7820 6974 6572 2063 6f75 6e74 0a20 2020  x iter count.   
+000194f0: 2023 2069 6e70 7574 735b 315d 3a20 696e   # inputs[1]: in
+00019500: 6974 6961 6c20 636f 6e64 6974 696f 6e0a  itial condition.
+00019510: 2020 2020 2320 696e 7075 7473 5b32 5d3a      # inputs[2]:
+00019520: 2062 6c6f 636b 2069 6e70 7574 2030 0a20   block input 0. 
+00019530: 2020 2023 202e 2e2e 0a20 2020 2023 2069     # ....    # i
+00019540: 6e70 7574 735b 4e2b 325d 3a20 626c 6f63  nputs[N+2]: bloc
+00019550: 6b20 696e 7075 7420 4e0a 2020 2020 696e  k input N.    in
+00019560: 7075 7473 203d 205f 6765 745f 696e 7075  puts = _get_inpu
+00019570: 7473 2863 6f6e 7465 7874 2c20 6e6f 6465  ts(context, node
+00019580: 290a 2020 2020 6d61 785f 6974 6572 5f63  ).    max_iter_c
+00019590: 6f75 6e74 203d 2069 6e70 7574 735b 305d  ount = inputs[0]
+000195a0: 0a0a 2020 2020 2320 4d61 6769 6320 6465  ..    # Magic de
+000195b0: 6661 756c 7420 7369 676e 616c 7320 7468  fault signals th
+000195c0: 6973 2069 7320 6120 7768 696c 652d 6f6e  is is a while-on
+000195d0: 6c79 206c 6f6f 702c 2073 6f20 6e6f 2069  ly loop, so no i
+000195e0: 7465 7261 7469 6f6e 2063 6f75 6e74 0a20  teration count. 
+000195f0: 2020 2023 2069 7320 6e65 6564 6564 2e0a     # is needed..
+00019600: 2020 2020 6861 735f 6974 6572 5f63 6f75      has_iter_cou
+00019610: 6e74 203d 206d 6178 5f69 7465 725f 636f  nt = max_iter_co
+00019620: 756e 7420 6973 206e 6f74 204e 6f6e 650a  unt is not None.
+00019630: 0a20 2020 2023 2043 7265 6174 6520 616e  .    # Create an
+00019640: 2069 6e74 6572 6174 696f 6e20 636f 756e   interation coun
+00019650: 742e 2054 6869 7320 7769 6c6c 206f 6e6c  t. This will onl
+00019660: 7920 6265 2075 7365 6420 6966 2074 6869  y be used if thi
+00019670: 7320 6973 2061 2066 6f72 206c 6f6f 702e  s is a for loop.
+00019680: 0a20 2020 2069 7465 725f 636f 756e 7420  .    iter_count 
+00019690: 3d20 6d62 2e63 6f6e 7374 2876 616c 3d30  = mb.const(val=0
+000196a0: 2c20 6e61 6d65 3d6e 6f64 652e 6e61 6d65  , name=node.name
+000196b0: 202b 2022 5f69 7465 7222 290a 2020 2020   + "_iter").    
+000196c0: 2320 406c 6f6f 705f 7661 7273 2069 7320  # @loop_vars is 
+000196d0: 7475 706c 6528 6974 6572 5f63 6f75 6e74  tuple(iter_count
+000196e0: 2c20 636f 6e64 2c20 696e 7075 7473 2e2e  , cond, inputs..
+000196f0: 2e29 0a20 2020 206c 6f6f 705f 7661 7273  .).    loop_vars
+00019700: 203d 2074 7570 6c65 285b 6974 6572 5f63   = tuple([iter_c
+00019710: 6f75 6e74 5d20 2b20 696e 7075 7473 5b31  ount] + inputs[1
+00019720: 3a5d 290a 0a20 2020 2064 6566 205f 6c6f  :])..    def _lo
+00019730: 6f70 5f63 6f6e 6428 2a6c 6f6f 705f 7661  op_cond(*loop_va
+00019740: 7273 293a 0a20 2020 2020 2020 2063 6f6e  rs):.        con
+00019750: 6420 3d20 6c6f 6f70 5f76 6172 735b 315d  d = loop_vars[1]
+00019760: 0a0a 2020 2020 2020 2020 2320 4368 6563  ..        # Chec
+00019770: 6b20 7468 6520 6974 6572 6174 696f 6e20  k the iteration 
+00019780: 636f 756e 7420 6966 2077 6527 7265 206b  count if we're k
+00019790: 6565 7069 6e67 2074 7261 636b 2e0a 2020  eeping track..  
+000197a0: 2020 2020 2020 6966 2068 6173 5f69 7465        if has_ite
+000197b0: 725f 636f 756e 743a 0a20 2020 2020 2020  r_count:.       
+000197c0: 2020 2020 2069 7465 725f 636f 756e 7420       iter_count 
+000197d0: 3d20 6c6f 6f70 5f76 6172 735b 305d 0a20  = loop_vars[0]. 
+000197e0: 2020 2020 2020 2020 2020 2069 7465 725f             iter_
+000197f0: 636f 6e64 203d 206d 622e 6c65 7373 280a  cond = mb.less(.
+00019800: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019810: 783d 6974 6572 5f63 6f75 6e74 2c20 793d  x=iter_count, y=
+00019820: 6d61 785f 6974 6572 5f63 6f75 6e74 2c20  max_iter_count, 
+00019830: 6e61 6d65 3d6e 6f64 652e 6e61 6d65 202b  name=node.name +
+00019840: 2022 5f63 6f6e 6422 0a20 2020 2020 2020   "_cond".       
+00019850: 2020 2020 2029 0a20 2020 2020 2020 2020       ).         
+00019860: 2020 2072 6574 7572 6e20 6d62 2e6c 6f67     return mb.log
+00019870: 6963 616c 5f61 6e64 2878 3d63 6f6e 642c  ical_and(x=cond,
+00019880: 2079 3d69 7465 725f 636f 6e64 290a 2020   y=iter_cond).  
+00019890: 2020 2020 2020 656c 7365 3a0a 2020 2020        else:.    
+000198a0: 2020 2020 2020 2020 7265 7475 726e 206d          return m
+000198b0: 622e 6964 656e 7469 7479 2878 3d63 6f6e  b.identity(x=con
+000198c0: 6429 0a0a 2020 2020 6465 6620 5f73 6861  d)..    def _sha
+000198d0: 7065 735f 6172 655f 6571 7569 7661 6c65  pes_are_equivale
+000198e0: 6e74 2873 6861 7065 312c 2073 6861 7065  nt(shape1, shape
+000198f0: 3229 3a0a 2020 2020 2020 2020 2222 2220  2):.        """ 
+00019900: 436f 6d70 6172 6573 2074 776f 2073 6574  Compares two set
+00019910: 7320 6f66 2074 656e 736f 7220 7368 6170  s of tensor shap
+00019920: 6573 2061 6e64 2072 6574 7572 6e73 2054  es and returns T
+00019930: 7275 6520 6966 2074 6865 7920 6172 650a  rue if they are.
+00019940: 2020 2020 2020 2020 2020 2020 6571 7569              equi
+00019950: 7661 6c65 6e74 2e20 5468 6174 2069 732c  valent. That is,
+00019960: 2074 6865 7920 6172 6520 7468 6520 7361   they are the sa
+00019970: 6d65 2072 616e 6b2c 2061 6e64 2065 6163  me rank, and eac
+00019980: 6820 6469 6d65 6e73 696f 6e0a 2020 2020  h dimension.    
+00019990: 2020 2020 2020 2020 6973 2074 6865 2073          is the s
+000199a0: 616d 6520 6f72 2073 796d 626f 6c69 632e  ame or symbolic.
+000199b0: 0a20 2020 2020 2020 2022 2222 0a20 2020  .        """.   
+000199c0: 2020 2020 2069 6620 6c65 6e28 7368 6170       if len(shap
+000199d0: 6531 2920 213d 206c 656e 2873 6861 7065  e1) != len(shape
+000199e0: 3229 3a0a 2020 2020 2020 2020 2020 2020  2):.            
+000199f0: 7265 7475 726e 2046 616c 7365 0a0a 2020  return False..  
+00019a00: 2020 2020 2020 2320 4561 6368 2064 696d        # Each dim
+00019a10: 656e 7369 6f6e 206d 7573 7420 6861 7665  ension must have
+00019a20: 2074 6865 2073 616d 6520 696e 7465 6765   the same intege
+00019a30: 7220 6c65 6e67 7468 2c20 6f72 2065 6c73  r length, or els
+00019a40: 6520 6265 0a20 2020 2020 2020 2023 2073  e be.        # s
+00019a50: 796d 626f 6c69 632e 0a20 2020 2020 2020  ymbolic..       
+00019a60: 2061 6c6c 5f65 7175 6976 616c 656e 7420   all_equivalent 
+00019a70: 3d20 5b0a 2020 2020 2020 2020 2020 2020  = [.            
+00019a80: 7331 203d 3d20 7332 206f 7220 2869 7369  s1 == s2 or (isi
+00019a90: 6e73 7461 6e63 6528 7331 2c20 5379 6d62  nstance(s1, Symb
+00019aa0: 6f6c 2920 616e 6420 6973 696e 7374 616e  ol) and isinstan
+00019ab0: 6365 2873 322c 2053 796d 626f 6c29 290a  ce(s2, Symbol)).
+00019ac0: 2020 2020 2020 2020 2020 2020 666f 7220              for 
+00019ad0: 7331 2c20 7332 2069 6e20 7a69 7028 7368  s1, s2 in zip(sh
+00019ae0: 6170 6531 2c20 7368 6170 6532 290a 2020  ape1, shape2).  
+00019af0: 2020 2020 2020 5d0a 2020 2020 2020 2020        ].        
+00019b00: 7265 7475 726e 2061 6c6c 5f65 7175 6976  return all_equiv
+00019b10: 616c 656e 740a 0a20 2020 2064 6566 205f  alent..    def _
+00019b20: 6c6f 6f70 5f62 6f64 7928 2a6c 6f6f 705f  loop_body(*loop_
+00019b30: 7661 7273 293a 0a20 2020 2020 2020 2062  vars):.        b
+00019b40: 6c6f 636b 203d 206e 6f64 652e 626c 6f63  lock = node.bloc
+00019b50: 6b73 5b30 5d0a 2020 2020 2020 2020 6974  ks[0].        it
+00019b60: 6572 5f76 6172 203d 206c 6f6f 705f 7661  er_var = loop_va
+00019b70: 7273 5b30 5d0a 2020 2020 2020 2020 696e  rs[0].        in
+00019b80: 7075 7473 203d 2028 6974 6572 5f76 6172  puts = (iter_var
+00019b90: 2c29 202b 206c 6f6f 705f 7661 7273 5b32  ,) + loop_vars[2
+00019ba0: 3a5d 0a20 2020 2020 2020 2072 6573 203d  :].        res =
+00019bb0: 2063 6f6e 7665 7274 5f62 6c6f 636b 2863   convert_block(c
+00019bc0: 6f6e 7465 7874 2c20 626c 6f63 6b2c 2069  ontext, block, i
+00019bd0: 6e70 7574 7329 0a0a 2020 2020 2020 2020  nputs)..        
+00019be0: 666f 7220 696e 7075 745f 7661 722c 206f  for input_var, o
+00019bf0: 7574 7075 745f 7661 7220 696e 207a 6970  utput_var in zip
+00019c00: 286c 6f6f 705f 7661 7273 5b32 3a5d 2c20  (loop_vars[2:], 
+00019c10: 7265 735b 313a 5d29 3a0a 2020 2020 2020  res[1:]):.      
+00019c20: 2020 2020 2020 6966 206e 6f74 205f 7368        if not _sh
+00019c30: 6170 6573 5f61 7265 5f65 7175 6976 616c  apes_are_equival
+00019c40: 656e 7428 696e 7075 745f 7661 722e 7368  ent(input_var.sh
+00019c50: 6170 652c 206f 7574 7075 745f 7661 722e  ape, output_var.
+00019c60: 7368 6170 6529 3a0a 2020 2020 2020 2020  shape):.        
+00019c70: 2020 2020 2020 2020 6c6f 6767 6572 2e77          logger.w
+00019c80: 6172 6e69 6e67 280a 2020 2020 2020 2020  arning(.        
+00019c90: 2020 2020 2020 2020 2020 2020 2264 6574              "det
+00019ca0: 6563 7465 6420 6368 616e 6765 2069 6e20  ected change in 
+00019cb0: 7368 6170 6520 6f66 206c 6f6f 7020 7661  shape of loop va
+00019cc0: 7269 6162 6c65 2e20 7468 6973 2063 6f75  riable. this cou
+00019cd0: 6c64 206c 6561 6420 746f 2069 6e63 6f72  ld lead to incor
+00019ce0: 7265 6374 2069 6e66 6572 656e 6365 2072  rect inference r
+00019cf0: 6573 756c 7473 2122 0a20 2020 2020 2020  esults!".       
+00019d00: 2020 2020 2020 2020 2029 0a20 2020 2020           ).     
+00019d10: 2020 2020 2020 2020 2020 206c 6f67 6765             logge
+00019d20: 722e 7761 726e 696e 6728 0a20 2020 2020  r.warning(.     
+00019d30: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+00019d40: 7b7d 3a7b 7d20 2d3e 207b 7d3a 7b7d 222e  {}:{} -> {}:{}".
+00019d50: 666f 726d 6174 280a 2020 2020 2020 2020  format(.        
+00019d60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019d70: 696e 7075 745f 7661 722e 6e61 6d65 2c0a  input_var.name,.
+00019d80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019d90: 2020 2020 2020 2020 696e 7075 745f 7661          input_va
+00019da0: 722e 7368 6170 652c 0a20 2020 2020 2020  r.shape,.       
+00019db0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019dc0: 206f 7574 7075 745f 7661 722e 6e61 6d65   output_var.name
+00019dd0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00019de0: 2020 2020 2020 2020 2020 6f75 7470 7574            output
+00019df0: 5f76 6172 2e73 6861 7065 2c0a 2020 2020  _var.shape,.    
+00019e00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019e10: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
+00019e20: 2020 290a 0a20 2020 2020 2020 2023 2055    )..        # U
+00019e30: 7064 6174 6520 7468 6520 6974 6572 6174  pdate the iterat
+00019e40: 696f 6e20 636f 756e 7420 6966 2077 6527  ion count if we'
+00019e50: 7265 206b 6565 7069 6e67 2074 7261 636b  re keeping track
+00019e60: 2e0a 2020 2020 2020 2020 6966 2068 6173  ..        if has
+00019e70: 5f69 7465 725f 636f 756e 743a 0a20 2020  _iter_count:.   
+00019e80: 2020 2020 2020 2020 2069 7465 725f 7661           iter_va
+00019e90: 7220 3d20 6d62 2e61 6464 2878 3d69 7465  r = mb.add(x=ite
+00019ea0: 725f 7661 722c 2079 3d31 2c20 6e61 6d65  r_var, y=1, name
+00019eb0: 3d69 7465 725f 7661 722e 6e61 6d65 202b  =iter_var.name +
+00019ec0: 2022 5f69 6e63 2229 0a20 2020 2020 2020   "_inc").       
+00019ed0: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
+00019ee0: 2020 2069 7465 725f 7661 7220 3d20 6d62     iter_var = mb
+00019ef0: 2e69 6465 6e74 6974 7928 783d 6974 6572  .identity(x=iter
+00019f00: 5f76 6172 290a 0a20 2020 2020 2020 2023  _var)..        #
+00019f10: 204d 7573 7420 7265 7475 726e 2074 7570   Must return tup
+00019f20: 6c65 2077 6974 6820 7361 6d65 206c 656e  le with same len
+00019f30: 6774 6820 616e 6420 7479 7065 7320 6173  gth and types as
+00019f40: 2040 6c6f 6f70 5f76 6172 732e 0a20 2020   @loop_vars..   
+00019f50: 2020 2020 2072 6574 7572 6e20 7475 706c       return tupl
+00019f60: 6528 0a20 2020 2020 2020 2020 2020 205b  e(.            [
+00019f70: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00019f80: 2069 7465 725f 7661 722c 0a20 2020 2020   iter_var,.     
+00019f90: 2020 2020 2020 205d 0a20 2020 2020 2020         ].       
+00019fa0: 2020 2020 202b 2072 6573 0a20 2020 2020       + res.     
+00019fb0: 2020 2029 0a0a 2020 2020 6c6f 6f70 203d     )..    loop =
+00019fc0: 206d 622e 7768 696c 655f 6c6f 6f70 280a   mb.while_loop(.
+00019fd0: 2020 2020 2020 2020 5f63 6f6e 643d 5f6c          _cond=_l
+00019fe0: 6f6f 705f 636f 6e64 2c20 5f62 6f64 793d  oop_cond, _body=
+00019ff0: 5f6c 6f6f 705f 626f 6479 2c20 6c6f 6f70  _loop_body, loop
+0001a000: 5f76 6172 733d 6c6f 6f70 5f76 6172 732c  _vars=loop_vars,
+0001a010: 206e 616d 653d 6e61 6d65 0a20 2020 2029   name=name.    )
+0001a020: 0a0a 2020 2020 2320 4d61 6b65 2073 7572  ..    # Make sur
+0001a030: 6520 7468 6520 6c6f 6f70 2072 6574 7572  e the loop retur
+0001a040: 6e65 6420 7468 6520 6578 7065 6374 6564  ned the expected
+0001a050: 206e 756d 6265 7220 6f66 206f 7574 7075   number of outpu
+0001a060: 7473 2e20 4e6f 7465 2074 6861 7420 7468  ts. Note that th
+0001a070: 650a 2020 2020 2320 6669 7273 7420 7477  e.    # first tw
+0001a080: 6f20 6c6f 6f70 206f 7574 7075 7473 2061  o loop outputs a
+0001a090: 7265 2074 6865 2069 7465 7261 7469 6f6e  re the iteration
+0001a0a0: 2063 6f75 6e74 2061 6e64 2063 6f6e 6469   count and condi
+0001a0b0: 7469 6f6e 2e0a 2020 2020 6173 7365 7274  tion..    assert
+0001a0c0: 206c 656e 286c 6f6f 7029 202d 2032 203d   len(loop) - 2 =
+0001a0d0: 3d20 6c65 6e28 6e6f 6465 2e6f 7574 7075  = len(node.outpu
+0001a0e0: 7473 290a 2020 2020 666f 7220 6f75 7470  ts).    for outp
+0001a0f0: 7574 5f6e 616d 652c 206f 7574 7075 745f  ut_name, output_
+0001a100: 7661 7220 696e 207a 6970 286e 6f64 652e  var in zip(node.
+0001a110: 6f75 7470 7574 732c 206c 6f6f 705b 323a  outputs, loop[2:
+0001a120: 5d29 3a0a 2020 2020 2020 2020 636f 6e74  ]):.        cont
+0001a130: 6578 742e 6164 6428 6f75 7470 7574 5f76  ext.add(output_v
+0001a140: 6172 2c20 746f 7263 685f 6e61 6d65 3d6f  ar, torch_name=o
+0001a150: 7574 7075 745f 6e61 6d65 290a 0a0a 4072  utput_name)...@r
+0001a160: 6567 6973 7465 725f 746f 7263 685f 6f70  egister_torch_op
+0001a170: 2874 6f72 6368 5f61 6c69 6173 3d5b 2269  (torch_alias=["i
+0001a180: 6622 5d29 0a64 6566 205f 6966 2863 6f6e  f"]).def _if(con
+0001a190: 7465 7874 2c20 6e6f 6465 293a 0a20 2020  text, node):.   
+0001a1a0: 2022 2222 2049 6e20 546f 7263 6849 522c   """ In TorchIR,
+0001a1b0: 2061 2063 6f6e 6469 7469 6f6e 616c 206c   a conditional l
+0001a1c0: 6f6f 6b73 206c 696b 653a 0a20 2020 2020  ooks like:.     
+0001a1d0: 2020 2020 2020 2025 795f 312c 202e 2e2e         %y_1, ...
+0001a1e0: 2c20 2579 5f72 203d 2070 7269 6d3a 3a49  , %y_r = prim::I
+0001a1f0: 6628 2563 6f6e 6469 7469 6f6e 290a 2020  f(%condition).  
+0001a200: 2020 2020 2020 2020 2020 626c 6f63 6b30            block0
+0001a210: 2829 3a20 2023 2054 5255 4520 4252 414e  ():  # TRUE BRAN
+0001a220: 4348 2c20 6e65 7665 7220 7461 6b65 7320  CH, never takes 
+0001a230: 6172 6775 6d65 6e74 732c 2068 6173 2074  arguments, has t
+0001a240: 6f20 7265 7475 726e 2072 206f 7574 7075  o return r outpu
+0001a250: 7473 0a20 2020 2020 2020 2020 2020 2020  ts.             
+0001a260: 2020 2025 745f 312c 202e 2e2e 2c20 2574     %t_1, ..., %t
+0001a270: 5f6b 203d 2073 6f6d 653a 3a6e 6f64 6528  _k = some::node(
+0001a280: 2561 5f76 616c 7565 5f66 726f 6d5f 6f75  %a_value_from_ou
+0001a290: 7465 725f 626c 6f63 6b29 0a20 2020 2020  ter_block).     
+0001a2a0: 2020 2020 2020 2020 2020 202d 3e20 2825             -> (%
+0001a2b0: 745f 312c 202e 2e2e 2c20 2574 5f72 290a  t_1, ..., %t_r).
+0001a2c0: 2020 2020 2020 2020 2020 2020 626c 6f63              bloc
+0001a2d0: 6b31 2829 3a20 2023 2046 414c 5345 2042  k1():  # FALSE B
+0001a2e0: 5241 4e43 482c 206e 6576 6572 2074 616b  RANCH, never tak
+0001a2f0: 6573 2061 7267 756d 656e 7473 2c20 6861  es arguments, ha
+0001a300: 7320 746f 2072 6574 7572 6e20 7220 6f75  s to return r ou
+0001a310: 7470 7574 730a 2020 2020 2020 2020 2020  tputs.          
+0001a320: 2020 2020 2020 2566 5f31 2c20 2e2e 2e2c        %f_1, ...,
+0001a330: 2025 665f 6d20 3d20 736f 6d65 3a3a 6e6f   %f_m = some::no
+0001a340: 6465 2825 615f 7661 6c75 655f 6672 6f6d  de(%a_value_from
+0001a350: 5f6f 7574 6572 5f62 6c6f 636b 290a 2020  _outer_block).  
+0001a360: 2020 2020 2020 2020 2020 2020 2020 2d3e                ->
+0001a370: 2028 2566 5f31 2c20 2e2e 2e2c 2025 665f   (%f_1, ..., %f_
+0001a380: 7229 0a0a 2020 2020 2020 2020 5468 6973  r)..        This
+0001a390: 2074 7261 6e73 6c61 7465 7320 746f 2070   translates to p
+0001a3a0: 7365 7564 6f20 636f 6465 2061 733a 0a20  seudo code as:. 
+0001a3b0: 2020 2020 2020 2020 2020 2069 6620 2863             if (c
+0001a3c0: 6f6e 6469 7469 6f6e 293a 0a20 2020 2020  ondition):.     
+0001a3d0: 2020 2020 2020 2020 2020 2074 5f31 2c20             t_1, 
+0001a3e0: 2e2e 2e2c 2074 5f6b 203d 2073 6f6d 653a  ..., t_k = some:
+0001a3f0: 3a6e 6f64 6528 615f 7661 6c75 655f 6672  :node(a_value_fr
+0001a400: 6f6d 5f6f 7574 6572 5f62 6c6f 636b 290a  om_outer_block).
+0001a410: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001a420: 795f 312c 202e 2e2e 2c20 795f 7220 3d20  y_1, ..., y_r = 
+0001a430: 745f 312c 202e 2e2e 2c20 745f 720a 2020  t_1, ..., t_r.  
+0001a440: 2020 2020 2020 2020 2020 656c 7365 3a0a            else:.
+0001a450: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001a460: 665f 312c 202e 2e2e 2c20 665f 6d20 3d20  f_1, ..., f_m = 
+0001a470: 736f 6d65 3a3a 6e6f 6465 2861 5f76 616c  some::node(a_val
+0001a480: 7565 5f66 726f 6d5f 6f75 7465 725f 626c  ue_from_outer_bl
+0001a490: 6f63 6b29 0a20 2020 2020 2020 2020 2020  ock).           
+0001a4a0: 2020 2020 2079 5f31 2c20 2e2e 2e2c 2079       y_1, ..., y
+0001a4b0: 5f72 203d 2066 5f31 2c20 2e2e 2e2c 2066  _r = f_1, ..., f
+0001a4c0: 5f72 0a0a 2020 2020 2020 2020 5768 6963  _r..        Whic
+0001a4d0: 6820 6675 7274 6865 7220 7472 616e 736c  h further transl
+0001a4e0: 6174 6573 2074 6f20 4d49 4c20 636f 6e64  ates to MIL cond
+0001a4f0: 2061 733a 0a20 2020 2020 2020 2020 2020   as:.           
+0001a500: 205f 7472 7565 203d 207b 0a20 2020 2020   _true = {.     
+0001a510: 2020 2020 2020 2020 2020 2074 5f31 2c20             t_1, 
+0001a520: 2e2e 2e2c 2074 5f6b 203d 2073 6f6d 653a  ..., t_k = some:
+0001a530: 3a6e 6f64 6528 615f 7661 6c75 655f 6672  :node(a_value_fr
+0001a540: 6f6d 5f6f 7574 6572 5f62 6c6f 636b 290a  om_outer_block).
+0001a550: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001a560: 7265 7475 726e 2028 745f 312c 202e 2e2e  return (t_1, ...
+0001a570: 2c20 745f 7229 0a20 2020 2020 2020 2020  , t_r).         
+0001a580: 2020 207d 0a20 2020 2020 2020 2020 2020     }.           
+0001a590: 205f 6661 6c73 6520 3d20 7b0a 2020 2020   _false = {.    
+0001a5a0: 2020 2020 2020 2020 2020 2020 665f 312c              f_1,
+0001a5b0: 202e 2e2e 2c20 665f 6d20 3d20 736f 6d65   ..., f_m = some
+0001a5c0: 3a3a 6e6f 6465 2861 5f76 616c 7565 5f66  ::node(a_value_f
+0001a5d0: 726f 6d5f 6f75 7465 725f 626c 6f63 6b29  rom_outer_block)
+0001a5e0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001a5f0: 2072 6574 7572 6e20 2866 5f31 2c20 2e2e   return (f_1, ..
+0001a600: 2e2c 2066 5f6d 290a 2020 2020 2020 2020  ., f_m).        
+0001a610: 2020 2020 7d0a 2020 2020 2222 220a 2020      }.    """.  
+0001a620: 2020 6e61 6d65 203d 206e 6f64 652e 6e61    name = node.na
+0001a630: 6d65 0a20 2020 2023 2069 6e70 7574 735b  me.    # inputs[
+0001a640: 305d 3a20 636f 6e64 6974 696f 6e0a 2020  0]: condition.  
+0001a650: 2020 696e 7075 7473 203d 205f 6765 745f    inputs = _get_
+0001a660: 696e 7075 7473 2863 6f6e 7465 7874 2c20  inputs(context, 
+0001a670: 6e6f 6465 2c20 6578 7065 6374 6564 3d31  node, expected=1
+0001a680: 290a 2020 2020 636f 6e64 6974 696f 6e20  ).    condition 
+0001a690: 3d20 696e 7075 7473 5b30 5d0a 0a20 2020  = inputs[0]..   
+0001a6a0: 2061 7373 6572 7420 6c65 6e28 6e6f 6465   assert len(node
+0001a6b0: 2e62 6c6f 636b 7329 203d 3d20 320a 2020  .blocks) == 2.  
+0001a6c0: 2020 7472 7565 5f62 6c6f 636b 203d 206e    true_block = n
+0001a6d0: 6f64 652e 626c 6f63 6b73 5b30 5d0a 2020  ode.blocks[0].  
+0001a6e0: 2020 6661 6c73 655f 626c 6f63 6b20 3d20    false_block = 
+0001a6f0: 6e6f 6465 2e62 6c6f 636b 735b 315d 0a0a  node.blocks[1]..
+0001a700: 2020 2020 6465 6620 5f74 7275 655f 7061      def _true_pa
+0001a710: 7468 2829 3a0a 2020 2020 2020 2020 7265  th():.        re
+0001a720: 7320 3d20 636f 6e76 6572 745f 626c 6f63  s = convert_bloc
+0001a730: 6b28 636f 6e74 6578 742c 2074 7275 655f  k(context, true_
+0001a740: 626c 6f63 6b2c 205b 5d29 0a20 2020 2020  block, []).     
+0001a750: 2020 2072 6574 7572 6e20 7475 706c 6528     return tuple(
+0001a760: 7265 7329 0a0a 2020 2020 6465 6620 5f66  res)..    def _f
+0001a770: 616c 7365 5f70 6174 6828 293a 0a20 2020  alse_path():.   
+0001a780: 2020 2020 2072 6573 203d 2063 6f6e 7665       res = conve
+0001a790: 7274 5f62 6c6f 636b 2863 6f6e 7465 7874  rt_block(context
+0001a7a0: 2c20 6661 6c73 655f 626c 6f63 6b2c 205b  , false_block, [
+0001a7b0: 5d29 0a20 2020 2020 2020 2072 6574 7572  ]).        retur
+0001a7c0: 6e20 7475 706c 6528 7265 7329 0a0a 2020  n tuple(res)..  
+0001a7d0: 2020 636f 6e64 203d 206d 622e 636f 6e64    cond = mb.cond
+0001a7e0: 280a 2020 2020 2020 2020 7072 6564 3d63  (.        pred=c
+0001a7f0: 6f6e 6469 7469 6f6e 2c20 5f74 7275 655f  ondition, _true_
+0001a800: 666e 3d5f 7472 7565 5f70 6174 682c 205f  fn=_true_path, _
+0001a810: 6661 6c73 655f 666e 3d5f 6661 6c73 655f  false_fn=_false_
+0001a820: 7061 7468 2c20 6e61 6d65 3d6e 616d 650a  path, name=name.
+0001a830: 2020 2020 290a 2020 2020 2320 4966 2074      ).    # If t
+0001a840: 6865 2063 6f6e 6469 7469 6f6e 206f 6e6c  he condition onl
+0001a850: 7920 7265 7475 726e 7320 6f6e 6520 6974  y returns one it
+0001a860: 656d 2c20 7772 6170 2069 7420 696e 2061  em, wrap it in a
+0001a870: 2074 7570 6c65 2e0a 2020 2020 6966 206e   tuple..    if n
+0001a880: 6f74 2069 7369 6e73 7461 6e63 6528 636f  ot isinstance(co
+0001a890: 6e64 2c20 2874 7570 6c65 2c20 6c69 7374  nd, (tuple, list
+0001a8a0: 2929 3a0a 2020 2020 2020 2020 636f 6e64  )):.        cond
+0001a8b0: 203d 2028 636f 6e64 2c29 0a0a 2020 2020   = (cond,)..    
+0001a8c0: 2320 4d61 6b65 2073 7572 6520 7468 6520  # Make sure the 
+0001a8d0: 636f 6e64 6974 696f 6e20 7265 7475 726e  condition return
+0001a8e0: 6564 2074 6865 2065 7870 6563 7465 6420  ed the expected 
+0001a8f0: 6e75 6d62 6572 206f 6620 6f75 7470 7574  number of output
+0001a900: 732e 0a20 2020 2061 7373 6572 7420 6c65  s..    assert le
+0001a910: 6e28 636f 6e64 2920 3d3d 206c 656e 286e  n(cond) == len(n
+0001a920: 6f64 652e 6f75 7470 7574 7329 0a20 2020  ode.outputs).   
+0001a930: 2066 6f72 206f 7574 7075 745f 6e61 6d65   for output_name
+0001a940: 2c20 6f75 7470 7574 5f76 6172 2069 6e20  , output_var in 
+0001a950: 7a69 7028 6e6f 6465 2e6f 7574 7075 7473  zip(node.outputs
+0001a960: 2c20 636f 6e64 293a 0a20 2020 2020 2020  , cond):.       
+0001a970: 2063 6f6e 7465 7874 2e61 6464 286f 7574   context.add(out
+0001a980: 7075 745f 7661 722c 2074 6f72 6368 5f6e  put_var, torch_n
+0001a990: 616d 653d 6f75 7470 7574 5f6e 616d 6529  ame=output_name)
+0001a9a0: 0a0a 0a40 7265 6769 7374 6572 5f74 6f72  ...@register_tor
+0001a9b0: 6368 5f6f 700a 6465 6620 7365 6c65 6374  ch_op.def select
+0001a9c0: 2863 6f6e 7465 7874 2c20 6e6f 6465 293a  (context, node):
+0001a9d0: 0a20 2020 2069 6e70 7574 7320 3d20 5f67  .    inputs = _g
+0001a9e0: 6574 5f69 6e70 7574 7328 636f 6e74 6578  et_inputs(contex
+0001a9f0: 742c 206e 6f64 652c 2065 7870 6563 7465  t, node, expecte
+0001aa00: 643d 3329 0a20 2020 205f 696e 7075 7420  d=3).    _input 
+0001aa10: 3d20 696e 7075 7473 5b30 5d0a 2020 2020  = inputs[0].    
+0001aa20: 6469 6d20 3d20 696e 7075 7473 5b31 5d2e  dim = inputs[1].
+0001aa30: 7661 6c0a 2020 2020 696e 6465 7820 3d20  val.    index = 
+0001aa40: 696e 7075 7473 5b32 5d2e 7661 6c0a 0a20  inputs[2].val.. 
+0001aa50: 2020 2061 7373 6572 7420 6469 6d2e 7368     assert dim.sh
+0001aa60: 6170 6520 3d3d 2028 290a 2020 2020 6173  ape == ().    as
+0001aa70: 7365 7274 2069 6e64 6578 2e73 6861 7065  sert index.shape
+0001aa80: 203d 3d20 2829 0a0a 2020 2020 2320 4e4f   == ()..    # NO
+0001aa90: 5445 3a0a 2020 2020 2320 4561 6368 2069  TE:.    # Each i
+0001aaa0: 6e64 6578 2069 6e20 4062 6567 696e 5f61  ndex in @begin_a
+0001aab0: 7272 6179 2f40 656e 645f 6172 7261 7920  rray/@end_array 
+0001aac0: 636f 7272 6573 706f 6e64 7320 746f 2061  corresponds to a
+0001aad0: 2064 696d 656e 7369 6f6e 206f 6620 405f   dimension of @_
+0001aae0: 696e 7075 740a 2020 2020 2320 4561 6368  input.    # Each
+0001aaf0: 2076 616c 206f 6620 7468 6f73 6520 6172   val of those ar
+0001ab00: 7261 7973 2063 6f72 7265 7370 6f6e 6473  rays corresponds
+0001ab10: 2074 6f20 7468 6520 7374 6172 742f 656e   to the start/en
+0001ab20: 6420 696e 6465 7820 746f 2073 6c69 6365  d index to slice
+0001ab30: 2069 6e20 7468 6174 2064 696d 656e 7369   in that dimensi
+0001ab40: 6f6e 0a20 2020 2072 616e 6b20 3d20 5f69  on.    rank = _i
+0001ab50: 6e70 7574 2e72 616e 6b0a 2020 2020 6265  nput.rank.    be
+0001ab60: 6769 6e5f 6172 7261 7920 3d20 5b30 5d20  gin_array = [0] 
+0001ab70: 2a20 7261 6e6b 0a20 2020 2062 6567 696e  * rank.    begin
+0001ab80: 5f61 7272 6179 5b64 696d 5d20 3d20 696e  _array[dim] = in
+0001ab90: 6465 780a 2020 2020 656e 645f 6172 7261  dex.    end_arra
+0001aba0: 7920 3d20 5b73 2069 6620 6973 696e 7374  y = [s if isinst
+0001abb0: 616e 6365 2873 2c20 696e 7429 2065 6c73  ance(s, int) els
+0001abc0: 6520 3020 666f 7220 7320 696e 205f 696e  e 0 for s in _in
+0001abd0: 7075 742e 7368 6170 655d 0a20 2020 2065  put.shape].    e
+0001abe0: 6e64 5f6d 6173 6b20 3d20 5b54 7275 655d  nd_mask = [True]
+0001abf0: 202a 2072 616e 6b0a 2020 2020 7371 7565   * rank.    sque
+0001ac00: 657a 655f 6d61 736b 203d 205b 4661 6c73  eze_mask = [Fals
+0001ac10: 655d 202a 2072 616e 6b0a 2020 2020 7371  e] * rank.    sq
+0001ac20: 7565 657a 655f 6d61 736b 5b64 696d 5d20  ueeze_mask[dim] 
+0001ac30: 3d20 5472 7565 0a0a 2020 2020 6966 2069  = True..    if i
+0001ac40: 6e64 6578 2021 3d20 2d31 3a0a 2020 2020  ndex != -1:.    
+0001ac50: 2020 2020 656e 645f 6172 7261 795b 6469      end_array[di
+0001ac60: 6d5d 203d 2069 6e64 6578 202b 2031 0a20  m] = index + 1. 
+0001ac70: 2020 2020 2020 2065 6e64 5f6d 6173 6b5b         end_mask[
+0001ac80: 6469 6d5d 203d 2046 616c 7365 0a0a 2020  dim] = False..  
+0001ac90: 2020 736c 6963 655f 6279 5f69 6e64 6578    slice_by_index
+0001aca0: 203d 206d 622e 736c 6963 655f 6279 5f69   = mb.slice_by_i
+0001acb0: 6e64 6578 280a 2020 2020 2020 2020 783d  ndex(.        x=
+0001acc0: 5f69 6e70 7574 2c0a 2020 2020 2020 2020  _input,.        
+0001acd0: 6265 6769 6e3d 6265 6769 6e5f 6172 7261  begin=begin_arra
+0001ace0: 792c 0a20 2020 2020 2020 2065 6e64 3d65  y,.        end=e
+0001acf0: 6e64 5f61 7272 6179 2c0a 2020 2020 2020  nd_array,.      
+0001ad00: 2020 656e 645f 6d61 736b 3d65 6e64 5f6d    end_mask=end_m
+0001ad10: 6173 6b2c 0a20 2020 2020 2020 2073 7175  ask,.        squ
+0001ad20: 6565 7a65 5f6d 6173 6b3d 7371 7565 657a  eeze_mask=squeez
+0001ad30: 655f 6d61 736b 2c0a 2020 2020 2020 2020  e_mask,.        
+0001ad40: 6e61 6d65 3d6e 6f64 652e 6e61 6d65 2c0a  name=node.name,.
+0001ad50: 2020 2020 290a 2020 2020 636f 6e74 6578      ).    contex
+0001ad60: 742e 6164 6428 736c 6963 655f 6279 5f69  t.add(slice_by_i
+0001ad70: 6e64 6578 290a 0a0a 4072 6567 6973 7465  ndex)...@registe
+0001ad80: 725f 746f 7263 685f 6f70 0a64 6566 2074  r_torch_op.def t
+0001ad90: 7970 655f 6173 2863 6f6e 7465 7874 2c20  ype_as(context, 
+0001ada0: 6e6f 6465 293a 0a20 2020 2069 6e70 7574  node):.    input
+0001adb0: 7320 3d20 5f67 6574 5f69 6e70 7574 7328  s = _get_inputs(
+0001adc0: 636f 6e74 6578 742c 206e 6f64 652c 2065  context, node, e
+0001add0: 7870 6563 7465 643d 3229 0a0a 2020 2020  xpected=2)..    
+0001ade0: 6966 2069 6e70 7574 735b 305d 2e64 7479  if inputs[0].dty
+0001adf0: 7065 203d 3d20 696e 7075 7473 5b31 5d2e  pe == inputs[1].
+0001ae00: 6474 7970 653a 0a20 2020 2020 2020 2078  dtype:.        x
+0001ae10: 203d 206d 622e 6964 656e 7469 7479 2878   = mb.identity(x
+0001ae20: 3d69 6e70 7574 735b 305d 2c20 6e61 6d65  =inputs[0], name
+0001ae30: 3d6e 6f64 652e 6e61 6d65 290a 2020 2020  =node.name).    
+0001ae40: 656c 7365 3a0a 2020 2020 2020 2020 7820  else:.        x 
+0001ae50: 3d20 696e 7075 7473 5b30 5d0a 2020 2020  = inputs[0].    
+0001ae60: 2020 2020 6966 2069 6e70 7574 735b 315d      if inputs[1]
+0001ae70: 2e64 7479 7065 206e 6f74 2069 6e20 5459  .dtype not in TY
+0001ae80: 5045 5f54 4f5f 4454 5950 455f 5354 5249  PE_TO_DTYPE_STRI
+0001ae90: 4e47 3a0a 2020 2020 2020 2020 2020 2020  NG:.            
+0001aea0: 7261 6973 6520 4e6f 7449 6d70 6c65 6d65  raise NotImpleme
+0001aeb0: 6e74 6564 4572 726f 7228 0a20 2020 2020  ntedError(.     
+0001aec0: 2020 2020 2020 2020 2020 2022 5465 6e73             "Tens
+0001aed0: 6f72 2074 7970 6520 7b7d 2063 6173 7420  or type {} cast 
+0001aee0: 6973 206e 6f74 2073 7570 706f 7274 6564  is not supported
+0001aef0: 2e22 2e66 6f72 6d61 7428 696e 7075 7473  .".format(inputs
+0001af00: 5b31 5d2e 6474 7970 6529 0a20 2020 2020  [1].dtype).     
+0001af10: 2020 2020 2020 2029 0a20 2020 2020 2020         ).       
+0001af20: 2078 203d 206d 622e 6361 7374 2878 3d78   x = mb.cast(x=x
+0001af30: 2c20 6474 7970 653d 5459 5045 5f54 4f5f  , dtype=TYPE_TO_
+0001af40: 4454 5950 455f 5354 5249 4e47 5b69 6e70  DTYPE_STRING[inp
+0001af50: 7574 735b 315d 2e64 7479 7065 5d2c 206e  uts[1].dtype], n
+0001af60: 616d 653d 6e6f 6465 2e6e 616d 6529 0a0a  ame=node.name)..
+0001af70: 2020 2020 636f 6e74 6578 742e 6164 6428      context.add(
+0001af80: 7829 0a0a 0a40 7265 6769 7374 6572 5f74  x)...@register_t
+0001af90: 6f72 6368 5f6f 700a 6465 6620 6e6f 6e7a  orch_op.def nonz
+0001afa0: 6572 6f28 636f 6e74 6578 742c 206e 6f64  ero(context, nod
+0001afb0: 6529 3a0a 2020 2020 696e 7075 7473 203d  e):.    inputs =
+0001afc0: 205f 6765 745f 696e 7075 7473 2863 6f6e   _get_inputs(con
+0001afd0: 7465 7874 2c20 6e6f 6465 2c20 6578 7065  text, node, expe
+0001afe0: 6374 6564 3d31 290a 2020 2020 7820 3d20  cted=1).    x = 
+0001aff0: 696e 7075 7473 5b30 5d0a 2020 2020 6e6f  inputs[0].    no
+0001b000: 6e7a 6572 6f20 3d20 6d62 2e6e 6f6e 5f7a  nzero = mb.non_z
+0001b010: 6572 6f28 783d 782c 206e 616d 653d 6e6f  ero(x=x, name=no
+0001b020: 6465 2e6e 616d 6529 0a20 2020 2063 6f6e  de.name).    con
+0001b030: 7465 7874 2e61 6464 286e 6f6e 7a65 726f  text.add(nonzero
+0001b040: 290a 0a0a 6465 6620 5f67 6574 5f73 6c69  )...def _get_sli
+0001b050: 6365 5f70 6172 616d 7328 636f 6e74 6578  ce_params(contex
+0001b060: 742c 2064 6174 612c 2069 6e70 7574 7329  t, data, inputs)
+0001b070: 3a0a 2020 2020 7261 6e6b 203d 2064 6174  :.    rank = dat
+0001b080: 612e 7261 6e6b 0a20 2020 2062 6567 696e  a.rank.    begin
+0001b090: 203d 205b 305d 202a 2072 616e 6b0a 2020   = [0] * rank.  
+0001b0a0: 2020 656e 6420 3d20 5b30 5d20 2a20 7261    end = [0] * ra
+0001b0b0: 6e6b 0a20 2020 2073 7472 6964 6520 3d20  nk.    stride = 
+0001b0c0: 5b31 5d20 2a20 7261 6e6b 0a20 2020 2062  [1] * rank.    b
+0001b0d0: 6567 696e 5f6d 6173 6b20 3d20 5b46 616c  egin_mask = [Fal
+0001b0e0: 7365 5d20 2a20 7261 6e6b 0a20 2020 2065  se] * rank.    e
+0001b0f0: 6e64 5f6d 6173 6b20 3d20 5b46 616c 7365  nd_mask = [False
+0001b100: 5d20 2a20 7261 6e6b 0a20 2020 2073 7175  ] * rank.    squ
+0001b110: 6565 7a65 5f6d 6173 6b20 3d20 5b46 616c  eeze_mask = [Fal
+0001b120: 7365 5d20 2a20 7261 6e6b 0a0a 2020 2020  se] * rank..    
+0001b130: 6e75 6d5f 6f66 5f73 6c69 6365 5f73 6574  num_of_slice_set
+0001b140: 203d 206c 656e 2869 6e70 7574 7329 202f   = len(inputs) /
+0001b150: 2f20 330a 0a20 2020 2066 6f72 2069 2069  / 3..    for i i
+0001b160: 6e20 7261 6e67 6528 6e75 6d5f 6f66 5f73  n range(num_of_s
+0001b170: 6c69 6365 5f73 6574 293a 0a20 2020 2020  lice_set):.     
+0001b180: 2020 2069 6620 696e 7075 7473 5b33 202a     if inputs[3 *
+0001b190: 2069 202b 2031 5d20 6973 204e 6f6e 653a   i + 1] is None:
+0001b1a0: 0a20 2020 2020 2020 2020 2020 2023 2054  .            # T
+0001b1b0: 6869 7320 6973 2070 7572 6520 696e 6465  his is pure inde
+0001b1c0: 7820 7365 6c65 6374 0a20 2020 2020 2020  x select.       
+0001b1d0: 2020 2020 2069 6478 203d 2063 6f6e 7465       idx = conte
+0001b1e0: 7874 5b69 6e70 7574 735b 3320 2a20 695d  xt[inputs[3 * i]
+0001b1f0: 5d2e 7661 6c0a 2020 2020 2020 2020 2020  ].val.          
+0001b200: 2020 6265 6769 6e5b 695d 203d 2069 6478    begin[i] = idx
+0001b210: 0a20 2020 2020 2020 2020 2020 2073 7175  .            squ
+0001b220: 6565 7a65 5f6d 6173 6b5b 695d 203d 2054  eeze_mask[i] = T
+0001b230: 7275 650a 2020 2020 2020 2020 656c 7365  rue.        else
+0001b240: 3a0a 2020 2020 2020 2020 2020 2020 2320  :.            # 
+0001b250: 5468 6973 2069 7320 6120 736c 6963 650a  This is a slice.
+0001b260: 2020 2020 2020 2020 2020 2020 6265 6769              begi
+0001b270: 6e5f 7661 7220 3d20 636f 6e74 6578 745b  n_var = context[
+0001b280: 696e 7075 7473 5b33 202a 2069 5d5d 0a20  inputs[3 * i]]. 
+0001b290: 2020 2020 2020 2020 2020 2065 6e64 5f76             end_v
+0001b2a0: 6172 203d 2063 6f6e 7465 7874 5b69 6e70  ar = context[inp
+0001b2b0: 7574 735b 3320 2a20 6920 2b20 315d 5d0a  uts[3 * i + 1]].
+0001b2c0: 2020 2020 2020 2020 2020 2020 7374 7269              stri
+0001b2d0: 6465 5f76 6172 203d 2063 6f6e 7465 7874  de_var = context
+0001b2e0: 5b69 6e70 7574 735b 3320 2a20 6920 2b20  [inputs[3 * i + 
+0001b2f0: 325d 5d0a 0a20 2020 2020 2020 2020 2020  2]]..           
+0001b300: 2069 6620 6265 6769 6e5f 7661 7220 6973   if begin_var is
+0001b310: 204e 6f6e 653a 0a20 2020 2020 2020 2020   None:.         
+0001b320: 2020 2020 2020 2062 6567 696e 5f6d 6173         begin_mas
+0001b330: 6b5b 695d 203d 2054 7275 650a 2020 2020  k[i] = True.    
+0001b340: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
+0001b350: 2020 2020 2020 2020 2020 2020 2020 6265                be
+0001b360: 6769 6e5b 695d 203d 2062 6567 696e 5f76  gin[i] = begin_v
+0001b370: 6172 0a0a 2020 2020 2020 2020 2020 2020  ar..            
+0001b380: 6966 2065 6e64 5f76 6172 2069 7320 4e6f  if end_var is No
+0001b390: 6e65 3a0a 2020 2020 2020 2020 2020 2020  ne:.            
+0001b3a0: 2020 2020 656e 645f 6d61 736b 5b69 5d20      end_mask[i] 
+0001b3b0: 3d20 5472 7565 0a20 2020 2020 2020 2020  = True.         
+0001b3c0: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
+0001b3d0: 2020 2020 2020 2020 2065 6e64 5b69 5d20           end[i] 
+0001b3e0: 3d20 656e 645f 7661 720a 0a20 2020 2020  = end_var..     
+0001b3f0: 2020 2020 2020 2069 6620 7374 7269 6465         if stride
+0001b400: 5f76 6172 2069 7320 4e6f 6e65 3a0a 2020  _var is None:.  
+0001b410: 2020 2020 2020 2020 2020 2020 2020 7374                st
+0001b420: 7269 6465 5b69 5d20 3d20 310a 2020 2020  ride[i] = 1.    
+0001b430: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
+0001b440: 2020 2020 2020 2020 2020 2020 2020 7374                st
+0001b450: 7269 6465 5b69 5d20 3d20 7374 7269 6465  ride[i] = stride
+0001b460: 5f76 6172 2e76 616c 0a0a 2020 2020 666f  _var.val..    fo
+0001b470: 7220 6920 696e 2072 616e 6765 286e 756d  r i in range(num
+0001b480: 5f6f 665f 736c 6963 655f 7365 742c 2072  _of_slice_set, r
+0001b490: 616e 6b29 3a0a 2020 2020 2020 2020 6265  ank):.        be
+0001b4a0: 6769 6e5f 6d61 736b 5b69 5d20 3d20 5472  gin_mask[i] = Tr
+0001b4b0: 7565 0a20 2020 2020 2020 2065 6e64 5f6d  ue.        end_m
+0001b4c0: 6173 6b5b 695d 203d 2054 7275 650a 0a20  ask[i] = True.. 
+0001b4d0: 2020 2062 6567 696e 203d 206d 622e 636f     begin = mb.co
+0001b4e0: 6e63 6174 2876 616c 7565 733d 6265 6769  ncat(values=begi
+0001b4f0: 6e2c 2061 7869 733d 3029 0a20 2020 2065  n, axis=0).    e
+0001b500: 6e64 203d 206d 622e 636f 6e63 6174 2876  nd = mb.concat(v
+0001b510: 616c 7565 733d 656e 642c 2061 7869 733d  alues=end, axis=
+0001b520: 3029 0a0a 2020 2020 7265 7475 726e 2062  0)..    return b
+0001b530: 6567 696e 2c20 656e 642c 2073 7472 6964  egin, end, strid
+0001b540: 652c 2062 6567 696e 5f6d 6173 6b2c 2065  e, begin_mask, e
+0001b550: 6e64 5f6d 6173 6b2c 2073 7175 6565 7a65  nd_mask, squeeze
+0001b560: 5f6d 6173 6b0a 0a0a 4072 6567 6973 7465  _mask...@registe
+0001b570: 725f 746f 7263 685f 6f70 0a64 6566 205f  r_torch_op.def _
+0001b580: 696e 7465 726e 616c 5f6f 705f 7465 6e73  internal_op_tens
+0001b590: 6f72 5f69 6e70 6c61 6365 5f63 6f70 7928  or_inplace_copy(
+0001b5a0: 636f 6e74 6578 742c 206e 6f64 6529 3a0a  context, node):.
+0001b5b0: 2020 2020 6461 7461 203d 2063 6f6e 7465      data = conte
+0001b5c0: 7874 5b6e 6f64 652e 696e 7075 7473 5b30  xt[node.inputs[0
+0001b5d0: 5d5d 0a20 2020 2075 7064 6174 6573 203d  ]].    updates =
+0001b5e0: 2063 6f6e 7465 7874 5b6e 6f64 652e 696e   context[node.in
+0001b5f0: 7075 7473 5b31 5d5d 0a20 2020 2062 6567  puts[1]].    beg
+0001b600: 696e 2c20 656e 642c 2073 7472 6964 652c  in, end, stride,
+0001b610: 2062 6567 696e 5f6d 6173 6b2c 2065 6e64   begin_mask, end
+0001b620: 5f6d 6173 6b2c 2073 7175 6565 7a65 5f6d  _mask, squeeze_m
+0001b630: 6173 6b20 3d20 5f67 6574 5f73 6c69 6365  ask = _get_slice
+0001b640: 5f70 6172 616d 7328 0a20 2020 2020 2020  _params(.       
+0001b650: 2063 6f6e 7465 7874 2c20 6461 7461 2c20   context, data, 
+0001b660: 6e6f 6465 2e69 6e70 7574 735b 323a 5d0a  node.inputs[2:].
+0001b670: 2020 2020 290a 0a20 2020 2064 6174 612c      )..    data,
+0001b680: 2075 7064 6174 6573 203d 2070 726f 6d6f   updates = promo
+0001b690: 7465 5f69 6e70 7574 5f64 7479 7065 7328  te_input_dtypes(
+0001b6a0: 5b64 6174 612c 2075 7064 6174 6573 5d29  [data, updates])
+0001b6b0: 0a20 2020 2075 7064 6174 6564 5f78 203d  .    updated_x =
+0001b6c0: 206d 622e 746f 7263 685f 7465 6e73 6f72   mb.torch_tensor
+0001b6d0: 5f61 7373 6967 6e28 0a20 2020 2020 2020  _assign(.       
+0001b6e0: 2064 6174 613d 6461 7461 2c0a 2020 2020   data=data,.    
+0001b6f0: 2020 2020 7570 6461 7465 733d 7570 6461      updates=upda
+0001b700: 7465 732c 0a20 2020 2020 2020 2062 6567  tes,.        beg
+0001b710: 696e 3d62 6567 696e 2c0a 2020 2020 2020  in=begin,.      
+0001b720: 2020 656e 643d 656e 642c 0a20 2020 2020    end=end,.     
+0001b730: 2020 2073 7472 6964 653d 7374 7269 6465     stride=stride
+0001b740: 2c0a 2020 2020 2020 2020 6265 6769 6e5f  ,.        begin_
+0001b750: 6d61 736b 3d62 6567 696e 5f6d 6173 6b2c  mask=begin_mask,
+0001b760: 0a20 2020 2020 2020 2065 6e64 5f6d 6173  .        end_mas
+0001b770: 6b3d 656e 645f 6d61 736b 2c0a 2020 2020  k=end_mask,.    
+0001b780: 2020 2020 7371 7565 657a 655f 6d61 736b      squeeze_mask
+0001b790: 3d73 7175 6565 7a65 5f6d 6173 6b2c 0a20  =squeeze_mask,. 
+0001b7a0: 2020 2020 2020 206e 616d 653d 6e6f 6465         name=node
+0001b7b0: 2e6e 616d 652c 0a20 2020 2029 0a20 2020  .name,.    ).   
+0001b7c0: 2063 6f6e 7465 7874 2e61 6464 2875 7064   context.add(upd
+0001b7d0: 6174 6564 5f78 290a 0a0a 4072 6567 6973  ated_x)...@regis
+0001b7e0: 7465 725f 746f 7263 685f 6f70 0a64 6566  ter_torch_op.def
+0001b7f0: 205f 696e 7465 726e 616c 5f6f 705f 7465   _internal_op_te
+0001b800: 6e73 6f72 5f69 6e70 6c61 6365 5f66 696c  nsor_inplace_fil
+0001b810: 6c28 636f 6e74 6578 742c 206e 6f64 6529  l(context, node)
+0001b820: 3a0a 2020 2020 6461 7461 203d 2063 6f6e  :.    data = con
+0001b830: 7465 7874 5b6e 6f64 652e 696e 7075 7473  text[node.inputs
+0001b840: 5b30 5d5d 0a20 2020 2066 696c 6c5f 7363  [0]].    fill_sc
+0001b850: 616c 6172 203d 2063 6f6e 7465 7874 5b6e  alar = context[n
+0001b860: 6f64 652e 696e 7075 7473 5b31 5d5d 0a0a  ode.inputs[1]]..
+0001b870: 2020 2020 6265 6769 6e2c 2065 6e64 2c20      begin, end, 
+0001b880: 7374 7269 6465 2c20 6265 6769 6e5f 6d61  stride, begin_ma
+0001b890: 736b 2c20 656e 645f 6d61 736b 2c20 7371  sk, end_mask, sq
+0001b8a0: 7565 657a 655f 6d61 736b 203d 205f 6765  ueeze_mask = _ge
+0001b8b0: 745f 736c 6963 655f 7061 7261 6d73 280a  t_slice_params(.
+0001b8c0: 2020 2020 2020 2020 636f 6e74 6578 742c          context,
+0001b8d0: 2064 6174 612c 206e 6f64 652e 696e 7075   data, node.inpu
+0001b8e0: 7473 5b32 3a5d 0a20 2020 2029 0a20 2020  ts[2:].    ).   
+0001b8f0: 2069 6620 6265 6769 6e2e 7661 6c20 6973   if begin.val is
+0001b900: 204e 6f6e 6520 6f72 2065 6e64 2e76 616c   None or end.val
+0001b910: 2069 7320 4e6f 6e65 3a0a 2020 2020 2020   is None:.      
+0001b920: 2020 7261 6973 6520 5661 6c75 6545 7272    raise ValueErr
+0001b930: 6f72 2822 5f69 6e74 6572 6e61 6c5f 6f70  or("_internal_op
+0001b940: 5f74 656e 736f 725f 696e 706c 6163 655f  _tensor_inplace_
+0001b950: 6669 6c6c 2064 6f65 7320 6e6f 7420 7375  fill does not su
+0001b960: 7070 6f72 7420 6479 6e61 6d69 6320 696e  pport dynamic in
+0001b970: 6465 7822 290a 0a20 2020 2066 696c 6c5f  dex")..    fill_
+0001b980: 7368 6170 6520 3d20 736f 6c76 655f 736c  shape = solve_sl
+0001b990: 6963 655f 6279 5f69 6e64 6578 5f73 6861  ice_by_index_sha
+0001b9a0: 7065 280a 2020 2020 2020 2020 6461 7461  pe(.        data
+0001b9b0: 2e73 6861 7065 2c20 6265 6769 6e2e 7661  .shape, begin.va
+0001b9c0: 6c2c 2065 6e64 2e76 616c 2c20 7374 7269  l, end.val, stri
+0001b9d0: 6465 2c20 6265 6769 6e5f 6d61 736b 2c20  de, begin_mask, 
+0001b9e0: 656e 645f 6d61 736b 2c20 7371 7565 657a  end_mask, squeez
+0001b9f0: 655f 6d61 736b 0a20 2020 2029 0a20 2020  e_mask.    ).   
+0001ba00: 2075 7064 6174 655f 7661 6c75 6573 203d   update_values =
+0001ba10: 205f 6e70 2e66 756c 6c28 6669 6c6c 5f73   _np.full(fill_s
+0001ba20: 6861 7065 2c20 6669 6c6c 5f73 6361 6c61  hape, fill_scala
+0001ba30: 722e 7661 6c29 0a0a 2020 2020 6461 7461  r.val)..    data
+0001ba40: 2c20 7570 6461 7465 5f76 616c 7565 7320  , update_values 
+0001ba50: 3d20 7072 6f6d 6f74 655f 696e 7075 745f  = promote_input_
+0001ba60: 6474 7970 6573 285b 6461 7461 2c20 7570  dtypes([data, up
+0001ba70: 6461 7465 5f76 616c 7565 735d 290a 2020  date_values]).  
+0001ba80: 2020 7570 6461 7465 645f 7820 3d20 6d62    updated_x = mb
+0001ba90: 2e74 6f72 6368 5f74 656e 736f 725f 6173  .torch_tensor_as
+0001baa0: 7369 676e 280a 2020 2020 2020 2020 6461  sign(.        da
+0001bab0: 7461 3d64 6174 612c 0a20 2020 2020 2020  ta=data,.       
+0001bac0: 2075 7064 6174 6573 3d75 7064 6174 655f   updates=update_
+0001bad0: 7661 6c75 6573 2c0a 2020 2020 2020 2020  values,.        
+0001bae0: 6265 6769 6e3d 6265 6769 6e2c 0a20 2020  begin=begin,.   
+0001baf0: 2020 2020 2065 6e64 3d65 6e64 2c0a 2020       end=end,.  
+0001bb00: 2020 2020 2020 7374 7269 6465 3d73 7472        stride=str
+0001bb10: 6964 652c 0a20 2020 2020 2020 2062 6567  ide,.        beg
+0001bb20: 696e 5f6d 6173 6b3d 6265 6769 6e5f 6d61  in_mask=begin_ma
+0001bb30: 736b 2c0a 2020 2020 2020 2020 656e 645f  sk,.        end_
+0001bb40: 6d61 736b 3d65 6e64 5f6d 6173 6b2c 0a20  mask=end_mask,. 
+0001bb50: 2020 2020 2020 2073 7175 6565 7a65 5f6d         squeeze_m
+0001bb60: 6173 6b3d 7371 7565 657a 655f 6d61 736b  ask=squeeze_mask
+0001bb70: 2c0a 2020 2020 2020 2020 6e61 6d65 3d6e  ,.        name=n
+0001bb80: 6f64 652e 6e61 6d65 2c0a 2020 2020 290a  ode.name,.    ).
+0001bb90: 2020 2020 636f 6e74 6578 742e 6164 6428      context.add(
+0001bba0: 7570 6461 7465 645f 7829 0a0a 0a40 7265  updated_x)...@re
+0001bbb0: 6769 7374 6572 5f74 6f72 6368 5f6f 700a  gister_torch_op.
+0001bbc0: 6465 6620 696e 6465 785f 7075 7428 636f  def index_put(co
+0001bbd0: 6e74 6578 742c 206e 6f64 6529 3a0a 2020  ntext, node):.  
+0001bbe0: 2020 696e 7075 7473 203d 205f 6765 745f    inputs = _get_
+0001bbf0: 696e 7075 7473 2863 6f6e 7465 7874 2c20  inputs(context, 
+0001bc00: 6e6f 6465 2c20 6578 7065 6374 6564 3d34  node, expected=4
+0001bc10: 290a 2020 2020 7820 3d20 696e 7075 7473  ).    x = inputs
+0001bc20: 5b30 5d0a 2020 2020 696e 6469 6365 7320  [0].    indices 
+0001bc30: 3d20 696e 7075 7473 5b31 5d0a 2020 2020  = inputs[1].    
+0001bc40: 7661 6c75 6573 203d 2069 6e70 7574 735b  values = inputs[
+0001bc50: 325d 0a20 2020 2061 6363 756d 756c 6174  2].    accumulat
+0001bc60: 6520 3d20 696e 7075 7473 5b33 5d2e 7661  e = inputs[3].va
+0001bc70: 6c0a 2020 2020 7261 6e6b 203d 2078 2e72  l.    rank = x.r
+0001bc80: 616e 6b0a 2020 2020 6d6f 6465 203d 2022  ank.    mode = "
+0001bc90: 6164 6422 2069 6620 6163 6375 6d75 6c61  add" if accumula
+0001bca0: 7465 2065 6c73 6520 2275 7064 6174 6522  te else "update"
+0001bcb0: 0a0a 2020 2020 696e 6469 6365 735f 7479  ..    indices_ty
+0001bcc0: 7065 203d 2069 6e64 6963 6573 5b30 5d2e  pe = indices[0].
+0001bcd0: 7379 6d5f 7479 7065 2e67 6574 5f70 7269  sym_type.get_pri
+0001bce0: 6d69 7469 7665 2829 0a0a 2020 2020 6966  mitive()..    if
+0001bcf0: 2074 7970 6573 2e69 735f 626f 6f6c 2869   types.is_bool(i
+0001bd00: 6e64 6963 6573 5f74 7970 6529 3a0a 2020  ndices_type):.  
+0001bd10: 2020 2020 2020 6173 7365 7274 206c 656e        assert len
+0001bd20: 2869 6e64 6963 6573 2920 3d3d 2031 2c20  (indices) == 1, 
+0001bd30: 2255 6e73 7570 706f 7274 6564 2069 6e64  "Unsupported ind
+0001bd40: 6578 5f70 7574 5f20 7573 6167 652e 220a  ex_put_ usage.".
+0001bd50: 2020 2020 2020 2020 696e 6469 6365 7320          indices 
+0001bd60: 3d20 696e 6469 6365 735b 305d 0a20 2020  = indices[0].   
+0001bd70: 2020 2020 2061 7373 6572 7420 280a 2020       assert (.  
+0001bd80: 2020 2020 2020 2020 2020 696e 6469 6365            indice
+0001bd90: 732e 7368 6170 6520 3d3d 2078 2e73 6861  s.shape == x.sha
+0001bda0: 7065 0a20 2020 2020 2020 2029 2c20 2269  pe.        ), "i
+0001bdb0: 6e64 6963 6573 2073 6861 7065 206d 7573  ndices shape mus
+0001bdc0: 7420 6571 7561 6c20 746f 2069 6e70 7574  t equal to input
+0001bdd0: 2073 6861 7065 2066 6f72 2069 6e64 6578   shape for index
+0001bde0: 2070 7574 206f 7065 7261 7469 6f6e 2e22   put operation."
+0001bdf0: 0a20 2020 2020 2020 2069 6e64 6963 6573  .        indices
+0001be00: 203d 206d 622e 6361 7374 2878 3d69 6e64   = mb.cast(x=ind
+0001be10: 6963 6573 2c20 6474 7970 653d 2269 6e74  ices, dtype="int
+0001be20: 3332 2229 0a20 2020 2020 2020 2069 6e64  32").        ind
+0001be30: 6963 6573 203d 206d 622e 6e6f 6e5f 7a65  ices = mb.non_ze
+0001be40: 726f 2878 3d69 6e64 6963 6573 290a 0a20  ro(x=indices).. 
+0001be50: 2020 2069 6620 7479 7065 732e 6973 5f69     if types.is_i
+0001be60: 6e74 2869 6e64 6963 6573 5f74 7970 6529  nt(indices_type)
+0001be70: 3a0a 2020 2020 2020 2020 6966 206c 656e  :.        if len
+0001be80: 2869 6e64 6963 6573 2920 3e20 313a 0a20  (indices) > 1:. 
+0001be90: 2020 2020 2020 2020 2020 2069 6e64 6963             indic
+0001bea0: 6573 203d 206d 622e 7374 6163 6b28 7661  es = mb.stack(va
+0001beb0: 6c75 6573 3d69 6e64 6963 6573 2c20 6178  lues=indices, ax
+0001bec0: 6973 3d69 6e64 6963 6573 5b30 5d2e 7261  is=indices[0].ra
+0001bed0: 6e6b 290a 2020 2020 2020 2020 656c 7365  nk).        else
+0001bee0: 3a0a 2020 2020 2020 2020 2020 2020 696e  :.            in
+0001bef0: 6469 6365 7320 3d20 6d62 2e65 7870 616e  dices = mb.expan
+0001bf00: 645f 6469 6d73 2878 3d69 6e64 6963 6573  d_dims(x=indices
+0001bf10: 5b30 5d2c 2061 7865 733d 5b2d 315d 290a  [0], axes=[-1]).
+0001bf20: 0a20 2020 2069 6620 6c65 6e28 7661 6c75  .    if len(valu
+0001bf30: 6573 2e73 6861 7065 2920 3d3d 2030 3a0a  es.shape) == 0:.
+0001bf40: 2020 2020 2020 2020 7661 6c75 6573 203d          values =
+0001bf50: 206d 622e 6578 7061 6e64 5f64 696d 7328   mb.expand_dims(
+0001bf60: 783d 7661 6c75 6573 2c20 6178 6573 3d5b  x=values, axes=[
+0001bf70: 305d 290a 0a20 2020 2069 6620 7661 6c75  0])..    if valu
+0001bf80: 6573 2e72 616e 6b20 3d3d 2031 2061 6e64  es.rank == 1 and
+0001bf90: 2076 616c 7565 732e 7368 6170 655b 305d   values.shape[0]
+0001bfa0: 203d 3d20 313a 0a20 2020 2020 2020 2072   == 1:.        r
+0001bfb0: 6570 7320 3d20 7661 6c75 655f 6174 286d  eps = value_at(m
+0001bfc0: 622e 7368 6170 6528 783d 696e 6469 6365  b.shape(x=indice
+0001bfd0: 7329 2c20 3029 0a20 2020 2020 2020 2072  s), 0).        r
+0001bfe0: 6570 7320 3d20 6d62 2e65 7870 616e 645f  eps = mb.expand_
+0001bff0: 6469 6d73 2878 3d72 6570 732c 2061 7865  dims(x=reps, axe
+0001c000: 733d 5b30 5d29 0a20 2020 2020 2020 2076  s=[0]).        v
+0001c010: 616c 7565 7320 3d20 6d62 2e74 696c 6528  alues = mb.tile(
+0001c020: 783d 7661 6c75 6573 2c20 7265 7073 3d72  x=values, reps=r
+0001c030: 6570 7329 0a0a 2020 2020 6966 2069 735f  eps)..    if is_
+0001c040: 6375 7272 656e 745f 6f70 7365 745f 7665  current_opset_ve
+0001c050: 7273 696f 6e5f 636f 6d70 6174 6962 6c65  rsion_compatible
+0001c060: 5f77 6974 6828 7461 7267 6574 2e69 4f53  _with(target.iOS
+0001c070: 3137 293a 0a20 2020 2020 2020 2023 2049  17):.        # I
+0001c080: 4f53 3137 2060 7363 6174 7465 725f 6e64  OS17 `scatter_nd
+0001c090: 6020 6265 6861 7669 6f75 7220 6973 2075  ` behaviour is u
+0001c0a0: 6e64 6566 696e 6564 2066 6f72 206e 6567  ndefined for neg
+0001c0b0: 6174 6976 6520 696e 6469 6365 732e 0a20  ative indices.. 
+0001c0c0: 2020 2020 2020 2063 6f6e 6420 3d20 6d62         cond = mb
+0001c0d0: 2e67 7265 6174 6572 5f65 7175 616c 2878  .greater_equal(x
+0001c0e0: 3d69 6e64 6963 6573 2c20 793d 3029 0a20  =indices, y=0). 
+0001c0f0: 2020 2020 2020 2078 5f73 6861 7065 203d         x_shape =
+0001c100: 206d 622e 7368 6170 6528 783d 7829 0a20   mb.shape(x=x). 
+0001c110: 2020 2020 2020 2069 6e64 6963 6573 5f73         indices_s
+0001c120: 6861 7065 203d 206d 622e 7368 6170 6528  hape = mb.shape(
+0001c130: 783d 696e 6469 6365 7329 0a20 2020 2020  x=indices).     
+0001c140: 2020 2069 6e64 6963 6573 5f6c 6173 745f     indices_last_
+0001c150: 6469 6d20 3d20 7661 6c75 655f 6174 2869  dim = value_at(i
+0001c160: 6e64 6963 6573 5f73 6861 7065 2c20 696e  ndices_shape, in
+0001c170: 6469 6365 732e 7261 6e6b 202d 2031 290a  dices.rank - 1).
+0001c180: 2020 2020 2020 2020 696e 6469 6365 735f          indices_
+0001c190: 6c61 7374 5f64 696d 5f65 7870 616e 6420  last_dim_expand 
+0001c1a0: 3d20 6d62 2e65 7870 616e 645f 6469 6d73  = mb.expand_dims
+0001c1b0: 2878 3d69 6e64 6963 6573 5f6c 6173 745f  (x=indices_last_
+0001c1c0: 6469 6d2c 2061 7865 733d 5b30 5d29 0a20  dim, axes=[0]). 
+0001c1d0: 2020 2020 2020 2073 6c69 6365 5f73 6861         slice_sha
+0001c1e0: 7065 203d 206d 622e 736c 6963 655f 6279  pe = mb.slice_by
+0001c1f0: 5f73 697a 6528 783d 785f 7368 6170 652c  _size(x=x_shape,
+0001c200: 2062 6567 696e 3d5b 305d 2c20 7369 7a65   begin=[0], size
+0001c210: 3d69 6e64 6963 6573 5f6c 6173 745f 6469  =indices_last_di
+0001c220: 6d5f 6578 7061 6e64 290a 2020 2020 2020  m_expand).      
+0001c230: 2020 696e 6469 6365 7320 3d20 6d62 2e73    indices = mb.s
+0001c240: 656c 6563 7428 0a20 2020 2020 2020 2020  elect(.         
+0001c250: 2020 2063 6f6e 643d 636f 6e64 2c0a 2020     cond=cond,.  
+0001c260: 2020 2020 2020 2020 2020 613d 696e 6469            a=indi
+0001c270: 6365 732c 0a20 2020 2020 2020 2020 2020  ces,.           
+0001c280: 2062 3d6d 622e 6164 6428 783d 696e 6469   b=mb.add(x=indi
+0001c290: 6365 732c 2079 3d73 6c69 6365 5f73 6861  ces, y=slice_sha
+0001c2a0: 7065 292c 0a20 2020 2020 2020 2029 0a20  pe),.        ). 
+0001c2b0: 2020 2072 6573 756c 7420 3d20 6d62 2e73     result = mb.s
+0001c2c0: 6361 7474 6572 5f6e 6428 6461 7461 3d78  catter_nd(data=x
+0001c2d0: 2c20 696e 6469 6365 733d 696e 6469 6365  , indices=indice
+0001c2e0: 732c 2075 7064 6174 6573 3d76 616c 7565  s, updates=value
+0001c2f0: 732c 206d 6f64 653d 6d6f 6465 2c20 6e61  s, mode=mode, na
+0001c300: 6d65 3d6e 6f64 652e 6e61 6d65 290a 2020  me=node.name).  
+0001c310: 2020 636f 6e74 6578 742e 6164 6428 7265    context.add(re
+0001c320: 7375 6c74 290a 0a0a 4072 6567 6973 7465  sult)...@registe
+0001c330: 725f 746f 7263 685f 6f70 0a64 6566 2069  r_torch_op.def i
+0001c340: 6e64 6578 2863 6f6e 7465 7874 2c20 6e6f  ndex(context, no
+0001c350: 6465 293a 0a20 2020 2069 6e70 7574 7320  de):.    inputs 
+0001c360: 3d20 5f67 6574 5f69 6e70 7574 7328 636f  = _get_inputs(co
+0001c370: 6e74 6578 742c 206e 6f64 652c 2065 7870  ntext, node, exp
+0001c380: 6563 7465 643d 3229 0a20 2020 2078 203d  ected=2).    x =
+0001c390: 2069 6e70 7574 735b 305d 0a20 2020 2069   inputs[0].    i
+0001c3a0: 6e64 6963 6573 203d 2069 6e70 7574 735b  ndices = inputs[
+0001c3b0: 315d 0a20 2020 2072 616e 6b20 3d20 782e  1].    rank = x.
+0001c3c0: 7261 6e6b 0a0a 2020 2020 2222 220a 2020  rank..    """.  
+0001c3d0: 2020 4361 7365 2031 3a20 4120 7369 6e67    Case 1: A sing
+0001c3e0: 6c65 2062 6f6f 6c65 616e 2069 6e64 6578  le boolean index
+0001c3f0: 2073 656c 6563 7469 6f6e 0a20 2020 2045   selection.    E
+0001c400: 783a 0a20 2020 2020 2020 2061 203d 2074  x:.        a = t
+0001c410: 6f72 6368 2e72 616e 6428 322c 2033 2c20  orch.rand(2, 3, 
+0001c420: 3429 0a20 2020 2020 2020 2062 203d 2074  4).        b = t
+0001c430: 6f72 6368 2e72 616e 6428 332c 2034 290a  orch.rand(3, 4).
+0001c440: 2020 2020 2020 2020 696e 6465 7820 3d20          index = 
+0001c450: 6220 3e20 302e 310a 2020 2020 2020 2020  b > 0.1.        
+0001c460: 6320 3d20 615b 3a2c 2062 5d0a 0a20 2020  c = a[:, b]..   
+0001c470: 2046 6f72 2074 6869 7320 6361 7365 2c20   For this case, 
+0001c480: 7468 6520 6f6e 6c79 206e 6f6e 2d4e 6f6e  the only non-Non
+0001c490: 6520 7465 6e73 6f72 2069 7320 7769 7468  e tensor is with
+0001c4a0: 2064 7479 7065 2062 6f6f 6c0a 2020 2020   dtype bool.    
+0001c4b0: 5468 6520 7472 7565 2076 616c 7565 2069  The true value i
+0001c4c0: 6e64 6963 6174 6573 2077 6865 7468 6572  ndicates whether
+0001c4d0: 2074 6865 2065 6c65 6d65 6e74 2073 686f   the element sho
+0001c4e0: 756c 6420 6265 2073 656c 6563 7465 6420  uld be selected 
+0001c4f0: 616d 6f6e 6720 7468 6520 6d61 736b 6564  among the masked
+0001c500: 2061 7865 730a 2020 2020 5468 6520 6f75   axes.    The ou
+0001c510: 7470 7574 2063 2069 7320 6120 7465 6e73  tput c is a tens
+0001c520: 6f72 2077 6974 6820 7368 6170 6520 2832  or with shape (2
+0001c530: 2c20 4e29 2c20 7768 6572 6520 4e20 6973  , N), where N is
+0001c540: 2074 6865 206e 756d 6265 7220 6f66 2065   the number of e
+0001c550: 6c65 6d65 6e74 7320 6f66 2062 2073 6174  lements of b sat
+0001c560: 6973 6679 696e 6720 636f 6e64 6974 696f  isfying conditio
+0001c570: 6e20 3e20 302e 310a 2020 2020 2222 220a  n > 0.1.    """.
+0001c580: 2020 2020 626f 6f6c 6561 6e5f 696e 6469      boolean_indi
+0001c590: 6365 735f 6178 6973 203d 205b 5d0a 2020  ces_axis = [].  
+0001c5a0: 2020 666f 7220 692c 2069 6e64 6578 2069    for i, index i
+0001c5b0: 6e20 656e 756d 6572 6174 6528 696e 6469  n enumerate(indi
+0001c5c0: 6365 7329 3a0a 2020 2020 2020 2020 6966  ces):.        if
+0001c5d0: 2069 6e64 6578 2069 7320 6e6f 7420 4e6f   index is not No
+0001c5e0: 6e65 2061 6e64 2074 7970 6573 2e69 735f  ne and types.is_
+0001c5f0: 626f 6f6c 2869 6e64 6578 2e64 7479 7065  bool(index.dtype
+0001c600: 293a 0a20 2020 2020 2020 2020 2020 2062  ):.            b
+0001c610: 6f6f 6c65 616e 5f69 6e64 6963 6573 5f61  oolean_indices_a
+0001c620: 7869 732e 6170 7065 6e64 2869 290a 2020  xis.append(i).  
+0001c630: 2020 6966 206c 656e 2862 6f6f 6c65 616e    if len(boolean
+0001c640: 5f69 6e64 6963 6573 5f61 7869 7329 203d  _indices_axis) =
+0001c650: 3d20 313a 0a20 2020 2020 2020 2023 2067  = 1:.        # g
+0001c660: 6574 2074 6865 2054 7275 6520 656c 656d  et the True elem
+0001c670: 656e 7420 696e 6469 6365 730a 2020 2020  ent indices.    
+0001c680: 2020 2020 6178 6973 203d 2062 6f6f 6c65      axis = boole
+0001c690: 616e 5f69 6e64 6963 6573 5f61 7869 735b  an_indices_axis[
+0001c6a0: 305d 0a20 2020 2020 2020 2061 7865 7320  0].        axes 
+0001c6b0: 3d20 6c69 7374 2872 616e 6765 2861 7869  = list(range(axi
+0001c6c0: 732c 2061 7869 7320 2b20 696e 6465 782e  s, axis + index.
+0001c6d0: 7261 6e6b 2929 0a20 2020 2020 2020 2069  rank)).        i
+0001c6e0: 6e64 6578 203d 2069 6e64 6963 6573 5b61  ndex = indices[a
+0001c6f0: 7869 735d 0a20 2020 2020 2020 2069 6e64  xis].        ind
+0001c700: 6578 203d 206d 622e 6e6f 6e5f 7a65 726f  ex = mb.non_zero
+0001c710: 2878 3d69 6e64 6578 290a 0a20 2020 2020  (x=index)..     
+0001c720: 2020 2023 2074 7261 6e70 6f73 6520 7468     # tranpose th
+0001c730: 6520 6d61 736b 6564 2061 7865 7320 746f  e masked axes to
+0001c740: 2074 6865 2062 6567 696e 6e69 6e67 0a20   the beginning. 
+0001c750: 2020 2020 2020 2070 6572 6d20 3d20 6178         perm = ax
+0001c760: 6573 202b 205b 6920 666f 7220 6920 696e  es + [i for i in
+0001c770: 2072 616e 6765 2872 616e 6b29 2069 6620   range(rank) if 
+0001c780: 6920 6e6f 7420 696e 2061 7865 735d 0a20  i not in axes]. 
+0001c790: 2020 2020 2020 2078 203d 206d 622e 7472         x = mb.tr
+0001c7a0: 616e 7370 6f73 6528 783d 782c 2070 6572  anspose(x=x, per
+0001c7b0: 6d3d 7065 726d 290a 2020 2020 2020 2020  m=perm).        
+0001c7c0: 7820 3d20 6d62 2e67 6174 6865 725f 6e64  x = mb.gather_nd
+0001c7d0: 2878 3d78 2c20 696e 6469 6365 733d 696e  (x=x, indices=in
+0001c7e0: 6465 7829 0a0a 2020 2020 2020 2020 2320  dex)..        # 
+0001c7f0: 7472 616e 7370 6f73 6520 7468 6520 7465  transpose the te
+0001c800: 6e73 6f72 2062 6163 6b0a 2020 2020 2020  nsor back.      
+0001c810: 2020 7065 726d 5f62 6163 6b20 3d20 6c69    perm_back = li
+0001c820: 7374 2872 616e 6765 2831 2c20 782e 7261  st(range(1, x.ra
+0001c830: 6e6b 2929 0a20 2020 2020 2020 2070 6572  nk)).        per
+0001c840: 6d5f 6261 636b 2e69 6e73 6572 7428 6178  m_back.insert(ax
+0001c850: 6973 2c20 3029 0a20 2020 2020 2020 2072  is, 0).        r
+0001c860: 6573 203d 206d 622e 7472 616e 7370 6f73  es = mb.transpos
+0001c870: 6528 783d 782c 2070 6572 6d3d 7065 726d  e(x=x, perm=perm
+0001c880: 5f62 6163 6b2c 206e 616d 653d 6e6f 6465  _back, name=node
+0001c890: 2e6e 616d 6529 0a20 2020 2020 2020 2063  .name).        c
+0001c8a0: 6f6e 7465 7874 2e61 6464 2872 6573 290a  ontext.add(res).
+0001c8b0: 2020 2020 2020 2020 7265 7475 726e 0a0a          return..
+0001c8c0: 2020 2020 2222 220a 2020 2020 4361 7365      """.    Case
+0001c8d0: 2032 3a20 5075 7265 2069 6e64 6578 2073   2: Pure index s
+0001c8e0: 656c 6563 7469 6f6e 0a20 2020 2045 7820  election.    Ex 
+0001c8f0: 2320 3120 5b53 696e 676c 6520 6469 6d65  # 1 [Single dime
+0001c900: 6e73 696f 6e20 7365 6c65 6374 696f 6e5d  nsion selection]
+0001c910: 3a0a 2020 2020 2020 2020 6120 3d20 746f  :.        a = to
+0001c920: 7263 682e 7261 6e64 2831 2c32 2c33 2c34  rch.rand(1,2,3,4
+0001c930: 290a 2020 2020 2020 2020 696e 6465 7820  ).        index 
+0001c940: 3d20 746f 7263 682e 7465 6e73 6f72 285b  = torch.tensor([
+0001c950: 302c 2031 5d29 0a20 2020 2020 2020 2062  0, 1]).        b
+0001c960: 203d 2061 5b3a 2c3a 2c3a 2c69 6e64 6578   = a[:,:,:,index
+0001c970: 5d0a 0a20 2020 2020 2020 2049 6e20 7468  ]..        In th
+0001c980: 6973 2063 6173 652c 2069 6e64 6963 6573  is case, indices
+0001c990: 2069 7320 6120 6c69 7374 205b 4e6f 6e65   is a list [None
+0001c9a0: 2c20 4e6f 6e65 2c20 4e6f 6e65 2c20 5b30  , None, None, [0
+0001c9b0: 2c20 315d 5d5d 2e20 5468 6520 4e6f 6e65  , 1]]]. The None
+0001c9c0: 2065 6c65 6d65 6e74 206d 6561 6e73 2074   element means t
+0001c9d0: 6865 2063 6f72 7265 7370 6f6e 6469 6e67  he corresponding
+0001c9e0: 0a20 2020 2020 2020 2064 696d 656e 7369  .        dimensi
+0001c9f0: 6f6e 2069 7320 6d61 736b 6564 2e0a 0a20  on is masked... 
+0001ca00: 2020 2020 2020 2062 2068 6173 2073 6861         b has sha
+0001ca10: 7065 2028 312c 322c 332c 3229 2e0a 0a20  pe (1,2,3,2)... 
+0001ca20: 2020 2045 7820 2320 3220 5b4d 756c 7469     Ex # 2 [Multi
+0001ca30: 706c 6520 6469 7363 6f6e 6e65 6374 6564  ple disconnected
+0001ca40: 2064 696d 656e 7369 6f6e 7320 7365 6c65   dimensions sele
+0001ca50: 6374 696f 6e5d 3a0a 2020 2020 2020 2020  ction]:.        
+0001ca60: 6120 3d20 746f 7263 682e 7261 6e64 2831  a = torch.rand(1
+0001ca70: 2c32 2c33 2c34 290a 2020 2020 2020 2020  ,2,3,4).        
+0001ca80: 696e 6465 7820 3d20 746f 7263 682e 7465  index = torch.te
+0001ca90: 6e73 6f72 285b 302c 2031 5d29 0a20 2020  nsor([0, 1]).   
+0001caa0: 2020 2020 2062 203d 2061 5b3a 2c69 6e64       b = a[:,ind
+0001cab0: 6578 2c3a 2c69 6e64 6578 5d0a 0a20 2020  ex,:,index]..   
+0001cac0: 2020 2020 2049 6e20 7468 6973 2063 6173       In this cas
+0001cad0: 652c 2069 6e64 6963 6573 2069 7320 6120  e, indices is a 
+0001cae0: 6c69 7374 205b 4e6f 6e65 2c20 5b30 2c31  list [None, [0,1
+0001caf0: 5d2c 204e 6f6e 652c 205b 302c 315d 5d0a  ], None, [0,1]].
+0001cb00: 0a20 2020 2020 2020 2062 2068 6173 2073  .        b has s
+0001cb10: 6861 7065 2028 322c 312c 3329 2c0a 2020  hape (2,1,3),.  
+0001cb20: 2020 2020 2020 7768 6572 6520 625b 302c        where b[0,
+0001cb30: 3a2c 3a5d 203d 2061 5b3a 2c30 2c3a 2c30  :,:] = a[:,0,:,0
+0001cb40: 5d20 616e 6420 625b 312c 3a2c 3a5d 203d  ] and b[1,:,:] =
+0001cb50: 2061 5b3a 2c31 2c3a 2c31 5d0a 0a20 2020   a[:,1,:,1]..   
+0001cb60: 2045 7820 2320 3320 5b4d 756c 7469 706c   Ex # 3 [Multipl
+0001cb70: 6520 636f 6e6e 6563 7465 6420 6469 6d65  e connected dime
+0001cb80: 6e73 696f 6e73 2073 656c 6563 7469 6f6e  nsions selection
+0001cb90: 5d3a 0a20 2020 2020 2020 2061 203d 2074  ]:.        a = t
+0001cba0: 6f72 6368 2e72 616e 6428 312c 322c 332c  orch.rand(1,2,3,
+0001cbb0: 3429 0a20 2020 2020 2020 2069 6e64 6578  4).        index
+0001cbc0: 5f31 203d 2074 6f72 6368 2e74 656e 736f  _1 = torch.tenso
+0001cbd0: 7228 5b30 2c20 315d 290a 2020 2020 2020  r([0, 1]).      
+0001cbe0: 2020 696e 6465 785f 3220 3d20 746f 7263    index_2 = torc
+0001cbf0: 682e 7465 6e73 6f72 285b 302c 2031 5d29  h.tensor([0, 1])
+0001cc00: 0a20 2020 2020 2020 2062 203d 2061 5b3a  .        b = a[:
+0001cc10: 2c69 6e64 6578 5f31 2c69 6e64 6578 5f32  ,index_1,index_2
+0001cc20: 2c3a 5d0a 0a20 2020 2020 2020 2069 6e64  ,:]..        ind
+0001cc30: 6963 6573 2069 7320 6120 6c69 7374 205b  ices is a list [
+0001cc40: 4e6f 6e65 2c20 5b30 2c20 315d 2c20 5b30  None, [0, 1], [0
+0001cc50: 2c20 315d 2c20 4e6f 6e65 5d0a 0a20 2020  , 1], None]..   
+0001cc60: 2020 2020 2062 2068 6173 2073 6861 7065       b has shape
+0001cc70: 2028 312c 322c 3429 2c0a 2020 2020 2020   (1,2,4),.      
+0001cc80: 2020 7768 6572 6520 625b 3a2c 302c 3a5d    where b[:,0,:]
+0001cc90: 203d 2061 5b3a 2c30 2c30 2c3a 5d20 616e   = a[:,0,0,:] an
+0001cca0: 6420 625b 3a2c 312c 3a5d 203d 2061 5b3a  d b[:,1,:] = a[:
+0001ccb0: 2c31 2c31 2c3a 5d0a 0a20 2020 2045 7820  ,1,1,:]..    Ex 
+0001ccc0: 2320 3420 5b53 656c 6563 7469 6f6e 2077  # 4 [Selection w
+0001ccd0: 6974 6820 626f 6f6c 6561 6e20 6d61 736b  ith boolean mask
+0001cce0: 735d 3a0a 2020 2020 2020 2020 6120 3d20  s]:.        a = 
+0001ccf0: 746f 7263 682e 7261 6e64 2834 2c35 290a  torch.rand(4,5).
+0001cd00: 2020 2020 2020 2020 696e 6465 785f 3120          index_1 
+0001cd10: 3d20 5b54 7275 652c 2054 7275 652c 2046  = [True, True, F
+0001cd20: 616c 7365 2c20 4661 6c73 655d 0a20 2020  alse, False].   
+0001cd30: 2020 2020 2069 6e64 6578 5f32 203d 205b       index_2 = [
+0001cd40: 4661 6c73 652c 2054 7275 652c 2054 7275  False, True, Tru
+0001cd50: 652c 2046 616c 7365 2c20 4661 6c73 655d  e, False, False]
+0001cd60: 0a20 2020 2020 2020 2062 203d 2061 5b69  .        b = a[i
+0001cd70: 6e64 6578 5f31 2c20 696e 6465 785f 325d  ndex_1, index_2]
+0001cd80: 0a0a 2020 2020 2020 2020 696e 6469 6365  ..        indice
+0001cd90: 7320 6973 2061 206c 6973 7420 5b5b 5472  s is a list [[Tr
+0001cda0: 7565 2c20 5472 7565 2c20 4661 6c73 652c  ue, True, False,
+0001cdb0: 2046 616c 7365 5d2c 205b 4661 6c73 652c   False], [False,
+0001cdc0: 2054 7275 652c 2054 7275 652c 2046 616c   True, True, Fal
+0001cdd0: 7365 2c20 4661 6c73 655d 5d0a 0a20 2020  se, False]]..   
+0001cde0: 2020 2020 2049 6e20 7468 6973 2063 6173       In this cas
+0001cdf0: 652c 2069 6e64 6578 5f31 2061 6e64 2069  e, index_1 and i
+0001ce00: 6e64 6578 5f32 2061 7265 2069 6e74 6572  ndex_2 are inter
+0001ce10: 7072 6574 6564 2061 7320 6d61 736b 2062  preted as mask b
+0001ce20: 7920 696e 6469 6365 7320 6f66 2054 7275  y indices of Tru
+0001ce30: 652c 0a20 2020 2020 2020 2069 6e64 6578  e,.        index
+0001ce40: 5f31 202d 3e20 5b30 2c20 315d 0a20 2020  _1 -> [0, 1].   
+0001ce50: 2020 2020 2069 6e64 6578 5f32 202d 3e20       index_2 -> 
+0001ce60: 5b31 2c20 325d 0a0a 2020 2020 2020 2020  [1, 2]..        
+0001ce70: 6220 6861 7320 7368 6170 6520 2832 2c29  b has shape (2,)
+0001ce80: 2c0a 2020 2020 2020 2020 7768 6572 6520  ,.        where 
+0001ce90: 625b 305d 203d 2061 5b30 2c20 315d 2061  b[0] = a[0, 1] a
+0001cea0: 6e64 2062 5b31 5d20 3d20 615b 312c 2032  nd b[1] = a[1, 2
+0001ceb0: 5d0a 0a20 2020 2045 7820 2320 3520 5b42  ]..    Ex # 5 [B
+0001cec0: 726f 6164 6361 7374 2073 656c 6563 7469  roadcast selecti
+0001ced0: 6f6e 5d3a 0a20 2020 2020 2020 2061 203d  on]:.        a =
+0001cee0: 2074 6f72 6368 2e72 616e 6428 312c 322c   torch.rand(1,2,
+0001cef0: 332c 3429 0a20 2020 2020 2020 2069 6e64  3,4).        ind
+0001cf00: 6578 5f31 203d 2074 6f72 6368 2e74 656e  ex_1 = torch.ten
+0001cf10: 736f 7228 5b30 2c20 315d 290a 2020 2020  sor([0, 1]).    
+0001cf20: 2020 2020 696e 6465 785f 3220 3d20 746f      index_2 = to
+0001cf30: 7263 682e 7465 6e73 6f72 285b 305d 290a  rch.tensor([0]).
+0001cf40: 2020 2020 2020 2020 6220 3d20 615b 3a2c          b = a[:,
+0001cf50: 696e 6465 785f 312c 696e 6465 785f 322c  index_1,index_2,
+0001cf60: 3a5d 0a0a 2020 2020 2020 2020 696e 6469  :]..        indi
+0001cf70: 6365 7320 6973 2061 206c 6973 7420 5b4e  ces is a list [N
+0001cf80: 6f6e 652c 205b 302c 2031 5d2c 205b 305d  one, [0, 1], [0]
+0001cf90: 2c20 4e6f 6e65 5d0a 0a20 2020 2020 2020  , None]..       
+0001cfa0: 2049 6e20 7468 6973 2063 6173 652c 2069   In this case, i
+0001cfb0: 6e64 6578 5f32 2069 7320 676f 696e 6720  ndex_2 is going 
+0001cfc0: 746f 2062 6520 6272 6f61 6463 6173 7465  to be broadcaste
+0001cfd0: 6420 746f 205b 302c 2030 5d0a 0a20 2020  d to [0, 0]..   
+0001cfe0: 2020 2020 2062 2068 6173 2073 6861 7065       b has shape
+0001cff0: 2028 312c 322c 3429 2c0a 2020 2020 2020   (1,2,4),.      
+0001d000: 2020 7768 6572 6520 625b 3a2c 302c 3a5d    where b[:,0,:]
+0001d010: 203d 2061 5b3a 2c30 2c30 2c3a 5d20 616e   = a[:,0,0,:] an
+0001d020: 6420 625b 3a2c 312c 3a5d 203d 2061 5b3a  d b[:,1,:] = a[:
+0001d030: 2c31 2c30 2c3a 5d0a 0a20 2020 2022 2222  ,1,0,:]..    """
+0001d040: 0a0a 2020 2020 2320 6765 7420 7468 6520  ..    # get the 
+0001d050: 696e 6465 7820 6178 6573 0a20 2020 2069  index axes.    i
+0001d060: 6e64 6963 6573 203d 2069 6e64 6963 6573  ndices = indices
+0001d070: 202b 205b 4e6f 6e65 5d20 2a20 2878 2e72   + [None] * (x.r
+0001d080: 616e 6b20 2d20 6c65 6e28 696e 6469 6365  ank - len(indice
+0001d090: 7329 290a 2020 2020 696e 6469 6365 735f  s)).    indices_
+0001d0a0: 6178 6573 203d 205b 5d0a 2020 2020 7661  axes = [].    va
+0001d0b0: 6c69 645f 696e 6469 6365 7320 3d20 5b5d  lid_indices = []
+0001d0c0: 0a20 2020 2066 6f72 2069 2c20 696e 6465  .    for i, inde
+0001d0d0: 7820 696e 2065 6e75 6d65 7261 7465 2869  x in enumerate(i
+0001d0e0: 6e64 6963 6573 293a 0a20 2020 2020 2020  ndices):.       
+0001d0f0: 2069 6620 696e 6465 7820 6973 206e 6f74   if index is not
+0001d100: 204e 6f6e 653a 0a20 2020 2020 2020 2020   None:.         
+0001d110: 2020 2069 6e64 6963 6573 5f61 7865 732e     indices_axes.
+0001d120: 6170 7065 6e64 2869 290a 2020 2020 2020  append(i).      
+0001d130: 2020 2020 2020 7661 6c69 645f 696e 6469        valid_indi
+0001d140: 6365 732e 6170 7065 6e64 2869 6e64 6578  ces.append(index
+0001d150: 290a 0a20 2020 2023 2049 6620 616c 6c20  )..    # If all 
+0001d160: 656c 656d 656e 7473 2069 6e20 696e 6469  elements in indi
+0001d170: 6365 7320 6973 204e 6f6e 652c 2073 696d  ces is None, sim
+0001d180: 7069 6c79 2072 6574 7572 6e20 7468 6520  pily return the 
+0001d190: 6f72 6967 696e 616c 2074 656e 736f 722e  original tensor.
+0001d1a0: 0a20 2020 2069 6620 6c65 6e28 696e 6469  .    if len(indi
+0001d1b0: 6365 735f 6178 6573 2920 3d3d 2030 3a0a  ces_axes) == 0:.
+0001d1c0: 2020 2020 2020 2020 7820 3d20 6d62 2e69          x = mb.i
+0001d1d0: 6465 6e74 6974 7928 783d 782c 206e 616d  dentity(x=x, nam
+0001d1e0: 653d 6e6f 6465 2e6e 616d 6529 0a20 2020  e=node.name).   
+0001d1f0: 2020 2020 2063 6f6e 7465 7874 2e61 6464       context.add
+0001d200: 2878 290a 2020 2020 2020 2020 7265 7475  (x).        retu
+0001d210: 726e 0a0a 2020 2020 2320 636f 6e76 6572  rn..    # conver
+0001d220: 7420 616c 6c20 696e 6469 6365 7320 746f  t all indices to
+0001d230: 2069 6e74 2074 7970 650a 2020 2020 666f   int type.    fo
+0001d240: 7220 692c 2069 6e64 6963 6520 696e 2065  r i, indice in e
+0001d250: 6e75 6d65 7261 7465 2876 616c 6964 5f69  numerate(valid_i
+0001d260: 6e64 6963 6573 293a 0a20 2020 2020 2020  ndices):.       
+0001d270: 2069 6620 696e 6469 6365 2069 7320 6e6f   if indice is no
+0001d280: 7420 4e6f 6e65 2061 6e64 2074 7970 6573  t None and types
+0001d290: 2e69 735f 626f 6f6c 2869 6e64 6963 652e  .is_bool(indice.
+0001d2a0: 6474 7970 6529 3a0a 2020 2020 2020 2020  dtype):.        
+0001d2b0: 2020 2020 696e 6469 6365 203d 206d 622e      indice = mb.
+0001d2c0: 6e6f 6e5f 7a65 726f 2878 3d69 6e64 6963  non_zero(x=indic
+0001d2d0: 6529 0a20 2020 2020 2020 2020 2020 2069  e).            i
+0001d2e0: 6e64 6963 6520 3d20 6d62 2e73 7175 6565  ndice = mb.squee
+0001d2f0: 7a65 2878 3d69 6e64 6963 652c 2061 7865  ze(x=indice, axe
+0001d300: 733d 5b31 5d29 0a20 2020 2020 2020 2076  s=[1]).        v
+0001d310: 616c 6964 5f69 6e64 6963 6573 5b69 5d20  alid_indices[i] 
+0001d320: 3d20 696e 6469 6365 0a0a 2020 2020 2320  = indice..    # 
+0001d330: 466f 7220 7468 6520 7369 6e67 6c65 2069  For the single i
+0001d340: 6e64 6578 2061 7869 7320 6361 7365 2c20  ndex axis case, 
+0001d350: 7765 2063 616e 2075 7365 206d 622e 6761  we can use mb.ga
+0001d360: 7468 6572 2064 6972 6563 746c 790a 2020  ther directly.  
+0001d370: 2020 6966 206c 656e 2869 6e64 6963 6573    if len(indices
+0001d380: 5f61 7865 7329 203d 3d20 313a 0a20 2020  _axes) == 1:.   
+0001d390: 2020 2020 2061 7869 7320 3d20 696e 6469       axis = indi
+0001d3a0: 6365 735f 6178 6573 5b30 5d0a 2020 2020  ces_axes[0].    
+0001d3b0: 2020 2020 696e 6469 6365 7320 3d20 7661      indices = va
+0001d3c0: 6c69 645f 696e 6469 6365 735b 305d 0a20  lid_indices[0]. 
+0001d3d0: 2020 2020 2020 2069 6620 6973 5f63 7572         if is_cur
+0001d3e0: 7265 6e74 5f6f 7073 6574 5f76 6572 7369  rent_opset_versi
+0001d3f0: 6f6e 5f63 6f6d 7061 7469 626c 655f 7769  on_compatible_wi
+0001d400: 7468 2874 6172 6765 742e 694f 5331 3729  th(target.iOS17)
+0001d410: 3a0a 2020 2020 2020 2020 2020 2020 2320  :.            # 
+0001d420: 494f 5331 3720 6067 6174 6865 7260 2062  IOS17 `gather` b
+0001d430: 6568 6176 696f 7572 2069 7320 756e 6465  ehaviour is unde
+0001d440: 6669 6e65 6420 666f 7220 6e65 6761 7469  fined for negati
+0001d450: 7665 2069 6e64 6963 6573 2e0a 2020 2020  ve indices..    
+0001d460: 2020 2020 2020 2020 696e 6469 6365 7320          indices 
+0001d470: 3d20 6d62 2e73 656c 6563 7428 0a20 2020  = mb.select(.   
+0001d480: 2020 2020 2020 2020 2020 2020 2063 6f6e               con
+0001d490: 643d 6d62 2e67 7265 6174 6572 5f65 7175  d=mb.greater_equ
+0001d4a0: 616c 2878 3d69 6e64 6963 6573 2c20 793d  al(x=indices, y=
+0001d4b0: 3029 2c0a 2020 2020 2020 2020 2020 2020  0),.            
+0001d4c0: 2020 2020 613d 696e 6469 6365 732c 0a20      a=indices,. 
+0001d4d0: 2020 2020 2020 2020 2020 2020 2020 2062                 b
+0001d4e0: 3d6d 622e 6164 6428 783d 696e 6469 6365  =mb.add(x=indice
+0001d4f0: 732c 2079 3d76 616c 7565 5f61 7428 6d62  s, y=value_at(mb
+0001d500: 2e73 6861 7065 2878 3d78 292c 2061 7869  .shape(x=x), axi
+0001d510: 7329 292c 0a20 2020 2020 2020 2020 2020  s)),.           
+0001d520: 2029 0a20 2020 2020 2020 2078 203d 206d   ).        x = m
+0001d530: 622e 6761 7468 6572 2878 3d78 2c20 696e  b.gather(x=x, in
+0001d540: 6469 6365 733d 696e 6469 6365 732c 2061  dices=indices, a
+0001d550: 7869 733d 6178 6973 2c20 6e61 6d65 3d6e  xis=axis, name=n
+0001d560: 6f64 652e 6e61 6d65 290a 2020 2020 2020  ode.name).      
+0001d570: 2020 636f 6e74 6578 742e 6164 6428 7829    context.add(x)
+0001d580: 0a20 2020 2020 2020 2072 6574 7572 6e0a  .        return.
+0001d590: 0a20 2020 2023 2046 6f72 206d 756c 7469  .    # For multi
+0001d5a0: 706c 6520 696e 6465 7820 6178 6573 2063  ple index axes c
+0001d5b0: 6173 652c 2077 6520 6465 6c65 6761 7465  ase, we delegate
+0001d5c0: 2062 726f 6164 6361 7374 2074 6f20 6e70   broadcast to np
+0001d5d0: 2069 6620 7468 6572 6520 6973 206e 6f20   if there is no 
+0001d5e0: 6479 6e61 6d69 6320 7368 6170 652e 0a20  dynamic shape.. 
+0001d5f0: 2020 2069 6620 616c 6c28 6e6f 7420 616e     if all(not an
+0001d600: 795f 7379 6d62 6f6c 6963 2869 6478 2e73  y_symbolic(idx.s
+0001d610: 6861 7065 2920 666f 7220 6964 7820 696e  hape) for idx in
+0001d620: 2076 616c 6964 5f69 6e64 6963 6573 293a   valid_indices):
+0001d630: 0a20 2020 2020 2020 2062 726f 6164 6361  .        broadca
+0001d640: 7374 6564 5f73 6861 7065 203d 205f 6e70  sted_shape = _np
+0001d650: 2e62 726f 6164 6361 7374 5f73 6861 7065  .broadcast_shape
+0001d660: 7328 2a5b 6964 782e 7368 6170 6520 666f  s(*[idx.shape fo
+0001d670: 7220 6964 7820 696e 2076 616c 6964 5f69  r idx in valid_i
+0001d680: 6e64 6963 6573 5d29 0a20 2020 2020 2020  ndices]).       
+0001d690: 2066 6f72 2069 2c20 696e 6465 7820 696e   for i, index in
+0001d6a0: 2065 6e75 6d65 7261 7465 2876 616c 6964   enumerate(valid
+0001d6b0: 5f69 6e64 6963 6573 293a 0a20 2020 2020  _indices):.     
+0001d6c0: 2020 2020 2020 2069 6620 2869 6e64 6578         if (index
+0001d6d0: 2e73 6861 7065 2021 3d20 6272 6f61 6463  .shape != broadc
+0001d6e0: 6173 7465 645f 7368 6170 6529 2061 6e64  asted_shape) and
+0001d6f0: 2069 6e64 6578 2e76 616c 2069 7320 6e6f   index.val is no
+0001d700: 7420 4e6f 6e65 3a0a 2020 2020 2020 2020  t None:.        
+0001d710: 2020 2020 2020 2020 6e65 775f 7661 6c20          new_val 
+0001d720: 3d20 5f6e 702e 6272 6f61 6463 6173 745f  = _np.broadcast_
+0001d730: 746f 2869 6e64 6578 2e76 616c 2c20 6272  to(index.val, br
+0001d740: 6f61 6463 6173 7465 645f 7368 6170 6529  oadcasted_shape)
+0001d750: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001d760: 2076 616c 6964 5f69 6e64 6963 6573 5b69   valid_indices[i
+0001d770: 5d20 3d20 6d62 2e63 6f6e 7374 280a 2020  ] = mb.const(.  
+0001d780: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d790: 2020 7661 6c3d 6e65 775f 7661 6c2c 206e    val=new_val, n
+0001d7a0: 616d 653d 696e 6465 782e 6e61 6d65 202b  ame=index.name +
+0001d7b0: 2022 5f62 726f 6164 6361 7374 6564 220a   "_broadcasted".
+0001d7c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d7d0: 290a 2020 2020 7661 6c69 645f 696e 6469  ).    valid_indi
+0001d7e0: 6365 7320 3d20 5b6d 622e 6361 7374 2878  ces = [mb.cast(x
+0001d7f0: 3d69 6e64 6578 2c20 6474 7970 653d 2269  =index, dtype="i
+0001d800: 6e74 3332 2229 2066 6f72 2069 6e64 6578  nt32") for index
+0001d810: 2069 6e20 7661 6c69 645f 696e 6469 6365   in valid_indice
+0001d820: 735d 0a0a 2020 2020 2320 4669 7273 7420  s]..    # First 
+0001d830: 7374 6163 6b20 7468 6520 696e 6465 7820  stack the index 
+0001d840: 746f 6765 7468 6572 0a20 2020 2069 6e64  together.    ind
+0001d850: 6963 6573 5f72 616e 6b20 3d20 7661 6c69  ices_rank = vali
+0001d860: 645f 696e 6469 6365 735b 305d 2e72 616e  d_indices[0].ran
+0001d870: 6b0a 2020 2020 696e 6469 6365 7320 3d20  k.    indices = 
+0001d880: 6d62 2e73 7461 636b 2876 616c 7565 733d  mb.stack(values=
+0001d890: 7661 6c69 645f 696e 6469 6365 732c 2061  valid_indices, a
+0001d8a0: 7869 733d 696e 6469 6365 735f 7261 6e6b  xis=indices_rank
+0001d8b0: 290a 0a20 2020 2023 2074 7261 6e73 706f  )..    # transpo
+0001d8c0: 7365 2074 6865 2069 6e70 7574 2074 656e  se the input ten
+0001d8d0: 736f 7220 746f 2067 6174 6865 7220 7468  sor to gather th
+0001d8e0: 6520 736c 6963 696e 6720 696e 6465 7820  e slicing index 
+0001d8f0: 696e 2066 726f 6e74 0a20 2020 2069 735f  in front.    is_
+0001d900: 636f 6e6e 6563 7465 6420 3d20 5472 7565  connected = True
+0001d910: 0a20 2020 2066 6f72 2069 2069 6e20 7261  .    for i in ra
+0001d920: 6e67 6528 312c 206c 656e 2869 6e64 6963  nge(1, len(indic
+0001d930: 6573 5f61 7865 7329 293a 0a20 2020 2020  es_axes)):.     
+0001d940: 2020 2069 6620 696e 6469 6365 735f 6178     if indices_ax
+0001d950: 6573 5b69 5d20 213d 2069 6e64 6963 6573  es[i] != indices
+0001d960: 5f61 7865 735b 6920 2d20 315d 202b 2031  _axes[i - 1] + 1
+0001d970: 3a0a 2020 2020 2020 2020 2020 2020 6973  :.            is
+0001d980: 5f63 6f6e 6e65 6374 6564 203d 2046 616c  _connected = Fal
+0001d990: 7365 0a20 2020 2020 2020 2020 2020 2062  se.            b
+0001d9a0: 7265 616b 0a0a 2020 2020 6e61 6d65 203d  reak..    name =
+0001d9b0: 206e 6f64 652e 6e61 6d65 202b 2022 5f74   node.name + "_t
+0001d9c0: 7261 6e73 706f 7365 2220 6966 2069 735f  ranspose" if is_
+0001d9d0: 636f 6e6e 6563 7465 6420 656c 7365 206e  connected else n
+0001d9e0: 6f64 652e 6e61 6d65 0a20 2020 2070 6572  ode.name.    per
+0001d9f0: 6d20 3d20 696e 6469 6365 735f 6178 6573  m = indices_axes
+0001da00: 202b 205b 6178 6973 2066 6f72 2061 7869   + [axis for axi
+0001da10: 7320 696e 2072 616e 6765 2878 2e72 616e  s in range(x.ran
+0001da20: 6b29 2069 6620 6178 6973 206e 6f74 2069  k) if axis not i
+0001da30: 6e20 696e 6469 6365 735f 6178 6573 5d0a  n indices_axes].
+0001da40: 2020 2020 7820 3d20 6d62 2e74 7261 6e73      x = mb.trans
+0001da50: 706f 7365 2878 3d78 2c20 7065 726d 3d70  pose(x=x, perm=p
+0001da60: 6572 6d29 0a0a 2020 2020 6966 2069 735f  erm)..    if is_
+0001da70: 6375 7272 656e 745f 6f70 7365 745f 7665  current_opset_ve
+0001da80: 7273 696f 6e5f 636f 6d70 6174 6962 6c65  rsion_compatible
+0001da90: 5f77 6974 6828 7461 7267 6574 2e69 4f53  _with(target.iOS
+0001daa0: 3137 293a 0a20 2020 2020 2020 2023 2049  17):.        # I
+0001dab0: 4f53 3137 2060 6761 7468 6572 5f6e 6460  OS17 `gather_nd`
+0001dac0: 2062 6568 6176 696f 7572 2069 7320 756e   behaviour is un
+0001dad0: 6465 6669 6e65 6420 666f 7220 6e65 6761  defined for nega
+0001dae0: 7469 7665 2069 6e64 6963 6573 2e0a 2020  tive indices..  
+0001daf0: 2020 2020 2020 636f 6e64 203d 206d 622e        cond = mb.
+0001db00: 6772 6561 7465 725f 6571 7561 6c28 783d  greater_equal(x=
+0001db10: 696e 6469 6365 732c 2079 3d30 290a 2020  indices, y=0).  
+0001db20: 2020 2020 2020 785f 7368 6170 6520 3d20        x_shape = 
+0001db30: 6d62 2e73 6861 7065 2878 3d78 290a 2020  mb.shape(x=x).  
+0001db40: 2020 2020 2020 696e 6469 6365 735f 7368        indices_sh
+0001db50: 6170 6520 3d20 6d62 2e73 6861 7065 2878  ape = mb.shape(x
+0001db60: 3d69 6e64 6963 6573 290a 2020 2020 2020  =indices).      
+0001db70: 2020 696e 6469 6365 735f 6c61 7374 5f64    indices_last_d
+0001db80: 696d 203d 2076 616c 7565 5f61 7428 696e  im = value_at(in
+0001db90: 6469 6365 735f 7368 6170 652c 2069 6e64  dices_shape, ind
+0001dba0: 6963 6573 2e72 616e 6b20 2d20 3129 0a20  ices.rank - 1). 
+0001dbb0: 2020 2020 2020 2069 6e64 6963 6573 5f6c         indices_l
+0001dbc0: 6173 745f 6469 6d5f 6578 7061 6e64 203d  ast_dim_expand =
+0001dbd0: 206d 622e 6578 7061 6e64 5f64 696d 7328   mb.expand_dims(
+0001dbe0: 783d 696e 6469 6365 735f 6c61 7374 5f64  x=indices_last_d
+0001dbf0: 696d 2c20 6178 6573 3d5b 305d 290a 2020  im, axes=[0]).  
+0001dc00: 2020 2020 2020 736c 6963 655f 7368 6170        slice_shap
+0001dc10: 6520 3d20 6d62 2e73 6c69 6365 5f62 795f  e = mb.slice_by_
+0001dc20: 7369 7a65 2878 3d78 5f73 6861 7065 2c20  size(x=x_shape, 
+0001dc30: 6265 6769 6e3d 5b30 5d2c 2073 697a 653d  begin=[0], size=
+0001dc40: 696e 6469 6365 735f 6c61 7374 5f64 696d  indices_last_dim
+0001dc50: 5f65 7870 616e 6429 0a20 2020 2020 2020  _expand).       
+0001dc60: 2069 6e64 6963 6573 203d 206d 622e 7365   indices = mb.se
+0001dc70: 6c65 6374 280a 2020 2020 2020 2020 2020  lect(.          
+0001dc80: 2020 636f 6e64 3d63 6f6e 642c 0a20 2020    cond=cond,.   
+0001dc90: 2020 2020 2020 2020 2061 3d69 6e64 6963           a=indic
+0001dca0: 6573 2c0a 2020 2020 2020 2020 2020 2020  es,.            
+0001dcb0: 623d 6d62 2e61 6464 2878 3d69 6e64 6963  b=mb.add(x=indic
+0001dcc0: 6573 2c20 793d 736c 6963 655f 7368 6170  es, y=slice_shap
+0001dcd0: 6529 2c0a 2020 2020 2020 2020 290a 2020  e),.        ).  
+0001dce0: 2020 7820 3d20 6d62 2e67 6174 6865 725f    x = mb.gather_
+0001dcf0: 6e64 2878 3d78 2c20 696e 6469 6365 733d  nd(x=x, indices=
+0001dd00: 696e 6469 6365 732c 206e 616d 653d 6e61  indices, name=na
+0001dd10: 6d65 290a 0a20 2020 2023 2069 6620 7468  me)..    # if th
+0001dd20: 6520 696e 6465 7820 6178 6573 2061 7265  e index axes are
+0001dd30: 2063 6f6e 6e65 6374 2c20 7765 206e 6565   connect, we nee
+0001dd40: 6420 746f 2074 7261 6e73 706f 7365 2069  d to transpose i
+0001dd50: 7420 6261 636b 0a20 2020 2069 6620 6973  t back.    if is
+0001dd60: 5f63 6f6e 6e65 6374 6564 3a0a 2020 2020  _connected:.    
+0001dd70: 2020 2020 6e65 775f 6469 6d65 6e73 696f      new_dimensio
+0001dd80: 6e73 203d 206c 6973 7428 7261 6e67 6528  ns = list(range(
+0001dd90: 696e 6469 6365 735f 6178 6573 5b30 5d2c  indices_axes[0],
+0001dda0: 2069 6e64 6963 6573 5f61 7865 735b 305d   indices_axes[0]
+0001ddb0: 202b 2069 6e64 6963 6573 5f72 616e 6b29   + indices_rank)
+0001ddc0: 290a 2020 2020 2020 2020 6e65 775f 7065  ).        new_pe
+0001ddd0: 726d 203d 206e 6577 5f64 696d 656e 7369  rm = new_dimensi
+0001dde0: 6f6e 7320 2b20 5b0a 2020 2020 2020 2020  ons + [.        
+0001ddf0: 2020 2020 6178 6973 0a20 2020 2020 2020      axis.       
+0001de00: 2020 2020 2066 6f72 2061 7869 7320 696e       for axis in
+0001de10: 2072 616e 6765 2872 616e 6b20 2b20 696e   range(rank + in
+0001de20: 6469 6365 735f 7261 6e6b 202d 206c 656e  dices_rank - len
+0001de30: 2869 6e64 6963 6573 5f61 7865 7329 290a  (indices_axes)).
+0001de40: 2020 2020 2020 2020 2020 2020 6966 2061              if a
+0001de50: 7869 7320 6e6f 7420 696e 206e 6577 5f64  xis not in new_d
+0001de60: 696d 656e 7369 6f6e 730a 2020 2020 2020  imensions.      
+0001de70: 2020 5d0a 2020 2020 2020 2020 7065 726d    ].        perm
+0001de80: 5f62 6163 6b20 3d20 5b6e 6577 5f70 6572  _back = [new_per
+0001de90: 6d2e 696e 6465 7828 6178 6973 2920 666f  m.index(axis) fo
+0001dea0: 7220 6178 6973 2069 6e20 7261 6e67 6528  r axis in range(
+0001deb0: 6c65 6e28 6e65 775f 7065 726d 2929 5d0a  len(new_perm))].
+0001dec0: 2020 2020 2020 2020 7820 3d20 6d62 2e74          x = mb.t
+0001ded0: 7261 6e73 706f 7365 2878 3d78 2c20 7065  ranspose(x=x, pe
+0001dee0: 726d 3d70 6572 6d5f 6261 636b 2c20 6e61  rm=perm_back, na
+0001def0: 6d65 3d6e 6f64 652e 6e61 6d65 290a 2020  me=node.name).  
+0001df00: 2020 636f 6e74 6578 742e 6164 6428 7829    context.add(x)
+0001df10: 0a0a 0a40 7265 6769 7374 6572 5f74 6f72  ...@register_tor
+0001df20: 6368 5f6f 700a 6465 6620 6f6e 6573 2863  ch_op.def ones(c
+0001df30: 6f6e 7465 7874 2c20 6e6f 6465 293a 0a20  ontext, node):. 
+0001df40: 2020 2069 6e70 7574 7320 3d20 5f67 6574     inputs = _get
+0001df50: 5f69 6e70 7574 7328 636f 6e74 6578 742c  _inputs(context,
+0001df60: 206e 6f64 652c 2065 7870 6563 7465 643d   node, expected=
+0001df70: 5b35 2c20 365d 290a 2020 2020 7369 7a65  [5, 6]).    size
+0001df80: 203d 2069 6e70 7574 735b 305d 0a20 2020   = inputs[0].   
+0001df90: 2023 2064 7479 7065 203d 204e 554d 5f54   # dtype = NUM_T
+0001dfa0: 4f5f 544f 5243 485f 4454 5950 455b 696e  O_TORCH_DTYPE[in
+0001dfb0: 7075 7473 5b31 5d2e 7661 6c5d 2075 6e75  puts[1].val] unu
+0001dfc0: 7365 640a 2020 2020 2320 6c61 796f 7574  sed.    # layout
+0001dfd0: 203d 2069 6e70 7574 735b 325d 2075 6e75   = inputs[2] unu
+0001dfe0: 7365 640a 2020 2020 2320 6465 7669 6365  sed.    # device
+0001dff0: 203d 2069 6e70 7574 735b 335d 2075 6e75   = inputs[3] unu
+0001e000: 7365 640a 2020 2020 2320 7265 7175 6972  sed.    # requir
+0001e010: 6573 5f67 7261 6420 3d20 696e 7075 7473  es_grad = inputs
+0001e020: 5b34 5d20 756e 7573 6564 0a20 2020 2023  [4] unused.    #
+0001e030: 206f 7574 203d 2069 6e70 7574 735b 355d   out = inputs[5]
+0001e040: 2075 6e75 7365 640a 2020 2020 6966 2069   unused.    if i
+0001e050: 7369 6e73 7461 6e63 6528 7369 7a65 2c20  sinstance(size, 
+0001e060: 6c69 7374 293a 0a20 2020 2020 2020 2073  list):.        s
+0001e070: 697a 6520 3d20 6d62 2e63 6f6e 6361 7428  ize = mb.concat(
+0001e080: 7661 6c75 6573 3d73 697a 652c 2061 7869  values=size, axi
+0001e090: 733d 3029 0a20 2020 2066 696c 6c20 3d20  s=0).    fill = 
+0001e0a0: 6d62 2e66 696c 6c28 7368 6170 653d 7369  mb.fill(shape=si
+0001e0b0: 7a65 2c20 7661 6c75 653d 312e 302c 206e  ze, value=1.0, n
+0001e0c0: 616d 653d 6e6f 6465 2e6e 616d 6529 0a20  ame=node.name). 
+0001e0d0: 2020 2063 6f6e 7465 7874 2e61 6464 2866     context.add(f
+0001e0e0: 696c 6c29 0a0a 0a40 7265 6769 7374 6572  ill)...@register
+0001e0f0: 5f74 6f72 6368 5f6f 700a 6465 6620 6f6e  _torch_op.def on
+0001e100: 6573 5f6c 696b 6528 636f 6e74 6578 742c  es_like(context,
+0001e110: 206e 6f64 6529 3a0a 2020 2020 696e 7075   node):.    inpu
+0001e120: 7473 203d 205f 6765 745f 696e 7075 7473  ts = _get_inputs
+0001e130: 2863 6f6e 7465 7874 2c20 6e6f 6465 2c20  (context, node, 
+0001e140: 6578 7065 6374 6564 3d36 290a 2020 2020  expected=6).    
+0001e150: 7820 3d20 696e 7075 7473 5b30 5d0a 2020  x = inputs[0].  
+0001e160: 2020 6966 2069 735f 6375 7272 656e 745f    if is_current_
+0001e170: 6f70 7365 745f 7665 7273 696f 6e5f 636f  opset_version_co
+0001e180: 6d70 6174 6962 6c65 5f77 6974 6828 7461  mpatible_with(ta
+0001e190: 7267 6574 2e69 4f53 3136 293a 0a20 2020  rget.iOS16):.   
+0001e1a0: 2020 2020 2066 696c 6c20 3d20 6d62 2e66       fill = mb.f
+0001e1b0: 696c 6c5f 6c69 6b65 2872 6566 5f74 656e  ill_like(ref_ten
+0001e1c0: 736f 723d 782c 2076 616c 7565 3d31 2e30  sor=x, value=1.0
+0001e1d0: 2c20 6e61 6d65 3d6e 6f64 652e 6e61 6d65  , name=node.name
+0001e1e0: 290a 2020 2020 656c 7365 3a0a 2020 2020  ).    else:.    
+0001e1f0: 2020 2020 7369 7a65 203d 206d 622e 7368      size = mb.sh
+0001e200: 6170 6528 783d 7829 0a20 2020 2020 2020  ape(x=x).       
+0001e210: 2023 2064 7479 7065 203d 204e 554d 5f54   # dtype = NUM_T
+0001e220: 4f5f 544f 5243 485f 4454 5950 455b 696e  O_TORCH_DTYPE[in
+0001e230: 7075 7473 5b31 5d2e 7661 6c5d 2075 6e75  puts[1].val] unu
+0001e240: 7365 640a 2020 2020 2020 2020 2320 6c61  sed.        # la
+0001e250: 796f 7574 203d 2069 6e70 7574 735b 325d  yout = inputs[2]
+0001e260: 2075 6e75 7365 640a 2020 2020 2020 2020   unused.        
+0001e270: 2320 6465 7669 6365 203d 2069 6e70 7574  # device = input
+0001e280: 735b 335d 2075 6e75 7365 640a 2020 2020  s[3] unused.    
+0001e290: 2020 2020 2320 7265 7175 6972 6573 5f67      # requires_g
+0001e2a0: 7261 6420 3d20 696e 7075 7473 5b34 5d20  rad = inputs[4] 
+0001e2b0: 756e 7573 6564 0a20 2020 2020 2020 2023  unused.        #
+0001e2c0: 206f 7574 203d 2069 6e70 7574 735b 355d   out = inputs[5]
+0001e2d0: 2075 6e75 7365 640a 2020 2020 2020 2020   unused.        
+0001e2e0: 6669 6c6c 203d 206d 622e 6669 6c6c 2873  fill = mb.fill(s
+0001e2f0: 6861 7065 3d73 697a 652c 2076 616c 7565  hape=size, value
+0001e300: 3d31 2e30 2c20 6e61 6d65 3d6e 6f64 652e  =1.0, name=node.
+0001e310: 6e61 6d65 290a 2020 2020 636f 6e74 6578  name).    contex
+0001e320: 742e 6164 6428 6669 6c6c 290a 0a0a 6465  t.add(fill)...de
+0001e330: 6620 5f6d 616b 655f 6669 6c6c 5f6f 7028  f _make_fill_op(
+0001e340: 7369 7a65 2c20 7661 6c2c 206e 616d 6529  size, val, name)
+0001e350: 3a0a 2020 2020 6173 7365 7274 2076 616c  :.    assert val
+0001e360: 2069 7320 6e6f 7420 4e6f 6e65 0a20 2020   is not None.   
+0001e370: 2069 6620 6973 696e 7374 616e 6365 2873   if isinstance(s
+0001e380: 697a 652c 206c 6973 7429 3a0a 2020 2020  ize, list):.    
+0001e390: 2020 2020 7369 7a65 203d 206d 622e 636f      size = mb.co
+0001e3a0: 6e63 6174 2876 616c 7565 733d 7369 7a65  ncat(values=size
+0001e3b0: 2c20 6178 6973 3d30 290a 2020 2020 6966  , axis=0).    if
+0001e3c0: 2074 7970 6573 2e69 735f 666c 6f61 7428   types.is_float(
+0001e3d0: 7369 7a65 2e64 7479 7065 293a 0a20 2020  size.dtype):.   
+0001e3e0: 2020 2020 2073 697a 6520 3d20 6d62 2e63       size = mb.c
+0001e3f0: 6173 7428 783d 7369 7a65 2c20 6474 7970  ast(x=size, dtyp
+0001e400: 653d 2269 6e74 3332 2229 0a20 2020 2066  e="int32").    f
+0001e410: 696c 6c20 3d20 6d62 2e66 696c 6c28 7368  ill = mb.fill(sh
+0001e420: 6170 653d 7369 7a65 2c20 7661 6c75 653d  ape=size, value=
+0001e430: 7661 6c2c 206e 616d 653d 6e61 6d65 290a  val, name=name).
+0001e440: 2020 2020 7265 7475 726e 2066 696c 6c0a      return fill.
+0001e450: 0a0a 4072 6567 6973 7465 725f 746f 7263  ..@register_torc
+0001e460: 685f 6f70 0a64 6566 2066 756c 6c28 636f  h_op.def full(co
+0001e470: 6e74 6578 742c 206e 6f64 6529 3a0a 2020  ntext, node):.  
+0001e480: 2020 696e 7075 7473 203d 205f 6765 745f    inputs = _get_
+0001e490: 696e 7075 7473 2863 6f6e 7465 7874 2c20  inputs(context, 
+0001e4a0: 6e6f 6465 290a 2020 2020 7369 7a65 203d  node).    size =
+0001e4b0: 2069 6e70 7574 735b 305d 0a20 2020 2076   inputs[0].    v
+0001e4c0: 616c 203d 2069 6e70 7574 735b 315d 2e76  al = inputs[1].v
+0001e4d0: 616c 0a20 2020 2072 6573 756c 7420 3d20  al.    result = 
+0001e4e0: 5f6d 616b 655f 6669 6c6c 5f6f 7028 7369  _make_fill_op(si
+0001e4f0: 7a65 2c20 7661 6c2c 206e 6f64 652e 6e61  ze, val, node.na
+0001e500: 6d65 290a 2020 2020 636f 6e74 6578 742e  me).    context.
+0001e510: 6164 6428 7265 7375 6c74 290a 0a0a 4072  add(result)...@r
+0001e520: 6567 6973 7465 725f 746f 7263 685f 6f70  egister_torch_op
+0001e530: 0a64 6566 2066 756c 6c5f 6c69 6b65 2863  .def full_like(c
+0001e540: 6f6e 7465 7874 2c20 6e6f 6465 293a 0a20  ontext, node):. 
+0001e550: 2020 2069 6e70 7574 7320 3d20 5f67 6574     inputs = _get
+0001e560: 5f69 6e70 7574 7328 636f 6e74 6578 742c  _inputs(context,
+0001e570: 206e 6f64 652c 2065 7870 6563 7465 643d   node, expected=
+0001e580: 3729 0a20 2020 2078 203d 2069 6e70 7574  7).    x = input
+0001e590: 735b 305d 0a20 2020 2076 616c 203d 2069  s[0].    val = i
+0001e5a0: 6e70 7574 735b 315d 2e76 616c 0a20 2020  nputs[1].val.   
+0001e5b0: 2069 6620 6973 5f63 7572 7265 6e74 5f6f   if is_current_o
+0001e5c0: 7073 6574 5f76 6572 7369 6f6e 5f63 6f6d  pset_version_com
+0001e5d0: 7061 7469 626c 655f 7769 7468 2874 6172  patible_with(tar
+0001e5e0: 6765 742e 694f 5331 3629 3a0a 2020 2020  get.iOS16):.    
+0001e5f0: 2020 2020 7265 7375 6c74 203d 206d 622e      result = mb.
+0001e600: 6669 6c6c 5f6c 696b 6528 7265 665f 7465  fill_like(ref_te
+0001e610: 6e73 6f72 3d78 2c20 7661 6c75 653d 7661  nsor=x, value=va
+0001e620: 6c2c 206e 616d 653d 6e6f 6465 2e6e 616d  l, name=node.nam
+0001e630: 6529 0a20 2020 2065 6c73 653a 0a20 2020  e).    else:.   
+0001e640: 2020 2020 2073 697a 6520 3d20 6d62 2e73       size = mb.s
+0001e650: 6861 7065 2878 3d69 6e70 7574 735b 305d  hape(x=inputs[0]
+0001e660: 290a 2020 2020 2020 2020 7265 7375 6c74  ).        result
+0001e670: 203d 205f 6d61 6b65 5f66 696c 6c5f 6f70   = _make_fill_op
+0001e680: 2873 697a 652c 2076 616c 2c20 6e6f 6465  (size, val, node
+0001e690: 2e6e 616d 6529 0a20 2020 2063 6f6e 7465  .name).    conte
+0001e6a0: 7874 2e61 6464 2872 6573 756c 7429 0a0a  xt.add(result)..
+0001e6b0: 0a40 7265 6769 7374 6572 5f74 6f72 6368  .@register_torch
+0001e6c0: 5f6f 700a 6465 6620 6e65 775f 6675 6c6c  _op.def new_full
+0001e6d0: 2863 6f6e 7465 7874 2c20 6e6f 6465 293a  (context, node):
+0001e6e0: 0a20 2020 2023 2054 6865 2064 6966 6665  .    # The diffe
+0001e6f0: 7265 6e63 6520 6265 7477 6565 6e20 226e  rence between "n
+0001e700: 6577 5f66 756c 6c22 2061 6e64 2022 6675  ew_full" and "fu
+0001e710: 6c6c 2220 6973 2074 6861 7420 7468 6520  ll" is that the 
+0001e720: 226e 6577 5f66 756c 6c22 2069 7320 6361  "new_full" is ca
+0001e730: 6c6c 6564 2066 726f 6d0a 2020 2020 2320  lled from.    # 
+0001e740: 616e 2065 7869 7374 696e 6720 7465 6e73  an existing tens
+0001e750: 6f72 3a20 7465 6e73 6f72 2e6e 6577 5f66  or: tensor.new_f
+0001e760: 756c 6c28 7369 7a65 2c20 6669 6c6c 5f76  ull(size, fill_v
+0001e770: 616c 7565 292c 2077 6869 6c65 2074 6865  alue), while the
+0001e780: 2022 6675 6c6c 2220 6973 2063 616c 6c65   "full" is calle
+0001e790: 640a 2020 2020 2320 6672 6f6d 2074 6865  d.    # from the
+0001e7a0: 2074 6f72 6368 2041 5049 3a20 746f 7263   torch API: torc
+0001e7b0: 682e 6675 6c6c 2873 697a 652c 2066 696c  h.full(size, fil
+0001e7c0: 6c5f 7661 6c75 6529 2e0a 2020 2020 2320  l_value)..    # 
+0001e7d0: 4275 7420 7468 6579 2061 7265 2062 6173  But they are bas
+0001e7e0: 6963 616c 6c79 2064 6f69 6e67 2074 6865  ically doing the
+0001e7f0: 2073 616d 6520 7468 696e 672e 0a20 2020   same thing..   
+0001e800: 2069 6e70 7574 7320 3d20 5f67 6574 5f69   inputs = _get_i
+0001e810: 6e70 7574 7328 636f 6e74 6578 742c 206e  nputs(context, n
+0001e820: 6f64 6529 0a20 2020 2073 697a 6520 3d20  ode).    size = 
+0001e830: 696e 7075 7473 5b31 5d0a 2020 2020 7661  inputs[1].    va
+0001e840: 6c20 3d20 696e 7075 7473 5b32 5d2e 7661  l = inputs[2].va
+0001e850: 6c0a 2020 2020 7265 7375 6c74 203d 205f  l.    result = _
+0001e860: 6d61 6b65 5f66 696c 6c5f 6f70 2873 697a  make_fill_op(siz
+0001e870: 652c 2076 616c 2c20 6e6f 6465 2e6e 616d  e, val, node.nam
+0001e880: 6529 0a20 2020 2063 6f6e 7465 7874 2e61  e).    context.a
+0001e890: 6464 2872 6573 756c 7429 0a0a 4072 6567  dd(result)..@reg
+0001e8a0: 6973 7465 725f 746f 7263 685f 6f70 0a64  ister_torch_op.d
+0001e8b0: 6566 2072 616e 6469 6e74 2863 6f6e 7465  ef randint(conte
+0001e8c0: 7874 2c20 6e6f 6465 293a 0a20 2020 2069  xt, node):.    i
+0001e8d0: 6e70 7574 7320 3d20 5f67 6574 5f69 6e70  nputs = _get_inp
+0001e8e0: 7574 7328 636f 6e74 6578 742c 206e 6f64  uts(context, nod
+0001e8f0: 652c 2065 7870 6563 7465 643d 3829 0a20  e, expected=8). 
+0001e900: 2020 206c 6f77 203d 206d 622e 6361 7374     low = mb.cast
+0001e910: 2878 3d69 6e70 7574 735b 305d 2c20 6474  (x=inputs[0], dt
+0001e920: 7970 653d 2266 7033 3222 290a 2020 2020  ype="fp32").    
+0001e930: 6869 6768 203d 206d 622e 6361 7374 2878  high = mb.cast(x
+0001e940: 3d69 6e70 7574 735b 315d 2c20 6474 7970  =inputs[1], dtyp
+0001e950: 653d 2266 7033 3222 290a 2020 2020 7368  e="fp32").    sh
+0001e960: 6170 6520 3d20 696e 7075 7473 5b32 5d0a  ape = inputs[2].
+0001e970: 2020 2020 7261 6e64 5f75 6e69 666f 726d      rand_uniform
+0001e980: 203d 206d 622e 7261 6e64 6f6d 5f75 6e69   = mb.random_uni
+0001e990: 666f 726d 2873 6861 7065 3d73 6861 7065  form(shape=shape
+0001e9a0: 2c20 6c6f 773d 6c6f 772c 2068 6967 683d  , low=low, high=
+0001e9b0: 6869 6768 290a 2020 2020 7261 6e64 5f69  high).    rand_i
+0001e9c0: 6e74 203d 206d 622e 6361 7374 2878 3d72  nt = mb.cast(x=r
+0001e9d0: 616e 645f 756e 6966 6f72 6d2c 2064 7479  and_uniform, dty
+0001e9e0: 7065 3d22 696e 7433 3222 2c20 6e61 6d65  pe="int32", name
+0001e9f0: 3d6e 6f64 652e 6e61 6d65 290a 2020 2020  =node.name).    
+0001ea00: 636f 6e74 6578 742e 6164 6428 7261 6e64  context.add(rand
+0001ea10: 5f69 6e74 290a 0a40 7265 6769 7374 6572  _int)..@register
+0001ea20: 5f74 6f72 6368 5f6f 700a 6465 6620 7261  _torch_op.def ra
+0001ea30: 6e64 6e28 636f 6e74 6578 742c 206e 6f64  ndn(context, nod
+0001ea40: 6529 3a0a 2020 2020 696e 7075 7473 203d  e):.    inputs =
+0001ea50: 205f 6765 745f 696e 7075 7473 2863 6f6e   _get_inputs(con
+0001ea60: 7465 7874 2c20 6e6f 6465 2c20 6578 7065  text, node, expe
+0001ea70: 6374 6564 3d35 290a 2020 2020 7368 6170  cted=5).    shap
+0001ea80: 6520 3d20 696e 7075 7473 5b30 5d0a 2020  e = inputs[0].  
+0001ea90: 2020 7261 6e64 5f6e 6f72 6d61 6c20 3d20    rand_normal = 
+0001eaa0: 6d62 2e72 616e 646f 6d5f 6e6f 726d 616c  mb.random_normal
+0001eab0: 2873 6861 7065 3d73 6861 7065 290a 2020  (shape=shape).  
+0001eac0: 2020 7261 6e64 5f66 7033 3220 3d20 6d62    rand_fp32 = mb
+0001ead0: 2e63 6173 7428 783d 7261 6e64 5f6e 6f72  .cast(x=rand_nor
+0001eae0: 6d61 6c2c 2064 7479 7065 3d22 6670 3332  mal, dtype="fp32
+0001eaf0: 222c 206e 616d 653d 6e6f 6465 2e6e 616d  ", name=node.nam
+0001eb00: 6529 0a20 2020 2063 6f6e 7465 7874 2e61  e).    context.a
+0001eb10: 6464 2872 616e 645f 6670 3332 290a 0a40  dd(rand_fp32)..@
+0001eb20: 7265 6769 7374 6572 5f74 6f72 6368 5f6f  register_torch_o
+0001eb30: 700a 6465 6620 7261 6e64 6e5f 6c69 6b65  p.def randn_like
+0001eb40: 2863 6f6e 7465 7874 2c20 6e6f 6465 293a  (context, node):
+0001eb50: 0a20 2020 2069 6e70 7574 7320 3d20 5f67  .    inputs = _g
+0001eb60: 6574 5f69 6e70 7574 7328 636f 6e74 6578  et_inputs(contex
+0001eb70: 742c 206e 6f64 652c 2065 7870 6563 7465  t, node, expecte
+0001eb80: 643d 3629 0a20 2020 2078 203d 2069 6e70  d=6).    x = inp
+0001eb90: 7574 735b 305d 0a20 2020 2073 6861 7065  uts[0].    shape
+0001eba0: 203d 206d 622e 7368 6170 6528 783d 7829   = mb.shape(x=x)
+0001ebb0: 0a20 2020 2072 616e 645f 6e6f 726d 616c  .    rand_normal
+0001ebc0: 203d 206d 622e 7261 6e64 6f6d 5f6e 6f72   = mb.random_nor
+0001ebd0: 6d61 6c28 7368 6170 653d 7368 6170 6529  mal(shape=shape)
+0001ebe0: 0a20 2020 2072 616e 645f 6670 3332 203d  .    rand_fp32 =
+0001ebf0: 206d 622e 6361 7374 2878 3d72 616e 645f   mb.cast(x=rand_
+0001ec00: 6e6f 726d 616c 2c20 6474 7970 653d 2266  normal, dtype="f
+0001ec10: 7033 3222 2c20 6e61 6d65 3d6e 6f64 652e  p32", name=node.
+0001ec20: 6e61 6d65 290a 2020 2020 636f 6e74 6578  name).    contex
+0001ec30: 742e 6164 6428 7261 6e64 5f66 7033 3229  t.add(rand_fp32)
+0001ec40: 0a0a 4072 6567 6973 7465 725f 746f 7263  ..@register_torc
+0001ec50: 685f 6f70 0a64 6566 2062 6974 7769 7365  h_op.def bitwise
+0001ec60: 5f6e 6f74 2863 6f6e 7465 7874 2c20 6e6f  _not(context, no
+0001ec70: 6465 293a 0a20 2020 2069 6e70 7574 7320  de):.    inputs 
+0001ec80: 3d20 5f67 6574 5f69 6e70 7574 7328 636f  = _get_inputs(co
+0001ec90: 6e74 6578 742c 206e 6f64 6529 0a20 2020  ntext, node).   
+0001eca0: 2078 203d 2069 6e70 7574 735b 305d 0a20   x = inputs[0]. 
+0001ecb0: 2020 2064 7479 7065 203d 2078 2e64 7479     dtype = x.dty
+0001ecc0: 7065 0a20 2020 2069 6620 7479 7065 732e  pe.    if types.
+0001ecd0: 6973 5f69 6e74 2864 7479 7065 293a 0a20  is_int(dtype):. 
+0001ece0: 2020 2020 2020 2078 203d 206d 622e 6164         x = mb.ad
+0001ecf0: 6428 783d 782c 2079 3d31 290a 2020 2020  d(x=x, y=1).    
+0001ed00: 2020 2020 7820 3d20 6d62 2e6d 756c 2878      x = mb.mul(x
+0001ed10: 3d78 2c20 793d 2d31 2c20 6e61 6d65 3d6e  =x, y=-1, name=n
+0001ed20: 6f64 652e 6e61 6d65 290a 2020 2020 656c  ode.name).    el
+0001ed30: 6966 2074 7970 6573 2e69 735f 626f 6f6c  if types.is_bool
+0001ed40: 2864 7479 7065 293a 0a20 2020 2020 2020  (dtype):.       
+0001ed50: 2078 203d 206d 622e 6c6f 6769 6361 6c5f   x = mb.logical_
+0001ed60: 6e6f 7428 783d 782c 206e 616d 653d 6e6f  not(x=x, name=no
+0001ed70: 6465 2e6e 616d 6529 0a20 2020 2065 6c73  de.name).    els
+0001ed80: 653a 0a20 2020 2020 2020 2072 6169 7365  e:.        raise
+0001ed90: 2056 616c 7565 4572 726f 7228 224e 6f74   ValueError("Not
+0001eda0: 2073 7570 706f 7274 6564 2074 7970 6520   supported type 
+0001edb0: 7b7d 2066 6f75 6e64 2066 6f72 2027 6269  {} found for 'bi
+0001edc0: 7477 6973 655f 6e6f 7427 206f 7022 2e66  twise_not' op".f
+0001edd0: 6f72 6d61 7428 6474 7970 6529 290a 2020  ormat(dtype)).  
+0001ede0: 2020 636f 6e74 6578 742e 6164 6428 7829    context.add(x)
+0001edf0: 0a0a 0a40 7265 6769 7374 6572 5f74 6f72  ...@register_tor
+0001ee00: 6368 5f6f 7028 746f 7263 685f 616c 6961  ch_op(torch_alia
+0001ee10: 733d 5b22 616e 6422 5d29 0a64 6566 2062  s=["and"]).def b
+0001ee20: 6974 7769 7365 5f61 6e64 2863 6f6e 7465  itwise_and(conte
+0001ee30: 7874 2c20 6e6f 6465 293a 0a20 2020 2069  xt, node):.    i
+0001ee40: 6e70 7574 7320 3d20 5f67 6574 5f69 6e70  nputs = _get_inp
+0001ee50: 7574 7328 636f 6e74 6578 742c 206e 6f64  uts(context, nod
+0001ee60: 6529 0a0a 2020 2020 696e 7075 745f 6474  e)..    input_dt
+0001ee70: 7970 6573 203d 205b 692e 6474 7970 6520  ypes = [i.dtype 
+0001ee80: 666f 7220 6920 696e 2069 6e70 7574 735d  for i in inputs]
+0001ee90: 0a20 2020 2069 6620 616c 6c28 7479 7065  .    if all(type
+0001eea0: 732e 6973 5f62 6f6f 6c28 696e 7075 745f  s.is_bool(input_
+0001eeb0: 6474 7970 6529 2066 6f72 2069 6e70 7574  dtype) for input
+0001eec0: 5f64 7479 7065 2069 6e20 696e 7075 745f  _dtype in input_
+0001eed0: 6474 7970 6573 293a 0a20 2020 2020 2020  dtypes):.       
+0001eee0: 206c 6f67 6963 616c 5f61 6e64 2863 6f6e   logical_and(con
+0001eef0: 7465 7874 2c20 6e6f 6465 290a 2020 2020  text, node).    
+0001ef00: 656c 7365 3a0a 2020 2020 2020 2020 7261  else:.        ra
+0001ef10: 6973 6520 4e6f 7449 6d70 6c65 6d65 6e74  ise NotImplement
+0001ef20: 6564 4572 726f 7228 0a20 2020 2020 2020  edError(.       
+0001ef30: 2020 2020 2066 2254 6865 2060 6269 7477       f"The `bitw
+0001ef40: 6973 655f 616e 6460 206f 7020 6f6e 6c79  ise_and` op only
+0001ef50: 2073 7570 706f 7274 7320 626f 6f6c 6561   supports boolea
+0001ef60: 6e20 696e 7075 742c 2062 7574 2067 6574  n input, but get
+0001ef70: 207b 696e 7075 745f 6474 7970 6573 7d2e   {input_dtypes}.
+0001ef80: 220a 2020 2020 2020 2020 290a 0a0a 6465  ".        )...de
+0001ef90: 6620 5f61 7667 5f70 6f6f 6c28 636f 6e74  f _avg_pool(cont
+0001efa0: 6578 742c 206e 6f64 652c 2069 6e70 7574  ext, node, input
+0001efb0: 7329 3a0a 2020 2020 7820 3d20 696e 7075  s):.    x = inpu
+0001efc0: 7473 5b30 5d0a 2020 2020 6b65 726e 656c  ts[0].    kernel
+0001efd0: 5f73 697a 6573 203d 2069 6e70 7574 735b  _sizes = inputs[
+0001efe0: 315d 0a20 2020 2073 7472 6964 6573 203d  1].    strides =
+0001eff0: 2069 6e70 7574 735b 325d 0a20 2020 2069   inputs[2].    i
+0001f000: 6620 7374 7269 6465 732e 6f70 2e6f 705f  f strides.op.op_
+0001f010: 7479 7065 203d 3d20 2263 6f6e 7374 2220  type == "const" 
+0001f020: 616e 6420 286e 6f74 206c 6973 7428 7374  and (not list(st
+0001f030: 7269 6465 732e 7661 6c29 293a 0a20 2020  rides.val)):.   
+0001f040: 2020 2020 2073 7472 6964 6573 203d 206d       strides = m
+0001f050: 622e 636f 6e73 7428 7661 6c3d 6b65 726e  b.const(val=kern
+0001f060: 656c 5f73 697a 6573 2e76 616c 2c20 6e61  el_sizes.val, na
+0001f070: 6d65 3d73 7472 6964 6573 2e6e 616d 6529  me=strides.name)
+0001f080: 0a20 2020 2070 6164 5f74 7970 6520 3d20  .    pad_type = 
+0001f090: 2263 7573 746f 6d22 0a20 2020 2023 204e  "custom".    # N
+0001f0a0: 6565 6420 746f 2065 7870 6c69 6369 746c  eed to explicitl
+0001f0b0: 7920 7374 6174 6520 4c2d 522c 2054 2d42  y state L-R, T-B
+0001f0c0: 2070 6164 0a20 2020 2070 6164 203d 2069   pad.    pad = i
+0001f0d0: 6e70 7574 735b 335d 0a20 2020 2070 6164  nputs[3].    pad
+0001f0e0: 203d 205f 6e70 2e72 6570 6561 7428 7061   = _np.repeat(pa
+0001f0f0: 642e 7661 6c2c 2032 290a 2020 2020 6365  d.val, 2).    ce
+0001f100: 696c 5f6d 6f64 6520 3d20 696e 7075 7473  il_mode = inputs
+0001f110: 5b34 5d2e 7661 6c0a 2020 2020 696e 636c  [4].val.    incl
+0001f120: 7564 655f 7061 6420 3d20 696e 7075 7473  ude_pad = inputs
+0001f130: 5b35 5d2e 7661 6c0a 0a20 2020 2073 7061  [5].val..    spa
+0001f140: 7469 616c 5f72 616e 6b20 3d20 6c65 6e28  tial_rank = len(
+0001f150: 7061 6429 202f 2f20 320a 2020 2020 6966  pad) // 2.    if
+0001f160: 2073 7061 7469 616c 5f72 616e 6b20 3e20   spatial_rank > 
+0001f170: 3220 616e 6420 6365 696c 5f6d 6f64 6520  2 and ceil_mode 
+0001f180: 6973 2054 7275 6520 616e 6420 6c69 7374  is True and list
+0001f190: 2873 7472 6964 6573 2e76 616c 2920 213d  (strides.val) !=
+0001f1a0: 205b 315d 202a 206c 656e 2873 7472 6964   [1] * len(strid
+0001f1b0: 6573 2e76 616c 293a 0a20 2020 2020 2020  es.val):.       
+0001f1c0: 2023 2073 696e 6365 204d 494c 2064 6f65   # since MIL doe
+0001f1d0: 7320 6e6f 7420 7375 7070 6f72 7420 6365  s not support ce
+0001f1e0: 696c 5f6d 6f64 6520 666f 7220 3344 2070  il_mode for 3D p
+0001f1f0: 6f6f 6c2c 0a20 2020 2020 2020 2023 206e  ool,.        # n
+0001f200: 6565 6420 746f 2061 646a 7573 7420 7061  eed to adjust pa
+0001f210: 6464 696e 6720 7661 6c75 6573 2069 6620  dding values if 
+0001f220: 6365 696c 5f6d 6f64 6520 6973 2054 7275  ceil_mode is Tru
+0001f230: 650a 2020 2020 2020 2020 2320 6365 696c  e.        # ceil
+0001f240: 5f6d 6f64 6520 6f6e 6c79 2063 6175 7365  _mode only cause
+0001f250: 7320 616e 7920 6469 6666 6572 656e 6365  s any difference
+0001f260: 2074 686f 7567 682c 2069 6620 7468 6520   though, if the 
+0001f270: 7374 7269 6465 7320 6172 6520 6e6f 7420  strides are not 
+0001f280: 310a 2020 2020 2020 2020 785f 7370 6174  1.        x_spat
+0001f290: 6961 6c5f 6469 6d65 6e73 696f 6e73 203d  ial_dimensions =
+0001f2a0: 2078 2e73 6861 7065 5b2d 7370 6174 6961   x.shape[-spatia
+0001f2b0: 6c5f 7261 6e6b 3a5d 0a20 2020 2020 2020  l_rank:].       
+0001f2c0: 206e 6577 5f70 6164 203d 205f 6164 6a75   new_pad = _adju
+0001f2d0: 7374 5f70 6164 5f66 6f72 5f63 6569 6c5f  st_pad_for_ceil_
+0001f2e0: 6d6f 6465 280a 2020 2020 2020 2020 2020  mode(.          
+0001f2f0: 2020 785f 7370 6174 6961 6c5f 6469 6d65    x_spatial_dime
+0001f300: 6e73 696f 6e73 2c20 6b65 726e 656c 5f73  nsions, kernel_s
+0001f310: 697a 6573 2e76 616c 2c20 7374 7269 6465  izes.val, stride
+0001f320: 732e 7661 6c2c 2070 6164 0a20 2020 2020  s.val, pad.     
+0001f330: 2020 2029 0a20 2020 2020 2020 2069 6620     ).        if 
+0001f340: 5f6e 702e 7375 6d28 5f6e 702e 6162 7328  _np.sum(_np.abs(
+0001f350: 6e65 775f 7061 6420 2d20 7061 6429 2920  new_pad - pad)) 
+0001f360: 3e20 3165 2d33 3a0a 2020 2020 2020 2020  > 1e-3:.        
+0001f370: 2020 2020 6966 2069 6e63 6c75 6465 5f70      if include_p
+0001f380: 6164 3a0a 2020 2020 2020 2020 2020 2020  ad:.            
+0001f390: 2020 2020 7261 6973 6520 5661 6c75 6545      raise ValueE
+0001f3a0: 7272 6f72 2827 706f 6f6c 3344 2077 6974  rror('pool3D wit
+0001f3b0: 6820 6365 696c 206d 6f64 653d 5472 7565  h ceil mode=True
+0001f3c0: 2061 6e64 2069 6e63 6c75 6465 5f70 6164   and include_pad
+0001f3d0: 3d54 7275 6520 6e6f 7420 7375 7070 6f72  =True not suppor
+0001f3e0: 7465 6427 290a 2020 2020 2020 2020 7061  ted').        pa
+0001f3f0: 6420 3d20 6e65 775f 7061 640a 0a20 2020  d = new_pad..   
+0001f400: 2070 6f6f 6c20 3d20 6d62 2e61 7667 5f70   pool = mb.avg_p
+0001f410: 6f6f 6c28 0a20 2020 2020 2020 2078 3d78  ool(.        x=x
+0001f420: 2c0a 2020 2020 2020 2020 6b65 726e 656c  ,.        kernel
+0001f430: 5f73 697a 6573 3d6b 6572 6e65 6c5f 7369  _sizes=kernel_si
+0001f440: 7a65 732c 0a20 2020 2020 2020 2073 7472  zes,.        str
+0001f450: 6964 6573 3d73 7472 6964 6573 2c0a 2020  ides=strides,.  
+0001f460: 2020 2020 2020 7061 645f 7479 7065 3d70        pad_type=p
+0001f470: 6164 5f74 7970 652c 0a20 2020 2020 2020  ad_type,.       
+0001f480: 2070 6164 3d70 6164 2c0a 2020 2020 2020   pad=pad,.      
+0001f490: 2020 6e61 6d65 3d6e 6f64 652e 6e61 6d65    name=node.name
+0001f4a0: 2c0a 2020 2020 2020 2020 6578 636c 7564  ,.        exclud
+0001f4b0: 655f 7061 6464 696e 675f 6672 6f6d 5f61  e_padding_from_a
+0001f4c0: 7665 7261 6765 3d6e 6f74 2069 6e63 6c75  verage=not inclu
+0001f4d0: 6465 5f70 6164 2c0a 2020 2020 2020 2020  de_pad,.        
+0001f4e0: 6365 696c 5f6d 6f64 653d 6365 696c 5f6d  ceil_mode=ceil_m
+0001f4f0: 6f64 6520 6966 2073 7061 7469 616c 5f72  ode if spatial_r
+0001f500: 616e 6b20 3c3d 2032 2065 6c73 6520 4661  ank <= 2 else Fa
+0001f510: 6c73 652c 0a20 2020 2029 0a20 2020 2063  lse,.    ).    c
+0001f520: 6f6e 7465 7874 2e61 6464 2870 6f6f 6c29  ontext.add(pool)
+0001f530: 0a0a 0a40 7265 6769 7374 6572 5f74 6f72  ...@register_tor
+0001f540: 6368 5f6f 700a 6465 6620 6176 675f 706f  ch_op.def avg_po
+0001f550: 6f6c 3164 2863 6f6e 7465 7874 2c20 6e6f  ol1d(context, no
+0001f560: 6465 293a 0a20 2020 2069 6e70 7574 7320  de):.    inputs 
+0001f570: 3d20 5f67 6574 5f69 6e70 7574 7328 636f  = _get_inputs(co
+0001f580: 6e74 6578 742c 206e 6f64 652c 2065 7870  ntext, node, exp
+0001f590: 6563 7465 643d 3629 0a20 2020 205f 6176  ected=6).    _av
+0001f5a0: 675f 706f 6f6c 2863 6f6e 7465 7874 2c20  g_pool(context, 
+0001f5b0: 6e6f 6465 2c20 696e 7075 7473 290a 0a0a  node, inputs)...
+0001f5c0: 4072 6567 6973 7465 725f 746f 7263 685f  @register_torch_
+0001f5d0: 6f70 0a64 6566 2061 7667 5f70 6f6f 6c32  op.def avg_pool2
+0001f5e0: 6428 636f 6e74 6578 742c 206e 6f64 6529  d(context, node)
+0001f5f0: 3a0a 2020 2020 696e 7075 7473 203d 205f  :.    inputs = _
+0001f600: 6765 745f 696e 7075 7473 2863 6f6e 7465  get_inputs(conte
+0001f610: 7874 2c20 6e6f 6465 2c20 6578 7065 6374  xt, node, expect
+0001f620: 6564 3d37 290a 2020 2020 6469 7669 736f  ed=7).    diviso
+0001f630: 725f 6f76 6572 7269 6465 203d 2069 6e70  r_override = inp
+0001f640: 7574 735b 365d 0a20 2020 2069 6620 6469  uts[6].    if di
+0001f650: 7669 736f 725f 6f76 6572 7269 6465 2069  visor_override i
+0001f660: 7320 6e6f 7420 4e6f 6e65 3a0a 2020 2020  s not None:.    
+0001f670: 2020 2020 7261 6973 6520 5661 6c75 6545      raise ValueE
+0001f680: 7272 6f72 2822 6469 7669 736f 725f 6f76  rror("divisor_ov
+0001f690: 6572 7269 6465 2069 7320 6e6f 7420 7375  erride is not su
+0001f6a0: 7070 6f72 7465 6420 666f 7220 6176 675f  pported for avg_
+0001f6b0: 706f 6f6c 3264 2229 0a20 2020 205f 6176  pool2d").    _av
+0001f6c0: 675f 706f 6f6c 2863 6f6e 7465 7874 2c20  g_pool(context, 
+0001f6d0: 6e6f 6465 2c20 696e 7075 7473 290a 0a0a  node, inputs)...
+0001f6e0: 4072 6567 6973 7465 725f 746f 7263 685f  @register_torch_
+0001f6f0: 6f70 0a64 6566 2061 7667 5f70 6f6f 6c33  op.def avg_pool3
+0001f700: 6428 636f 6e74 6578 742c 206e 6f64 6529  d(context, node)
+0001f710: 3a0a 2020 2020 696e 7075 7473 203d 205f  :.    inputs = _
+0001f720: 6765 745f 696e 7075 7473 2863 6f6e 7465  get_inputs(conte
+0001f730: 7874 2c20 6e6f 6465 2c20 6578 7065 6374  xt, node, expect
+0001f740: 6564 3d37 290a 2020 2020 6469 7669 736f  ed=7).    diviso
+0001f750: 725f 6f76 6572 7269 6465 203d 2069 6e70  r_override = inp
+0001f760: 7574 735b 365d 0a20 2020 2069 6620 6469  uts[6].    if di
+0001f770: 7669 736f 725f 6f76 6572 7269 6465 2069  visor_override i
+0001f780: 7320 6e6f 7420 4e6f 6e65 3a0a 2020 2020  s not None:.    
+0001f790: 2020 2020 7261 6973 6520 5661 6c75 6545      raise ValueE
+0001f7a0: 7272 6f72 2822 6469 7669 736f 725f 6f76  rror("divisor_ov
+0001f7b0: 6572 7269 6465 2069 7320 6e6f 7420 7375  erride is not su
+0001f7c0: 7070 6f72 7465 6420 666f 7220 6176 675f  pported for avg_
+0001f7d0: 706f 6f6c 3364 2229 0a20 2020 205f 6176  pool3d").    _av
+0001f7e0: 675f 706f 6f6c 2863 6f6e 7465 7874 2c20  g_pool(context, 
+0001f7f0: 6e6f 6465 2c20 696e 7075 7473 290a 0a0a  node, inputs)...
+0001f800: 4072 6567 6973 7465 725f 746f 7263 685f  @register_torch_
+0001f810: 6f70 0a64 6566 206c 6f67 5f73 6f66 746d  op.def log_softm
+0001f820: 6178 2863 6f6e 7465 7874 2c20 6e6f 6465  ax(context, node
+0001f830: 293a 0a20 2020 2069 6e70 7574 7320 3d20  ):.    inputs = 
+0001f840: 5f67 6574 5f69 6e70 7574 7328 636f 6e74  _get_inputs(cont
+0001f850: 6578 742c 206e 6f64 6529 0a0a 2020 2020  ext, node)..    
+0001f860: 7820 3d20 696e 7075 7473 5b30 5d0a 2020  x = inputs[0].  
+0001f870: 2020 6178 6973 203d 2069 6e70 7574 735b    axis = inputs[
+0001f880: 315d 0a20 2020 206f 7574 203d 2069 6e70  1].    out = inp
+0001f890: 7574 735b 325d 2020 2320 4967 6e6f 7265  uts[2]  # Ignore
+0001f8a0: 642e 0a20 2020 2061 7373 6572 7420 6f75  d..    assert ou
+0001f8b0: 7420 6973 204e 6f6e 650a 2020 2020 7265  t is None.    re
+0001f8c0: 7320 3d20 6d62 2e73 6f66 746d 6178 2878  s = mb.softmax(x
+0001f8d0: 3d78 2c20 6178 6973 3d61 7869 732c 206e  =x, axis=axis, n
+0001f8e0: 616d 653d 6e6f 6465 2e6e 616d 6520 2b20  ame=node.name + 
+0001f8f0: 225f 736f 6674 6d61 7822 290a 2020 2020  "_softmax").    
+0001f900: 7265 7320 3d20 6d62 2e6c 6f67 2878 3d72  res = mb.log(x=r
+0001f910: 6573 2c20 6e61 6d65 3d6e 6f64 652e 6e61  es, name=node.na
+0001f920: 6d65 290a 2020 2020 636f 6e74 6578 742e  me).    context.
+0001f930: 6164 6428 7265 7329 0a0a 0a40 7265 6769  add(res)...@regi
+0001f940: 7374 6572 5f74 6f72 6368 5f6f 7028 746f  ster_torch_op(to
+0001f950: 7263 685f 616c 6961 733d 5b22 6e6c 6c5f  rch_alias=["nll_
+0001f960: 6c6f 7373 5f6e 6422 5d29 0a64 6566 206e  loss_nd"]).def n
+0001f970: 6c6c 5f6c 6f73 7328 636f 6e74 6578 742c  ll_loss(context,
+0001f980: 206e 6f64 6529 3a0a 2020 2020 696e 7075   node):.    inpu
+0001f990: 7473 203d 205f 6765 745f 696e 7075 7473  ts = _get_inputs
+0001f9a0: 2863 6f6e 7465 7874 2c20 6e6f 6465 2c20  (context, node, 
+0001f9b0: 6578 7065 6374 6564 3d35 290a 0a20 2020  expected=5)..   
+0001f9c0: 2078 203d 2069 6e70 7574 735b 305d 0a20   x = inputs[0]. 
+0001f9d0: 2020 2074 6172 6765 7420 3d20 696e 7075     target = inpu
+0001f9e0: 7473 5b31 5d0a 2020 2020 7765 6967 6874  ts[1].    weight
+0001f9f0: 203d 2069 6e70 7574 735b 325d 0a20 2020   = inputs[2].   
+0001fa00: 2072 6564 7563 7469 6f6e 203d 2069 6e70   reduction = inp
+0001fa10: 7574 735b 335d 0a20 2020 2069 676e 6f72  uts[3].    ignor
+0001fa20: 655f 696e 6465 7820 3d20 696e 7075 7473  e_index = inputs
+0001fa30: 5b34 5d0a 0a20 2020 2023 206d 6170 7069  [4]..    # mappi
+0001fa40: 6e67 2066 6f72 2072 6564 7563 7469 6f6e  ng for reduction
+0001fa50: 0a20 2020 2072 6564 7563 7469 6f6e 5f6d  .    reduction_m
+0001fa60: 6170 7069 6e67 203d 207b 303a 2022 6e6f  apping = {0: "no
+0001fa70: 6e65 222c 2031 3a20 226d 6561 6e22 2c20  ne", 1: "mean", 
+0001fa80: 323a 2022 7375 6d22 7d0a 2020 2020 7265  2: "sum"}.    re
+0001fa90: 6475 6374 696f 6e20 3d20 7265 6475 6374  duction = reduct
+0001faa0: 696f 6e5f 6d61 7070 696e 675b 7265 6475  ion_mapping[redu
+0001fab0: 6374 696f 6e2e 7661 6c5d 0a0a 2020 2020  ction.val]..    
+0001fac0: 2320 636f 6d70 7574 6520 7468 6520 7765  # compute the we
+0001fad0: 6967 6874 7320 6c6f 7373 0a20 2020 2062  ights loss.    b
+0001fae0: 6174 6368 5f73 697a 6520 3d20 782e 7368  atch_size = x.sh
+0001faf0: 6170 655b 305d 0a0a 2020 2020 2320 6f6e  ape[0]..    # on
+0001fb00: 6c79 2073 7570 706f 7274 2077 6569 6768  ly support weigh
+0001fb10: 7420 616e 6420 6967 6e6f 7265 5f69 6e64  t and ignore_ind
+0001fb20: 6578 2062 6f74 6820 4e6f 6e65 0a20 2020  ex both None.   
+0001fb30: 2069 6620 7765 6967 6874 2069 7320 6e6f   if weight is no
+0001fb40: 7420 4e6f 6e65 3a0a 2020 2020 2020 2020  t None:.        
+0001fb50: 7261 6973 6520 4e6f 7449 6d70 6c65 6d65  raise NotImpleme
+0001fb60: 6e74 6564 4572 726f 7228 224f 6e6c 7920  ntedError("Only 
+0001fb70: 756e 6974 7920 7765 6967 6874 2069 7320  unity weight is 
+0001fb80: 7375 7070 6f72 7465 6420 666f 7220 4e4c  supported for NL
+0001fb90: 4c4c 6f73 732e 2229 0a20 2020 2069 6620  LLoss.").    if 
+0001fba0: 6967 6e6f 7265 5f69 6e64 6578 2e76 616c  ignore_index.val
+0001fbb0: 2021 3d20 2d31 3030 3a0a 2020 2020 2020   != -100:.      
+0001fbc0: 2020 7261 6973 6520 4e6f 7449 6d70 6c65    raise NotImple
+0001fbd0: 6d65 6e74 6564 4572 726f 7228 2269 676e  mentedError("ign
+0001fbe0: 6f72 6520 696e 6465 7820 6e6f 7420 7375  ore index not su
+0001fbf0: 7070 6f72 7465 6420 666f 7220 4e4c 4c4c  pported for NLLL
+0001fc00: 6f73 732e 2229 0a0a 2020 2020 7820 3d20  oss.")..    x = 
+0001fc10: 6d62 2e63 6173 7428 783d 782c 2064 7479  mb.cast(x=x, dty
+0001fc20: 7065 3d22 6670 3332 2229 0a20 2020 2078  pe="fp32").    x
+0001fc30: 203d 206d 622e 6d75 6c28 783d 782c 2079   = mb.mul(x=x, y
+0001fc40: 3d2d 312e 290a 2020 2020 7261 6e67 655f  =-1.).    range_
+0001fc50: 696e 6469 6365 7320 3d20 6d62 2e72 616e  indices = mb.ran
+0001fc60: 6765 5f31 6428 656e 643d 6261 7463 685f  ge_1d(end=batch_
+0001fc70: 7369 7a65 2c20 7374 6172 743d 302c 2073  size, start=0, s
+0001fc80: 7465 703d 3129 0a20 2020 2074 6f74 616c  tep=1).    total
+0001fc90: 5f69 6e64 6963 6573 203d 206d 622e 7374  _indices = mb.st
+0001fca0: 6163 6b28 7661 6c75 6573 3d5b 7261 6e67  ack(values=[rang
+0001fcb0: 655f 696e 6469 6365 732c 2074 6172 6765  e_indices, targe
+0001fcc0: 745d 2c20 6178 6973 3d31 290a 2020 2020  t], axis=1).    
+0001fcd0: 6c6f 7373 203d 206d 622e 6761 7468 6572  loss = mb.gather
+0001fce0: 5f6e 6428 783d 782c 2069 6e64 6963 6573  _nd(x=x, indices
+0001fcf0: 3d74 6f74 616c 5f69 6e64 6963 6573 290a  =total_indices).
+0001fd00: 0a20 2020 2023 2072 6564 7563 7469 6f6e  .    # reduction
+0001fd10: 2074 7970 650a 2020 2020 6966 2072 6564   type.    if red
+0001fd20: 7563 7469 6f6e 203d 3d20 226e 6f6e 6522  uction == "none"
+0001fd30: 3a0a 2020 2020 2020 2020 6f75 7420 3d20  :.        out = 
+0001fd40: 6d62 2e69 6465 6e74 6974 7928 783d 6c6f  mb.identity(x=lo
+0001fd50: 7373 2c20 6e61 6d65 3d6e 6f64 652e 6e61  ss, name=node.na
+0001fd60: 6d65 290a 2020 2020 656c 6966 2072 6564  me).    elif red
+0001fd70: 7563 7469 6f6e 203d 3d20 2273 756d 223a  uction == "sum":
+0001fd80: 0a20 2020 2020 2020 206f 7574 203d 206d  .        out = m
+0001fd90: 622e 7265 6475 6365 5f73 756d 2878 3d6c  b.reduce_sum(x=l
+0001fda0: 6f73 732c 2061 7865 733d 5b30 5d2c 206b  oss, axes=[0], k
+0001fdb0: 6565 705f 6469 6d73 3d46 616c 7365 2c20  eep_dims=False, 
+0001fdc0: 6e61 6d65 3d6e 6f64 652e 6e61 6d65 290a  name=node.name).
+0001fdd0: 2020 2020 656c 6966 2072 6564 7563 7469      elif reducti
+0001fde0: 6f6e 203d 3d20 226d 6561 6e22 3a0a 2020  on == "mean":.  
+0001fdf0: 2020 2020 2020 6f75 7420 3d20 6d62 2e72        out = mb.r
+0001fe00: 6561 6c5f 6469 7628 783d 6c6f 7373 2c20  eal_div(x=loss, 
+0001fe10: 793d 5f6e 702e 666c 6f61 7433 3228 6261  y=_np.float32(ba
+0001fe20: 7463 685f 7369 7a65 2929 0a20 2020 2020  tch_size)).     
+0001fe30: 2020 206f 7574 203d 206d 622e 7265 6475     out = mb.redu
+0001fe40: 6365 5f73 756d 2878 3d6f 7574 2c20 6178  ce_sum(x=out, ax
+0001fe50: 6573 3d5b 305d 2c20 6b65 6570 5f64 696d  es=[0], keep_dim
+0001fe60: 733d 4661 6c73 652c 206e 616d 653d 6e6f  s=False, name=no
+0001fe70: 6465 2e6e 616d 6529 0a20 2020 2065 6c73  de.name).    els
+0001fe80: 653a 0a20 2020 2020 2020 2072 6169 7365  e:.        raise
+0001fe90: 204e 6f74 496d 706c 656d 656e 7465 6445   NotImplementedE
+0001fea0: 7272 6f72 2822 556e 7375 7070 6f72 7465  rror("Unsupporte
+0001feb0: 6420 7265 6475 6374 696f 6e20 7479 7065  d reduction type
+0001fec0: 2066 6f72 204e 4c4c 4c6f 7373 2e22 290a   for NLLLoss.").
+0001fed0: 0a20 2020 2063 6f6e 7465 7874 2e61 6464  .    context.add
+0001fee0: 286f 7574 290a 0a0a 4072 6567 6973 7465  (out)...@registe
+0001fef0: 725f 746f 7263 685f 6f70 0a64 6566 2073  r_torch_op.def s
+0001ff00: 6967 6d6f 6964 2863 6f6e 7465 7874 2c20  igmoid(context, 
+0001ff10: 6e6f 6465 293a 0a20 2020 2069 6e70 7574  node):.    input
+0001ff20: 7320 3d20 5f67 6574 5f69 6e70 7574 7328  s = _get_inputs(
+0001ff30: 636f 6e74 6578 742c 206e 6f64 652c 2065  context, node, e
+0001ff40: 7870 6563 7465 643d 3129 0a0a 2020 2020  xpected=1)..    
+0001ff50: 7265 7320 3d20 6d62 2e73 6967 6d6f 6964  res = mb.sigmoid
+0001ff60: 2878 3d69 6e70 7574 735b 305d 2c20 6e61  (x=inputs[0], na
+0001ff70: 6d65 3d6e 6f64 652e 6e61 6d65 290a 2020  me=node.name).  
+0001ff80: 2020 636f 6e74 6578 742e 6164 6428 7265    context.add(re
+0001ff90: 7329 0a0a 0a40 7265 6769 7374 6572 5f74  s)...@register_t
+0001ffa0: 6f72 6368 5f6f 700a 6465 6620 6861 7264  orch_op.def hard
+0001ffb0: 7369 676d 6f69 6428 636f 6e74 6578 742c  sigmoid(context,
+0001ffc0: 206e 6f64 6529 3a0a 2020 2020 696e 7075   node):.    inpu
+0001ffd0: 7473 203d 205f 6765 745f 696e 7075 7473  ts = _get_inputs
+0001ffe0: 2863 6f6e 7465 7874 2c20 6e6f 6465 2c20  (context, node, 
+0001fff0: 6578 7065 6374 6564 3d31 290a 0a20 2020  expected=1)..   
+00020000: 2072 6573 203d 206d 622e 7369 676d 6f69   res = mb.sigmoi
+00020010: 645f 6861 7264 2878 3d69 6e70 7574 735b  d_hard(x=inputs[
+00020020: 305d 2c20 616c 7068 613d 312e 3020 2f20  0], alpha=1.0 / 
+00020030: 362c 2062 6574 613d 302e 352c 206e 616d  6, beta=0.5, nam
+00020040: 653d 6e6f 6465 2e6e 616d 6529 0a20 2020  e=node.name).   
+00020050: 2063 6f6e 7465 7874 2e61 6464 2872 6573   context.add(res
+00020060: 290a 0a0a 4072 6567 6973 7465 725f 746f  )...@register_to
+00020070: 7263 685f 6f70 0a64 6566 2067 656c 7528  rch_op.def gelu(
+00020080: 636f 6e74 6578 742c 206e 6f64 6529 3a0a  context, node):.
+00020090: 2020 2020 696e 7075 7473 203d 205f 6765      inputs = _ge
+000200a0: 745f 696e 7075 7473 2863 6f6e 7465 7874  t_inputs(context
+000200b0: 2c20 6e6f 6465 290a 2020 2020 6173 7365  , node).    asse
+000200c0: 7274 206c 656e 2869 6e70 7574 7329 2069  rt len(inputs) i
+000200d0: 6e20 2831 2c20 3229 0a20 2020 2069 6620  n (1, 2).    if 
+000200e0: 6c65 6e28 696e 7075 7473 2920 3d3d 2032  len(inputs) == 2
+000200f0: 3a0a 2020 2020 2020 2020 6170 7072 6f78  :.        approx
+00020100: 696d 6174 6520 3d20 696e 7075 7473 5b31  imate = inputs[1
+00020110: 5d2e 7661 6c0a 2020 2020 2020 2020 6173  ].val.        as
+00020120: 7365 7274 2061 7070 726f 7869 6d61 7465  sert approximate
+00020130: 203d 3d20 276e 6f6e 6527 0a20 2020 2072   == 'none'.    r
+00020140: 6573 203d 206d 622e 6765 6c75 2878 3d69  es = mb.gelu(x=i
+00020150: 6e70 7574 735b 305d 2c20 6e61 6d65 3d6e  nputs[0], name=n
+00020160: 6f64 652e 6e61 6d65 290a 2020 2020 636f  ode.name).    co
+00020170: 6e74 6578 742e 6164 6428 7265 7329 0a0a  ntext.add(res)..
+00020180: 0a40 7265 6769 7374 6572 5f74 6f72 6368  .@register_torch
+00020190: 5f6f 7028 746f 7263 685f 616c 6961 733d  _op(torch_alias=
+000201a0: 5b22 736c 6963 6522 5d29 0a64 6566 205f  ["slice"]).def _
+000201b0: 736c 6963 6528 636f 6e74 6578 742c 206e  slice(context, n
+000201c0: 6f64 6529 3a0a 2020 2020 696e 7075 7473  ode):.    inputs
+000201d0: 203d 205f 6765 745f 696e 7075 7473 2863   = _get_inputs(c
+000201e0: 6f6e 7465 7874 2c20 6e6f 6465 2c20 6578  ontext, node, ex
+000201f0: 7065 6374 6564 3d35 290a 2020 2020 7820  pected=5).    x 
+00020200: 3d20 696e 7075 7473 5b30 5d0a 2020 2020  = inputs[0].    
+00020210: 6469 6d20 3d20 696e 7075 7473 5b31 5d2e  dim = inputs[1].
+00020220: 7661 6c0a 0a20 2020 2069 6620 696e 7075  val..    if inpu
+00020230: 7473 5b32 5d20 616e 6420 696e 7075 7473  ts[2] and inputs
+00020240: 5b32 5d2e 7661 6c20 6973 206e 6f74 204e  [2].val is not N
+00020250: 6f6e 653a 0a20 2020 2020 2020 2073 7461  one:.        sta
+00020260: 7274 203d 2069 6e70 7574 735b 325d 2e76  rt = inputs[2].v
+00020270: 616c 0a20 2020 2065 6c69 6620 6973 696e  al.    elif isin
+00020280: 7374 616e 6365 2869 6e70 7574 735b 325d  stance(inputs[2]
+00020290: 2c20 5661 7229 3a0a 2020 2020 2020 2020  , Var):.        
+000202a0: 7374 6172 7420 3d20 696e 7075 7473 5b32  start = inputs[2
+000202b0: 5d0a 2020 2020 656c 7365 3a0a 2020 2020  ].    else:.    
+000202c0: 2020 2020 7374 6172 7420 3d20 300a 0a20      start = 0.. 
+000202d0: 2020 2069 6620 696e 7075 7473 5b33 5d20     if inputs[3] 
+000202e0: 616e 6420 696e 7075 7473 5b33 5d2e 7661  and inputs[3].va
+000202f0: 6c20 6973 206e 6f74 204e 6f6e 653a 0a20  l is not None:. 
+00020300: 2020 2020 2020 2065 6e64 203d 2069 6e70         end = inp
+00020310: 7574 735b 335d 2e76 616c 0a20 2020 2065  uts[3].val.    e
+00020320: 6c69 6620 6973 696e 7374 616e 6365 2869  lif isinstance(i
+00020330: 6e70 7574 735b 335d 2c20 5661 7229 3a0a  nputs[3], Var):.
+00020340: 2020 2020 2020 2020 656e 6420 3d20 696e          end = in
+00020350: 7075 7473 5b33 5d0a 2020 2020 656c 7365  puts[3].    else
+00020360: 3a0a 2020 2020 2020 2020 656e 6420 3d20  :.        end = 
+00020370: 4e6f 6e65 0a0a 2020 2020 7374 6570 203d  None..    step =
+00020380: 2069 6e70 7574 735b 345d 2e76 616c 0a0a   inputs[4].val..
+00020390: 2020 2020 6966 2073 7461 7274 203d 3d20      if start == 
+000203a0: 3020 616e 6420 656e 6420 6973 204e 6f6e  0 and end is Non
+000203b0: 6520 616e 6420 7374 6570 203d 3d20 313a  e and step == 1:
+000203c0: 0a20 2020 2020 2020 2023 2048 616e 646c  .        # Handl
+000203d0: 696e 6720 785b 3a5d 2c20 6a75 7374 2070  ing x[:], just p
+000203e0: 6173 7320 7468 726f 7567 6820 7468 6520  ass through the 
+000203f0: 7465 6e73 6f72 2e0a 2020 2020 2020 2020  tensor..        
+00020400: 636f 6e74 6578 742e 6164 6428 782c 206e  context.add(x, n
+00020410: 6f64 652e 6e61 6d65 290a 2020 2020 2020  ode.name).      
+00020420: 2020 7265 7475 726e 0a0a 2020 2020 6265    return..    be
+00020430: 6769 6e5f 6172 7261 7920 3d20 5b30 5d20  gin_array = [0] 
+00020440: 2a20 6c65 6e28 782e 7368 6170 6529 0a20  * len(x.shape). 
+00020450: 2020 2062 6567 696e 5f61 7272 6179 5b64     begin_array[d
+00020460: 696d 5d20 3d20 7374 6172 740a 2020 2020  im] = start.    
+00020470: 656e 645f 6172 7261 7920 3d20 5b73 2069  end_array = [s i
+00020480: 6620 6973 696e 7374 616e 6365 2873 2c20  f isinstance(s, 
+00020490: 696e 7429 2065 6c73 6520 3020 666f 7220  int) else 0 for 
+000204a0: 7320 696e 2078 2e73 6861 7065 5d0a 2020  s in x.shape].  
+000204b0: 2020 656e 645f 6d61 736b 203d 205b 5472    end_mask = [Tr
+000204c0: 7565 5d20 2a20 6c65 6e28 782e 7368 6170  ue] * len(x.shap
+000204d0: 6529 0a20 2020 2069 6620 656e 6420 6973  e).    if end is
+000204e0: 206e 6f74 204e 6f6e 653a 0a20 2020 2020   not None:.     
+000204f0: 2020 2065 6e64 5f61 7272 6179 5b64 696d     end_array[dim
+00020500: 5d20 3d20 656e 640a 2020 2020 2020 2020  ] = end.        
+00020510: 656e 645f 6d61 736b 5b64 696d 5d20 3d20  end_mask[dim] = 
+00020520: 4661 6c73 650a 0a20 2020 2069 6620 6973  False..    if is
+00020530: 696e 7374 616e 6365 2873 7461 7274 2c20  instance(start, 
+00020540: 5661 7229 3a0a 2020 2020 2020 2020 6265  Var):.        be
+00020550: 6769 6e5f 6172 7261 7920 3d20 6d62 2e63  gin_array = mb.c
+00020560: 6f6e 6361 7428 7661 6c75 6573 3d62 6567  oncat(values=beg
+00020570: 696e 5f61 7272 6179 2c20 6178 6973 3d30  in_array, axis=0
+00020580: 290a 0a20 2020 2069 6620 6973 696e 7374  )..    if isinst
+00020590: 616e 6365 2865 6e64 2c20 5661 7229 3a0a  ance(end, Var):.
+000205a0: 2020 2020 2020 2020 656e 645f 6172 7261          end_arra
+000205b0: 7920 3d20 6d62 2e63 6f6e 6361 7428 7661  y = mb.concat(va
+000205c0: 6c75 6573 3d65 6e64 5f61 7272 6179 2c20  lues=end_array, 
+000205d0: 6178 6973 3d30 290a 0a20 2020 206b 7761  axis=0)..    kwa
+000205e0: 7267 7320 3d20 7b0a 2020 2020 2020 2020  rgs = {.        
+000205f0: 2278 223a 2078 2c0a 2020 2020 2020 2020  "x": x,.        
+00020600: 2262 6567 696e 223a 2062 6567 696e 5f61  "begin": begin_a
+00020610: 7272 6179 2c0a 2020 2020 2020 2020 2265  rray,.        "e
+00020620: 6e64 223a 2065 6e64 5f61 7272 6179 2c0a  nd": end_array,.
+00020630: 2020 2020 2020 2020 2265 6e64 5f6d 6173          "end_mas
+00020640: 6b22 3a20 656e 645f 6d61 736b 2c0a 2020  k": end_mask,.  
+00020650: 2020 2020 2020 226e 616d 6522 3a20 6e6f        "name": no
+00020660: 6465 2e6e 616d 652c 0a20 2020 207d 0a0a  de.name,.    }..
+00020670: 2020 2020 6966 2073 7465 7020 213d 2031      if step != 1
+00020680: 3a0a 2020 2020 2020 2020 7374 7269 6465  :.        stride
+00020690: 5f61 7272 6179 203d 205f 6e70 2e61 7272  _array = _np.arr
+000206a0: 6179 285b 315d 202a 206c 656e 2878 2e73  ay([1] * len(x.s
+000206b0: 6861 7065 2929 0a20 2020 2020 2020 2073  hape)).        s
+000206c0: 7472 6964 655f 6172 7261 795b 6469 6d5d  tride_array[dim]
+000206d0: 203d 2073 7465 700a 2020 2020 2020 2020   = step.        
+000206e0: 6b77 6172 6773 5b22 7374 7269 6465 225d  kwargs["stride"]
+000206f0: 203d 2073 7472 6964 655f 6172 7261 790a   = stride_array.
+00020700: 0a20 2020 2072 6573 203d 206d 622e 736c  .    res = mb.sl
+00020710: 6963 655f 6279 5f69 6e64 6578 282a 2a6b  ice_by_index(**k
+00020720: 7761 7267 7329 0a20 2020 2063 6f6e 7465  wargs).    conte
+00020730: 7874 2e61 6464 2872 6573 290a 0a0a 4072  xt.add(res)...@r
+00020740: 6567 6973 7465 725f 746f 7263 685f 6f70  egister_torch_op
+00020750: 2874 6f72 6368 5f61 6c69 6173 3d5b 2273  (torch_alias=["s
+00020760: 706c 6974 5f77 6974 685f 7369 7a65 7322  plit_with_sizes"
+00020770: 5d29 0a64 6566 2073 706c 6974 2863 6f6e  ]).def split(con
+00020780: 7465 7874 2c20 6e6f 6465 293a 0a20 2020  text, node):.   
+00020790: 2069 6e70 7574 7320 3d20 5f67 6574 5f69   inputs = _get_i
+000207a0: 6e70 7574 7328 636f 6e74 6578 742c 206e  nputs(context, n
+000207b0: 6f64 652c 2065 7870 6563 7465 643d 3329  ode, expected=3)
+000207c0: 0a20 2020 2078 203d 2069 6e70 7574 735b  .    x = inputs[
+000207d0: 305d 0a20 2020 2073 706c 6974 5f73 697a  0].    split_siz
+000207e0: 6573 203d 2069 6e70 7574 735b 315d 0a20  es = inputs[1]. 
+000207f0: 2020 2064 696d 203d 2069 6e70 7574 735b     dim = inputs[
+00020800: 325d 2e76 616c 0a0a 2020 2020 6966 206e  2].val..    if n
+00020810: 6f74 2069 7369 6e73 7461 6e63 6528 7370  ot isinstance(sp
+00020820: 6c69 745f 7369 7a65 732e 7661 6c2c 205f  lit_sizes.val, _
+00020830: 6e70 2e6e 6461 7272 6179 293a 0a20 2020  np.ndarray):.   
+00020840: 2020 2020 2073 6861 7065 203d 206d 622e       shape = mb.
+00020850: 7368 6170 6528 783d 7829 0a20 2020 2020  shape(x=x).     
+00020860: 2020 2064 696d 5f73 697a 6520 3d20 5f6c     dim_size = _l
+00020870: 6973 745f 7365 6c65 6374 2873 6861 7065  ist_select(shape
+00020880: 2c20 6469 6d29 0a20 2020 2020 2020 2023  , dim).        #
+00020890: 204d 494c 2073 706c 6974 206f 7020 6e65   MIL split op ne
+000208a0: 6564 7320 7468 6520 7369 7a65 206f 6620  eds the size of 
+000208b0: 6561 6368 2073 706c 6974 2074 6f20 6265  each split to be
+000208c0: 2067 6976 656e 2065 7870 6c69 6369 746c   given explicitl
+000208d0: 792e 0a20 2020 2020 2020 206e 756d 5f77  y..        num_w
+000208e0: 686f 6c65 5f73 706c 6974 7320 3d20 6d62  hole_splits = mb
+000208f0: 2e66 6c6f 6f72 5f64 6976 2878 3d64 696d  .floor_div(x=dim
+00020900: 5f73 697a 652c 2079 3d73 706c 6974 5f73  _size, y=split_s
+00020910: 697a 6573 290a 2020 2020 2020 2020 7265  izes).        re
+00020920: 6d61 696e 6465 7220 3d20 6d62 2e6d 6f64  mainder = mb.mod
+00020930: 2878 3d64 696d 5f73 697a 652c 2079 3d73  (x=dim_size, y=s
+00020940: 706c 6974 5f73 697a 6573 290a 0a20 2020  plit_sizes)..   
+00020950: 2020 2020 2023 204d 494c 2064 6f65 736e       # MIL doesn
+00020960: 2774 2068 6176 6520 6120 7761 7920 6f66  't have a way of
+00020970: 2074 7572 6e69 6e67 2061 2073 6361 6c61   turning a scala
+00020980: 7220 696e 746f 2061 2074 656e 736f 7220  r into a tensor 
+00020990: 286c 6973 7420 7772 6974 650a 2020 2020  (list write.    
+000209a0: 2020 2020 2320 6f6e 6c79 2073 7570 706f      # only suppo
+000209b0: 7274 7320 7465 6e73 6f72 7329 2e20 4173  rts tensors). As
+000209c0: 2061 2077 6f72 6b61 726f 756e 642c 2077   a workaround, w
+000209d0: 6520 6372 6561 7465 2061 2063 6f6e 7374  e create a const
+000209e0: 616e 7420 5b31 5d0a 2020 2020 2020 2020  ant [1].        
+000209f0: 2320 7465 6e73 6f72 2061 6e64 206d 756c  # tensor and mul
+00020a00: 7469 706c 7920 6974 2062 7920 7468 6520  tiply it by the 
+00020a10: 7363 616c 6172 2076 616c 7565 2c20 7468  scalar value, th
+00020a20: 7573 2063 7265 6174 696e 6720 6120 7465  us creating a te
+00020a30: 6e73 6f72 0a20 2020 2020 2020 2023 2077  nsor.        # w
+00020a40: 6974 6820 7468 6520 7363 616c 6172 2076  ith the scalar v
+00020a50: 616c 7565 2069 6e20 6974 2e0a 2020 2020  alue in it..    
+00020a60: 2020 2020 746d 7020 3d20 6d62 2e63 6f6e      tmp = mb.con
+00020a70: 7374 2876 616c 3d5b 315d 290a 2020 2020  st(val=[1]).    
+00020a80: 2020 2020 7768 6f6c 655f 7369 7a65 7320      whole_sizes 
+00020a90: 3d20 6d62 2e6d 756c 2878 3d74 6d70 2c20  = mb.mul(x=tmp, 
+00020aa0: 793d 7370 6c69 745f 7369 7a65 7329 0a20  y=split_sizes). 
+00020ab0: 2020 2020 2020 2072 6570 7320 3d20 6d62         reps = mb
+00020ac0: 2e6d 756c 2878 3d74 6d70 2c20 793d 6e75  .mul(x=tmp, y=nu
+00020ad0: 6d5f 7768 6f6c 655f 7370 6c69 7473 290a  m_whole_splits).
+00020ae0: 2020 2020 2020 2020 7768 6f6c 655f 7369          whole_si
+00020af0: 7a65 7320 3d20 6d62 2e74 696c 6528 783d  zes = mb.tile(x=
+00020b00: 7768 6f6c 655f 7369 7a65 732c 2072 6570  whole_sizes, rep
+00020b10: 733d 7265 7073 290a 2020 2020 2020 2020  s=reps).        
+00020b20: 6966 2072 656d 6169 6e64 6572 2e76 616c  if remainder.val
+00020b30: 203d 3d20 303a 0a20 2020 2020 2020 2020   == 0:.         
+00020b40: 2020 2073 706c 6974 5f73 697a 6573 203d     split_sizes =
+00020b50: 2077 686f 6c65 5f73 697a 6573 0a20 2020   whole_sizes.   
+00020b60: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
+00020b70: 2020 2020 2020 2070 6172 7469 616c 5f73         partial_s
+00020b80: 697a 6520 3d20 6d62 2e6d 756c 2878 3d74  ize = mb.mul(x=t
+00020b90: 6d70 2c20 793d 7265 6d61 696e 6465 7229  mp, y=remainder)
+00020ba0: 0a20 2020 2020 2020 2020 2020 2073 706c  .            spl
+00020bb0: 6974 5f73 697a 6573 203d 206d 622e 636f  it_sizes = mb.co
+00020bc0: 6e63 6174 2876 616c 7565 733d 5b77 686f  ncat(values=[who
+00020bd0: 6c65 5f73 697a 6573 2c20 7061 7274 6961  le_sizes, partia
+00020be0: 6c5f 7369 7a65 5d2c 2061 7869 733d 3029  l_size], axis=0)
+00020bf0: 0a20 2020 2072 6573 203d 206d 622e 7370  .    res = mb.sp
+00020c00: 6c69 7428 783d 782c 2073 706c 6974 5f73  lit(x=x, split_s
+00020c10: 697a 6573 3d73 706c 6974 5f73 697a 6573  izes=split_sizes
+00020c20: 2c20 6178 6973 3d64 696d 2c20 6e61 6d65  , axis=dim, name
+00020c30: 3d6e 6f64 652e 6e61 6d65 290a 2020 2020  =node.name).    
+00020c40: 636f 6e74 6578 742e 6164 6428 7265 732c  context.add(res,
+00020c50: 2074 6f72 6368 5f6e 616d 653d 6e6f 6465   torch_name=node
+00020c60: 2e6e 616d 6529 0a0a 0a40 7265 6769 7374  .name)...@regist
+00020c70: 6572 5f74 6f72 6368 5f6f 700a 6465 6620  er_torch_op.def 
+00020c80: 756e 6269 6e64 2863 6f6e 7465 7874 2c20  unbind(context, 
+00020c90: 6e6f 6465 293a 0a20 2020 2069 6e70 7574  node):.    input
+00020ca0: 7320 3d20 5f67 6574 5f69 6e70 7574 7328  s = _get_inputs(
+00020cb0: 636f 6e74 6578 742c 206e 6f64 652c 2065  context, node, e
+00020cc0: 7870 6563 7465 643d 3229 0a20 2020 2078  xpected=2).    x
+00020cd0: 203d 2069 6e70 7574 735b 305d 0a20 2020   = inputs[0].   
+00020ce0: 2064 696d 203d 2069 6e70 7574 735b 315d   dim = inputs[1]
+00020cf0: 2e76 616c 0a20 2020 2073 706c 6974 5f73  .val.    split_s
+00020d00: 697a 6573 203d 205b 315d 202a 2078 2e73  izes = [1] * x.s
+00020d10: 6861 7065 5b64 696d 5d0a 2020 2020 6966  hape[dim].    if
+00020d20: 206c 656e 2873 706c 6974 5f73 697a 6573   len(split_sizes
+00020d30: 2920 3d3d 2031 3a0a 2020 2020 2020 2020  ) == 1:.        
+00020d40: 7265 7320 3d20 5b6d 622e 7371 7565 657a  res = [mb.squeez
+00020d50: 6528 783d 782c 2061 7865 733d 5b64 696d  e(x=x, axes=[dim
+00020d60: 5d29 5d0a 2020 2020 656c 7365 3a0a 2020  ])].    else:.  
+00020d70: 2020 2020 2020 7265 7320 3d20 6d62 2e73        res = mb.s
+00020d80: 706c 6974 2878 3d78 2c20 7370 6c69 745f  plit(x=x, split_
+00020d90: 7369 7a65 733d 7370 6c69 745f 7369 7a65  sizes=split_size
+00020da0: 732c 2061 7869 733d 6469 6d2c 206e 616d  s, axis=dim, nam
+00020db0: 653d 6e6f 6465 2e6e 616d 6529 0a20 2020  e=node.name).   
+00020dc0: 2020 2020 2072 6573 203d 205b 6d62 2e73       res = [mb.s
+00020dd0: 7175 6565 7a65 2878 3d78 2c20 6178 6573  queeze(x=x, axes
+00020de0: 3d5b 6469 6d5d 2920 666f 7220 7820 696e  =[dim]) for x in
+00020df0: 2072 6573 5d0a 2020 2020 636f 6e74 6578   res].    contex
+00020e00: 742e 6164 6428 7265 732c 2074 6f72 6368  t.add(res, torch
+00020e10: 5f6e 616d 653d 6e6f 6465 2e6e 616d 6529  _name=node.name)
+00020e20: 0a0a 0a40 7265 6769 7374 6572 5f74 6f72  ...@register_tor
+00020e30: 6368 5f6f 700a 6465 6620 746f 2863 6f6e  ch_op.def to(con
+00020e40: 7465 7874 2c20 6e6f 6465 293a 0a20 2020  text, node):.   
+00020e50: 2069 6e70 7574 7320 3d20 5f67 6574 5f69   inputs = _get_i
+00020e60: 6e70 7574 7328 636f 6e74 6578 742c 206e  nputs(context, n
+00020e70: 6f64 6529 0a0a 2020 2020 2320 5468 6572  ode)..    # Ther
+00020e80: 6520 6172 6520 6120 6c6f 7420 6f66 2076  e are a lot of v
+00020e90: 6172 6961 6e74 7320 6f66 2060 746f 6020  ariants of `to` 
+00020ea0: 6f70 2e0a 2020 2020 2320 2d20 5768 656e  op..    # - When
+00020eb0: 206c 656e 2869 6e70 7574 7329 2069 7320   len(inputs) is 
+00020ec0: 3720 6f72 2038 2c20 7765 206f 6e6c 7920  7 or 8, we only 
+00020ed0: 6361 7265 2061 626f 7574 2074 6865 2066  care about the f
+00020ee0: 6972 7374 2074 776f 2070 6172 616d 7320  irst two params 
+00020ef0: 2869 6e70 7574 2061 6e64 2064 7479 7065  (input and dtype
+00020f00: 292e 0a20 2020 2023 202d 2057 6865 6e20  )..    # - When 
+00020f10: 6c65 6e28 696e 7075 7473 2920 3d3d 2036  len(inputs) == 6
+00020f20: 2c20 7468 6520 7061 7261 6d65 7465 7220  , the parameter 
+00020f30: 6973 2028 696e 7075 742c 205f 2c20 6474  is (input, _, dt
+00020f40: 7970 652c 206e 6f6e 5f62 6c6f 636b 696e  ype, non_blockin
+00020f50: 672c 2063 6f70 792c 206d 656d 6f72 795f  g, copy, memory_
+00020f60: 666f 726d 6174 290a 2020 2020 2320 2d20  format).    # - 
+00020f70: 5768 656e 206c 656e 2869 6e70 7574 7329  When len(inputs)
+00020f80: 203d 3d20 352c 2074 6865 2070 6172 616d   == 5, the param
+00020f90: 6574 6572 2069 7320 2869 6e70 7574 2c20  eter is (input, 
+00020fa0: 6474 7970 652c 206e 6f6e 5f62 6c6f 636b  dtype, non_block
+00020fb0: 696e 672c 2063 6f70 792c 206d 656d 6f72  ing, copy, memor
+00020fc0: 795f 666f 726d 6174 290a 2020 2020 2320  y_format).    # 
+00020fd0: 2d20 5768 656e 206c 656e 2869 6e70 7574  - When len(input
+00020fe0: 7329 203d 3d20 342c 2074 6865 2070 6172  s) == 4, the par
+00020ff0: 616d 6574 6572 2069 7320 2869 6e70 7574  ameter is (input
+00021000: 2c20 6474 7970 652c 206e 6f6e 5f62 6c6f  , dtype, non_blo
+00021010: 636b 696e 672c 2063 6f70 7929 0a20 2020  cking, copy).   
+00021020: 2023 202d 2057 6865 6e20 6c65 6e28 696e   # - When len(in
+00021030: 7075 7473 2920 3d3d 2033 2c20 7468 6520  puts) == 3, the 
+00021040: 7061 7261 6d65 7465 7220 6973 2028 696e  parameter is (in
+00021050: 7075 742c 206e 6f6e 5f62 6c6f 636b 696e  put, non_blockin
+00021060: 672c 2063 6f70 7929 0a20 2020 2023 2057  g, copy).    # W
+00021070: 6520 6f6e 6c79 2075 7365 2060 696e 7075  e only use `inpu
+00021080: 7460 2061 6e64 2060 6474 7970 6560 2c20  t` and `dtype`, 
+00021090: 616e 6420 606e 6f6e 5f62 6c6f 636b 696e  and `non_blockin
+000210a0: 6760 2061 6e64 2060 636f 7079 6020 6172  g` and `copy` ar
+000210b0: 6520 756e 7573 6564 2e0a 2020 2020 5f69  e unused..    _i
+000210c0: 6e70 7574 203d 2069 6e70 7574 735b 305d  nput = inputs[0]
+000210d0: 0a20 2020 2074 6172 6765 745f 6474 7970  .    target_dtyp
+000210e0: 653a 204f 7074 696f 6e61 6c5b 5661 725d  e: Optional[Var]
+000210f0: 0a20 2020 2069 6e70 7574 735f 6c65 6e20  .    inputs_len 
+00021100: 3d20 6c65 6e28 696e 7075 7473 290a 2020  = len(inputs).  
+00021110: 2020 6966 2069 6e70 7574 735f 6c65 6e20    if inputs_len 
+00021120: 696e 2028 342c 2035 2c20 372c 2038 293a  in (4, 5, 7, 8):
+00021130: 0a20 2020 2020 2020 2074 6172 6765 745f  .        target_
+00021140: 6474 7970 6520 3d20 696e 7075 7473 5b31  dtype = inputs[1
+00021150: 5d0a 2020 2020 656c 6966 2069 6e70 7574  ].    elif input
+00021160: 735f 6c65 6e20 3d3d 2036 3a0a 2020 2020  s_len == 6:.    
+00021170: 2020 2020 7461 7267 6574 5f64 7479 7065      target_dtype
+00021180: 203d 2069 6e70 7574 735b 325d 0a20 2020   = inputs[2].   
+00021190: 2065 6c69 6620 696e 7075 7473 5f6c 656e   elif inputs_len
+000211a0: 203d 3d20 333a 0a20 2020 2020 2020 2074   == 3:.        t
+000211b0: 6172 6765 745f 6474 7970 6520 3d20 4e6f  arget_dtype = No
+000211c0: 6e65 0a20 2020 2065 6c73 653a 0a20 2020  ne.    else:.   
+000211d0: 2020 2020 2072 6169 7365 2056 616c 7565       raise Value
+000211e0: 4572 726f 7228 0a20 2020 2020 2020 2020  Error(.         
+000211f0: 2020 2022 5265 6365 6976 6564 2069 6e76     "Received inv
+00021200: 616c 6964 2061 7267 756d 656e 7473 2066  alid arguments f
+00021210: 6f72 2050 7954 6f72 6368 2063 6f6e 7665  or PyTorch conve
+00021220: 7273 696f 6e20 6f66 206f 7020 7b7d 222e  rsion of op {}".
+00021230: 666f 726d 6174 286e 6f64 6529 0a20 2020  format(node).   
+00021240: 2020 2020 2029 0a0a 2020 2020 6966 2074       )..    if t
+00021250: 6172 6765 745f 6474 7970 6520 6973 204e  arget_dtype is N
+00021260: 6f6e 653a 0a20 2020 2020 2020 2023 2057  one:.        # W
+00021270: 6865 6e20 7461 7267 6574 5f64 7479 7065  hen target_dtype
+00021280: 2069 7320 4e6f 6e65 2c20 6974 206d 6561   is None, it mea
+00021290: 6e73 2074 6865 2069 6e70 7574 2773 2064  ns the input's d
+000212a0: 7479 7065 2069 7320 616c 7265 6164 7920  type is already 
+000212b0: 7468 6520 7461 7267 6574 2064 7479 7065  the target dtype
+000212c0: 2e0a 2020 2020 2020 2020 636f 6e74 6578  ..        contex
+000212d0: 742e 6164 6428 5f69 6e70 7574 2c20 746f  t.add(_input, to
+000212e0: 7263 685f 6e61 6d65 3d6e 6f64 652e 6e61  rch_name=node.na
+000212f0: 6d65 290a 2020 2020 2020 2020 7265 7475  me).        retu
+00021300: 726e 0a20 2020 2065 6c69 6620 7479 7065  rn.    elif type
+00021310: 732e 6973 5f73 6361 6c61 7228 7461 7267  s.is_scalar(targ
+00021320: 6574 5f64 7479 7065 2e73 796d 5f74 7970  et_dtype.sym_typ
+00021330: 6529 2061 6e64 2074 6172 6765 745f 6474  e) and target_dt
+00021340: 7970 652e 7661 6c20 6973 206e 6f74 204e  ype.val is not N
+00021350: 6f6e 653a 0a20 2020 2020 2020 2064 7479  one:.        dty
+00021360: 7065 203d 2074 6172 6765 745f 6474 7970  pe = target_dtyp
+00021370: 652e 7661 6c0a 2020 2020 656c 7365 3a0a  e.val.    else:.
+00021380: 2020 2020 2020 2020 2320 5768 656e 2074          # When t
+00021390: 6865 2076 616c 206f 6620 6474 7970 6520  he val of dtype 
+000213a0: 6973 206e 6f74 2061 7661 696c 6162 6c65  is not available
+000213b0: 2c20 6272 6964 6765 2066 726f 6d20 7468  , bridge from th
+000213c0: 6520 6e70 2064 7479 7065 2e0a 2020 2020  e np dtype..    
+000213d0: 2020 2020 6e70 5f74 7970 6520 3d20 6e70      np_type = np
+000213e0: 7479 7065 5f66 726f 6d5f 6275 696c 7469  type_from_builti
+000213f0: 6e28 7461 7267 6574 5f64 7479 7065 2e64  n(target_dtype.d
+00021400: 7479 7065 290a 2020 2020 2020 2020 6474  type).        dt
+00021410: 7970 6520 3d20 4e55 4d50 595f 4454 5950  ype = NUMPY_DTYP
+00021420: 455f 544f 5f54 4f52 4348 5f4e 554d 5b6e  E_TO_TORCH_NUM[n
+00021430: 705f 7479 7065 5d0a 0a20 2020 2074 6f72  p_type]..    tor
+00021440: 6368 5f64 7479 7065 203d 204e 554d 5f54  ch_dtype = NUM_T
+00021450: 4f5f 544f 5243 485f 4454 5950 455b 6474  O_TORCH_DTYPE[dt
+00021460: 7970 655d 0a20 2020 2069 6620 6973 696e  ype].    if isin
+00021470: 7374 616e 6365 285f 696e 7075 742c 2056  stance(_input, V
+00021480: 6172 2920 616e 6420 5f69 6e70 7574 2e63  ar) and _input.c
+00021490: 616e 5f62 655f 666f 6c64 6564 5f74 6f5f  an_be_folded_to_
+000214a0: 636f 6e73 7428 293a 0a20 2020 2020 2020  const():.       
+000214b0: 2023 206e 756d 7079 202d 3e20 746f 7263   # numpy -> torc
+000214c0: 6820 2d3e 2074 6f72 6368 2063 6173 7420  h -> torch cast 
+000214d0: 2d3e 206e 756d 7079 0a20 2020 2020 2020  -> numpy.       
+000214e0: 2023 2054 6869 7320 7061 7468 2069 7320   # This path is 
+000214f0: 6e65 6564 6564 2074 6f20 7573 6520 7468  needed to use th
+00021500: 6520 6d61 7070 696e 6720 6f66 2070 6173  e mapping of pas
+00021510: 7365 6420 696e 2064 7479 7065 7320 746f  sed in dtypes to
+00021520: 2074 6f72 6368 2064 7479 7065 732e 0a20   torch dtypes.. 
+00021530: 2020 2020 2020 2063 6173 7465 645f 696e         casted_in
+00021540: 7075 7420 3d20 746f 7263 682e 7465 6e73  put = torch.tens
+00021550: 6f72 285f 696e 7075 742e 7661 6c29 2e74  or(_input.val).t
+00021560: 7970 6528 746f 7263 685f 6474 7970 6529  ype(torch_dtype)
+00021570: 2e63 7075 2829 2e6e 756d 7079 2829 0a20  .cpu().numpy(). 
+00021580: 2020 2020 2020 2072 6573 203d 206d 622e         res = mb.
+00021590: 636f 6e73 7428 7661 6c3d 6361 7374 6564  const(val=casted
+000215a0: 5f69 6e70 7574 2c20 6e61 6d65 3d6e 6f64  _input, name=nod
+000215b0: 652e 6e61 6d65 290a 2020 2020 656c 7365  e.name).    else
+000215c0: 3a0a 2020 2020 2020 2020 6966 2064 7479  :.        if dty
+000215d0: 7065 2069 6e20 4e55 4d5f 544f 5f44 5459  pe in NUM_TO_DTY
+000215e0: 5045 5f53 5452 494e 473a 0a20 2020 2020  PE_STRING:.     
+000215f0: 2020 2020 2020 2072 6573 203d 206d 622e         res = mb.
+00021600: 6361 7374 2878 3d5f 696e 7075 742c 2064  cast(x=_input, d
+00021610: 7479 7065 3d4e 554d 5f54 4f5f 4454 5950  type=NUM_TO_DTYP
+00021620: 455f 5354 5249 4e47 5b64 7479 7065 5d2c  E_STRING[dtype],
+00021630: 206e 616d 653d 6e6f 6465 2e6e 616d 6529   name=node.name)
+00021640: 0a20 2020 2020 2020 2065 6c73 653a 0a20  .        else:. 
+00021650: 2020 2020 2020 2020 2020 2023 2046 6f72             # For
+00021660: 2064 7479 7065 2074 6861 7420 6973 206e   dtype that is n
+00021670: 6f74 2073 7570 706f 7274 6564 2062 7920  ot supported by 
+00021680: 6d62 2e63 6173 742c 2077 6520 646f 2069  mb.cast, we do i
+00021690: 7420 696e 2062 6573 742d 6566 666f 7274  t in best-effort
+000216a0: 2074 6f20 6361 7374 2069 7420 746f 2069   to cast it to i
+000216b0: 6e74 0a20 2020 2020 2020 2020 2020 2023  nt.            #
+000216c0: 206f 7220 666c 6f61 7420 6261 7365 6420   or float based 
+000216d0: 6f6e 2074 6865 2064 7479 7065 2e0a 2020  on the dtype..  
+000216e0: 2020 2020 2020 2020 2020 6e70 5f64 7479            np_dty
+000216f0: 7065 203d 204e 554d 5f54 4f5f 4e55 4d50  pe = NUM_TO_NUMP
+00021700: 595f 4454 5950 455b 6474 7970 655d 0a20  Y_DTYPE[dtype]. 
+00021710: 2020 2020 2020 2020 2020 2069 6620 5f6e             if _n
+00021720: 702e 6973 7375 6264 7479 7065 286e 705f  p.issubdtype(np_
+00021730: 6474 7970 652c 205f 6e70 2e69 6e74 6567  dtype, _np.integ
+00021740: 6572 293a 0a20 2020 2020 2020 2020 2020  er):.           
+00021750: 2020 2020 2072 6573 203d 206d 622e 6361       res = mb.ca
+00021760: 7374 2878 3d5f 696e 7075 742c 2064 7479  st(x=_input, dty
+00021770: 7065 3d22 696e 7433 3222 2c20 6e61 6d65  pe="int32", name
+00021780: 3d6e 6f64 652e 6e61 6d65 290a 2020 2020  =node.name).    
+00021790: 2020 2020 2020 2020 656c 6966 205f 6e70          elif _np
+000217a0: 2e69 7373 7562 6474 7970 6528 6e70 5f64  .issubdtype(np_d
+000217b0: 7479 7065 2c20 5f6e 702e 666c 6f61 7469  type, _np.floati
+000217c0: 6e67 293a 0a20 2020 2020 2020 2020 2020  ng):.           
+000217d0: 2020 2020 2072 6573 203d 206d 622e 6361       res = mb.ca
+000217e0: 7374 2878 3d5f 696e 7075 742c 2064 7479  st(x=_input, dty
+000217f0: 7065 3d22 6670 3332 222c 206e 616d 653d  pe="fp32", name=
+00021800: 6e6f 6465 2e6e 616d 6529 0a20 2020 2020  node.name).     
+00021810: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
+00021820: 2020 2020 2020 2020 2020 2020 2072 6169               rai
+00021830: 7365 2056 616c 7565 4572 726f 7228 6622  se ValueError(f"
+00021840: 556e 7375 7070 6f72 7465 6420 6f70 207b  Unsupported op {
+00021850: 6e6f 6465 7d20 7769 7468 2074 6172 6765  node} with targe
+00021860: 7420 6474 7970 6520 7b6e 705f 6474 7970  t dtype {np_dtyp
+00021870: 657d 2229 0a20 2020 2063 6f6e 7465 7874  e}").    context
+00021880: 2e61 6464 2872 6573 290a 0a0a 4072 6567  .add(res)...@reg
+00021890: 6973 7465 725f 746f 7263 685f 6f70 0a64  ister_torch_op.d
+000218a0: 6566 2065 7266 2863 6f6e 7465 7874 2c20  ef erf(context, 
+000218b0: 6e6f 6465 293a 0a20 2020 2069 6e70 7574  node):.    input
+000218c0: 7320 3d20 5f67 6574 5f69 6e70 7574 7328  s = _get_inputs(
+000218d0: 636f 6e74 6578 742c 206e 6f64 652c 2065  context, node, e
+000218e0: 7870 6563 7465 643d 3129 0a20 2020 205f  xpected=1).    _
+000218f0: 696e 7075 7420 3d20 696e 7075 7473 5b30  input = inputs[0
+00021900: 5d0a 2020 2020 6572 6620 3d20 6d62 2e65  ].    erf = mb.e
+00021910: 7266 2878 3d5f 696e 7075 742c 206e 616d  rf(x=_input, nam
+00021920: 653d 6e6f 6465 2e6e 616d 6529 0a20 2020  e=node.name).   
+00021930: 2063 6f6e 7465 7874 2e61 6464 2865 7266   context.add(erf
+00021940: 290a 0a0a 4072 6567 6973 7465 725f 746f  )...@register_to
+00021950: 7263 685f 6f70 2874 6f72 6368 5f61 6c69  rch_op(torch_ali
+00021960: 6173 3d5b 2273 6361 6c61 7269 6d70 6c69  as=["scalarimpli
+00021970: 6369 7422 5d29 0a64 6566 2069 6d70 6c69  cit"]).def impli
+00021980: 6369 7474 656e 736f 7274 6f6e 756d 2863  cittensortonum(c
+00021990: 6f6e 7465 7874 2c20 6e6f 6465 293a 0a20  ontext, node):. 
+000219a0: 2020 2069 6e70 7574 7320 3d20 5f67 6574     inputs = _get
+000219b0: 5f69 6e70 7574 7328 636f 6e74 6578 742c  _inputs(context,
+000219c0: 206e 6f64 652c 2065 7870 6563 7465 643d   node, expected=
+000219d0: 3129 0a20 2020 205f 696e 7075 7420 3d20  1).    _input = 
+000219e0: 696e 7075 7473 5b30 5d0a 0a20 2020 2069  inputs[0]..    i
+000219f0: 6620 5f69 6e70 7574 2e73 6861 7065 203d  f _input.shape =
+00021a00: 3d20 2829 3a20 2023 2061 6c72 6561 6479  = ():  # already
+00021a10: 2061 2073 6361 6c61 720a 2020 2020 2020   a scalar.      
+00021a20: 2020 636f 6e74 6578 742e 6164 6428 5f69    context.add(_i
+00021a30: 6e70 7574 2c20 6e6f 6465 2e6e 616d 6529  nput, node.name)
+00021a40: 0a20 2020 2065 6c73 653a 0a20 2020 2020  .    else:.     
+00021a50: 2020 2061 7373 6572 7420 5f69 6e70 7574     assert _input
+00021a60: 2e73 6861 7065 203d 3d20 2831 2c29 0a20  .shape == (1,). 
+00021a70: 2020 2020 2020 2023 2073 6861 7065 3a20         # shape: 
+00021a80: 2831 2c29 202d 3e20 2829 0a20 2020 2020  (1,) -> ().     
+00021a90: 2020 2073 7175 6565 7a65 203d 206d 622e     squeeze = mb.
+00021aa0: 7371 7565 657a 6528 783d 5f69 6e70 7574  squeeze(x=_input
+00021ab0: 2c20 6e61 6d65 3d6e 6f64 652e 6e61 6d65  , name=node.name
+00021ac0: 290a 2020 2020 2020 2020 636f 6e74 6578  ).        contex
+00021ad0: 742e 6164 6428 7371 7565 657a 6529 0a0a  t.add(squeeze)..
+00021ae0: 0a40 7265 6769 7374 6572 5f74 6f72 6368  .@register_torch
+00021af0: 5f6f 700a 6465 6620 636f 6e73 7461 6e74  _op.def constant
+00021b00: 6368 756e 6b28 636f 6e74 6578 742c 206e  chunk(context, n
+00021b10: 6f64 6529 3a0a 2020 2020 696e 7075 7473  ode):.    inputs
+00021b20: 203d 205f 6765 745f 696e 7075 7473 2863   = _get_inputs(c
+00021b30: 6f6e 7465 7874 2c20 6e6f 6465 2c20 6578  ontext, node, ex
+00021b40: 7065 6374 6564 3d31 290a 2020 2020 7820  pected=1).    x 
+00021b50: 3d20 696e 7075 7473 5b30 5d0a 2020 2020  = inputs[0].    
+00021b60: 2320 436f 6e73 7461 6e74 4368 756e 6b20  # ConstantChunk 
+00021b70: 6765 7473 2069 7473 2070 6172 616d 6574  gets its paramet
+00021b80: 6572 7320 6173 2061 7474 7269 6275 7465  ers as attribute
+00021b90: 7320 6f66 2074 6865 206e 6f64 652e 0a20  s of the node.. 
+00021ba0: 2020 2063 6875 6e6b 7320 3d20 6e6f 6465     chunks = node
+00021bb0: 2e61 7474 725b 2263 6875 6e6b 7322 5d0a  .attr["chunks"].
+00021bc0: 2020 2020 6469 6d20 3d20 6e6f 6465 2e61      dim = node.a
+00021bd0: 7474 725b 2264 696d 225d 0a0a 2020 2020  ttr["dim"]..    
+00021be0: 746f 7461 6c20 3d20 782e 7368 6170 655b  total = x.shape[
+00021bf0: 6469 6d5d 0a20 2020 2073 697a 6520 3d20  dim].    size = 
+00021c00: 696e 7428 5f6d 6174 682e 6365 696c 2866  int(_math.ceil(f
+00021c10: 6c6f 6174 2874 6f74 616c 2920 2f20 666c  loat(total) / fl
+00021c20: 6f61 7428 6368 756e 6b73 2929 290a 2020  oat(chunks))).  
+00021c30: 2020 7370 6c69 745f 7369 7a65 7320 3d20    split_sizes = 
+00021c40: 5b73 697a 655d 202a 2069 6e74 285f 6d61  [size] * int(_ma
+00021c50: 7468 2e66 6c6f 6f72 2874 6f74 616c 202f  th.floor(total /
+00021c60: 2073 697a 6529 290a 2020 2020 7265 6d61   size)).    rema
+00021c70: 696e 6465 7220 3d20 746f 7461 6c20 2d20  inder = total - 
+00021c80: 7375 6d28 7370 6c69 745f 7369 7a65 7329  sum(split_sizes)
+00021c90: 0a20 2020 2069 6620 7265 6d61 696e 6465  .    if remainde
+00021ca0: 7220 3e20 303a 0a20 2020 2020 2020 2073  r > 0:.        s
+00021cb0: 706c 6974 5f73 697a 6573 2e61 7070 656e  plit_sizes.appen
+00021cc0: 6428 7265 6d61 696e 6465 7229 0a0a 2020  d(remainder)..  
+00021cd0: 2020 7265 7320 3d20 6d62 2e73 706c 6974    res = mb.split
+00021ce0: 2878 3d78 2c20 7370 6c69 745f 7369 7a65  (x=x, split_size
+00021cf0: 733d 7370 6c69 745f 7369 7a65 732c 2061  s=split_sizes, a
+00021d00: 7869 733d 6469 6d2c 206e 616d 653d 6e6f  xis=dim, name=no
+00021d10: 6465 2e6e 616d 6529 0a20 2020 2066 6f72  de.name).    for
+00021d20: 2076 616c 2c20 6e61 6d65 2069 6e20 7a69   val, name in zi
+00021d30: 7028 7265 732c 206e 6f64 652e 6f75 7470  p(res, node.outp
+00021d40: 7574 7329 3a0a 2020 2020 2020 2020 636f  uts):.        co
+00021d50: 6e74 6578 742e 6164 6428 7661 6c2c 206e  ntext.add(val, n
+00021d60: 616d 6529 0a0a 0a64 6566 205f 6272 6f61  ame)...def _broa
+00021d70: 6463 6173 7428 6e61 6d65 2c20 7465 6e73  dcast(name, tens
+00021d80: 6f72 2c20 7368 6170 6529 3a0a 2020 2020  or, shape):.    
+00021d90: 6966 206c 656e 2873 6861 7065 2920 3e20  if len(shape) > 
+00021da0: 7465 6e73 6f72 2e72 616e 6b3a 0a20 2020  tensor.rank:.   
+00021db0: 2020 2020 206e 6577 5f64 696d 7320 3d20       new_dims = 
+00021dc0: 6c65 6e28 7368 6170 6529 202d 2074 656e  len(shape) - ten
+00021dd0: 736f 722e 7261 6e6b 0a20 2020 2020 2020  sor.rank.       
+00021de0: 2074 656e 736f 7220 3d20 6d62 2e65 7870   tensor = mb.exp
+00021df0: 616e 645f 6469 6d73 2878 3d74 656e 736f  and_dims(x=tenso
+00021e00: 722c 2061 7865 733d 6c69 7374 2872 616e  r, axes=list(ran
+00021e10: 6765 286e 6577 5f64 696d 7329 2929 0a0a  ge(new_dims)))..
+00021e20: 2020 2020 7265 7073 203d 205b 5d0a 2020      reps = [].  
+00021e30: 2020 666f 7220 7473 2c20 6473 2069 6e20    for ts, ds in 
+00021e40: 7a69 7028 7465 6e73 6f72 2e73 6861 7065  zip(tensor.shape
+00021e50: 2c20 7368 6170 6529 3a0a 2020 2020 2020  , shape):.      
+00021e60: 2020 6966 206e 6f74 2069 735f 7379 6d62    if not is_symb
+00021e70: 6f6c 6963 2874 7329 2061 6e64 206e 6f74  olic(ts) and not
+00021e80: 2069 735f 7379 6d62 6f6c 6963 2864 7329   is_symbolic(ds)
+00021e90: 2061 6e64 2064 7320 3e20 3020 616e 6420   and ds > 0 and 
+00021ea0: 7473 203d 3d20 313a 0a20 2020 2020 2020  ts == 1:.       
+00021eb0: 2020 2020 2072 6570 732e 6170 7065 6e64       reps.append
+00021ec0: 2864 7329 0a20 2020 2020 2020 2065 6c73  (ds).        els
+00021ed0: 653a 0a20 2020 2020 2020 2020 2020 2072  e:.            r
+00021ee0: 6570 732e 6170 7065 6e64 2831 290a 0a20  eps.append(1).. 
+00021ef0: 2020 2072 6573 203d 206d 622e 7469 6c65     res = mb.tile
+00021f00: 2878 3d74 656e 736f 722c 2072 6570 733d  (x=tensor, reps=
+00021f10: 7265 7073 2c20 6e61 6d65 3d6e 616d 6529  reps, name=name)
+00021f20: 0a20 2020 2072 6574 7572 6e20 7265 730a  .    return res.
+00021f30: 0a0a 4072 6567 6973 7465 725f 746f 7263  ..@register_torc
+00021f40: 685f 6f70 0a64 6566 2065 7870 616e 6428  h_op.def expand(
+00021f50: 636f 6e74 6578 742c 206e 6f64 6529 3a0a  context, node):.
+00021f60: 2020 2020 6465 6620 5f62 726f 6164 6361      def _broadca
+00021f70: 7374 5f64 796e 616d 6963 286e 616d 652c  st_dynamic(name,
+00021f80: 2074 656e 736f 722c 2073 6861 7065 293a   tensor, shape):
+00021f90: 0a20 2020 2020 2020 2023 2041 6464 2061  .        # Add a
+00021fa0: 6e79 2065 7874 7261 2064 696d 656e 7369  ny extra dimensi
+00021fb0: 6f6e 730a 2020 2020 2020 2020 6966 206c  ons.        if l
+00021fc0: 656e 2873 6861 7065 2920 3e20 7465 6e73  en(shape) > tens
+00021fd0: 6f72 2e72 616e 6b3a 0a20 2020 2020 2020  or.rank:.       
+00021fe0: 2020 2020 206e 6577 5f64 696d 7320 3d20       new_dims = 
+00021ff0: 6c65 6e28 7368 6170 6529 202d 2074 656e  len(shape) - ten
+00022000: 736f 722e 7261 6e6b 0a20 2020 2020 2020  sor.rank.       
+00022010: 2020 2020 2074 656e 736f 7220 3d20 6d62       tensor = mb
+00022020: 2e65 7870 616e 645f 6469 6d73 2878 3d74  .expand_dims(x=t
+00022030: 656e 736f 722c 2061 7865 733d 6c69 7374  ensor, axes=list
+00022040: 2872 616e 6765 286e 6577 5f64 696d 7329  (range(new_dims)
+00022050: 2929 0a0a 2020 2020 2020 2020 7465 6e73  ))..        tens
+00022060: 6f72 5f73 6861 7065 203d 206d 622e 7368  or_shape = mb.sh
+00022070: 6170 6528 783d 7465 6e73 6f72 290a 2020  ape(x=tensor).  
+00022080: 2020 2020 2020 7368 6170 6520 3d20 6d62        shape = mb
+00022090: 2e63 6f6e 6361 7428 7661 6c75 6573 3d73  .concat(values=s
+000220a0: 6861 7065 2c20 6178 6973 3d30 290a 2020  hape, axis=0).  
+000220b0: 2020 2020 2020 7265 7073 203d 206d 622e        reps = mb.
+000220c0: 7265 616c 5f64 6976 2878 3d73 6861 7065  real_div(x=shape
+000220d0: 2c20 793d 7465 6e73 6f72 5f73 6861 7065  , y=tensor_shape
+000220e0: 290a 2020 2020 2020 2020 7265 7073 203d  ).        reps =
+000220f0: 206d 622e 6361 7374 2878 3d72 6570 732c   mb.cast(x=reps,
+00022100: 2064 7479 7065 3d22 696e 7433 3222 290a   dtype="int32").
+00022110: 2020 2020 2020 2020 7265 7320 3d20 6d62          res = mb
+00022120: 2e74 696c 6528 783d 7465 6e73 6f72 2c20  .tile(x=tensor, 
+00022130: 7265 7073 3d72 6570 732c 206e 616d 653d  reps=reps, name=
+00022140: 6e61 6d65 290a 2020 2020 2020 2020 7265  name).        re
+00022150: 7475 726e 2072 6573 0a0a 0a20 2020 2023  turn res...    #
+00022160: 2050 7954 6f72 6368 2031 2e36 2b20 6861   PyTorch 1.6+ ha
+00022170: 7320 3320 696e 7075 7473 2077 6869 6c65  s 3 inputs while
+00022180: 206f 6c64 6572 2076 6572 7369 6f6e 2068   older version h
+00022190: 6173 2032 0a20 2020 2069 6e70 7574 7320  as 2.    inputs 
+000221a0: 3d20 5f67 6574 5f69 6e70 7574 7328 636f  = _get_inputs(co
+000221b0: 6e74 6578 742c 206e 6f64 652c 2065 7870  ntext, node, exp
+000221c0: 6563 7465 643d 5b32 2c20 335d 290a 0a20  ected=[2, 3]).. 
+000221d0: 2020 2078 203d 2069 6e70 7574 735b 305d     x = inputs[0]
+000221e0: 0a20 2020 2073 6861 7065 203d 2069 6e70  .    shape = inp
+000221f0: 7574 735b 315d 0a0a 2020 2020 6966 2069  uts[1]..    if i
+00022200: 7369 6e73 7461 6e63 6528 7368 6170 652c  sinstance(shape,
+00022210: 206c 6973 7429 3a0a 2020 2020 2020 2020   list):.        
+00022220: 7265 7320 3d20 5f62 726f 6164 6361 7374  res = _broadcast
+00022230: 5f64 796e 616d 6963 286e 6f64 652e 6e61  _dynamic(node.na
+00022240: 6d65 2c20 782c 2073 6861 7065 290a 2020  me, x, shape).  
+00022250: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
+00022260: 7265 7320 3d20 5f62 726f 6164 6361 7374  res = _broadcast
+00022270: 286e 6f64 652e 6e61 6d65 2c20 782c 2073  (node.name, x, s
+00022280: 6861 7065 2e76 616c 290a 2020 2020 636f  hape.val).    co
+00022290: 6e74 6578 742e 6164 6428 7265 7329 0a0a  ntext.add(res)..
+000222a0: 0a40 7265 6769 7374 6572 5f74 6f72 6368  .@register_torch
+000222b0: 5f6f 700a 6465 6620 6578 7061 6e64 5f61  _op.def expand_a
+000222c0: 7328 636f 6e74 6578 742c 206e 6f64 6529  s(context, node)
+000222d0: 3a0a 2020 2020 2320 5079 546f 7263 6820  :.    # PyTorch 
+000222e0: 312e 362b 2068 6173 2033 2069 6e70 7574  1.6+ has 3 input
+000222f0: 7320 7768 696c 6520 6f6c 6465 7220 7665  s while older ve
+00022300: 7273 696f 6e20 6861 7320 320a 2020 2020  rsion has 2.    
+00022310: 696e 7075 7473 203d 205f 6765 745f 696e  inputs = _get_in
+00022320: 7075 7473 2863 6f6e 7465 7874 2c20 6e6f  puts(context, no
+00022330: 6465 2c20 6578 7065 6374 6564 3d5b 322c  de, expected=[2,
+00022340: 2033 5d29 0a20 2020 2078 203d 2069 6e70   3]).    x = inp
+00022350: 7574 735b 305d 0a20 2020 206f 7468 6572  uts[0].    other
+00022360: 203d 2069 6e70 7574 735b 315d 0a0a 2020   = inputs[1]..  
+00022370: 2020 7265 7320 3d20 5f62 726f 6164 6361    res = _broadca
+00022380: 7374 286e 6f64 652e 6e61 6d65 2c20 782c  st(node.name, x,
+00022390: 206f 7468 6572 2e73 6861 7065 290a 2020   other.shape).  
+000223a0: 2020 636f 6e74 6578 742e 6164 6428 7265    context.add(re
+000223b0: 7329 0a0a 0a40 7265 6769 7374 6572 5f74  s)...@register_t
+000223c0: 6f72 6368 5f6f 700a 6465 6620 6172 616e  orch_op.def aran
+000223d0: 6765 2863 6f6e 7465 7874 2c20 6e6f 6465  ge(context, node
+000223e0: 293a 0a20 2020 2069 6e70 7574 7320 3d20  ):.    inputs = 
+000223f0: 5f67 6574 5f69 6e70 7574 7328 636f 6e74  _get_inputs(cont
+00022400: 6578 742c 206e 6f64 6529 0a20 2020 2023  ext, node).    #
+00022410: 2064 7479 7065 203d 2069 6e70 7574 735b   dtype = inputs[
+00022420: 2d34 5d0a 2020 2020 2320 6c61 796f 7574  -4].    # layout
+00022430: 203d 2069 6e70 7574 735b 2d33 5d0a 2020   = inputs[-3].  
+00022440: 2020 2320 6465 7669 6365 203d 2069 6e70    # device = inp
+00022450: 7574 735b 2d32 5d0a 2020 2020 2320 7069  uts[-2].    # pi
+00022460: 6e5f 6d65 6d6f 7279 203d 2069 6e70 7574  n_memory = input
+00022470: 735b 2d31 5d0a 2020 2020 6966 206c 656e  s[-1].    if len
+00022480: 2869 6e70 7574 7329 203d 3d20 353a 0a20  (inputs) == 5:. 
+00022490: 2020 2020 2020 2023 2069 6e70 7574 7320         # inputs 
+000224a0: 6172 6520 5b65 6e64 2c20 6474 7970 652c  are [end, dtype,
+000224b0: 206c 6179 6f75 742c 2064 6576 6963 652c   layout, device,
+000224c0: 2070 696e 5f6d 656d 6f72 795d 0a20 2020   pin_memory].   
+000224d0: 2020 2020 2073 7461 7274 203d 2030 0a20       start = 0. 
+000224e0: 2020 2020 2020 2065 6e64 203d 2069 6e70         end = inp
+000224f0: 7574 735b 305d 0a20 2020 2020 2020 2073  uts[0].        s
+00022500: 7465 7020 3d20 310a 2020 2020 656c 6966  tep = 1.    elif
+00022510: 206c 656e 2869 6e70 7574 7329 203d 3d20   len(inputs) == 
+00022520: 363a 0a20 2020 2020 2020 2023 2069 6e70  6:.        # inp
+00022530: 7574 7320 6172 6520 5b73 7461 7274 2c20  uts are [start, 
+00022540: 656e 642c 2064 7479 7065 2c20 6c61 796f  end, dtype, layo
+00022550: 7574 2c20 6465 7669 6365 2c20 7069 6e5f  ut, device, pin_
+00022560: 6d65 6d6f 7279 5d0a 2020 2020 2020 2020  memory].        
+00022570: 7374 6172 7420 3d20 696e 7075 7473 5b30  start = inputs[0
+00022580: 5d0a 2020 2020 2020 2020 656e 6420 3d20  ].        end = 
+00022590: 696e 7075 7473 5b31 5d0a 2020 2020 2020  inputs[1].      
+000225a0: 2020 7374 6570 203d 2031 0a20 2020 2065    step = 1.    e
+000225b0: 6c69 6620 6c65 6e28 696e 7075 7473 2920  lif len(inputs) 
+000225c0: 3d3d 2037 3a0a 2020 2020 2020 2020 2320  == 7:.        # 
+000225d0: 696e 7075 7473 2061 7265 205b 7374 6172  inputs are [star
+000225e0: 742c 2065 6e64 2c20 7374 6570 2c20 6474  t, end, step, dt
+000225f0: 7970 652c 206c 6179 6f75 742c 2064 6576  ype, layout, dev
+00022600: 6963 652c 2070 696e 5f6d 656d 6f72 795d  ice, pin_memory]
+00022610: 0a20 2020 2020 2020 2073 7461 7274 203d  .        start =
+00022620: 2069 6e70 7574 735b 305d 0a20 2020 2020   inputs[0].     
+00022630: 2020 2065 6e64 203d 2069 6e70 7574 735b     end = inputs[
+00022640: 315d 0a20 2020 2020 2020 2073 7465 7020  1].        step 
+00022650: 3d20 696e 7075 7473 5b32 5d0a 2020 2020  = inputs[2].    
+00022660: 656c 7365 3a0a 2020 2020 2020 2020 7261  else:.        ra
+00022670: 6973 6520 5661 6c75 6545 7272 6f72 280a  ise ValueError(.
+00022680: 2020 2020 2020 2020 2020 2020 2261 7261              "ara
+00022690: 6e67 6520 6d75 7374 2068 6176 6520 6578  nge must have ex
+000226a0: 6163 746c 7920 352c 2036 2c20 6f72 2037  actly 5, 6, or 7
+000226b0: 2069 6e70 7574 732c 2067 6f74 207b 7d22   inputs, got {}"
+000226c0: 2e66 6f72 6d61 7428 6c65 6e28 696e 7075  .format(len(inpu
+000226d0: 7473 2929 0a20 2020 2020 2020 2029 0a20  ts)).        ). 
+000226e0: 2020 2023 2049 6620 7374 6172 742c 2065     # If start, e
+000226f0: 6e64 2c20 616e 6420 7374 6570 2064 6f6e  nd, and step don
+00022700: 2774 2068 6176 6520 7468 6520 7361 6d65  't have the same
+00022710: 2064 7479 7065 2c20 7765 2063 6173 7420   dtype, we cast 
+00022720: 7468 656d 2074 6f20 6670 3332 0a20 2020  them to fp32.   
+00022730: 2069 6e74 5f73 7461 7274 203d 2069 7369   int_start = isi
+00022740: 6e73 7461 6e63 6528 7374 6172 742c 2069  nstance(start, i
+00022750: 6e74 2920 6f72 2074 7970 6573 2e69 735f  nt) or types.is_
+00022760: 696e 7428 7374 6172 742e 6474 7970 6529  int(start.dtype)
+00022770: 0a20 2020 2069 6e74 5f65 6e64 203d 2069  .    int_end = i
+00022780: 7369 6e73 7461 6e63 6528 656e 642c 2069  sinstance(end, i
+00022790: 6e74 2920 6f72 2074 7970 6573 2e69 735f  nt) or types.is_
+000227a0: 696e 7428 656e 642e 6474 7970 6529 0a20  int(end.dtype). 
+000227b0: 2020 2069 6e74 5f73 7465 7020 3d20 6973     int_step = is
+000227c0: 696e 7374 616e 6365 2873 7465 702c 2069  instance(step, i
+000227d0: 6e74 2920 6f72 2074 7970 6573 2e69 735f  nt) or types.is_
+000227e0: 696e 7428 7374 6570 2e64 7479 7065 290a  int(step.dtype).
+000227f0: 0a20 2020 2069 6620 696e 745f 7374 6172  .    if int_star
+00022800: 7420 213d 2069 6e74 5f65 6e64 206f 7220  t != int_end or 
+00022810: 696e 745f 7374 6172 7420 213d 2069 6e74  int_start != int
+00022820: 5f73 7465 703a 0a20 2020 2020 2020 2073  _step:.        s
+00022830: 7461 7274 203d 206d 622e 6361 7374 2878  tart = mb.cast(x
+00022840: 3d73 7461 7274 2c20 6474 7970 653d 2266  =start, dtype="f
+00022850: 7033 3222 290a 2020 2020 2020 2020 656e  p32").        en
+00022860: 6420 3d20 6d62 2e63 6173 7428 783d 656e  d = mb.cast(x=en
+00022870: 642c 2064 7479 7065 3d22 6670 3332 2229  d, dtype="fp32")
+00022880: 0a20 2020 2020 2020 2073 7465 7020 3d20  .        step = 
+00022890: 6d62 2e63 6173 7428 783d 7374 6570 2c20  mb.cast(x=step, 
+000228a0: 6474 7970 653d 2266 7033 3222 290a 2020  dtype="fp32").  
+000228b0: 2020 7265 7320 3d20 6d62 2e72 616e 6765    res = mb.range
+000228c0: 5f31 6428 7374 6172 743d 7374 6172 742c  _1d(start=start,
+000228d0: 2065 6e64 3d65 6e64 2c20 7374 6570 3d73   end=end, step=s
+000228e0: 7465 702c 206e 616d 653d 6e6f 6465 2e6e  tep, name=node.n
+000228f0: 616d 6529 0a20 2020 2063 6f6e 7465 7874  ame).    context
+00022900: 2e61 6464 2872 6573 290a 0a0a 4072 6567  .add(res)...@reg
+00022910: 6973 7465 725f 746f 7263 685f 6f70 0a64  ister_torch_op.d
+00022920: 6566 206d 6173 6b65 645f 6669 6c6c 2863  ef masked_fill(c
+00022930: 6f6e 7465 7874 2c20 6e6f 6465 293a 0a20  ontext, node):. 
+00022940: 2020 2069 6e70 7574 7320 3d20 5f67 6574     inputs = _get
+00022950: 5f69 6e70 7574 7328 636f 6e74 6578 742c  _inputs(context,
+00022960: 206e 6f64 652c 2065 7870 6563 7465 643d   node, expected=
+00022970: 3329 0a20 2020 2078 203d 2069 6e70 7574  3).    x = input
+00022980: 735b 305d 0a20 2020 206d 6173 6b20 3d20  s[0].    mask = 
+00022990: 696e 7075 7473 5b31 5d0a 2020 2020 7661  inputs[1].    va
+000229a0: 6c75 6520 3d20 696e 7075 7473 5b32 5d0a  lue = inputs[2].
+000229b0: 0a20 2020 2069 6620 6e6f 7420 7479 7065  .    if not type
+000229c0: 732e 6973 5f62 6f6f 6c28 6d61 736b 2e64  s.is_bool(mask.d
+000229d0: 7479 7065 293a 0a20 2020 2020 2020 2023  type):.        #
+000229e0: 2063 6f6e 6420 6d75 7374 2062 6520 626f   cond must be bo
+000229f0: 6f6c 2074 7970 650a 2020 2020 2020 2020  ol type.        
+00022a00: 6d61 736b 203d 206d 622e 6361 7374 2878  mask = mb.cast(x
+00022a10: 3d6d 6173 6b2c 2064 7479 7065 3d22 626f  =mask, dtype="bo
+00022a20: 6f6c 2229 0a0a 2020 2020 7265 7320 3d20  ol")..    res = 
+00022a30: 6d62 2e73 656c 6563 7428 636f 6e64 3d6d  mb.select(cond=m
+00022a40: 6173 6b2c 2061 3d76 616c 7565 2c20 623d  ask, a=value, b=
+00022a50: 782c 206e 616d 653d 6e6f 6465 2e6e 616d  x, name=node.nam
+00022a60: 6529 0a20 2020 2063 6f6e 7465 7874 2e61  e).    context.a
+00022a70: 6464 2872 6573 290a 0a0a 4072 6567 6973  dd(res)...@regis
+00022a80: 7465 725f 746f 7263 685f 6f70 0a64 6566  ter_torch_op.def
+00022a90: 206d 6573 6867 7269 6428 636f 6e74 6578   meshgrid(contex
+00022aa0: 742c 206e 6f64 6529 3a0a 2020 2020 2222  t, node):.    ""
+00022ab0: 220a 2020 2020 466f 7220 4e20 696e 7075  ".    For N inpu
+00022ac0: 7420 7465 6e73 6f72 732c 2061 206d 6573  t tensors, a mes
+00022ad0: 6867 7269 6420 6973 2063 6f6e 7374 7275  hgrid is constru
+00022ae0: 6374 6564 2062 7920 7669 6577 696e 6720  cted by viewing 
+00022af0: 6561 6368 2074 656e 736f 7220 6173 2061  each tensor as a
+00022b00: 6e20 4e2d 6469 6d65 6e73 696f 6e20 7465  n N-dimension te
+00022b10: 6e73 6f72 0a20 2020 2077 6974 6820 7661  nsor.    with va
+00022b20: 6c75 6573 2069 6e20 7468 6520 6469 6d65  lues in the dime
+00022b30: 6e73 696f 6e20 636f 7272 6573 706f 6e64  nsion correspond
+00022b40: 696e 6720 6974 2069 7473 206f 7264 6572  ing it its order
+00022b50: 2069 6e20 7468 6520 6172 6773 2e20 2861   in the args. (a
+00022b60: 2e29 0a20 2020 2054 6865 6e2c 2069 7420  .).    Then, it 
+00022b70: 6973 2065 7870 616e 6465 6420 616c 6f6e  is expanded alon
+00022b80: 6720 6469 6d65 6e73 696f 6e73 2063 6f72  g dimensions cor
+00022b90: 7265 7370 6f6e 6469 6e67 2074 6f20 7468  responding to th
+00022ba0: 6520 6469 6d65 6e73 696f 6e73 206f 6620  e dimensions of 
+00022bb0: 6561 6368 0a20 2020 2031 6420 7465 6e73  each.    1d tens
+00022bc0: 6f72 2069 6e20 7468 6520 6f72 6465 7220  or in the order 
+00022bd0: 7468 6174 2074 6865 7920 7765 7265 2070  that they were p
+00022be0: 6173 7365 6420 696e 2e20 2862 2e29 0a0a  assed in. (b.)..
+00022bf0: 2020 2020 4561 6368 206f 7574 7075 7420      Each output 
+00022c00: 7465 6e73 6f72 2069 7320 7075 7420 696e  tensor is put in
+00022c10: 746f 2061 2074 7570 6c65 2074 6861 7420  to a tuple that 
+00022c20: 6973 2072 6574 7572 6e65 642e 2054 6865  is returned. The
+00022c30: 7365 2074 7570 6c65 7320 666f 726d 0a20  se tuples form. 
+00022c40: 2020 204e 2c20 4e2d 6469 6d65 6e69 6f6e     N, N-dimenion
+00022c50: 616c 2067 7269 6473 2c20 7768 6572 6520  al grids, where 
+00022c60: 7468 6520 6974 6820 6772 6964 2069 7320  the ith grid is 
+00022c70: 6465 6669 6e65 6420 6173 2065 7870 616e  defined as expan
+00022c80: 6469 6e67 2074 6865 2069 7468 2069 6e70  ding the ith inp
+00022c90: 7574 206f 7665 720a 2020 2020 6469 6d65  ut over.    dime
+00022ca0: 6e73 696f 6e73 2064 6566 696e 6564 2062  nsions defined b
+00022cb0: 7920 7468 6520 6f74 6865 7220 696e 7075  y the other inpu
+00022cc0: 7473 2e0a 2020 2020 2222 220a 2020 2020  ts..    """.    
+00022cd0: 7375 7070 6f72 7465 645f 696e 6465 7869  supported_indexi
+00022ce0: 6e67 5f6d 6f64 6573 203d 2028 2269 6a22  ng_modes = ("ij"
+00022cf0: 2c20 2278 7922 290a 2020 2020 696e 6465  , "xy").    inde
+00022d00: 7869 6e67 203d 2022 696a 220a 2020 2020  xing = "ij".    
+00022d10: 696e 7075 7473 203d 205f 6765 745f 696e  inputs = _get_in
+00022d20: 7075 7473 2863 6f6e 7465 7874 2c20 6e6f  puts(context, no
+00022d30: 6465 2c20 6578 7065 6374 6564 3d5b 312c  de, expected=[1,
+00022d40: 2032 5d29 0a0a 2020 2020 6966 206c 656e   2])..    if len
+00022d50: 2869 6e70 7574 7329 203d 3d20 323a 0a20  (inputs) == 2:. 
+00022d60: 2020 2020 2020 2069 6e64 6578 696e 6720         indexing 
+00022d70: 3d20 696e 7075 7473 5b31 5d2e 7661 6c0a  = inputs[1].val.
+00022d80: 2020 2020 2020 2020 6966 2069 6e64 6578          if index
+00022d90: 696e 6720 6e6f 7420 696e 2073 7570 706f  ing not in suppo
+00022da0: 7274 6564 5f69 6e64 6578 696e 675f 6d6f  rted_indexing_mo
+00022db0: 6465 733a 0a20 2020 2020 2020 2020 2020  des:.           
+00022dc0: 2072 6169 7365 2056 616c 7565 4572 726f   raise ValueErro
+00022dd0: 7228 2269 6e64 6578 696e 6720 6d6f 6465  r("indexing mode
+00022de0: 207b 7d20 6e6f 7420 7375 7070 6f72 7465   {} not supporte
+00022df0: 6422 2e66 6f72 6d61 7428 696e 6465 7869  d".format(indexi
+00022e00: 6e67 2929 0a0a 2020 2020 7465 6e73 6f72  ng))..    tensor
+00022e10: 5f69 6e70 7574 7320 3d20 696e 7075 7473  _inputs = inputs
+00022e20: 5b30 5d0a 2020 2020 6173 7365 7274 2069  [0].    assert i
+00022e30: 7369 6e73 7461 6e63 6528 7465 6e73 6f72  sinstance(tensor
+00022e40: 5f69 6e70 7574 732c 2028 6c69 7374 2c20  _inputs, (list, 
+00022e50: 7475 706c 6529 290a 2020 2020 6966 206c  tuple)).    if l
+00022e60: 656e 2874 656e 736f 725f 696e 7075 7473  en(tensor_inputs
+00022e70: 2920 3c20 323a 0a20 2020 2020 2020 2072  ) < 2:.        r
+00022e80: 6169 7365 2056 616c 7565 4572 726f 7228  aise ValueError(
+00022e90: 2252 6571 7569 7265 7320 3e3d 2032 2074  "Requires >= 2 t
+00022ea0: 656e 736f 7220 696e 7075 7473 2e22 290a  ensor inputs.").
+00022eb0: 0a20 2020 2069 6620 616e 7928 5b6c 656e  .    if any([len
+00022ec0: 2874 656e 736f 725f 7661 722e 7368 6170  (tensor_var.shap
+00022ed0: 6529 203e 2031 2066 6f72 2074 656e 736f  e) > 1 for tenso
+00022ee0: 725f 7661 7220 696e 2074 656e 736f 725f  r_var in tensor_
+00022ef0: 696e 7075 7473 5d29 3a0a 2020 2020 2020  inputs]):.      
+00022f00: 2020 7261 6973 6520 5661 6c75 6545 7272    raise ValueErr
+00022f10: 6f72 2822 6d65 7368 6772 6964 2072 6563  or("meshgrid rec
+00022f20: 6965 7665 6420 6e6f 6e2d 3164 2074 656e  ieved non-1d ten
+00022f30: 736f 722e 2229 0a0a 2020 2020 6469 6d5f  sor.")..    dim_
+00022f40: 7475 706c 6520 3d20 7475 706c 6528 7465  tuple = tuple(te
+00022f50: 6e73 6f72 5f76 6172 2e73 6861 7065 5b30  nsor_var.shape[0
+00022f60: 5d20 666f 7220 7465 6e73 6f72 5f76 6172  ] for tensor_var
+00022f70: 2069 6e20 7465 6e73 6f72 5f69 6e70 7574   in tensor_input
+00022f80: 7329 0a0a 2020 2020 6772 6964 7320 3d20  s)..    grids = 
+00022f90: 5b5d 0a20 2020 2073 697a 6520 3d20 6c65  [].    size = le
+00022fa0: 6e28 7465 6e73 6f72 5f69 6e70 7574 7329  n(tensor_inputs)
+00022fb0: 0a20 2020 2066 6f72 2069 2069 6e20 7261  .    for i in ra
+00022fc0: 6e67 6528 7369 7a65 293a 0a20 2020 2020  nge(size):.     
+00022fd0: 2020 2076 6965 775f 7368 6170 6520 3d20     view_shape = 
+00022fe0: 5b31 5d20 2a20 7369 7a65 0a20 2020 2020  [1] * size.     
+00022ff0: 2020 2076 6965 775f 7368 6170 655b 695d     view_shape[i]
+00023000: 203d 202d 310a 2020 2020 2020 2020 7669   = -1.        vi
+00023010: 6577 5f73 6861 7065 203d 2074 7570 6c65  ew_shape = tuple
+00023020: 2876 6965 775f 7368 6170 6529 0a20 2020  (view_shape).   
+00023030: 2020 2020 2023 2028 612e 2920 696e 2064       # (a.) in d
+00023040: 6f63 7374 7269 6e67 0a20 2020 2020 2020  ocstring.       
+00023050: 2076 6965 7720 3d20 6d62 2e72 6573 6861   view = mb.resha
+00023060: 7065 280a 2020 2020 2020 2020 2020 2020  pe(.            
+00023070: 783d 7465 6e73 6f72 5f69 6e70 7574 735b  x=tensor_inputs[
+00023080: 695d 2c20 7368 6170 653d 7669 6577 5f73  i], shape=view_s
+00023090: 6861 7065 2c20 6e61 6d65 3d6e 6f64 652e  hape, name=node.
+000230a0: 6e61 6d65 202b 2022 5f76 6965 775f 2220  name + "_view_" 
+000230b0: 2b20 7374 7228 6929 0a20 2020 2020 2020  + str(i).       
+000230c0: 2029 0a0a 2020 2020 2020 2020 2320 2862   )..        # (b
+000230d0: 2e29 2069 6e20 646f 6373 7472 696e 670a  .) in docstring.
+000230e0: 2020 2020 2020 2020 7265 7073 203d 205b          reps = [
+000230f0: 0a20 2020 2020 2020 2020 2020 2064 7320  .            ds 
+00023100: 6966 2064 7320 3e20 3020 616e 6420 7473  if ds > 0 and ts
+00023110: 203d 3d20 3120 656c 7365 2031 2066 6f72   == 1 else 1 for
+00023120: 2074 732c 2064 7320 696e 207a 6970 2876   ts, ds in zip(v
+00023130: 6965 772e 7368 6170 652c 2064 696d 5f74  iew.shape, dim_t
+00023140: 7570 6c65 290a 2020 2020 2020 2020 5d0a  uple).        ].
+00023150: 2020 2020 2020 2020 7265 7320 3d20 6d62          res = mb
+00023160: 2e74 696c 6528 783d 7669 6577 2c20 7265  .tile(x=view, re
+00023170: 7073 3d72 6570 732c 206e 616d 653d 6e6f  ps=reps, name=no
+00023180: 6465 2e6e 616d 6520 2b20 225f 6578 7061  de.name + "_expa
+00023190: 6e64 5f22 202b 2073 7472 2869 2929 0a0a  nd_" + str(i))..
+000231a0: 2020 2020 2020 2020 2320 7472 616e 7370          # transp
+000231b0: 6f73 6520 7468 6520 6669 7273 7420 7477  ose the first tw
+000231c0: 6f20 6469 6d65 6e73 696f 6e73 2066 6f72  o dimensions for
+000231d0: 2022 7879 2220 696e 6465 7869 6e67 0a20   "xy" indexing. 
+000231e0: 2020 2020 2020 2069 6620 696e 6465 7869         if indexi
+000231f0: 6e67 203d 3d20 2278 7922 3a0a 2020 2020  ng == "xy":.    
+00023200: 2020 2020 2020 2020 7065 726d 203d 205b          perm = [
+00023210: 312c 2030 5d20 2b20 6c69 7374 2872 616e  1, 0] + list(ran
+00023220: 6765 2832 2c20 7369 7a65 2929 0a20 2020  ge(2, size)).   
+00023230: 2020 2020 2020 2020 2072 6573 203d 206d           res = m
+00023240: 622e 7472 616e 7370 6f73 6528 783d 7265  b.transpose(x=re
+00023250: 732c 2070 6572 6d3d 7065 726d 2c20 6e61  s, perm=perm, na
+00023260: 6d65 3d6e 6f64 652e 6e61 6d65 202b 2022  me=node.name + "
+00023270: 5f74 7261 6e73 706f 7365 5f22 202b 2073  _transpose_" + s
+00023280: 7472 2869 2929 0a0a 2020 2020 2020 2020  tr(i))..        
+00023290: 6772 6964 732e 6170 7065 6e64 2872 6573  grids.append(res
+000232a0: 290a 0a20 2020 2063 6f6e 7465 7874 2e61  )..    context.a
+000232b0: 6464 2874 7570 6c65 2867 7269 6473 292c  dd(tuple(grids),
+000232c0: 206e 6f64 652e 6e61 6d65 290a 0a0a 2320   node.name)...# 
+000232d0: 4465 6669 6e65 7320 616c 6c20 7468 6520  Defines all the 
+000232e0: 6e6f 6465 7320 7468 6174 2061 7265 206e  nodes that are n
+000232f0: 6f4f 7073 0a40 7265 6769 7374 6572 5f74  oOps.@register_t
+00023300: 6f72 6368 5f6f 7028 0a20 2020 2074 6f72  orch_op(.    tor
+00023310: 6368 5f61 6c69 6173 3d5b 0a20 2020 2020  ch_alias=[.     
+00023320: 2020 2022 6472 6f70 6f75 7422 2c0a 2020     "dropout",.  
+00023330: 2020 2020 2020 2264 726f 706f 7574 5f22        "dropout_"
+00023340: 2c0a 2020 2020 2020 2020 2266 6561 7475  ,.        "featu
+00023350: 7265 5f64 726f 706f 7574 222c 0a20 2020  re_dropout",.   
+00023360: 2020 2020 2022 636f 6e74 6967 756f 7573       "contiguous
+00023370: 222c 0a20 2020 2020 2020 2022 6465 7669  ",.        "devi
+00023380: 6365 222c 0a20 2020 2020 2020 2022 6465  ce",.        "de
+00023390: 7461 6368 222c 0a20 2020 2020 2020 2022  tach",.        "
+000233a0: 636c 6f6e 6522 2c0a 2020 2020 5d0a 290a  clone",.    ].).
+000233b0: 6465 6620 6e6f 6f70 2863 6f6e 7465 7874  def noop(context
+000233c0: 2c20 6e6f 6465 293a 0a20 2020 206c 6f67  , node):.    log
+000233d0: 6765 722e 696e 666f 2822 5365 7474 696e  ger.info("Settin
+000233e0: 6720 7079 746f 7263 6820 6f70 3a20 7b7d  g pytorch op: {}
+000233f0: 2074 6f20 6e6f 2d6f 702e 222e 666f 726d   to no-op.".form
+00023400: 6174 286e 6f64 6529 290a 2020 2020 696e  at(node)).    in
+00023410: 7075 7473 203d 205f 6765 745f 696e 7075  puts = _get_inpu
+00023420: 7473 2863 6f6e 7465 7874 2c20 6e6f 6465  ts(context, node
+00023430: 290a 2020 2020 5f69 6e70 7574 203d 2069  ).    _input = i
+00023440: 6e70 7574 735b 305d 0a20 2020 2063 6f6e  nputs[0].    con
+00023450: 7465 7874 2e61 6464 285f 696e 7075 742c  text.add(_input,
+00023460: 2074 6f72 6368 5f6e 616d 653d 6e6f 6465   torch_name=node
+00023470: 2e6e 616d 6529 0a0a 0a40 7265 6769 7374  .name)...@regist
+00023480: 6572 5f74 6f72 6368 5f6f 700a 6465 6620  er_torch_op.def 
+00023490: 6172 676d 6178 2863 6f6e 7465 7874 2c20  argmax(context, 
+000234a0: 6e6f 6465 293a 0a20 2020 2069 6e70 7574  node):.    input
+000234b0: 7320 3d20 5f67 6574 5f69 6e70 7574 7328  s = _get_inputs(
+000234c0: 636f 6e74 6578 742c 206e 6f64 6529 0a20  context, node). 
+000234d0: 2020 2078 203d 2069 6e70 7574 735b 305d     x = inputs[0]
+000234e0: 0a20 2020 2061 7869 7320 3d20 696e 7075  .    axis = inpu
+000234f0: 7473 5b31 5d0a 2020 2020 6b65 6570 5f64  ts[1].    keep_d
+00023500: 696d 7320 3d20 696e 7075 7473 5b32 5d0a  ims = inputs[2].
+00023510: 2020 2020 6966 2074 7970 6573 2e69 735f      if types.is_
+00023520: 696e 7428 782e 6474 7970 6529 2061 6e64  int(x.dtype) and
+00023530: 2078 2e64 7479 7065 2e5f 7769 6474 6820   x.dtype._width 
+00023540: 3d3d 2036 343a 0a20 2020 2020 2020 2023  == 64:.        #
+00023550: 204d 494c 2072 6564 7563 655f 6172 676d   MIL reduce_argm
+00023560: 6178 2064 6f65 736e 2774 2073 7570 706f  ax doesn't suppo
+00023570: 7274 2069 6e74 3634 2e0a 2020 2020 2020  rt int64..      
+00023580: 2020 7820 3d20 6d62 2e63 6173 7428 783d    x = mb.cast(x=
+00023590: 782c 2064 7479 7065 3d22 696e 7433 3222  x, dtype="int32"
+000235a0: 290a 2020 2020 7265 7320 3d20 6d62 2e72  ).    res = mb.r
+000235b0: 6564 7563 655f 6172 676d 6178 2878 3d78  educe_argmax(x=x
+000235c0: 2c20 6178 6973 3d61 7869 732c 206b 6565  , axis=axis, kee
+000235d0: 705f 6469 6d73 3d6b 6565 705f 6469 6d73  p_dims=keep_dims
 000235e0: 2c20 6e61 6d65 3d6e 6f64 652e 6e61 6d65  , name=node.name
-000235f0: 290a 2020 2020 2020 2020 636f 6e74 6578  ).        contex
-00023600: 742e 6164 6428 7661 6c75 6529 0a20 2020  t.add(value).   
-00023610: 2065 6c69 6620 6c65 6e28 696e 7075 7473   elif len(inputs
-00023620: 2920 3d3d 2033 3a0a 2020 2020 2020 2020  ) == 3:.        
-00023630: 5f69 6e70 7574 203d 2069 6e70 7574 735b  _input = inputs[
-00023640: 305d 0a20 2020 2020 2020 2064 696d 203d  0].        dim =
-00023650: 2069 6e70 7574 735b 315d 2e76 616c 0a20   inputs[1].val. 
-00023660: 2020 2020 2020 206b 6565 7064 696d 203d         keepdim =
-00023670: 2069 6e70 7574 735b 325d 2e76 616c 0a0a   inputs[2].val..
-00023680: 2020 2020 2020 2020 7661 6c75 6573 203d          values =
-00023690: 206d 622e 7265 6475 6365 5f6d 6178 2878   mb.reduce_max(x
-000236a0: 3d5f 696e 7075 742c 2061 7865 733d 5b64  =_input, axes=[d
-000236b0: 696d 5d2c 206b 6565 705f 6469 6d73 3d6b  im], keep_dims=k
-000236c0: 6565 7064 696d 290a 2020 2020 2020 2020  eepdim).        
-000236d0: 696e 6469 6365 7320 3d20 6d62 2e72 6564  indices = mb.red
-000236e0: 7563 655f 6172 676d 6178 2878 3d5f 696e  uce_argmax(x=_in
-000236f0: 7075 742c 2061 7869 733d 6469 6d2c 206b  put, axis=dim, k
-00023700: 6565 705f 6469 6d73 3d6b 6565 7064 696d  eep_dims=keepdim
-00023710: 290a 2020 2020 2020 2020 6173 7365 7274  ).        assert
-00023720: 206c 656e 286e 6f64 652e 6f75 7470 7574   len(node.output
-00023730: 7329 203d 3d20 320a 2020 2020 2020 2020  s) == 2.        
-00023740: 7661 6c75 6573 5f6e 616d 6520 3d20 6e6f  values_name = no
-00023750: 6465 2e6f 7574 7075 7473 5b30 5d0a 2020  de.outputs[0].  
-00023760: 2020 2020 2020 696e 6469 6365 735f 6e61        indices_na
-00023770: 6d65 203d 206e 6f64 652e 6f75 7470 7574  me = node.output
-00023780: 735b 315d 0a20 2020 2020 2020 2063 6f6e  s[1].        con
-00023790: 7465 7874 2e61 6464 2876 616c 7565 732c  text.add(values,
-000237a0: 2074 6f72 6368 5f6e 616d 653d 7661 6c75   torch_name=valu
-000237b0: 6573 5f6e 616d 6529 0a20 2020 2020 2020  es_name).       
-000237c0: 2063 6f6e 7465 7874 2e61 6464 2869 6e64   context.add(ind
-000237d0: 6963 6573 2c20 746f 7263 685f 6e61 6d65  ices, torch_name
-000237e0: 3d69 6e64 6963 6573 5f6e 616d 6529 0a0a  =indices_name)..
-000237f0: 6465 6620 5f61 6464 5f61 6d61 785f 616d  def _add_amax_am
-00023800: 696e 2863 6f6e 7465 7874 2c20 6e6f 6465  in(context, node
-00023810: 2c20 7265 6475 6365 5f6f 7029 3a0a 2020  , reduce_op):.  
-00023820: 2020 2023 206d 696d 6963 2066 756e 6374     # mimic funct
-00023830: 696f 6e61 6c69 7479 2066 726f 6d20 6874  ionality from ht
-00023840: 7470 733a 2f2f 7079 746f 7263 682e 6f72  tps://pytorch.or
-00023850: 672f 646f 6373 2f73 7461 626c 652f 6765  g/docs/stable/ge
-00023860: 6e65 7261 7465 642f 746f 7263 682e 616d  nerated/torch.am
-00023870: 6178 2e68 746d 6c0a 2020 2020 2023 206d  ax.html.     # m
-00023880: 696d 6963 2066 756e 6374 696f 6e61 6c69  imic functionali
-00023890: 7479 2066 726f 6d20 6874 7470 733a 2f2f  ty from https://
-000238a0: 7079 746f 7263 682e 6f72 672f 646f 6373  pytorch.org/docs
-000238b0: 2f73 7461 626c 652f 6765 6e65 7261 7465  /stable/generate
-000238c0: 642f 746f 7263 682e 616d 696e 2e68 746d  d/torch.amin.htm
-000238d0: 6c0a 2020 2020 6173 7365 7274 206c 656e  l.    assert len
-000238e0: 286e 6f64 652e 6f75 7470 7574 7329 203d  (node.outputs) =
-000238f0: 3d20 310a 0a20 2020 2061 6c6c 5f69 6e70  = 1..    all_inp
-00023900: 7574 7320 3d20 5f67 6574 5f69 6e70 7574  uts = _get_input
-00023910: 7328 636f 6e74 6578 742c 206e 6f64 652c  s(context, node,
-00023920: 2065 7870 6563 7465 643d 5b32 2c20 335d   expected=[2, 3]
-00023930: 290a 2020 2020 5f69 6e70 7574 203d 2061  ).    _input = a
-00023940: 6c6c 5f69 6e70 7574 735b 305d 0a20 2020  ll_inputs[0].   
-00023950: 2064 696d 203d 205b 616c 6c5f 696e 7075   dim = [all_inpu
-00023960: 7473 5b31 5d2e 7661 6c5d 2069 6620 7479  ts[1].val] if ty
-00023970: 7065 2861 6c6c 5f69 6e70 7574 735b 315d  pe(all_inputs[1]
-00023980: 2e76 616c 2920 3d3d 2069 6e74 2065 6c73  .val) == int els
-00023990: 6520 5b78 2066 6f72 2078 2069 6e20 616c  e [x for x in al
-000239a0: 6c5f 696e 7075 7473 5b31 5d2e 7661 6c5d  l_inputs[1].val]
-000239b0: 0a20 2020 206b 6565 7064 696d 203d 2061  .    keepdim = a
-000239c0: 6c6c 5f69 6e70 7574 735b 325d 2069 6620  ll_inputs[2] if 
-000239d0: 6c65 6e28 616c 6c5f 696e 7075 7473 2920  len(all_inputs) 
-000239e0: 3d3d 2033 2065 6c73 6520 4661 6c73 650a  == 3 else False.
-000239f0: 0a20 2020 2063 6f6e 7465 7874 2e61 6464  .    context.add
-00023a00: 2872 6564 7563 655f 6f70 2878 3d5f 696e  (reduce_op(x=_in
-00023a10: 7075 742c 2061 7865 733d 6469 6d2c 206b  put, axes=dim, k
-00023a20: 6565 705f 6469 6d73 3d6b 6565 7064 696d  eep_dims=keepdim
-00023a30: 292c 2074 6f72 6368 5f6e 616d 653d 6e6f  ), torch_name=no
-00023a40: 6465 2e6f 7574 7075 7473 5b30 5d29 0a0a  de.outputs[0])..
-00023a50: 4072 6567 6973 7465 725f 746f 7263 685f  @register_torch_
-00023a60: 6f70 0a64 6566 2061 6d61 7828 636f 6e74  op.def amax(cont
-00023a70: 6578 742c 206e 6f64 6529 3a0a 2020 2020  ext, node):.    
-00023a80: 5f61 6464 5f61 6d61 785f 616d 696e 2863  _add_amax_amin(c
-00023a90: 6f6e 7465 7874 2c20 6e6f 6465 2c20 6d62  ontext, node, mb
-00023aa0: 2e72 6564 7563 655f 6d61 7829 0a0a 4072  .reduce_max)..@r
-00023ab0: 6567 6973 7465 725f 746f 7263 685f 6f70  egister_torch_op
-00023ac0: 0a64 6566 2061 6d69 6e28 636f 6e74 6578  .def amin(contex
-00023ad0: 742c 206e 6f64 6529 3a0a 2020 2020 5f61  t, node):.    _a
-00023ae0: 6464 5f61 6d61 785f 616d 696e 2863 6f6e  dd_amax_amin(con
-00023af0: 7465 7874 2c20 6e6f 6465 2c20 6d62 2e72  text, node, mb.r
-00023b00: 6564 7563 655f 6d69 6e29 0a0a 0a40 7265  educe_min)...@re
-00023b10: 6769 7374 6572 5f74 6f72 6368 5f6f 700a  gister_torch_op.
-00023b20: 6465 6620 6172 6773 6f72 7428 636f 6e74  def argsort(cont
-00023b30: 6578 742c 206e 6f64 6529 3a0a 2020 2020  ext, node):.    
-00023b40: 696e 7075 7473 203d 205f 6765 745f 696e  inputs = _get_in
-00023b50: 7075 7473 2863 6f6e 7465 7874 2c20 6e6f  puts(context, no
-00023b60: 6465 2c20 6578 7065 6374 6564 3d33 290a  de, expected=3).
-00023b70: 2020 2020 6173 6365 6e64 696e 6720 3d20      ascending = 
-00023b80: 6d62 2e6c 6f67 6963 616c 5f6e 6f74 2878  mb.logical_not(x
-00023b90: 3d69 6e70 7574 735b 325d 290a 2020 2020  =inputs[2]).    
-00023ba0: 6172 6773 6f72 7420 3d20 6d62 2e61 7267  argsort = mb.arg
-00023bb0: 736f 7274 2878 3d69 6e70 7574 735b 305d  sort(x=inputs[0]
-00023bc0: 2c20 6178 6973 3d69 6e70 7574 735b 315d  , axis=inputs[1]
-00023bd0: 2c20 6173 6365 6e64 696e 673d 6173 6365  , ascending=asce
-00023be0: 6e64 696e 672c 206e 616d 653d 6e6f 6465  nding, name=node
-00023bf0: 2e6e 616d 6529 0a20 2020 2063 6f6e 7465  .name).    conte
-00023c00: 7874 2e61 6464 2861 7267 736f 7274 290a  xt.add(argsort).
-00023c10: 0a0a 4072 6567 6973 7465 725f 746f 7263  ..@register_torc
-00023c20: 685f 6f70 0a64 6566 2073 6f72 7428 636f  h_op.def sort(co
-00023c30: 6e74 6578 742c 206e 6f64 6529 3a0a 2020  ntext, node):.  
-00023c40: 2020 696e 7075 7473 203d 205f 6765 745f    inputs = _get_
-00023c50: 696e 7075 7473 2863 6f6e 7465 7874 2c20  inputs(context, 
-00023c60: 6e6f 6465 290a 2020 2020 5f69 6e70 7574  node).    _input
-00023c70: 203d 2069 6e70 7574 735b 305d 0a20 2020   = inputs[0].   
-00023c80: 2061 7869 7320 3d20 696e 7075 7473 5b31   axis = inputs[1
-00023c90: 5d2e 7661 6c0a 2020 2020 6173 6365 6e64  ].val.    ascend
-00023ca0: 696e 6720 3d20 6e6f 7420 696e 7075 7473  ing = not inputs
-00023cb0: 5b32 5d2e 7661 6c0a 2020 2020 696e 6469  [2].val.    indi
-00023cc0: 6365 735f 6e61 6d65 203d 206e 6f64 652e  ces_name = node.
-00023cd0: 6f75 7470 7574 735b 315d 0a20 2020 2076  outputs[1].    v
-00023ce0: 616c 7565 735f 6e61 6d65 203d 206e 6f64  alues_name = nod
-00023cf0: 652e 6f75 7470 7574 735b 305d 0a20 2020  e.outputs[0].   
-00023d00: 2069 6e64 6963 6573 203d 206d 622e 6172   indices = mb.ar
-00023d10: 6773 6f72 7428 783d 5f69 6e70 7574 2c20  gsort(x=_input, 
-00023d20: 6178 6973 3d61 7869 732c 2061 7363 656e  axis=axis, ascen
-00023d30: 6469 6e67 3d61 7363 656e 6469 6e67 2c20  ding=ascending, 
-00023d40: 6e61 6d65 3d69 6e64 6963 6573 5f6e 616d  name=indices_nam
-00023d50: 6529 0a20 2020 2076 616c 7565 7320 3d20  e).    values = 
-00023d60: 6d62 2e67 6174 6865 725f 616c 6f6e 675f  mb.gather_along_
-00023d70: 6178 6973 2878 3d5f 696e 7075 742c 2069  axis(x=_input, i
-00023d80: 6e64 6963 6573 3d69 6e64 6963 6573 2c20  ndices=indices, 
-00023d90: 6178 6973 3d61 7869 732c 206e 616d 653d  axis=axis, name=
-00023da0: 7661 6c75 6573 5f6e 616d 6529 0a20 2020  values_name).   
-00023db0: 2063 6f6e 7465 7874 2e61 6464 2876 616c   context.add(val
-00023dc0: 7565 732c 2074 6f72 6368 5f6e 616d 653d  ues, torch_name=
-00023dd0: 7661 6c75 6573 5f6e 616d 6529 0a20 2020  values_name).   
-00023de0: 2063 6f6e 7465 7874 2e61 6464 2869 6e64   context.add(ind
-00023df0: 6963 6573 2c20 746f 7263 685f 6e61 6d65  ices, torch_name
-00023e00: 3d69 6e64 6963 6573 5f6e 616d 6529 0a0a  =indices_name)..
-00023e10: 0a40 7265 6769 7374 6572 5f74 6f72 6368  .@register_torch
-00023e20: 5f6f 700a 6465 6620 6170 7065 6e64 2863  _op.def append(c
-00023e30: 6f6e 7465 7874 2c20 6e6f 6465 293a 0a20  ontext, node):. 
-00023e40: 2020 2023 204e 6f74 653a 2062 7920 6170     # Note: by ap
-00023e50: 706c 7969 6e67 2074 6f72 6368 6972 5f70  plying torchir_p
-00023e60: 6173 7365 732e 7472 616e 7366 6f72 6d5f  asses.transform_
-00023e70: 696e 706c 6163 655f 6f70 7320 7468 6520  inplace_ops the 
-00023e80: 6d65 616e 696e 6720 6f66 0a20 2020 2023  meaning of.    #
-00023e90: 2074 6869 7320 6f70 2069 7320 6368 616e   this op is chan
-00023ea0: 6765 6420 6672 6f6d 2074 6865 206f 7269  ged from the ori
-00023eb0: 6769 6e61 6c20 546f 7263 6849 522e 2054  ginal TorchIR. T
-00023ec0: 6869 7320 6f70 2065 7870 6563 7473 2061  his op expects a
-00023ed0: 2070 7974 686f 6e0a 2020 2020 2320 6c69   python.    # li
-00023ee0: 7374 206f 7220 4d49 4c20 4c69 7374 2061  st or MIL List a
-00023ef0: 7320 6974 7320 6669 7273 7420 696e 7075  s its first inpu
-00023f00: 742e 2049 6620 616e 204d 494c 204c 6973  t. If an MIL Lis
-00023f10: 742c 2074 6865 2073 6563 6f6e 6420 696e  t, the second in
-00023f20: 7075 740a 2020 2020 2320 6d75 7374 2062  put.    # must b
-00023f30: 6520 6120 7465 6e73 6f72 206f 6620 7768  e a tensor of wh
-00023f40: 6174 6576 6572 2073 6861 7065 2074 6865  atever shape the
-00023f50: 204c 6973 7420 6578 7065 6374 732e 2049   List expects. I
-00023f60: 6620 6e6f 7420 616e 204d 494c 204c 6973  f not an MIL Lis
-00023f70: 742c 0a20 2020 2023 2074 6865 2073 6563  t,.    # the sec
-00023f80: 6f6e 6420 696e 7075 7420 6361 6e20 6279  ond input can by
-00023f90: 2061 6e79 7468 696e 672e 2054 6865 2072   anything. The r
-00023fa0: 6573 756c 7420 7769 6c6c 2062 6520 7468  esult will be th
-00023fb0: 6520 7365 636f 6e64 2069 6e70 7574 0a20  e second input. 
-00023fc0: 2020 2023 206a 6f69 6e65 6420 746f 2074     # joined to t
-00023fd0: 6865 2066 6972 7374 2069 6e70 7574 2c20  he first input, 
-00023fe0: 6569 7468 6572 2062 7920 6c69 7374 5f77  either by list_w
-00023ff0: 7269 7465 2069 6620 616e 204d 494c 206c  rite if an MIL l
-00024000: 6973 742c 206f 720a 2020 2020 2320 6170  ist, or.    # ap
-00024010: 7065 6e64 2069 6620 6120 7079 7468 6f6e  pend if a python
-00024020: 206c 6973 742e 0a20 2020 2069 6e70 7574   list..    input
-00024030: 7320 3d20 5f67 6574 5f69 6e70 7574 7328  s = _get_inputs(
-00024040: 636f 6e74 6578 742c 206e 6f64 652c 2065  context, node, e
-00024050: 7870 6563 7465 643d 3229 0a20 2020 206c  xpected=2).    l
-00024060: 7320 3d20 696e 7075 7473 5b30 5d0a 2020  s = inputs[0].  
-00024070: 2020 7661 6c75 6520 3d20 696e 7075 7473    value = inputs
-00024080: 5b31 5d0a 0a20 2020 2069 6620 6973 696e  [1]..    if isin
-00024090: 7374 616e 6365 286c 732c 206c 6973 7429  stance(ls, list)
-000240a0: 3a0a 2020 2020 2020 2020 636f 6e74 6578  :.        contex
-000240b0: 742e 6164 6428 6c73 202b 205b 7661 6c75  t.add(ls + [valu
-000240c0: 655d 2c20 6e6f 6465 2e6e 616d 6529 0a20  e], node.name). 
-000240d0: 2020 2065 6c69 6620 6973 696e 7374 616e     elif isinstan
-000240e0: 6365 286c 732c 204c 6973 7456 6172 293a  ce(ls, ListVar):
-000240f0: 0a20 2020 2020 2020 2069 6e64 6578 203d  .        index =
-00024100: 206d 622e 6c69 7374 5f6c 656e 6774 6828   mb.list_length(
-00024110: 6c73 3d6c 732c 206e 616d 653d 6e6f 6465  ls=ls, name=node
-00024120: 2e6e 616d 6520 2b20 225f 696e 6465 7822  .name + "_index"
-00024130: 290a 2020 2020 2020 2020 7265 7320 3d20  ).        res = 
-00024140: 6d62 2e6c 6973 745f 7772 6974 6528 6c73  mb.list_write(ls
-00024150: 3d6c 732c 2069 6e64 6578 3d69 6e64 6578  =ls, index=index
-00024160: 2c20 7661 6c75 653d 7661 6c75 652c 206e  , value=value, n
-00024170: 616d 653d 6e6f 6465 2e6e 616d 6529 0a20  ame=node.name). 
-00024180: 2020 2020 2020 2063 6f6e 7465 7874 2e61         context.a
-00024190: 6464 2872 6573 290a 2020 2020 656c 7365  dd(res).    else
-000241a0: 3a0a 2020 2020 2020 2020 7261 6973 6520  :.        raise 
-000241b0: 5661 6c75 6545 7272 6f72 280a 2020 2020  ValueError(.    
-000241c0: 2020 2020 2020 2020 2263 616e 206f 6e6c          "can onl
-000241d0: 7920 6170 7065 6e64 2074 6f20 5079 7468  y append to Pyth
-000241e0: 6f6e 206c 6973 7420 6f72 204d 494c 204c  on list or MIL L
-000241f0: 6973 7456 6172 2c20 676f 7420 7b7d 2e22  istVar, got {}."
-00024200: 2e66 6f72 6d61 7428 0a20 2020 2020 2020  .format(.       
-00024210: 2020 2020 2020 2020 2074 7970 6528 696e           type(in
-00024220: 7075 7473 5b30 5d29 0a20 2020 2020 2020  puts[0]).       
-00024230: 2020 2020 2029 0a20 2020 2020 2020 2029       ).        )
-00024240: 0a0a 0a40 7265 6769 7374 6572 5f74 6f72  ...@register_tor
-00024250: 6368 5f6f 700a 6465 6620 6761 7468 6572  ch_op.def gather
-00024260: 2863 6f6e 7465 7874 2c20 6e6f 6465 293a  (context, node):
-00024270: 0a20 2020 2069 6e70 7574 7320 3d20 5f67  .    inputs = _g
-00024280: 6574 5f69 6e70 7574 7328 636f 6e74 6578  et_inputs(contex
-00024290: 742c 206e 6f64 6529 0a20 2020 2072 6573  t, node).    res
-000242a0: 203d 206d 622e 6761 7468 6572 5f61 6c6f   = mb.gather_alo
-000242b0: 6e67 5f61 7869 7328 783d 696e 7075 7473  ng_axis(x=inputs
-000242c0: 5b30 5d2c 2069 6e64 6963 6573 3d69 6e70  [0], indices=inp
-000242d0: 7574 735b 325d 2c20 6178 6973 3d69 6e70  uts[2], axis=inp
-000242e0: 7574 735b 315d 2c20 6e61 6d65 3d6e 6f64  uts[1], name=nod
-000242f0: 652e 6e61 6d65 290a 2020 2020 636f 6e74  e.name).    cont
-00024300: 6578 742e 6164 6428 7265 7329 0a0a 0a40  ext.add(res)...@
-00024310: 7265 6769 7374 6572 5f74 6f72 6368 5f6f  register_torch_o
-00024320: 700a 6465 6620 696e 6465 785f 7365 6c65  p.def index_sele
-00024330: 6374 2863 6f6e 7465 7874 2c20 6e6f 6465  ct(context, node
-00024340: 293a 0a20 2020 2078 203d 2063 6f6e 7465  ):.    x = conte
-00024350: 7874 5b6e 6f64 652e 696e 7075 7473 5b30  xt[node.inputs[0
-00024360: 5d5d 0a20 2020 2061 7869 7320 3d20 636f  ]].    axis = co
-00024370: 6e74 6578 745b 6e6f 6465 2e69 6e70 7574  ntext[node.input
-00024380: 735b 315d 5d0a 2020 2020 696e 6469 6365  s[1]].    indice
-00024390: 7320 3d20 636f 6e74 6578 745b 6e6f 6465  s = context[node
-000243a0: 2e69 6e70 7574 735b 325d 5d0a 2020 2020  .inputs[2]].    
-000243b0: 636f 6e74 6578 742e 6164 6428 6d62 2e67  context.add(mb.g
-000243c0: 6174 6865 7228 783d 782c 2069 6e64 6963  ather(x=x, indic
-000243d0: 6573 3d69 6e64 6963 6573 2c20 6178 6973  es=indices, axis
-000243e0: 3d61 7869 732c 206e 616d 653d 6e6f 6465  =axis, name=node
-000243f0: 2e6e 616d 6529 290a 0a0a 4072 6567 6973  .name))...@regis
-00024400: 7465 725f 746f 7263 685f 6f70 2874 6f72  ter_torch_op(tor
-00024410: 6368 5f61 6c69 6173 3d5b 2261 6273 225d  ch_alias=["abs"]
-00024420: 290a 6465 6620 5f61 6273 2863 6f6e 7465  ).def _abs(conte
-00024430: 7874 2c20 6e6f 6465 293a 0a20 2020 2069  xt, node):.    i
-00024440: 6e70 7574 7320 3d20 5f67 6574 5f69 6e70  nputs = _get_inp
-00024450: 7574 7328 636f 6e74 6578 742c 206e 6f64  uts(context, nod
-00024460: 652c 2065 7870 6563 7465 643d 3129 0a20  e, expected=1). 
-00024470: 2020 2063 6f6e 7465 7874 2e61 6464 286d     context.add(m
-00024480: 622e 6162 7328 783d 696e 7075 7473 5b30  b.abs(x=inputs[0
-00024490: 5d2c 206e 616d 653d 6e6f 6465 2e6e 616d  ], name=node.nam
-000244a0: 6529 290a 0a0a 4072 6567 6973 7465 725f  e))...@register_
-000244b0: 746f 7263 685f 6f70 0a64 6566 2072 6570  torch_op.def rep
-000244c0: 6561 7428 636f 6e74 6578 742c 206e 6f64  eat(context, nod
-000244d0: 6529 3a0a 2020 2020 7820 3d20 636f 6e74  e):.    x = cont
-000244e0: 6578 745b 6e6f 6465 2e69 6e70 7574 735b  ext[node.inputs[
-000244f0: 305d 5d0a 2020 2020 7265 7073 203d 2063  0]].    reps = c
-00024500: 6f6e 7465 7874 5b6e 6f64 652e 696e 7075  ontext[node.inpu
-00024510: 7473 5b31 5d5d 0a20 2020 2069 6620 6973  ts[1]].    if is
-00024520: 696e 7374 616e 6365 2872 6570 732c 206c  instance(reps, l
-00024530: 6973 7429 3a0a 2020 2020 2020 2020 7265  ist):.        re
-00024540: 7073 203d 206d 622e 636f 6e63 6174 2876  ps = mb.concat(v
-00024550: 616c 7565 733d 7265 7073 2c20 6178 6973  alues=reps, axis
-00024560: 3d30 290a 0a20 2020 2069 6620 7265 7073  =0)..    if reps
-00024570: 2e73 6861 7065 5b30 5d20 3e20 6c65 6e28  .shape[0] > len(
-00024580: 782e 7368 6170 6529 3a0a 2020 2020 2020  x.shape):.      
-00024590: 2020 7820 3d20 6d62 2e65 7870 616e 645f    x = mb.expand_
-000245a0: 6469 6d73 2878 3d78 2c20 6178 6573 3d6c  dims(x=x, axes=l
-000245b0: 6973 7428 7261 6e67 6528 7265 7073 2e73  ist(range(reps.s
-000245c0: 6861 7065 5b30 5d20 2d20 782e 7261 6e6b  hape[0] - x.rank
-000245d0: 2929 290a 2020 2020 636f 6e74 6578 742e  ))).    context.
-000245e0: 6164 6428 6d62 2e74 696c 6528 783d 782c  add(mb.tile(x=x,
-000245f0: 2072 6570 733d 7265 7073 2c20 6e61 6d65   reps=reps, name
-00024600: 3d6e 6f64 652e 6e61 6d65 2929 0a0a 0a40  =node.name))...@
-00024610: 7265 6769 7374 6572 5f74 6f72 6368 5f6f  register_torch_o
-00024620: 700a 6465 6620 6163 6f73 2863 6f6e 7465  p.def acos(conte
-00024630: 7874 2c20 6e6f 6465 293a 0a20 2020 2069  xt, node):.    i
-00024640: 6e70 7574 7320 3d20 5f67 6574 5f69 6e70  nputs = _get_inp
-00024650: 7574 7328 636f 6e74 6578 742c 206e 6f64  uts(context, nod
-00024660: 652c 2065 7870 6563 7465 643d 3129 0a20  e, expected=1). 
-00024670: 2020 2063 6f6e 7465 7874 2e61 6464 286d     context.add(m
-00024680: 622e 6163 6f73 2878 3d69 6e70 7574 735b  b.acos(x=inputs[
-00024690: 305d 2c20 6e61 6d65 3d6e 6f64 652e 6e61  0], name=node.na
-000246a0: 6d65 2929 0a0a 0a40 7265 6769 7374 6572  me))...@register
-000246b0: 5f74 6f72 6368 5f6f 700a 6465 6620 6163  _torch_op.def ac
-000246c0: 6f73 6828 636f 6e74 6578 742c 206e 6f64  osh(context, nod
-000246d0: 6529 3a0a 2020 2020 696e 7075 7473 203d  e):.    inputs =
-000246e0: 205f 6765 745f 696e 7075 7473 2863 6f6e   _get_inputs(con
-000246f0: 7465 7874 2c20 6e6f 6465 2c20 6578 7065  text, node, expe
-00024700: 6374 6564 3d31 290a 2020 2020 636f 6e74  cted=1).    cont
-00024710: 6578 742e 6164 6428 6d62 2e61 636f 7368  ext.add(mb.acosh
-00024720: 2878 3d69 6e70 7574 735b 305d 2c20 6e61  (x=inputs[0], na
-00024730: 6d65 3d6e 6f64 652e 6e61 6d65 2929 0a0a  me=node.name))..
-00024740: 0a40 7265 6769 7374 6572 5f74 6f72 6368  .@register_torch
-00024750: 5f6f 700a 6465 6620 6173 696e 2863 6f6e  _op.def asin(con
-00024760: 7465 7874 2c20 6e6f 6465 293a 0a20 2020  text, node):.   
-00024770: 2069 6e70 7574 7320 3d20 5f67 6574 5f69   inputs = _get_i
-00024780: 6e70 7574 7328 636f 6e74 6578 742c 206e  nputs(context, n
-00024790: 6f64 652c 2065 7870 6563 7465 643d 3129  ode, expected=1)
-000247a0: 0a20 2020 2063 6f6e 7465 7874 2e61 6464  .    context.add
-000247b0: 286d 622e 6173 696e 2878 3d69 6e70 7574  (mb.asin(x=input
-000247c0: 735b 305d 2c20 6e61 6d65 3d6e 6f64 652e  s[0], name=node.
-000247d0: 6e61 6d65 2929 0a0a 0a40 7265 6769 7374  name))...@regist
-000247e0: 6572 5f74 6f72 6368 5f6f 700a 6465 6620  er_torch_op.def 
-000247f0: 6174 616e 2863 6f6e 7465 7874 2c20 6e6f  atan(context, no
-00024800: 6465 293a 0a20 2020 2069 6e70 7574 7320  de):.    inputs 
-00024810: 3d20 5f67 6574 5f69 6e70 7574 7328 636f  = _get_inputs(co
-00024820: 6e74 6578 742c 206e 6f64 652c 2065 7870  ntext, node, exp
-00024830: 6563 7465 643d 3129 0a20 2020 2063 6f6e  ected=1).    con
-00024840: 7465 7874 2e61 6464 286d 622e 6174 616e  text.add(mb.atan
-00024850: 2878 3d69 6e70 7574 735b 305d 2c20 6e61  (x=inputs[0], na
-00024860: 6d65 3d6e 6f64 652e 6e61 6d65 2929 0a0a  me=node.name))..
-00024870: 0a40 7265 6769 7374 6572 5f74 6f72 6368  .@register_torch
-00024880: 5f6f 700a 6465 6620 6174 616e 3228 636f  _op.def atan2(co
-00024890: 6e74 6578 742c 206e 6f64 6529 3a0a 2020  ntext, node):.  
-000248a0: 2020 2222 220a 2020 2020 6174 616e 3228    """.    atan2(
-000248b0: 5465 6e73 6f72 2079 2c20 5465 6e73 6f72  Tensor y, Tensor
-000248c0: 2078 290a 2020 2020 456c 656d 656e 742d   x).    Element-
-000248d0: 7769 7365 2061 7263 7461 6e67 656e 7420  wise arctangent 
-000248e0: 6f66 2079 202f 2078 2077 6974 6820 636f  of y / x with co
-000248f0: 6e73 6964 6572 6174 696f 6e20 6f66 2074  nsideration of t
-00024900: 6865 2071 7561 6472 616e 740a 2020 2020  he quadrant.    
-00024910: 5265 7475 726e 7320 6120 6e65 7720 7465  Returns a new te
-00024920: 6e73 6f72 2077 6974 6820 7468 6520 7369  nsor with the si
-00024930: 676e 6564 2061 6e67 6c65 7320 696e 2072  gned angles in r
-00024940: 6164 6961 6e73 2062 6574 7765 656e 2076  adians between v
-00024950: 6563 746f 7220 2878 2c20 7929 2061 6e64  ector (x, y) and
-00024960: 2076 6563 746f 7220 2831 2c20 3029 0a0a   vector (1, 0)..
-00024970: 2020 2020 4f6e 2061 2068 6967 6820 6c65      On a high le
-00024980: 7665 6c3a 0a20 2020 2031 2e20 6174 616e  vel:.    1. atan
-00024990: 2879 202f 2078 2920 746f 2067 6574 2074  (y / x) to get t
-000249a0: 6865 2061 6e67 6c65 2069 6e20 5b2d 7069  he angle in [-pi
-000249b0: 202f 2032 2c20 7069 202f 2032 5d0a 2020   / 2, pi / 2].  
-000249c0: 2020 322e 2061 6e61 6c79 7a65 2071 7561    2. analyze qua
-000249d0: 6472 616e 7420 746f 2064 6574 6572 6d69  drant to determi
-000249e0: 6e65 2074 6865 2061 6e67 6c65 2069 6e20  ne the angle in 
-000249f0: 5b2d 7069 2c20 7069 5d0a 0a20 2020 2052  [-pi, pi]..    R
-00024a00: 6566 6572 656e 6365 2050 7954 6f72 6368  eference PyTorch
-00024a10: 2063 6f64 6520 6874 7470 733a 2f2f 6769   code https://gi
-00024a20: 7374 2e67 6974 6875 622e 636f 6d2f 6e69  st.github.com/ni
-00024a30: 6b6f 6c61 2d6a 2f62 3562 6236 6231 3431  kola-j/b5bb6b141
-00024a40: 6238 6439 3932 3033 3138 3637 3765 3162  b8d9920318677e1b
-00024a50: 6261 3730 3436 360a 2020 2020 6465 6620  ba70466.    def 
-00024a60: 6d79 5f61 7461 6e32 2879 2c20 7829 3a0a  my_atan2(y, x):.
-00024a70: 2020 2020 2020 2020 7069 203d 2074 6f72          pi = tor
-00024a80: 6368 2e66 726f 6d5f 6e75 6d70 7928 6e70  ch.from_numpy(np
-00024a90: 2e61 7272 6179 285b 6e70 2e70 695d 2929  .array([np.pi]))
-00024aa0: 2e74 6f28 792e 6465 7669 6365 2c20 792e  .to(y.device, y.
-00024ab0: 6474 7970 6529 0a20 2020 2020 2020 2061  dtype).        a
-00024ac0: 6e73 203d 2074 6f72 6368 2e61 7461 6e28  ns = torch.atan(
-00024ad0: 7920 2f20 7829 0a20 2020 2020 2020 2061  y / x).        a
-00024ae0: 6e73 202b 3d20 2828 7920 3e20 3029 2026  ns += ((y > 0) &
-00024af0: 2028 7820 3c20 3029 2920 2a20 7069 0a20   (x < 0)) * pi. 
-00024b00: 2020 2020 2020 2061 6e73 202d 3d20 2828         ans -= ((
-00024b10: 7920 3c20 3029 2026 2028 7820 3c20 3029  y < 0) & (x < 0)
-00024b20: 2920 2a20 7069 0a20 2020 2020 2020 2061  ) * pi.        a
-00024b30: 6e73 202a 3d20 2831 202d 2028 2879 203e  ns *= (1 - ((y >
-00024b40: 2030 2920 2620 2878 203d 3d20 3029 2920   0) & (x == 0)) 
-00024b50: 2a20 312e 3029 0a20 2020 2020 2020 2061  * 1.0).        a
-00024b60: 6e73 202b 3d20 2828 7920 3e20 3029 2026  ns += ((y > 0) &
-00024b70: 2028 7820 3d3d 2030 2929 202a 2028 7069   (x == 0)) * (pi
-00024b80: 202f 2032 290a 2020 2020 2020 2020 616e   / 2).        an
-00024b90: 7320 2a3d 2028 3120 2d20 2828 7920 3c20  s *= (1 - ((y < 
-00024ba0: 3029 2026 2028 7820 3d3d 2030 2929 202a  0) & (x == 0)) *
-00024bb0: 2031 2e30 290a 2020 2020 2020 2020 616e   1.0).        an
-00024bc0: 7320 2b3d 2028 2879 203c 2030 2920 2620  s += ((y < 0) & 
-00024bd0: 2878 203d 3d20 3029 2920 2a20 282d 7069  (x == 0)) * (-pi
-00024be0: 202f 2032 290a 2020 2020 2020 2020 7265   / 2).        re
-00024bf0: 7475 726e 2061 6e73 0a20 2020 2022 2222  turn ans.    """
-00024c00: 0a20 2020 2069 6e70 7574 7320 3d20 5f67  .    inputs = _g
-00024c10: 6574 5f69 6e70 7574 7328 636f 6e74 6578  et_inputs(contex
-00024c20: 742c 206e 6f64 652c 2065 7870 6563 7465  t, node, expecte
-00024c30: 643d 3229 0a20 2020 2079 203d 2069 6e70  d=2).    y = inp
-00024c40: 7574 735b 305d 0a20 2020 2078 203d 2069  uts[0].    x = i
-00024c50: 6e70 7574 735b 315d 0a20 2020 2069 6620  nputs[1].    if 
-00024c60: 6e6f 7420 7479 7065 732e 6973 5f66 6c6f  not types.is_flo
-00024c70: 6174 2879 2e64 7479 7065 293a 0a20 2020  at(y.dtype):.   
-00024c80: 2020 2020 2079 203d 206d 622e 6361 7374       y = mb.cast
-00024c90: 2878 3d79 2c20 6474 7970 653d 2266 7033  (x=y, dtype="fp3
-00024ca0: 3222 290a 2020 2020 6966 206e 6f74 2074  2").    if not t
-00024cb0: 7970 6573 2e69 735f 666c 6f61 7428 782e  ypes.is_float(x.
-00024cc0: 6474 7970 6529 3a0a 2020 2020 2020 2020  dtype):.        
-00024cd0: 7820 3d20 6d62 2e63 6173 7428 783d 782c  x = mb.cast(x=x,
-00024ce0: 2064 7479 7065 3d22 6670 3332 2229 0a0a   dtype="fp32")..
-00024cf0: 2020 2020 2320 6261 7369 6320 6c6f 6769      # basic logi
-00024d00: 6361 6c20 6578 7072 6573 7369 6f6e 730a  cal expressions.
-00024d10: 2020 2020 795f 6c65 7373 5f30 203d 206d      y_less_0 = m
-00024d20: 622e 6c65 7373 2878 3d79 2c20 793d 302e  b.less(x=y, y=0.
-00024d30: 3029 0a20 2020 2079 5f67 7265 6174 6572  0).    y_greater
-00024d40: 5f30 203d 206d 622e 6772 6561 7465 7228  _0 = mb.greater(
-00024d50: 783d 792c 2079 3d30 2e30 290a 2020 2020  x=y, y=0.0).    
-00024d60: 785f 6c65 7373 5f30 203d 206d 622e 6c65  x_less_0 = mb.le
-00024d70: 7373 2878 3d78 2c20 793d 302e 3029 0a20  ss(x=x, y=0.0). 
-00024d80: 2020 2078 5f65 7175 616c 5f30 203d 206d     x_equal_0 = m
-00024d90: 622e 6571 7561 6c28 783d 782c 2079 3d30  b.equal(x=x, y=0
-00024da0: 2e30 290a 0a20 2020 2023 2063 6f6d 6269  .0)..    # combi
-00024db0: 6e65 6420 6c6f 6769 6361 6c20 6578 7072  ned logical expr
-00024dc0: 6573 7369 6f6e 730a 2020 2020 7967 7265  essions.    ygre
-00024dd0: 6174 6572 305f 616e 645f 786c 6573 7330  ater0_and_xless0
-00024de0: 203d 206d 622e 6c6f 6769 6361 6c5f 616e   = mb.logical_an
-00024df0: 6428 783d 795f 6772 6561 7465 725f 302c  d(x=y_greater_0,
-00024e00: 2079 3d78 5f6c 6573 735f 3029 0a20 2020   y=x_less_0).   
-00024e10: 2079 6c65 7373 305f 616e 645f 786c 6573   yless0_and_xles
-00024e20: 7330 203d 206d 622e 6c6f 6769 6361 6c5f  s0 = mb.logical_
-00024e30: 616e 6428 783d 795f 6c65 7373 5f30 2c20  and(x=y_less_0, 
-00024e40: 793d 785f 6c65 7373 5f30 290a 2020 2020  y=x_less_0).    
-00024e50: 7967 7265 6174 6572 305f 616e 645f 7865  ygreater0_and_xe
-00024e60: 7175 616c 3020 3d20 6d62 2e6c 6f67 6963  qual0 = mb.logic
-00024e70: 616c 5f61 6e64 2878 3d79 5f67 7265 6174  al_and(x=y_great
-00024e80: 6572 5f30 2c20 793d 785f 6571 7561 6c5f  er_0, y=x_equal_
-00024e90: 3029 0a20 2020 2079 6c65 7373 305f 616e  0).    yless0_an
-00024ea0: 645f 7865 7175 616c 3020 3d20 6d62 2e6c  d_xequal0 = mb.l
-00024eb0: 6f67 6963 616c 5f61 6e64 2878 3d79 5f6c  ogical_and(x=y_l
-00024ec0: 6573 735f 302c 2079 3d78 5f65 7175 616c  ess_0, y=x_equal
-00024ed0: 5f30 290a 0a20 2020 2023 2062 6f6f 6c20  _0)..    # bool 
-00024ee0: 2d3e 2066 7033 3220 666f 7220 6e75 6d65  -> fp32 for nume
-00024ef0: 7269 6320 6f70 6572 6174 696f 6e0a 2020  ric operation.  
-00024f00: 2020 7967 7265 6174 6572 305f 616e 645f    ygreater0_and_
-00024f10: 786c 6573 7330 5f6e 756d 6572 6963 203d  xless0_numeric =
-00024f20: 206d 622e 6361 7374 2878 3d79 6772 6561   mb.cast(x=ygrea
-00024f30: 7465 7230 5f61 6e64 5f78 6c65 7373 302c  ter0_and_xless0,
-00024f40: 2064 7479 7065 3d22 6670 3332 2229 0a20   dtype="fp32"). 
-00024f50: 2020 2079 6c65 7373 305f 616e 645f 786c     yless0_and_xl
-00024f60: 6573 7330 5f6e 756d 6572 6963 203d 206d  ess0_numeric = m
-00024f70: 622e 6361 7374 2878 3d79 6c65 7373 305f  b.cast(x=yless0_
-00024f80: 616e 645f 786c 6573 7330 2c20 6474 7970  and_xless0, dtyp
-00024f90: 653d 2266 7033 3222 290a 2020 2020 7967  e="fp32").    yg
-00024fa0: 7265 6174 6572 305f 616e 645f 7865 7175  reater0_and_xequ
-00024fb0: 616c 305f 6e75 6d65 7269 6320 3d20 6d62  al0_numeric = mb
-00024fc0: 2e63 6173 7428 783d 7967 7265 6174 6572  .cast(x=ygreater
-00024fd0: 305f 616e 645f 7865 7175 616c 302c 2064  0_and_xequal0, d
-00024fe0: 7479 7065 3d22 6670 3332 2229 0a20 2020  type="fp32").   
-00024ff0: 2079 6c65 7373 305f 616e 645f 7865 7175   yless0_and_xequ
-00025000: 616c 305f 6e75 6d65 7269 6320 3d20 6d62  al0_numeric = mb
-00025010: 2e63 6173 7428 783d 796c 6573 7330 5f61  .cast(x=yless0_a
-00025020: 6e64 5f78 6571 7561 6c30 2c20 6474 7970  nd_xequal0, dtyp
-00025030: 653d 2266 7033 3222 290a 0a20 2020 2023  e="fp32")..    #
-00025040: 2071 7561 6472 616e 7420 6d6f 6469 6669   quadrant modifi
-00025050: 6361 7469 6f6e 2063 6f65 6666 6963 6965  cation coefficie
-00025060: 6e74 730a 2020 2020 636f 6566 6631 203d  nts.    coeff1 =
-00025070: 206d 622e 6d75 6c28 783d 7967 7265 6174   mb.mul(x=ygreat
-00025080: 6572 305f 616e 645f 786c 6573 7330 5f6e  er0_and_xless0_n
-00025090: 756d 6572 6963 2c20 793d 5f6e 702e 7069  umeric, y=_np.pi
-000250a0: 290a 2020 2020 636f 6566 6632 203d 206d  ).    coeff2 = m
-000250b0: 622e 6d75 6c28 783d 796c 6573 7330 5f61  b.mul(x=yless0_a
-000250c0: 6e64 5f78 6c65 7373 305f 6e75 6d65 7269  nd_xless0_numeri
-000250d0: 632c 2079 3d5f 6e70 2e70 6929 0a20 2020  c, y=_np.pi).   
-000250e0: 2063 6f65 6666 3320 3d20 6d62 2e73 7562   coeff3 = mb.sub
-000250f0: 2878 3d31 2e30 2c20 793d 7967 7265 6174  (x=1.0, y=ygreat
-00025100: 6572 305f 616e 645f 7865 7175 616c 305f  er0_and_xequal0_
-00025110: 6e75 6d65 7269 6329 0a20 2020 2063 6f65  numeric).    coe
-00025120: 6666 3420 3d20 6d62 2e6d 756c 2878 3d79  ff4 = mb.mul(x=y
-00025130: 6772 6561 7465 7230 5f61 6e64 5f78 6571  greater0_and_xeq
-00025140: 7561 6c30 5f6e 756d 6572 6963 2c20 793d  ual0_numeric, y=
-00025150: 5f6e 702e 7069 202f 2032 2e30 290a 2020  _np.pi / 2.0).  
-00025160: 2020 636f 6566 6635 203d 206d 622e 7375    coeff5 = mb.su
-00025170: 6228 783d 312e 302c 2079 3d79 6c65 7373  b(x=1.0, y=yless
-00025180: 305f 616e 645f 7865 7175 616c 305f 6e75  0_and_xequal0_nu
-00025190: 6d65 7269 6329 0a20 2020 2063 6f65 6666  meric).    coeff
-000251a0: 3620 3d20 6d62 2e6d 756c 2878 3d79 6c65  6 = mb.mul(x=yle
-000251b0: 7373 305f 616e 645f 7865 7175 616c 305f  ss0_and_xequal0_
-000251c0: 6e75 6d65 7269 632c 2079 3d2d 5f6e 702e  numeric, y=-_np.
-000251d0: 7069 202f 2032 2e30 290a 0a20 2020 2023  pi / 2.0)..    #
-000251e0: 2069 6620 2d31 652d 3820 3c20 7820 3c20   if -1e-8 < x < 
-000251f0: 3165 2d38 2c20 7820 2b3d 2032 652d 3820  1e-8, x += 2e-8 
-00025200: 746f 2061 766f 6964 2079 202f 2030 0a20  to avoid y / 0. 
-00025210: 2020 2023 2074 6869 7320 7368 6966 7420     # this shift 
-00025220: 6d61 6b65 7320 6174 616e 3228 302c 2030  makes atan2(0, 0
-00025230: 2920 3d20 302c 2077 6869 6368 2069 7320  ) = 0, which is 
-00025240: 636f 6e73 6973 7465 6e74 2077 6974 6820  consistent with 
-00025250: 5079 546f 7263 6820 746f 7263 682e 6174  PyTorch torch.at
-00025260: 616e 320a 2020 2020 7830 6c65 6674 203d  an2.    x0left =
-00025270: 206d 622e 6772 6561 7465 7228 783d 782c   mb.greater(x=x,
-00025280: 2079 3d2d 3165 2d38 290a 2020 2020 7830   y=-1e-8).    x0
-00025290: 7269 6768 7420 3d20 6d62 2e6c 6573 7328  right = mb.less(
-000252a0: 783d 782c 2079 3d31 652d 3829 0a20 2020  x=x, y=1e-8).   
-000252b0: 2078 3020 3d20 6d62 2e6c 6f67 6963 616c   x0 = mb.logical
-000252c0: 5f61 6e64 2878 3d78 306c 6566 742c 2079  _and(x=x0left, y
-000252d0: 3d78 3072 6967 6874 290a 2020 2020 7830  =x0right).    x0
-000252e0: 6e75 6d65 7269 6320 3d20 6d62 2e63 6173  numeric = mb.cas
-000252f0: 7428 783d 7830 2c20 6474 7970 653d 2266  t(x=x0, dtype="f
-00025300: 7033 3222 290a 2020 2020 7361 6665 5f73  p32").    safe_s
-00025310: 6869 6674 203d 206d 622e 6d75 6c28 783d  hift = mb.mul(x=
-00025320: 7830 6e75 6d65 7269 632c 2079 3d32 652d  x0numeric, y=2e-
-00025330: 3829 0a20 2020 2078 5f73 6166 6520 3d20  8).    x_safe = 
-00025340: 6d62 2e61 6464 2878 3d78 2c20 793d 7361  mb.add(x=x, y=sa
-00025350: 6665 5f73 6869 6674 290a 0a20 2020 2023  fe_shift)..    #
-00025360: 2063 6f6d 7075 7465 2061 7461 6e28 7920   compute atan(y 
-00025370: 2f20 7829 0a20 2020 2079 6478 203d 206d  / x).    ydx = m
-00025380: 622e 7265 616c 5f64 6976 2878 3d79 2c20  b.real_div(x=y, 
-00025390: 793d 785f 7361 6665 290a 2020 2020 6174  y=x_safe).    at
-000253a0: 616e 325f 3120 3d20 6d62 2e61 7461 6e28  an2_1 = mb.atan(
-000253b0: 783d 7964 7829 0a0a 2020 2020 2320 616e  x=ydx)..    # an
-000253c0: 616c 797a 6520 7175 6164 7261 6e74 0a20  alyze quadrant. 
-000253d0: 2020 2061 7461 6e32 5f32 203d 206d 622e     atan2_2 = mb.
-000253e0: 6164 6428 783d 6174 616e 325f 312c 2079  add(x=atan2_1, y
-000253f0: 3d63 6f65 6666 3129 0a20 2020 2061 7461  =coeff1).    ata
-00025400: 6e32 5f33 203d 206d 622e 7375 6228 783d  n2_3 = mb.sub(x=
-00025410: 6174 616e 325f 322c 2079 3d63 6f65 6666  atan2_2, y=coeff
-00025420: 3229 0a20 2020 2061 7461 6e32 5f34 203d  2).    atan2_4 =
-00025430: 206d 622e 6d75 6c28 783d 6174 616e 325f   mb.mul(x=atan2_
-00025440: 332c 2079 3d63 6f65 6666 3329 0a20 2020  3, y=coeff3).   
-00025450: 2061 7461 6e32 5f35 203d 206d 622e 6164   atan2_5 = mb.ad
-00025460: 6428 783d 6174 616e 325f 342c 2079 3d63  d(x=atan2_4, y=c
-00025470: 6f65 6666 3429 0a20 2020 2061 7461 6e32  oeff4).    atan2
-00025480: 5f36 203d 206d 622e 6d75 6c28 783d 6174  _6 = mb.mul(x=at
-00025490: 616e 325f 352c 2079 3d63 6f65 6666 3529  an2_5, y=coeff5)
-000254a0: 0a20 2020 2063 6f6e 7465 7874 2e61 6464  .    context.add
-000254b0: 286d 622e 6164 6428 783d 6174 616e 325f  (mb.add(x=atan2_
-000254c0: 362c 2079 3d63 6f65 6666 362c 206e 616d  6, y=coeff6, nam
-000254d0: 653d 6e6f 6465 2e6e 616d 6529 290a 0a0a  e=node.name))...
-000254e0: 4072 6567 6973 7465 725f 746f 7263 685f  @register_torch_
-000254f0: 6f70 0a64 6566 2061 7461 6e68 2863 6f6e  op.def atanh(con
-00025500: 7465 7874 2c20 6e6f 6465 293a 0a20 2020  text, node):.   
-00025510: 2069 6e70 7574 7320 3d20 5f67 6574 5f69   inputs = _get_i
-00025520: 6e70 7574 7328 636f 6e74 6578 742c 206e  nputs(context, n
-00025530: 6f64 652c 2065 7870 6563 7465 643d 3129  ode, expected=1)
-00025540: 0a20 2020 2063 6f6e 7465 7874 2e61 6464  .    context.add
-00025550: 286d 622e 6174 616e 6828 783d 696e 7075  (mb.atanh(x=inpu
-00025560: 7473 5b30 5d2c 206e 616d 653d 6e6f 6465  ts[0], name=node
-00025570: 2e6e 616d 6529 290a 0a0a 4072 6567 6973  .name))...@regis
-00025580: 7465 725f 746f 7263 685f 6f70 0a64 6566  ter_torch_op.def
-00025590: 2063 6569 6c28 636f 6e74 6578 742c 206e   ceil(context, n
-000255a0: 6f64 6529 3a0a 2020 2020 696e 7075 7473  ode):.    inputs
-000255b0: 203d 205f 6765 745f 696e 7075 7473 2863   = _get_inputs(c
-000255c0: 6f6e 7465 7874 2c20 6e6f 6465 2c20 6578  ontext, node, ex
-000255d0: 7065 6374 6564 3d31 290a 2020 2020 636f  pected=1).    co
-000255e0: 6e74 6578 742e 6164 6428 6d62 2e63 6569  ntext.add(mb.cei
-000255f0: 6c28 783d 696e 7075 7473 5b30 5d2c 206e  l(x=inputs[0], n
-00025600: 616d 653d 6e6f 6465 2e6e 616d 6529 290a  ame=node.name)).
-00025610: 0a0a 4072 6567 6973 7465 725f 746f 7263  ..@register_torc
-00025620: 685f 6f70 0a64 6566 2063 6c61 6d70 2863  h_op.def clamp(c
-00025630: 6f6e 7465 7874 2c20 6e6f 6465 293a 0a20  ontext, node):. 
-00025640: 2020 2069 6e70 7574 7320 3d20 5f67 6574     inputs = _get
-00025650: 5f69 6e70 7574 7328 636f 6e74 6578 742c  _inputs(context,
-00025660: 206e 6f64 652c 2065 7870 6563 7465 643d   node, expected=
-00025670: 3329 0a20 2020 2078 203d 2069 6e70 7574  3).    x = input
-00025680: 735b 305d 0a20 2020 206d 696e 5f76 616c  s[0].    min_val
-00025690: 203d 2069 6e70 7574 735b 315d 2069 6620   = inputs[1] if 
-000256a0: 696e 7075 7473 5b31 5d20 656c 7365 205f  inputs[1] else _
-000256b0: 6e70 2e66 696e 666f 285f 6e70 2e66 6c6f  np.finfo(_np.flo
-000256c0: 6174 3332 292e 6d69 6e0a 2020 2020 6d61  at32).min.    ma
-000256d0: 785f 7661 6c20 3d20 696e 7075 7473 5b32  x_val = inputs[2
-000256e0: 5d20 6966 2069 6e70 7574 735b 325d 2065  ] if inputs[2] e
-000256f0: 6c73 6520 5f6e 702e 6669 6e66 6f28 5f6e  lse _np.finfo(_n
-00025700: 702e 666c 6f61 7433 3229 2e6d 6178 0a0a  p.float32).max..
-00025710: 2020 2020 6966 2069 7369 6e73 7461 6e63      if isinstanc
-00025720: 6528 6d69 6e5f 7661 6c2c 2056 6172 2920  e(min_val, Var) 
-00025730: 616e 6420 6973 696e 7374 616e 6365 286d  and isinstance(m
-00025740: 6178 5f76 616c 2c20 5661 7229 2061 6e64  ax_val, Var) and
-00025750: 206d 696e 5f76 616c 2e76 616c 203e 3d20   min_val.val >= 
-00025760: 6d61 785f 7661 6c2e 7661 6c3a 0a20 2020  max_val.val:.   
-00025770: 2020 2020 2023 2057 6865 6e20 6d69 6e20       # When min 
-00025780: 3e3d 206d 6178 2c20 5079 546f 7263 6820  >= max, PyTorch 
-00025790: 7365 7473 2061 6c6c 2076 616c 7565 7320  sets all values 
-000257a0: 746f 206d 6178 2e0a 2020 2020 2020 2020  to max..        
-000257b0: 636f 6e74 6578 742e 6164 6428 6d62 2e66  context.add(mb.f
-000257c0: 696c 6c28 7368 6170 653d 6d62 2e73 6861  ill(shape=mb.sha
-000257d0: 7065 2878 3d78 292c 2076 616c 7565 3d6d  pe(x=x), value=m
-000257e0: 6178 5f76 616c 2e76 616c 2c20 6e61 6d65  ax_val.val, name
-000257f0: 3d6e 6f64 652e 6e61 6d65 2929 0a20 2020  =node.name)).   
-00025800: 2020 2020 2072 6574 7572 6e0a 0a20 2020       return..   
-00025810: 2069 735f 696e 7075 745f 696e 7420 3d20   is_input_int = 
-00025820: 7479 7065 732e 6973 5f69 6e74 2878 2e64  types.is_int(x.d
-00025830: 7479 7065 290a 2020 2020 6966 206e 6f74  type).    if not
-00025840: 2074 7970 6573 2e69 735f 666c 6f61 7428   types.is_float(
-00025850: 782e 6474 7970 6529 3a0a 2020 2020 2020  x.dtype):.      
-00025860: 2020 2320 5468 6520 606d 622e 636c 6970    # The `mb.clip
-00025870: 6020 6f70 2072 6571 7569 7265 7320 7061  ` op requires pa
-00025880: 7261 6d65 7465 7273 2066 726f 6d20 7479  rameters from ty
-00025890: 7065 2064 6f6d 6169 6e20 5b27 6670 3136  pe domain ['fp16
-000258a0: 272c 2027 6670 3332 275d 2e0a 2020 2020  ', 'fp32']..    
-000258b0: 2020 2020 7820 3d20 6d62 2e63 6173 7428      x = mb.cast(
-000258c0: 783d 782c 2064 7479 7065 3d22 6670 3332  x=x, dtype="fp32
-000258d0: 2229 0a20 2020 2078 2c20 6d69 6e5f 7661  ").    x, min_va
-000258e0: 6c2c 206d 6178 5f76 616c 203d 2070 726f  l, max_val = pro
-000258f0: 6d6f 7465 5f69 6e70 7574 5f64 7479 7065  mote_input_dtype
-00025900: 7328 5b78 2c20 6d69 6e5f 7661 6c2c 206d  s([x, min_val, m
-00025910: 6178 5f76 616c 5d29 0a20 2020 2069 6620  ax_val]).    if 
-00025920: 6973 5f69 6e70 7574 5f69 6e74 3a0a 2020  is_input_int:.  
-00025930: 2020 2020 2020 636c 6970 5f72 6573 203d        clip_res =
-00025940: 206d 622e 636c 6970 2878 3d78 2c20 616c   mb.clip(x=x, al
-00025950: 7068 613d 6d69 6e5f 7661 6c2c 2062 6574  pha=min_val, bet
-00025960: 613d 6d61 785f 7661 6c29 0a20 2020 2020  a=max_val).     
-00025970: 2020 2063 6f6e 7465 7874 2e61 6464 286d     context.add(m
-00025980: 622e 6361 7374 2878 3d63 6c69 705f 7265  b.cast(x=clip_re
-00025990: 732c 2064 7479 7065 3d22 696e 7433 3222  s, dtype="int32"
-000259a0: 2c20 6e61 6d65 3d6e 6f64 652e 6e61 6d65  , name=node.name
-000259b0: 2929 0a20 2020 2065 6c73 653a 0a20 2020  )).    else:.   
-000259c0: 2020 2020 2063 6f6e 7465 7874 2e61 6464       context.add
-000259d0: 286d 622e 636c 6970 2878 3d78 2c20 616c  (mb.clip(x=x, al
-000259e0: 7068 613d 6d69 6e5f 7661 6c2c 2062 6574  pha=min_val, bet
-000259f0: 613d 6d61 785f 7661 6c2c 206e 616d 653d  a=max_val, name=
-00025a00: 6e6f 6465 2e6e 616d 6529 290a 0a0a 4072  node.name))...@r
-00025a10: 6567 6973 7465 725f 746f 7263 685f 6f70  egister_torch_op
-00025a20: 0a64 6566 2074 7269 7528 636f 6e74 6578  .def triu(contex
-00025a30: 742c 206e 6f64 6529 3a0a 2020 2020 696e  t, node):.    in
-00025a40: 7075 7473 203d 205f 6765 745f 696e 7075  puts = _get_inpu
-00025a50: 7473 2863 6f6e 7465 7874 2c20 6e6f 6465  ts(context, node
-00025a60: 2c20 6578 7065 6374 6564 3d32 290a 2020  , expected=2).  
-00025a70: 2020 7820 3d20 696e 7075 7473 5b30 5d0a    x = inputs[0].
-00025a80: 2020 2020 6469 6167 6f6e 616c 203d 2069      diagonal = i
-00025a90: 6e70 7574 735b 315d 0a20 2020 2064 6961  nputs[1].    dia
-00025aa0: 676f 6e61 6c20 3d20 3020 6966 2064 6961  gonal = 0 if dia
-00025ab0: 676f 6e61 6c20 6973 204e 6f6e 6520 656c  gonal is None el
-00025ac0: 7365 2064 6961 676f 6e61 6c2e 7661 6c0a  se diagonal.val.
-00025ad0: 2020 2020 6966 2064 6961 676f 6e61 6c20      if diagonal 
-00025ae0: 3c3d 2030 3a0a 2020 2020 2020 2020 7265  <= 0:.        re
-00025af0: 7320 3d20 6d62 2e62 616e 645f 7061 7274  s = mb.band_part
-00025b00: 2878 3d78 2c20 6c6f 7765 723d 2d64 6961  (x=x, lower=-dia
-00025b10: 676f 6e61 6c2c 2075 7070 6572 3d2d 312c  gonal, upper=-1,
-00025b20: 206e 616d 653d 6e6f 6465 2e6e 616d 6529   name=node.name)
-00025b30: 0a20 2020 2065 6c73 653a 0a20 2020 2020  .    else:.     
-00025b40: 2020 2079 203d 206d 622e 6261 6e64 5f70     y = mb.band_p
-00025b50: 6172 7428 783d 782c 206c 6f77 6572 3d2d  art(x=x, lower=-
-00025b60: 312c 2075 7070 6572 3d64 6961 676f 6e61  1, upper=diagona
-00025b70: 6c20 2d20 3129 0a20 2020 2020 2020 2072  l - 1).        r
-00025b80: 6573 203d 206d 622e 7375 6228 783d 782c  es = mb.sub(x=x,
-00025b90: 2079 3d79 2c20 6e61 6d65 3d6e 6f64 652e   y=y, name=node.
-00025ba0: 6e61 6d65 290a 2020 2020 636f 6e74 6578  name).    contex
-00025bb0: 742e 6164 6428 7265 7329 0a0a 0a40 7265  t.add(res)...@re
-00025bc0: 6769 7374 6572 5f74 6f72 6368 5f6f 700a  gister_torch_op.
-00025bd0: 6465 6620 7472 696c 2863 6f6e 7465 7874  def tril(context
-00025be0: 2c20 6e6f 6465 293a 0a20 2020 2069 6e70  , node):.    inp
-00025bf0: 7574 7320 3d20 5f67 6574 5f69 6e70 7574  uts = _get_input
-00025c00: 7328 636f 6e74 6578 742c 206e 6f64 652c  s(context, node,
-00025c10: 2065 7870 6563 7465 643d 3229 0a20 2020   expected=2).   
-00025c20: 2078 203d 2069 6e70 7574 735b 305d 0a20   x = inputs[0]. 
-00025c30: 2020 2064 6961 676f 6e61 6c20 3d20 696e     diagonal = in
-00025c40: 7075 7473 5b31 5d0a 2020 2020 6469 6167  puts[1].    diag
-00025c50: 6f6e 616c 203d 2030 2069 6620 6469 6167  onal = 0 if diag
-00025c60: 6f6e 616c 2069 7320 4e6f 6e65 2065 6c73  onal is None els
-00025c70: 6520 6469 6167 6f6e 616c 2e76 616c 0a20  e diagonal.val. 
-00025c80: 2020 2069 6620 6469 6167 6f6e 616c 203e     if diagonal >
-00025c90: 3d20 303a 0a20 2020 2020 2020 2072 6573  = 0:.        res
-00025ca0: 203d 206d 622e 6261 6e64 5f70 6172 7428   = mb.band_part(
-00025cb0: 783d 782c 206c 6f77 6572 3d2d 312c 2075  x=x, lower=-1, u
-00025cc0: 7070 6572 3d64 6961 676f 6e61 6c2c 206e  pper=diagonal, n
-00025cd0: 616d 653d 6e6f 6465 2e6e 616d 6529 0a20  ame=node.name). 
-00025ce0: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
-00025cf0: 2079 203d 206d 622e 6261 6e64 5f70 6172   y = mb.band_par
-00025d00: 7428 783d 782c 206c 6f77 6572 3d2d 6469  t(x=x, lower=-di
-00025d10: 6167 6f6e 616c 202d 2031 2c20 7570 7065  agonal - 1, uppe
-00025d20: 723d 2d31 290a 2020 2020 2020 2020 7265  r=-1).        re
-00025d30: 7320 3d20 6d62 2e73 7562 2878 3d78 2c20  s = mb.sub(x=x, 
-00025d40: 793d 792c 206e 616d 653d 6e6f 6465 2e6e  y=y, name=node.n
-00025d50: 616d 6529 0a20 2020 2063 6f6e 7465 7874  ame).    context
-00025d60: 2e61 6464 2872 6573 290a 0a0a 4072 6567  .add(res)...@reg
-00025d70: 6973 7465 725f 746f 7263 685f 6f70 0a64  ister_torch_op.d
-00025d80: 6566 2063 6f73 2863 6f6e 7465 7874 2c20  ef cos(context, 
-00025d90: 6e6f 6465 293a 0a20 2020 2069 6e70 7574  node):.    input
-00025da0: 7320 3d20 5f67 6574 5f69 6e70 7574 7328  s = _get_inputs(
-00025db0: 636f 6e74 6578 742c 206e 6f64 652c 2065  context, node, e
-00025dc0: 7870 6563 7465 643d 3129 0a20 2020 2063  xpected=1).    c
-00025dd0: 6f6e 7465 7874 2e61 6464 286d 622e 636f  ontext.add(mb.co
-00025de0: 7328 783d 696e 7075 7473 5b30 5d2c 206e  s(x=inputs[0], n
-00025df0: 616d 653d 6e6f 6465 2e6e 616d 6529 290a  ame=node.name)).
-00025e00: 0a0a 4072 6567 6973 7465 725f 746f 7263  ..@register_torc
-00025e10: 685f 6f70 0a64 6566 2063 6f73 6828 636f  h_op.def cosh(co
-00025e20: 6e74 6578 742c 206e 6f64 6529 3a0a 2020  ntext, node):.  
-00025e30: 2020 696e 7075 7473 203d 205f 6765 745f    inputs = _get_
-00025e40: 696e 7075 7473 2863 6f6e 7465 7874 2c20  inputs(context, 
-00025e50: 6e6f 6465 2c20 6578 7065 6374 6564 3d31  node, expected=1
-00025e60: 290a 2020 2020 636f 6e74 6578 742e 6164  ).    context.ad
-00025e70: 6428 6d62 2e63 6f73 6828 783d 696e 7075  d(mb.cosh(x=inpu
-00025e80: 7473 5b30 5d2c 206e 616d 653d 6e6f 6465  ts[0], name=node
-00025e90: 2e6e 616d 6529 290a 0a0a 4072 6567 6973  .name))...@regis
-00025ea0: 7465 725f 746f 7263 685f 6f70 0a64 6566  ter_torch_op.def
-00025eb0: 2065 7870 2863 6f6e 7465 7874 2c20 6e6f   exp(context, no
-00025ec0: 6465 293a 0a20 2020 2069 6e70 7574 7320  de):.    inputs 
-00025ed0: 3d20 5f67 6574 5f69 6e70 7574 7328 636f  = _get_inputs(co
-00025ee0: 6e74 6578 742c 206e 6f64 652c 2065 7870  ntext, node, exp
-00025ef0: 6563 7465 643d 3129 0a20 2020 2063 6f6e  ected=1).    con
-00025f00: 7465 7874 2e61 6464 286d 622e 6578 7028  text.add(mb.exp(
-00025f10: 783d 696e 7075 7473 5b30 5d2c 206e 616d  x=inputs[0], nam
-00025f20: 653d 6e6f 6465 2e6e 616d 6529 290a 0a0a  e=node.name))...
-00025f30: 4072 6567 6973 7465 725f 746f 7263 685f  @register_torch_
-00025f40: 6f70 0a64 6566 2065 7870 3228 636f 6e74  op.def exp2(cont
-00025f50: 6578 742c 206e 6f64 6529 3a0a 2020 2020  ext, node):.    
-00025f60: 696e 7075 7473 203d 205f 6765 745f 696e  inputs = _get_in
-00025f70: 7075 7473 2863 6f6e 7465 7874 2c20 6e6f  puts(context, no
-00025f80: 6465 2c20 6578 7065 6374 6564 3d31 290a  de, expected=1).
-00025f90: 2020 2020 636f 6e74 6578 742e 6164 6428      context.add(
-00025fa0: 6d62 2e65 7870 3228 783d 696e 7075 7473  mb.exp2(x=inputs
-00025fb0: 5b30 5d2c 206e 616d 653d 6e6f 6465 2e6e  [0], name=node.n
-00025fc0: 616d 6529 290a 0a0a 4072 6567 6973 7465  ame))...@registe
-00025fd0: 725f 746f 7263 685f 6f70 0a64 6566 2066  r_torch_op.def f
-00025fe0: 6c6f 6f72 2863 6f6e 7465 7874 2c20 6e6f  loor(context, no
-00025ff0: 6465 293a 0a20 2020 2069 6e70 7574 7320  de):.    inputs 
-00026000: 3d20 5f67 6574 5f69 6e70 7574 7328 636f  = _get_inputs(co
-00026010: 6e74 6578 742c 206e 6f64 652c 2065 7870  ntext, node, exp
-00026020: 6563 7465 643d 3129 0a20 2020 2063 6f6e  ected=1).    con
-00026030: 7465 7874 2e61 6464 286d 622e 666c 6f6f  text.add(mb.floo
-00026040: 7228 783d 696e 7075 7473 5b30 5d2c 206e  r(x=inputs[0], n
-00026050: 616d 653d 6e6f 6465 2e6e 616d 6529 290a  ame=node.name)).
-00026060: 0a0a 4072 6567 6973 7465 725f 746f 7263  ..@register_torc
-00026070: 685f 6f70 0a64 6566 2072 6563 6970 726f  h_op.def recipro
-00026080: 6361 6c28 636f 6e74 6578 742c 206e 6f64  cal(context, nod
-00026090: 6529 3a0a 2020 2020 696e 7075 7473 203d  e):.    inputs =
-000260a0: 205f 6765 745f 696e 7075 7473 2863 6f6e   _get_inputs(con
-000260b0: 7465 7874 2c20 6e6f 6465 2c20 6578 7065  text, node, expe
-000260c0: 6374 6564 3d31 290a 2020 2020 636f 6e74  cted=1).    cont
-000260d0: 6578 742e 6164 6428 6d62 2e69 6e76 6572  ext.add(mb.inver
-000260e0: 7365 2878 3d69 6e70 7574 735b 305d 2c20  se(x=inputs[0], 
-000260f0: 6e61 6d65 3d6e 6f64 652e 6e61 6d65 2929  name=node.name))
-00026100: 0a0a 0a40 7265 6769 7374 6572 5f74 6f72  ...@register_tor
-00026110: 6368 5f6f 700a 6465 6620 6c6f 6728 636f  ch_op.def log(co
-00026120: 6e74 6578 742c 206e 6f64 6529 3a0a 2020  ntext, node):.  
-00026130: 2020 696e 7075 7473 203d 205f 6765 745f    inputs = _get_
-00026140: 696e 7075 7473 2863 6f6e 7465 7874 2c20  inputs(context, 
-00026150: 6e6f 6465 2c20 6578 7065 6374 6564 3d31  node, expected=1
-00026160: 290a 2020 2020 636f 6e74 6578 742e 6164  ).    context.ad
-00026170: 6428 6d62 2e6c 6f67 2878 3d69 6e70 7574  d(mb.log(x=input
-00026180: 735b 305d 2c20 6e61 6d65 3d6e 6f64 652e  s[0], name=node.
-00026190: 6e61 6d65 2929 0a0a 0a40 7265 6769 7374  name))...@regist
-000261a0: 6572 5f74 6f72 6368 5f6f 7028 746f 7263  er_torch_op(torc
-000261b0: 685f 616c 6961 733d 5b22 726f 756e 6422  h_alias=["round"
-000261c0: 5d29 0a64 6566 205f 726f 756e 6428 636f  ]).def _round(co
-000261d0: 6e74 6578 742c 206e 6f64 6529 3a0a 2020  ntext, node):.  
-000261e0: 2020 696e 7075 7473 203d 205f 6765 745f    inputs = _get_
-000261f0: 696e 7075 7473 2863 6f6e 7465 7874 2c20  inputs(context, 
-00026200: 6e6f 6465 2c20 6578 7065 6374 6564 3d31  node, expected=1
-00026210: 290a 2020 2020 636f 6e74 6578 742e 6164  ).    context.ad
-00026220: 6428 6d62 2e72 6f75 6e64 2878 3d69 6e70  d(mb.round(x=inp
-00026230: 7574 735b 305d 2c20 6e61 6d65 3d6e 6f64  uts[0], name=nod
-00026240: 652e 6e61 6d65 2929 0a0a 0a40 7265 6769  e.name))...@regi
-00026250: 7374 6572 5f74 6f72 6368 5f6f 700a 6465  ster_torch_op.de
-00026260: 6620 7273 7172 7428 636f 6e74 6578 742c  f rsqrt(context,
-00026270: 206e 6f64 6529 3a0a 2020 2020 696e 7075   node):.    inpu
-00026280: 7473 203d 205f 6765 745f 696e 7075 7473  ts = _get_inputs
-00026290: 2863 6f6e 7465 7874 2c20 6e6f 6465 2c20  (context, node, 
-000262a0: 6578 7065 6374 6564 3d31 290a 2020 2020  expected=1).    
-000262b0: 636f 6e74 6578 742e 6164 6428 6d62 2e72  context.add(mb.r
-000262c0: 7371 7274 2878 3d69 6e70 7574 735b 305d  sqrt(x=inputs[0]
-000262d0: 2c20 6e61 6d65 3d6e 6f64 652e 6e61 6d65  , name=node.name
-000262e0: 2929 0a0a 0a40 7265 6769 7374 6572 5f74  ))...@register_t
-000262f0: 6f72 6368 5f6f 700a 6465 6620 7369 6e28  orch_op.def sin(
-00026300: 636f 6e74 6578 742c 206e 6f64 6529 3a0a  context, node):.
-00026310: 2020 2020 696e 7075 7473 203d 205f 6765      inputs = _ge
-00026320: 745f 696e 7075 7473 2863 6f6e 7465 7874  t_inputs(context
-00026330: 2c20 6e6f 6465 2c20 6578 7065 6374 6564  , node, expected
-00026340: 3d31 290a 2020 2020 636f 6e74 6578 742e  =1).    context.
-00026350: 6164 6428 6d62 2e73 696e 2878 3d69 6e70  add(mb.sin(x=inp
-00026360: 7574 735b 305d 2c20 6e61 6d65 3d6e 6f64  uts[0], name=nod
-00026370: 652e 6e61 6d65 2929 0a0a 0a40 7265 6769  e.name))...@regi
-00026380: 7374 6572 5f74 6f72 6368 5f6f 700a 6465  ster_torch_op.de
-00026390: 6620 7369 6e68 2863 6f6e 7465 7874 2c20  f sinh(context, 
-000263a0: 6e6f 6465 293a 0a20 2020 2069 6e70 7574  node):.    input
-000263b0: 7320 3d20 5f67 6574 5f69 6e70 7574 7328  s = _get_inputs(
-000263c0: 636f 6e74 6578 742c 206e 6f64 652c 2065  context, node, e
-000263d0: 7870 6563 7465 643d 3129 0a20 2020 2063  xpected=1).    c
-000263e0: 6f6e 7465 7874 2e61 6464 286d 622e 7369  ontext.add(mb.si
-000263f0: 6e68 2878 3d69 6e70 7574 735b 305d 2c20  nh(x=inputs[0], 
-00026400: 6e61 6d65 3d6e 6f64 652e 6e61 6d65 2929  name=node.name))
-00026410: 0a0a 0a40 7265 6769 7374 6572 5f74 6f72  ...@register_tor
-00026420: 6368 5f6f 700a 6465 6620 6173 696e 6828  ch_op.def asinh(
-00026430: 636f 6e74 6578 742c 206e 6f64 6529 3a0a  context, node):.
-00026440: 2020 2020 696e 7075 7473 203d 205f 6765      inputs = _ge
-00026450: 745f 696e 7075 7473 2863 6f6e 7465 7874  t_inputs(context
-00026460: 2c20 6e6f 6465 2c20 6578 7065 6374 6564  , node, expected
-00026470: 3d31 290a 2020 2020 636f 6e74 6578 742e  =1).    context.
-00026480: 6164 6428 6d62 2e61 7369 6e68 2878 3d69  add(mb.asinh(x=i
-00026490: 6e70 7574 735b 305d 2c20 6e61 6d65 3d6e  nputs[0], name=n
-000264a0: 6f64 652e 6e61 6d65 2929 0a0a 0a40 7265  ode.name))...@re
-000264b0: 6769 7374 6572 5f74 6f72 6368 5f6f 700a  gister_torch_op.
-000264c0: 6465 6620 7371 7274 2863 6f6e 7465 7874  def sqrt(context
-000264d0: 2c20 6e6f 6465 293a 0a20 2020 2069 6e70  , node):.    inp
-000264e0: 7574 7320 3d20 5f67 6574 5f69 6e70 7574  uts = _get_input
-000264f0: 7328 636f 6e74 6578 742c 206e 6f64 652c  s(context, node,
-00026500: 2065 7870 6563 7465 643d 3129 0a20 2020   expected=1).   
-00026510: 2063 6f6e 7465 7874 2e61 6464 286d 622e   context.add(mb.
-00026520: 7371 7274 2878 3d69 6e70 7574 735b 305d  sqrt(x=inputs[0]
-00026530: 2c20 6e61 6d65 3d6e 6f64 652e 6e61 6d65  , name=node.name
-00026540: 2929 0a0a 0a40 7265 6769 7374 6572 5f74  ))...@register_t
-00026550: 6f72 6368 5f6f 700a 6465 6620 7371 7561  orch_op.def squa
-00026560: 7265 2863 6f6e 7465 7874 2c20 6e6f 6465  re(context, node
-00026570: 293a 0a20 2020 2069 6e70 7574 7320 3d20  ):.    inputs = 
-00026580: 5f67 6574 5f69 6e70 7574 7328 636f 6e74  _get_inputs(cont
-00026590: 6578 742c 206e 6f64 652c 2065 7870 6563  ext, node, expec
-000265a0: 7465 643d 3129 0a20 2020 2023 206d 622e  ted=1).    # mb.
-000265b0: 7371 7561 7265 2069 7320 6e6f 7420 7375  square is not su
-000265c0: 7070 6f72 7465 6420 696e 2073 6f6d 6520  pported in some 
-000265d0: 6261 636b 656e 640a 2020 2020 636f 6e74  backend.    cont
-000265e0: 6578 742e 6164 6428 6d62 2e6d 756c 2878  ext.add(mb.mul(x
-000265f0: 3d69 6e70 7574 735b 305d 2c20 793d 696e  =inputs[0], y=in
-00026600: 7075 7473 5b30 5d2c 206e 616d 653d 6e6f  puts[0], name=no
-00026610: 6465 2e6e 616d 6529 290a 0a0a 4072 6567  de.name))...@reg
-00026620: 6973 7465 725f 746f 7263 685f 6f70 0a64  ister_torch_op.d
-00026630: 6566 2074 616e 2863 6f6e 7465 7874 2c20  ef tan(context, 
-00026640: 6e6f 6465 293a 0a20 2020 2069 6e70 7574  node):.    input
-00026650: 7320 3d20 5f67 6574 5f69 6e70 7574 7328  s = _get_inputs(
-00026660: 636f 6e74 6578 742c 206e 6f64 652c 2065  context, node, e
-00026670: 7870 6563 7465 643d 3129 0a20 2020 2063  xpected=1).    c
-00026680: 6f6e 7465 7874 2e61 6464 286d 622e 7461  ontext.add(mb.ta
-00026690: 6e28 783d 696e 7075 7473 5b30 5d2c 206e  n(x=inputs[0], n
-000266a0: 616d 653d 6e6f 6465 2e6e 616d 6529 290a  ame=node.name)).
-000266b0: 0a0a 4072 6567 6973 7465 725f 746f 7263  ..@register_torc
-000266c0: 685f 6f70 0a64 6566 2074 616e 6828 636f  h_op.def tanh(co
-000266d0: 6e74 6578 742c 206e 6f64 6529 3a0a 2020  ntext, node):.  
-000266e0: 2020 696e 7075 7473 203d 205f 6765 745f    inputs = _get_
-000266f0: 696e 7075 7473 2863 6f6e 7465 7874 2c20  inputs(context, 
-00026700: 6e6f 6465 2c20 6578 7065 6374 6564 3d31  node, expected=1
-00026710: 290a 2020 2020 636f 6e74 6578 742e 6164  ).    context.ad
-00026720: 6428 6d62 2e74 616e 6828 783d 696e 7075  d(mb.tanh(x=inpu
-00026730: 7473 5b30 5d2c 206e 616d 653d 6e6f 6465  ts[0], name=node
-00026740: 2e6e 616d 6529 290a 0a0a 4072 6567 6973  .name))...@regis
-00026750: 7465 725f 746f 7263 685f 6f70 0a64 6566  ter_torch_op.def
-00026760: 2074 6872 6573 686f 6c64 2863 6f6e 7465   threshold(conte
-00026770: 7874 2c20 6e6f 6465 293a 0a20 2020 2069  xt, node):.    i
-00026780: 6e70 7574 7320 3d20 5f67 6574 5f69 6e70  nputs = _get_inp
-00026790: 7574 7328 636f 6e74 6578 742c 206e 6f64  uts(context, nod
-000267a0: 652c 2065 7870 6563 7465 643d 3329 0a20  e, expected=3). 
-000267b0: 2020 2078 203d 2069 6e70 7574 735b 305d     x = inputs[0]
-000267c0: 0a20 2020 2061 6c70 6861 203d 2069 6e70  .    alpha = inp
-000267d0: 7574 735b 315d 0a20 2020 2074 6872 6573  uts[1].    thres
-000267e0: 686f 6c64 5f76 616c 203d 2069 6e70 7574  hold_val = input
-000267f0: 735b 325d 0a0a 2020 2020 2320 5369 6d70  s[2]..    # Simp
-00026800: 6c65 2063 6173 6520 2874 6872 6573 686f  le case (thresho
-00026810: 6c64 5f76 616c 203d 3d20 616c 7068 6129  ld_val == alpha)
-00026820: 0a20 2020 2069 6620 616c 7068 612e 7661  .    if alpha.va
-00026830: 6c20 3d3d 2074 6872 6573 686f 6c64 5f76  l == threshold_v
-00026840: 616c 2e76 616c 3a0a 2020 2020 2020 2020  al.val:.        
-00026850: 7468 7265 7368 6f6c 645f 6e6f 6465 203d  threshold_node =
-00026860: 206d 622e 7468 7265 7368 6f6c 6428 783d   mb.threshold(x=
-00026870: 782c 2061 6c70 6861 3d61 6c70 6861 2c20  x, alpha=alpha, 
-00026880: 6e61 6d65 3d6e 6f64 652e 6e61 6d65 290a  name=node.name).
-00026890: 2020 2020 2020 2020 636f 6e74 6578 742e          context.
-000268a0: 6164 6428 7468 7265 7368 6f6c 645f 6e6f  add(threshold_no
-000268b0: 6465 290a 2020 2020 2020 2020 7265 7475  de).        retu
-000268c0: 726e 0a0a 2020 2020 2320 436f 6d70 6c65  rn..    # Comple
-000268d0: 7820 6361 7365 2028 7468 7265 7368 6f6c  x case (threshol
-000268e0: 645f 7661 6c20 213d 2074 6872 6573 686f  d_val != thresho
-000268f0: 6c64 290a 2020 2020 7468 7265 7368 6f6c  ld).    threshol
-00026900: 645f 6e6f 6465 203d 206d 622e 7468 7265  d_node = mb.thre
-00026910: 7368 6f6c 6428 783d 782c 2061 6c70 6861  shold(x=x, alpha
-00026920: 3d61 6c70 6861 2c20 6e61 6d65 3d6e 6f64  =alpha, name=nod
-00026930: 652e 6e61 6d65 202b 2027 5f74 6872 6573  e.name + '_thres
-00026940: 686f 6c64 2729 0a20 2020 2063 6f6e 7465  hold').    conte
-00026950: 7874 2e61 6464 2874 6872 6573 686f 6c64  xt.add(threshold
-00026960: 5f6e 6f64 6529 0a0a 2020 2020 6774 5f6e  _node)..    gt_n
-00026970: 6f64 6520 3d20 6d62 2e67 7265 6174 6572  ode = mb.greater
-00026980: 5f65 7175 616c 2878 3d61 6c70 6861 2c20  _equal(x=alpha, 
-00026990: 793d 782c 206e 616d 653d 6e6f 6465 2e6e  y=x, name=node.n
-000269a0: 616d 6520 2b20 275f 6765 2729 0a20 2020  ame + '_ge').   
-000269b0: 2063 6f6e 7465 7874 2e61 6464 2867 745f   context.add(gt_
-000269c0: 6e6f 6465 290a 2020 2020 6774 5f6e 6f64  node).    gt_nod
-000269d0: 655f 3332 203d 206d 622e 6361 7374 2878  e_32 = mb.cast(x
-000269e0: 3d67 745f 6e6f 6465 2c20 6474 7970 653d  =gt_node, dtype=
-000269f0: 2266 7033 3222 2c20 6e61 6d65 3d6e 6f64  "fp32", name=nod
-00026a00: 652e 6e61 6d65 202b 2027 5f67 6533 3227  e.name + '_ge32'
-00026a10: 290a 0a20 2020 206d 756c 5f6e 6f64 6520  )..    mul_node 
-00026a20: 3d20 6d62 2e6c 696e 6561 725f 6163 7469  = mb.linear_acti
-00026a30: 7661 7469 6f6e 280a 2020 2020 2020 2020  vation(.        
-00026a40: 783d 6774 5f6e 6f64 655f 3332 2c0a 2020  x=gt_node_32,.  
-00026a50: 2020 2020 2020 616c 7068 613d 666c 6f61        alpha=floa
-00026a60: 7428 7468 7265 7368 6f6c 645f 7661 6c2e  t(threshold_val.
-00026a70: 7661 6c20 2d20 616c 7068 612e 7661 6c29  val - alpha.val)
-00026a80: 2c0a 2020 2020 2020 2020 6265 7461 3d30  ,.        beta=0
-00026a90: 2e2c 0a20 2020 2020 2020 206e 616d 653d  .,.        name=
-00026aa0: 6e6f 6465 2e6e 616d 6520 2b20 275f 6d75  node.name + '_mu
-00026ab0: 6c27 0a20 2020 2029 0a20 2020 2063 6f6e  l'.    ).    con
-00026ac0: 7465 7874 2e61 6464 286d 756c 5f6e 6f64  text.add(mul_nod
-00026ad0: 6529 0a0a 2020 2020 6669 6e61 6c5f 6e6f  e)..    final_no
-00026ae0: 6465 203d 206d 622e 6164 6428 783d 6d75  de = mb.add(x=mu
-00026af0: 6c5f 6e6f 6465 2c20 793d 7468 7265 7368  l_node, y=thresh
-00026b00: 6f6c 645f 6e6f 6465 2c20 6e61 6d65 3d6e  old_node, name=n
-00026b10: 6f64 652e 6e61 6d65 290a 2020 2020 636f  ode.name).    co
-00026b20: 6e74 6578 742e 6164 6428 6669 6e61 6c5f  ntext.add(final_
-00026b30: 6e6f 6465 290a 0a0a 4072 6567 6973 7465  node)...@registe
-00026b40: 725f 746f 7263 685f 6f70 0a64 6566 2073  r_torch_op.def s
-00026b50: 6967 6e28 636f 6e74 6578 742c 206e 6f64  ign(context, nod
-00026b60: 6529 3a0a 2020 2020 696e 7075 7473 203d  e):.    inputs =
-00026b70: 205f 6765 745f 696e 7075 7473 2863 6f6e   _get_inputs(con
-00026b80: 7465 7874 2c20 6e6f 6465 2c20 6578 7065  text, node, expe
-00026b90: 6374 6564 3d31 290a 2020 2020 636f 6e74  cted=1).    cont
-00026ba0: 6578 742e 6164 6428 6d62 2e73 6967 6e28  ext.add(mb.sign(
-00026bb0: 783d 696e 7075 7473 5b30 5d2c 206e 616d  x=inputs[0], nam
-00026bc0: 653d 6e6f 6465 2e6e 616d 6529 290a 0a0a  e=node.name))...
-00026bd0: 4072 6567 6973 7465 725f 746f 7263 685f  @register_torch_
-00026be0: 6f70 0a64 6566 2069 735f 666c 6f61 7469  op.def is_floati
-00026bf0: 6e67 5f70 6f69 6e74 2863 6f6e 7465 7874  ng_point(context
-00026c00: 2c20 6e6f 6465 293a 0a20 2020 2069 6e70  , node):.    inp
-00026c10: 7574 7320 3d20 5f67 6574 5f69 6e70 7574  uts = _get_input
-00026c20: 7328 636f 6e74 6578 742c 206e 6f64 652c  s(context, node,
-00026c30: 2065 7870 6563 7465 643d 3129 0a20 2020   expected=1).   
-00026c40: 2069 735f 666c 6f61 7420 3d20 7479 7065   is_float = type
-00026c50: 732e 6973 5f66 6c6f 6174 2869 6e70 7574  s.is_float(input
-00026c60: 735b 305d 2e64 7479 7065 290a 2020 2020  s[0].dtype).    
-00026c70: 636f 6e74 6578 742e 6164 6428 6d62 2e63  context.add(mb.c
-00026c80: 6f6e 7374 2876 616c 3d69 735f 666c 6f61  onst(val=is_floa
-00026c90: 742c 206e 616d 653d 6e6f 6465 2e6e 616d  t, name=node.nam
-00026ca0: 6529 290a 0a0a 4072 6567 6973 7465 725f  e))...@register_
-00026cb0: 746f 7263 685f 6f70 0a64 6566 206c 6f67  torch_op.def log
-00026cc0: 6963 616c 5f61 6e64 2863 6f6e 7465 7874  ical_and(context
-00026cd0: 2c20 6e6f 6465 293a 0a20 2020 2069 6e70  , node):.    inp
-00026ce0: 7574 7320 3d20 5f67 6574 5f69 6e70 7574  uts = _get_input
-00026cf0: 7328 636f 6e74 6578 742c 206e 6f64 652c  s(context, node,
-00026d00: 2065 7870 6563 7465 643d 3229 0a20 2020   expected=2).   
-00026d10: 2078 2c20 7920 3d20 696e 7075 7473 0a20   x, y = inputs. 
-00026d20: 2020 2078 203d 206d 622e 6361 7374 2878     x = mb.cast(x
-00026d30: 3d78 2c20 6474 7970 653d 2262 6f6f 6c22  =x, dtype="bool"
-00026d40: 290a 2020 2020 7920 3d20 6d62 2e63 6173  ).    y = mb.cas
-00026d50: 7428 783d 792c 2064 7479 7065 3d22 626f  t(x=y, dtype="bo
-00026d60: 6f6c 2229 0a20 2020 2063 6f6e 7465 7874  ol").    context
-00026d70: 2e61 6464 286d 622e 6c6f 6769 6361 6c5f  .add(mb.logical_
-00026d80: 616e 6428 783d 782c 2079 3d79 2c20 6e61  and(x=x, y=y, na
-00026d90: 6d65 3d6e 6f64 652e 6e61 6d65 2929 0a0a  me=node.name))..
-00026da0: 4072 6567 6973 7465 725f 746f 7263 685f  @register_torch_
-00026db0: 6f70 0a64 6566 206c 6f67 6963 616c 5f6f  op.def logical_o
-00026dc0: 7228 636f 6e74 6578 742c 206e 6f64 6529  r(context, node)
-00026dd0: 3a0a 2020 2020 696e 7075 7473 203d 205f  :.    inputs = _
-00026de0: 6765 745f 696e 7075 7473 2863 6f6e 7465  get_inputs(conte
-00026df0: 7874 2c20 6e6f 6465 2c20 6578 7065 6374  xt, node, expect
-00026e00: 6564 3d32 290a 2020 2020 782c 2079 203d  ed=2).    x, y =
-00026e10: 2069 6e70 7574 730a 2020 2020 7820 3d20   inputs.    x = 
-00026e20: 6d62 2e63 6173 7428 783d 782c 2064 7479  mb.cast(x=x, dty
-00026e30: 7065 3d22 626f 6f6c 2229 0a20 2020 2079  pe="bool").    y
-00026e40: 203d 206d 622e 6361 7374 2878 3d79 2c20   = mb.cast(x=y, 
-00026e50: 6474 7970 653d 2262 6f6f 6c22 290a 2020  dtype="bool").  
-00026e60: 2020 636f 6e74 6578 742e 6164 6428 6d62    context.add(mb
-00026e70: 2e6c 6f67 6963 616c 5f6f 7228 783d 782c  .logical_or(x=x,
-00026e80: 2079 3d79 2c20 6e61 6d65 3d6e 6f64 652e   y=y, name=node.
-00026e90: 6e61 6d65 2929 0a0a 0a40 7265 6769 7374  name))...@regist
-00026ea0: 6572 5f74 6f72 6368 5f6f 700a 6465 6620  er_torch_op.def 
-00026eb0: 6c6f 6769 6361 6c5f 786f 7228 636f 6e74  logical_xor(cont
-00026ec0: 6578 742c 206e 6f64 6529 3a0a 2020 2020  ext, node):.    
-00026ed0: 696e 7075 7473 203d 205f 6765 745f 696e  inputs = _get_in
-00026ee0: 7075 7473 2863 6f6e 7465 7874 2c20 6e6f  puts(context, no
-00026ef0: 6465 2c20 6578 7065 6374 6564 3d32 290a  de, expected=2).
-00026f00: 2020 2020 782c 2079 203d 2069 6e70 7574      x, y = input
-00026f10: 730a 2020 2020 7820 3d20 6d62 2e63 6173  s.    x = mb.cas
-00026f20: 7428 783d 782c 2064 7479 7065 3d22 626f  t(x=x, dtype="bo
-00026f30: 6f6c 2229 0a20 2020 2079 203d 206d 622e  ol").    y = mb.
-00026f40: 6361 7374 2878 3d79 2c20 6474 7970 653d  cast(x=y, dtype=
-00026f50: 2262 6f6f 6c22 290a 2020 2020 636f 6e74  "bool").    cont
-00026f60: 6578 742e 6164 6428 6d62 2e6c 6f67 6963  ext.add(mb.logic
-00026f70: 616c 5f78 6f72 2878 3d78 2c20 793d 792c  al_xor(x=x, y=y,
-00026f80: 206e 616d 653d 6e6f 6465 2e6e 616d 6529   name=node.name)
-00026f90: 290a 0a0a 6465 6620 5f6e 6f6e 7a65 726f  )...def _nonzero
-00026fa0: 5f61 735f 7475 706c 6528 636f 6e74 6578  _as_tuple(contex
-00026fb0: 742c 206e 6f64 652c 2078 293a 0a20 2020  t, node, x):.   
-00026fc0: 2027 2727 0a20 2020 2043 616c 6375 6c61   '''.    Calcula
-00026fd0: 7465 7320 7468 6520 6e6f 6e2d 7a65 726f  tes the non-zero
-00026fe0: 2065 6c65 6d65 6e74 7320 6f66 2078 2074   elements of x t
-00026ff0: 6865 6e20 736c 6963 6573 2072 6573 756c  hen slices resul
-00027000: 7473 2062 7920 6561 6368 2069 6e6e 6572  ts by each inner
-00027010: 2069 6e64 6578 2e0a 2020 2020 2727 270a   index..    '''.
-00027020: 2020 2020 6e6f 6e5f 7a65 726f 203d 206d      non_zero = m
-00027030: 622e 6e6f 6e5f 7a65 726f 2878 3d78 290a  b.non_zero(x=x).
-00027040: 0a20 2020 2072 6573 756c 7420 3d20 5b5d  .    result = []
-00027050: 0a20 2020 2066 6f72 2069 2069 6e20 7261  .    for i in ra
-00027060: 6e67 6528 782e 7261 6e6b 293a 0a20 2020  nge(x.rank):.   
-00027070: 2020 2020 2072 6573 756c 742e 6170 7065       result.appe
-00027080: 6e64 280a 2020 2020 2020 2020 2020 2020  nd(.            
-00027090: 6d62 2e73 6c69 6365 5f62 795f 696e 6465  mb.slice_by_inde
-000270a0: 7828 0a20 2020 2020 2020 2020 2020 2020  x(.             
-000270b0: 2020 2078 3d6e 6f6e 5f7a 6572 6f2c 0a20     x=non_zero,. 
-000270c0: 2020 2020 2020 2020 2020 2020 2020 2062                 b
-000270d0: 6567 696e 3d5b 302c 2069 5d2c 0a20 2020  egin=[0, i],.   
-000270e0: 2020 2020 2020 2020 2020 2020 2065 6e64               end
-000270f0: 3d5b 2d31 2c20 2d31 5d2c 2023 2049 676e  =[-1, -1], # Ign
-00027100: 6f72 6564 2c20 6275 7420 7265 7175 6972  ored, but requir
-00027110: 6564 0a20 2020 2020 2020 2020 2020 2020  ed.             
-00027120: 2020 2065 6e64 5f6d 6173 6b3d 5b54 7275     end_mask=[Tru
-00027130: 652c 2046 616c 7365 5d2c 0a20 2020 2020  e, False],.     
-00027140: 2020 2020 2020 2020 2020 2073 7175 6565             squee
-00027150: 7a65 5f6d 6173 6b3d 5b46 616c 7365 2c20  ze_mask=[False, 
-00027160: 5472 7565 5d0a 2020 2020 2020 2020 2020  True].          
-00027170: 2020 290a 2020 2020 2020 2020 290a 0a20    ).        ).. 
-00027180: 2020 2063 6f6e 7465 7874 2e61 6464 2872     context.add(r
-00027190: 6573 756c 742c 206e 6f64 652e 6e61 6d65  esult, node.name
-000271a0: 290a 0a0a 4072 6567 6973 7465 725f 746f  )...@register_to
-000271b0: 7263 685f 6f70 0a64 6566 2077 6865 7265  rch_op.def where
-000271c0: 2863 6f6e 7465 7874 2c20 6e6f 6465 293a  (context, node):
-000271d0: 0a20 2020 2069 6e70 7574 7320 3d20 5f67  .    inputs = _g
-000271e0: 6574 5f69 6e70 7574 7328 636f 6e74 6578  et_inputs(contex
-000271f0: 742c 206e 6f64 6529 0a0a 2020 2020 6966  t, node)..    if
-00027200: 206c 656e 2869 6e70 7574 7329 203d 3d20   len(inputs) == 
-00027210: 313a 0a20 2020 2020 2020 205f 6e6f 6e7a  1:.        _nonz
-00027220: 6572 6f5f 6173 5f74 7570 6c65 2863 6f6e  ero_as_tuple(con
-00027230: 7465 7874 2c20 6e6f 6465 2c20 696e 7075  text, node, inpu
-00027240: 7473 5b30 5d29 0a20 2020 2020 2020 2072  ts[0]).        r
-00027250: 6574 7572 6e0a 0a20 2020 2061 7373 6572  eturn..    asser
-00027260: 7420 6c65 6e28 696e 7075 7473 2920 3d3d  t len(inputs) ==
-00027270: 2033 0a20 2020 2063 6f6e 6420 3d20 696e   3.    cond = in
-00027280: 7075 7473 5b30 5d0a 2020 2020 6966 206e  puts[0].    if n
-00027290: 6f74 2074 7970 6573 2e69 735f 626f 6f6c  ot types.is_bool
-000272a0: 2863 6f6e 642e 6474 7970 6529 3a0a 2020  (cond.dtype):.  
-000272b0: 2020 2020 2020 2320 636f 6e64 206d 7573        # cond mus
-000272c0: 7420 6265 2062 6f6f 6c20 7479 7065 0a20  t be bool type. 
-000272d0: 2020 2020 2020 2063 6f6e 6420 3d20 6d62         cond = mb
-000272e0: 2e63 6173 7428 783d 636f 6e64 2c20 6474  .cast(x=cond, dt
-000272f0: 7970 653d 2262 6f6f 6c22 290a 2020 2020  ype="bool").    
-00027300: 6966 206e 6f74 2061 6e79 285b 616e 795f  if not any([any_
-00027310: 7379 6d62 6f6c 6963 2878 2e73 6861 7065  symbolic(x.shape
-00027320: 2920 666f 7220 7820 696e 2069 6e70 7574  ) for x in input
-00027330: 735b 3a33 5d5d 293a 0a20 2020 2020 2020  s[:3]]):.       
-00027340: 2023 2062 726f 6164 6361 7374 2061 6c6c   # broadcast all
-00027350: 2074 656e 736f 7273 2074 6f20 7468 6520   tensors to the 
-00027360: 7361 6d65 2073 6861 7065 0a20 2020 2020  same shape.     
-00027370: 2020 2062 726f 6164 6361 7374 5f69 6e70     broadcast_inp
-00027380: 7574 7320 3d20 5f62 726f 6164 6361 7374  uts = _broadcast
-00027390: 5f74 656e 736f 7273 285b 636f 6e64 2c20  _tensors([cond, 
-000273a0: 696e 7075 7473 5b31 5d2c 2069 6e70 7574  inputs[1], input
-000273b0: 735b 325d 5d29 0a20 2020 2020 2020 2072  s[2]]).        r
-000273c0: 6573 756c 7420 3d20 6d62 2e73 656c 6563  esult = mb.selec
-000273d0: 7428 0a20 2020 2020 2020 2020 2020 2063  t(.            c
-000273e0: 6f6e 643d 6272 6f61 6463 6173 745f 696e  ond=broadcast_in
-000273f0: 7075 7473 5b30 5d2c 0a20 2020 2020 2020  puts[0],.       
-00027400: 2020 2020 2061 3d62 726f 6164 6361 7374       a=broadcast
-00027410: 5f69 6e70 7574 735b 315d 2c0a 2020 2020  _inputs[1],.    
-00027420: 2020 2020 2020 2020 623d 6272 6f61 6463          b=broadc
-00027430: 6173 745f 696e 7075 7473 5b32 5d2c 0a20  ast_inputs[2],. 
-00027440: 2020 2020 2020 2020 2020 206e 616d 653d             name=
-00027450: 6e6f 6465 2e6e 616d 652c 0a20 2020 2020  node.name,.     
-00027460: 2020 2029 0a20 2020 2065 6c73 653a 0a20     ).    else:. 
-00027470: 2020 2020 2020 2072 6573 756c 7420 3d20         result = 
-00027480: 6d62 2e73 656c 6563 7428 636f 6e64 3d63  mb.select(cond=c
-00027490: 6f6e 642c 2061 3d69 6e70 7574 735b 315d  ond, a=inputs[1]
-000274a0: 2c20 623d 696e 7075 7473 5b32 5d2c 206e  , b=inputs[2], n
-000274b0: 616d 653d 6e6f 6465 2e6e 616d 6529 0a20  ame=node.name). 
-000274c0: 2020 2063 6f6e 7465 7874 2e61 6464 2872     context.add(r
-000274d0: 6573 756c 7429 0a0a 0a40 7265 6769 7374  esult)...@regist
-000274e0: 6572 5f74 6f72 6368 5f6f 700a 6465 6620  er_torch_op.def 
-000274f0: 6e6f 6e7a 6572 6f5f 6e75 6d70 7928 636f  nonzero_numpy(co
-00027500: 6e74 6578 742c 206e 6f64 6529 3a0a 2020  ntext, node):.  
-00027510: 2020 696e 7075 7473 203d 205f 6765 745f    inputs = _get_
-00027520: 696e 7075 7473 2863 6f6e 7465 7874 2c20  inputs(context, 
-00027530: 6e6f 6465 2c20 6578 7065 6374 6564 3d31  node, expected=1
-00027540: 290a 2020 2020 5f6e 6f6e 7a65 726f 5f61  ).    _nonzero_a
-00027550: 735f 7475 706c 6528 636f 6e74 6578 742c  s_tuple(context,
-00027560: 206e 6f64 652c 2069 6e70 7574 735b 305d   node, inputs[0]
-00027570: 290a 0a0a 4072 6567 6973 7465 725f 746f  )...@register_to
-00027580: 7263 685f 6f70 0a64 6566 206e 6567 2863  rch_op.def neg(c
-00027590: 6f6e 7465 7874 2c20 6e6f 6465 293a 0a20  ontext, node):. 
-000275a0: 2020 2069 6e70 7574 7320 3d20 5f67 6574     inputs = _get
-000275b0: 5f69 6e70 7574 7328 636f 6e74 6578 742c  _inputs(context,
-000275c0: 206e 6f64 652c 2065 7870 6563 7465 643d   node, expected=
-000275d0: 3129 0a20 2020 2078 2c20 7920 3d20 7072  1).    x, y = pr
-000275e0: 6f6d 6f74 655f 696e 7075 745f 6474 7970  omote_input_dtyp
-000275f0: 6573 285b 696e 7075 7473 5b30 5d2c 202d  es([inputs[0], -
-00027600: 315d 290a 2020 2020 636f 6e74 6578 742e  1]).    context.
-00027610: 6164 6428 6d62 2e6d 756c 2878 3d78 2c20  add(mb.mul(x=x, 
-00027620: 793d 792c 206e 616d 653d 6e6f 6465 2e6e  y=y, name=node.n
-00027630: 616d 6529 290a 0a40 7265 6769 7374 6572  ame))..@register
-00027640: 5f74 6f72 6368 5f6f 700a 6465 6620 746f  _torch_op.def to
-00027650: 706b 2863 6f6e 7465 7874 2c20 6e6f 6465  pk(context, node
-00027660: 293a 0a20 2020 2064 6566 2064 796e 616d  ):.    def dynam
-00027670: 6963 5f74 6f70 6b28 782c 206b 2c20 6178  ic_topk(x, k, ax
-00027680: 6973 2c20 6173 6365 6e64 696e 6729 3a0a  is, ascending):.
-00027690: 2020 2020 2020 2020 6173 7365 7274 206b          assert k
-000276a0: 2e76 616c 2069 7320 4e6f 6e65 2c20 2250  .val is None, "P
-000276b0: 6c65 6173 6520 7573 6520 6d62 2e74 6f70  lease use mb.top
-000276c0: 6b20 6469 7265 6374 6c79 2069 6620 6b20  k directly if k 
-000276d0: 6973 2063 6f6d 7069 6c65 2074 696d 6520  is compile time 
-000276e0: 6b6e 6f77 6e22 0a20 2020 2020 2020 2069  known".        i
-000276f0: 6e64 6963 6573 203d 206d 622e 6172 6773  ndices = mb.args
-00027700: 6f72 7428 783d 782c 2061 7869 733d 6178  ort(x=x, axis=ax
-00027710: 6973 2c20 6173 6365 6e64 696e 673d 6173  is, ascending=as
-00027720: 6365 6e64 696e 6729 0a20 2020 2020 2020  cending).       
-00027730: 2076 616c 7565 7320 3d20 6d62 2e67 6174   values = mb.gat
-00027740: 6865 725f 616c 6f6e 675f 6178 6973 2878  her_along_axis(x
-00027750: 3d78 2c20 696e 6469 6365 733d 696e 6469  =x, indices=indi
-00027760: 6365 732c 2061 7869 733d 6178 6973 290a  ces, axis=axis).
-00027770: 0a20 2020 2020 2020 206b 5f69 6e64 6963  .        k_indic
-00027780: 6573 203d 206d 622e 7261 6e67 655f 3164  es = mb.range_1d
-00027790: 2865 6e64 3d6b 2c20 7374 6172 743d 302c  (end=k, start=0,
-000277a0: 2073 7465 703d 3129 0a20 2020 2020 2020   step=1).       
-000277b0: 2076 616c 7565 7320 3d20 6d62 2e67 6174   values = mb.gat
-000277c0: 6865 7228 783d 7661 6c75 6573 2c20 696e  her(x=values, in
-000277d0: 6469 6365 733d 6b5f 696e 6469 6365 732c  dices=k_indices,
-000277e0: 2061 7869 733d 6178 6973 290a 2020 2020   axis=axis).    
-000277f0: 2020 2020 696e 6469 6365 7320 3d20 6d62      indices = mb
-00027800: 2e67 6174 6865 7228 783d 696e 6469 6365  .gather(x=indice
-00027810: 732c 2069 6e64 6963 6573 3d6b 5f69 6e64  s, indices=k_ind
-00027820: 6963 6573 2c20 6178 6973 3d61 7869 7329  ices, axis=axis)
-00027830: 0a0a 2020 2020 2020 2020 7265 7475 726e  ..        return
-00027840: 2076 616c 7565 732c 2069 6e64 6963 6573   values, indices
-00027850: 0a0a 2020 2020 696e 7075 7473 203d 205f  ..    inputs = _
-00027860: 6765 745f 696e 7075 7473 2863 6f6e 7465  get_inputs(conte
-00027870: 7874 2c20 6e6f 6465 290a 2020 2020 6b77  xt, node).    kw
-00027880: 6172 6773 203d 207b 226e 616d 6522 3a20  args = {"name": 
-00027890: 6e6f 6465 2e6e 616d 652c 2022 7822 3a20  node.name, "x": 
-000278a0: 696e 7075 7473 5b30 5d2c 2022 6b22 3a20  inputs[0], "k": 
-000278b0: 696e 7075 7473 5b31 5d7d 0a0a 2020 2020  inputs[1]}..    
-000278c0: 6966 206c 656e 2869 6e70 7574 7329 203e  if len(inputs) >
-000278d0: 2036 3a0a 2020 2020 2020 2020 7261 6973   6:.        rais
-000278e0: 6520 4578 6365 7074 696f 6e28 224e 756d  e Exception("Num
-000278f0: 6265 7220 6f66 2069 6e70 7574 7320 746f  ber of inputs to
-00027900: 2074 6f70 6b20 6578 6365 6564 7320 3622   topk exceeds 6"
-00027910: 290a 2020 2020 2320 6f70 7469 6f6e 616c  ).    # optional
-00027920: 3a20 4061 7869 730a 2020 2020 6966 206c  : @axis.    if l
-00027930: 656e 2869 6e70 7574 7329 203e 2032 3a0a  en(inputs) > 2:.
-00027940: 2020 2020 2020 2020 6966 2069 6e70 7574          if input
-00027950: 735b 325d 2069 7320 6e6f 7420 4e6f 6e65  s[2] is not None
-00027960: 3a0a 2020 2020 2020 2020 2020 2020 6b77  :.            kw
-00027970: 6172 6773 5b22 6178 6973 225d 203d 2069  args["axis"] = i
-00027980: 6e70 7574 735b 325d 2e76 616c 0a0a 2020  nputs[2].val..  
-00027990: 2020 2320 6f70 7469 6f6e 616c 3a20 4061    # optional: @a
-000279a0: 7363 656e 6469 6e67 0a20 2020 2069 6620  scending.    if 
-000279b0: 6c65 6e28 696e 7075 7473 2920 3e20 333a  len(inputs) > 3:
-000279c0: 0a20 2020 2020 2020 206c 6172 6765 7374  .        largest
-000279d0: 203d 2069 6e70 7574 735b 335d 2e76 616c   = inputs[3].val
-000279e0: 0a20 2020 2020 2020 206b 7761 7267 735b  .        kwargs[
-000279f0: 2261 7363 656e 6469 6e67 225d 203d 206e  "ascending"] = n
-00027a00: 6f74 206c 6172 6765 7374 0a0a 2020 2020  ot largest..    
-00027a10: 2320 6c61 7374 2069 6e70 7574 7320 746f  # last inputs to
-00027a20: 2074 6f70 6b20 6172 6520 6f70 7469 6f6e   topk are option
-00027a30: 616c 202d 2073 6f72 7465 6420 616e 6420  al - sorted and 
-00027a40: 6f75 742e 0a20 2020 2073 6f72 7420 3d20  out..    sort = 
-00027a50: 5472 7565 0a20 2020 2069 6620 6c65 6e28  True.    if len(
-00027a60: 696e 7075 7473 2920 3e20 343a 0a20 2020  inputs) > 4:.   
-00027a70: 2020 2020 2069 6620 696e 7075 7473 5b34       if inputs[4
-00027a80: 5d2e 7661 6c20 6973 2046 616c 7365 2061  ].val is False a
-00027a90: 6e64 206e 6f74 2069 735f 6375 7272 656e  nd not is_curren
-00027aa0: 745f 6f70 7365 745f 7665 7273 696f 6e5f  t_opset_version_
-00027ab0: 636f 6d70 6174 6962 6c65 5f77 6974 6828  compatible_with(
-00027ac0: 7461 7267 6574 2e69 4f53 3136 293a 0a20  target.iOS16):. 
-00027ad0: 2020 2020 2020 2020 2020 2072 6169 7365             raise
-00027ae0: 2045 7863 6570 7469 6f6e 2822 466f 7220   Exception("For 
-00027af0: 6f70 7365 7420 3c3d 2069 4f53 3136 2c20  opset <= iOS16, 
-00027b00: 6f6e 6c79 2073 6f72 7465 643d 5472 7565  only sorted=True
-00027b10: 2073 7570 706f 7274 6564 2066 6f72 2074   supported for t
-00027b20: 6865 2074 6f70 6b22 290a 2020 2020 2020  he topk").      
-00027b30: 2020 736f 7274 203d 2069 6e70 7574 735b    sort = inputs[
-00027b40: 345d 2e76 616c 0a0a 2020 2020 6966 206c  4].val..    if l
-00027b50: 656e 2869 6e70 7574 7329 203e 2035 3a0a  en(inputs) > 5:.
-00027b60: 2020 2020 2020 2020 6966 2069 6e70 7574          if input
-00027b70: 735b 355d 2069 7320 6e6f 7420 4e6f 6e65  s[5] is not None
-00027b80: 3a0a 2020 2020 2020 2020 2020 2020 7261  :.            ra
-00027b90: 6973 6520 4578 6365 7074 696f 6e28 0a20  ise Exception(. 
-00027ba0: 2020 2020 2020 2020 2020 2020 2020 2022                 "
-00027bb0: 556e 7375 7070 6f72 7465 6420 7661 6c75  Unsupported valu
-00027bc0: 6520 666f 7220 6172 6775 6d65 6e74 2027  e for argument '
-00027bd0: 6f75 7427 2069 6e20 746f 706b 2e20 5375  out' in topk. Su
-00027be0: 7070 6f72 7465 6420 7661 6c75 6573 3a20  pported values: 
-00027bf0: 4e6f 6e65 2c20 6275 7420 696e 7075 7420  None, but input 
-00027c00: 220a 2020 2020 2020 2020 2020 2020 2020  ".              
-00027c10: 2020 2269 7320 7b7d 222e 666f 726d 6174    "is {}".format
-00027c20: 2869 6e70 7574 735b 355d 2e76 616c 290a  (inputs[5].val).
-00027c30: 2020 2020 2020 2020 2020 2020 290a 0a20              ).. 
-00027c40: 2020 2069 6620 6973 5f63 7572 7265 6e74     if is_current
-00027c50: 5f6f 7073 6574 5f76 6572 7369 6f6e 5f63  _opset_version_c
-00027c60: 6f6d 7061 7469 626c 655f 7769 7468 2874  ompatible_with(t
-00027c70: 6172 6765 742e 694f 5331 3629 3a0a 2020  arget.iOS16):.  
-00027c80: 2020 2020 2020 6b77 6172 6773 5b22 736f        kwargs["so
-00027c90: 7274 225d 203d 2073 6f72 740a 0a20 2020  rt"] = sort..   
-00027ca0: 2069 6620 6b77 6172 6773 5b22 6b22 5d2e   if kwargs["k"].
-00027cb0: 7661 6c20 6973 204e 6f6e 653a 0a20 2020  val is None:.   
-00027cc0: 2020 2020 2072 6573 203d 2064 796e 616d       res = dynam
-00027cd0: 6963 5f74 6f70 6b28 0a20 2020 2020 2020  ic_topk(.       
-00027ce0: 2020 2020 2020 2020 2078 3d6b 7761 7267           x=kwarg
-00027cf0: 735b 2278 225d 2c0a 2020 2020 2020 2020  s["x"],.        
-00027d00: 2020 2020 2020 2020 6b3d 6b77 6172 6773          k=kwargs
-00027d10: 5b22 6b22 5d2c 0a20 2020 2020 2020 2020  ["k"],.         
-00027d20: 2020 2020 2020 2061 7869 733d 6b77 6172         axis=kwar
-00027d30: 6773 5b22 6178 6973 225d 2c0a 2020 2020  gs["axis"],.    
-00027d40: 2020 2020 2020 2020 2020 2020 6173 6365              asce
-00027d50: 6e64 696e 673d 6b77 6172 6773 5b22 6173  nding=kwargs["as
-00027d60: 6365 6e64 696e 6722 5d0a 2020 2020 2020  cending"].      
-00027d70: 2020 290a 2020 2020 656c 7365 3a0a 2020    ).    else:.  
-00027d80: 2020 2020 2020 7265 7320 3d20 6d62 2e74        res = mb.t
-00027d90: 6f70 6b28 2a2a 6b77 6172 6773 290a 0a20  opk(**kwargs).. 
-00027da0: 2020 2076 616c 7565 735f 6e61 6d65 203d     values_name =
-00027db0: 206e 6f64 652e 6f75 7470 7574 735b 305d   node.outputs[0]
-00027dc0: 0a20 2020 2069 6e64 6963 6573 5f6e 616d  .    indices_nam
-00027dd0: 6520 3d20 6e6f 6465 2e6f 7574 7075 7473  e = node.outputs
-00027de0: 5b31 5d0a 2020 2020 636f 6e74 6578 742e  [1].    context.
-00027df0: 6164 6428 7265 735b 305d 2c20 746f 7263  add(res[0], torc
-00027e00: 685f 6e61 6d65 3d76 616c 7565 735f 6e61  h_name=values_na
-00027e10: 6d65 290a 2020 2020 636f 6e74 6578 742e  me).    context.
-00027e20: 6164 6428 7265 735b 315d 2c20 746f 7263  add(res[1], torc
-00027e30: 685f 6e61 6d65 3d69 6e64 6963 6573 5f6e  h_name=indices_n
-00027e40: 616d 6529 0a0a 0a64 6566 205f 7374 6428  ame)...def _std(
-00027e50: 782c 2061 7865 732c 206b 6565 705f 6469  x, axes, keep_di
-00027e60: 6d2c 2075 6e62 6961 7365 642c 2065 7073  m, unbiased, eps
-00027e70: 293a 0a20 2020 206e 6565 645f 7265 7363  ):.    need_resc
-00027e80: 616c 6520 3d20 4661 6c73 650a 2020 2020  ale = False.    
-00027e90: 6966 2075 6e62 6961 7365 643a 0a20 2020  if unbiased:.   
-00027ea0: 2020 2020 2023 2049 6620 2275 6e62 6961       # If "unbia
-00027eb0: 7365 6422 2069 7320 5472 7565 2c0a 2020  sed" is True,.  
-00027ec0: 2020 2020 2020 2320 7468 656e 2077 6520        # then we 
-00027ed0: 6e65 6564 2074 6f20 6469 7669 6465 2062  need to divide b
-00027ee0: 7920 224e 2d31 2220 2869 6e73 7465 6164  y "N-1" (instead
-00027ef0: 206f 6620 224e 2229 2074 6f20 636f 6d70   of "N") to comp
-00027f00: 7574 6520 7468 6520 6d65 616e 206f 6620  ute the mean of 
-00027f10: 2878 2d45 5b78 5d29 5e32 0a20 2020 2020  (x-E[x])^2.     
-00027f20: 2020 2023 2066 6f72 2061 6e20 756e 6269     # for an unbi
-00027f30: 6173 6564 2065 7374 696d 6174 6520 6f66  ased estimate of
-00027f40: 2074 6865 2076 6172 6961 6e63 6520 2f20   the variance / 
-00027f50: 2073 7461 6e64 6172 6420 6465 7669 6174   standard deviat
-00027f60: 696f 6e2e 0a20 2020 2020 2020 2023 2049  ion..        # I
-00027f70: 6e20 7468 6520 7365 7175 656e 6365 206f  n the sequence o
-00027f80: 6620 4d49 4c20 6f70 7320 6164 6465 6420  f MIL ops added 
-00027f90: 6265 6c6f 772c 2077 6520 6669 7273 7420  below, we first 
-00027fa0: 636f 6d70 7574 6520 7468 6520 6d65 616e  compute the mean
-00027fb0: 2075 7369 6e67 2022 4e22 2c20 616e 6420   using "N", and 
-00027fc0: 6f6e 6c79 2069 6620 6974 7320 756e 6269  only if its unbi
-00027fd0: 6173 6564 0a20 2020 2020 2020 2023 2077  ased.        # w
-00027fe0: 6520 7265 7363 616c 6520 6c61 7465 722c  e rescale later,
-00027ff0: 2074 6865 2066 696e 616c 2072 6573 756c   the final resul
-00028000: 742e 0a20 2020 2020 2020 2023 2057 6520  t..        # We 
-00028010: 6967 6e6f 7265 2074 6865 2022 756e 6269  ignore the "unbi
-00028020: 6173 6564 2220 666c 6167 2c20 6966 2061  ased" flag, if a
-00028030: 6e79 206f 6620 7468 6520 6469 6d65 6e73  ny of the dimens
-00028040: 696f 6e73 2069 6e76 6f6c 7665 6420 696e  ions involved in
-00028050: 2074 6869 7320 6f70 6572 6174 696f 6e20   this operation 
-00028060: 6172 6520 6479 6e61 6d69 630a 2020 2020  are dynamic.    
-00028070: 2020 2020 2320 2877 6520 636f 756c 6420      # (we could 
-00028080: 6861 7665 2073 7469 6c6c 2068 616e 646c  have still handl
-00028090: 6564 2074 6861 7420 6361 7365 2062 7920  ed that case by 
-000280a0: 7573 696e 6720 2267 6574 5f73 6861 7065  using "get_shape
-000280b0: 2220 6574 6320 6f70 732c 2062 7574 2077  " etc ops, but w
-000280c0: 6520 646f 6e27 7420 646f 2074 6861 7420  e don't do that 
-000280d0: 6865 7265 2c0a 2020 2020 2020 2020 2320  here,.        # 
-000280e0: 7472 6164 696e 6720 7065 7266 6f72 6d61  trading performa
-000280f0: 6e63 6520 666f 7220 6e75 6d65 7269 6361  nce for numerica
-00028100: 6c20 6163 6375 7261 6379 290a 2020 2020  l accuracy).    
-00028110: 2020 2020 6966 2061 7865 7320 6973 204e      if axes is N
-00028120: 6f6e 653a 0a20 2020 2020 2020 2020 2020  one:.           
-00028130: 2069 6620 6e6f 7420 616e 795f 7379 6d62   if not any_symb
-00028140: 6f6c 6963 2878 2e73 6861 7065 2920 616e  olic(x.shape) an
-00028150: 6420 5f6e 702e 7072 6f64 2878 2e73 6861  d _np.prod(x.sha
-00028160: 7065 2920 3e20 313a 0a20 2020 2020 2020  pe) > 1:.       
-00028170: 2020 2020 2020 2020 204e 203d 205f 6e70           N = _np
-00028180: 2e70 726f 6428 782e 7368 6170 6529 0a20  .prod(x.shape). 
-00028190: 2020 2020 2020 2020 2020 2020 2020 206e                 n
-000281a0: 6565 645f 7265 7363 616c 6520 3d20 5472  eed_rescale = Tr
-000281b0: 7565 0a20 2020 2020 2020 2065 6c73 653a  ue.        else:
-000281c0: 0a20 2020 2020 2020 2020 2020 2064 696d  .            dim
-000281d0: 7320 3d20 5b5d 0a20 2020 2020 2020 2020  s = [].         
-000281e0: 2020 2023 2063 6f6c 6c65 6374 2064 696d     # collect dim
-000281f0: 656e 7369 6f6e 7320 636f 7272 6573 706f  ensions correspo
-00028200: 6e64 696e 6720 746f 2022 6178 6573 220a  nding to "axes".
-00028210: 2020 2020 2020 2020 2020 2020 666f 7220              for 
-00028220: 6178 6973 2069 6e20 6178 6573 3a0a 2020  axis in axes:.  
-00028230: 2020 2020 2020 2020 2020 2020 2020 6469                di
-00028240: 6d73 2e61 7070 656e 6428 782e 7368 6170  ms.append(x.shap
-00028250: 655b 6178 6973 5d29 0a20 2020 2020 2020  e[axis]).       
-00028260: 2020 2020 2069 6620 616c 6c28 5b6e 6f74       if all([not
-00028270: 2069 735f 7379 6d62 6f6c 6963 2873 2920   is_symbolic(s) 
-00028280: 666f 7220 7320 696e 2064 696d 735d 293a  for s in dims]):
-00028290: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000282a0: 204e 203d 205f 6e70 2e70 726f 6428 6469   N = _np.prod(di
-000282b0: 6d73 290a 2020 2020 2020 2020 2020 2020  ms).            
-000282c0: 2020 2020 6966 204e 203e 2031 3a0a 2020      if N > 1:.  
-000282d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000282e0: 2020 6e65 6564 5f72 6573 6361 6c65 203d    need_rescale =
-000282f0: 2054 7275 650a 2020 2020 6966 206e 6565   True.    if nee
-00028300: 645f 7265 7363 616c 653a 0a20 2020 2020  d_rescale:.     
-00028310: 2020 2072 6573 6361 6c65 5f66 6163 746f     rescale_facto
-00028320: 7220 3d20 5f6e 702e 7371 7274 284e 202f  r = _np.sqrt(N /
-00028330: 2066 6c6f 6174 284e 202d 2031 2929 0a0a   float(N - 1))..
-00028340: 2020 2020 785f 6d65 616e 203d 206d 622e      x_mean = mb.
-00028350: 7265 6475 6365 5f6d 6561 6e28 783d 782c  reduce_mean(x=x,
-00028360: 2061 7865 733d 6178 6573 2c20 6b65 6570   axes=axes, keep
-00028370: 5f64 696d 733d 5472 7565 290a 2020 2020  _dims=True).    
-00028380: 785f 6465 6d65 616e 6564 203d 206d 622e  x_demeaned = mb.
-00028390: 7375 6228 783d 782c 2079 3d78 5f6d 6561  sub(x=x, y=x_mea
-000283a0: 6e29 0a20 2020 2078 5f64 656d 6561 6e65  n).    x_demeane
-000283b0: 645f 7371 7561 7265 203d 206d 622e 7371  d_square = mb.sq
-000283c0: 7561 7265 2878 3d78 5f64 656d 6561 6e65  uare(x=x_demeane
-000283d0: 6429 0a20 2020 2078 5f64 656d 6561 6e65  d).    x_demeane
-000283e0: 645f 7371 7561 7265 5f6d 6561 6e20 3d20  d_square_mean = 
-000283f0: 6d62 2e72 6564 7563 655f 6d65 616e 2878  mb.reduce_mean(x
-00028400: 3d78 5f64 656d 6561 6e65 645f 7371 7561  =x_demeaned_squa
-00028410: 7265 2c20 6178 6573 3d61 7865 732c 206b  re, axes=axes, k
-00028420: 6565 705f 6469 6d73 3d6b 6565 705f 6469  eep_dims=keep_di
-00028430: 6d29 0a20 2020 2069 6620 6570 7320 3e20  m).    if eps > 
-00028440: 303a 0a20 2020 2020 2020 2078 5f64 656d  0:.        x_dem
-00028450: 6561 6e65 645f 7371 7561 7265 5f6d 6561  eaned_square_mea
-00028460: 6e20 3d20 6d62 2e61 6464 2878 3d78 5f64  n = mb.add(x=x_d
-00028470: 656d 6561 6e65 645f 7371 7561 7265 5f6d  emeaned_square_m
-00028480: 6561 6e2c 2079 3d65 7073 290a 2020 2020  ean, y=eps).    
-00028490: 6966 206e 6565 645f 7265 7363 616c 653a  if need_rescale:
-000284a0: 0a20 2020 2020 2020 2079 5f62 6566 6f72  .        y_befor
-000284b0: 655f 7363 616c 6520 3d20 6d62 2e73 7172  e_scale = mb.sqr
-000284c0: 7428 783d 785f 6465 6d65 616e 6564 5f73  t(x=x_demeaned_s
-000284d0: 7175 6172 655f 6d65 616e 290a 2020 2020  quare_mean).    
-000284e0: 2020 2020 7920 3d20 6d62 2e6d 756c 2878      y = mb.mul(x
-000284f0: 3d79 5f62 6566 6f72 655f 7363 616c 652c  =y_before_scale,
-00028500: 2079 3d72 6573 6361 6c65 5f66 6163 746f   y=rescale_facto
-00028510: 7229 0a20 2020 2065 6c73 653a 0a20 2020  r).    else:.   
-00028520: 2020 2020 2079 203d 206d 622e 7371 7274       y = mb.sqrt
-00028530: 2878 3d78 5f64 656d 6561 6e65 645f 7371  (x=x_demeaned_sq
-00028540: 7561 7265 5f6d 6561 6e29 0a20 2020 2072  uare_mean).    r
-00028550: 6574 7572 6e20 790a 0a40 7265 6769 7374  eturn y..@regist
-00028560: 6572 5f74 6f72 6368 5f6f 700a 6465 6620  er_torch_op.def 
-00028570: 6e75 6d65 6c28 636f 6e74 6578 742c 206e  numel(context, n
-00028580: 6f64 6529 3a0a 2020 2020 696e 7075 7473  ode):.    inputs
-00028590: 203d 205f 6765 745f 696e 7075 7473 2863   = _get_inputs(c
-000285a0: 6f6e 7465 7874 2c20 6e6f 6465 2c20 6578  ontext, node, ex
-000285b0: 7065 6374 6564 3d31 290a 2020 2020 7820  pected=1).    x 
-000285c0: 3d20 696e 7075 7473 5b30 5d0a 2020 2020  = inputs[0].    
-000285d0: 7820 3d20 6d62 2e73 6861 7065 2878 3d78  x = mb.shape(x=x
-000285e0: 290a 2020 2020 7820 3d20 6d62 2e72 6564  ).    x = mb.red
-000285f0: 7563 655f 7072 6f64 2878 3d78 2c20 6178  uce_prod(x=x, ax
-00028600: 6573 3d5b 305d 2c20 6e61 6d65 3d6e 6f64  es=[0], name=nod
-00028610: 652e 6e61 6d65 290a 2020 2020 636f 6e74  e.name).    cont
-00028620: 6578 742e 6164 6428 7829 0a0a 4072 6567  ext.add(x)..@reg
-00028630: 6973 7465 725f 746f 7263 685f 6f70 0a64  ister_torch_op.d
-00028640: 6566 2073 7464 2863 6f6e 7465 7874 2c20  ef std(context, 
-00028650: 6e6f 6465 293a 0a20 2020 2069 6e70 7574  node):.    input
-00028660: 7320 3d20 5f67 6574 5f69 6e70 7574 7328  s = _get_inputs(
-00028670: 636f 6e74 6578 742c 206e 6f64 6529 0a20  context, node). 
-00028680: 2020 2078 203d 2069 6e70 7574 735b 305d     x = inputs[0]
-00028690: 0a20 2020 2069 6620 6e6f 7420 286c 656e  .    if not (len
-000286a0: 2869 6e70 7574 7329 203d 3d20 3220 6f72  (inputs) == 2 or
-000286b0: 206c 656e 2869 6e70 7574 7329 203d 3d20   len(inputs) == 
-000286c0: 3429 3a0a 2020 2020 2020 2020 7261 6973  4):.        rais
-000286d0: 6520 5661 6c75 6545 7272 6f72 2822 4e75  e ValueError("Nu
-000286e0: 6d62 6572 206f 6620 696e 7075 7473 2074  mber of inputs t
-000286f0: 6f20 7468 6520 2773 7464 2720 6f70 206d  o the 'std' op m
-00028700: 7573 7420 6265 220a 2020 2020 2020 2020  ust be".        
-00028710: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00028720: 2022 3220 6f72 2034 2229 0a0a 2020 2020   "2 or 4")..    
-00028730: 6b65 6570 5f64 696d 203d 2046 616c 7365  keep_dim = False
-00028740: 0a20 2020 2061 7865 7320 3d20 4e6f 6e65  .    axes = None
-00028750: 0a20 2020 2069 6620 6c65 6e28 696e 7075  .    if len(inpu
-00028760: 7473 2920 3d3d 2032 3a0a 2020 2020 2020  ts) == 2:.      
-00028770: 2020 756e 6269 6173 6564 203d 2069 6e70    unbiased = inp
-00028780: 7574 735b 315d 2e76 616c 0a20 2020 2069  uts[1].val.    i
-00028790: 6620 6c65 6e28 696e 7075 7473 2920 3d3d  f len(inputs) ==
-000287a0: 2034 3a0a 2020 2020 2020 2020 6178 6573   4:.        axes
-000287b0: 203d 2069 6e70 7574 735b 315d 2e76 616c   = inputs[1].val
-000287c0: 0a20 2020 2020 2020 2069 6620 6973 696e  .        if isin
-000287d0: 7374 616e 6365 2861 7865 732c 2069 6e74  stance(axes, int
-000287e0: 293a 0a20 2020 2020 2020 2020 2020 2061  ):.            a
-000287f0: 7865 7320 3d20 5b61 7865 735d 0a20 2020  xes = [axes].   
-00028800: 2020 2020 2075 6e62 6961 7365 6420 3d20       unbiased = 
-00028810: 696e 7075 7473 5b32 5d2e 7661 6c0a 2020  inputs[2].val.  
-00028820: 2020 2020 2020 6b65 6570 5f64 696d 203d        keep_dim =
-00028830: 2069 6e70 7574 735b 335d 2e76 616c 0a0a   inputs[3].val..
-00028840: 2020 2020 7920 3d20 5f73 7464 2878 2c20      y = _std(x, 
-00028850: 6178 6573 2c20 6b65 6570 5f64 696d 2c20  axes, keep_dim, 
-00028860: 756e 6269 6173 6564 2c20 3029 0a20 2020  unbiased, 0).   
-00028870: 2063 6f6e 7465 7874 2e61 6464 2879 2c20   context.add(y, 
-00028880: 6e6f 6465 2e6e 616d 6529 0a0a 0a40 7265  node.name)...@re
-00028890: 6769 7374 6572 5f74 6f72 6368 5f6f 700a  gister_torch_op.
-000288a0: 6465 6620 636f 7079 2863 6f6e 7465 7874  def copy(context
-000288b0: 2c20 6e6f 6465 293a 0a20 2020 2069 6e70  , node):.    inp
-000288c0: 7574 7320 3d20 5f67 6574 5f69 6e70 7574  uts = _get_input
-000288d0: 7328 636f 6e74 6578 742c 206e 6f64 652c  s(context, node,
-000288e0: 2065 7870 6563 7465 643d 5b32 2c20 335d   expected=[2, 3]
-000288f0: 290a 2020 2020 636f 6e74 6578 742e 6164  ).    context.ad
-00028900: 6428 6d62 2e69 6465 6e74 6974 7928 783d  d(mb.identity(x=
-00028910: 696e 7075 7473 5b30 5d2c 206e 616d 653d  inputs[0], name=
-00028920: 6e6f 6465 2e6e 616d 6529 290a 0a0a 4072  node.name))...@r
-00028930: 6567 6973 7465 725f 746f 7263 685f 6f70  egister_torch_op
-00028940: 0a64 6566 2064 7479 7065 2863 6f6e 7465  .def dtype(conte
-00028950: 7874 2c20 6e6f 6465 293a 0a20 2020 2069  xt, node):.    i
-00028960: 6e70 7574 7320 3d20 5f67 6574 5f69 6e70  nputs = _get_inp
-00028970: 7574 7328 636f 6e74 6578 742c 206e 6f64  uts(context, nod
-00028980: 652c 2065 7870 6563 7465 643d 3129 0a20  e, expected=1). 
-00028990: 2020 2064 7479 7065 5f73 7472 203d 2069     dtype_str = i
-000289a0: 6e70 7574 735b 305d 2e64 7479 7065 2e5f  nputs[0].dtype._
-000289b0: 5f6e 616d 655f 5f0a 2020 2020 636f 6e74  _name__.    cont
-000289c0: 6578 742e 6164 6428 6d62 2e63 6f6e 7374  ext.add(mb.const
-000289d0: 2876 616c 3d64 7479 7065 5f73 7472 2c20  (val=dtype_str, 
-000289e0: 6e61 6d65 3d6e 6f64 652e 6e61 6d65 2929  name=node.name))
-000289f0: 0a0a 0a40 7265 6769 7374 6572 5f74 6f72  ...@register_tor
-00028a00: 6368 5f6f 700a 6465 6620 7465 6e73 6f72  ch_op.def tensor
-00028a10: 2863 6f6e 7465 7874 2c20 6e6f 6465 293a  (context, node):
-00028a20: 0a20 2020 2064 6566 205f 6d61 6b65 5f74  .    def _make_t
-00028a30: 656e 736f 7228 6c69 7374 5f6f 665f 7465  ensor(list_of_te
-00028a40: 6e73 6f72 2c20 6e61 6d65 2c20 7261 6e6b  nsor, name, rank
-00028a50: 293a 0a20 2020 2020 2020 2069 6620 7261  ):.        if ra
-00028a60: 6e6b 203d 3d20 363a 0a20 2020 2020 2020  nk == 6:.       
-00028a70: 2020 2020 2072 6169 7365 204e 6f74 496d       raise NotIm
-00028a80: 706c 656d 656e 7465 6445 7272 6f72 2822  plementedError("
-00028a90: 436f 7265 204d 4c20 6f6e 6c79 2073 7570  Core ML only sup
-00028aa0: 706f 7274 7320 7465 6e73 6f72 2072 616e  ports tensor ran
-00028ab0: 6b20 3c3d 2035 2e22 290a 2020 2020 2020  k <= 5.").      
-00028ac0: 2020 6966 206e 6f74 2069 7369 6e73 7461    if not isinsta
-00028ad0: 6e63 6528 6c69 7374 5f6f 665f 7465 6e73  nce(list_of_tens
-00028ae0: 6f72 2c20 6c69 7374 293a 0a20 2020 2020  or, list):.     
-00028af0: 2020 2020 2020 2072 6574 7572 6e20 6c69         return li
-00028b00: 7374 5f6f 665f 7465 6e73 6f72 0a20 2020  st_of_tensor.   
-00028b10: 2020 2020 2076 616c 7565 7320 3d20 5b0a       values = [.
-00028b20: 2020 2020 2020 2020 2020 2020 5f6d 616b              _mak
-00028b30: 655f 7465 6e73 6f72 2878 2c20 6e61 6d65  e_tensor(x, name
-00028b40: 202b 2022 5f72 5f22 202b 2073 7472 2869   + "_r_" + str(i
-00028b50: 292c 2072 616e 6b20 2b20 3129 0a20 2020  ), rank + 1).   
-00028b60: 2020 2020 2020 2020 2066 6f72 2069 2c20           for i, 
-00028b70: 7820 696e 2065 6e75 6d65 7261 7465 286c  x in enumerate(l
-00028b80: 6973 745f 6f66 5f74 656e 736f 7229 0a20  ist_of_tensor). 
-00028b90: 2020 2020 2020 205d 0a20 2020 2020 2020         ].       
-00028ba0: 2069 6620 6c65 6e28 7661 6c75 6573 2920   if len(values) 
-00028bb0: 3d3d 2031 3a0a 2020 2020 2020 2020 2020  == 1:.          
-00028bc0: 2020 7265 7475 726e 206d 622e 6578 7061    return mb.expa
-00028bd0: 6e64 5f64 696d 7328 783d 7661 6c75 6573  nd_dims(x=values
-00028be0: 5b30 5d2c 2061 7865 733d 5b30 5d2c 206e  [0], axes=[0], n
-00028bf0: 616d 653d 6e61 6d65 290a 2020 2020 2020  ame=name).      
-00028c00: 2020 7265 7475 726e 206d 622e 7374 6163    return mb.stac
-00028c10: 6b28 7661 6c75 6573 3d76 616c 7565 732c  k(values=values,
-00028c20: 2061 7869 733d 302c 206e 616d 653d 6e61   axis=0, name=na
-00028c30: 6d65 290a 0a20 2020 2069 6e70 7574 7320  me)..    inputs 
-00028c40: 3d20 5f67 6574 5f69 6e70 7574 7328 636f  = _get_inputs(co
-00028c50: 6e74 6578 742c 206e 6f64 652c 2065 7870  ntext, node, exp
-00028c60: 6563 7465 643d 3429 0a0a 2020 2020 2320  ected=4)..    # 
-00028c70: 4361 7365 2031 3a20 5573 696e 6720 746f  Case 1: Using to
-00028c80: 7263 682e 7465 6e73 6f72 2074 6f20 6372  rch.tensor to cr
-00028c90: 6561 7465 2061 2063 6f6e 7374 2074 656e  eate a const ten
-00028ca0: 736f 720a 2020 2020 2320 466f 7220 6578  sor.    # For ex
-00028cb0: 616d 706c 653a 0a20 2020 2023 2074 6f72  ample:.    # tor
-00028cc0: 6368 2e74 656e 736f 7228 5b5b 5b30 2c20  ch.tensor([[[0, 
-00028cd0: 305d 2c20 5b30 2c20 3130 5d2c 205b 352c  0], [0, 10], [5,
-00028ce0: 2031 305d 2c20 5b35 2c20 305d 5d5d 2c20   10], [5, 0]]], 
-00028cf0: 6474 7970 653d 746f 7263 682e 666c 6f61  dtype=torch.floa
-00028d00: 7433 3229 0a20 2020 2076 616c 203d 2069  t32).    val = i
-00028d10: 6e70 7574 735b 305d 0a20 2020 2069 6620  nputs[0].    if 
-00028d20: 6973 696e 7374 616e 6365 2876 616c 2c20  isinstance(val, 
-00028d30: 6c69 7374 293a 0a20 2020 2020 2020 2063  list):.        c
-00028d40: 6f6e 7465 7874 2e61 6464 285f 6d61 6b65  ontext.add(_make
-00028d50: 5f74 656e 736f 7228 7661 6c2c 206e 6f64  _tensor(val, nod
-00028d60: 652e 6e61 6d65 2c20 3129 290a 2020 2020  e.name, 1)).    
-00028d70: 2020 2020 7265 7475 726e 0a0a 2020 2020      return..    
-00028d80: 6966 2069 6e70 7574 735b 325d 2069 7320  if inputs[2] is 
-00028d90: 4e6f 6e65 3a0a 2020 2020 2020 2020 636f  None:.        co
-00028da0: 6e74 6578 742e 6164 6428 6d62 2e69 6465  ntext.add(mb.ide
-00028db0: 6e74 6974 7928 783d 7661 6c2c 206e 616d  ntity(x=val, nam
-00028dc0: 653d 6e6f 6465 2e6e 616d 6529 290a 2020  e=node.name)).  
-00028dd0: 2020 2020 2020 7265 7475 726e 0a0a 2020        return..  
-00028de0: 2020 2320 4361 7365 2032 3a20 4372 6561    # Case 2: Crea
-00028df0: 7465 2061 2074 656e 736f 7220 6669 6c6c  te a tensor fill
-00028e00: 6564 2077 6974 6820 6120 7369 6e67 6c65  ed with a single
-00028e10: 2076 616c 7565 0a20 2020 2076 616c 203d   value.    val =
-00028e20: 2076 616c 2e76 616c 2020 2320 656c 656d   val.val  # elem
-00028e30: 656e 7420 7661 6c20 746f 2066 696c 6c0a  ent val to fill.
-00028e40: 2020 2020 6d73 675f 7072 6566 6978 203d      msg_prefix =
-00028e50: 2027 746f 7263 683a 3a74 656e 736f 7220   'torch::tensor 
-00028e60: 7b7d 2027 2e66 6f72 6d61 7428 6e6f 6465  {} '.format(node
-00028e70: 2e6e 616d 6529 0a20 2020 2069 6620 7661  .name).    if va
-00028e80: 6c20 6973 204e 6f6e 653a 0a20 2020 2020  l is None:.     
-00028e90: 2020 2072 6169 7365 2056 616c 7565 4572     raise ValueEr
-00028ea0: 726f 7228 6d73 675f 7072 6566 6978 202b  ror(msg_prefix +
-00028eb0: 2027 7661 6c20 6973 204e 6f6e 6527 290a   'val is None').
-00028ec0: 2020 2020 6474 7970 655f 7374 7220 3d20      dtype_str = 
-00028ed0: 696e 7075 7473 5b31 5d2e 7661 6c0a 2020  inputs[1].val.  
-00028ee0: 2020 6966 2064 7479 7065 5f73 7472 2021    if dtype_str !
-00028ef0: 3d20 2266 7033 3222 3a0a 2020 2020 2020  = "fp32":.      
-00028f00: 2020 7261 6973 6520 4e6f 7449 6d70 6c65    raise NotImple
-00028f10: 6d65 6e74 6564 4572 726f 7228 0a20 2020  mentedError(.   
-00028f20: 2020 2020 2020 2020 206d 7367 5f70 7265           msg_pre
-00028f30: 6669 7820 2b20 2255 6e73 7570 706f 7274  fix + "Unsupport
-00028f40: 6564 2064 7479 7065 3a20 7b7d 222e 666f  ed dtype: {}".fo
-00028f50: 726d 6174 2864 7479 7065 5f73 7472 290a  rmat(dtype_str).
-00028f60: 2020 2020 2020 2020 290a 2020 2020 2320          ).    # 
-00028f70: 696e 7075 7473 5b33 5d20 6973 2061 2062  inputs[3] is a b
-00028f80: 6f6f 6c20 286e 6f74 2073 7572 6520 7768  ool (not sure wh
-00028f90: 6174 2069 7420 6973 290a 2020 2020 7368  at it is).    sh
-00028fa0: 6170 6520 3d20 6d62 2e73 6861 7065 2878  ape = mb.shape(x
-00028fb0: 3d69 6e70 7574 735b 325d 2c20 6e61 6d65  =inputs[2], name
-00028fc0: 3d6e 6f64 652e 6e61 6d65 202b 2022 5f73  =node.name + "_s
-00028fd0: 6861 7065 2229 0a20 2020 2063 6f6e 7465  hape").    conte
-00028fe0: 7874 2e61 6464 286d 622e 6669 6c6c 2873  xt.add(mb.fill(s
-00028ff0: 6861 7065 3d73 6861 7065 2c20 7661 6c75  hape=shape, valu
-00029000: 653d 7661 6c2c 206e 616d 653d 6e6f 6465  e=val, name=node
-00029010: 2e6e 616d 6529 290a 0a0a 2222 220a 5061  .name))...""".Pa
-00029020: 636b 2061 6e64 2075 6e70 6163 6b20 6f70  ck and unpack op
-00029030: 2069 6e20 7079 746f 7263 682e 0a54 6865   in pytorch..The
-00029040: 2074 7970 6963 616c 2070 6174 7465 726e   typical pattern
-00029050: 2069 7320 6173 2066 6f6c 6c6f 7769 6e67   is as following
-00029060: 0a0a 3e3e 3e20 7365 7120 3d20 746f 7263  ..>>> seq = torc
-00029070: 682e 7465 6e73 6f72 285b 5b31 2c32 2c30  h.tensor([[1,2,0
-00029080: 5d2c 205b 332c 302c 305d 2c20 5b34 2c35  ], [3,0,0], [4,5
-00029090: 2c36 5d5d 290a 3e3e 3e20 6c65 6e73 203d  ,6]]).>>> lens =
-000290a0: 205b 322c 2031 2c20 335d 0a3e 3e3e 2070   [2, 1, 3].>>> p
-000290b0: 6163 6b65 6420 3d20 7061 636b 5f70 6164  acked = pack_pad
-000290c0: 6465 645f 7365 7175 656e 6365 2873 6571  ded_sequence(seq
-000290d0: 2c20 6c65 6e73 2c20 6261 7463 685f 6669  , lens, batch_fi
-000290e0: 7273 743d 5472 7565 2c20 656e 666f 7263  rst=True, enforc
-000290f0: 655f 736f 7274 6564 3d46 616c 7365 290a  e_sorted=False).
-00029100: 3e3e 3e20 7061 636b 6564 0a50 6163 6b65  >>> packed.Packe
-00029110: 6453 6571 7565 6e63 6528 6461 7461 3d74  dSequence(data=t
-00029120: 656e 736f 7228 5b34 2c20 312c 2033 2c20  ensor([4, 1, 3, 
-00029130: 352c 2032 2c20 365d 292c 2062 6174 6368  5, 2, 6]), batch
-00029140: 5f73 697a 6573 3d74 656e 736f 7228 5b33  _sizes=tensor([3
-00029150: 2c20 322c 2031 5d29 2c0a 2020 2020 2020  , 2, 1]),.      
-00029160: 2020 2020 2020 2020 2073 6f72 7465 645f           sorted_
-00029170: 696e 6469 6365 733d 7465 6e73 6f72 285b  indices=tensor([
-00029180: 322c 2030 2c20 315d 292c 2075 6e73 6f72  2, 0, 1]), unsor
-00029190: 7465 645f 696e 6469 6365 733d 7465 6e73  ted_indices=tens
-000291a0: 6f72 285b 312c 2032 2c20 305d 2929 0a3e  or([1, 2, 0])).>
-000291b0: 3e3e 2073 6571 5f75 6e70 6163 6b65 642c  >> seq_unpacked,
-000291c0: 206c 656e 735f 756e 7061 636b 6564 203d   lens_unpacked =
-000291d0: 2070 6164 5f70 6163 6b65 645f 7365 7175   pad_packed_sequ
-000291e0: 656e 6365 2870 6163 6b65 642c 2062 6174  ence(packed, bat
-000291f0: 6368 5f66 6972 7374 3d54 7275 6529 0a3e  ch_first=True).>
-00029200: 3e3e 2073 6571 5f75 6e70 6163 6b65 640a  >> seq_unpacked.
-00029210: 7465 6e73 6f72 285b 5b31 2c20 322c 2030  tensor([[1, 2, 0
-00029220: 5d2c 0a20 2020 2020 2020 205b 332c 2030  ],.        [3, 0
-00029230: 2c20 305d 2c0a 2020 2020 2020 2020 5b34  , 0],.        [4
-00029240: 2c20 352c 2036 5d5d 290a 3e3e 3e20 6c65  , 5, 6]]).>>> le
-00029250: 6e73 5f75 6e70 6163 6b65 640a 7465 6e73  ns_unpacked.tens
-00029260: 6f72 285b 322c 2031 2c20 335d 290a 0a73  or([2, 1, 3])..s
-00029270: 6f75 7263 6520 6672 6f6d 2068 7474 7073  ource from https
-00029280: 3a2f 2f70 7974 6f72 6368 2e6f 7267 2f64  ://pytorch.org/d
-00029290: 6f63 732f 7374 6162 6c65 2f67 656e 6572  ocs/stable/gener
-000292a0: 6174 6564 2f74 6f72 6368 2e6e 6e2e 7574  ated/torch.nn.ut
-000292b0: 696c 732e 726e 6e2e 7061 645f 7061 636b  ils.rnn.pad_pack
-000292c0: 6564 5f73 6571 7565 6e63 652e 6874 6d6c  ed_sequence.html
-000292d0: 0a22 2222 0a0a 0a40 7265 6769 7374 6572  ."""...@register
-000292e0: 5f74 6f72 6368 5f6f 700a 6465 6620 5f70  _torch_op.def _p
-000292f0: 6163 6b5f 7061 6464 6564 5f73 6571 7565  ack_padded_seque
-00029300: 6e63 6528 636f 6e74 6578 742c 206e 6f64  nce(context, nod
-00029310: 6529 3a0a 2020 2020 2320 5468 6520 696d  e):.    # The im
-00029320: 706c 656d 656e 7461 7469 6f6e 206f 6620  plementation of 
-00029330: 7468 6973 206f 7020 6973 206e 6f74 2065  this op is not e
-00029340: 6666 6963 6965 6e74 2e20 5261 6973 6520  fficient. Raise 
-00029350: 6120 7761 726e 696e 672e 0a20 2020 206c  a warning..    l
-00029360: 6f67 6765 722e 7761 726e 696e 6728 0a20  ogger.warning(. 
-00029370: 2020 2020 2020 2022 456e 636f 756e 7465         "Encounte
-00029380: 7265 6420 6120 5f70 6163 6b5f 7061 6464  red a _pack_padd
-00029390: 6564 5f73 6571 7565 6e63 6520 6c61 7965  ed_sequence laye
-000293a0: 722e 2054 6865 2069 6d70 6c65 6d65 6e74  r. The implement
-000293b0: 6174 696f 6e20 6f66 2074 7261 6e73 6c61  ation of transla
-000293c0: 7469 6e67 2070 6163 6b2f 756e 7061 636b  ting pack/unpack
-000293d0: 206f 705c 0a20 2020 2020 2020 2069 6e20   op\.        in 
-000293e0: 7079 746f 7263 6820 6973 206e 6f74 2065  pytorch is not e
-000293f0: 6666 6963 6965 6e74 2064 7565 2074 6f20  fficient due to 
-00029400: 7468 6520 6375 7272 656e 7420 6c69 6d69  the current limi
-00029410: 7461 7469 6f6e 206f 6620 436f 7265 204d  tation of Core M
-00029420: 4c2e 2052 656d 6f76 696e 6720 7468 6520  L. Removing the 
-00029430: 7061 636b 2d75 6e70 6163 6b20 6c6f 6769  pack-unpack logi
-00029440: 6320 5c0a 2020 2020 2020 2020 616e 6420  c \.        and 
-00029450: 7573 6520 6120 6669 7865 6420 6261 7463  use a fixed batc
-00029460: 6820 7369 7a65 206d 6f64 656c 2069 7320  h size model is 
-00029470: 7265 636f 6d6d 656e 6465 642e 220a 2020  recommended.".  
-00029480: 2020 290a 0a20 2020 2069 6e70 7574 7320    )..    inputs 
-00029490: 3d20 5f67 6574 5f69 6e70 7574 7328 636f  = _get_inputs(co
-000294a0: 6e74 6578 742c 206e 6f64 652c 2065 7870  ntext, node, exp
-000294b0: 6563 7465 643d 3329 0a20 2020 2074 656e  ected=3).    ten
-000294c0: 736f 725f 6e61 6d65 2c20 6261 7463 685f  sor_name, batch_
-000294d0: 7369 7a65 735f 6e61 6d65 203d 206e 6f64  sizes_name = nod
-000294e0: 652e 6f75 7470 7574 730a 2020 2020 7465  e.outputs.    te
-000294f0: 6e73 6f72 5f69 6e70 7574 203d 2069 6e70  nsor_input = inp
-00029500: 7574 735b 305d 0a20 2020 2062 6174 6368  uts[0].    batch
-00029510: 5f73 697a 6573 203d 2069 6e70 7574 735b  _sizes = inputs[
-00029520: 315d 0a20 2020 2062 6174 6368 5f66 6972  1].    batch_fir
-00029530: 7374 203d 2069 6e70 7574 735b 325d 2e76  st = inputs[2].v
-00029540: 616c 0a0a 2020 2020 2320 6279 2061 7373  al..    # by ass
-00029550: 756d 696e 6720 7468 6174 2074 6865 206f  uming that the o
-00029560: 7574 7075 7420 6f66 2074 6869 7320 6f70  utput of this op
-00029570: 2069 7320 616c 7761 7973 2066 6565 6420   is always feed 
-00029580: 696e 206c 7374 6d20 6c61 7965 722c 0a20  in lstm layer,. 
-00029590: 2020 2023 2077 6520 656e 666f 7263 6520     # we enforce 
-000295a0: 7468 6520 6c61 796f 7574 2074 6f20 6265  the layout to be
-000295b0: 2042 6174 6368 202a 2073 6571 5f6c 656e   Batch * seq_len
-000295c0: 6774 6820 2a20 4665 6174 7572 652e 0a20  gth * Feature.. 
-000295d0: 2020 2069 6620 6e6f 7420 6261 7463 685f     if not batch_
-000295e0: 6669 7273 743a 0a20 2020 2020 2020 2074  first:.        t
-000295f0: 656e 736f 725f 696e 7075 7420 3d20 6d62  ensor_input = mb
-00029600: 2e74 7261 6e73 706f 7365 2878 3d74 656e  .transpose(x=ten
-00029610: 736f 725f 696e 7075 742c 2070 6572 6d3d  sor_input, perm=
-00029620: 5b31 2c20 302c 2032 5d29 0a20 2020 2063  [1, 0, 2]).    c
-00029630: 6f6e 7465 7874 2e61 6464 286d 622e 6964  ontext.add(mb.id
-00029640: 656e 7469 7479 2878 3d74 656e 736f 725f  entity(x=tensor_
-00029650: 696e 7075 742c 206e 616d 653d 7465 6e73  input, name=tens
-00029660: 6f72 5f6e 616d 6529 290a 0a20 2020 2023  or_name))..    #
-00029670: 2061 6464 2074 6865 2062 6174 6368 5f73   add the batch_s
-00029680: 697a 6573 2069 6e20 7468 6520 636f 6e74  izes in the cont
-00029690: 6578 742c 2073 6f20 7468 6174 205f 7061  ext, so that _pa
-000296a0: 645f 7061 636b 6564 5f73 6571 7565 6e63  d_packed_sequenc
-000296b0: 6520 6361 6e0a 2020 2020 2320 6669 6e64  e can.    # find
-000296c0: 2069 7420 6c61 7465 722e 0a20 2020 2063   it later..    c
-000296d0: 6f6e 7465 7874 2e61 6464 286d 622e 6964  ontext.add(mb.id
-000296e0: 656e 7469 7479 2878 3d62 6174 6368 5f73  entity(x=batch_s
-000296f0: 697a 6573 2c20 6e61 6d65 3d62 6174 6368  izes, name=batch
-00029700: 5f73 697a 6573 5f6e 616d 6529 290a 0a0a  _sizes_name))...
-00029710: 4072 6567 6973 7465 725f 746f 7263 685f  @register_torch_
-00029720: 6f70 0a64 6566 205f 7061 645f 7061 636b  op.def _pad_pack
-00029730: 6564 5f73 6571 7565 6e63 6528 636f 6e74  ed_sequence(cont
-00029740: 6578 742c 206e 6f64 6529 3a0a 2020 2020  ext, node):.    
-00029750: 2320 5468 6520 696d 706c 656d 656e 7461  # The implementa
-00029760: 7469 6f6e 206f 6620 7468 6973 206f 7020  tion of this op 
-00029770: 6973 206e 6f74 2065 6666 6963 6965 6e74  is not efficient
-00029780: 2e20 5261 6973 6520 6120 7761 726e 696e  . Raise a warnin
-00029790: 672e 0a20 2020 206c 6f67 6765 722e 7761  g..    logger.wa
-000297a0: 726e 696e 6728 0a20 2020 2020 2020 2022  rning(.        "
-000297b0: 456e 636f 756e 7465 7265 6420 6120 5f70  Encountered a _p
-000297c0: 6164 5f70 6163 6b65 645f 7365 7175 656e  ad_packed_sequen
-000297d0: 6365 206c 6179 6572 2e20 5468 6520 696d  ce layer. The im
-000297e0: 706c 656d 656e 7461 7469 6f6e 206f 6620  plementation of 
-000297f0: 7472 616e 736c 6174 696e 6720 7061 636b  translating pack
-00029800: 2f75 6e70 6163 6b20 6f70 5c0a 2020 2020  /unpack op\.    
-00029810: 2020 2020 696e 2070 7974 6f72 6368 2069      in pytorch i
-00029820: 7320 6e6f 7420 6566 6669 6369 656e 7420  s not efficient 
-00029830: 6475 6520 746f 2074 6865 2063 7572 7265  due to the curre
-00029840: 6e74 206c 696d 6974 6174 696f 6e20 6f66  nt limitation of
-00029850: 2043 6f72 6520 4d4c 2e20 5265 6d6f 7669   Core ML. Removi
-00029860: 6e67 2074 6865 2070 6163 6b2d 756e 7061  ng the pack-unpa
-00029870: 636b 206c 6f67 6963 205c 0a20 2020 2020  ck logic \.     
-00029880: 2020 2061 6e64 2075 7365 2061 2066 6978     and use a fix
-00029890: 6564 2062 6174 6368 2073 697a 6520 6d6f  ed batch size mo
-000298a0: 6465 6c20 6973 2072 6563 6f6d 6d65 6e64  del is recommend
-000298b0: 6564 2e22 0a20 2020 2029 0a20 2020 2069  ed.".    ).    i
-000298c0: 6e70 7574 7320 3d20 5f67 6574 5f69 6e70  nputs = _get_inp
-000298d0: 7574 7328 636f 6e74 6578 742c 206e 6f64  uts(context, nod
-000298e0: 6529 0a0a 2020 2020 2320 7365 715f 6c65  e)..    # seq_le
-000298f0: 6e67 7468 7320 6465 6e6f 7465 7320 7468  ngths denotes th
-00029900: 6520 6163 7475 616c 2073 6571 7565 6e63  e actual sequenc
-00029910: 6520 6c65 6e67 7468 2066 6f72 2065 6163  e length for eac
-00029920: 6820 6261 7463 682e 0a20 2020 2023 2070  h batch..    # p
-00029930: 6164 2064 656e 6f74 6573 2074 6865 2070  ad denotes the p
-00029940: 6164 6469 6e67 2076 616c 7565 2066 6f72  adding value for
-00029950: 2074 686f 7365 2064 6174 6120 7768 6963   those data whic
-00029960: 6820 6861 7320 7368 6f72 7465 7220 6c65  h has shorter le
-00029970: 6e67 7468 2e0a 2020 2020 696e 7075 745f  ngth..    input_
-00029980: 7465 6e73 6f72 203d 2069 6e70 7574 735b  tensor = inputs[
-00029990: 305d 0a20 2020 2073 6571 5f6c 656e 6774  0].    seq_lengt
-000299a0: 6873 203d 2069 6e70 7574 735b 315d 0a20  hs = inputs[1]. 
-000299b0: 2020 2062 6174 6368 5f66 6972 7374 203d     batch_first =
-000299c0: 2069 6e70 7574 735b 325d 2e76 616c 0a20   inputs[2].val. 
-000299d0: 2020 2070 6164 203d 2069 6e70 7574 735b     pad = inputs[
-000299e0: 335d 2e76 616c 0a0a 2020 2020 2320 7765  3].val..    # we
-000299f0: 206f 6e6c 7920 7375 7070 6f72 7420 7061   only support pa
-00029a00: 636b 2061 6e64 2075 6e70 6163 6b20 7472  ck and unpack tr
-00029a10: 616e 736c 6174 696f 6e20 666f 7220 7374  anslation for st
-00029a20: 6174 6963 2074 656e 736f 7220 7368 6170  atic tensor shap
-00029a30: 652c 0a20 2020 2023 2069 2e65 2e2c 2074  e,.    # i.e., t
-00029a40: 6865 2074 6872 6565 2064 696d 656e 7369  he three dimensi
-00029a50: 6f6e 7320 6172 6520 616c 6c20 6b6e 6f77  ons are all know
-00029a60: 6e20 6475 7269 6e67 2063 6f6d 7069 6c65  n during compile
-00029a70: 2074 696d 652e 0a20 2020 2069 6620 616e   time..    if an
-00029a80: 7928 5b69 735f 7379 6d62 6f6c 6963 2878  y([is_symbolic(x
-00029a90: 2920 666f 7220 7820 696e 2069 6e70 7574  ) for x in input
-00029aa0: 5f74 656e 736f 722e 7368 6170 655d 293a  _tensor.shape]):
-00029ab0: 0a20 2020 2020 2020 2072 6169 7365 204e  .        raise N
-00029ac0: 6f74 496d 706c 656d 656e 7465 6445 7272  otImplementedErr
-00029ad0: 6f72 2822 4f6e 6c79 2073 7461 7469 6320  or("Only static 
-00029ae0: 7368 6170 6520 6f66 2050 6163 6b65 6453  shape of PackedS
-00029af0: 6571 7565 6e63 6520 6f62 6a65 6374 2069  equence object i
-00029b00: 7320 7375 7070 6f72 7465 642e 2229 0a0a  s supported.")..
-00029b10: 2020 2020 2320 7468 6520 696e 7075 7420      # the input 
-00029b20: 616c 7761 7973 2068 6173 2062 6174 6368  always has batch
-00029b30: 2066 6972 7374 206c 6179 6f75 742e 0a20   first layout.. 
-00029b40: 2020 2023 2070 6164 6465 645f 7365 715f     # padded_seq_
-00029b50: 6c65 6e20 6465 6e6f 7465 7320 7468 6520  len denotes the 
-00029b60: 6d61 7869 6d75 6d20 7365 7175 656e 6365  maximum sequence
-00029b70: 206c 656e 6774 6820 6163 726f 7373 2062   length across b
-00029b80: 6174 6368 6573 2e0a 2020 2020 6261 7463  atches..    batc
-00029b90: 682c 2070 6164 6465 645f 7365 715f 6c65  h, padded_seq_le
-00029ba0: 6e2c 2069 6e70 7574 5f64 696d 203d 2069  n, input_dim = i
-00029bb0: 6e70 7574 5f74 656e 736f 722e 7368 6170  nput_tensor.shap
-00029bc0: 650a 2020 2020 6173 7365 7274 2073 6571  e.    assert seq
-00029bd0: 5f6c 656e 6774 6873 2e72 616e 6b20 3d3d  _lengths.rank ==
-00029be0: 2031 0a20 2020 2061 7373 6572 7420 6261   1.    assert ba
-00029bf0: 7463 6820 3d3d 2073 6571 5f6c 656e 6774  tch == seq_lengt
-00029c00: 6873 2e73 6861 7065 5b30 5d0a 0a20 2020  hs.shape[0]..   
-00029c10: 2023 2077 6520 6974 6572 6174 6520 7468   # we iterate th
-00029c20: 726f 7567 6820 7468 6520 6261 7463 682c  rough the batch,
-00029c30: 2070 6164 2065 6163 6820 6461 7461 2c20   pad each data, 
-00029c40: 616e 6420 636f 6e63 6174 6520 7468 656d  and concate them
-00029c50: 2069 6e74 6f20 6120 7369 6e67 6c65 2074   into a single t
-00029c60: 656e 736f 7220 696e 2074 6865 2065 6e64  ensor in the end
-00029c70: 2c0a 2020 2020 2320 7768 6963 6820 6973  ,.    # which is
-00029c80: 2074 6865 2074 6f74 616c 5f74 656e 736f   the total_tenso
-00029c90: 7220 6865 7265 2e0a 2020 2020 2320 5361  r here..    # Sa
-00029ca0: 7920 7468 6520 696e 7075 745f 7465 6e73  y the input_tens
-00029cb0: 6f72 2068 6173 2073 6861 7065 205b 6261  or has shape [ba
-00029cc0: 7463 6820 2c20 7061 6464 6564 5f73 6571  tch , padded_seq
-00029cd0: 5f6c 656e 2c20 696e 7075 745f 6469 6d5d  _len, input_dim]
-00029ce0: 2c0a 2020 2020 2320 616e 6420 7468 6520  ,.    # and the 
-00029cf0: 7365 715f 6c65 6e67 7468 7320 3d20 5b6c  seq_lengths = [l
-00029d00: 656e 5f31 2c20 6c65 6e5f 322c 206c 656e  en_1, len_2, len
-00029d10: 5f33 5d2e 0a20 2020 2023 204e 6f74 6520  _3]..    # Note 
-00029d20: 7468 6174 2069 6e20 7079 746f 7263 682c  that in pytorch,
-00029d30: 2074 6865 2073 6571 5f6c 656e 6774 6873   the seq_lengths
-00029d40: 206d 7573 7420 6265 2064 6563 7265 6173   must be decreas
-00029d50: 696e 6720 696e 206f 7264 6572 2c20 6c65  ing in order, le
-00029d60: 6e5f 3120 3e3d 206c 656e 5f32 203e 3d20  n_1 >= len_2 >= 
-00029d70: 6c65 6e5f 332e 0a20 2020 2074 6f74 616c  len_3..    total
-00029d80: 5f74 656e 736f 7220 3d20 5b5d 0a0a 2020  _tensor = []..  
-00029d90: 2020 666f 7220 6920 696e 2072 616e 6765    for i in range
-00029da0: 2862 6174 6368 293a 0a20 2020 2020 2020  (batch):.       
-00029db0: 2023 2073 6c69 6365 2066 6f72 2065 6163   # slice for eac
-00029dc0: 6820 6461 7461 0a20 2020 2020 2020 2023  h data.        #
-00029dd0: 2078 2068 6173 2073 6861 7065 205b 7061   x has shape [pa
-00029de0: 6464 6564 5f73 6571 5f6c 656e 2c20 696e  dded_seq_len, in
-00029df0: 7075 745f 6469 6d5d 0a20 2020 2020 2020  put_dim].       
-00029e00: 2078 203d 206d 622e 736c 6963 655f 6279   x = mb.slice_by
-00029e10: 5f69 6e64 6578 280a 2020 2020 2020 2020  _index(.        
-00029e20: 2020 2020 783d 696e 7075 745f 7465 6e73      x=input_tens
-00029e30: 6f72 2c0a 2020 2020 2020 2020 2020 2020  or,.            
-00029e40: 6265 6769 6e3d 5b69 2c20 302c 2030 5d2c  begin=[i, 0, 0],
-00029e50: 0a20 2020 2020 2020 2020 2020 2065 6e64  .            end
-00029e60: 3d5b 302c 2030 2c20 305d 2c0a 2020 2020  =[0, 0, 0],.    
-00029e70: 2020 2020 2020 2020 7374 7269 6465 3d5b          stride=[
-00029e80: 312c 2031 2c20 315d 2c0a 2020 2020 2020  1, 1, 1],.      
-00029e90: 2020 2020 2020 6265 6769 6e5f 6d61 736b        begin_mask
-00029ea0: 3d5b 4661 6c73 652c 2054 7275 652c 2054  =[False, True, T
-00029eb0: 7275 655d 2c0a 2020 2020 2020 2020 2020  rue],.          
-00029ec0: 2020 656e 645f 6d61 736b 3d5b 4661 6c73    end_mask=[Fals
-00029ed0: 652c 2054 7275 652c 2054 7275 655d 2c0a  e, True, True],.
-00029ee0: 2020 2020 2020 2020 2020 2020 7371 7565              sque
-00029ef0: 657a 655f 6d61 736b 3d5b 5472 7565 2c20  eze_mask=[True, 
-00029f00: 4661 6c73 652c 2046 616c 7365 5d2c 0a20  False, False],. 
-00029f10: 2020 2020 2020 2029 0a0a 2020 2020 2020         )..      
-00029f20: 2020 2320 6765 7420 7468 6520 756e 7061    # get the unpa
-00029f30: 6464 6564 2073 6571 7565 6e63 652c 0a20  dded sequence,. 
-00029f40: 2020 2020 2020 2023 2069 6620 7468 6520         # if the 
-00029f50: 756e 7061 6464 6564 2073 6571 7565 6e63  unpadded sequenc
-00029f60: 6520 6861 7320 6c65 6e67 7468 2073 6571  e has length seq
-00029f70: 5f6c 656e 6774 682c 0a20 2020 2020 2020  _length,.       
-00029f80: 2023 2078 2077 6f75 6c64 2068 6176 6520   # x would have 
-00029f90: 7368 6170 6520 5b73 6571 5f6c 656e 6774  shape [seq_lengt
-00029fa0: 682c 2069 6e70 7574 5f64 696d 5d2e 0a20  h, input_dim].. 
-00029fb0: 2020 2020 2020 2023 2046 6f72 2065 7861         # For exa
-00029fc0: 6d70 6c65 2c20 7468 6520 6669 7273 7420  mple, the first 
-00029fd0: 6461 7461 2077 6f75 6c64 2072 6573 756c  data would resul
-00029fe0: 7420 696e 2061 205b 6c65 6e5f 312c 2069  t in a [len_1, i
-00029ff0: 6e70 7574 5f64 696d 5d20 7465 6e73 6f72  nput_dim] tensor
-0002a000: 2e0a 2020 2020 2020 2020 7365 715f 6c65  ..        seq_le
-0002a010: 6e67 7468 203d 206d 622e 6361 7374 2878  ngth = mb.cast(x
-0002a020: 3d76 616c 7565 5f61 7428 7365 715f 6c65  =value_at(seq_le
-0002a030: 6e67 7468 732c 2069 292c 2064 7479 7065  ngths, i), dtype
-0002a040: 3d22 696e 7433 3222 290a 2020 2020 2020  ="int32").      
-0002a050: 2020 636f 6e63 6174 655f 7661 6c75 6573    concate_values
-0002a060: 203d 205b 7365 715f 6c65 6e67 7468 2c20   = [seq_length, 
-0002a070: 696e 7075 745f 6469 6d5d 0a20 2020 2020  input_dim].     
-0002a080: 2020 2065 6e64 5f69 6e64 6578 203d 206d     end_index = m
-0002a090: 622e 636f 6e63 6174 2876 616c 7565 733d  b.concat(values=
-0002a0a0: 636f 6e63 6174 655f 7661 6c75 6573 2c20  concate_values, 
-0002a0b0: 6178 6973 3d30 290a 2020 2020 2020 2020  axis=0).        
-0002a0c0: 7820 3d20 6d62 2e73 6c69 6365 5f62 795f  x = mb.slice_by_
-0002a0d0: 696e 6465 7828 0a20 2020 2020 2020 2020  index(.         
-0002a0e0: 2020 2078 3d78 2c0a 2020 2020 2020 2020     x=x,.        
-0002a0f0: 2020 2020 6265 6769 6e3d 5b30 2c20 305d      begin=[0, 0]
-0002a100: 2c0a 2020 2020 2020 2020 2020 2020 656e  ,.            en
-0002a110: 643d 656e 645f 696e 6465 782c 0a20 2020  d=end_index,.   
-0002a120: 2020 2020 2020 2020 2073 7472 6964 653d           stride=
-0002a130: 5b31 2c20 315d 2c0a 2020 2020 2020 2020  [1, 1],.        
-0002a140: 2020 2020 6265 6769 6e5f 6d61 736b 3d5b      begin_mask=[
-0002a150: 5472 7565 2c20 5472 7565 5d2c 0a20 2020  True, True],.   
-0002a160: 2020 2020 2020 2020 2065 6e64 5f6d 6173           end_mas
-0002a170: 6b3d 5b46 616c 7365 2c20 5472 7565 5d2c  k=[False, True],
-0002a180: 0a20 2020 2020 2020 2029 0a0a 2020 2020  .        )..    
-0002a190: 2020 2020 2320 6765 7420 7468 6520 7061      # get the pa
-0002a1a0: 6464 696e 6720 7061 7274 206f 6620 7468  dding part of th
-0002a1b0: 6520 6461 7461 0a20 2020 2020 2020 2023  e data.        #
-0002a1c0: 204e 6f74 6520 7468 6174 2077 6520 616c   Note that we al
-0002a1d0: 7761 7973 2061 6464 206f 6e65 2064 756d  ways add one dum
-0002a1e0: 6d79 2070 6164 6469 6e67 2069 6e20 7468  my padding in th
-0002a1f0: 6520 656e 6420 7769 7468 2073 6861 7065  e end with shape
-0002a200: 205b 7061 6464 6564 5f73 6571 5f6c 656e   [padded_seq_len
-0002a210: 202d 2073 6571 5f6c 656e 6774 6820 2b20   - seq_length + 
-0002a220: 312c 2069 6e70 7574 5f64 696d 5d2e 0a20  1, input_dim].. 
-0002a230: 2020 2020 2020 2023 2054 6865 2072 6561         # The rea
-0002a240: 736f 6e20 6973 2074 6861 7420 666f 7220  son is that for 
-0002a250: 7468 6520 6361 7365 2077 6865 6e20 7365  the case when se
-0002a260: 715f 6c65 6e67 7468 203d 2070 6164 6465  q_length = padde
-0002a270: 645f 7365 715f 6c65 6e2c 0a20 2020 2020  d_seq_len,.     
-0002a280: 2020 2023 2063 6f72 656d 6c20 6361 6e6e     # coreml cann
-0002a290: 6f74 2068 616e 646c 6520 7468 6520 656d  ot handle the em
-0002a2a0: 7074 7920 7465 6e73 6f72 2e0a 2020 2020  pty tensor..    
-0002a2b0: 2020 2020 7061 645f 6c65 6e67 7468 203d      pad_length =
-0002a2c0: 206d 622e 7375 6228 783d 7061 6464 6564   mb.sub(x=padded
-0002a2d0: 5f73 6571 5f6c 656e 202b 2031 2c20 793d  _seq_len + 1, y=
-0002a2e0: 7365 715f 6c65 6e67 7468 290a 2020 2020  seq_length).    
-0002a2f0: 2020 2020 636f 6e63 6174 655f 7661 6c75      concate_valu
-0002a300: 6573 203d 205b 7061 645f 6c65 6e67 7468  es = [pad_length
-0002a310: 2c20 696e 7075 745f 6469 6d5d 0a20 2020  , input_dim].   
-0002a320: 2020 2020 2073 6861 7065 203d 206d 622e       shape = mb.
-0002a330: 636f 6e63 6174 2876 616c 7565 733d 636f  concat(values=co
-0002a340: 6e63 6174 655f 7661 6c75 6573 2c20 6178  ncate_values, ax
-0002a350: 6973 3d30 290a 2020 2020 2020 2020 7061  is=0).        pa
-0002a360: 645f 7661 6c75 6573 203d 206d 622e 6669  d_values = mb.fi
-0002a370: 6c6c 2873 6861 7065 3d73 6861 7065 2c20  ll(shape=shape, 
-0002a380: 7661 6c75 653d 7061 6429 0a0a 2020 2020  value=pad)..    
-0002a390: 2020 2020 2320 636f 6e63 6174 6520 7468      # concate th
-0002a3a0: 6520 756e 7061 6464 6564 2073 6571 7565  e unpadded seque
-0002a3b0: 6e63 6520 616e 6420 7468 6520 7061 6464  nce and the padd
-0002a3c0: 696e 6720 6461 7461 0a20 2020 2020 2020  ing data.       
-0002a3d0: 2023 2074 6865 2072 6573 756c 7469 6e67   # the resulting
-0002a3e0: 2074 656e 736f 7220 776f 756c 6420 6861   tensor would ha
-0002a3f0: 7665 2073 6861 7065 205b 7061 6464 6564  ve shape [padded
-0002a400: 5f73 6571 5f6c 656e 202b 2031 2c20 696e  _seq_len + 1, in
-0002a410: 7075 745f 6469 6d5d 0a20 2020 2020 2020  put_dim].       
-0002a420: 2078 2c20 7061 645f 7661 6c75 6573 203d   x, pad_values =
-0002a430: 2070 726f 6d6f 7465 5f69 6e70 7574 5f64   promote_input_d
-0002a440: 7479 7065 7328 5b78 2c20 7061 645f 7661  types([x, pad_va
-0002a450: 6c75 6573 5d29 0a20 2020 2020 2020 2063  lues]).        c
-0002a460: 6f6e 6361 7465 5f76 616c 7565 7320 3d20  oncate_values = 
-0002a470: 5b78 2c20 7061 645f 7661 6c75 6573 5d0a  [x, pad_values].
-0002a480: 2020 2020 2020 2020 6164 645f 7661 6c75          add_valu
-0002a490: 6573 203d 206d 622e 636f 6e63 6174 2876  es = mb.concat(v
-0002a4a0: 616c 7565 733d 636f 6e63 6174 655f 7661  alues=concate_va
-0002a4b0: 6c75 6573 2c20 6178 6973 3d30 290a 0a20  lues, axis=0).. 
-0002a4c0: 2020 2020 2020 2023 2074 7269 6d20 7468         # trim th
-0002a4d0: 6520 6475 6d6d 7920 7061 6464 696e 6720  e dummy padding 
-0002a4e0: 7465 6e73 6f72 0a20 2020 2020 2020 2023  tensor.        #
-0002a4f0: 2074 6865 206f 7574 7075 7420 776f 756c   the output woul
-0002a500: 6420 6861 7665 2073 6870 6165 205b 7061  d have shpae [pa
-0002a510: 6464 6564 5f73 6571 5f6c 656e 2c20 696e  dded_seq_len, in
-0002a520: 7075 745f 6469 6d5d 0a20 2020 2020 2020  put_dim].       
-0002a530: 2078 203d 206d 622e 736c 6963 655f 6279   x = mb.slice_by
-0002a540: 5f69 6e64 6578 280a 2020 2020 2020 2020  _index(.        
-0002a550: 2020 2020 783d 6164 645f 7661 6c75 6573      x=add_values
-0002a560: 2c0a 2020 2020 2020 2020 2020 2020 6265  ,.            be
-0002a570: 6769 6e3d 5b30 2c20 305d 2c0a 2020 2020  gin=[0, 0],.    
-0002a580: 2020 2020 2020 2020 656e 643d 5b70 6164          end=[pad
-0002a590: 6465 645f 7365 715f 6c65 6e2c 2030 5d2c  ded_seq_len, 0],
-0002a5a0: 0a20 2020 2020 2020 2020 2020 2073 7472  .            str
-0002a5b0: 6964 653d 5b31 2c20 315d 2c0a 2020 2020  ide=[1, 1],.    
-0002a5c0: 2020 2020 2020 2020 6265 6769 6e5f 6d61          begin_ma
-0002a5d0: 736b 3d5b 5472 7565 2c20 5472 7565 5d2c  sk=[True, True],
-0002a5e0: 0a20 2020 2020 2020 2020 2020 2065 6e64  .            end
-0002a5f0: 5f6d 6173 6b3d 5b46 616c 7365 2c20 5472  _mask=[False, Tr
-0002a600: 7565 5d2c 0a20 2020 2020 2020 2029 0a0a  ue],.        )..
-0002a610: 2020 2020 2020 2020 2320 6164 6420 6974          # add it
-0002a620: 2074 6f20 746f 7461 6c20 7465 6e73 6f72   to total tensor
-0002a630: 0a20 2020 2020 2020 2074 6f74 616c 5f74  .        total_t
-0002a640: 656e 736f 722e 6170 7065 6e64 2878 290a  ensor.append(x).
-0002a650: 0a20 2020 2023 2074 7261 6e73 706f 7365  .    # transpose
-0002a660: 2074 6865 2074 656e 736f 7220 6966 2062   the tensor if b
-0002a670: 6174 6368 5f66 6972 7374 203d 2046 616c  atch_first = Fal
-0002a680: 7365 0a20 2020 2069 6620 6e6f 7420 6261  se.    if not ba
-0002a690: 7463 685f 6669 7273 743a 0a20 2020 2020  tch_first:.     
-0002a6a0: 2020 2078 203d 206d 622e 7374 6163 6b28     x = mb.stack(
-0002a6b0: 7661 6c75 6573 3d74 6f74 616c 5f74 656e  values=total_ten
-0002a6c0: 736f 722c 2061 7869 733d 3029 0a20 2020  sor, axis=0).   
-0002a6d0: 2020 2020 2078 203d 206d 622e 7472 616e       x = mb.tran
-0002a6e0: 7370 6f73 6528 783d 782c 2070 6572 6d3d  spose(x=x, perm=
-0002a6f0: 5b31 2c20 302c 2032 5d2c 206e 616d 653d  [1, 0, 2], name=
-0002a700: 6e6f 6465 2e6e 616d 6529 0a20 2020 2065  node.name).    e
-0002a710: 6c73 653a 0a20 2020 2020 2020 2078 203d  lse:.        x =
-0002a720: 206d 622e 7374 6163 6b28 7661 6c75 6573   mb.stack(values
-0002a730: 3d74 6f74 616c 5f74 656e 736f 722c 2061  =total_tensor, a
-0002a740: 7869 733d 302c 206e 616d 653d 6e6f 6465  xis=0, name=node
-0002a750: 2e6e 616d 6529 0a0a 2020 2020 636f 6e74  .name)..    cont
-0002a760: 6578 742e 6164 6428 7829 0a0a 0a40 7265  ext.add(x)...@re
-0002a770: 6769 7374 6572 5f74 6f72 6368 5f6f 700a  gister_torch_op.
-0002a780: 6465 6620 6c6f 6731 3028 636f 6e74 6578  def log10(contex
-0002a790: 742c 206e 6f64 6529 3a0a 2020 2020 696e  t, node):.    in
-0002a7a0: 7075 7473 203d 205f 6765 745f 696e 7075  puts = _get_inpu
-0002a7b0: 7473 2863 6f6e 7465 7874 2c20 6e6f 6465  ts(context, node
-0002a7c0: 290a 2020 2020 7820 3d20 696e 7075 7473  ).    x = inputs
-0002a7d0: 5b30 5d0a 2020 2020 6c6f 675f 7820 3d20  [0].    log_x = 
-0002a7e0: 6d62 2e6c 6f67 2878 3d78 290a 2020 2020  mb.log(x=x).    
-0002a7f0: 636f 6e74 6578 742e 6164 6428 6d62 2e6d  context.add(mb.m
-0002a800: 756c 2878 3d6c 6f67 5f78 2c20 793d 3120  ul(x=log_x, y=1 
-0002a810: 2f20 5f6e 702e 6c6f 6728 3130 2e30 2929  / _np.log(10.0))
-0002a820: 2c20 6e6f 6465 2e6e 616d 6529 0a0a 0a40  , node.name)...@
-0002a830: 7265 6769 7374 6572 5f74 6f72 6368 5f6f  register_torch_o
-0002a840: 700a 6465 6620 6c6f 6732 2863 6f6e 7465  p.def log2(conte
-0002a850: 7874 2c20 6e6f 6465 293a 0a20 2020 2069  xt, node):.    i
-0002a860: 6e70 7574 7320 3d20 5f67 6574 5f69 6e70  nputs = _get_inp
-0002a870: 7574 7328 636f 6e74 6578 742c 206e 6f64  uts(context, nod
-0002a880: 6529 0a20 2020 2078 203d 2069 6e70 7574  e).    x = input
-0002a890: 735b 305d 0a20 2020 206c 6f67 5f78 203d  s[0].    log_x =
-0002a8a0: 206d 622e 6c6f 6728 783d 7829 0a20 2020   mb.log(x=x).   
-0002a8b0: 2063 6f6e 7465 7874 2e61 6464 286d 622e   context.add(mb.
-0002a8c0: 6d75 6c28 783d 6c6f 675f 782c 2079 3d31  mul(x=log_x, y=1
-0002a8d0: 202f 205f 6e70 2e6c 6f67 2832 2e30 2929   / _np.log(2.0))
-0002a8e0: 2c20 6e6f 6465 2e6e 616d 6529 0a0a 0a40  , node.name)...@
-0002a8f0: 7265 6769 7374 6572 5f74 6f72 6368 5f6f  register_torch_o
-0002a900: 700a 6465 6620 666c 6970 2863 6f6e 7465  p.def flip(conte
-0002a910: 7874 2c20 6e6f 6465 293a 0a20 2020 2069  xt, node):.    i
-0002a920: 6e70 7574 7320 3d20 5f67 6574 5f69 6e70  nputs = _get_inp
-0002a930: 7574 7328 636f 6e74 6578 742c 206e 6f64  uts(context, nod
-0002a940: 652c 2065 7870 6563 7465 643d 3229 0a20  e, expected=2). 
-0002a950: 2020 2078 203d 206d 622e 7265 7665 7273     x = mb.revers
-0002a960: 6528 783d 696e 7075 7473 5b30 5d2c 2061  e(x=inputs[0], a
-0002a970: 7865 733d 696e 7075 7473 5b31 5d2c 206e  xes=inputs[1], n
-0002a980: 616d 653d 6e6f 6465 2e6e 616d 6529 0a20  ame=node.name). 
-0002a990: 2020 2063 6f6e 7465 7874 2e61 6464 2878     context.add(x
-0002a9a0: 2c20 6e6f 6465 2e6e 616d 6529 0a0a 0a40  , node.name)...@
-0002a9b0: 7265 6769 7374 6572 5f74 6f72 6368 5f6f  register_torch_o
-0002a9c0: 7028 746f 7263 685f 616c 6961 733d 5b22  p(torch_alias=["
-0002a9d0: 7265 666c 6563 7469 6f6e 5f70 6164 3164  reflection_pad1d
-0002a9e0: 225d 290a 6465 6620 7265 666c 6563 7469  "]).def reflecti
-0002a9f0: 6f6e 5f70 6164 3264 2863 6f6e 7465 7874  on_pad2d(context
-0002aa00: 2c20 6e6f 6465 293a 0a20 2020 2069 6e70  , node):.    inp
-0002aa10: 7574 7320 3d20 5f67 6574 5f69 6e70 7574  uts = _get_input
-0002aa20: 7328 636f 6e74 6578 742c 206e 6f64 6529  s(context, node)
-0002aa30: 0a20 2020 2078 203d 2069 6e70 7574 735b  .    x = inputs[
-0002aa40: 305d 0a20 2020 2074 6f72 6368 5f70 6164  0].    torch_pad
-0002aa50: 203d 2069 6e70 7574 735b 315d 2e76 616c   = inputs[1].val
-0002aa60: 0a20 2020 2070 6164 5f66 6c69 7070 6564  .    pad_flipped
-0002aa70: 203d 2074 6f72 6368 5f70 6164 2e72 6573   = torch_pad.res
-0002aa80: 6861 7065 2828 2d31 2c20 3229 295b 3a3a  hape((-1, 2))[::
-0002aa90: 2d31 5d2e 7261 7665 6c28 290a 2020 2020  -1].ravel().    
-0002aaa0: 7061 6420 3d20 5f6e 702e 7061 6428 7061  pad = _np.pad(pa
-0002aab0: 645f 666c 6970 7065 642c 2028 6c65 6e28  d_flipped, (len(
-0002aac0: 782e 7368 6170 6529 202a 2032 202d 206c  x.shape) * 2 - l
-0002aad0: 656e 2870 6164 5f66 6c69 7070 6564 292c  en(pad_flipped),
-0002aae0: 2030 2929 0a20 2020 2063 6f6e 7465 7874   0)).    context
-0002aaf0: 2e61 6464 286d 622e 7061 6428 783d 782c  .add(mb.pad(x=x,
-0002ab00: 2070 6164 3d70 6164 2c20 6d6f 6465 3d27   pad=pad, mode='
-0002ab10: 7265 666c 6563 7427 292c 206e 6f64 652e  reflect'), node.
-0002ab20: 6e61 6d65 290a 0a0a 4072 6567 6973 7465  name)...@registe
-0002ab30: 725f 746f 7263 685f 6f70 2874 6f72 6368  r_torch_op(torch
-0002ab40: 5f61 6c69 6173 3d5b 2272 6570 6c69 6361  _alias=["replica
-0002ab50: 7469 6f6e 5f70 6164 3164 225d 290a 6465  tion_pad1d"]).de
-0002ab60: 6620 7265 706c 6963 6174 696f 6e5f 7061  f replication_pa
-0002ab70: 6432 6428 636f 6e74 6578 742c 206e 6f64  d2d(context, nod
-0002ab80: 6529 3a0a 2020 2020 696e 7075 7473 203d  e):.    inputs =
-0002ab90: 205f 6765 745f 696e 7075 7473 2863 6f6e   _get_inputs(con
-0002aba0: 7465 7874 2c20 6e6f 6465 290a 2020 2020  text, node).    
-0002abb0: 7820 3d20 696e 7075 7473 5b30 5d0a 2020  x = inputs[0].  
-0002abc0: 2020 746f 7263 685f 7061 6420 3d20 696e    torch_pad = in
-0002abd0: 7075 7473 5b31 5d2e 7661 6c0a 2020 2020  puts[1].val.    
-0002abe0: 7061 645f 666c 6970 7065 6420 3d20 746f  pad_flipped = to
-0002abf0: 7263 685f 7061 642e 7265 7368 6170 6528  rch_pad.reshape(
-0002ac00: 282d 312c 2032 2929 5b3a 3a2d 315d 2e72  (-1, 2))[::-1].r
-0002ac10: 6176 656c 2829 0a20 2020 2070 6164 203d  avel().    pad =
-0002ac20: 205f 6e70 2e70 6164 2870 6164 5f66 6c69   _np.pad(pad_fli
-0002ac30: 7070 6564 2c20 286c 656e 2878 2e73 6861  pped, (len(x.sha
-0002ac40: 7065 2920 2a20 3220 2d20 6c65 6e28 7061  pe) * 2 - len(pa
-0002ac50: 645f 666c 6970 7065 6429 2c20 3029 290a  d_flipped), 0)).
-0002ac60: 2020 2020 636f 6e74 6578 742e 6164 6428      context.add(
-0002ac70: 6d62 2e70 6164 2878 3d78 2c20 7061 643d  mb.pad(x=x, pad=
-0002ac80: 7061 642c 206d 6f64 653d 2772 6570 6c69  pad, mode='repli
-0002ac90: 6361 7465 2729 2c20 6e6f 6465 2e6e 616d  cate'), node.nam
-0002aca0: 6529 0a0a 0a64 6566 205f 6272 6f61 6463  e)...def _broadc
-0002acb0: 6173 745f 7465 6e73 6f72 7328 7465 6e73  ast_tensors(tens
-0002acc0: 6f72 7329 3a0a 2020 2020 6465 6620 5f73  ors):.    def _s
-0002acd0: 6f6c 7665 5f62 726f 6164 6361 7374 5f73  olve_broadcast_s
-0002ace0: 6861 7065 2873 6861 7065 7329 3a0a 2020  hape(shapes):.  
-0002acf0: 2020 2020 2020 7261 6e6b 203d 205f 6e70        rank = _np
-0002ad00: 2e6d 6178 285b 6c65 6e28 7368 6170 6529  .max([len(shape)
-0002ad10: 2066 6f72 2073 6861 7065 2069 6e20 7368   for shape in sh
-0002ad20: 6170 6573 5d29 0a20 2020 2020 2020 2073  apes]).        s
-0002ad30: 6861 7065 7320 3d20 5b5b 315d 202a 2028  hapes = [[1] * (
-0002ad40: 7261 6e6b 202d 206c 656e 2873 6861 7065  rank - len(shape
-0002ad50: 2929 202b 2073 6861 7065 2066 6f72 2073  )) + shape for s
-0002ad60: 6861 7065 2069 6e20 7368 6170 6573 5d0a  hape in shapes].
-0002ad70: 2020 2020 2020 2020 7265 7375 6c74 5f73          result_s
-0002ad80: 6861 7065 203d 205b 5d0a 2020 2020 2020  hape = [].      
-0002ad90: 2020 666f 7220 6920 696e 2072 616e 6765    for i in range
-0002ada0: 2872 616e 6b29 3a0a 2020 2020 2020 2020  (rank):.        
-0002adb0: 2020 2020 6469 6d73 203d 205b 7368 6170      dims = [shap
-0002adc0: 6573 5b6a 5d5b 695d 2066 6f72 206a 2069  es[j][i] for j i
-0002add0: 6e20 7261 6e67 6528 6c65 6e28 7465 6e73  n range(len(tens
-0002ade0: 6f72 7329 295d 0a20 2020 2020 2020 2020  ors))].         
-0002adf0: 2020 2069 6620 616e 795f 7379 6d62 6f6c     if any_symbol
-0002ae00: 6963 2864 696d 7329 3a0a 2020 2020 2020  ic(dims):.      
-0002ae10: 2020 2020 2020 2020 2020 2320 7264 6172            # rdar
-0002ae20: 3a2f 2f38 3535 3539 3439 3720 2848 616e  ://85559497 (Han
-0002ae30: 646c 6520 6479 6e61 6d69 6320 7368 6170  dle dynamic shap
-0002ae40: 6573 2069 6e70 7574 7320 6272 6f61 6463  es inputs broadc
-0002ae50: 6173 7420 666f 7220 7079 746f 7263 6829  ast for pytorch)
-0002ae60: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0002ae70: 2072 6169 7365 204e 6f74 496d 706c 656d   raise NotImplem
-0002ae80: 656e 7465 6445 7272 6f72 280a 2020 2020  entedError(.    
-0002ae90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002aea0: 224f 6e6c 7920 7374 6174 6963 2073 6861  "Only static sha
-0002aeb0: 7065 6420 696e 7075 7473 2061 7265 2073  ped inputs are s
-0002aec0: 7570 706f 7274 6564 2066 6f72 2074 6f72  upported for tor
-0002aed0: 6368 2e62 726f 6164 6361 7374 5f74 656e  ch.broadcast_ten
-0002aee0: 736f 7273 2063 6f6e 7665 7273 696f 6e2e  sors conversion.
-0002aef0: 220a 2020 2020 2020 2020 2020 2020 2020  ".              
-0002af00: 2020 290a 2020 2020 2020 2020 2020 2020    ).            
-0002af10: 7265 7375 6c74 5f73 6861 7065 2e61 7070  result_shape.app
-0002af20: 656e 6428 5f6e 702e 6d61 7828 6469 6d73  end(_np.max(dims
-0002af30: 2929 0a20 2020 2020 2020 2072 6574 7572  )).        retur
-0002af40: 6e20 7265 7375 6c74 5f73 6861 7065 0a0a  n result_shape..
-0002af50: 2020 2020 6966 206c 656e 2874 656e 736f      if len(tenso
-0002af60: 7273 2920 3d3d 2031 3a0a 2020 2020 2020  rs) == 1:.      
-0002af70: 2020 7265 7475 726e 2074 656e 736f 7273    return tensors
-0002af80: 0a0a 2020 2020 2320 736f 6c76 6520 7468  ..    # solve th
-0002af90: 6520 6272 6f61 6463 6173 7420 7368 6170  e broadcast shap
-0002afa0: 650a 2020 2020 696e 7075 745f 7368 6170  e.    input_shap
-0002afb0: 6573 203d 205b 6c69 7374 2878 2e73 6861  es = [list(x.sha
-0002afc0: 7065 2920 666f 7220 7820 696e 2074 656e  pe) for x in ten
-0002afd0: 736f 7273 5d0a 2020 2020 6272 6f61 6463  sors].    broadc
-0002afe0: 6173 745f 7368 6170 6520 3d20 5f73 6f6c  ast_shape = _sol
-0002aff0: 7665 5f62 726f 6164 6361 7374 5f73 6861  ve_broadcast_sha
-0002b000: 7065 2869 6e70 7574 5f73 6861 7065 7329  pe(input_shapes)
-0002b010: 0a0a 2020 2020 2320 646f 2074 6865 2062  ..    # do the b
-0002b020: 726f 6164 6361 7374 696e 670a 2020 2020  roadcasting.    
-0002b030: 7265 7375 6c74 7320 3d20 5b5d 0a20 2020  results = [].   
-0002b040: 2066 6f72 2074 656e 736f 7220 696e 2074   for tensor in t
-0002b050: 656e 736f 7273 3a0a 2020 2020 2020 2020  ensors:.        
-0002b060: 6e61 6d65 203d 2074 656e 736f 722e 6e61  name = tensor.na
-0002b070: 6d65 202b 2022 5f61 6674 6572 5f62 726f  me + "_after_bro
-0002b080: 6164 6361 7374 220a 2020 2020 2020 2020  adcast".        
-0002b090: 7265 7375 6c74 732e 6170 7065 6e64 285f  results.append(_
-0002b0a0: 6272 6f61 6463 6173 7428 6e61 6d65 2c20  broadcast(name, 
-0002b0b0: 7465 6e73 6f72 2c20 6272 6f61 6463 6173  tensor, broadcas
-0002b0c0: 745f 7368 6170 6529 290a 2020 2020 7265  t_shape)).    re
-0002b0d0: 7475 726e 2072 6573 756c 7473 0a0a 0a40  turn results...@
-0002b0e0: 7265 6769 7374 6572 5f74 6f72 6368 5f6f  register_torch_o
-0002b0f0: 700a 6465 6620 6272 6f61 6463 6173 745f  p.def broadcast_
-0002b100: 7465 6e73 6f72 7328 636f 6e74 6578 742c  tensors(context,
-0002b110: 206e 6f64 6529 3a0a 2020 2020 696e 7075   node):.    inpu
-0002b120: 7473 203d 205f 6765 745f 696e 7075 7473  ts = _get_inputs
-0002b130: 2863 6f6e 7465 7874 2c20 6e6f 6465 290a  (context, node).
-0002b140: 2020 2020 636f 6e74 6578 742e 6164 6428      context.add(
-0002b150: 5f62 726f 6164 6361 7374 5f74 656e 736f  _broadcast_tenso
-0002b160: 7273 2869 6e70 7574 735b 305d 292c 206e  rs(inputs[0]), n
-0002b170: 6f64 652e 6e61 6d65 290a 0a0a 6465 6620  ode.name)...def 
-0002b180: 5f73 6361 7474 6572 2863 6f6e 7465 7874  _scatter(context
-0002b190: 2c20 696e 7075 7473 2c20 6d6f 6465 2c20  , inputs, mode, 
-0002b1a0: 6e61 6d65 293a 0a20 2020 2064 6174 6120  name):.    data 
-0002b1b0: 3d20 696e 7075 7473 5b30 5d0a 2020 2020  = inputs[0].    
-0002b1c0: 6178 6973 203d 2069 6e70 7574 735b 315d  axis = inputs[1]
-0002b1d0: 2e76 616c 0a20 2020 2069 6e64 6963 6573  .val.    indices
-0002b1e0: 203d 2069 6e70 7574 735b 325d 0a20 2020   = inputs[2].   
-0002b1f0: 2075 7064 6174 6573 203d 2069 6e70 7574   updates = input
-0002b200: 735b 335d 0a20 2020 2069 6620 7479 7065  s[3].    if type
-0002b210: 732e 6973 5f73 6361 6c61 7228 7570 6461  s.is_scalar(upda
-0002b220: 7465 732e 7379 6d5f 7479 7065 293a 0a20  tes.sym_type):. 
-0002b230: 2020 2020 2020 2075 7064 6174 6573 203d         updates =
-0002b240: 206d 622e 6669 6c6c 2873 6861 7065 3d69   mb.fill(shape=i
-0002b250: 6e64 6963 6573 2e73 6861 7065 2c20 7661  ndices.shape, va
-0002b260: 6c75 653d 7570 6461 7465 732e 7661 6c2c  lue=updates.val,
-0002b270: 206e 616d 653d 6e61 6d65 290a 2020 2020   name=name).    
-0002b280: 7265 7375 6c74 203d 206d 622e 7363 6174  result = mb.scat
-0002b290: 7465 725f 616c 6f6e 675f 6178 6973 2864  ter_along_axis(d
-0002b2a0: 6174 613d 6461 7461 2c20 696e 6469 6365  ata=data, indice
-0002b2b0: 733d 696e 6469 6365 732c 2075 7064 6174  s=indices, updat
-0002b2c0: 6573 3d75 7064 6174 6573 2c0a 2020 2020  es=updates,.    
-0002b2d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002b2e0: 2020 2020 2020 2020 2020 2020 2020 2061                 a
-0002b2f0: 7869 733d 6178 6973 2c20 6d6f 6465 3d6d  xis=axis, mode=m
-0002b300: 6f64 652c 206e 616d 653d 6e61 6d65 290a  ode, name=name).
-0002b310: 2020 2020 636f 6e74 6578 742e 6164 6428      context.add(
-0002b320: 7265 7375 6c74 290a 0a0a 4072 6567 6973  result)...@regis
-0002b330: 7465 725f 746f 7263 685f 6f70 0a64 6566  ter_torch_op.def
-0002b340: 2073 6361 7474 6572 2863 6f6e 7465 7874   scatter(context
-0002b350: 2c20 6e6f 6465 293a 0a20 2020 2069 6e70  , node):.    inp
-0002b360: 7574 7320 3d20 5f67 6574 5f69 6e70 7574  uts = _get_input
-0002b370: 7328 636f 6e74 6578 742c 206e 6f64 6529  s(context, node)
-0002b380: 0a20 2020 2061 7373 6572 7420 6c65 6e28  .    assert len(
-0002b390: 696e 7075 7473 2920 696e 2028 342c 2035  inputs) in (4, 5
-0002b3a0: 290a 0a20 2020 2023 2044 6574 6572 6d69  )..    # Determi
-0002b3b0: 6e65 2072 6564 7563 652f 6d6f 6465 2070  ne reduce/mode p
-0002b3c0: 6172 616d 6574 6572 0a20 2020 2069 6620  arameter.    if 
-0002b3d0: 6c65 6e28 696e 7075 7473 2920 3d3d 2035  len(inputs) == 5
-0002b3e0: 3a0a 2020 2020 2020 2020 6d6f 6465 203d  :.        mode =
-0002b3f0: 2069 6e70 7574 735b 345d 2e76 616c 0a20   inputs[4].val. 
-0002b400: 2020 2020 2020 2069 6620 6d6f 6465 203d         if mode =
-0002b410: 3d20 276d 756c 7469 706c 7927 3a0a 2020  = 'multiply':.  
-0002b420: 2020 2020 2020 2020 2020 6d6f 6465 203d            mode =
-0002b430: 2027 6d75 6c27 0a20 2020 2020 2020 2065   'mul'.        e
-0002b440: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
-0002b450: 2061 7373 6572 7420 6d6f 6465 203d 3d20   assert mode == 
-0002b460: 2761 6464 270a 2020 2020 656c 7365 3a0a  'add'.    else:.
-0002b470: 2020 2020 2020 2020 6d6f 6465 203d 2027          mode = '
-0002b480: 7570 6461 7465 270a 0a20 2020 205f 7363  update'..    _sc
-0002b490: 6174 7465 7228 636f 6e74 6578 742c 2069  atter(context, i
-0002b4a0: 6e70 7574 732c 206d 6f64 652c 206e 6f64  nputs, mode, nod
-0002b4b0: 652e 6e61 6d65 290a 0a0a 4072 6567 6973  e.name)...@regis
-0002b4c0: 7465 725f 746f 7263 685f 6f70 0a64 6566  ter_torch_op.def
-0002b4d0: 2073 6361 7474 6572 5f61 6464 2863 6f6e   scatter_add(con
-0002b4e0: 7465 7874 2c20 6e6f 6465 293a 0a20 2020  text, node):.   
-0002b4f0: 2069 6e70 7574 7320 3d20 5f67 6574 5f69   inputs = _get_i
-0002b500: 6e70 7574 7328 636f 6e74 6578 742c 206e  nputs(context, n
-0002b510: 6f64 6529 0a20 2020 205f 7363 6174 7465  ode).    _scatte
-0002b520: 7228 636f 6e74 6578 742c 2069 6e70 7574  r(context, input
-0002b530: 732c 2027 6164 6427 2c20 6e6f 6465 2e6e  s, 'add', node.n
-0002b540: 616d 6529 0a0a 0a40 7265 6769 7374 6572  ame)...@register
-0002b550: 5f74 6f72 6368 5f6f 700a 6465 6620 6261  _torch_op.def ba
-0002b560: 6464 626d 6d28 636f 6e74 6578 742c 206e  ddbmm(context, n
-0002b570: 6f64 6529 3a0a 2020 2020 2222 220a 2020  ode):.    """.  
-0002b580: 2020 6261 6464 626d 6d28 5465 6e73 6f72    baddbmm(Tensor
-0002b590: 2069 6e70 7574 2c20 5465 6e73 6f72 2062   input, Tensor b
-0002b5a0: 6174 6368 312c 2054 656e 736f 7220 6261  atch1, Tensor ba
-0002b5b0: 7463 6832 2c20 5363 616c 6172 2062 6574  tch2, Scalar bet
-0002b5c0: 613d 312c 2053 6361 6c61 7220 616c 7068  a=1, Scalar alph
-0002b5d0: 613d 3129 0a20 2020 206f 7574 7075 7420  a=1).    output 
-0002b5e0: 3d20 6265 7461 202a 2069 6e70 7574 202b  = beta * input +
-0002b5f0: 2061 6c70 6861 202a 2062 6174 6368 3120   alpha * batch1 
-0002b600: 2a20 6261 7463 6832 0a0a 2020 2020 4e6f  * batch2..    No
-0002b610: 7469 6365 2074 6861 7420 6261 7463 6831  tice that batch1
-0002b620: 2061 6e64 2062 6174 6368 3220 6d75 7374   and batch2 must
-0002b630: 2062 6520 332d 4420 7465 6e73 6f72 7320   be 3-D tensors 
-0002b640: 6561 6368 2063 6f6e 7461 696e 696e 6720  each containing 
-0002b650: 7468 6520 7361 6d65 206e 756d 6265 7220  the same number 
-0002b660: 6f66 206d 6174 7269 6365 732e 0a20 2020  of matrices..   
-0002b670: 2049 6620 6261 7463 6831 2069 7320 6120   If batch1 is a 
-0002b680: 2862 c397 6ec3 976d 2920 7465 6e73 6f72  (b..n..m) tensor
-0002b690: 2c20 6261 7463 6832 2069 7320 6120 2862  , batch2 is a (b
-0002b6a0: c397 6dc3 9770 2920 7465 6e73 6f72 2c20  ..m..p) tensor, 
-0002b6b0: 7468 656e 2069 6e70 7574 206d 7573 7420  then input must 
-0002b6c0: 6265 2062 726f 6164 6361 7374 6162 6c65  be broadcastable
-0002b6d0: 2077 6974 6820 6120 2862 c397 6ec3 9770   with a (b..n..p
-0002b6e0: 2920 7465 6e73 6f72 0a20 2020 2061 6e64  ) tensor.    and
-0002b6f0: 206f 7574 2077 696c 6c20 6265 2061 2028   out will be a (
-0002b700: 62c3 976e c397 7029 2074 656e 736f 722e  b..n..p) tensor.
-0002b710: 0a20 2020 2022 2222 0a20 2020 2061 7373  .    """.    ass
-0002b720: 6572 7420 6c65 6e28 6e6f 6465 2e6f 7574  ert len(node.out
-0002b730: 7075 7473 2920 3d3d 2031 0a20 2020 2069  puts) == 1.    i
-0002b740: 6e70 7574 7320 3d20 5f67 6574 5f69 6e70  nputs = _get_inp
-0002b750: 7574 7328 636f 6e74 6578 742c 206e 6f64  uts(context, nod
-0002b760: 652c 2065 7870 6563 7465 643d 3529 0a20  e, expected=5). 
-0002b770: 2020 2062 6961 732c 2062 6174 6368 312c     bias, batch1,
-0002b780: 2062 6174 6368 322c 2062 6574 612c 2061   batch2, beta, a
-0002b790: 6c70 6861 203d 2069 6e70 7574 730a 0a20  lpha = inputs.. 
-0002b7a0: 2020 2069 6620 6265 7461 2e76 616c 2021     if beta.val !
-0002b7b0: 3d20 312e 303a 0a20 2020 2020 2020 2023  = 1.0:.        #
-0002b7c0: 2041 7070 6c79 2073 6361 6c69 6e67 2066   Apply scaling f
-0002b7d0: 6163 746f 7220 6265 7461 2074 6f20 7468  actor beta to th
-0002b7e0: 6520 6269 6173 2e0a 2020 2020 2020 2020  e bias..        
-0002b7f0: 6269 6173 203d 206d 622e 6d75 6c28 783d  bias = mb.mul(x=
-0002b800: 6265 7461 2c20 793d 6269 6173 2c20 6e61  beta, y=bias, na
-0002b810: 6d65 3d62 6961 732e 6e61 6d65 202b 2022  me=bias.name + "
-0002b820: 5f73 6361 6c65 6422 290a 2020 2020 2020  _scaled").      
-0002b830: 2020 636f 6e74 6578 742e 6164 6428 6269    context.add(bi
-0002b840: 6173 290a 0a20 2020 2069 6620 616c 7068  as)..    if alph
-0002b850: 612e 7661 6c20 213d 2031 2e30 3a0a 2020  a.val != 1.0:.  
-0002b860: 2020 2020 2020 2320 4170 706c 7920 7363        # Apply sc
-0002b870: 616c 696e 6720 6661 6374 6f72 2061 6c70  aling factor alp
-0002b880: 6861 2074 6f20 7468 6520 696e 7075 742e  ha to the input.
-0002b890: 0a20 2020 2020 2020 2062 6174 6368 3120  .        batch1 
-0002b8a0: 3d20 6d62 2e6d 756c 2878 3d61 6c70 6861  = mb.mul(x=alpha
-0002b8b0: 2c20 793d 6261 7463 6831 2c20 6e61 6d65  , y=batch1, name
-0002b8c0: 3d62 6174 6368 312e 6e61 6d65 202b 2022  =batch1.name + "
-0002b8d0: 5f73 6361 6c65 6422 290a 2020 2020 2020  _scaled").      
-0002b8e0: 2020 636f 6e74 6578 742e 6164 6428 6261    context.add(ba
-0002b8f0: 7463 6831 290a 0a20 2020 2062 6d6d 5f6e  tch1)..    bmm_n
-0002b900: 6f64 6520 3d20 6d62 2e6d 6174 6d75 6c28  ode = mb.matmul(
-0002b910: 783d 6261 7463 6831 2c20 793d 6261 7463  x=batch1, y=batc
-0002b920: 6832 2c20 6e61 6d65 3d6e 6f64 652e 6e61  h2, name=node.na
-0002b930: 6d65 202b 2022 5f62 6d6d 2229 0a20 2020  me + "_bmm").   
-0002b940: 2063 6f6e 7465 7874 2e61 6464 2862 6d6d   context.add(bmm
-0002b950: 5f6e 6f64 6529 0a0a 2020 2020 6261 6464  _node)..    badd
-0002b960: 626d 6d5f 6e6f 6465 203d 206d 622e 6164  bmm_node = mb.ad
-0002b970: 6428 783d 6269 6173 2c20 793d 626d 6d5f  d(x=bias, y=bmm_
-0002b980: 6e6f 6465 2c20 6e61 6d65 3d6e 6f64 652e  node, name=node.
-0002b990: 6e61 6d65 290a 2020 2020 636f 6e74 6578  name).    contex
-0002b9a0: 742e 6164 6428 6261 6464 626d 6d5f 6e6f  t.add(baddbmm_no
-0002b9b0: 6465 290a 0a0a 4072 6567 6973 7465 725f  de)...@register_
-0002b9c0: 746f 7263 685f 6f70 0a64 6566 2067 6c75  torch_op.def glu
-0002b9d0: 2863 6f6e 7465 7874 2c20 6e6f 6465 293a  (context, node):
-0002b9e0: 0a20 2020 2022 2222 0a20 2020 2067 6c75  .    """.    glu
-0002b9f0: 2854 656e 736f 7220 696e 7075 742c 2053  (Tensor input, S
-0002ba00: 6361 6c61 7220 6469 6d3d 2d31 290a 2020  calar dim=-1).  
-0002ba10: 2020 4170 706c 6965 7320 7468 6520 6761    Applies the ga
-0002ba20: 7465 6420 6c69 6e65 6172 2075 6e69 7420  ted linear unit 
-0002ba30: 6675 6e63 7469 6f6e 2047 4c55 2861 2c62  function GLU(a,b
-0002ba40: 293d 61e2 8a97 cf83 2862 2920 7768 6572  )=a.....(b) wher
-0002ba50: 6520 6120 6973 2074 6865 2066 6972 7374  e a is the first
-0002ba60: 2068 616c 6620 6f66 2074 6865 2069 6e70   half of the inp
-0002ba70: 7574 206d 6174 7269 6365 7320 616e 6420  ut matrices and 
-0002ba80: 6220 6973 2074 6865 0a20 2020 2073 6563  b is the.    sec
-0002ba90: 6f6e 6420 6861 6c66 2e0a 2020 2020 2222  ond half..    ""
-0002baa0: 220a 2020 2020 6173 7365 7274 206c 656e  ".    assert len
-0002bab0: 286e 6f64 652e 6f75 7470 7574 7329 203d  (node.outputs) =
-0002bac0: 3d20 310a 2020 2020 696e 7075 7473 203d  = 1.    inputs =
-0002bad0: 205f 6765 745f 696e 7075 7473 2863 6f6e   _get_inputs(con
-0002bae0: 7465 7874 2c20 6e6f 6465 2c20 6578 7065  text, node, expe
-0002baf0: 6374 6564 3d32 290a 2020 2020 696e 7075  cted=2).    inpu
-0002bb00: 742c 2061 7869 7320 3d20 696e 7075 7473  t, axis = inputs
-0002bb10: 0a0a 2020 2020 6669 7273 745f 6861 6c66  ..    first_half
-0002bb20: 2c20 7365 636f 6e64 5f68 616c 6620 3d20  , second_half = 
-0002bb30: 6d62 2e73 706c 6974 2878 3d69 6e70 7574  mb.split(x=input
-0002bb40: 2c20 6e75 6d5f 7370 6c69 7473 3d32 2c20  , num_splits=2, 
-0002bb50: 6178 6973 3d61 7869 732e 7661 6c2c 206e  axis=axis.val, n
-0002bb60: 616d 653d 6e6f 6465 2e6e 616d 6520 2b20  ame=node.name + 
-0002bb70: 225f 7370 6c69 7422 290a 2020 2020 636f  "_split").    co
-0002bb80: 6e74 6578 742e 6164 6428 6669 7273 745f  ntext.add(first_
-0002bb90: 6861 6c66 290a 2020 2020 636f 6e74 6578  half).    contex
-0002bba0: 742e 6164 6428 7365 636f 6e64 5f68 616c  t.add(second_hal
-0002bbb0: 6629 0a0a 2020 2020 7369 676d 6f69 645f  f)..    sigmoid_
-0002bbc0: 7365 636f 6e64 5f68 616c 6620 3d20 6d62  second_half = mb
-0002bbd0: 2e73 6967 6d6f 6964 2878 3d73 6563 6f6e  .sigmoid(x=secon
-0002bbe0: 645f 6861 6c66 2c20 6e61 6d65 3d73 6563  d_half, name=sec
-0002bbf0: 6f6e 645f 6861 6c66 2e6e 616d 6520 2b20  ond_half.name + 
-0002bc00: 225f 7369 676d 6f69 6422 290a 2020 2020  "_sigmoid").    
-0002bc10: 636f 6e74 6578 742e 6164 6428 7369 676d  context.add(sigm
-0002bc20: 6f69 645f 7365 636f 6e64 5f68 616c 6629  oid_second_half)
-0002bc30: 0a0a 2020 2020 676c 755f 6e6f 6465 203d  ..    glu_node =
-0002bc40: 206d 622e 6d75 6c28 783d 6669 7273 745f   mb.mul(x=first_
-0002bc50: 6861 6c66 2c20 793d 7369 676d 6f69 645f  half, y=sigmoid_
-0002bc60: 7365 636f 6e64 5f68 616c 662c 206e 616d  second_half, nam
-0002bc70: 653d 6e6f 6465 2e6e 616d 6529 0a20 2020  e=node.name).   
-0002bc80: 2063 6f6e 7465 7874 2e61 6464 2867 6c75   context.add(glu
-0002bc90: 5f6e 6f64 6529 0a0a 0a40 7265 6769 7374  _node)...@regist
-0002bca0: 6572 5f74 6f72 6368 5f6f 700a 6465 6620  er_torch_op.def 
-0002bcb0: 6873 7461 636b 2863 6f6e 7465 7874 2c20  hstack(context, 
-0002bcc0: 6e6f 6465 293a 0a20 2020 2022 2222 0a20  node):.    """. 
-0002bcd0: 2020 2068 7374 6163 6b28 4c69 7374 5b54     hstack(List[T
-0002bce0: 656e 736f 725d 2074 656e 736f 7273 2c20  ensor] tensors, 
-0002bcf0: 4f70 7469 6f6e 616c 5b54 656e 736f 725d  Optional[Tensor]
-0002bd00: 206f 7574 290a 2020 2020 5374 6163 6b20   out).    Stack 
-0002bd10: 7465 6e73 6f72 7320 696e 2073 6571 7565  tensors in seque
-0002bd20: 6e63 6520 686f 7269 7a6f 6e74 616c 6c79  nce horizontally
-0002bd30: 2028 636f 6c75 6d6e 2077 6973 6529 2e20   (column wise). 
-0002bd40: 5468 6973 2069 7320 6571 7569 7661 6c65  This is equivale
-0002bd50: 6e74 2074 6f20 636f 6e63 6174 656e 6174  nt to concatenat
-0002bd60: 696f 6e20 616c 6f6e 6720 7468 6520 6669  ion along the fi
-0002bd70: 7273 7420 6178 6973 2066 6f72 0a20 2020  rst axis for.   
-0002bd80: 2031 2d44 2074 656e 736f 7273 2c20 616e   1-D tensors, an
-0002bd90: 6420 616c 6f6e 6720 7468 6520 7365 636f  d along the seco
-0002bda0: 6e64 2061 7869 7320 666f 7220 616c 6c20  nd axis for all 
-0002bdb0: 6f74 6865 7220 7465 6e73 6f72 732e 0a20  other tensors.. 
-0002bdc0: 2020 2022 2222 0a20 2020 2069 6e70 7574     """.    input
-0002bdd0: 7320 3d20 5f67 6574 5f69 6e70 7574 7328  s = _get_inputs(
-0002bde0: 636f 6e74 6578 742c 206e 6f64 6529 0a20  context, node). 
-0002bdf0: 2020 2074 656e 736f 7273 203d 2069 6e70     tensors = inp
-0002be00: 7574 735b 305d 0a20 2020 2069 6e70 7574  uts[0].    input
-0002be10: 5f73 6861 7065 7320 3d20 5b6c 6973 7428  _shapes = [list(
-0002be20: 782e 7368 6170 6529 2066 6f72 2078 2069  x.shape) for x i
-0002be30: 6e20 7465 6e73 6f72 735d 0a20 2020 2023  n tensors].    #
-0002be40: 2043 6f6e 6361 7465 6e61 7465 7320 616c   Concatenates al
-0002be50: 6f6e 6720 7468 6520 6669 7273 7420 6178  ong the first ax
-0002be60: 6973 2066 6f72 2031 2d44 2074 656e 736f  is for 1-D tenso
-0002be70: 7273 2c20 616e 6420 616c 6f6e 6720 7468  rs, and along th
-0002be80: 6520 7365 636f 6e64 2061 7869 7320 666f  e second axis fo
-0002be90: 7220 616c 6c20 6f74 6865 7220 7465 6e73  r all other tens
-0002bea0: 6f72 732e 0a20 2020 2061 7869 7320 3d20  ors..    axis = 
-0002beb0: 3020 6966 206c 656e 2869 6e70 7574 5f73  0 if len(input_s
-0002bec0: 6861 7065 735b 305d 2920 3d3d 2031 2065  hapes[0]) == 1 e
-0002bed0: 6c73 6520 310a 2020 2020 6873 7461 636b  lse 1.    hstack
-0002bee0: 5f6e 6f64 6520 3d20 6d62 2e63 6f6e 6361  _node = mb.conca
-0002bef0: 7428 7661 6c75 6573 3d74 656e 736f 7273  t(values=tensors
-0002bf00: 2c20 6178 6973 3d61 7869 732c 206e 616d  , axis=axis, nam
-0002bf10: 653d 6e6f 6465 2e6e 616d 6529 0a20 2020  e=node.name).   
-0002bf20: 2063 6f6e 7465 7874 2e61 6464 2868 7374   context.add(hst
-0002bf30: 6163 6b5f 6e6f 6465 290a 0a0a 4072 6567  ack_node)...@reg
-0002bf40: 6973 7465 725f 746f 7263 685f 6f70 0a64  ister_torch_op.d
-0002bf50: 6566 2072 656d 6169 6e64 6572 2863 6f6e  ef remainder(con
-0002bf60: 7465 7874 2c20 6e6f 6465 293a 0a20 2020  text, node):.   
-0002bf70: 2022 2222 0a20 2020 2072 656d 6169 6e64   """.    remaind
-0002bf80: 6572 2854 656e 736f 7220 6469 7669 6465  er(Tensor divide
-0002bf90: 6e64 2c20 5465 6e73 6f72 2064 6976 6973  nd, Tensor divis
-0002bfa0: 6f72 2c20 4f70 7469 6f6e 616c 5b54 656e  or, Optional[Ten
-0002bfb0: 736f 725d 206f 7574 290a 2020 2020 436f  sor] out).    Co
-0002bfc0: 6d70 7574 6573 2050 7974 686f 6ee2 8099  mputes Python...
-0002bfd0: 7320 6d6f 6475 6c75 7320 6f70 6572 6174  s modulus operat
-0002bfe0: 696f 6e20 656e 7472 7977 6973 652e 2054  ion entrywise. T
-0002bff0: 6865 2072 6573 756c 7420 6861 7320 7468  he result has th
-0002c000: 6520 7361 6d65 2073 6967 6e20 6173 2074  e same sign as t
-0002c010: 6865 2064 6976 6973 6f72 2061 6e64 2069  he divisor and i
-0002c020: 7473 2061 6273 6f6c 7574 6520 7661 6c75  ts absolute valu
-0002c030: 650a 2020 2020 6973 206c 6573 7320 7468  e.    is less th
-0002c040: 616e 2074 6861 7420 6f66 2064 6976 6973  an that of divis
-0002c050: 6f72 2e20 4974 206d 6179 2061 6c73 6f20  or. It may also 
-0002c060: 6265 2064 6566 696e 6564 2069 6e20 7465  be defined in te
-0002c070: 726d 7320 6f66 2074 6f72 6368 2e64 6976  rms of torch.div
-0002c080: 2829 2061 733a 0a20 2020 2072 656d 6169  () as:.    remai
-0002c090: 6e64 6572 2861 2c20 6229 203d 3d20 6120  nder(a, b) == a 
-0002c0a0: 2d20 612e 6469 7628 622c 2072 6f75 6e64  - a.div(b, round
-0002c0b0: 696e 675f 6d6f 6465 3d22 666c 6f6f 7222  ing_mode="floor"
-0002c0c0: 2920 2a20 620a 2020 2020 2222 220a 2020  ) * b.    """.  
-0002c0d0: 2020 2320 446f 6e27 7420 7370 6563 6966    # Don't specif
-0002c0e0: 7920 6065 7870 6563 7465 6460 2062 6563  y `expected` bec
-0002c0f0: 6175 7365 2074 6865 2070 6172 616d 6574  ause the paramet
-0002c100: 6572 2060 6f75 7460 2069 7320 6f70 7469  er `out` is opti
-0002c110: 6f6e 616c 2e0a 2020 2020 696e 7075 7473  onal..    inputs
-0002c120: 203d 205f 6765 745f 696e 7075 7473 2863   = _get_inputs(c
-0002c130: 6f6e 7465 7874 2c20 6e6f 6465 290a 2020  ontext, node).  
-0002c140: 2020 6469 7669 6465 6e64 2c20 6469 7669    dividend, divi
-0002c150: 736f 7220 3d20 7072 6f6d 6f74 655f 696e  sor = promote_in
-0002c160: 7075 745f 6474 7970 6573 285b 696e 7075  put_dtypes([inpu
-0002c170: 7473 5b30 5d2c 2069 6e70 7574 735b 315d  ts[0], inputs[1]
-0002c180: 5d29 0a20 2020 2064 6976 5f6e 6f64 6520  ]).    div_node 
-0002c190: 3d20 6d62 2e66 6c6f 6f72 5f64 6976 2878  = mb.floor_div(x
-0002c1a0: 3d64 6976 6964 656e 642c 2079 3d64 6976  =dividend, y=div
-0002c1b0: 6973 6f72 2c20 6e61 6d65 3d6e 6f64 652e  isor, name=node.
-0002c1c0: 6e61 6d65 202b 2022 5f64 6976 2229 0a20  name + "_div"). 
-0002c1d0: 2020 2063 6f6e 7465 7874 2e61 6464 2864     context.add(d
-0002c1e0: 6976 5f6e 6f64 6529 0a20 2020 2073 6361  iv_node).    sca
-0002c1f0: 6c65 645f 6469 7620 3d20 6d62 2e6d 756c  led_div = mb.mul
-0002c200: 2878 3d64 6976 5f6e 6f64 652c 2079 3d64  (x=div_node, y=d
-0002c210: 6976 6973 6f72 2c20 6e61 6d65 3d64 6976  ivisor, name=div
-0002c220: 5f6e 6f64 652e 6e61 6d65 202b 2022 5f73  _node.name + "_s
-0002c230: 6361 6c65 6422 290a 2020 2020 636f 6e74  caled").    cont
-0002c240: 6578 742e 6164 6428 7363 616c 6564 5f64  ext.add(scaled_d
-0002c250: 6976 290a 2020 2020 7265 6d61 696e 6465  iv).    remainde
-0002c260: 725f 6e6f 6465 203d 206d 622e 7375 6228  r_node = mb.sub(
-0002c270: 783d 6469 7669 6465 6e64 2c20 793d 7363  x=dividend, y=sc
-0002c280: 616c 6564 5f64 6976 2c20 6e61 6d65 3d6e  aled_div, name=n
-0002c290: 6f64 652e 6e61 6d65 290a 2020 2020 636f  ode.name).    co
-0002c2a0: 6e74 6578 742e 6164 6428 7265 6d61 696e  ntext.add(remain
-0002c2b0: 6465 725f 6e6f 6465 290a 0a0a 4072 6567  der_node)...@reg
-0002c2c0: 6973 7465 725f 746f 7263 685f 6f70 0a64  ister_torch_op.d
-0002c2d0: 6566 2068 616e 6e5f 7769 6e64 6f77 2863  ef hann_window(c
-0002c2e0: 6f6e 7465 7874 2c20 6e6f 6465 293a 0a20  ontext, node):. 
-0002c2f0: 2020 2069 6e70 7574 7320 3d20 5f67 6574     inputs = _get
-0002c300: 5f69 6e70 7574 7328 636f 6e74 6578 742c  _inputs(context,
-0002c310: 206e 6f64 652c 2065 7870 6563 7465 643d   node, expected=
-0002c320: 5b35 2c20 365d 290a 2020 2020 6966 2069  [5, 6]).    if i
-0002c330: 6e70 7574 735b 305d 2e76 616c 2069 7320  nputs[0].val is 
-0002c340: 4e6f 6e65 3a0a 2020 2020 2020 2020 7261  None:.        ra
-0002c350: 6973 6520 4e6f 7449 6d70 6c65 6d65 6e74  ise NotImplement
-0002c360: 6564 4572 726f 7228 2276 6172 6961 626c  edError("variabl
-0002c370: 6520 2777 696e 646f 775f 6c65 6e67 7468  e 'window_length
-0002c380: 2720 6e6f 7420 7375 7070 6f72 7465 642e  ' not supported.
-0002c390: 2229 0a0a 2020 2020 7065 7269 6f64 6963  ")..    periodic
-0002c3a0: 203d 2054 7275 650a 2020 2020 6966 206c   = True.    if l
-0002c3b0: 656e 2869 6e70 7574 7329 203d 3d20 363a  en(inputs) == 6:
-0002c3c0: 0a20 2020 2020 2020 2069 6620 696e 7075  .        if inpu
-0002c3d0: 7473 5b31 5d2e 7661 6c20 6973 204e 6f6e  ts[1].val is Non
-0002c3e0: 653a 0a20 2020 2020 2020 2020 2020 2072  e:.            r
-0002c3f0: 6169 7365 204e 6f74 496d 706c 656d 656e  aise NotImplemen
-0002c400: 7465 6445 7272 6f72 2822 7661 7269 6162  tedError("variab
-0002c410: 6c65 2027 7065 7269 6f64 6963 2720 6e6f  le 'periodic' no
-0002c420: 7420 7375 7070 6f72 7465 642e 2229 0a20  t supported."). 
-0002c430: 2020 2020 2020 2069 6620 6e6f 7420 696e         if not in
-0002c440: 7075 7473 5b31 5d2e 7661 6c3a 0a20 2020  puts[1].val:.   
-0002c450: 2020 2020 2020 2020 2070 6572 696f 6469           periodi
-0002c460: 6320 3d20 4661 6c73 650a 0a20 2020 2073  c = False..    s
-0002c470: 697a 6520 3d20 2869 6e70 7574 735b 305d  ize = (inputs[0]
-0002c480: 2e76 616c 2c29 0a20 2020 2069 6620 696e  .val,).    if in
-0002c490: 7075 7473 5b30 5d2e 7661 6c20 3c3d 2031  puts[0].val <= 1
-0002c4a0: 3a0a 2020 2020 2020 2020 6f6e 6520 3d20  :.        one = 
-0002c4b0: 6d62 2e66 696c 6c28 7368 6170 653d 7369  mb.fill(shape=si
-0002c4c0: 7a65 2c20 7661 6c75 653d 312e 302c 206e  ze, value=1.0, n
-0002c4d0: 616d 653d 6e6f 6465 2e6e 616d 6529 0a20  ame=node.name). 
-0002c4e0: 2020 2020 2020 2063 6f6e 7465 7874 2e61         context.a
-0002c4f0: 6464 286f 6e65 290a 2020 2020 2020 2020  dd(one).        
-0002c500: 7265 7475 726e 0a0a 2020 2020 6f6e 6573  return..    ones
-0002c510: 203d 206d 622e 6669 6c6c 2873 6861 7065   = mb.fill(shape
-0002c520: 3d73 697a 652c 2076 616c 7565 3d31 2e30  =size, value=1.0
-0002c530: 290a 2020 2020 6375 6d20 3d20 6d62 2e63  ).    cum = mb.c
-0002c540: 756d 7375 6d28 783d 6f6e 6573 2c20 6178  umsum(x=ones, ax
-0002c550: 6973 3d30 290a 2020 2020 7365 7120 3d20  is=0).    seq = 
-0002c560: 6d62 2e73 7562 2878 3d63 756d 2c20 793d  mb.sub(x=cum, y=
-0002c570: 6f6e 6573 290a 2020 2020 7069 203d 206d  ones).    pi = m
-0002c580: 622e 6669 6c6c 2873 6861 7065 3d73 697a  b.fill(shape=siz
-0002c590: 652c 2076 616c 7565 3d5f 6d61 7468 2e70  e, value=_math.p
-0002c5a0: 6929 0a20 2020 2077 696e 646f 775f 6c65  i).    window_le
-0002c5b0: 6e67 7468 5f66 6c6f 6174 203d 206d 622e  ngth_float = mb.
-0002c5c0: 6361 7374 2878 3d69 6e70 7574 735b 305d  cast(x=inputs[0]
-0002c5d0: 2c20 6474 7970 653d 2266 7033 3222 290a  , dtype="fp32").
-0002c5e0: 2020 2020 6966 206e 6f74 2070 6572 696f      if not perio
-0002c5f0: 6469 633a 0a20 2020 2020 2020 2077 696e  dic:.        win
-0002c600: 646f 775f 6c65 6e67 7468 5f66 6c6f 6174  dow_length_float
-0002c610: 203d 206d 622e 7375 6228 783d 7769 6e64   = mb.sub(x=wind
-0002c620: 6f77 5f6c 656e 6774 685f 666c 6f61 742c  ow_length_float,
-0002c630: 2079 3d6f 6e65 7329 0a20 2020 2064 656e   y=ones).    den
-0002c640: 6f6d 696e 6174 6f72 203d 206d 622e 6669  ominator = mb.fi
-0002c650: 6c6c 2873 6861 7065 3d73 697a 652c 2076  ll(shape=size, v
-0002c660: 616c 7565 3d77 696e 646f 775f 6c65 6e67  alue=window_leng
-0002c670: 7468 5f66 6c6f 6174 290a 2020 2020 6e75  th_float).    nu
-0002c680: 6d65 7261 746f 7220 3d20 6d62 2e6d 756c  merator = mb.mul
-0002c690: 2878 3d73 6571 2c20 793d 7069 290a 2020  (x=seq, y=pi).  
-0002c6a0: 2020 6672 6163 203d 206d 622e 7265 616c    frac = mb.real
-0002c6b0: 5f64 6976 2878 3d6e 756d 6572 6174 6f72  _div(x=numerator
-0002c6c0: 2c20 793d 6465 6e6f 6d69 6e61 746f 7229  , y=denominator)
-0002c6d0: 0a20 2020 2073 696e 203d 206d 622e 7369  .    sin = mb.si
-0002c6e0: 6e28 783d 6672 6163 290a 2020 2020 7369  n(x=frac).    si
-0002c6f0: 6e5f 7371 203d 206d 622e 6d75 6c28 783d  n_sq = mb.mul(x=
-0002c700: 7369 6e2c 2079 3d73 696e 2c20 6e61 6d65  sin, y=sin, name
-0002c710: 3d6e 6f64 652e 6e61 6d65 290a 2020 2020  =node.name).    
-0002c720: 636f 6e74 6578 742e 6164 6428 7369 6e5f  context.add(sin_
-0002c730: 7371 290a 0a40 7265 6769 7374 6572 5f74  sq)..@register_t
-0002c740: 6f72 6368 5f6f 700a 6465 6620 6d73 655f  orch_op.def mse_
-0002c750: 6c6f 7373 2863 6f6e 7465 7874 2c20 6e6f  loss(context, no
-0002c760: 6465 293a 0a20 2020 2069 6e70 7574 7320  de):.    inputs 
-0002c770: 3d20 5f67 6574 5f69 6e70 7574 7328 636f  = _get_inputs(co
-0002c780: 6e74 6578 742c 206e 6f64 652c 2065 7870  ntext, node, exp
-0002c790: 6563 7465 643d 3329 0a20 2020 2078 203d  ected=3).    x =
-0002c7a0: 2069 6e70 7574 735b 305d 0a20 2020 2079   inputs[0].    y
-0002c7b0: 203d 2069 6e70 7574 735b 315d 0a20 2020   = inputs[1].   
-0002c7c0: 2072 6564 7563 7469 6f6e 203d 2069 6e70   reduction = inp
-0002c7d0: 7574 735b 325d 2e76 616c 0a0a 2020 2020  uts[2].val..    
-0002c7e0: 6469 6666 203d 206d 622e 7375 6228 783d  diff = mb.sub(x=
-0002c7f0: 782c 2079 3d79 290a 0a20 2020 2069 6620  x, y=y)..    if 
-0002c800: 7265 6475 6374 696f 6e20 3d3d 2030 3a0a  reduction == 0:.
-0002c810: 2020 2020 2020 2020 2320 7265 6475 6374          # reduct
-0002c820: 696f 6e20 6973 2022 6e6f 6e65 220a 2020  ion is "none".  
-0002c830: 2020 2020 2020 7265 7320 3d20 6d62 2e6d        res = mb.m
-0002c840: 756c 2878 3d64 6966 662c 2079 3d64 6966  ul(x=diff, y=dif
-0002c850: 662c 206e 616d 653d 6e6f 6465 2e6e 616d  f, name=node.nam
-0002c860: 6529 0a20 2020 2020 2020 2063 6f6e 7465  e).        conte
-0002c870: 7874 2e61 6464 2872 6573 290a 2020 2020  xt.add(res).    
-0002c880: 2020 2020 7265 7475 726e 0a0a 2020 2020      return..    
-0002c890: 7371 7561 7265 203d 206d 622e 6d75 6c28  square = mb.mul(
-0002c8a0: 783d 6469 6666 2c20 793d 6469 6666 290a  x=diff, y=diff).
-0002c8b0: 2020 2020 6966 2072 6564 7563 7469 6f6e      if reduction
-0002c8c0: 203d 3d20 313a 0a20 2020 2020 2020 2023   == 1:.        #
-0002c8d0: 2072 6564 7563 7469 6f6e 2069 7320 226d   reduction is "m
-0002c8e0: 6561 6e22 0a20 2020 2020 2020 2072 6573  ean".        res
-0002c8f0: 203d 206d 622e 7265 6475 6365 5f6d 6561   = mb.reduce_mea
-0002c900: 6e28 783d 7371 7561 7265 2c20 6178 6573  n(x=square, axes
-0002c910: 3d4e 6f6e 652c 206e 616d 653d 6e6f 6465  =None, name=node
-0002c920: 2e6e 616d 6529 0a0a 2020 2020 656c 6966  .name)..    elif
-0002c930: 2072 6564 7563 7469 6f6e 203d 3d20 323a   reduction == 2:
-0002c940: 0a20 2020 2020 2020 2023 2072 6564 7563  .        # reduc
-0002c950: 7469 6f6e 2069 7320 2273 756d 220a 2020  tion is "sum".  
-0002c960: 2020 2020 2020 7265 7320 3d20 6d62 2e72        res = mb.r
-0002c970: 6564 7563 655f 7375 6d28 783d 7371 7561  educe_sum(x=squa
-0002c980: 7265 2c20 6178 6573 3d4e 6f6e 652c 206e  re, axes=None, n
-0002c990: 616d 653d 6e6f 6465 2e6e 616d 6529 0a20  ame=node.name). 
-0002c9a0: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
-0002c9b0: 2072 6169 7365 2056 616c 7565 4572 726f   raise ValueErro
-0002c9c0: 7228 2252 6564 7563 7469 6f6e 2069 7320  r("Reduction is 
-0002c9d0: 6e6f 7420 7375 7070 6f72 7465 6422 290a  not supported").
-0002c9e0: 0a20 2020 2063 6f6e 7465 7874 2e61 6464  .    context.add
-0002c9f0: 2872 6573 290a 0a40 7265 6769 7374 6572  (res)..@register
-0002ca00: 5f74 6f72 6368 5f6f 700a 6465 6620 7472  _torch_op.def tr
-0002ca10: 6163 6528 636f 6e74 6578 742c 206e 6f64  ace(context, nod
-0002ca20: 6529 3a0a 2020 2020 696e 7075 7473 203d  e):.    inputs =
-0002ca30: 205f 6765 745f 696e 7075 7473 2863 6f6e   _get_inputs(con
-0002ca40: 7465 7874 2c20 6e6f 6465 2c20 6578 7065  text, node, expe
-0002ca50: 6374 6564 3d31 290a 2020 2020 7820 3d20  cted=1).    x = 
-0002ca60: 696e 7075 7473 5b30 5d0a 2020 2020 6469  inputs[0].    di
-0002ca70: 6d73 203d 206d 622e 7368 6170 6528 783d  ms = mb.shape(x=
-0002ca80: 7829 0a20 2020 2064 696d 3020 3d20 7661  x).    dim0 = va
-0002ca90: 6c75 655f 6174 2864 696d 732c 2030 290a  lue_at(dims, 0).
-0002caa0: 2020 2020 6469 6d31 203d 2076 616c 7565      dim1 = value
-0002cab0: 5f61 7428 6469 6d73 2c20 3129 0a20 2020  _at(dims, 1).   
-0002cac0: 206d 696e 5f64 696d 203d 206d 622e 6d69   min_dim = mb.mi
-0002cad0: 6e69 6d75 6d28 783d 6469 6d30 2c20 793d  nimum(x=dim0, y=
-0002cae0: 6469 6d31 290a 2020 2020 696e 6469 6365  dim1).    indice
-0002caf0: 7320 3d20 6d62 2e72 616e 6765 5f31 6428  s = mb.range_1d(
-0002cb00: 656e 643d 6d69 6e5f 6469 6d2c 2073 7461  end=min_dim, sta
-0002cb10: 7274 3d30 2c20 7374 6570 3d31 290a 2020  rt=0, step=1).  
-0002cb20: 2020 696e 6469 6365 7320 3d20 6d62 2e73    indices = mb.s
-0002cb30: 7461 636b 2876 616c 7565 733d 5b69 6e64  tack(values=[ind
-0002cb40: 6963 6573 2c20 696e 6469 6365 735d 2c20  ices, indices], 
-0002cb50: 6178 6973 3d31 290a 2020 2020 6469 6167  axis=1).    diag
-0002cb60: 6f6e 616c 203d 206d 622e 6761 7468 6572  onal = mb.gather
-0002cb70: 5f6e 6428 783d 782c 2069 6e64 6963 6573  _nd(x=x, indices
-0002cb80: 3d69 6e64 6963 6573 290a 2020 2020 7472  =indices).    tr
-0002cb90: 6163 6520 3d20 6d62 2e72 6564 7563 655f  ace = mb.reduce_
-0002cba0: 7375 6d28 783d 6469 6167 6f6e 616c 2c20  sum(x=diagonal, 
-0002cbb0: 6e61 6d65 3d6e 6f64 652e 6e61 6d65 290a  name=node.name).
-0002cbc0: 2020 2020 636f 6e74 6578 742e 6164 6428      context.add(
-0002cbd0: 7472 6163 6529 0a0a 4072 6567 6973 7465  trace)..@registe
-0002cbe0: 725f 746f 7263 685f 6f70 0a64 6566 2072  r_torch_op.def r
-0002cbf0: 6f6c 6c28 636f 6e74 6578 742c 206e 6f64  oll(context, nod
-0002cc00: 6529 3a0a 2020 2020 696e 7075 7473 203d  e):.    inputs =
-0002cc10: 205f 6765 745f 696e 7075 7473 2863 6f6e   _get_inputs(con
-0002cc20: 7465 7874 2c20 6e6f 6465 2c20 6578 7065  text, node, expe
-0002cc30: 6374 6564 3d33 290a 2020 2020 7820 3d20  cted=3).    x = 
-0002cc40: 696e 7075 7473 5b30 5d0a 2020 2020 7368  inputs[0].    sh
-0002cc50: 6966 7420 3d20 696e 7075 7473 5b31 5d2e  ift = inputs[1].
-0002cc60: 7661 6c0a 2020 2020 6469 6d73 203d 2069  val.    dims = i
-0002cc70: 6e70 7574 735b 325d 2e76 616c 0a20 2020  nputs[2].val.   
-0002cc80: 206f 7269 6769 6e5f 7368 6170 6520 3d20   origin_shape = 
-0002cc90: 6d62 2e73 6861 7065 2878 3d78 290a 0a20  mb.shape(x=x).. 
-0002cca0: 2020 206e 6565 645f 666c 6174 7465 6e20     need_flatten 
-0002ccb0: 3d20 6c65 6e28 6469 6d73 2920 3d3d 2030  = len(dims) == 0
-0002ccc0: 0a0a 2020 2020 6966 206e 6565 645f 666c  ..    if need_fl
-0002ccd0: 6174 7465 6e3a 0a20 2020 2020 2020 2023  atten:.        #
-0002cce0: 2054 6865 2074 656e 736f 7220 6973 2066   The tensor is f
-0002ccf0: 6c61 7474 656e 6564 2062 6566 6f72 6520  lattened before 
-0002cd00: 726f 6c6c 696e 670a 2020 2020 2020 2020  rolling.        
-0002cd10: 7820 3d20 6d62 2e72 6573 6861 7065 2878  x = mb.reshape(x
-0002cd20: 3d78 2c20 7368 6170 653d 5b2d 315d 290a  =x, shape=[-1]).
-0002cd30: 2020 2020 2020 2020 6469 6d73 203d 205b          dims = [
-0002cd40: 305d 0a0a 2020 2020 7368 6170 6520 3d20  0]..    shape = 
-0002cd50: 6d62 2e73 6861 7065 2878 3d78 290a 0a20  mb.shape(x=x).. 
-0002cd60: 2020 2066 6f72 2073 2c20 6920 696e 207a     for s, i in z
-0002cd70: 6970 2873 6869 6674 2c20 6469 6d73 293a  ip(shift, dims):
-0002cd80: 0a20 2020 2020 2020 2064 696d 203d 2076  .        dim = v
-0002cd90: 616c 7565 5f61 7428 7368 6170 652c 2069  alue_at(shape, i
-0002cda0: 290a 2020 2020 2020 2020 7320 3d20 6d62  ).        s = mb
-0002cdb0: 2e6d 6f64 2878 3d73 2c20 793d 6469 6d29  .mod(x=s, y=dim)
-0002cdc0: 0a20 2020 2020 2020 2073 7461 7274 5f69  .        start_i
-0002cdd0: 6478 203d 206d 622e 7375 6228 783d 6469  dx = mb.sub(x=di
-0002cde0: 6d2c 2079 3d73 290a 2020 2020 2020 2020  m, y=s).        
-0002cdf0: 696e 6469 6365 7330 203d 206d 622e 7261  indices0 = mb.ra
-0002ce00: 6e67 655f 3164 2865 6e64 3d64 696d 2c20  nge_1d(end=dim, 
-0002ce10: 7374 6172 743d 7374 6172 745f 6964 782c  start=start_idx,
-0002ce20: 2073 7465 703d 3129 0a20 2020 2020 2020   step=1).       
-0002ce30: 2069 6e64 6963 6573 3120 3d20 6d62 2e72   indices1 = mb.r
-0002ce40: 616e 6765 5f31 6428 656e 643d 7374 6172  ange_1d(end=star
-0002ce50: 745f 6964 782c 2073 7461 7274 3d30 2c20  t_idx, start=0, 
-0002ce60: 7374 6570 3d31 290a 2020 2020 2020 2020  step=1).        
-0002ce70: 696e 6469 6365 7320 3d20 6d62 2e63 6f6e  indices = mb.con
-0002ce80: 6361 7428 7661 6c75 6573 3d5b 696e 6469  cat(values=[indi
-0002ce90: 6365 7330 2c20 696e 6469 6365 7331 5d2c  ces0, indices1],
-0002cea0: 2061 7869 733d 3029 0a20 2020 2020 2020   axis=0).       
-0002ceb0: 2078 203d 206d 622e 6761 7468 6572 2878   x = mb.gather(x
-0002cec0: 3d78 2c20 696e 6469 6365 733d 696e 6469  =x, indices=indi
-0002ced0: 6365 732c 2061 7869 733d 6929 0a0a 2020  ces, axis=i)..  
-0002cee0: 2020 6966 206e 6565 645f 666c 6174 7465    if need_flatte
-0002cef0: 6e3a 0a20 2020 2020 2020 2078 203d 206d  n:.        x = m
-0002cf00: 622e 7265 7368 6170 6528 783d 782c 2073  b.reshape(x=x, s
-0002cf10: 6861 7065 3d6f 7269 6769 6e5f 7368 6170  hape=origin_shap
-0002cf20: 6529 0a0a 2020 2020 636f 6e74 6578 742e  e)..    context.
-0002cf30: 6164 6428 782c 206e 6f64 652e 6e61 6d65  add(x, node.name
-0002cf40: 290a 0a0a 4072 6567 6973 7465 725f 746f  )...@register_to
-0002cf50: 7263 685f 6f70 0a64 6566 2069 6d32 636f  rch_op.def im2co
-0002cf60: 6c28 636f 6e74 6578 742c 206e 6f64 6529  l(context, node)
-0002cf70: 3a0a 2020 2020 2222 220a 2020 2020 4578  :.    """.    Ex
-0002cf80: 7472 6163 7420 736c 6964 696e 6720 6c6f  tract sliding lo
-0002cf90: 6361 6c20 626c 6f63 6b73 2066 726f 6d20  cal blocks from 
-0002cfa0: 6120 6261 7463 6865 6420 696e 7075 7420  a batched input 
-0002cfb0: 7465 6e73 6f72 2028 7261 6e6b 3d34 292e  tensor (rank=4).
-0002cfc0: 0a0a 2020 2020 746f 7263 682e 6e6e 2e66  ..    torch.nn.f
-0002cfd0: 756e 6374 696f 6e61 6c2e 756e 666f 6c64  unctional.unfold
-0002cfe0: 2061 696d 7320 746f 2062 6520 7468 6520   aims to be the 
-0002cff0: 6765 6e65 7261 6c20 7665 7273 696f 6e3a  general version:
-0002d000: 2069 6d32 636f 6c20 6973 2074 6865 2072   im2col is the r
-0002d010: 616e 6b3d 3420 6361 7365 206f 6620 756e  ank=4 case of un
-0002d020: 666f 6c64 2e0a 2020 2020 5079 546f 7263  fold..    PyTorc
-0002d030: 6820 6375 7272 656e 746c 7920 6f6e 6c79  h currently only
-0002d040: 2073 7570 706f 7274 7320 7261 6e6b 3d34   supports rank=4
-0002d050: 2069 6e70 7574 3a20 746f 7263 682e 6e6e   input: torch.nn
-0002d060: 2e66 756e 6374 696f 6e61 6c2e 756e 666f  .functional.unfo
-0002d070: 6c64 2072 6564 6973 7061 7463 6865 7320  ld redispatches 
-0002d080: 746f 2061 743a 3a69 6d32 636f 6c2c 0a20  to at::im2col,. 
-0002d090: 2020 2077 6869 6368 2069 7320 7768 7920     which is why 
-0002d0a0: 636f 7265 6d6c 746f 6f6c 7320 6e65 6564  coremltools need
-0002d0b0: 7320 696d 3263 6f6c 2074 6f20 636f 6e76  s im2col to conv
-0002d0c0: 6572 7420 746f 7263 682e 6e6e 2e66 756e  ert torch.nn.fun
-0002d0d0: 6374 696f 6e61 6c2e 756e 666f 6c64 2e0a  ctional.unfold..
-0002d0e0: 0a20 2020 2057 6520 6375 7272 656e 746c  .    We currentl
-0002d0f0: 7920 6f6e 6c79 2073 7570 706f 7274 2072  y only support r
-0002d100: 616e 6b3d 3420 696e 7075 7420 2863 6f6e  ank=4 input (con
-0002d110: 7369 7374 656e 7420 7769 7468 2050 7954  sistent with PyT
-0002d120: 6f72 6368 2920 616e 6420 6469 6c61 7469  orch) and dilati
-0002d130: 6f6e 2073 6574 2074 6f20 312e 0a20 2020  on set to 1..   
-0002d140: 204d 6f72 6520 666c 6578 6269 626c 6520   More flexbible 
-0002d150: 6469 6c61 7469 6f6e 2073 7570 706f 7274  dilation support
-0002d160: 2077 696c 6c20 6265 2061 6464 6564 2069   will be added i
-0002d170: 6e20 7468 6520 6675 7475 7265 2e0a 0a20  n the future... 
-0002d180: 2020 2052 6566 6572 656e 6365 2068 7474     Reference htt
-0002d190: 7073 3a2f 2f70 7974 6f72 6368 2e6f 7267  ps://pytorch.org
-0002d1a0: 2f64 6f63 732f 7374 6162 6c65 2f67 656e  /docs/stable/gen
-0002d1b0: 6572 6174 6564 2f74 6f72 6368 2e6e 6e2e  erated/torch.nn.
-0002d1c0: 556e 666f 6c64 2e68 746d 6c0a 2020 2020  Unfold.html.    
-0002d1d0: 2222 220a 2020 2020 696e 7075 7473 203d  """.    inputs =
-0002d1e0: 205f 6765 745f 696e 7075 7473 2863 6f6e   _get_inputs(con
-0002d1f0: 7465 7874 2c20 6e6f 6465 2c20 6578 7065  text, node, expe
-0002d200: 6374 6564 3d35 290a 2020 2020 7820 3d20  cted=5).    x = 
-0002d210: 696e 7075 7473 5b30 5d0a 2020 2020 6b65  inputs[0].    ke
-0002d220: 726e 656c 5f73 697a 6520 3d20 696e 7075  rnel_size = inpu
-0002d230: 7473 5b31 5d2e 7661 6c0a 2020 2020 6469  ts[1].val.    di
-0002d240: 6c61 7469 6f6e 203d 2069 6e70 7574 735b  lation = inputs[
-0002d250: 325d 2e76 616c 0a20 2020 2070 6164 6469  2].val.    paddi
-0002d260: 6e67 203d 2069 6e70 7574 735b 335d 2e76  ng = inputs[3].v
-0002d270: 616c 0a20 2020 2073 7472 6964 6520 3d20  al.    stride = 
-0002d280: 696e 7075 7473 5b34 5d2e 7661 6c0a 0a20  inputs[4].val.. 
-0002d290: 2020 2069 6620 782e 7261 6e6b 2021 3d20     if x.rank != 
-0002d2a0: 343a 0a20 2020 2020 2020 2072 6169 7365  4:.        raise
-0002d2b0: 2056 616c 7565 4572 726f 7228 224f 6e6c   ValueError("Onl
-0002d2c0: 7920 7375 7070 6f72 7473 2072 616e 6b3d  y supports rank=
-0002d2d0: 3420 696e 7075 7420 6461 7461 2066 6f72  4 input data for
-0002d2e0: 2069 6d32 636f 6c20 2875 6e66 6f6c 6429   im2col (unfold)
-0002d2f0: 2e22 290a 2020 2020 6966 206e 6f74 2028  .").    if not (
-0002d300: 6469 6c61 7469 6f6e 5b30 5d20 3d3d 2031  dilation[0] == 1
-0002d310: 2061 6e64 2064 696c 6174 696f 6e5b 315d   and dilation[1]
-0002d320: 203d 3d20 3129 3a0a 2020 2020 2020 2020   == 1):.        
-0002d330: 7261 6973 6520 5661 6c75 6545 7272 6f72  raise ValueError
-0002d340: 2822 4f6e 6c79 2073 7570 706f 7274 7320  ("Only supports 
-0002d350: 6469 6c61 7469 6f6e 3d31 2066 6f72 2069  dilation=1 for i
-0002d360: 6d32 636f 6c20 2875 6e66 6f6c 6429 2e22  m2col (unfold)."
-0002d370: 290a 0a20 2020 2023 2066 6f72 2073 696d  )..    # for sim
-0002d380: 706c 6963 6974 792c 2077 6520 6578 706c  plicity, we expl
-0002d390: 6963 6974 6c79 2070 6164 3b20 544f 444f  icitly pad; TODO
-0002d3a0: 3a20 696d 706c 6963 6974 2070 6164 6469  : implicit paddi
-0002d3b0: 6e67 2077 6f75 6c64 2062 6520 6d6f 7265  ng would be more
-0002d3c0: 2065 6666 6963 6965 6e74 0a20 2020 2023   efficient.    #
-0002d3d0: 2074 6f72 6368 2e75 6e66 6f6c 6420 7061   torch.unfold pa
-0002d3e0: 6464 696e 6720 6861 7320 6469 6666 6572  dding has differ
-0002d3f0: 656e 7420 7365 6d61 6e74 6963 730a 2020  ent semantics.  
-0002d400: 2020 2320 2a20 666f 7220 746f 7263 682e    # * for torch.
-0002d410: 756e 666f 6c64 0a20 2020 2023 2020 2078  unfold.    #   x
-0002d420: 2e73 6861 7065 5b69 202b 2078 2e72 616e  .shape[i + x.ran
-0002d430: 6b20 2d20 7061 6464 696e 672e 7261 6e6b  k - padding.rank
-0002d440: 5d20 3d20 7061 6464 696e 675b 695d 202b  ] = padding[i] +
-0002d450: 2078 2e73 6861 7065 5b69 202b 2078 2e72   x.shape[i + x.r
-0002d460: 616e 6b20 2d20 7061 6464 696e 672e 7261  ank - padding.ra
-0002d470: 6e6b 5d20 2b20 7061 6464 696e 675b 695d  nk] + padding[i]
-0002d480: 0a20 2020 2023 2020 2074 616b 696e 6720  .    #   taking 
-0002d490: 782e 7261 6e6b 203d 2034 2061 6e64 2070  x.rank = 4 and p
-0002d4a0: 6164 6469 6e67 2e72 616e 6b20 3d20 3220  adding.rank = 2 
-0002d4b0: 6173 2061 6e20 6578 616d 706c 653a 0a20  as an example:. 
-0002d4c0: 2020 2023 2020 2020 2020 2078 2e73 6861     #       x.sha
-0002d4d0: 7065 5b30 202b 2034 202d 2032 5d20 3d20  pe[0 + 4 - 2] = 
-0002d4e0: 7061 6464 696e 675b 305d 202b 2078 2e73  padding[0] + x.s
-0002d4f0: 6861 7065 5b30 202b 2034 202d 2032 5d20  hape[0 + 4 - 2] 
-0002d500: 2b20 7061 6464 696e 675b 305d 0a20 2020  + padding[0].   
-0002d510: 2023 2020 2020 2020 2078 2e73 6861 7065   #       x.shape
-0002d520: 5b31 202b 2034 202d 2032 5d20 3d20 7061  [1 + 4 - 2] = pa
-0002d530: 6464 696e 675b 315d 202b 2078 2e73 6861  dding[1] + x.sha
-0002d540: 7065 5b31 202b 2034 202d 2032 5d20 2b20  pe[1 + 4 - 2] + 
-0002d550: 7061 6464 696e 675b 315d 0a20 2020 2023  padding[1].    #
-0002d560: 202a 2066 6f72 206d 622e 7061 6428 783d   * for mb.pad(x=
-0002d570: 782c 2070 6164 3d70 6164 2c20 6d6f 6465  x, pad=pad, mode
-0002d580: 3d22 636f 6e73 7461 6e74 2229 0a20 2020  ="constant").   
-0002d590: 2023 2020 2078 2e73 6861 7065 5b69 5d20   #   x.shape[i] 
-0002d5a0: 3d20 7061 645b 3220 2a20 695d 202b 2078  = pad[2 * i] + x
-0002d5b0: 2e73 6861 7065 5b69 5d20 2b20 7061 645b  .shape[i] + pad[
-0002d5c0: 3220 2a20 6920 2b20 315d 0a20 2020 2023  2 * i + 1].    #
-0002d5d0: 202a 2066 6f72 2074 6f72 6368 2e6e 6e2e   * for torch.nn.
-0002d5e0: 6675 6e63 7469 6f6e 616c 2e70 6164 0a20  functional.pad. 
-0002d5f0: 2020 2023 2020 2078 2e73 6861 7065 5b2d     #   x.shape[-
-0002d600: 315d 203d 2070 6164 6469 6e67 5b30 5d20  1] = padding[0] 
-0002d610: 2b78 2e73 6861 7065 5b2d 315d 202b 2070  +x.shape[-1] + p
-0002d620: 6164 6469 6e67 5b31 5d0a 2020 2020 2320  adding[1].    # 
-0002d630: 2020 782e 7368 6170 655b 2d32 5d20 3d20    x.shape[-2] = 
-0002d640: 7061 6464 696e 675b 325d 202b 782e 7368  padding[2] +x.sh
-0002d650: 6170 655b 2d31 5d20 2b20 7061 6464 696e  ape[-1] + paddin
-0002d660: 675b 335d 0a20 2020 2023 2020 202e 2e2e  g[3].    #   ...
-0002d670: 0a20 2020 2023 2020 2078 2e73 6861 7065  .    #   x.shape
-0002d680: 5b2d 695d 203d 2070 6164 6469 6e67 5b32  [-i] = padding[2
-0002d690: 202a 2069 202d 2032 5d20 2b20 782e 7368   * i - 2] + x.sh
-0002d6a0: 6170 655b 2d69 5d20 2b20 7061 6464 696e  ape[-i] + paddin
-0002d6b0: 675b 3220 2a20 6920 2d20 315d 0a20 2020  g[2 * i - 1].   
-0002d6c0: 2023 2073 6f20 7765 206e 6565 6420 746f   # so we need to
-0002d6d0: 2063 6f6e 7665 7274 2074 6f72 6368 2e75   convert torch.u
-0002d6e0: 6e66 6f6c 6420 7061 6464 696e 6720 746f  nfold padding to
-0002d6f0: 206d 622e 7061 6428 6d6f 6465 3d22 636f   mb.pad(mode="co
-0002d700: 6e73 7461 6e74 2229 2070 6164 0a20 2020  nstant") pad.   
-0002d710: 206d 6973 7369 6e67 5f64 696d 7320 3d20   missing_dims = 
-0002d720: 782e 7261 6e6b 202d 206c 656e 2870 6164  x.rank - len(pad
-0002d730: 6469 6e67 290a 2020 2020 7061 6420 3d20  ding).    pad = 
-0002d740: 5b30 2c20 305d 202a 206d 6973 7369 6e67  [0, 0] * missing
-0002d750: 5f64 696d 7320 2b20 5f6e 702e 6172 7261  _dims + _np.arra
-0002d760: 7928 7061 6464 696e 6729 2e72 6570 6561  y(padding).repea
-0002d770: 7428 3229 2e74 6f6c 6973 7428 290a 2020  t(2).tolist().  
-0002d780: 2020 7820 3d20 6d62 2e70 6164 2878 3d78    x = mb.pad(x=x
-0002d790: 2c20 7061 643d 7061 642c 206d 6f64 653d  , pad=pad, mode=
-0002d7a0: 2263 6f6e 7374 616e 7422 290a 0a20 2020  "constant")..   
-0002d7b0: 204e 2c20 432c 2048 2c20 5720 3d20 782e   N, C, H, W = x.
-0002d7c0: 7368 6170 650a 0a20 2020 2023 2047 6574  shape..    # Get
-0002d7d0: 2074 6f74 616c 206e 756d 6265 7220 6f66   total number of
-0002d7e0: 2062 6c6f 636b 732e 2049 7420 666f 6c6c   blocks. It foll
-0002d7f0: 6f77 7320 7468 6520 666f 726d 756c 6120  ows the formula 
-0002d800: 6174 2074 6f72 6368 2e6e 6e2e 556e 666f  at torch.nn.Unfo
-0002d810: 6c64 2064 6f63 756d 656e 7461 7469 6f6e  ld documentation
-0002d820: 2e0a 2020 2020 7370 7469 616c 5f73 697a  ..    sptial_siz
-0002d830: 6520 3d20 2848 2c20 5729 0a20 2020 2062  e = (H, W).    b
-0002d840: 6c6f 636b 5f63 6f75 6e74 203d 2031 0a20  lock_count = 1. 
-0002d850: 2020 2066 6f72 2069 2069 6e20 7261 6e67     for i in rang
-0002d860: 6528 3229 3a0a 2020 2020 2020 2020 626c  e(2):.        bl
-0002d870: 6f63 6b5f 636f 756e 7420 2a3d 2028 0a20  ock_count *= (. 
-0002d880: 2020 2020 2020 2020 2020 205f 6e70 2e66             _np.f
-0002d890: 6c6f 6f72 280a 2020 2020 2020 2020 2020  loor(.          
-0002d8a0: 2020 2020 2020 2320 7468 6520 6f72 6967        # the orig
-0002d8b0: 696e 616c 2066 6f72 6d75 6c61 2069 730a  inal formula is.
-0002d8c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002d8d0: 2320 2020 2020 2873 7074 6961 6c5f 7369  #     (sptial_si
-0002d8e0: 7a65 5b69 5d20 2b20 3220 2a20 7061 6464  ze[i] + 2 * padd
-0002d8f0: 696e 675b 695d 202d 2064 696c 6174 696f  ing[i] - dilatio
-0002d900: 6e5b 695d 202a 2028 6b65 726e 656c 5f73  n[i] * (kernel_s
-0002d910: 697a 655b 695d 202d 2031 2920 2d20 3129  ize[i] - 1) - 1)
-0002d920: 202f 2073 7472 6964 655b 695d 0a20 2020   / stride[i].   
-0002d930: 2020 2020 2020 2020 2020 2020 2023 2073               # s
-0002d940: 696e 6365 2077 6520 6861 7665 2065 7870  ince we have exp
-0002d950: 6c69 6369 746c 7920 7061 6464 6564 2c20  licitly padded, 
-0002d960: 7765 206e 6f20 6c6f 6e67 6572 2061 6464  we no longer add
-0002d970: 2032 202a 2070 6164 6469 6e67 5b69 5d20   2 * padding[i] 
-0002d980: 746f 2073 7074 6961 6c5f 7369 7a65 5b69  to sptial_size[i
-0002d990: 5d0a 2020 2020 2020 2020 2020 2020 2020  ].              
-0002d9a0: 2020 2873 7074 6961 6c5f 7369 7a65 5b69    (sptial_size[i
-0002d9b0: 5d20 2d20 6469 6c61 7469 6f6e 5b69 5d20  ] - dilation[i] 
-0002d9c0: 2a20 286b 6572 6e65 6c5f 7369 7a65 5b69  * (kernel_size[i
-0002d9d0: 5d20 2d20 3129 202d 2031 2920 2f20 7374  ] - 1) - 1) / st
-0002d9e0: 7269 6465 5b69 5d0a 2020 2020 2020 2020  ride[i].        
-0002d9f0: 2020 2020 292e 6173 7479 7065 285f 6e70      ).astype(_np
-0002da00: 2e69 6e74 3332 290a 2020 2020 2020 2020  .int32).        
-0002da10: 2020 2020 2b20 310a 2020 2020 2020 2020      + 1.        
-0002da20: 290a 0a20 2020 2022 2222 0a20 2020 2054  )..    """.    T
-0002da30: 6865 2069 6d70 6c65 6d65 6e74 6174 696f  he implementatio
-0002da40: 6e20 6265 6c6f 7720 6173 7375 6d65 7320  n below assumes 
-0002da50: 7820 746f 2062 6520 636f 6e74 6967 756f  x to be contiguo
-0002da60: 7573 0a20 2020 2022 2222 0a0a 2020 2020  us.    """..    
-0002da70: 2320 4765 7420 6261 7463 6820 626c 6f63  # Get batch bloc
-0002da80: 6b20 696e 6469 6365 732e 0a20 2020 2062  k indices..    b
-0002da90: 6174 6368 5f69 6478 203d 205f 6e70 2e61  atch_idx = _np.a
-0002daa0: 7261 6e67 6528 4e29 5b3a 2c20 4e6f 6e65  range(N)[:, None
-0002dab0: 2c20 4e6f 6e65 5d20 2a20 4320 2a20 4820  , None] * C * H 
-0002dac0: 2a20 570a 0a20 2020 2023 2047 6574 2073  * W..    # Get s
-0002dad0: 7461 7274 696e 6720 626c 6f63 6b20 696e  tarting block in
-0002dae0: 6469 6365 732e 0a20 2020 2073 7461 7274  dices..    start
-0002daf0: 5f69 6478 203d 205f 6e70 2e61 7261 6e67  _idx = _np.arang
-0002db00: 6528 6b65 726e 656c 5f73 697a 655b 305d  e(kernel_size[0]
-0002db10: 295b 4e6f 6e65 2c20 3a2c 204e 6f6e 655d  )[None, :, None]
-0002db20: 202a 2057 202b 205f 6e70 2e61 7261 6e67   * W + _np.arang
-0002db30: 6528 0a20 2020 2020 2020 206b 6572 6e65  e(.        kerne
-0002db40: 6c5f 7369 7a65 5b31 5d0a 2020 2020 290a  l_size[1].    ).
-0002db50: 0a20 2020 2023 2047 656e 6572 6174 6520  .    # Generate 
-0002db60: 6465 7074 6820 696e 6469 6365 732e 0a20  depth indices.. 
-0002db70: 2020 2063 6861 6e6e 656c 5f69 6e64 6578     channel_index
-0002db80: 203d 2048 202a 2057 202a 205f 6e70 2e61   = H * W * _np.a
-0002db90: 7261 6e67 6528 4329 0a20 2020 2073 7461  range(C).    sta
-0002dba0: 7274 5f69 6478 203d 2028 6368 616e 6e65  rt_idx = (channe
-0002dbb0: 6c5f 696e 6465 785b 4e6f 6e65 2c20 3a2c  l_index[None, :,
-0002dbc0: 204e 6f6e 655d 202b 205f 6e70 2e72 6176   None] + _np.rav
-0002dbd0: 656c 2873 7461 7274 5f69 6478 2929 2e72  el(start_idx)).r
-0002dbe0: 6573 6861 7065 280a 2020 2020 2020 2020  eshape(.        
-0002dbf0: 282d 312c 206b 6572 6e65 6c5f 7369 7a65  (-1, kernel_size
-0002dc00: 5b30 5d2c 206b 6572 6e65 6c5f 7369 7a65  [0], kernel_size
-0002dc10: 5b31 5d29 0a20 2020 2029 0a0a 2020 2020  [1]).    )..    
-0002dc20: 2320 4765 7420 6f66 6673 6574 7465 6420  # Get offsetted 
-0002dc30: 696e 6469 6365 7320 6163 726f 7373 2074  indices across t
-0002dc40: 6865 2068 6569 6768 7420 616e 6420 7769  he height and wi
-0002dc50: 6474 6820 6f66 2069 6e70 7574 2061 7272  dth of input arr
-0002dc60: 6179 2e0a 2020 2020 726f 775f 6578 7465  ay..    row_exte
-0002dc70: 6e74 203d 2048 202d 206b 6572 6e65 6c5f  nt = H - kernel_
-0002dc80: 7369 7a65 5b30 5d20 2b20 310a 2020 2020  size[0] + 1.    
-0002dc90: 636f 6c5f 6578 7465 6e74 203d 2057 202d  col_extent = W -
-0002dca0: 206b 6572 6e65 6c5f 7369 7a65 5b31 5d20   kernel_size[1] 
-0002dcb0: 2b20 310a 2020 2020 6f66 6673 6574 5f69  + 1.    offset_i
-0002dcc0: 6478 203d 205f 6e70 2e61 7261 6e67 6528  dx = _np.arange(
-0002dcd0: 302c 2072 6f77 5f65 7874 656e 742c 2073  0, row_extent, s
-0002dce0: 7472 6964 655b 305d 295b 4e6f 6e65 2c20  tride[0])[None, 
-0002dcf0: 3a2c 204e 6f6e 655d 202a 2057 202b 205f  :, None] * W + _
-0002dd00: 6e70 2e61 7261 6e67 6528 302c 2063 6f6c  np.arange(0, col
-0002dd10: 5f65 7874 656e 742c 2073 7472 6964 655b  _extent, stride[
-0002dd20: 315d 290a 2020 2020 696e 6469 6365 7320  1]).    indices 
-0002dd30: 3d20 5f6e 702e 7261 7665 6c28 7374 6172  = _np.ravel(star
-0002dd40: 745f 6964 7829 5b3a 2c20 4e6f 6e65 5d20  t_idx)[:, None] 
-0002dd50: 2b20 5f6e 702e 7261 7665 6c28 6f66 6673  + _np.ravel(offs
-0002dd60: 6574 5f69 6478 290a 0a20 2020 2023 2047  et_idx)..    # G
-0002dd70: 6174 6865 7220 6261 7463 6865 7320 746f  ather batches to
-0002dd80: 6765 7468 6572 2e0a 2020 2020 696e 6469  gether..    indi
-0002dd90: 6365 7320 3d20 6261 7463 685f 6964 7820  ces = batch_idx 
-0002dda0: 2b20 696e 6469 6365 730a 2020 2020 7820  + indices.    x 
-0002ddb0: 3d20 6d62 2e72 6573 6861 7065 2878 3d78  = mb.reshape(x=x
-0002ddc0: 2c20 7368 6170 653d 5b2d 315d 290a 2020  , shape=[-1]).  
-0002ddd0: 2020 6761 7468 6572 6564 5f64 6174 6120    gathered_data 
-0002dde0: 3d20 6d62 2e67 6174 6865 725f 616c 6f6e  = mb.gather_alon
-0002ddf0: 675f 6178 6973 2878 3d78 2c20 696e 6469  g_axis(x=x, indi
-0002de00: 6365 733d 696e 6469 6365 732e 7265 7368  ces=indices.resh
-0002de10: 6170 6528 2d31 292c 2061 7869 733d 3029  ape(-1), axis=0)
-0002de20: 0a20 2020 2062 6c6f 636b 5f73 697a 6520  .    block_size 
-0002de30: 3d20 4320 2a20 6b65 726e 656c 5f73 697a  = C * kernel_siz
-0002de40: 655b 305d 202a 206b 6572 6e65 6c5f 7369  e[0] * kernel_si
-0002de50: 7a65 5b31 5d0a 2020 2020 6f75 7470 7574  ze[1].    output
-0002de60: 203d 206d 622e 7265 7368 6170 6528 0a20   = mb.reshape(. 
-0002de70: 2020 2020 2020 2078 3d67 6174 6865 7265         x=gathere
-0002de80: 645f 6461 7461 2c20 7368 6170 653d 284e  d_data, shape=(N
-0002de90: 2c20 626c 6f63 6b5f 7369 7a65 2c20 626c  , block_size, bl
-0002dea0: 6f63 6b5f 636f 756e 7429 2c20 6e61 6d65  ock_count), name
-0002deb0: 3d6e 6f64 652e 6e61 6d65 0a20 2020 2029  =node.name.    )
-0002dec0: 0a0a 2020 2020 636f 6e74 6578 742e 6164  ..    context.ad
-0002ded0: 6428 6f75 7470 7574 290a 0a0a 4072 6567  d(output)...@reg
-0002dee0: 6973 7465 725f 746f 7263 685f 6f70 0a64  ister_torch_op.d
-0002def0: 6566 2063 6f6d 706c 6578 2863 6f6e 7465  ef complex(conte
-0002df00: 7874 2c20 6e6f 6465 293a 0a20 2020 2072  xt, node):.    r
-0002df10: 6561 6c5f 7061 7274 2c20 696d 6167 5f70  eal_part, imag_p
-0002df20: 6172 7420 3d20 5f67 6574 5f69 6e70 7574  art = _get_input
-0002df30: 7328 636f 6e74 6578 742c 206e 6f64 652c  s(context, node,
-0002df40: 2065 7870 6563 7465 643d 3229 0a20 2020   expected=2).   
-0002df50: 2072 6573 756c 7420 3d20 6d62 2e63 6f6d   result = mb.com
-0002df60: 706c 6578 2872 6561 6c5f 6461 7461 3d72  plex(real_data=r
-0002df70: 6561 6c5f 7061 7274 2c20 696d 6167 5f64  eal_part, imag_d
-0002df80: 6174 613d 696d 6167 5f70 6172 7429 0a20  ata=imag_part). 
-0002df90: 2020 2063 6f6e 7465 7874 2e61 6464 2872     context.add(r
-0002dfa0: 6573 756c 742c 206e 6f64 652e 6e61 6d65  esult, node.name
-0002dfb0: 290a 0a0a 4072 6567 6973 7465 725f 746f  )...@register_to
-0002dfc0: 7263 685f 6f70 0a64 6566 2072 6561 6c28  rch_op.def real(
-0002dfd0: 636f 6e74 6578 742c 206e 6f64 6529 3a0a  context, node):.
-0002dfe0: 2020 2020 696e 7075 745f 6461 7461 203d      input_data =
-0002dff0: 205f 6765 745f 696e 7075 7473 2863 6f6e   _get_inputs(con
-0002e000: 7465 7874 2c20 6e6f 6465 2c20 6578 7065  text, node, expe
-0002e010: 6374 6564 3d31 295b 305d 0a20 2020 2069  cted=1)[0].    i
-0002e020: 6620 7479 7065 732e 6973 5f63 6f6d 706c  f types.is_compl
-0002e030: 6578 2869 6e70 7574 5f64 6174 612e 6474  ex(input_data.dt
-0002e040: 7970 6529 3a0a 2020 2020 2020 2020 7265  ype):.        re
-0002e050: 616c 5f70 6172 7420 3d20 6d62 2e63 6f6d  al_part = mb.com
-0002e060: 706c 6578 5f72 6561 6c28 6461 7461 3d69  plex_real(data=i
-0002e070: 6e70 7574 5f64 6174 6129 0a20 2020 2020  nput_data).     
-0002e080: 2020 2063 6f6e 7465 7874 2e61 6464 2872     context.add(r
-0002e090: 6561 6c5f 7061 7274 2c20 6e6f 6465 2e6e  eal_part, node.n
-0002e0a0: 616d 6529 0a20 2020 2065 6c73 653a 0a20  ame).    else:. 
-0002e0b0: 2020 2020 2020 2063 6f6e 7465 7874 2e61         context.a
-0002e0c0: 6464 2869 6e70 7574 5f64 6174 612c 206e  dd(input_data, n
-0002e0d0: 6f64 652e 6e61 6d65 290a 0a0a 4072 6567  ode.name)...@reg
-0002e0e0: 6973 7465 725f 746f 7263 685f 6f70 0a64  ister_torch_op.d
-0002e0f0: 6566 2069 6d61 6728 636f 6e74 6578 742c  ef imag(context,
-0002e100: 206e 6f64 6529 3a0a 2020 2020 696e 7075   node):.    inpu
-0002e110: 745f 6461 7461 203d 205f 6765 745f 696e  t_data = _get_in
-0002e120: 7075 7473 2863 6f6e 7465 7874 2c20 6e6f  puts(context, no
-0002e130: 6465 2c20 6578 7065 6374 6564 3d31 295b  de, expected=1)[
-0002e140: 305d 0a20 2020 2069 6620 6e6f 7420 7479  0].    if not ty
-0002e150: 7065 732e 6973 5f63 6f6d 706c 6578 2869  pes.is_complex(i
-0002e160: 6e70 7574 5f64 6174 612e 6474 7970 6529  nput_data.dtype)
-0002e170: 3a0a 2020 2020 2020 2020 2320 4b65 6570  :.        # Keep
-0002e180: 2063 6f6e 7369 7374 656e 7420 7769 7468   consistent with
-0002e190: 2050 7954 6f72 6368 2e0a 2020 2020 2020   PyTorch..      
-0002e1a0: 2020 7261 6973 6520 5661 6c75 6545 7272    raise ValueErr
-0002e1b0: 6f72 2822 5468 6520 6069 6d61 6760 206f  or("The `imag` o
-0002e1c0: 7020 6f6e 6c79 2073 7570 706f 7274 7320  p only supports 
-0002e1d0: 636f 6d70 6c65 7820 696e 7075 742e 2229  complex input.")
-0002e1e0: 0a20 2020 2072 6561 6c5f 7061 7274 203d  .    real_part =
-0002e1f0: 206d 622e 636f 6d70 6c65 785f 696d 6167   mb.complex_imag
-0002e200: 2864 6174 613d 696e 7075 745f 6461 7461  (data=input_data
-0002e210: 290a 2020 2020 636f 6e74 6578 742e 6164  ).    context.ad
-0002e220: 6428 7265 616c 5f70 6172 742c 206e 6f64  d(real_part, nod
-0002e230: 652e 6e61 6d65 290a 0a0a 4072 6567 6973  e.name)...@regis
-0002e240: 7465 725f 746f 7263 685f 6f70 0a64 6566  ter_torch_op.def
-0002e250: 2066 6674 5f66 6674 2863 6f6e 7465 7874   fft_fft(context
-0002e260: 2c20 6e6f 6465 293a 0a20 2020 2022 2222  , node):.    """
-0002e270: 4c6f 7765 7273 2074 6f72 6368 2e66 6674  Lowers torch.fft
-0002e280: 2e66 6674 2062 7920 7468 6520 6469 616c  .fft by the dial
-0002e290: 6563 7420 6f70 2060 636f 6d70 6c65 785f  ect op `complex_
-0002e2a0: 6666 7460 2066 726f 6d20 636f 6d70 6c65  fft` from comple
-0002e2b0: 785f 6469 616c 6563 745f 6f70 732e 7079  x_dialect_ops.py
-0002e2c0: 2e22 2222 0a20 2020 2069 6e70 7574 5f64  .""".    input_d
-0002e2d0: 6174 612c 206e 2c20 6469 6d2c 206e 6f72  ata, n, dim, nor
-0002e2e0: 6d20 3d20 5f67 6574 5f69 6e70 7574 7328  m = _get_inputs(
-0002e2f0: 636f 6e74 6578 742c 206e 6f64 652c 2065  context, node, e
-0002e300: 7870 6563 7465 643d 5b34 5d29 0a20 2020  xpected=[4]).   
-0002e310: 2066 6674 5f72 6573 203d 206d 622e 636f   fft_res = mb.co
-0002e320: 6d70 6c65 785f 6666 7428 6461 7461 3d69  mplex_fft(data=i
-0002e330: 6e70 7574 5f64 6174 612c 206e 3d6e 2c20  nput_data, n=n, 
-0002e340: 6469 6d3d 6469 6d2c 206e 6f72 6d3d 6e6f  dim=dim, norm=no
-0002e350: 726d 290a 2020 2020 636f 6e74 6578 742e  rm).    context.
-0002e360: 6164 6428 6666 745f 7265 732c 206e 6f64  add(fft_res, nod
-0002e370: 652e 6e61 6d65 290a 0a0a 4072 6567 6973  e.name)...@regis
-0002e380: 7465 725f 746f 7263 685f 6f70 0a64 6566  ter_torch_op.def
-0002e390: 2066 6674 5f66 6674 6e28 636f 6e74 6578   fft_fftn(contex
-0002e3a0: 742c 206e 6f64 6529 3a0a 2020 2020 2222  t, node):.    ""
-0002e3b0: 224c 6f77 6572 7320 746f 7263 682e 6666  "Lowers torch.ff
-0002e3c0: 742e 6666 746e 2062 7920 7468 6520 6469  t.fftn by the di
-0002e3d0: 616c 6563 7420 6f70 2060 636f 6d70 6c65  alect op `comple
-0002e3e0: 785f 6666 746e 6020 6672 6f6d 2063 6f6d  x_fftn` from com
-0002e3f0: 706c 6578 5f64 6961 6c65 6374 5f6f 7073  plex_dialect_ops
-0002e400: 2e70 792e 2222 220a 2020 2020 696e 7075  .py.""".    inpu
-0002e410: 745f 6461 7461 2c20 7368 6170 6573 2c20  t_data, shapes, 
-0002e420: 6469 6d73 2c20 6e6f 726d 203d 205f 6765  dims, norm = _ge
-0002e430: 745f 696e 7075 7473 2863 6f6e 7465 7874  t_inputs(context
-0002e440: 2c20 6e6f 6465 2c20 6578 7065 6374 6564  , node, expected
-0002e450: 3d5b 345d 290a 2020 2020 6666 745f 7265  =[4]).    fft_re
-0002e460: 7320 3d20 6d62 2e63 6f6d 706c 6578 5f66  s = mb.complex_f
-0002e470: 6674 6e28 6461 7461 3d69 6e70 7574 5f64  ftn(data=input_d
-0002e480: 6174 612c 2073 6861 7065 733d 7368 6170  ata, shapes=shap
-0002e490: 6573 2c20 6469 6d73 3d64 696d 732c 206e  es, dims=dims, n
-0002e4a0: 6f72 6d3d 6e6f 726d 290a 2020 2020 636f  orm=norm).    co
-0002e4b0: 6e74 6578 742e 6164 6428 6666 745f 7265  ntext.add(fft_re
-0002e4c0: 732c 206e 6f64 652e 6e61 6d65 290a 0a0a  s, node.name)...
-0002e4d0: 4072 6567 6973 7465 725f 746f 7263 685f  @register_torch_
-0002e4e0: 6f70 0a64 6566 2066 6674 5f72 6666 7428  op.def fft_rfft(
-0002e4f0: 636f 6e74 6578 742c 206e 6f64 6529 3a0a  context, node):.
-0002e500: 2020 2020 2222 224c 6f77 6572 7320 746f      """Lowers to
-0002e510: 7263 682e 6666 742e 7266 6674 2062 7920  rch.fft.rfft by 
-0002e520: 7468 6520 6469 616c 6563 7420 6f70 2060  the dialect op `
-0002e530: 636f 6d70 6c65 785f 7266 6674 6020 6672  complex_rfft` fr
-0002e540: 6f6d 2063 6f6d 706c 6578 5f64 6961 6c65  om complex_diale
-0002e550: 6374 5f6f 7073 2e70 792e 2222 220a 2020  ct_ops.py.""".  
-0002e560: 2020 696e 7075 745f 6461 7461 2c20 6e2c    input_data, n,
-0002e570: 2064 696d 2c20 6e6f 726d 203d 205f 6765   dim, norm = _ge
-0002e580: 745f 696e 7075 7473 2863 6f6e 7465 7874  t_inputs(context
-0002e590: 2c20 6e6f 6465 2c20 6578 7065 6374 6564  , node, expected
-0002e5a0: 3d5b 345d 290a 2020 2020 7266 6674 5f72  =[4]).    rfft_r
-0002e5b0: 6573 203d 206d 622e 636f 6d70 6c65 785f  es = mb.complex_
-0002e5c0: 7266 6674 2864 6174 613d 696e 7075 745f  rfft(data=input_
-0002e5d0: 6461 7461 2c20 6e3d 6e2c 2064 696d 3d64  data, n=n, dim=d
-0002e5e0: 696d 2c20 6e6f 726d 3d6e 6f72 6d29 0a20  im, norm=norm). 
-0002e5f0: 2020 2063 6f6e 7465 7874 2e61 6464 2872     context.add(r
-0002e600: 6666 745f 7265 732c 206e 6f64 652e 6e61  fft_res, node.na
-0002e610: 6d65 290a 0a0a 4072 6567 6973 7465 725f  me)...@register_
-0002e620: 746f 7263 685f 6f70 0a64 6566 2066 6674  torch_op.def fft
-0002e630: 5f72 6666 746e 2863 6f6e 7465 7874 2c20  _rfftn(context, 
-0002e640: 6e6f 6465 293a 0a20 2020 2022 2222 4c6f  node):.    """Lo
-0002e650: 7765 7273 2074 6f72 6368 2e66 6674 2e72  wers torch.fft.r
-0002e660: 6666 746e 2062 7920 7468 6520 6469 616c  fftn by the dial
-0002e670: 6563 7420 6f70 2060 636f 6d70 6c65 785f  ect op `complex_
-0002e680: 7266 6674 6e60 2066 726f 6d20 636f 6d70  rfftn` from comp
-0002e690: 6c65 785f 6469 616c 6563 745f 6f70 732e  lex_dialect_ops.
-0002e6a0: 7079 2e22 2222 0a20 2020 2069 6e70 7574  py.""".    input
-0002e6b0: 5f64 6174 612c 2073 6861 7065 732c 2064  _data, shapes, d
-0002e6c0: 696d 732c 206e 6f72 6d20 3d20 5f67 6574  ims, norm = _get
-0002e6d0: 5f69 6e70 7574 7328 636f 6e74 6578 742c  _inputs(context,
-0002e6e0: 206e 6f64 652c 2065 7870 6563 7465 643d   node, expected=
-0002e6f0: 5b34 5d29 0a20 2020 2072 6666 745f 7265  [4]).    rfft_re
-0002e700: 7320 3d20 6d62 2e63 6f6d 706c 6578 5f72  s = mb.complex_r
-0002e710: 6666 746e 2864 6174 613d 696e 7075 745f  fftn(data=input_
-0002e720: 6461 7461 2c20 7368 6170 6573 3d73 6861  data, shapes=sha
-0002e730: 7065 732c 2064 696d 733d 6469 6d73 2c20  pes, dims=dims, 
-0002e740: 6e6f 726d 3d6e 6f72 6d29 0a20 2020 2063  norm=norm).    c
-0002e750: 6f6e 7465 7874 2e61 6464 2872 6666 745f  ontext.add(rfft_
-0002e760: 7265 732c 206e 6f64 652e 6e61 6d65 290a  res, node.name).
-0002e770: 0a0a 4072 6567 6973 7465 725f 746f 7263  ..@register_torc
-0002e780: 685f 6f70 0a64 6566 2066 6674 5f69 6666  h_op.def fft_iff
-0002e790: 7428 636f 6e74 6578 742c 206e 6f64 6529  t(context, node)
-0002e7a0: 3a0a 2020 2020 2222 224c 6f77 6572 7320  :.    """Lowers 
-0002e7b0: 746f 7263 682e 6666 742e 6966 6674 2062  torch.fft.ifft b
-0002e7c0: 7920 7468 6520 6469 616c 6563 7420 6f70  y the dialect op
-0002e7d0: 2060 636f 6d70 6c65 785f 6966 6674 6020   `complex_ifft` 
-0002e7e0: 6672 6f6d 2063 6f6d 706c 6578 5f64 6961  from complex_dia
-0002e7f0: 6c65 6374 5f6f 7073 2e70 792e 2222 220a  lect_ops.py.""".
-0002e800: 2020 2020 696e 7075 745f 6461 7461 2c20      input_data, 
-0002e810: 6e2c 2064 696d 2c20 6e6f 726d 203d 205f  n, dim, norm = _
-0002e820: 6765 745f 696e 7075 7473 2863 6f6e 7465  get_inputs(conte
-0002e830: 7874 2c20 6e6f 6465 2c20 6578 7065 6374  xt, node, expect
-0002e840: 6564 3d5b 345d 290a 2020 2020 6966 6674  ed=[4]).    ifft
-0002e850: 5f72 6573 203d 206d 622e 636f 6d70 6c65  _res = mb.comple
-0002e860: 785f 6966 6674 2864 6174 613d 696e 7075  x_ifft(data=inpu
-0002e870: 745f 6461 7461 2c20 6e3d 6e2c 2064 696d  t_data, n=n, dim
-0002e880: 3d64 696d 2c20 6e6f 726d 3d6e 6f72 6d29  =dim, norm=norm)
-0002e890: 0a20 2020 2063 6f6e 7465 7874 2e61 6464  .    context.add
-0002e8a0: 2869 6666 745f 7265 732c 206e 6f64 652e  (ifft_res, node.
-0002e8b0: 6e61 6d65 290a 0a0a 4072 6567 6973 7465  name)...@registe
-0002e8c0: 725f 746f 7263 685f 6f70 0a64 6566 2066  r_torch_op.def f
-0002e8d0: 6674 5f69 6666 746e 2863 6f6e 7465 7874  ft_ifftn(context
-0002e8e0: 2c20 6e6f 6465 293a 0a20 2020 2022 2222  , node):.    """
-0002e8f0: 4c6f 7765 7273 2074 6f72 6368 2e66 6674  Lowers torch.fft
-0002e900: 2e69 6666 746e 2062 7920 7468 6520 6469  .ifftn by the di
-0002e910: 616c 6563 7420 6f70 2060 636f 6d70 6c65  alect op `comple
-0002e920: 785f 6966 6674 6e60 2066 726f 6d20 636f  x_ifftn` from co
-0002e930: 6d70 6c65 785f 6469 616c 6563 745f 6f70  mplex_dialect_op
-0002e940: 732e 7079 2e22 2222 0a20 2020 2069 6e70  s.py.""".    inp
-0002e950: 7574 5f64 6174 612c 2073 6861 7065 732c  ut_data, shapes,
-0002e960: 2064 696d 732c 206e 6f72 6d20 3d20 5f67   dims, norm = _g
-0002e970: 6574 5f69 6e70 7574 7328 636f 6e74 6578  et_inputs(contex
-0002e980: 742c 206e 6f64 652c 2065 7870 6563 7465  t, node, expecte
-0002e990: 643d 5b34 5d29 0a20 2020 2069 6666 746e  d=[4]).    ifftn
-0002e9a0: 5f72 6573 203d 206d 622e 636f 6d70 6c65  _res = mb.comple
-0002e9b0: 785f 6966 6674 6e28 6461 7461 3d69 6e70  x_ifftn(data=inp
-0002e9c0: 7574 5f64 6174 612c 2073 6861 7065 733d  ut_data, shapes=
-0002e9d0: 7368 6170 6573 2c20 6469 6d73 3d64 696d  shapes, dims=dim
-0002e9e0: 732c 206e 6f72 6d3d 6e6f 726d 290a 2020  s, norm=norm).  
-0002e9f0: 2020 636f 6e74 6578 742e 6164 6428 6966    context.add(if
-0002ea00: 6674 6e5f 7265 732c 206e 6f64 652e 6e61  ftn_res, node.na
-0002ea10: 6d65 290a 0a0a 4072 6567 6973 7465 725f  me)...@register_
-0002ea20: 746f 7263 685f 6f70 0a64 6566 2066 6674  torch_op.def fft
-0002ea30: 5f69 7266 6674 2863 6f6e 7465 7874 2c20  _irfft(context, 
-0002ea40: 6e6f 6465 293a 0a20 2020 2022 2222 4c6f  node):.    """Lo
-0002ea50: 7765 7273 2074 6f72 6368 2e66 6674 2e69  wers torch.fft.i
-0002ea60: 7266 6674 2062 7920 7468 6520 6469 616c  rfft by the dial
-0002ea70: 6563 7420 6f70 2060 636f 6d70 6c65 785f  ect op `complex_
-0002ea80: 6972 6666 7460 2066 726f 6d20 636f 6d70  irfft` from comp
-0002ea90: 6c65 785f 6469 616c 6563 745f 6f70 732e  lex_dialect_ops.
-0002eaa0: 7079 2e22 2222 0a20 2020 2069 6e70 7574  py.""".    input
-0002eab0: 5f64 6174 612c 206e 2c20 6469 6d2c 206e  _data, n, dim, n
-0002eac0: 6f72 6d20 3d20 5f67 6574 5f69 6e70 7574  orm = _get_input
-0002ead0: 7328 636f 6e74 6578 742c 206e 6f64 652c  s(context, node,
-0002eae0: 2065 7870 6563 7465 643d 5b34 5d29 0a20   expected=[4]). 
-0002eaf0: 2020 2069 7266 6674 5f72 6573 203d 206d     irfft_res = m
-0002eb00: 622e 636f 6d70 6c65 785f 6972 6666 7428  b.complex_irfft(
-0002eb10: 6461 7461 3d69 6e70 7574 5f64 6174 612c  data=input_data,
-0002eb20: 206e 3d6e 2c20 6469 6d3d 6469 6d2c 206e   n=n, dim=dim, n
-0002eb30: 6f72 6d3d 6e6f 726d 290a 2020 2020 636f  orm=norm).    co
-0002eb40: 6e74 6578 742e 6164 6428 6972 6666 745f  ntext.add(irfft_
-0002eb50: 7265 732c 206e 6f64 652e 6e61 6d65 290a  res, node.name).
-0002eb60: 0a0a 4072 6567 6973 7465 725f 746f 7263  ..@register_torc
-0002eb70: 685f 6f70 0a64 6566 2066 6674 5f69 7266  h_op.def fft_irf
-0002eb80: 6674 6e28 636f 6e74 6578 742c 206e 6f64  ftn(context, nod
-0002eb90: 6529 3a0a 2020 2020 2222 224c 6f77 6572  e):.    """Lower
-0002eba0: 7320 746f 7263 682e 6666 742e 6972 6666  s torch.fft.irff
-0002ebb0: 746e 2062 7920 7468 6520 6469 616c 6563  tn by the dialec
-0002ebc0: 7420 6f70 2060 636f 6d70 6c65 785f 6972  t op `complex_ir
-0002ebd0: 6666 746e 6020 6672 6f6d 2063 6f6d 706c  fftn` from compl
-0002ebe0: 6578 5f64 6961 6c65 6374 5f6f 7073 2e70  ex_dialect_ops.p
-0002ebf0: 792e 2222 220a 2020 2020 696e 7075 745f  y.""".    input_
-0002ec00: 6461 7461 2c20 7368 6170 6573 2c20 6469  data, shapes, di
-0002ec10: 6d73 2c20 6e6f 726d 203d 205f 6765 745f  ms, norm = _get_
-0002ec20: 696e 7075 7473 2863 6f6e 7465 7874 2c20  inputs(context, 
-0002ec30: 6e6f 6465 2c20 6578 7065 6374 6564 3d5b  node, expected=[
-0002ec40: 345d 290a 2020 2020 6972 6666 746e 5f72  4]).    irfftn_r
-0002ec50: 6573 203d 206d 622e 636f 6d70 6c65 785f  es = mb.complex_
-0002ec60: 6972 6666 746e 2864 6174 613d 696e 7075  irfftn(data=inpu
-0002ec70: 745f 6461 7461 2c20 7368 6170 6573 3d73  t_data, shapes=s
-0002ec80: 6861 7065 732c 2064 696d 733d 6469 6d73  hapes, dims=dims
-0002ec90: 2c20 6e6f 726d 3d6e 6f72 6d29 0a20 2020  , norm=norm).   
-0002eca0: 2063 6f6e 7465 7874 2e61 6464 2869 7266   context.add(irf
-0002ecb0: 6674 6e5f 7265 732c 206e 6f64 652e 6e61  ftn_res, node.na
-0002ecc0: 6d65 290a 0a0a 4072 6567 6973 7465 725f  me)...@register_
-0002ecd0: 746f 7263 685f 6f70 2874 6f72 6368 5f61  torch_op(torch_a
-0002ece0: 6c69 6173 3d5b 2274 6f72 6368 7669 7369  lias=["torchvisi
-0002ecf0: 6f6e 3a3a 6e6d 7322 5d29 0a64 6566 2074  on::nms"]).def t
-0002ed00: 6f72 6368 7669 7369 6f6e 5f6e 6d73 2863  orchvision_nms(c
-0002ed10: 6f6e 7465 7874 2c20 6e6f 6465 293a 0a20  ontext, node):. 
-0002ed20: 2020 2069 6e70 7574 7320 3d20 5f67 6574     inputs = _get
-0002ed30: 5f69 6e70 7574 7328 636f 6e74 6578 742c  _inputs(context,
-0002ed40: 206e 6f64 652c 2065 7870 6563 7465 643d   node, expected=
-0002ed50: 3329 0a20 2020 2062 6f78 6573 2c20 7363  3).    boxes, sc
-0002ed60: 6f72 6573 203d 2070 726f 6d6f 7465 5f69  ores = promote_i
-0002ed70: 6e70 7574 5f64 7479 7065 7328 5b69 6e70  nput_dtypes([inp
-0002ed80: 7574 735b 305d 2c20 696e 7075 7473 5b31  uts[0], inputs[1
-0002ed90: 5d5d 290a 2020 2020 696f 755f 7468 7265  ]]).    iou_thre
-0002eda0: 7368 6f6c 6420 3d20 696e 7075 7473 5b32  shold = inputs[2
-0002edb0: 5d2e 7661 6c0a 2020 2020 2320 5573 6520  ].val.    # Use 
-0002edc0: 666c 6f61 7420 6d69 6e20 746f 2061 766f  float min to avo
-0002edd0: 6964 2062 6f78 6573 2062 6569 6e67 2070  id boxes being p
-0002ede0: 7275 6e65 6420 6279 2073 636f 7265 7320  runed by scores 
-0002edf0: 696e 204d 494c 204e 4d53 206f 702e 0a20  in MIL NMS op.. 
-0002ee00: 2020 2073 636f 7265 5f74 6872 6573 686f     score_thresho
-0002ee10: 6c64 203d 2028 0a20 2020 2020 2020 205f  ld = (.        _
-0002ee20: 6e70 2e66 696e 666f 285f 6e70 2e66 6c6f  np.finfo(_np.flo
-0002ee30: 6174 3136 292e 6d69 6e0a 2020 2020 2020  at16).min.      
-0002ee40: 2020 6966 2062 6f78 6573 2e64 7479 7065    if boxes.dtype
-0002ee50: 2e5f 7769 6474 6820 3d3d 2031 360a 2020  ._width == 16.  
-0002ee60: 2020 2020 2020 656c 7365 205f 6e70 2e66        else _np.f
-0002ee70: 696e 666f 285f 6e70 2e66 6c6f 6174 3332  info(_np.float32
-0002ee80: 292e 6d69 6e0a 2020 2020 290a 0a20 2020  ).min.    )..   
-0002ee90: 2062 6f78 5f6e 756d 203d 2062 6f78 6573   box_num = boxes
-0002eea0: 2e73 6861 7065 5b30 5d0a 2020 2020 6966  .shape[0].    if
-0002eeb0: 2069 735f 7379 6d62 6f6c 6963 2862 6f78   is_symbolic(box
-0002eec0: 5f6e 756d 293a 0a20 2020 2020 2020 2023  _num):.        #
-0002eed0: 2057 6865 6e20 7468 6520 6e75 6d62 6572   When the number
-0002eee0: 206f 6620 626f 7865 7320 6973 2075 6e6b   of boxes is unk
-0002eef0: 6e6f 776e 2061 7420 636f 6d70 696c 6520  nown at compile 
-0002ef00: 7469 6d65 2c20 7573 6520 6120 6c61 7267  time, use a larg
-0002ef10: 6520 6e75 6d62 6572 2074 6f20 6176 6f69  e number to avoi
-0002ef20: 6420 7661 6c69 640a 2020 2020 2020 2020  d valid.        
-0002ef30: 2320 626f 7865 7320 676f 7420 7072 756e  # boxes got prun
-0002ef40: 6564 2e20 5765 2064 6f6e 2774 2075 7365  ed. We don't use
-0002ef50: 205f 6e70 2e69 696e 666f 285f 6e70 2e69   _np.iinfo(_np.i
-0002ef60: 6e74 3332 292e 6d61 7820 6865 7265 2062  nt32).max here b
-0002ef70: 6563 6175 7365 2069 7420 7472 6967 6765  ecause it trigge
-0002ef80: 7273 2074 6865 204d 494c 0a20 2020 2020  rs the MIL.     
-0002ef90: 2020 2023 204e 4d53 206f 7020 7365 676d     # NMS op segm
-0002efa0: 656e 7420 6661 756c 742e 0a20 2020 2020  ent fault..     
-0002efb0: 2020 2062 6f78 5f6e 756d 203d 2031 3030     box_num = 100
-0002efc0: 3030 0a0a 2020 2020 2320 5468 6520 626f  00..    # The bo
-0002efd0: 7865 7327 2063 6f6f 7264 696e 6174 6573  xes' coordinates
-0002efe0: 2066 726f 6d20 5079 546f 7263 6820 696e   from PyTorch in
-0002eff0: 7075 7420 6973 2028 7831 2c20 7931 2c20  put is (x1, y1, 
-0002f000: 7832 2c20 7932 2920 666f 726d 6174 2077  x2, y2) format w
-0002f010: 6974 6820 3020 3c3d 2078 3120 3c20 7832  ith 0 <= x1 < x2
-0002f020: 2061 6e64 0a20 2020 2023 2030 203c 3d20   and.    # 0 <= 
-0002f030: 7931 203c 2079 322e 2048 6f77 6576 6572  y1 < y2. However
-0002f040: 2c20 7468 6520 4d49 4c20 4e4d 5320 6f70  , the MIL NMS op
-0002f050: 2065 7870 6563 7473 2043 454e 5445 525f   expects CENTER_
-0002f060: 5349 5a45 5f57 4944 5448 5f46 4952 5354  SIZE_WIDTH_FIRST
-0002f070: 2066 6f72 6d61 742c 2077 6869 6368 2069   format, which i
-0002f080: 730a 2020 2020 2320 2878 2c20 792c 2077  s.    # (x, y, w
-0002f090: 6964 7468 2c20 6865 6967 6874 2920 7768  idth, height) wh
-0002f0a0: 6572 6520 2878 2c20 7929 2069 7320 7468  ere (x, y) is th
-0002f0b0: 6520 6365 6e74 6572 2063 6f6f 7264 696e  e center coordin
-0002f0c0: 6174 652e 0a20 2020 2078 312c 2079 312c  ate..    x1, y1,
-0002f0d0: 2078 322c 2079 3220 3d20 6d62 2e73 706c   x2, y2 = mb.spl
-0002f0e0: 6974 2878 3d62 6f78 6573 2c20 6e75 6d5f  it(x=boxes, num_
-0002f0f0: 7370 6c69 7473 3d34 2c20 6178 6973 3d2d  splits=4, axis=-
-0002f100: 3129 0a20 2020 2023 2046 6f72 206e 756d  1).    # For num
-0002f110: 6572 6963 616c 2073 7461 6269 6c69 7479  erical stability
-0002f120: 2c20 7573 6520 7831 2b28 7832 2d78 3129  , use x1+(x2-x1)
-0002f130: 2f32 2069 6e73 7465 6164 206f 6620 2878  /2 instead of (x
-0002f140: 312b 7832 292f 3220 746f 2063 616c 6375  1+x2)/2 to calcu
-0002f150: 6c61 7465 2063 656e 7465 7220 636f 6f72  late center coor
-0002f160: 6469 6e61 7465 2e0a 2020 2020 7769 6474  dinate..    widt
-0002f170: 6820 3d20 6d62 2e73 7562 2878 3d78 322c  h = mb.sub(x=x2,
-0002f180: 2079 3d78 3129 0a20 2020 2068 6569 6768   y=x1).    heigh
-0002f190: 7420 3d20 6d62 2e73 7562 2878 3d79 322c  t = mb.sub(x=y2,
-0002f1a0: 2079 3d79 3129 0a20 2020 2063 656e 7465   y=y1).    cente
-0002f1b0: 725f 7820 3d20 6d62 2e61 6464 2878 3d78  r_x = mb.add(x=x
-0002f1c0: 312c 2079 3d6d 622e 7265 616c 5f64 6976  1, y=mb.real_div
-0002f1d0: 2878 3d77 6964 7468 2c20 793d 322e 3029  (x=width, y=2.0)
-0002f1e0: 290a 2020 2020 6365 6e74 6572 5f79 203d  ).    center_y =
-0002f1f0: 206d 622e 6164 6428 783d 7931 2c20 793d   mb.add(x=y1, y=
-0002f200: 6d62 2e72 6561 6c5f 6469 7628 783d 6865  mb.real_div(x=he
-0002f210: 6967 6874 2c20 793d 322e 3029 290a 2020  ight, y=2.0)).  
-0002f220: 2020 626f 7865 7320 3d20 6d62 2e63 6f6e    boxes = mb.con
-0002f230: 6361 7428 7661 6c75 6573 3d5b 6365 6e74  cat(values=[cent
-0002f240: 6572 5f78 2c20 6365 6e74 6572 5f79 2c20  er_x, center_y, 
-0002f250: 7769 6474 682c 2068 6569 6768 745d 2c20  width, height], 
-0002f260: 6178 6973 3d2d 3129 0a0a 2020 2020 2320  axis=-1)..    # 
-0002f270: 4578 7061 6e64 2064 696d 7320 746f 2063  Expand dims to c
-0002f280: 6f6e 7374 7275 6374 2074 6865 2062 6174  onstruct the bat
-0002f290: 6368 2064 696d 2061 6e64 2073 636f 7265  ch dim and score
-0002f2a0: 2063 6c61 7373 2064 696d 2065 7870 6563   class dim expec
-0002f2b0: 7465 6420 6279 204d 494c 204e 4d53 206f  ted by MIL NMS o
-0002f2c0: 702e 0a20 2020 2062 6f78 6573 203d 206d  p..    boxes = m
-0002f2d0: 622e 6578 7061 6e64 5f64 696d 7328 783d  b.expand_dims(x=
-0002f2e0: 626f 7865 732c 2061 7865 733d 5b30 5d29  boxes, axes=[0])
-0002f2f0: 0a20 2020 2073 636f 7265 7320 3d20 6d62  .    scores = mb
-0002f300: 2e65 7870 616e 645f 6469 6d73 2878 3d73  .expand_dims(x=s
-0002f310: 636f 7265 732c 2061 7865 733d 5b30 2c20  cores, axes=[0, 
-0002f320: 2d31 5d29 0a0a 2020 2020 5f2c 205f 2c20  -1])..    _, _, 
-0002f330: 696e 6469 6365 732c 2076 616c 6964 5f6f  indices, valid_o
-0002f340: 7574 7075 7473 203d 206d 622e 6e6f 6e5f  utputs = mb.non_
-0002f350: 6d61 7869 6d75 6d5f 7375 7070 7265 7373  maximum_suppress
-0002f360: 696f 6e28 0a20 2020 2020 2020 2062 6f78  ion(.        box
-0002f370: 6573 3d62 6f78 6573 2c0a 2020 2020 2020  es=boxes,.      
-0002f380: 2020 7363 6f72 6573 3d73 636f 7265 732c    scores=scores,
-0002f390: 0a20 2020 2020 2020 206d 6178 5f62 6f78  .        max_box
-0002f3a0: 6573 3d62 6f78 5f6e 756d 2c0a 2020 2020  es=box_num,.    
-0002f3b0: 2020 2020 696f 755f 7468 7265 7368 6f6c      iou_threshol
-0002f3c0: 643d 696f 755f 7468 7265 7368 6f6c 642c  d=iou_threshold,
-0002f3d0: 0a20 2020 2020 2020 2073 636f 7265 5f74  .        score_t
-0002f3e0: 6872 6573 686f 6c64 3d73 636f 7265 5f74  hreshold=score_t
-0002f3f0: 6872 6573 686f 6c64 2c0a 2020 2020 290a  hreshold,.    ).
-0002f400: 0a20 2020 2069 6e64 6963 6573 203d 206d  .    indices = m
-0002f410: 622e 7371 7565 657a 6528 783d 696e 6469  b.squeeze(x=indi
-0002f420: 6365 732c 2061 7865 733d 5b30 5d29 0a20  ces, axes=[0]). 
-0002f430: 2020 2076 616c 6964 5f6f 7574 7075 7473     valid_outputs
-0002f440: 203d 206d 622e 7371 7565 657a 6528 783d   = mb.squeeze(x=
-0002f450: 7661 6c69 645f 6f75 7470 7574 732c 2061  valid_outputs, a
-0002f460: 7865 733d 5b30 5d29 0a20 2020 2072 616e  xes=[0]).    ran
-0002f470: 6765 203d 206d 622e 7261 6e67 655f 3164  ge = mb.range_1d
-0002f480: 2865 6e64 3d76 616c 6964 5f6f 7574 7075  (end=valid_outpu
-0002f490: 7473 2c20 7374 6172 743d 302c 2073 7465  ts, start=0, ste
-0002f4a0: 703d 3129 0a20 2020 2069 6e64 6963 6573  p=1).    indices
-0002f4b0: 203d 206d 622e 6361 7374 2878 3d69 6e64   = mb.cast(x=ind
-0002f4c0: 6963 6573 2c20 6474 7970 653d 2266 7033  ices, dtype="fp3
-0002f4d0: 3222 290a 2020 2020 7661 6c69 645f 696e  2").    valid_in
-0002f4e0: 6469 6365 7320 3d20 6d62 2e67 6174 6865  dices = mb.gathe
-0002f4f0: 7228 783d 696e 6469 6365 732c 2069 6e64  r(x=indices, ind
-0002f500: 6963 6573 3d72 616e 6765 2c20 6178 6973  ices=range, axis
-0002f510: 3d30 290a 2020 2020 7661 6c69 645f 696e  =0).    valid_in
-0002f520: 6469 6365 7320 3d20 6d62 2e63 6173 7428  dices = mb.cast(
-0002f530: 783d 7661 6c69 645f 696e 6469 6365 732c  x=valid_indices,
-0002f540: 2064 7479 7065 3d22 696e 7433 3222 2c20   dtype="int32", 
-0002f550: 6e61 6d65 3d6e 6f64 652e 6e61 6d65 290a  name=node.name).
-0002f560: 2020 2020 636f 6e74 6578 742e 6164 6428      context.add(
-0002f570: 7661 6c69 645f 696e 6469 6365 7329 0a0a  valid_indices)..
-0002f580: 0a40 7265 6769 7374 6572 5f74 6f72 6368  .@register_torch
-0002f590: 5f6f 700a 6465 6620 7475 706c 6569 6e64  _op.def tupleind
-0002f5a0: 6578 2863 6f6e 7465 7874 2c20 6e6f 6465  ex(context, node
-0002f5b0: 293a 0a20 2020 2074 7570 6c65 5f69 6e70  ):.    tuple_inp
-0002f5c0: 7574 2c20 696e 6465 785f 696e 7075 7420  ut, index_input 
-0002f5d0: 3d20 5f67 6574 5f69 6e70 7574 7328 636f  = _get_inputs(co
-0002f5e0: 6e74 6578 742c 206e 6f64 652c 2065 7870  ntext, node, exp
-0002f5f0: 6563 7465 643d 3229 0a20 2020 2063 6f6e  ected=2).    con
-0002f600: 7465 7874 2e61 6464 2874 7570 6c65 5f69  text.add(tuple_i
-0002f610: 6e70 7574 5b69 6e64 6578 5f69 6e70 7574  nput[index_input
-0002f620: 2e76 616c 5d2c 206e 6f64 652e 6e61 6d65  .val], node.name
-0002f630: 290a                                     ).
+000235f0: 290a 2020 2020 636f 6e74 6578 742e 6164  ).    context.ad
+00023600: 6428 7265 7329 0a0a 0a40 7265 6769 7374  d(res)...@regist
+00023610: 6572 5f74 6f72 6368 5f6f 7028 746f 7263  er_torch_op(torc
+00023620: 685f 616c 6961 733d 5b22 656d 7074 795f  h_alias=["empty_
+00023630: 6c69 6b65 225d 290a 6465 6620 7a65 726f  like"]).def zero
+00023640: 735f 6c69 6b65 2863 6f6e 7465 7874 2c20  s_like(context, 
+00023650: 6e6f 6465 293a 0a20 2020 2069 6e70 7574  node):.    input
+00023660: 7320 3d20 5f67 6574 5f69 6e70 7574 7328  s = _get_inputs(
+00023670: 636f 6e74 6578 742c 206e 6f64 652c 2065  context, node, e
+00023680: 7870 6563 7465 643d 3629 0a20 2020 2078  xpected=6).    x
+00023690: 203d 2069 6e70 7574 735b 305d 0a20 2020   = inputs[0].   
+000236a0: 2064 7479 7065 203d 2069 6e70 7574 735b   dtype = inputs[
+000236b0: 315d 2e76 616c 0a20 2020 2073 6861 7065  1].val.    shape
+000236c0: 203d 206d 622e 7368 6170 6528 783d 7829   = mb.shape(x=x)
+000236d0: 0a20 2020 206e 705f 7479 7065 203d 204e  .    np_type = N
+000236e0: 554d 5f54 4f5f 4e55 4d50 595f 4454 5950  UM_TO_NUMPY_DTYP
+000236f0: 455b 6474 7970 655d 0a0a 2020 2020 6966  E[dtype]..    if
+00023700: 2073 6861 7065 2e63 616e 5f62 655f 666f   shape.can_be_fo
+00023710: 6c64 6564 5f74 6f5f 636f 6e73 7428 293a  lded_to_const():
+00023720: 0a20 2020 2020 2020 2073 6861 7065 203d  .        shape =
+00023730: 2073 6861 7065 2e76 616c 0a20 2020 2020   shape.val.     
+00023740: 2020 207a 6572 6f73 203d 205f 6e70 2e7a     zeros = _np.z
+00023750: 6572 6f73 2873 6861 7065 292e 6173 7479  eros(shape).asty
+00023760: 7065 286e 705f 7479 7065 290a 2020 2020  pe(np_type).    
+00023770: 2020 2020 7a65 726f 735f 6c69 6b65 203d      zeros_like =
+00023780: 206d 622e 636f 6e73 7428 7661 6c3d 7a65   mb.const(val=ze
+00023790: 726f 732c 206e 616d 653d 6e6f 6465 2e6e  ros, name=node.n
+000237a0: 616d 6529 0a20 2020 2065 6c73 653a 0a20  ame).    else:. 
+000237b0: 2020 2020 2020 2076 616c 7565 203d 206e         value = n
+000237c0: 705f 7479 7065 2830 290a 2020 2020 2020  p_type(0).      
+000237d0: 2020 6966 2069 735f 6375 7272 656e 745f    if is_current_
+000237e0: 6f70 7365 745f 7665 7273 696f 6e5f 636f  opset_version_co
+000237f0: 6d70 6174 6962 6c65 5f77 6974 6828 7461  mpatible_with(ta
+00023800: 7267 6574 2e69 4f53 3136 293a 0a20 2020  rget.iOS16):.   
+00023810: 2020 2020 2020 2020 207a 6572 6f73 5f6c           zeros_l
+00023820: 696b 6520 3d20 6d62 2e66 696c 6c5f 6c69  ike = mb.fill_li
+00023830: 6b65 2872 6566 5f74 656e 736f 723d 782c  ke(ref_tensor=x,
+00023840: 2076 616c 7565 3d76 616c 7565 2c20 6e61   value=value, na
+00023850: 6d65 3d6e 6f64 652e 6e61 6d65 290a 2020  me=node.name).  
+00023860: 2020 2020 2020 656c 7365 3a0a 2020 2020        else:.    
+00023870: 2020 2020 2020 2020 7a65 726f 735f 6c69          zeros_li
+00023880: 6b65 203d 206d 622e 6669 6c6c 2873 6861  ke = mb.fill(sha
+00023890: 7065 3d73 6861 7065 2c20 7661 6c75 653d  pe=shape, value=
+000238a0: 7661 6c75 652c 206e 616d 653d 6e6f 6465  value, name=node
+000238b0: 2e6e 616d 6529 0a0a 2020 2020 636f 6e74  .name)..    cont
+000238c0: 6578 742e 6164 6428 7a65 726f 735f 6c69  ext.add(zeros_li
+000238d0: 6b65 290a 0a0a 4072 6567 6973 7465 725f  ke)...@register_
+000238e0: 746f 7263 685f 6f70 2874 6f72 6368 5f61  torch_op(torch_a
+000238f0: 6c69 6173 3d5b 2265 6d70 7479 225d 290a  lias=["empty"]).
+00023900: 6465 6620 7a65 726f 7328 636f 6e74 6578  def zeros(contex
+00023910: 742c 206e 6f64 6529 3a0a 2020 2020 696e  t, node):.    in
+00023920: 7075 7473 203d 205f 6765 745f 696e 7075  puts = _get_inpu
+00023930: 7473 2863 6f6e 7465 7874 2c20 6e6f 6465  ts(context, node
+00023940: 290a 2020 2020 7369 7a65 203d 2069 6e70  ).    size = inp
+00023950: 7574 735b 305d 0a20 2020 2069 6620 696e  uts[0].    if in
+00023960: 7075 7473 5b31 5d20 6973 206e 6f74 204e  puts[1] is not N
+00023970: 6f6e 653a 0a20 2020 2020 2020 2064 7479  one:.        dty
+00023980: 7065 203d 2069 6e70 7574 735b 315d 2e76  pe = inputs[1].v
+00023990: 616c 0a20 2020 2065 6c73 653a 0a20 2020  al.    else:.   
+000239a0: 2020 2020 2064 7479 7065 203d 2074 6f72       dtype = tor
+000239b0: 6368 2e67 6574 5f64 6566 6175 6c74 5f64  ch.get_default_d
+000239c0: 7479 7065 2829 0a20 2020 2020 2020 2061  type().        a
+000239d0: 7373 6572 7420 6474 7970 6520 696e 2028  ssert dtype in (
+000239e0: 746f 7263 682e 666c 6f61 7433 322c 2074  torch.float32, t
+000239f0: 6f72 6368 2e66 6c6f 6174 3634 290a 2020  orch.float64).  
+00023a00: 2020 2020 2020 6474 7970 6520 3d20 360a        dtype = 6.
+00023a10: 0a20 2020 2069 6620 6973 696e 7374 616e  .    if isinstan
+00023a20: 6365 2873 697a 652c 206c 6973 7429 206f  ce(size, list) o
+00023a30: 7220 6e6f 7420 7369 7a65 2e63 616e 5f62  r not size.can_b
+00023a40: 655f 666f 6c64 6564 5f74 6f5f 636f 6e73  e_folded_to_cons
+00023a50: 7428 293a 0a20 2020 2020 2020 2023 2074  t():.        # t
+00023a60: 6865 2073 697a 6520 6973 2064 796e 616d  he size is dynam
+00023a70: 6963 206f 7220 7468 6973 207a 6572 6f73  ic or this zeros
+00023a80: 206f 7020 6361 6e6e 6f74 2062 6520 666f   op cannot be fo
+00023a90: 6c64 6564 2069 6e74 6f20 636f 6e73 742e  lded into const.
+00023aa0: 0a20 2020 2020 2020 2073 697a 6520 3d20  .        size = 
+00023ab0: 6d62 2e63 6f6e 6361 7428 7661 6c75 6573  mb.concat(values
+00023ac0: 3d73 697a 652c 2061 7869 733d 3029 2069  =size, axis=0) i
+00023ad0: 6620 6973 696e 7374 616e 6365 2873 697a  f isinstance(siz
+00023ae0: 652c 206c 6973 7429 2065 6c73 6520 7369  e, list) else si
+00023af0: 7a65 0a20 2020 2020 2020 206e 705f 7479  ze.        np_ty
+00023b00: 7065 203d 204e 554d 5f54 4f5f 4e55 4d50  pe = NUM_TO_NUMP
+00023b10: 595f 4454 5950 455b 6474 7970 655d 0a20  Y_DTYPE[dtype]. 
+00023b20: 2020 2020 2020 207a 6572 6f73 203d 206d         zeros = m
+00023b30: 622e 6669 6c6c 2873 6861 7065 3d73 697a  b.fill(shape=siz
+00023b40: 652c 2076 616c 7565 3d6e 705f 7479 7065  e, value=np_type
+00023b50: 2830 292c 206e 616d 653d 6e6f 6465 2e6e  (0), name=node.n
+00023b60: 616d 6529 0a20 2020 2065 6c73 653a 0a20  ame).    else:. 
+00023b70: 2020 2020 2020 2023 2074 6865 2073 697a         # the siz
+00023b80: 6520 6973 2073 7461 7469 6320 616e 6420  e is static and 
+00023b90: 7468 6973 207a 6572 6f73 206f 7020 6361  this zeros op ca
+00023ba0: 6e20 6265 2066 6f6c 6465 6420 696e 746f  n be folded into
+00023bb0: 2063 6f6e 7374 2e0a 2020 2020 2020 2020   const..        
+00023bc0: 7369 7a65 203d 2073 697a 652e 7661 6c0a  size = size.val.
+00023bd0: 2020 2020 2020 2020 2320 6c61 796f 7574          # layout
+00023be0: 203d 2069 6e70 7574 735b 325d 2075 6e75   = inputs[2] unu
+00023bf0: 7365 640a 2020 2020 2020 2020 2320 6465  sed.        # de
+00023c00: 7669 6365 203d 2069 6e70 7574 735b 335d  vice = inputs[3]
+00023c10: 2075 6e75 7365 640a 2020 2020 2020 2020   unused.        
+00023c20: 2320 7069 6e5f 6d65 6d6f 7279 203d 2069  # pin_memory = i
+00023c30: 6e70 7574 735b 345d 2075 6e75 7365 640a  nputs[4] unused.
+00023c40: 2020 2020 2020 2020 746f 7263 685f 6474          torch_dt
+00023c50: 7970 6520 3d20 4e55 4d5f 544f 5f54 4f52  ype = NUM_TO_TOR
+00023c60: 4348 5f44 5459 5045 5b64 7479 7065 5d0a  CH_DTYPE[dtype].
+00023c70: 2020 2020 2020 2020 7a65 726f 735f 6172          zeros_ar
+00023c80: 7261 7920 3d20 746f 7263 682e 7a65 726f  ray = torch.zero
+00023c90: 7328 7475 706c 6528 7369 7a65 2929 2e74  s(tuple(size)).t
+00023ca0: 7970 6528 746f 7263 685f 6474 7970 6529  ype(torch_dtype)
+00023cb0: 2e6e 756d 7079 2829 0a20 2020 2020 2020  .numpy().       
+00023cc0: 207a 6572 6f73 203d 206d 622e 636f 6e73   zeros = mb.cons
+00023cd0: 7428 7661 6c3d 7a65 726f 735f 6172 7261  t(val=zeros_arra
+00023ce0: 792c 206e 616d 653d 6e6f 6465 2e6e 616d  y, name=node.nam
+00023cf0: 6529 0a0a 2020 2020 636f 6e74 6578 742e  e)..    context.
+00023d00: 6164 6428 7a65 726f 7329 0a0a 0a40 7265  add(zeros)...@re
+00023d10: 6769 7374 6572 5f74 6f72 6368 5f6f 7028  gister_torch_op(
+00023d20: 746f 7263 685f 616c 6961 733d 5b22 6e65  torch_alias=["ne
+00023d30: 775f 656d 7074 7922 5d29 0a64 6566 206e  w_empty"]).def n
+00023d40: 6577 5f7a 6572 6f73 2863 6f6e 7465 7874  ew_zeros(context
+00023d50: 2c20 6e6f 6465 293a 0a20 2020 2069 6e70  , node):.    inp
+00023d60: 7574 7320 3d20 5f67 6574 5f69 6e70 7574  uts = _get_input
+00023d70: 7328 636f 6e74 6578 742c 206e 6f64 6529  s(context, node)
+00023d80: 0a20 2020 2073 6861 7065 203d 2069 6e70  .    shape = inp
+00023d90: 7574 735b 315d 0a20 2020 2069 6620 6973  uts[1].    if is
+00023da0: 696e 7374 616e 6365 2873 6861 7065 2c20  instance(shape, 
+00023db0: 6c69 7374 293a 0a20 2020 2020 2020 2023  list):.        #
+00023dc0: 2077 6865 6e20 7468 6520 7369 7a65 2069   when the size i
+00023dd0: 7320 6479 6e61 6d69 632c 2069 7420 6973  s dynamic, it is
+00023de0: 2061 206c 6973 7420 6f66 2070 796d 696c   a list of pymil
+00023df0: 2073 6361 6c61 722c 0a20 2020 2020 2020   scalar,.       
+00023e00: 2023 2077 6520 6e65 6564 2074 6f20 636f   # we need to co
+00023e10: 6e63 6174 2074 6865 6d20 6669 7273 7420  ncat them first 
+00023e20: 746f 2067 6574 2061 2073 6861 7065 2e0a  to get a shape..
+00023e30: 2020 2020 2020 2020 7368 6170 6520 3d20          shape = 
+00023e40: 6d62 2e63 6f6e 6361 7428 7661 6c75 6573  mb.concat(values
+00023e50: 3d73 6861 7065 2c20 6178 6973 3d30 290a  =shape, axis=0).
+00023e60: 2020 2020 636f 6e74 6578 742e 6164 6428      context.add(
+00023e70: 6d62 2e66 696c 6c28 7368 6170 653d 7368  mb.fill(shape=sh
+00023e80: 6170 652c 2076 616c 7565 3d30 2e2c 206e  ape, value=0., n
+00023e90: 616d 653d 6e6f 6465 2e6e 616d 6529 290a  ame=node.name)).
+00023ea0: 0a0a 4072 6567 6973 7465 725f 746f 7263  ..@register_torc
+00023eb0: 685f 6f70 0a64 6566 2064 696d 2863 6f6e  h_op.def dim(con
+00023ec0: 7465 7874 2c20 6e6f 6465 293a 0a20 2020  text, node):.   
+00023ed0: 2069 6e70 7574 7320 3d20 5f67 6574 5f69   inputs = _get_i
+00023ee0: 6e70 7574 7328 636f 6e74 6578 742c 206e  nputs(context, n
+00023ef0: 6f64 6529 0a20 2020 2073 6861 7065 203d  ode).    shape =
+00023f00: 206d 622e 7368 6170 6528 783d 696e 7075   mb.shape(x=inpu
+00023f10: 7473 5b30 5d29 0a20 2020 2072 616e 6b20  ts[0]).    rank 
+00023f20: 3d20 6d62 2e73 6861 7065 2878 3d73 6861  = mb.shape(x=sha
+00023f30: 7065 290a 2020 2020 636f 6e74 6578 742e  pe).    context.
+00023f40: 6164 6428 7661 6c75 655f 6174 2872 616e  add(value_at(ran
+00023f50: 6b2c 2030 2c20 6e6f 6465 2e6e 616d 6529  k, 0, node.name)
+00023f60: 290a 0a0a 4072 6567 6973 7465 725f 746f  )...@register_to
+00023f70: 7263 685f 6f70 0a64 6566 206d 696e 2863  rch_op.def min(c
+00023f80: 6f6e 7465 7874 2c20 6e6f 6465 293a 0a20  ontext, node):. 
+00023f90: 2020 2069 6e70 7574 7320 3d20 5f67 6574     inputs = _get
+00023fa0: 5f69 6e70 7574 7328 636f 6e74 6578 742c  _inputs(context,
+00023fb0: 206e 6f64 652c 2065 7870 6563 7465 643d   node, expected=
+00023fc0: 5b31 2c20 322c 2033 5d29 0a0a 2020 2020  [1, 2, 3])..    
+00023fd0: 2320 6d69 6d69 6320 6675 6e63 7469 6f6e  # mimic function
+00023fe0: 616c 6974 7920 6672 6f6d 2068 7474 7073  ality from https
+00023ff0: 3a2f 2f70 7974 6f72 6368 2e6f 7267 2f64  ://pytorch.org/d
+00024000: 6f63 732f 7374 6162 6c65 2f67 656e 6572  ocs/stable/gener
+00024010: 6174 6564 2f74 6f72 6368 2e6d 696e 2e68  ated/torch.min.h
+00024020: 746d 6c0a 2020 2020 6966 206c 656e 2869  tml.    if len(i
+00024030: 6e70 7574 7329 203d 3d20 313a 0a20 2020  nputs) == 1:.   
+00024040: 2020 2020 2076 616c 7565 203d 206d 622e       value = mb.
+00024050: 7265 6475 6365 5f6d 696e 2878 3d69 6e70  reduce_min(x=inp
+00024060: 7574 735b 305d 2c20 6178 6573 3d4e 6f6e  uts[0], axes=Non
+00024070: 652c 206e 616d 653d 6e6f 6465 2e6e 616d  e, name=node.nam
+00024080: 6529 0a20 2020 2020 2020 2063 6f6e 7465  e).        conte
+00024090: 7874 2e61 6464 2876 616c 7565 290a 2020  xt.add(value).  
+000240a0: 2020 656c 6966 206c 656e 2869 6e70 7574    elif len(input
+000240b0: 7329 203d 3d20 323a 0a20 2020 2020 2020  s) == 2:.       
+000240c0: 2076 616c 7565 203d 206d 622e 6d69 6e69   value = mb.mini
+000240d0: 6d75 6d28 783d 696e 7075 7473 5b30 5d2c  mum(x=inputs[0],
+000240e0: 2079 3d69 6e70 7574 735b 315d 2c20 6e61   y=inputs[1], na
+000240f0: 6d65 3d6e 6f64 652e 6e61 6d65 290a 2020  me=node.name).  
+00024100: 2020 2020 2020 636f 6e74 6578 742e 6164        context.ad
+00024110: 6428 7661 6c75 6529 0a20 2020 2065 6c69  d(value).    eli
+00024120: 6620 6c65 6e28 696e 7075 7473 2920 3d3d  f len(inputs) ==
+00024130: 2033 3a0a 2020 2020 2020 2020 5f69 6e70   3:.        _inp
+00024140: 7574 203d 2069 6e70 7574 735b 305d 0a20  ut = inputs[0]. 
+00024150: 2020 2020 2020 2064 696d 203d 2069 6e70         dim = inp
+00024160: 7574 735b 315d 2e76 616c 0a20 2020 2020  uts[1].val.     
+00024170: 2020 206b 6565 7064 696d 203d 2069 6e70     keepdim = inp
+00024180: 7574 735b 325d 2e76 616c 0a0a 2020 2020  uts[2].val..    
+00024190: 2020 2020 7661 6c75 6573 203d 206d 622e      values = mb.
+000241a0: 7265 6475 6365 5f6d 696e 2878 3d5f 696e  reduce_min(x=_in
+000241b0: 7075 742c 2061 7865 733d 5b64 696d 5d2c  put, axes=[dim],
+000241c0: 206b 6565 705f 6469 6d73 3d6b 6565 7064   keep_dims=keepd
+000241d0: 696d 290a 2020 2020 2020 2020 696e 6469  im).        indi
+000241e0: 6365 7320 3d20 6d62 2e72 6564 7563 655f  ces = mb.reduce_
+000241f0: 6172 676d 696e 2878 3d5f 696e 7075 742c  argmin(x=_input,
+00024200: 2061 7869 733d 6469 6d2c 206b 6565 705f   axis=dim, keep_
+00024210: 6469 6d73 3d6b 6565 7064 696d 290a 2020  dims=keepdim).  
+00024220: 2020 2020 2020 6173 7365 7274 206c 656e        assert len
+00024230: 286e 6f64 652e 6f75 7470 7574 7329 203d  (node.outputs) =
+00024240: 3d20 320a 2020 2020 2020 2020 7661 6c75  = 2.        valu
+00024250: 6573 5f6e 616d 6520 3d20 6e6f 6465 2e6f  es_name = node.o
+00024260: 7574 7075 7473 5b30 5d0a 2020 2020 2020  utputs[0].      
+00024270: 2020 696e 6469 6365 735f 6e61 6d65 203d    indices_name =
+00024280: 206e 6f64 652e 6f75 7470 7574 735b 315d   node.outputs[1]
+00024290: 0a20 2020 2020 2020 2063 6f6e 7465 7874  .        context
+000242a0: 2e61 6464 2876 616c 7565 732c 2074 6f72  .add(values, tor
+000242b0: 6368 5f6e 616d 653d 7661 6c75 6573 5f6e  ch_name=values_n
+000242c0: 616d 6529 0a20 2020 2020 2020 2063 6f6e  ame).        con
+000242d0: 7465 7874 2e61 6464 2869 6e64 6963 6573  text.add(indices
+000242e0: 2c20 746f 7263 685f 6e61 6d65 3d69 6e64  , torch_name=ind
+000242f0: 6963 6573 5f6e 616d 6529 0a0a 0a40 7265  ices_name)...@re
+00024300: 6769 7374 6572 5f74 6f72 6368 5f6f 700a  gister_torch_op.
+00024310: 6465 6620 6d61 7828 636f 6e74 6578 742c  def max(context,
+00024320: 206e 6f64 6529 3a0a 2020 2020 696e 7075   node):.    inpu
+00024330: 7473 203d 205f 6765 745f 696e 7075 7473  ts = _get_inputs
+00024340: 2863 6f6e 7465 7874 2c20 6e6f 6465 2c20  (context, node, 
+00024350: 6578 7065 6374 6564 3d5b 312c 2032 2c20  expected=[1, 2, 
+00024360: 335d 290a 0a20 2020 2023 206d 696d 6963  3])..    # mimic
+00024370: 2066 756e 6374 696f 6e61 6c69 7479 2066   functionality f
+00024380: 726f 6d20 6874 7470 733a 2f2f 7079 746f  rom https://pyto
+00024390: 7263 682e 6f72 672f 646f 6373 2f73 7461  rch.org/docs/sta
+000243a0: 626c 652f 6765 6e65 7261 7465 642f 746f  ble/generated/to
+000243b0: 7263 682e 6d61 782e 6874 6d6c 0a20 2020  rch.max.html.   
+000243c0: 2069 6620 6c65 6e28 696e 7075 7473 2920   if len(inputs) 
+000243d0: 3d3d 2031 3a0a 2020 2020 2020 2020 7661  == 1:.        va
+000243e0: 6c75 6520 3d20 6d62 2e72 6564 7563 655f  lue = mb.reduce_
+000243f0: 6d61 7828 783d 696e 7075 7473 5b30 5d2c  max(x=inputs[0],
+00024400: 2061 7865 733d 4e6f 6e65 2c20 6e61 6d65   axes=None, name
+00024410: 3d6e 6f64 652e 6e61 6d65 290a 2020 2020  =node.name).    
+00024420: 2020 2020 636f 6e74 6578 742e 6164 6428      context.add(
+00024430: 7661 6c75 6529 0a20 2020 2065 6c69 6620  value).    elif 
+00024440: 6c65 6e28 696e 7075 7473 2920 3d3d 2032  len(inputs) == 2
+00024450: 3a0a 2020 2020 2020 2020 7661 6c75 6520  :.        value 
+00024460: 3d20 6d62 2e6d 6178 696d 756d 2878 3d69  = mb.maximum(x=i
+00024470: 6e70 7574 735b 305d 2c20 793d 696e 7075  nputs[0], y=inpu
+00024480: 7473 5b31 5d2c 206e 616d 653d 6e6f 6465  ts[1], name=node
+00024490: 2e6e 616d 6529 0a20 2020 2020 2020 2063  .name).        c
+000244a0: 6f6e 7465 7874 2e61 6464 2876 616c 7565  ontext.add(value
+000244b0: 290a 2020 2020 656c 6966 206c 656e 2869  ).    elif len(i
+000244c0: 6e70 7574 7329 203d 3d20 333a 0a20 2020  nputs) == 3:.   
+000244d0: 2020 2020 205f 696e 7075 7420 3d20 696e       _input = in
+000244e0: 7075 7473 5b30 5d0a 2020 2020 2020 2020  puts[0].        
+000244f0: 6469 6d20 3d20 696e 7075 7473 5b31 5d2e  dim = inputs[1].
+00024500: 7661 6c0a 2020 2020 2020 2020 6b65 6570  val.        keep
+00024510: 6469 6d20 3d20 696e 7075 7473 5b32 5d2e  dim = inputs[2].
+00024520: 7661 6c0a 0a20 2020 2020 2020 2076 616c  val..        val
+00024530: 7565 7320 3d20 6d62 2e72 6564 7563 655f  ues = mb.reduce_
+00024540: 6d61 7828 783d 5f69 6e70 7574 2c20 6178  max(x=_input, ax
+00024550: 6573 3d5b 6469 6d5d 2c20 6b65 6570 5f64  es=[dim], keep_d
+00024560: 696d 733d 6b65 6570 6469 6d29 0a20 2020  ims=keepdim).   
+00024570: 2020 2020 2069 6e64 6963 6573 203d 206d       indices = m
+00024580: 622e 7265 6475 6365 5f61 7267 6d61 7828  b.reduce_argmax(
+00024590: 783d 5f69 6e70 7574 2c20 6178 6973 3d64  x=_input, axis=d
+000245a0: 696d 2c20 6b65 6570 5f64 696d 733d 6b65  im, keep_dims=ke
+000245b0: 6570 6469 6d29 0a20 2020 2020 2020 2061  epdim).        a
+000245c0: 7373 6572 7420 6c65 6e28 6e6f 6465 2e6f  ssert len(node.o
+000245d0: 7574 7075 7473 2920 3d3d 2032 0a20 2020  utputs) == 2.   
+000245e0: 2020 2020 2076 616c 7565 735f 6e61 6d65       values_name
+000245f0: 203d 206e 6f64 652e 6f75 7470 7574 735b   = node.outputs[
+00024600: 305d 0a20 2020 2020 2020 2069 6e64 6963  0].        indic
+00024610: 6573 5f6e 616d 6520 3d20 6e6f 6465 2e6f  es_name = node.o
+00024620: 7574 7075 7473 5b31 5d0a 2020 2020 2020  utputs[1].      
+00024630: 2020 636f 6e74 6578 742e 6164 6428 7661    context.add(va
+00024640: 6c75 6573 2c20 746f 7263 685f 6e61 6d65  lues, torch_name
+00024650: 3d76 616c 7565 735f 6e61 6d65 290a 2020  =values_name).  
+00024660: 2020 2020 2020 636f 6e74 6578 742e 6164        context.ad
+00024670: 6428 696e 6469 6365 732c 2074 6f72 6368  d(indices, torch
+00024680: 5f6e 616d 653d 696e 6469 6365 735f 6e61  _name=indices_na
+00024690: 6d65 290a 0a64 6566 205f 6164 645f 616d  me)..def _add_am
+000246a0: 6178 5f61 6d69 6e28 636f 6e74 6578 742c  ax_amin(context,
+000246b0: 206e 6f64 652c 2072 6564 7563 655f 6f70   node, reduce_op
+000246c0: 293a 0a20 2020 2020 2320 6d69 6d69 6320  ):.     # mimic 
+000246d0: 6675 6e63 7469 6f6e 616c 6974 7920 6672  functionality fr
+000246e0: 6f6d 2068 7474 7073 3a2f 2f70 7974 6f72  om https://pytor
+000246f0: 6368 2e6f 7267 2f64 6f63 732f 7374 6162  ch.org/docs/stab
+00024700: 6c65 2f67 656e 6572 6174 6564 2f74 6f72  le/generated/tor
+00024710: 6368 2e61 6d61 782e 6874 6d6c 0a20 2020  ch.amax.html.   
+00024720: 2020 2320 6d69 6d69 6320 6675 6e63 7469    # mimic functi
+00024730: 6f6e 616c 6974 7920 6672 6f6d 2068 7474  onality from htt
+00024740: 7073 3a2f 2f70 7974 6f72 6368 2e6f 7267  ps://pytorch.org
+00024750: 2f64 6f63 732f 7374 6162 6c65 2f67 656e  /docs/stable/gen
+00024760: 6572 6174 6564 2f74 6f72 6368 2e61 6d69  erated/torch.ami
+00024770: 6e2e 6874 6d6c 0a20 2020 2061 7373 6572  n.html.    asser
+00024780: 7420 6c65 6e28 6e6f 6465 2e6f 7574 7075  t len(node.outpu
+00024790: 7473 2920 3d3d 2031 0a0a 2020 2020 616c  ts) == 1..    al
+000247a0: 6c5f 696e 7075 7473 203d 205f 6765 745f  l_inputs = _get_
+000247b0: 696e 7075 7473 2863 6f6e 7465 7874 2c20  inputs(context, 
+000247c0: 6e6f 6465 2c20 6578 7065 6374 6564 3d5b  node, expected=[
+000247d0: 322c 2033 5d29 0a20 2020 205f 696e 7075  2, 3]).    _inpu
+000247e0: 7420 3d20 616c 6c5f 696e 7075 7473 5b30  t = all_inputs[0
+000247f0: 5d0a 2020 2020 6469 6d20 3d20 5b61 6c6c  ].    dim = [all
+00024800: 5f69 6e70 7574 735b 315d 2e76 616c 5d20  _inputs[1].val] 
+00024810: 6966 2074 7970 6528 616c 6c5f 696e 7075  if type(all_inpu
+00024820: 7473 5b31 5d2e 7661 6c29 203d 3d20 696e  ts[1].val) == in
+00024830: 7420 656c 7365 205b 7820 666f 7220 7820  t else [x for x 
+00024840: 696e 2061 6c6c 5f69 6e70 7574 735b 315d  in all_inputs[1]
+00024850: 2e76 616c 5d0a 2020 2020 6b65 6570 6469  .val].    keepdi
+00024860: 6d20 3d20 616c 6c5f 696e 7075 7473 5b32  m = all_inputs[2
+00024870: 5d20 6966 206c 656e 2861 6c6c 5f69 6e70  ] if len(all_inp
+00024880: 7574 7329 203d 3d20 3320 656c 7365 2046  uts) == 3 else F
+00024890: 616c 7365 0a0a 2020 2020 636f 6e74 6578  alse..    contex
+000248a0: 742e 6164 6428 7265 6475 6365 5f6f 7028  t.add(reduce_op(
+000248b0: 783d 5f69 6e70 7574 2c20 6178 6573 3d64  x=_input, axes=d
+000248c0: 696d 2c20 6b65 6570 5f64 696d 733d 6b65  im, keep_dims=ke
+000248d0: 6570 6469 6d29 2c20 746f 7263 685f 6e61  epdim), torch_na
+000248e0: 6d65 3d6e 6f64 652e 6f75 7470 7574 735b  me=node.outputs[
+000248f0: 305d 290a 0a40 7265 6769 7374 6572 5f74  0])..@register_t
+00024900: 6f72 6368 5f6f 700a 6465 6620 616d 6178  orch_op.def amax
+00024910: 2863 6f6e 7465 7874 2c20 6e6f 6465 293a  (context, node):
+00024920: 0a20 2020 205f 6164 645f 616d 6178 5f61  .    _add_amax_a
+00024930: 6d69 6e28 636f 6e74 6578 742c 206e 6f64  min(context, nod
+00024940: 652c 206d 622e 7265 6475 6365 5f6d 6178  e, mb.reduce_max
+00024950: 290a 0a40 7265 6769 7374 6572 5f74 6f72  )..@register_tor
+00024960: 6368 5f6f 700a 6465 6620 616d 696e 2863  ch_op.def amin(c
+00024970: 6f6e 7465 7874 2c20 6e6f 6465 293a 0a20  ontext, node):. 
+00024980: 2020 205f 6164 645f 616d 6178 5f61 6d69     _add_amax_ami
+00024990: 6e28 636f 6e74 6578 742c 206e 6f64 652c  n(context, node,
+000249a0: 206d 622e 7265 6475 6365 5f6d 696e 290a   mb.reduce_min).
+000249b0: 0a0a 4072 6567 6973 7465 725f 746f 7263  ..@register_torc
+000249c0: 685f 6f70 0a64 6566 2061 7267 736f 7274  h_op.def argsort
+000249d0: 2863 6f6e 7465 7874 2c20 6e6f 6465 293a  (context, node):
+000249e0: 0a20 2020 2069 6e70 7574 7320 3d20 5f67  .    inputs = _g
+000249f0: 6574 5f69 6e70 7574 7328 636f 6e74 6578  et_inputs(contex
+00024a00: 742c 206e 6f64 652c 2065 7870 6563 7465  t, node, expecte
+00024a10: 643d 3329 0a20 2020 2061 7363 656e 6469  d=3).    ascendi
+00024a20: 6e67 203d 206d 622e 6c6f 6769 6361 6c5f  ng = mb.logical_
+00024a30: 6e6f 7428 783d 696e 7075 7473 5b32 5d29  not(x=inputs[2])
+00024a40: 0a20 2020 2061 7267 736f 7274 203d 206d  .    argsort = m
+00024a50: 622e 6172 6773 6f72 7428 783d 696e 7075  b.argsort(x=inpu
+00024a60: 7473 5b30 5d2c 2061 7869 733d 696e 7075  ts[0], axis=inpu
+00024a70: 7473 5b31 5d2c 2061 7363 656e 6469 6e67  ts[1], ascending
+00024a80: 3d61 7363 656e 6469 6e67 2c20 6e61 6d65  =ascending, name
+00024a90: 3d6e 6f64 652e 6e61 6d65 290a 2020 2020  =node.name).    
+00024aa0: 636f 6e74 6578 742e 6164 6428 6172 6773  context.add(args
+00024ab0: 6f72 7429 0a0a 0a40 7265 6769 7374 6572  ort)...@register
+00024ac0: 5f74 6f72 6368 5f6f 700a 6465 6620 736f  _torch_op.def so
+00024ad0: 7274 2863 6f6e 7465 7874 2c20 6e6f 6465  rt(context, node
+00024ae0: 293a 0a20 2020 2069 6e70 7574 7320 3d20  ):.    inputs = 
+00024af0: 5f67 6574 5f69 6e70 7574 7328 636f 6e74  _get_inputs(cont
+00024b00: 6578 742c 206e 6f64 6529 0a20 2020 205f  ext, node).    _
+00024b10: 696e 7075 7420 3d20 696e 7075 7473 5b30  input = inputs[0
+00024b20: 5d0a 2020 2020 6178 6973 203d 2069 6e70  ].    axis = inp
+00024b30: 7574 735b 315d 2e76 616c 0a20 2020 2061  uts[1].val.    a
+00024b40: 7363 656e 6469 6e67 203d 206e 6f74 2069  scending = not i
+00024b50: 6e70 7574 735b 325d 2e76 616c 0a20 2020  nputs[2].val.   
+00024b60: 2069 6e64 6963 6573 5f6e 616d 6520 3d20   indices_name = 
+00024b70: 6e6f 6465 2e6f 7574 7075 7473 5b31 5d0a  node.outputs[1].
+00024b80: 2020 2020 7661 6c75 6573 5f6e 616d 6520      values_name 
+00024b90: 3d20 6e6f 6465 2e6f 7574 7075 7473 5b30  = node.outputs[0
+00024ba0: 5d0a 2020 2020 696e 6469 6365 7320 3d20  ].    indices = 
+00024bb0: 6d62 2e61 7267 736f 7274 2878 3d5f 696e  mb.argsort(x=_in
+00024bc0: 7075 742c 2061 7869 733d 6178 6973 2c20  put, axis=axis, 
+00024bd0: 6173 6365 6e64 696e 673d 6173 6365 6e64  ascending=ascend
+00024be0: 696e 672c 206e 616d 653d 696e 6469 6365  ing, name=indice
+00024bf0: 735f 6e61 6d65 290a 2020 2020 7661 6c75  s_name).    valu
+00024c00: 6573 203d 206d 622e 6761 7468 6572 5f61  es = mb.gather_a
+00024c10: 6c6f 6e67 5f61 7869 7328 783d 5f69 6e70  long_axis(x=_inp
+00024c20: 7574 2c20 696e 6469 6365 733d 696e 6469  ut, indices=indi
+00024c30: 6365 732c 2061 7869 733d 6178 6973 2c20  ces, axis=axis, 
+00024c40: 6e61 6d65 3d76 616c 7565 735f 6e61 6d65  name=values_name
+00024c50: 290a 2020 2020 636f 6e74 6578 742e 6164  ).    context.ad
+00024c60: 6428 7661 6c75 6573 2c20 746f 7263 685f  d(values, torch_
+00024c70: 6e61 6d65 3d76 616c 7565 735f 6e61 6d65  name=values_name
+00024c80: 290a 2020 2020 636f 6e74 6578 742e 6164  ).    context.ad
+00024c90: 6428 696e 6469 6365 732c 2074 6f72 6368  d(indices, torch
+00024ca0: 5f6e 616d 653d 696e 6469 6365 735f 6e61  _name=indices_na
+00024cb0: 6d65 290a 0a0a 4072 6567 6973 7465 725f  me)...@register_
+00024cc0: 746f 7263 685f 6f70 0a64 6566 2061 7070  torch_op.def app
+00024cd0: 656e 6428 636f 6e74 6578 742c 206e 6f64  end(context, nod
+00024ce0: 6529 3a0a 2020 2020 2320 4e6f 7465 3a20  e):.    # Note: 
+00024cf0: 6279 2061 7070 6c79 696e 6720 746f 7263  by applying torc
+00024d00: 6869 725f 7061 7373 6573 2e74 7261 6e73  hir_passes.trans
+00024d10: 666f 726d 5f69 6e70 6c61 6365 5f6f 7073  form_inplace_ops
+00024d20: 2074 6865 206d 6561 6e69 6e67 206f 660a   the meaning of.
+00024d30: 2020 2020 2320 7468 6973 206f 7020 6973      # this op is
+00024d40: 2063 6861 6e67 6564 2066 726f 6d20 7468   changed from th
+00024d50: 6520 6f72 6967 696e 616c 2054 6f72 6368  e original Torch
+00024d60: 4952 2e20 5468 6973 206f 7020 6578 7065  IR. This op expe
+00024d70: 6374 7320 6120 7079 7468 6f6e 0a20 2020  cts a python.   
+00024d80: 2023 206c 6973 7420 6f72 204d 494c 204c   # list or MIL L
+00024d90: 6973 7420 6173 2069 7473 2066 6972 7374  ist as its first
+00024da0: 2069 6e70 7574 2e20 4966 2061 6e20 4d49   input. If an MI
+00024db0: 4c20 4c69 7374 2c20 7468 6520 7365 636f  L List, the seco
+00024dc0: 6e64 2069 6e70 7574 0a20 2020 2023 206d  nd input.    # m
+00024dd0: 7573 7420 6265 2061 2074 656e 736f 7220  ust be a tensor 
+00024de0: 6f66 2077 6861 7465 7665 7220 7368 6170  of whatever shap
+00024df0: 6520 7468 6520 4c69 7374 2065 7870 6563  e the List expec
+00024e00: 7473 2e20 4966 206e 6f74 2061 6e20 4d49  ts. If not an MI
+00024e10: 4c20 4c69 7374 2c0a 2020 2020 2320 7468  L List,.    # th
+00024e20: 6520 7365 636f 6e64 2069 6e70 7574 2063  e second input c
+00024e30: 616e 2062 7920 616e 7974 6869 6e67 2e20  an by anything. 
+00024e40: 5468 6520 7265 7375 6c74 2077 696c 6c20  The result will 
+00024e50: 6265 2074 6865 2073 6563 6f6e 6420 696e  be the second in
+00024e60: 7075 740a 2020 2020 2320 6a6f 696e 6564  put.    # joined
+00024e70: 2074 6f20 7468 6520 6669 7273 7420 696e   to the first in
+00024e80: 7075 742c 2065 6974 6865 7220 6279 206c  put, either by l
+00024e90: 6973 745f 7772 6974 6520 6966 2061 6e20  ist_write if an 
+00024ea0: 4d49 4c20 6c69 7374 2c20 6f72 0a20 2020  MIL list, or.   
+00024eb0: 2023 2061 7070 656e 6420 6966 2061 2070   # append if a p
+00024ec0: 7974 686f 6e20 6c69 7374 2e0a 2020 2020  ython list..    
+00024ed0: 696e 7075 7473 203d 205f 6765 745f 696e  inputs = _get_in
+00024ee0: 7075 7473 2863 6f6e 7465 7874 2c20 6e6f  puts(context, no
+00024ef0: 6465 2c20 6578 7065 6374 6564 3d32 290a  de, expected=2).
+00024f00: 2020 2020 6c73 203d 2069 6e70 7574 735b      ls = inputs[
+00024f10: 305d 0a20 2020 2076 616c 7565 203d 2069  0].    value = i
+00024f20: 6e70 7574 735b 315d 0a0a 2020 2020 6966  nputs[1]..    if
+00024f30: 2069 7369 6e73 7461 6e63 6528 6c73 2c20   isinstance(ls, 
+00024f40: 6c69 7374 293a 0a20 2020 2020 2020 2063  list):.        c
+00024f50: 6f6e 7465 7874 2e61 6464 286c 7320 2b20  ontext.add(ls + 
+00024f60: 5b76 616c 7565 5d2c 206e 6f64 652e 6e61  [value], node.na
+00024f70: 6d65 290a 2020 2020 656c 6966 2069 7369  me).    elif isi
+00024f80: 6e73 7461 6e63 6528 6c73 2c20 4c69 7374  nstance(ls, List
+00024f90: 5661 7229 3a0a 2020 2020 2020 2020 696e  Var):.        in
+00024fa0: 6465 7820 3d20 6d62 2e6c 6973 745f 6c65  dex = mb.list_le
+00024fb0: 6e67 7468 286c 733d 6c73 2c20 6e61 6d65  ngth(ls=ls, name
+00024fc0: 3d6e 6f64 652e 6e61 6d65 202b 2022 5f69  =node.name + "_i
+00024fd0: 6e64 6578 2229 0a20 2020 2020 2020 2072  ndex").        r
+00024fe0: 6573 203d 206d 622e 6c69 7374 5f77 7269  es = mb.list_wri
+00024ff0: 7465 286c 733d 6c73 2c20 696e 6465 783d  te(ls=ls, index=
+00025000: 696e 6465 782c 2076 616c 7565 3d76 616c  index, value=val
+00025010: 7565 2c20 6e61 6d65 3d6e 6f64 652e 6e61  ue, name=node.na
+00025020: 6d65 290a 2020 2020 2020 2020 636f 6e74  me).        cont
+00025030: 6578 742e 6164 6428 7265 7329 0a20 2020  ext.add(res).   
+00025040: 2065 6c73 653a 0a20 2020 2020 2020 2072   else:.        r
+00025050: 6169 7365 2056 616c 7565 4572 726f 7228  aise ValueError(
+00025060: 0a20 2020 2020 2020 2020 2020 2022 6361  .            "ca
+00025070: 6e20 6f6e 6c79 2061 7070 656e 6420 746f  n only append to
+00025080: 2050 7974 686f 6e20 6c69 7374 206f 7220   Python list or 
+00025090: 4d49 4c20 4c69 7374 5661 722c 2067 6f74  MIL ListVar, got
+000250a0: 207b 7d2e 222e 666f 726d 6174 280a 2020   {}.".format(.  
+000250b0: 2020 2020 2020 2020 2020 2020 2020 7479                ty
+000250c0: 7065 2869 6e70 7574 735b 305d 290a 2020  pe(inputs[0]).  
+000250d0: 2020 2020 2020 2020 2020 290a 2020 2020            ).    
+000250e0: 2020 2020 290a 0a0a 4072 6567 6973 7465      )...@registe
+000250f0: 725f 746f 7263 685f 6f70 0a64 6566 2067  r_torch_op.def g
+00025100: 6174 6865 7228 636f 6e74 6578 742c 206e  ather(context, n
+00025110: 6f64 6529 3a0a 2020 2020 696e 7075 7473  ode):.    inputs
+00025120: 203d 205f 6765 745f 696e 7075 7473 2863   = _get_inputs(c
+00025130: 6f6e 7465 7874 2c20 6e6f 6465 290a 2020  ontext, node).  
+00025140: 2020 7265 7320 3d20 6d62 2e67 6174 6865    res = mb.gathe
+00025150: 725f 616c 6f6e 675f 6178 6973 2878 3d69  r_along_axis(x=i
+00025160: 6e70 7574 735b 305d 2c20 696e 6469 6365  nputs[0], indice
+00025170: 733d 696e 7075 7473 5b32 5d2c 2061 7869  s=inputs[2], axi
+00025180: 733d 696e 7075 7473 5b31 5d2c 206e 616d  s=inputs[1], nam
+00025190: 653d 6e6f 6465 2e6e 616d 6529 0a20 2020  e=node.name).   
+000251a0: 2063 6f6e 7465 7874 2e61 6464 2872 6573   context.add(res
+000251b0: 290a 0a0a 4072 6567 6973 7465 725f 746f  )...@register_to
+000251c0: 7263 685f 6f70 0a64 6566 2069 6e64 6578  rch_op.def index
+000251d0: 5f73 656c 6563 7428 636f 6e74 6578 742c  _select(context,
+000251e0: 206e 6f64 6529 3a0a 2020 2020 7820 3d20   node):.    x = 
+000251f0: 636f 6e74 6578 745b 6e6f 6465 2e69 6e70  context[node.inp
+00025200: 7574 735b 305d 5d0a 2020 2020 6178 6973  uts[0]].    axis
+00025210: 203d 2063 6f6e 7465 7874 5b6e 6f64 652e   = context[node.
+00025220: 696e 7075 7473 5b31 5d5d 0a20 2020 2069  inputs[1]].    i
+00025230: 6e64 6963 6573 203d 2063 6f6e 7465 7874  ndices = context
+00025240: 5b6e 6f64 652e 696e 7075 7473 5b32 5d5d  [node.inputs[2]]
+00025250: 0a20 2020 2063 6f6e 7465 7874 2e61 6464  .    context.add
+00025260: 286d 622e 6761 7468 6572 2878 3d78 2c20  (mb.gather(x=x, 
+00025270: 696e 6469 6365 733d 696e 6469 6365 732c  indices=indices,
+00025280: 2061 7869 733d 6178 6973 2c20 6e61 6d65   axis=axis, name
+00025290: 3d6e 6f64 652e 6e61 6d65 2929 0a0a 0a40  =node.name))...@
+000252a0: 7265 6769 7374 6572 5f74 6f72 6368 5f6f  register_torch_o
+000252b0: 7028 746f 7263 685f 616c 6961 733d 5b22  p(torch_alias=["
+000252c0: 6162 7322 5d29 0a64 6566 205f 6162 7328  abs"]).def _abs(
+000252d0: 636f 6e74 6578 742c 206e 6f64 6529 3a0a  context, node):.
+000252e0: 2020 2020 7820 3d20 5f67 6574 5f69 6e70      x = _get_inp
+000252f0: 7574 7328 636f 6e74 6578 742c 206e 6f64  uts(context, nod
+00025300: 652c 2065 7870 6563 7465 643d 3129 5b30  e, expected=1)[0
+00025310: 5d0a 2020 2020 6966 2074 7970 6573 2e69  ].    if types.i
+00025320: 735f 636f 6d70 6c65 7828 782e 6474 7970  s_complex(x.dtyp
+00025330: 6529 3a0a 2020 2020 2020 2020 636f 6e74  e):.        cont
+00025340: 6578 742e 6164 6428 6d62 2e63 6f6d 706c  ext.add(mb.compl
+00025350: 6578 5f61 6273 2878 3d78 2c20 6e61 6d65  ex_abs(x=x, name
+00025360: 3d6e 6f64 652e 6e61 6d65 2929 0a20 2020  =node.name)).   
+00025370: 2065 6c73 653a 0a20 2020 2020 2020 2063   else:.        c
+00025380: 6f6e 7465 7874 2e61 6464 286d 622e 6162  ontext.add(mb.ab
+00025390: 7328 783d 782c 206e 616d 653d 6e6f 6465  s(x=x, name=node
+000253a0: 2e6e 616d 6529 290a 0a0a 4072 6567 6973  .name))...@regis
+000253b0: 7465 725f 746f 7263 685f 6f70 0a64 6566  ter_torch_op.def
+000253c0: 2072 6570 6561 7428 636f 6e74 6578 742c   repeat(context,
+000253d0: 206e 6f64 6529 3a0a 2020 2020 7820 3d20   node):.    x = 
+000253e0: 636f 6e74 6578 745b 6e6f 6465 2e69 6e70  context[node.inp
+000253f0: 7574 735b 305d 5d0a 2020 2020 7265 7073  uts[0]].    reps
+00025400: 203d 2063 6f6e 7465 7874 5b6e 6f64 652e   = context[node.
+00025410: 696e 7075 7473 5b31 5d5d 0a20 2020 2069  inputs[1]].    i
+00025420: 6620 6973 696e 7374 616e 6365 2872 6570  f isinstance(rep
+00025430: 732c 206c 6973 7429 3a0a 2020 2020 2020  s, list):.      
+00025440: 2020 7265 7073 203d 206d 622e 636f 6e63    reps = mb.conc
+00025450: 6174 2876 616c 7565 733d 7265 7073 2c20  at(values=reps, 
+00025460: 6178 6973 3d30 290a 0a20 2020 2069 6620  axis=0)..    if 
+00025470: 7265 7073 2e73 6861 7065 5b30 5d20 3e20  reps.shape[0] > 
+00025480: 6c65 6e28 782e 7368 6170 6529 3a0a 2020  len(x.shape):.  
+00025490: 2020 2020 2020 7820 3d20 6d62 2e65 7870        x = mb.exp
+000254a0: 616e 645f 6469 6d73 2878 3d78 2c20 6178  and_dims(x=x, ax
+000254b0: 6573 3d6c 6973 7428 7261 6e67 6528 7265  es=list(range(re
+000254c0: 7073 2e73 6861 7065 5b30 5d20 2d20 782e  ps.shape[0] - x.
+000254d0: 7261 6e6b 2929 290a 2020 2020 636f 6e74  rank))).    cont
+000254e0: 6578 742e 6164 6428 6d62 2e74 696c 6528  ext.add(mb.tile(
+000254f0: 783d 782c 2072 6570 733d 7265 7073 2c20  x=x, reps=reps, 
+00025500: 6e61 6d65 3d6e 6f64 652e 6e61 6d65 2929  name=node.name))
+00025510: 0a0a 0a40 7265 6769 7374 6572 5f74 6f72  ...@register_tor
+00025520: 6368 5f6f 700a 6465 6620 6163 6f73 2863  ch_op.def acos(c
+00025530: 6f6e 7465 7874 2c20 6e6f 6465 293a 0a20  ontext, node):. 
+00025540: 2020 2069 6e70 7574 7320 3d20 5f67 6574     inputs = _get
+00025550: 5f69 6e70 7574 7328 636f 6e74 6578 742c  _inputs(context,
+00025560: 206e 6f64 652c 2065 7870 6563 7465 643d   node, expected=
+00025570: 3129 0a20 2020 2063 6f6e 7465 7874 2e61  1).    context.a
+00025580: 6464 286d 622e 6163 6f73 2878 3d69 6e70  dd(mb.acos(x=inp
+00025590: 7574 735b 305d 2c20 6e61 6d65 3d6e 6f64  uts[0], name=nod
+000255a0: 652e 6e61 6d65 2929 0a0a 0a40 7265 6769  e.name))...@regi
+000255b0: 7374 6572 5f74 6f72 6368 5f6f 700a 6465  ster_torch_op.de
+000255c0: 6620 6163 6f73 6828 636f 6e74 6578 742c  f acosh(context,
+000255d0: 206e 6f64 6529 3a0a 2020 2020 696e 7075   node):.    inpu
+000255e0: 7473 203d 205f 6765 745f 696e 7075 7473  ts = _get_inputs
+000255f0: 2863 6f6e 7465 7874 2c20 6e6f 6465 2c20  (context, node, 
+00025600: 6578 7065 6374 6564 3d31 290a 2020 2020  expected=1).    
+00025610: 636f 6e74 6578 742e 6164 6428 6d62 2e61  context.add(mb.a
+00025620: 636f 7368 2878 3d69 6e70 7574 735b 305d  cosh(x=inputs[0]
+00025630: 2c20 6e61 6d65 3d6e 6f64 652e 6e61 6d65  , name=node.name
+00025640: 2929 0a0a 0a40 7265 6769 7374 6572 5f74  ))...@register_t
+00025650: 6f72 6368 5f6f 700a 6465 6620 6173 696e  orch_op.def asin
+00025660: 2863 6f6e 7465 7874 2c20 6e6f 6465 293a  (context, node):
+00025670: 0a20 2020 2069 6e70 7574 7320 3d20 5f67  .    inputs = _g
+00025680: 6574 5f69 6e70 7574 7328 636f 6e74 6578  et_inputs(contex
+00025690: 742c 206e 6f64 652c 2065 7870 6563 7465  t, node, expecte
+000256a0: 643d 3129 0a20 2020 2063 6f6e 7465 7874  d=1).    context
+000256b0: 2e61 6464 286d 622e 6173 696e 2878 3d69  .add(mb.asin(x=i
+000256c0: 6e70 7574 735b 305d 2c20 6e61 6d65 3d6e  nputs[0], name=n
+000256d0: 6f64 652e 6e61 6d65 2929 0a0a 0a40 7265  ode.name))...@re
+000256e0: 6769 7374 6572 5f74 6f72 6368 5f6f 700a  gister_torch_op.
+000256f0: 6465 6620 6174 616e 2863 6f6e 7465 7874  def atan(context
+00025700: 2c20 6e6f 6465 293a 0a20 2020 2069 6e70  , node):.    inp
+00025710: 7574 7320 3d20 5f67 6574 5f69 6e70 7574  uts = _get_input
+00025720: 7328 636f 6e74 6578 742c 206e 6f64 652c  s(context, node,
+00025730: 2065 7870 6563 7465 643d 3129 0a20 2020   expected=1).   
+00025740: 2063 6f6e 7465 7874 2e61 6464 286d 622e   context.add(mb.
+00025750: 6174 616e 2878 3d69 6e70 7574 735b 305d  atan(x=inputs[0]
+00025760: 2c20 6e61 6d65 3d6e 6f64 652e 6e61 6d65  , name=node.name
+00025770: 2929 0a0a 0a40 7265 6769 7374 6572 5f74  ))...@register_t
+00025780: 6f72 6368 5f6f 700a 6465 6620 6174 616e  orch_op.def atan
+00025790: 3228 636f 6e74 6578 742c 206e 6f64 6529  2(context, node)
+000257a0: 3a0a 2020 2020 2222 220a 2020 2020 6174  :.    """.    at
+000257b0: 616e 3228 5465 6e73 6f72 2079 2c20 5465  an2(Tensor y, Te
+000257c0: 6e73 6f72 2078 290a 2020 2020 456c 656d  nsor x).    Elem
+000257d0: 656e 742d 7769 7365 2061 7263 7461 6e67  ent-wise arctang
+000257e0: 656e 7420 6f66 2079 202f 2078 2077 6974  ent of y / x wit
+000257f0: 6820 636f 6e73 6964 6572 6174 696f 6e20  h consideration 
+00025800: 6f66 2074 6865 2071 7561 6472 616e 740a  of the quadrant.
+00025810: 2020 2020 5265 7475 726e 7320 6120 6e65      Returns a ne
+00025820: 7720 7465 6e73 6f72 2077 6974 6820 7468  w tensor with th
+00025830: 6520 7369 676e 6564 2061 6e67 6c65 7320  e signed angles 
+00025840: 696e 2072 6164 6961 6e73 2062 6574 7765  in radians betwe
+00025850: 656e 2076 6563 746f 7220 2878 2c20 7929  en vector (x, y)
+00025860: 2061 6e64 2076 6563 746f 7220 2831 2c20   and vector (1, 
+00025870: 3029 0a0a 2020 2020 4f6e 2061 2068 6967  0)..    On a hig
+00025880: 6820 6c65 7665 6c3a 0a20 2020 2031 2e20  h level:.    1. 
+00025890: 6174 616e 2879 202f 2078 2920 746f 2067  atan(y / x) to g
+000258a0: 6574 2074 6865 2061 6e67 6c65 2069 6e20  et the angle in 
+000258b0: 5b2d 7069 202f 2032 2c20 7069 202f 2032  [-pi / 2, pi / 2
+000258c0: 5d0a 2020 2020 322e 2061 6e61 6c79 7a65  ].    2. analyze
+000258d0: 2071 7561 6472 616e 7420 746f 2064 6574   quadrant to det
+000258e0: 6572 6d69 6e65 2074 6865 2061 6e67 6c65  ermine the angle
+000258f0: 2069 6e20 5b2d 7069 2c20 7069 5d0a 0a20   in [-pi, pi].. 
+00025900: 2020 2052 6566 6572 656e 6365 2050 7954     Reference PyT
+00025910: 6f72 6368 2063 6f64 6520 6874 7470 733a  orch code https:
+00025920: 2f2f 6769 7374 2e67 6974 6875 622e 636f  //gist.github.co
+00025930: 6d2f 6e69 6b6f 6c61 2d6a 2f62 3562 6236  m/nikola-j/b5bb6
+00025940: 6231 3431 6238 6439 3932 3033 3138 3637  b141b8d992031867
+00025950: 3765 3162 6261 3730 3436 360a 2020 2020  7e1bba70466.    
+00025960: 6465 6620 6d79 5f61 7461 6e32 2879 2c20  def my_atan2(y, 
+00025970: 7829 3a0a 2020 2020 2020 2020 7069 203d  x):.        pi =
+00025980: 2074 6f72 6368 2e66 726f 6d5f 6e75 6d70   torch.from_nump
+00025990: 7928 6e70 2e61 7272 6179 285b 6e70 2e70  y(np.array([np.p
+000259a0: 695d 2929 2e74 6f28 792e 6465 7669 6365  i])).to(y.device
+000259b0: 2c20 792e 6474 7970 6529 0a20 2020 2020  , y.dtype).     
+000259c0: 2020 2061 6e73 203d 2074 6f72 6368 2e61     ans = torch.a
+000259d0: 7461 6e28 7920 2f20 7829 0a20 2020 2020  tan(y / x).     
+000259e0: 2020 2061 6e73 202b 3d20 2828 7920 3e20     ans += ((y > 
+000259f0: 3029 2026 2028 7820 3c20 3029 2920 2a20  0) & (x < 0)) * 
+00025a00: 7069 0a20 2020 2020 2020 2061 6e73 202d  pi.        ans -
+00025a10: 3d20 2828 7920 3c20 3029 2026 2028 7820  = ((y < 0) & (x 
+00025a20: 3c20 3029 2920 2a20 7069 0a20 2020 2020  < 0)) * pi.     
+00025a30: 2020 2061 6e73 202a 3d20 2831 202d 2028     ans *= (1 - (
+00025a40: 2879 203e 2030 2920 2620 2878 203d 3d20  (y > 0) & (x == 
+00025a50: 3029 2920 2a20 312e 3029 0a20 2020 2020  0)) * 1.0).     
+00025a60: 2020 2061 6e73 202b 3d20 2828 7920 3e20     ans += ((y > 
+00025a70: 3029 2026 2028 7820 3d3d 2030 2929 202a  0) & (x == 0)) *
+00025a80: 2028 7069 202f 2032 290a 2020 2020 2020   (pi / 2).      
+00025a90: 2020 616e 7320 2a3d 2028 3120 2d20 2828    ans *= (1 - ((
+00025aa0: 7920 3c20 3029 2026 2028 7820 3d3d 2030  y < 0) & (x == 0
+00025ab0: 2929 202a 2031 2e30 290a 2020 2020 2020  )) * 1.0).      
+00025ac0: 2020 616e 7320 2b3d 2028 2879 203c 2030    ans += ((y < 0
+00025ad0: 2920 2620 2878 203d 3d20 3029 2920 2a20  ) & (x == 0)) * 
+00025ae0: 282d 7069 202f 2032 290a 2020 2020 2020  (-pi / 2).      
+00025af0: 2020 7265 7475 726e 2061 6e73 0a20 2020    return ans.   
+00025b00: 2022 2222 0a20 2020 2069 6e70 7574 7320   """.    inputs 
+00025b10: 3d20 5f67 6574 5f69 6e70 7574 7328 636f  = _get_inputs(co
+00025b20: 6e74 6578 742c 206e 6f64 652c 2065 7870  ntext, node, exp
+00025b30: 6563 7465 643d 3229 0a20 2020 2079 203d  ected=2).    y =
+00025b40: 2069 6e70 7574 735b 305d 0a20 2020 2078   inputs[0].    x
+00025b50: 203d 2069 6e70 7574 735b 315d 0a20 2020   = inputs[1].   
+00025b60: 2069 6620 6e6f 7420 7479 7065 732e 6973   if not types.is
+00025b70: 5f66 6c6f 6174 2879 2e64 7479 7065 293a  _float(y.dtype):
+00025b80: 0a20 2020 2020 2020 2079 203d 206d 622e  .        y = mb.
+00025b90: 6361 7374 2878 3d79 2c20 6474 7970 653d  cast(x=y, dtype=
+00025ba0: 2266 7033 3222 290a 2020 2020 6966 206e  "fp32").    if n
+00025bb0: 6f74 2074 7970 6573 2e69 735f 666c 6f61  ot types.is_floa
+00025bc0: 7428 782e 6474 7970 6529 3a0a 2020 2020  t(x.dtype):.    
+00025bd0: 2020 2020 7820 3d20 6d62 2e63 6173 7428      x = mb.cast(
+00025be0: 783d 782c 2064 7479 7065 3d22 6670 3332  x=x, dtype="fp32
+00025bf0: 2229 0a0a 2020 2020 2320 6261 7369 6320  ")..    # basic 
+00025c00: 6c6f 6769 6361 6c20 6578 7072 6573 7369  logical expressi
+00025c10: 6f6e 730a 2020 2020 795f 6c65 7373 5f30  ons.    y_less_0
+00025c20: 203d 206d 622e 6c65 7373 2878 3d79 2c20   = mb.less(x=y, 
+00025c30: 793d 302e 3029 0a20 2020 2079 5f67 7265  y=0.0).    y_gre
+00025c40: 6174 6572 5f30 203d 206d 622e 6772 6561  ater_0 = mb.grea
+00025c50: 7465 7228 783d 792c 2079 3d30 2e30 290a  ter(x=y, y=0.0).
+00025c60: 2020 2020 785f 6c65 7373 5f30 203d 206d      x_less_0 = m
+00025c70: 622e 6c65 7373 2878 3d78 2c20 793d 302e  b.less(x=x, y=0.
+00025c80: 3029 0a20 2020 2078 5f65 7175 616c 5f30  0).    x_equal_0
+00025c90: 203d 206d 622e 6571 7561 6c28 783d 782c   = mb.equal(x=x,
+00025ca0: 2079 3d30 2e30 290a 0a20 2020 2023 2063   y=0.0)..    # c
+00025cb0: 6f6d 6269 6e65 6420 6c6f 6769 6361 6c20  ombined logical 
+00025cc0: 6578 7072 6573 7369 6f6e 730a 2020 2020  expressions.    
+00025cd0: 7967 7265 6174 6572 305f 616e 645f 786c  ygreater0_and_xl
+00025ce0: 6573 7330 203d 206d 622e 6c6f 6769 6361  ess0 = mb.logica
+00025cf0: 6c5f 616e 6428 783d 795f 6772 6561 7465  l_and(x=y_greate
+00025d00: 725f 302c 2079 3d78 5f6c 6573 735f 3029  r_0, y=x_less_0)
+00025d10: 0a20 2020 2079 6c65 7373 305f 616e 645f  .    yless0_and_
+00025d20: 786c 6573 7330 203d 206d 622e 6c6f 6769  xless0 = mb.logi
+00025d30: 6361 6c5f 616e 6428 783d 795f 6c65 7373  cal_and(x=y_less
+00025d40: 5f30 2c20 793d 785f 6c65 7373 5f30 290a  _0, y=x_less_0).
+00025d50: 2020 2020 7967 7265 6174 6572 305f 616e      ygreater0_an
+00025d60: 645f 7865 7175 616c 3020 3d20 6d62 2e6c  d_xequal0 = mb.l
+00025d70: 6f67 6963 616c 5f61 6e64 2878 3d79 5f67  ogical_and(x=y_g
+00025d80: 7265 6174 6572 5f30 2c20 793d 785f 6571  reater_0, y=x_eq
+00025d90: 7561 6c5f 3029 0a20 2020 2079 6c65 7373  ual_0).    yless
+00025da0: 305f 616e 645f 7865 7175 616c 3020 3d20  0_and_xequal0 = 
+00025db0: 6d62 2e6c 6f67 6963 616c 5f61 6e64 2878  mb.logical_and(x
+00025dc0: 3d79 5f6c 6573 735f 302c 2079 3d78 5f65  =y_less_0, y=x_e
+00025dd0: 7175 616c 5f30 290a 0a20 2020 2023 2062  qual_0)..    # b
+00025de0: 6f6f 6c20 2d3e 2066 7033 3220 666f 7220  ool -> fp32 for 
+00025df0: 6e75 6d65 7269 6320 6f70 6572 6174 696f  numeric operatio
+00025e00: 6e0a 2020 2020 7967 7265 6174 6572 305f  n.    ygreater0_
+00025e10: 616e 645f 786c 6573 7330 5f6e 756d 6572  and_xless0_numer
+00025e20: 6963 203d 206d 622e 6361 7374 2878 3d79  ic = mb.cast(x=y
+00025e30: 6772 6561 7465 7230 5f61 6e64 5f78 6c65  greater0_and_xle
+00025e40: 7373 302c 2064 7479 7065 3d22 6670 3332  ss0, dtype="fp32
+00025e50: 2229 0a20 2020 2079 6c65 7373 305f 616e  ").    yless0_an
+00025e60: 645f 786c 6573 7330 5f6e 756d 6572 6963  d_xless0_numeric
+00025e70: 203d 206d 622e 6361 7374 2878 3d79 6c65   = mb.cast(x=yle
+00025e80: 7373 305f 616e 645f 786c 6573 7330 2c20  ss0_and_xless0, 
+00025e90: 6474 7970 653d 2266 7033 3222 290a 2020  dtype="fp32").  
+00025ea0: 2020 7967 7265 6174 6572 305f 616e 645f    ygreater0_and_
+00025eb0: 7865 7175 616c 305f 6e75 6d65 7269 6320  xequal0_numeric 
+00025ec0: 3d20 6d62 2e63 6173 7428 783d 7967 7265  = mb.cast(x=ygre
+00025ed0: 6174 6572 305f 616e 645f 7865 7175 616c  ater0_and_xequal
+00025ee0: 302c 2064 7479 7065 3d22 6670 3332 2229  0, dtype="fp32")
+00025ef0: 0a20 2020 2079 6c65 7373 305f 616e 645f  .    yless0_and_
+00025f00: 7865 7175 616c 305f 6e75 6d65 7269 6320  xequal0_numeric 
+00025f10: 3d20 6d62 2e63 6173 7428 783d 796c 6573  = mb.cast(x=yles
+00025f20: 7330 5f61 6e64 5f78 6571 7561 6c30 2c20  s0_and_xequal0, 
+00025f30: 6474 7970 653d 2266 7033 3222 290a 0a20  dtype="fp32").. 
+00025f40: 2020 2023 2071 7561 6472 616e 7420 6d6f     # quadrant mo
+00025f50: 6469 6669 6361 7469 6f6e 2063 6f65 6666  dification coeff
+00025f60: 6963 6965 6e74 730a 2020 2020 636f 6566  icients.    coef
+00025f70: 6631 203d 206d 622e 6d75 6c28 783d 7967  f1 = mb.mul(x=yg
+00025f80: 7265 6174 6572 305f 616e 645f 786c 6573  reater0_and_xles
+00025f90: 7330 5f6e 756d 6572 6963 2c20 793d 5f6e  s0_numeric, y=_n
+00025fa0: 702e 7069 290a 2020 2020 636f 6566 6632  p.pi).    coeff2
+00025fb0: 203d 206d 622e 6d75 6c28 783d 796c 6573   = mb.mul(x=yles
+00025fc0: 7330 5f61 6e64 5f78 6c65 7373 305f 6e75  s0_and_xless0_nu
+00025fd0: 6d65 7269 632c 2079 3d5f 6e70 2e70 6929  meric, y=_np.pi)
+00025fe0: 0a20 2020 2063 6f65 6666 3320 3d20 6d62  .    coeff3 = mb
+00025ff0: 2e73 7562 2878 3d31 2e30 2c20 793d 7967  .sub(x=1.0, y=yg
+00026000: 7265 6174 6572 305f 616e 645f 7865 7175  reater0_and_xequ
+00026010: 616c 305f 6e75 6d65 7269 6329 0a20 2020  al0_numeric).   
+00026020: 2063 6f65 6666 3420 3d20 6d62 2e6d 756c   coeff4 = mb.mul
+00026030: 2878 3d79 6772 6561 7465 7230 5f61 6e64  (x=ygreater0_and
+00026040: 5f78 6571 7561 6c30 5f6e 756d 6572 6963  _xequal0_numeric
+00026050: 2c20 793d 5f6e 702e 7069 202f 2032 2e30  , y=_np.pi / 2.0
+00026060: 290a 2020 2020 636f 6566 6635 203d 206d  ).    coeff5 = m
+00026070: 622e 7375 6228 783d 312e 302c 2079 3d79  b.sub(x=1.0, y=y
+00026080: 6c65 7373 305f 616e 645f 7865 7175 616c  less0_and_xequal
+00026090: 305f 6e75 6d65 7269 6329 0a20 2020 2063  0_numeric).    c
+000260a0: 6f65 6666 3620 3d20 6d62 2e6d 756c 2878  oeff6 = mb.mul(x
+000260b0: 3d79 6c65 7373 305f 616e 645f 7865 7175  =yless0_and_xequ
+000260c0: 616c 305f 6e75 6d65 7269 632c 2079 3d2d  al0_numeric, y=-
+000260d0: 5f6e 702e 7069 202f 2032 2e30 290a 0a20  _np.pi / 2.0).. 
+000260e0: 2020 2023 2069 6620 2d31 652d 3820 3c20     # if -1e-8 < 
+000260f0: 7820 3c20 3165 2d38 2c20 7820 2b3d 2032  x < 1e-8, x += 2
+00026100: 652d 3820 746f 2061 766f 6964 2079 202f  e-8 to avoid y /
+00026110: 2030 0a20 2020 2023 2074 6869 7320 7368   0.    # this sh
+00026120: 6966 7420 6d61 6b65 7320 6174 616e 3228  ift makes atan2(
+00026130: 302c 2030 2920 3d20 302c 2077 6869 6368  0, 0) = 0, which
+00026140: 2069 7320 636f 6e73 6973 7465 6e74 2077   is consistent w
+00026150: 6974 6820 5079 546f 7263 6820 746f 7263  ith PyTorch torc
+00026160: 682e 6174 616e 320a 2020 2020 7830 6c65  h.atan2.    x0le
+00026170: 6674 203d 206d 622e 6772 6561 7465 7228  ft = mb.greater(
+00026180: 783d 782c 2079 3d2d 3165 2d38 290a 2020  x=x, y=-1e-8).  
+00026190: 2020 7830 7269 6768 7420 3d20 6d62 2e6c    x0right = mb.l
+000261a0: 6573 7328 783d 782c 2079 3d31 652d 3829  ess(x=x, y=1e-8)
+000261b0: 0a20 2020 2078 3020 3d20 6d62 2e6c 6f67  .    x0 = mb.log
+000261c0: 6963 616c 5f61 6e64 2878 3d78 306c 6566  ical_and(x=x0lef
+000261d0: 742c 2079 3d78 3072 6967 6874 290a 2020  t, y=x0right).  
+000261e0: 2020 7830 6e75 6d65 7269 6320 3d20 6d62    x0numeric = mb
+000261f0: 2e63 6173 7428 783d 7830 2c20 6474 7970  .cast(x=x0, dtyp
+00026200: 653d 2266 7033 3222 290a 2020 2020 7361  e="fp32").    sa
+00026210: 6665 5f73 6869 6674 203d 206d 622e 6d75  fe_shift = mb.mu
+00026220: 6c28 783d 7830 6e75 6d65 7269 632c 2079  l(x=x0numeric, y
+00026230: 3d32 652d 3829 0a20 2020 2078 5f73 6166  =2e-8).    x_saf
+00026240: 6520 3d20 6d62 2e61 6464 2878 3d78 2c20  e = mb.add(x=x, 
+00026250: 793d 7361 6665 5f73 6869 6674 290a 0a20  y=safe_shift).. 
+00026260: 2020 2023 2063 6f6d 7075 7465 2061 7461     # compute ata
+00026270: 6e28 7920 2f20 7829 0a20 2020 2079 6478  n(y / x).    ydx
+00026280: 203d 206d 622e 7265 616c 5f64 6976 2878   = mb.real_div(x
+00026290: 3d79 2c20 793d 785f 7361 6665 290a 2020  =y, y=x_safe).  
+000262a0: 2020 6174 616e 325f 3120 3d20 6d62 2e61    atan2_1 = mb.a
+000262b0: 7461 6e28 783d 7964 7829 0a0a 2020 2020  tan(x=ydx)..    
+000262c0: 2320 616e 616c 797a 6520 7175 6164 7261  # analyze quadra
+000262d0: 6e74 0a20 2020 2061 7461 6e32 5f32 203d  nt.    atan2_2 =
+000262e0: 206d 622e 6164 6428 783d 6174 616e 325f   mb.add(x=atan2_
+000262f0: 312c 2079 3d63 6f65 6666 3129 0a20 2020  1, y=coeff1).   
+00026300: 2061 7461 6e32 5f33 203d 206d 622e 7375   atan2_3 = mb.su
+00026310: 6228 783d 6174 616e 325f 322c 2079 3d63  b(x=atan2_2, y=c
+00026320: 6f65 6666 3229 0a20 2020 2061 7461 6e32  oeff2).    atan2
+00026330: 5f34 203d 206d 622e 6d75 6c28 783d 6174  _4 = mb.mul(x=at
+00026340: 616e 325f 332c 2079 3d63 6f65 6666 3329  an2_3, y=coeff3)
+00026350: 0a20 2020 2061 7461 6e32 5f35 203d 206d  .    atan2_5 = m
+00026360: 622e 6164 6428 783d 6174 616e 325f 342c  b.add(x=atan2_4,
+00026370: 2079 3d63 6f65 6666 3429 0a20 2020 2061   y=coeff4).    a
+00026380: 7461 6e32 5f36 203d 206d 622e 6d75 6c28  tan2_6 = mb.mul(
+00026390: 783d 6174 616e 325f 352c 2079 3d63 6f65  x=atan2_5, y=coe
+000263a0: 6666 3529 0a20 2020 2063 6f6e 7465 7874  ff5).    context
+000263b0: 2e61 6464 286d 622e 6164 6428 783d 6174  .add(mb.add(x=at
+000263c0: 616e 325f 362c 2079 3d63 6f65 6666 362c  an2_6, y=coeff6,
+000263d0: 206e 616d 653d 6e6f 6465 2e6e 616d 6529   name=node.name)
+000263e0: 290a 0a0a 4072 6567 6973 7465 725f 746f  )...@register_to
+000263f0: 7263 685f 6f70 0a64 6566 2061 7461 6e68  rch_op.def atanh
+00026400: 2863 6f6e 7465 7874 2c20 6e6f 6465 293a  (context, node):
+00026410: 0a20 2020 2069 6e70 7574 7320 3d20 5f67  .    inputs = _g
+00026420: 6574 5f69 6e70 7574 7328 636f 6e74 6578  et_inputs(contex
+00026430: 742c 206e 6f64 652c 2065 7870 6563 7465  t, node, expecte
+00026440: 643d 3129 0a20 2020 2063 6f6e 7465 7874  d=1).    context
+00026450: 2e61 6464 286d 622e 6174 616e 6828 783d  .add(mb.atanh(x=
+00026460: 696e 7075 7473 5b30 5d2c 206e 616d 653d  inputs[0], name=
+00026470: 6e6f 6465 2e6e 616d 6529 290a 0a0a 4072  node.name))...@r
+00026480: 6567 6973 7465 725f 746f 7263 685f 6f70  egister_torch_op
+00026490: 0a64 6566 2063 6569 6c28 636f 6e74 6578  .def ceil(contex
+000264a0: 742c 206e 6f64 6529 3a0a 2020 2020 696e  t, node):.    in
+000264b0: 7075 7473 203d 205f 6765 745f 696e 7075  puts = _get_inpu
+000264c0: 7473 2863 6f6e 7465 7874 2c20 6e6f 6465  ts(context, node
+000264d0: 2c20 6578 7065 6374 6564 3d31 290a 2020  , expected=1).  
+000264e0: 2020 636f 6e74 6578 742e 6164 6428 6d62    context.add(mb
+000264f0: 2e63 6569 6c28 783d 696e 7075 7473 5b30  .ceil(x=inputs[0
+00026500: 5d2c 206e 616d 653d 6e6f 6465 2e6e 616d  ], name=node.nam
+00026510: 6529 290a 0a0a 4072 6567 6973 7465 725f  e))...@register_
+00026520: 746f 7263 685f 6f70 0a64 6566 2063 6c61  torch_op.def cla
+00026530: 6d70 2863 6f6e 7465 7874 2c20 6e6f 6465  mp(context, node
+00026540: 293a 0a20 2020 2069 6e70 7574 7320 3d20  ):.    inputs = 
+00026550: 5f67 6574 5f69 6e70 7574 7328 636f 6e74  _get_inputs(cont
+00026560: 6578 742c 206e 6f64 652c 2065 7870 6563  ext, node, expec
+00026570: 7465 643d 3329 0a20 2020 2078 203d 2069  ted=3).    x = i
+00026580: 6e70 7574 735b 305d 0a20 2020 206d 696e  nputs[0].    min
+00026590: 5f76 616c 203d 2069 6e70 7574 735b 315d  _val = inputs[1]
+000265a0: 2069 6620 696e 7075 7473 5b31 5d20 656c   if inputs[1] el
+000265b0: 7365 205f 6e70 2e66 696e 666f 285f 6e70  se _np.finfo(_np
+000265c0: 2e66 6c6f 6174 3332 292e 6d69 6e0a 2020  .float32).min.  
+000265d0: 2020 6d61 785f 7661 6c20 3d20 696e 7075    max_val = inpu
+000265e0: 7473 5b32 5d20 6966 2069 6e70 7574 735b  ts[2] if inputs[
+000265f0: 325d 2065 6c73 6520 5f6e 702e 6669 6e66  2] else _np.finf
+00026600: 6f28 5f6e 702e 666c 6f61 7433 3229 2e6d  o(_np.float32).m
+00026610: 6178 0a0a 2020 2020 6966 2069 7369 6e73  ax..    if isins
+00026620: 7461 6e63 6528 6d69 6e5f 7661 6c2c 2056  tance(min_val, V
+00026630: 6172 2920 616e 6420 6973 696e 7374 616e  ar) and isinstan
+00026640: 6365 286d 6178 5f76 616c 2c20 5661 7229  ce(max_val, Var)
+00026650: 2061 6e64 206d 696e 5f76 616c 2e76 616c   and min_val.val
+00026660: 203e 3d20 6d61 785f 7661 6c2e 7661 6c3a   >= max_val.val:
+00026670: 0a20 2020 2020 2020 2023 2057 6865 6e20  .        # When 
+00026680: 6d69 6e20 3e3d 206d 6178 2c20 5079 546f  min >= max, PyTo
+00026690: 7263 6820 7365 7473 2061 6c6c 2076 616c  rch sets all val
+000266a0: 7565 7320 746f 206d 6178 2e0a 2020 2020  ues to max..    
+000266b0: 2020 2020 636f 6e74 6578 742e 6164 6428      context.add(
+000266c0: 6d62 2e66 696c 6c28 7368 6170 653d 6d62  mb.fill(shape=mb
+000266d0: 2e73 6861 7065 2878 3d78 292c 2076 616c  .shape(x=x), val
+000266e0: 7565 3d6d 6178 5f76 616c 2e76 616c 2c20  ue=max_val.val, 
+000266f0: 6e61 6d65 3d6e 6f64 652e 6e61 6d65 2929  name=node.name))
+00026700: 0a20 2020 2020 2020 2072 6574 7572 6e0a  .        return.
+00026710: 0a20 2020 2069 735f 696e 7075 745f 696e  .    is_input_in
+00026720: 7420 3d20 7479 7065 732e 6973 5f69 6e74  t = types.is_int
+00026730: 2878 2e64 7479 7065 290a 2020 2020 6966  (x.dtype).    if
+00026740: 206e 6f74 2074 7970 6573 2e69 735f 666c   not types.is_fl
+00026750: 6f61 7428 782e 6474 7970 6529 3a0a 2020  oat(x.dtype):.  
+00026760: 2020 2020 2020 2320 5468 6520 606d 622e        # The `mb.
+00026770: 636c 6970 6020 6f70 2072 6571 7569 7265  clip` op require
+00026780: 7320 7061 7261 6d65 7465 7273 2066 726f  s parameters fro
+00026790: 6d20 7479 7065 2064 6f6d 6169 6e20 5b27  m type domain ['
+000267a0: 6670 3136 272c 2027 6670 3332 275d 2e0a  fp16', 'fp32']..
+000267b0: 2020 2020 2020 2020 7820 3d20 6d62 2e63          x = mb.c
+000267c0: 6173 7428 783d 782c 2064 7479 7065 3d22  ast(x=x, dtype="
+000267d0: 6670 3332 2229 0a20 2020 2078 2c20 6d69  fp32").    x, mi
+000267e0: 6e5f 7661 6c2c 206d 6178 5f76 616c 203d  n_val, max_val =
+000267f0: 2070 726f 6d6f 7465 5f69 6e70 7574 5f64   promote_input_d
+00026800: 7479 7065 7328 5b78 2c20 6d69 6e5f 7661  types([x, min_va
+00026810: 6c2c 206d 6178 5f76 616c 5d29 0a20 2020  l, max_val]).   
+00026820: 2069 6620 6973 5f69 6e70 7574 5f69 6e74   if is_input_int
+00026830: 3a0a 2020 2020 2020 2020 636c 6970 5f72  :.        clip_r
+00026840: 6573 203d 206d 622e 636c 6970 2878 3d78  es = mb.clip(x=x
+00026850: 2c20 616c 7068 613d 6d69 6e5f 7661 6c2c  , alpha=min_val,
+00026860: 2062 6574 613d 6d61 785f 7661 6c29 0a20   beta=max_val). 
+00026870: 2020 2020 2020 2063 6f6e 7465 7874 2e61         context.a
+00026880: 6464 286d 622e 6361 7374 2878 3d63 6c69  dd(mb.cast(x=cli
+00026890: 705f 7265 732c 2064 7479 7065 3d22 696e  p_res, dtype="in
+000268a0: 7433 3222 2c20 6e61 6d65 3d6e 6f64 652e  t32", name=node.
+000268b0: 6e61 6d65 2929 0a20 2020 2065 6c73 653a  name)).    else:
+000268c0: 0a20 2020 2020 2020 2063 6f6e 7465 7874  .        context
+000268d0: 2e61 6464 286d 622e 636c 6970 2878 3d78  .add(mb.clip(x=x
+000268e0: 2c20 616c 7068 613d 6d69 6e5f 7661 6c2c  , alpha=min_val,
+000268f0: 2062 6574 613d 6d61 785f 7661 6c2c 206e   beta=max_val, n
+00026900: 616d 653d 6e6f 6465 2e6e 616d 6529 290a  ame=node.name)).
+00026910: 0a0a 4072 6567 6973 7465 725f 746f 7263  ..@register_torc
+00026920: 685f 6f70 0a64 6566 2074 7269 7528 636f  h_op.def triu(co
+00026930: 6e74 6578 742c 206e 6f64 6529 3a0a 2020  ntext, node):.  
+00026940: 2020 696e 7075 7473 203d 205f 6765 745f    inputs = _get_
+00026950: 696e 7075 7473 2863 6f6e 7465 7874 2c20  inputs(context, 
+00026960: 6e6f 6465 2c20 6578 7065 6374 6564 3d32  node, expected=2
+00026970: 290a 2020 2020 7820 3d20 696e 7075 7473  ).    x = inputs
+00026980: 5b30 5d0a 2020 2020 6469 6167 6f6e 616c  [0].    diagonal
+00026990: 203d 2069 6e70 7574 735b 315d 0a20 2020   = inputs[1].   
+000269a0: 2064 6961 676f 6e61 6c20 3d20 3020 6966   diagonal = 0 if
+000269b0: 2064 6961 676f 6e61 6c20 6973 204e 6f6e   diagonal is Non
+000269c0: 6520 656c 7365 2064 6961 676f 6e61 6c2e  e else diagonal.
+000269d0: 7661 6c0a 2020 2020 6966 2064 6961 676f  val.    if diago
+000269e0: 6e61 6c20 3c3d 2030 3a0a 2020 2020 2020  nal <= 0:.      
+000269f0: 2020 7265 7320 3d20 6d62 2e62 616e 645f    res = mb.band_
+00026a00: 7061 7274 2878 3d78 2c20 6c6f 7765 723d  part(x=x, lower=
+00026a10: 2d64 6961 676f 6e61 6c2c 2075 7070 6572  -diagonal, upper
+00026a20: 3d2d 312c 206e 616d 653d 6e6f 6465 2e6e  =-1, name=node.n
+00026a30: 616d 6529 0a20 2020 2065 6c73 653a 0a20  ame).    else:. 
+00026a40: 2020 2020 2020 2079 203d 206d 622e 6261         y = mb.ba
+00026a50: 6e64 5f70 6172 7428 783d 782c 206c 6f77  nd_part(x=x, low
+00026a60: 6572 3d2d 312c 2075 7070 6572 3d64 6961  er=-1, upper=dia
+00026a70: 676f 6e61 6c20 2d20 3129 0a20 2020 2020  gonal - 1).     
+00026a80: 2020 2072 6573 203d 206d 622e 7375 6228     res = mb.sub(
+00026a90: 783d 782c 2079 3d79 2c20 6e61 6d65 3d6e  x=x, y=y, name=n
+00026aa0: 6f64 652e 6e61 6d65 290a 2020 2020 636f  ode.name).    co
+00026ab0: 6e74 6578 742e 6164 6428 7265 7329 0a0a  ntext.add(res)..
+00026ac0: 0a40 7265 6769 7374 6572 5f74 6f72 6368  .@register_torch
+00026ad0: 5f6f 700a 6465 6620 7472 696c 2863 6f6e  _op.def tril(con
+00026ae0: 7465 7874 2c20 6e6f 6465 293a 0a20 2020  text, node):.   
+00026af0: 2069 6e70 7574 7320 3d20 5f67 6574 5f69   inputs = _get_i
+00026b00: 6e70 7574 7328 636f 6e74 6578 742c 206e  nputs(context, n
+00026b10: 6f64 652c 2065 7870 6563 7465 643d 3229  ode, expected=2)
+00026b20: 0a20 2020 2078 203d 2069 6e70 7574 735b  .    x = inputs[
+00026b30: 305d 0a20 2020 2064 6961 676f 6e61 6c20  0].    diagonal 
+00026b40: 3d20 696e 7075 7473 5b31 5d0a 2020 2020  = inputs[1].    
+00026b50: 6469 6167 6f6e 616c 203d 2030 2069 6620  diagonal = 0 if 
+00026b60: 6469 6167 6f6e 616c 2069 7320 4e6f 6e65  diagonal is None
+00026b70: 2065 6c73 6520 6469 6167 6f6e 616c 2e76   else diagonal.v
+00026b80: 616c 0a20 2020 2069 6620 6469 6167 6f6e  al.    if diagon
+00026b90: 616c 203e 3d20 303a 0a20 2020 2020 2020  al >= 0:.       
+00026ba0: 2072 6573 203d 206d 622e 6261 6e64 5f70   res = mb.band_p
+00026bb0: 6172 7428 783d 782c 206c 6f77 6572 3d2d  art(x=x, lower=-
+00026bc0: 312c 2075 7070 6572 3d64 6961 676f 6e61  1, upper=diagona
+00026bd0: 6c2c 206e 616d 653d 6e6f 6465 2e6e 616d  l, name=node.nam
+00026be0: 6529 0a20 2020 2065 6c73 653a 0a20 2020  e).    else:.   
+00026bf0: 2020 2020 2079 203d 206d 622e 6261 6e64       y = mb.band
+00026c00: 5f70 6172 7428 783d 782c 206c 6f77 6572  _part(x=x, lower
+00026c10: 3d2d 6469 6167 6f6e 616c 202d 2031 2c20  =-diagonal - 1, 
+00026c20: 7570 7065 723d 2d31 290a 2020 2020 2020  upper=-1).      
+00026c30: 2020 7265 7320 3d20 6d62 2e73 7562 2878    res = mb.sub(x
+00026c40: 3d78 2c20 793d 792c 206e 616d 653d 6e6f  =x, y=y, name=no
+00026c50: 6465 2e6e 616d 6529 0a20 2020 2063 6f6e  de.name).    con
+00026c60: 7465 7874 2e61 6464 2872 6573 290a 0a0a  text.add(res)...
+00026c70: 4072 6567 6973 7465 725f 746f 7263 685f  @register_torch_
+00026c80: 6f70 0a64 6566 2063 6f73 2863 6f6e 7465  op.def cos(conte
+00026c90: 7874 2c20 6e6f 6465 293a 0a20 2020 2069  xt, node):.    i
+00026ca0: 6e70 7574 7320 3d20 5f67 6574 5f69 6e70  nputs = _get_inp
+00026cb0: 7574 7328 636f 6e74 6578 742c 206e 6f64  uts(context, nod
+00026cc0: 652c 2065 7870 6563 7465 643d 3129 0a20  e, expected=1). 
+00026cd0: 2020 2063 6f6e 7465 7874 2e61 6464 286d     context.add(m
+00026ce0: 622e 636f 7328 783d 696e 7075 7473 5b30  b.cos(x=inputs[0
+00026cf0: 5d2c 206e 616d 653d 6e6f 6465 2e6e 616d  ], name=node.nam
+00026d00: 6529 290a 0a0a 4072 6567 6973 7465 725f  e))...@register_
+00026d10: 746f 7263 685f 6f70 0a64 6566 2063 6f73  torch_op.def cos
+00026d20: 6828 636f 6e74 6578 742c 206e 6f64 6529  h(context, node)
+00026d30: 3a0a 2020 2020 696e 7075 7473 203d 205f  :.    inputs = _
+00026d40: 6765 745f 696e 7075 7473 2863 6f6e 7465  get_inputs(conte
+00026d50: 7874 2c20 6e6f 6465 2c20 6578 7065 6374  xt, node, expect
+00026d60: 6564 3d31 290a 2020 2020 636f 6e74 6578  ed=1).    contex
+00026d70: 742e 6164 6428 6d62 2e63 6f73 6828 783d  t.add(mb.cosh(x=
+00026d80: 696e 7075 7473 5b30 5d2c 206e 616d 653d  inputs[0], name=
+00026d90: 6e6f 6465 2e6e 616d 6529 290a 0a0a 4072  node.name))...@r
+00026da0: 6567 6973 7465 725f 746f 7263 685f 6f70  egister_torch_op
+00026db0: 0a64 6566 2065 7870 2863 6f6e 7465 7874  .def exp(context
+00026dc0: 2c20 6e6f 6465 293a 0a20 2020 2069 6e70  , node):.    inp
+00026dd0: 7574 7320 3d20 5f67 6574 5f69 6e70 7574  uts = _get_input
+00026de0: 7328 636f 6e74 6578 742c 206e 6f64 652c  s(context, node,
+00026df0: 2065 7870 6563 7465 643d 3129 0a20 2020   expected=1).   
+00026e00: 2063 6f6e 7465 7874 2e61 6464 286d 622e   context.add(mb.
+00026e10: 6578 7028 783d 696e 7075 7473 5b30 5d2c  exp(x=inputs[0],
+00026e20: 206e 616d 653d 6e6f 6465 2e6e 616d 6529   name=node.name)
+00026e30: 290a 0a0a 4072 6567 6973 7465 725f 746f  )...@register_to
+00026e40: 7263 685f 6f70 0a64 6566 2065 7870 3228  rch_op.def exp2(
+00026e50: 636f 6e74 6578 742c 206e 6f64 6529 3a0a  context, node):.
+00026e60: 2020 2020 696e 7075 7473 203d 205f 6765      inputs = _ge
+00026e70: 745f 696e 7075 7473 2863 6f6e 7465 7874  t_inputs(context
+00026e80: 2c20 6e6f 6465 2c20 6578 7065 6374 6564  , node, expected
+00026e90: 3d31 290a 2020 2020 636f 6e74 6578 742e  =1).    context.
+00026ea0: 6164 6428 6d62 2e65 7870 3228 783d 696e  add(mb.exp2(x=in
+00026eb0: 7075 7473 5b30 5d2c 206e 616d 653d 6e6f  puts[0], name=no
+00026ec0: 6465 2e6e 616d 6529 290a 0a0a 4072 6567  de.name))...@reg
+00026ed0: 6973 7465 725f 746f 7263 685f 6f70 0a64  ister_torch_op.d
+00026ee0: 6566 2066 6c6f 6f72 2863 6f6e 7465 7874  ef floor(context
+00026ef0: 2c20 6e6f 6465 293a 0a20 2020 2069 6e70  , node):.    inp
+00026f00: 7574 7320 3d20 5f67 6574 5f69 6e70 7574  uts = _get_input
+00026f10: 7328 636f 6e74 6578 742c 206e 6f64 652c  s(context, node,
+00026f20: 2065 7870 6563 7465 643d 3129 0a20 2020   expected=1).   
+00026f30: 2063 6f6e 7465 7874 2e61 6464 286d 622e   context.add(mb.
+00026f40: 666c 6f6f 7228 783d 696e 7075 7473 5b30  floor(x=inputs[0
+00026f50: 5d2c 206e 616d 653d 6e6f 6465 2e6e 616d  ], name=node.nam
+00026f60: 6529 290a 0a0a 4072 6567 6973 7465 725f  e))...@register_
+00026f70: 746f 7263 685f 6f70 0a64 6566 2072 6563  torch_op.def rec
+00026f80: 6970 726f 6361 6c28 636f 6e74 6578 742c  iprocal(context,
+00026f90: 206e 6f64 6529 3a0a 2020 2020 696e 7075   node):.    inpu
+00026fa0: 7473 203d 205f 6765 745f 696e 7075 7473  ts = _get_inputs
+00026fb0: 2863 6f6e 7465 7874 2c20 6e6f 6465 2c20  (context, node, 
+00026fc0: 6578 7065 6374 6564 3d31 290a 2020 2020  expected=1).    
+00026fd0: 636f 6e74 6578 742e 6164 6428 6d62 2e69  context.add(mb.i
+00026fe0: 6e76 6572 7365 2878 3d69 6e70 7574 735b  nverse(x=inputs[
+00026ff0: 305d 2c20 6e61 6d65 3d6e 6f64 652e 6e61  0], name=node.na
+00027000: 6d65 2929 0a0a 0a40 7265 6769 7374 6572  me))...@register
+00027010: 5f74 6f72 6368 5f6f 700a 6465 6620 6c6f  _torch_op.def lo
+00027020: 6728 636f 6e74 6578 742c 206e 6f64 6529  g(context, node)
+00027030: 3a0a 2020 2020 696e 7075 7473 203d 205f  :.    inputs = _
+00027040: 6765 745f 696e 7075 7473 2863 6f6e 7465  get_inputs(conte
+00027050: 7874 2c20 6e6f 6465 2c20 6578 7065 6374  xt, node, expect
+00027060: 6564 3d31 290a 2020 2020 636f 6e74 6578  ed=1).    contex
+00027070: 742e 6164 6428 6d62 2e6c 6f67 2878 3d69  t.add(mb.log(x=i
+00027080: 6e70 7574 735b 305d 2c20 6e61 6d65 3d6e  nputs[0], name=n
+00027090: 6f64 652e 6e61 6d65 2929 0a0a 0a40 7265  ode.name))...@re
+000270a0: 6769 7374 6572 5f74 6f72 6368 5f6f 7028  gister_torch_op(
+000270b0: 746f 7263 685f 616c 6961 733d 5b22 726f  torch_alias=["ro
+000270c0: 756e 6422 5d29 0a64 6566 205f 726f 756e  und"]).def _roun
+000270d0: 6428 636f 6e74 6578 742c 206e 6f64 6529  d(context, node)
+000270e0: 3a0a 2020 2020 696e 7075 7473 203d 205f  :.    inputs = _
+000270f0: 6765 745f 696e 7075 7473 2863 6f6e 7465  get_inputs(conte
+00027100: 7874 2c20 6e6f 6465 2c20 6578 7065 6374  xt, node, expect
+00027110: 6564 3d31 290a 2020 2020 636f 6e74 6578  ed=1).    contex
+00027120: 742e 6164 6428 6d62 2e72 6f75 6e64 2878  t.add(mb.round(x
+00027130: 3d69 6e70 7574 735b 305d 2c20 6e61 6d65  =inputs[0], name
+00027140: 3d6e 6f64 652e 6e61 6d65 2929 0a0a 0a40  =node.name))...@
+00027150: 7265 6769 7374 6572 5f74 6f72 6368 5f6f  register_torch_o
+00027160: 700a 6465 6620 7273 7172 7428 636f 6e74  p.def rsqrt(cont
+00027170: 6578 742c 206e 6f64 6529 3a0a 2020 2020  ext, node):.    
+00027180: 696e 7075 7473 203d 205f 6765 745f 696e  inputs = _get_in
+00027190: 7075 7473 2863 6f6e 7465 7874 2c20 6e6f  puts(context, no
+000271a0: 6465 2c20 6578 7065 6374 6564 3d31 290a  de, expected=1).
+000271b0: 2020 2020 636f 6e74 6578 742e 6164 6428      context.add(
+000271c0: 6d62 2e72 7371 7274 2878 3d69 6e70 7574  mb.rsqrt(x=input
+000271d0: 735b 305d 2c20 6e61 6d65 3d6e 6f64 652e  s[0], name=node.
+000271e0: 6e61 6d65 2929 0a0a 0a40 7265 6769 7374  name))...@regist
+000271f0: 6572 5f74 6f72 6368 5f6f 700a 6465 6620  er_torch_op.def 
+00027200: 7369 6e28 636f 6e74 6578 742c 206e 6f64  sin(context, nod
+00027210: 6529 3a0a 2020 2020 696e 7075 7473 203d  e):.    inputs =
+00027220: 205f 6765 745f 696e 7075 7473 2863 6f6e   _get_inputs(con
+00027230: 7465 7874 2c20 6e6f 6465 2c20 6578 7065  text, node, expe
+00027240: 6374 6564 3d31 290a 2020 2020 636f 6e74  cted=1).    cont
+00027250: 6578 742e 6164 6428 6d62 2e73 696e 2878  ext.add(mb.sin(x
+00027260: 3d69 6e70 7574 735b 305d 2c20 6e61 6d65  =inputs[0], name
+00027270: 3d6e 6f64 652e 6e61 6d65 2929 0a0a 0a40  =node.name))...@
+00027280: 7265 6769 7374 6572 5f74 6f72 6368 5f6f  register_torch_o
+00027290: 700a 6465 6620 7369 6e68 2863 6f6e 7465  p.def sinh(conte
+000272a0: 7874 2c20 6e6f 6465 293a 0a20 2020 2069  xt, node):.    i
+000272b0: 6e70 7574 7320 3d20 5f67 6574 5f69 6e70  nputs = _get_inp
+000272c0: 7574 7328 636f 6e74 6578 742c 206e 6f64  uts(context, nod
+000272d0: 652c 2065 7870 6563 7465 643d 3129 0a20  e, expected=1). 
+000272e0: 2020 2063 6f6e 7465 7874 2e61 6464 286d     context.add(m
+000272f0: 622e 7369 6e68 2878 3d69 6e70 7574 735b  b.sinh(x=inputs[
+00027300: 305d 2c20 6e61 6d65 3d6e 6f64 652e 6e61  0], name=node.na
+00027310: 6d65 2929 0a0a 0a40 7265 6769 7374 6572  me))...@register
+00027320: 5f74 6f72 6368 5f6f 700a 6465 6620 6173  _torch_op.def as
+00027330: 696e 6828 636f 6e74 6578 742c 206e 6f64  inh(context, nod
+00027340: 6529 3a0a 2020 2020 696e 7075 7473 203d  e):.    inputs =
+00027350: 205f 6765 745f 696e 7075 7473 2863 6f6e   _get_inputs(con
+00027360: 7465 7874 2c20 6e6f 6465 2c20 6578 7065  text, node, expe
+00027370: 6374 6564 3d31 290a 2020 2020 636f 6e74  cted=1).    cont
+00027380: 6578 742e 6164 6428 6d62 2e61 7369 6e68  ext.add(mb.asinh
+00027390: 2878 3d69 6e70 7574 735b 305d 2c20 6e61  (x=inputs[0], na
+000273a0: 6d65 3d6e 6f64 652e 6e61 6d65 2929 0a0a  me=node.name))..
+000273b0: 0a40 7265 6769 7374 6572 5f74 6f72 6368  .@register_torch
+000273c0: 5f6f 700a 6465 6620 7371 7274 2863 6f6e  _op.def sqrt(con
+000273d0: 7465 7874 2c20 6e6f 6465 293a 0a20 2020  text, node):.   
+000273e0: 2069 6e70 7574 7320 3d20 5f67 6574 5f69   inputs = _get_i
+000273f0: 6e70 7574 7328 636f 6e74 6578 742c 206e  nputs(context, n
+00027400: 6f64 652c 2065 7870 6563 7465 643d 3129  ode, expected=1)
+00027410: 0a20 2020 2063 6f6e 7465 7874 2e61 6464  .    context.add
+00027420: 286d 622e 7371 7274 2878 3d69 6e70 7574  (mb.sqrt(x=input
+00027430: 735b 305d 2c20 6e61 6d65 3d6e 6f64 652e  s[0], name=node.
+00027440: 6e61 6d65 2929 0a0a 0a40 7265 6769 7374  name))...@regist
+00027450: 6572 5f74 6f72 6368 5f6f 700a 6465 6620  er_torch_op.def 
+00027460: 7371 7561 7265 2863 6f6e 7465 7874 2c20  square(context, 
+00027470: 6e6f 6465 293a 0a20 2020 2069 6e70 7574  node):.    input
+00027480: 7320 3d20 5f67 6574 5f69 6e70 7574 7328  s = _get_inputs(
+00027490: 636f 6e74 6578 742c 206e 6f64 652c 2065  context, node, e
+000274a0: 7870 6563 7465 643d 3129 0a20 2020 2023  xpected=1).    #
+000274b0: 206d 622e 7371 7561 7265 2069 7320 6e6f   mb.square is no
+000274c0: 7420 7375 7070 6f72 7465 6420 696e 2073  t supported in s
+000274d0: 6f6d 6520 6261 636b 656e 640a 2020 2020  ome backend.    
+000274e0: 636f 6e74 6578 742e 6164 6428 6d62 2e6d  context.add(mb.m
+000274f0: 756c 2878 3d69 6e70 7574 735b 305d 2c20  ul(x=inputs[0], 
+00027500: 793d 696e 7075 7473 5b30 5d2c 206e 616d  y=inputs[0], nam
+00027510: 653d 6e6f 6465 2e6e 616d 6529 290a 0a0a  e=node.name))...
+00027520: 4072 6567 6973 7465 725f 746f 7263 685f  @register_torch_
+00027530: 6f70 0a64 6566 2074 616e 2863 6f6e 7465  op.def tan(conte
+00027540: 7874 2c20 6e6f 6465 293a 0a20 2020 2069  xt, node):.    i
+00027550: 6e70 7574 7320 3d20 5f67 6574 5f69 6e70  nputs = _get_inp
+00027560: 7574 7328 636f 6e74 6578 742c 206e 6f64  uts(context, nod
+00027570: 652c 2065 7870 6563 7465 643d 3129 0a20  e, expected=1). 
+00027580: 2020 2063 6f6e 7465 7874 2e61 6464 286d     context.add(m
+00027590: 622e 7461 6e28 783d 696e 7075 7473 5b30  b.tan(x=inputs[0
+000275a0: 5d2c 206e 616d 653d 6e6f 6465 2e6e 616d  ], name=node.nam
+000275b0: 6529 290a 0a0a 4072 6567 6973 7465 725f  e))...@register_
+000275c0: 746f 7263 685f 6f70 0a64 6566 2074 616e  torch_op.def tan
+000275d0: 6828 636f 6e74 6578 742c 206e 6f64 6529  h(context, node)
+000275e0: 3a0a 2020 2020 696e 7075 7473 203d 205f  :.    inputs = _
+000275f0: 6765 745f 696e 7075 7473 2863 6f6e 7465  get_inputs(conte
+00027600: 7874 2c20 6e6f 6465 2c20 6578 7065 6374  xt, node, expect
+00027610: 6564 3d31 290a 2020 2020 636f 6e74 6578  ed=1).    contex
+00027620: 742e 6164 6428 6d62 2e74 616e 6828 783d  t.add(mb.tanh(x=
+00027630: 696e 7075 7473 5b30 5d2c 206e 616d 653d  inputs[0], name=
+00027640: 6e6f 6465 2e6e 616d 6529 290a 0a0a 4072  node.name))...@r
+00027650: 6567 6973 7465 725f 746f 7263 685f 6f70  egister_torch_op
+00027660: 0a64 6566 2074 6872 6573 686f 6c64 2863  .def threshold(c
+00027670: 6f6e 7465 7874 2c20 6e6f 6465 293a 0a20  ontext, node):. 
+00027680: 2020 2069 6e70 7574 7320 3d20 5f67 6574     inputs = _get
+00027690: 5f69 6e70 7574 7328 636f 6e74 6578 742c  _inputs(context,
+000276a0: 206e 6f64 652c 2065 7870 6563 7465 643d   node, expected=
+000276b0: 3329 0a20 2020 2078 203d 2069 6e70 7574  3).    x = input
+000276c0: 735b 305d 0a20 2020 2061 6c70 6861 203d  s[0].    alpha =
+000276d0: 2069 6e70 7574 735b 315d 0a20 2020 2074   inputs[1].    t
+000276e0: 6872 6573 686f 6c64 5f76 616c 203d 2069  hreshold_val = i
+000276f0: 6e70 7574 735b 325d 0a0a 2020 2020 2320  nputs[2]..    # 
+00027700: 5369 6d70 6c65 2063 6173 6520 2874 6872  Simple case (thr
+00027710: 6573 686f 6c64 5f76 616c 203d 3d20 616c  eshold_val == al
+00027720: 7068 6129 0a20 2020 2069 6620 616c 7068  pha).    if alph
+00027730: 612e 7661 6c20 3d3d 2074 6872 6573 686f  a.val == thresho
+00027740: 6c64 5f76 616c 2e76 616c 3a0a 2020 2020  ld_val.val:.    
+00027750: 2020 2020 7468 7265 7368 6f6c 645f 6e6f      threshold_no
+00027760: 6465 203d 206d 622e 7468 7265 7368 6f6c  de = mb.threshol
+00027770: 6428 783d 782c 2061 6c70 6861 3d61 6c70  d(x=x, alpha=alp
+00027780: 6861 2c20 6e61 6d65 3d6e 6f64 652e 6e61  ha, name=node.na
+00027790: 6d65 290a 2020 2020 2020 2020 636f 6e74  me).        cont
+000277a0: 6578 742e 6164 6428 7468 7265 7368 6f6c  ext.add(threshol
+000277b0: 645f 6e6f 6465 290a 2020 2020 2020 2020  d_node).        
+000277c0: 7265 7475 726e 0a0a 2020 2020 2320 436f  return..    # Co
+000277d0: 6d70 6c65 7820 6361 7365 2028 7468 7265  mplex case (thre
+000277e0: 7368 6f6c 645f 7661 6c20 213d 2074 6872  shold_val != thr
+000277f0: 6573 686f 6c64 290a 2020 2020 7468 7265  eshold).    thre
+00027800: 7368 6f6c 645f 6e6f 6465 203d 206d 622e  shold_node = mb.
+00027810: 7468 7265 7368 6f6c 6428 783d 782c 2061  threshold(x=x, a
+00027820: 6c70 6861 3d61 6c70 6861 2c20 6e61 6d65  lpha=alpha, name
+00027830: 3d6e 6f64 652e 6e61 6d65 202b 2027 5f74  =node.name + '_t
+00027840: 6872 6573 686f 6c64 2729 0a20 2020 2063  hreshold').    c
+00027850: 6f6e 7465 7874 2e61 6464 2874 6872 6573  ontext.add(thres
+00027860: 686f 6c64 5f6e 6f64 6529 0a0a 2020 2020  hold_node)..    
+00027870: 6774 5f6e 6f64 6520 3d20 6d62 2e67 7265  gt_node = mb.gre
+00027880: 6174 6572 5f65 7175 616c 2878 3d61 6c70  ater_equal(x=alp
+00027890: 6861 2c20 793d 782c 206e 616d 653d 6e6f  ha, y=x, name=no
+000278a0: 6465 2e6e 616d 6520 2b20 275f 6765 2729  de.name + '_ge')
+000278b0: 0a20 2020 2063 6f6e 7465 7874 2e61 6464  .    context.add
+000278c0: 2867 745f 6e6f 6465 290a 2020 2020 6774  (gt_node).    gt
+000278d0: 5f6e 6f64 655f 3332 203d 206d 622e 6361  _node_32 = mb.ca
+000278e0: 7374 2878 3d67 745f 6e6f 6465 2c20 6474  st(x=gt_node, dt
+000278f0: 7970 653d 2266 7033 3222 2c20 6e61 6d65  ype="fp32", name
+00027900: 3d6e 6f64 652e 6e61 6d65 202b 2027 5f67  =node.name + '_g
+00027910: 6533 3227 290a 0a20 2020 206d 756c 5f6e  e32')..    mul_n
+00027920: 6f64 6520 3d20 6d62 2e6c 696e 6561 725f  ode = mb.linear_
+00027930: 6163 7469 7661 7469 6f6e 280a 2020 2020  activation(.    
+00027940: 2020 2020 783d 6774 5f6e 6f64 655f 3332      x=gt_node_32
+00027950: 2c0a 2020 2020 2020 2020 616c 7068 613d  ,.        alpha=
+00027960: 666c 6f61 7428 7468 7265 7368 6f6c 645f  float(threshold_
+00027970: 7661 6c2e 7661 6c20 2d20 616c 7068 612e  val.val - alpha.
+00027980: 7661 6c29 2c0a 2020 2020 2020 2020 6265  val),.        be
+00027990: 7461 3d30 2e2c 0a20 2020 2020 2020 206e  ta=0.,.        n
+000279a0: 616d 653d 6e6f 6465 2e6e 616d 6520 2b20  ame=node.name + 
+000279b0: 275f 6d75 6c27 0a20 2020 2029 0a20 2020  '_mul'.    ).   
+000279c0: 2063 6f6e 7465 7874 2e61 6464 286d 756c   context.add(mul
+000279d0: 5f6e 6f64 6529 0a0a 2020 2020 6669 6e61  _node)..    fina
+000279e0: 6c5f 6e6f 6465 203d 206d 622e 6164 6428  l_node = mb.add(
+000279f0: 783d 6d75 6c5f 6e6f 6465 2c20 793d 7468  x=mul_node, y=th
+00027a00: 7265 7368 6f6c 645f 6e6f 6465 2c20 6e61  reshold_node, na
+00027a10: 6d65 3d6e 6f64 652e 6e61 6d65 290a 2020  me=node.name).  
+00027a20: 2020 636f 6e74 6578 742e 6164 6428 6669    context.add(fi
+00027a30: 6e61 6c5f 6e6f 6465 290a 0a0a 4072 6567  nal_node)...@reg
+00027a40: 6973 7465 725f 746f 7263 685f 6f70 0a64  ister_torch_op.d
+00027a50: 6566 2073 6967 6e28 636f 6e74 6578 742c  ef sign(context,
+00027a60: 206e 6f64 6529 3a0a 2020 2020 696e 7075   node):.    inpu
+00027a70: 7473 203d 205f 6765 745f 696e 7075 7473  ts = _get_inputs
+00027a80: 2863 6f6e 7465 7874 2c20 6e6f 6465 2c20  (context, node, 
+00027a90: 6578 7065 6374 6564 3d31 290a 2020 2020  expected=1).    
+00027aa0: 636f 6e74 6578 742e 6164 6428 6d62 2e73  context.add(mb.s
+00027ab0: 6967 6e28 783d 696e 7075 7473 5b30 5d2c  ign(x=inputs[0],
+00027ac0: 206e 616d 653d 6e6f 6465 2e6e 616d 6529   name=node.name)
+00027ad0: 290a 0a0a 4072 6567 6973 7465 725f 746f  )...@register_to
+00027ae0: 7263 685f 6f70 0a64 6566 2069 735f 666c  rch_op.def is_fl
+00027af0: 6f61 7469 6e67 5f70 6f69 6e74 2863 6f6e  oating_point(con
+00027b00: 7465 7874 2c20 6e6f 6465 293a 0a20 2020  text, node):.   
+00027b10: 2069 6e70 7574 7320 3d20 5f67 6574 5f69   inputs = _get_i
+00027b20: 6e70 7574 7328 636f 6e74 6578 742c 206e  nputs(context, n
+00027b30: 6f64 652c 2065 7870 6563 7465 643d 3129  ode, expected=1)
+00027b40: 0a20 2020 2069 735f 666c 6f61 7420 3d20  .    is_float = 
+00027b50: 7479 7065 732e 6973 5f66 6c6f 6174 2869  types.is_float(i
+00027b60: 6e70 7574 735b 305d 2e64 7479 7065 290a  nputs[0].dtype).
+00027b70: 2020 2020 636f 6e74 6578 742e 6164 6428      context.add(
+00027b80: 6d62 2e63 6f6e 7374 2876 616c 3d69 735f  mb.const(val=is_
+00027b90: 666c 6f61 742c 206e 616d 653d 6e6f 6465  float, name=node
+00027ba0: 2e6e 616d 6529 290a 0a0a 4072 6567 6973  .name))...@regis
+00027bb0: 7465 725f 746f 7263 685f 6f70 0a64 6566  ter_torch_op.def
+00027bc0: 206c 6f67 6963 616c 5f61 6e64 2863 6f6e   logical_and(con
+00027bd0: 7465 7874 2c20 6e6f 6465 293a 0a20 2020  text, node):.   
+00027be0: 2069 6e70 7574 7320 3d20 5f67 6574 5f69   inputs = _get_i
+00027bf0: 6e70 7574 7328 636f 6e74 6578 742c 206e  nputs(context, n
+00027c00: 6f64 652c 2065 7870 6563 7465 643d 3229  ode, expected=2)
+00027c10: 0a20 2020 2078 2c20 7920 3d20 696e 7075  .    x, y = inpu
+00027c20: 7473 0a20 2020 2078 203d 206d 622e 6361  ts.    x = mb.ca
+00027c30: 7374 2878 3d78 2c20 6474 7970 653d 2262  st(x=x, dtype="b
+00027c40: 6f6f 6c22 290a 2020 2020 7920 3d20 6d62  ool").    y = mb
+00027c50: 2e63 6173 7428 783d 792c 2064 7479 7065  .cast(x=y, dtype
+00027c60: 3d22 626f 6f6c 2229 0a20 2020 2063 6f6e  ="bool").    con
+00027c70: 7465 7874 2e61 6464 286d 622e 6c6f 6769  text.add(mb.logi
+00027c80: 6361 6c5f 616e 6428 783d 782c 2079 3d79  cal_and(x=x, y=y
+00027c90: 2c20 6e61 6d65 3d6e 6f64 652e 6e61 6d65  , name=node.name
+00027ca0: 2929 0a0a 4072 6567 6973 7465 725f 746f  ))..@register_to
+00027cb0: 7263 685f 6f70 0a64 6566 206c 6f67 6963  rch_op.def logic
+00027cc0: 616c 5f6f 7228 636f 6e74 6578 742c 206e  al_or(context, n
+00027cd0: 6f64 6529 3a0a 2020 2020 696e 7075 7473  ode):.    inputs
+00027ce0: 203d 205f 6765 745f 696e 7075 7473 2863   = _get_inputs(c
+00027cf0: 6f6e 7465 7874 2c20 6e6f 6465 2c20 6578  ontext, node, ex
+00027d00: 7065 6374 6564 3d32 290a 2020 2020 782c  pected=2).    x,
+00027d10: 2079 203d 2069 6e70 7574 730a 2020 2020   y = inputs.    
+00027d20: 7820 3d20 6d62 2e63 6173 7428 783d 782c  x = mb.cast(x=x,
+00027d30: 2064 7479 7065 3d22 626f 6f6c 2229 0a20   dtype="bool"). 
+00027d40: 2020 2079 203d 206d 622e 6361 7374 2878     y = mb.cast(x
+00027d50: 3d79 2c20 6474 7970 653d 2262 6f6f 6c22  =y, dtype="bool"
+00027d60: 290a 2020 2020 636f 6e74 6578 742e 6164  ).    context.ad
+00027d70: 6428 6d62 2e6c 6f67 6963 616c 5f6f 7228  d(mb.logical_or(
+00027d80: 783d 782c 2079 3d79 2c20 6e61 6d65 3d6e  x=x, y=y, name=n
+00027d90: 6f64 652e 6e61 6d65 2929 0a0a 0a40 7265  ode.name))...@re
+00027da0: 6769 7374 6572 5f74 6f72 6368 5f6f 700a  gister_torch_op.
+00027db0: 6465 6620 6c6f 6769 6361 6c5f 786f 7228  def logical_xor(
+00027dc0: 636f 6e74 6578 742c 206e 6f64 6529 3a0a  context, node):.
+00027dd0: 2020 2020 696e 7075 7473 203d 205f 6765      inputs = _ge
+00027de0: 745f 696e 7075 7473 2863 6f6e 7465 7874  t_inputs(context
+00027df0: 2c20 6e6f 6465 2c20 6578 7065 6374 6564  , node, expected
+00027e00: 3d32 290a 2020 2020 782c 2079 203d 2069  =2).    x, y = i
+00027e10: 6e70 7574 730a 2020 2020 7820 3d20 6d62  nputs.    x = mb
+00027e20: 2e63 6173 7428 783d 782c 2064 7479 7065  .cast(x=x, dtype
+00027e30: 3d22 626f 6f6c 2229 0a20 2020 2079 203d  ="bool").    y =
+00027e40: 206d 622e 6361 7374 2878 3d79 2c20 6474   mb.cast(x=y, dt
+00027e50: 7970 653d 2262 6f6f 6c22 290a 2020 2020  ype="bool").    
+00027e60: 636f 6e74 6578 742e 6164 6428 6d62 2e6c  context.add(mb.l
+00027e70: 6f67 6963 616c 5f78 6f72 2878 3d78 2c20  ogical_xor(x=x, 
+00027e80: 793d 792c 206e 616d 653d 6e6f 6465 2e6e  y=y, name=node.n
+00027e90: 616d 6529 290a 0a0a 6465 6620 5f6e 6f6e  ame))...def _non
+00027ea0: 7a65 726f 5f61 735f 7475 706c 6528 636f  zero_as_tuple(co
+00027eb0: 6e74 6578 742c 206e 6f64 652c 2078 293a  ntext, node, x):
+00027ec0: 0a20 2020 2027 2727 0a20 2020 2043 616c  .    '''.    Cal
+00027ed0: 6375 6c61 7465 7320 7468 6520 6e6f 6e2d  culates the non-
+00027ee0: 7a65 726f 2065 6c65 6d65 6e74 7320 6f66  zero elements of
+00027ef0: 2078 2074 6865 6e20 736c 6963 6573 2072   x then slices r
+00027f00: 6573 756c 7473 2062 7920 6561 6368 2069  esults by each i
+00027f10: 6e6e 6572 2069 6e64 6578 2e0a 2020 2020  nner index..    
+00027f20: 2727 270a 2020 2020 6e6f 6e5f 7a65 726f  '''.    non_zero
+00027f30: 203d 206d 622e 6e6f 6e5f 7a65 726f 2878   = mb.non_zero(x
+00027f40: 3d78 290a 0a20 2020 2072 6573 756c 7420  =x)..    result 
+00027f50: 3d20 5b5d 0a20 2020 2066 6f72 2069 2069  = [].    for i i
+00027f60: 6e20 7261 6e67 6528 782e 7261 6e6b 293a  n range(x.rank):
+00027f70: 0a20 2020 2020 2020 2072 6573 756c 742e  .        result.
+00027f80: 6170 7065 6e64 280a 2020 2020 2020 2020  append(.        
+00027f90: 2020 2020 6d62 2e73 6c69 6365 5f62 795f      mb.slice_by_
+00027fa0: 696e 6465 7828 0a20 2020 2020 2020 2020  index(.         
+00027fb0: 2020 2020 2020 2078 3d6e 6f6e 5f7a 6572         x=non_zer
+00027fc0: 6f2c 0a20 2020 2020 2020 2020 2020 2020  o,.             
+00027fd0: 2020 2062 6567 696e 3d5b 302c 2069 5d2c     begin=[0, i],
+00027fe0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00027ff0: 2065 6e64 3d5b 2d31 2c20 2d31 5d2c 2023   end=[-1, -1], #
+00028000: 2049 676e 6f72 6564 2c20 6275 7420 7265   Ignored, but re
+00028010: 7175 6972 6564 0a20 2020 2020 2020 2020  quired.         
+00028020: 2020 2020 2020 2065 6e64 5f6d 6173 6b3d         end_mask=
+00028030: 5b54 7275 652c 2046 616c 7365 5d2c 0a20  [True, False],. 
+00028040: 2020 2020 2020 2020 2020 2020 2020 2073                 s
+00028050: 7175 6565 7a65 5f6d 6173 6b3d 5b46 616c  queeze_mask=[Fal
+00028060: 7365 2c20 5472 7565 5d0a 2020 2020 2020  se, True].      
+00028070: 2020 2020 2020 290a 2020 2020 2020 2020        ).        
+00028080: 290a 0a20 2020 2063 6f6e 7465 7874 2e61  )..    context.a
+00028090: 6464 2872 6573 756c 742c 206e 6f64 652e  dd(result, node.
+000280a0: 6e61 6d65 290a 0a0a 4072 6567 6973 7465  name)...@registe
+000280b0: 725f 746f 7263 685f 6f70 0a64 6566 2077  r_torch_op.def w
+000280c0: 6865 7265 2863 6f6e 7465 7874 2c20 6e6f  here(context, no
+000280d0: 6465 293a 0a20 2020 2069 6e70 7574 7320  de):.    inputs 
+000280e0: 3d20 5f67 6574 5f69 6e70 7574 7328 636f  = _get_inputs(co
+000280f0: 6e74 6578 742c 206e 6f64 6529 0a0a 2020  ntext, node)..  
+00028100: 2020 6966 206c 656e 2869 6e70 7574 7329    if len(inputs)
+00028110: 203d 3d20 313a 0a20 2020 2020 2020 205f   == 1:.        _
+00028120: 6e6f 6e7a 6572 6f5f 6173 5f74 7570 6c65  nonzero_as_tuple
+00028130: 2863 6f6e 7465 7874 2c20 6e6f 6465 2c20  (context, node, 
+00028140: 696e 7075 7473 5b30 5d29 0a20 2020 2020  inputs[0]).     
+00028150: 2020 2072 6574 7572 6e0a 0a20 2020 2061     return..    a
+00028160: 7373 6572 7420 6c65 6e28 696e 7075 7473  ssert len(inputs
+00028170: 2920 3d3d 2033 0a20 2020 2063 6f6e 6420  ) == 3.    cond 
+00028180: 3d20 696e 7075 7473 5b30 5d0a 2020 2020  = inputs[0].    
+00028190: 6966 206e 6f74 2074 7970 6573 2e69 735f  if not types.is_
+000281a0: 626f 6f6c 2863 6f6e 642e 6474 7970 6529  bool(cond.dtype)
+000281b0: 3a0a 2020 2020 2020 2020 2320 636f 6e64  :.        # cond
+000281c0: 206d 7573 7420 6265 2062 6f6f 6c20 7479   must be bool ty
+000281d0: 7065 0a20 2020 2020 2020 2063 6f6e 6420  pe.        cond 
+000281e0: 3d20 6d62 2e63 6173 7428 783d 636f 6e64  = mb.cast(x=cond
+000281f0: 2c20 6474 7970 653d 2262 6f6f 6c22 290a  , dtype="bool").
+00028200: 2020 2020 6966 206e 6f74 2061 6e79 285b      if not any([
+00028210: 616e 795f 7379 6d62 6f6c 6963 2878 2e73  any_symbolic(x.s
+00028220: 6861 7065 2920 666f 7220 7820 696e 2069  hape) for x in i
+00028230: 6e70 7574 735b 3a33 5d5d 293a 0a20 2020  nputs[:3]]):.   
+00028240: 2020 2020 2023 2062 726f 6164 6361 7374       # broadcast
+00028250: 2061 6c6c 2074 656e 736f 7273 2074 6f20   all tensors to 
+00028260: 7468 6520 7361 6d65 2073 6861 7065 0a20  the same shape. 
+00028270: 2020 2020 2020 2062 726f 6164 6361 7374         broadcast
+00028280: 5f69 6e70 7574 7320 3d20 5f62 726f 6164  _inputs = _broad
+00028290: 6361 7374 5f74 656e 736f 7273 285b 636f  cast_tensors([co
+000282a0: 6e64 2c20 696e 7075 7473 5b31 5d2c 2069  nd, inputs[1], i
+000282b0: 6e70 7574 735b 325d 5d29 0a20 2020 2020  nputs[2]]).     
+000282c0: 2020 2072 6573 756c 7420 3d20 6d62 2e73     result = mb.s
+000282d0: 656c 6563 7428 0a20 2020 2020 2020 2020  elect(.         
+000282e0: 2020 2063 6f6e 643d 6272 6f61 6463 6173     cond=broadcas
+000282f0: 745f 696e 7075 7473 5b30 5d2c 0a20 2020  t_inputs[0],.   
+00028300: 2020 2020 2020 2020 2061 3d62 726f 6164           a=broad
+00028310: 6361 7374 5f69 6e70 7574 735b 315d 2c0a  cast_inputs[1],.
+00028320: 2020 2020 2020 2020 2020 2020 623d 6272              b=br
+00028330: 6f61 6463 6173 745f 696e 7075 7473 5b32  oadcast_inputs[2
+00028340: 5d2c 0a20 2020 2020 2020 2020 2020 206e  ],.            n
+00028350: 616d 653d 6e6f 6465 2e6e 616d 652c 0a20  ame=node.name,. 
+00028360: 2020 2020 2020 2029 0a20 2020 2065 6c73         ).    els
+00028370: 653a 0a20 2020 2020 2020 2072 6573 756c  e:.        resul
+00028380: 7420 3d20 6d62 2e73 656c 6563 7428 636f  t = mb.select(co
+00028390: 6e64 3d63 6f6e 642c 2061 3d69 6e70 7574  nd=cond, a=input
+000283a0: 735b 315d 2c20 623d 696e 7075 7473 5b32  s[1], b=inputs[2
+000283b0: 5d2c 206e 616d 653d 6e6f 6465 2e6e 616d  ], name=node.nam
+000283c0: 6529 0a20 2020 2063 6f6e 7465 7874 2e61  e).    context.a
+000283d0: 6464 2872 6573 756c 7429 0a0a 0a40 7265  dd(result)...@re
+000283e0: 6769 7374 6572 5f74 6f72 6368 5f6f 700a  gister_torch_op.
+000283f0: 6465 6620 6e6f 6e7a 6572 6f5f 6e75 6d70  def nonzero_nump
+00028400: 7928 636f 6e74 6578 742c 206e 6f64 6529  y(context, node)
+00028410: 3a0a 2020 2020 696e 7075 7473 203d 205f  :.    inputs = _
+00028420: 6765 745f 696e 7075 7473 2863 6f6e 7465  get_inputs(conte
+00028430: 7874 2c20 6e6f 6465 2c20 6578 7065 6374  xt, node, expect
+00028440: 6564 3d31 290a 2020 2020 5f6e 6f6e 7a65  ed=1).    _nonze
+00028450: 726f 5f61 735f 7475 706c 6528 636f 6e74  ro_as_tuple(cont
+00028460: 6578 742c 206e 6f64 652c 2069 6e70 7574  ext, node, input
+00028470: 735b 305d 290a 0a0a 4072 6567 6973 7465  s[0])...@registe
+00028480: 725f 746f 7263 685f 6f70 0a64 6566 206e  r_torch_op.def n
+00028490: 6567 2863 6f6e 7465 7874 2c20 6e6f 6465  eg(context, node
+000284a0: 293a 0a20 2020 2069 6e70 7574 7320 3d20  ):.    inputs = 
+000284b0: 5f67 6574 5f69 6e70 7574 7328 636f 6e74  _get_inputs(cont
+000284c0: 6578 742c 206e 6f64 652c 2065 7870 6563  ext, node, expec
+000284d0: 7465 643d 3129 0a20 2020 2078 2c20 7920  ted=1).    x, y 
+000284e0: 3d20 7072 6f6d 6f74 655f 696e 7075 745f  = promote_input_
+000284f0: 6474 7970 6573 285b 696e 7075 7473 5b30  dtypes([inputs[0
+00028500: 5d2c 202d 315d 290a 2020 2020 636f 6e74  ], -1]).    cont
+00028510: 6578 742e 6164 6428 6d62 2e6d 756c 2878  ext.add(mb.mul(x
+00028520: 3d78 2c20 793d 792c 206e 616d 653d 6e6f  =x, y=y, name=no
+00028530: 6465 2e6e 616d 6529 290a 0a40 7265 6769  de.name))..@regi
+00028540: 7374 6572 5f74 6f72 6368 5f6f 700a 6465  ster_torch_op.de
+00028550: 6620 746f 706b 2863 6f6e 7465 7874 2c20  f topk(context, 
+00028560: 6e6f 6465 293a 0a20 2020 2064 6566 2064  node):.    def d
+00028570: 796e 616d 6963 5f74 6f70 6b28 782c 206b  ynamic_topk(x, k
+00028580: 2c20 6178 6973 2c20 6173 6365 6e64 696e  , axis, ascendin
+00028590: 6729 3a0a 2020 2020 2020 2020 6173 7365  g):.        asse
+000285a0: 7274 206b 2e76 616c 2069 7320 4e6f 6e65  rt k.val is None
+000285b0: 2c20 2250 6c65 6173 6520 7573 6520 6d62  , "Please use mb
+000285c0: 2e74 6f70 6b20 6469 7265 6374 6c79 2069  .topk directly i
+000285d0: 6620 6b20 6973 2063 6f6d 7069 6c65 2074  f k is compile t
+000285e0: 696d 6520 6b6e 6f77 6e22 0a20 2020 2020  ime known".     
+000285f0: 2020 2069 6e64 6963 6573 203d 206d 622e     indices = mb.
+00028600: 6172 6773 6f72 7428 783d 782c 2061 7869  argsort(x=x, axi
+00028610: 733d 6178 6973 2c20 6173 6365 6e64 696e  s=axis, ascendin
+00028620: 673d 6173 6365 6e64 696e 6729 0a20 2020  g=ascending).   
+00028630: 2020 2020 2076 616c 7565 7320 3d20 6d62       values = mb
+00028640: 2e67 6174 6865 725f 616c 6f6e 675f 6178  .gather_along_ax
+00028650: 6973 2878 3d78 2c20 696e 6469 6365 733d  is(x=x, indices=
+00028660: 696e 6469 6365 732c 2061 7869 733d 6178  indices, axis=ax
+00028670: 6973 290a 0a20 2020 2020 2020 206b 5f69  is)..        k_i
+00028680: 6e64 6963 6573 203d 206d 622e 7261 6e67  ndices = mb.rang
+00028690: 655f 3164 2865 6e64 3d6b 2c20 7374 6172  e_1d(end=k, star
+000286a0: 743d 302c 2073 7465 703d 3129 0a20 2020  t=0, step=1).   
+000286b0: 2020 2020 2076 616c 7565 7320 3d20 6d62       values = mb
+000286c0: 2e67 6174 6865 7228 783d 7661 6c75 6573  .gather(x=values
+000286d0: 2c20 696e 6469 6365 733d 6b5f 696e 6469  , indices=k_indi
+000286e0: 6365 732c 2061 7869 733d 6178 6973 290a  ces, axis=axis).
+000286f0: 2020 2020 2020 2020 696e 6469 6365 7320          indices 
+00028700: 3d20 6d62 2e67 6174 6865 7228 783d 696e  = mb.gather(x=in
+00028710: 6469 6365 732c 2069 6e64 6963 6573 3d6b  dices, indices=k
+00028720: 5f69 6e64 6963 6573 2c20 6178 6973 3d61  _indices, axis=a
+00028730: 7869 7329 0a0a 2020 2020 2020 2020 7265  xis)..        re
+00028740: 7475 726e 2076 616c 7565 732c 2069 6e64  turn values, ind
+00028750: 6963 6573 0a0a 2020 2020 696e 7075 7473  ices..    inputs
+00028760: 203d 205f 6765 745f 696e 7075 7473 2863   = _get_inputs(c
+00028770: 6f6e 7465 7874 2c20 6e6f 6465 290a 2020  ontext, node).  
+00028780: 2020 6b77 6172 6773 203d 207b 226e 616d    kwargs = {"nam
+00028790: 6522 3a20 6e6f 6465 2e6e 616d 652c 2022  e": node.name, "
+000287a0: 7822 3a20 696e 7075 7473 5b30 5d2c 2022  x": inputs[0], "
+000287b0: 6b22 3a20 696e 7075 7473 5b31 5d7d 0a0a  k": inputs[1]}..
+000287c0: 2020 2020 6966 206c 656e 2869 6e70 7574      if len(input
+000287d0: 7329 203e 2036 3a0a 2020 2020 2020 2020  s) > 6:.        
+000287e0: 7261 6973 6520 4578 6365 7074 696f 6e28  raise Exception(
+000287f0: 224e 756d 6265 7220 6f66 2069 6e70 7574  "Number of input
+00028800: 7320 746f 2074 6f70 6b20 6578 6365 6564  s to topk exceed
+00028810: 7320 3622 290a 2020 2020 2320 6f70 7469  s 6").    # opti
+00028820: 6f6e 616c 3a20 4061 7869 730a 2020 2020  onal: @axis.    
+00028830: 6966 206c 656e 2869 6e70 7574 7329 203e  if len(inputs) >
+00028840: 2032 3a0a 2020 2020 2020 2020 6966 2069   2:.        if i
+00028850: 6e70 7574 735b 325d 2069 7320 6e6f 7420  nputs[2] is not 
+00028860: 4e6f 6e65 3a0a 2020 2020 2020 2020 2020  None:.          
+00028870: 2020 6b77 6172 6773 5b22 6178 6973 225d    kwargs["axis"]
+00028880: 203d 2069 6e70 7574 735b 325d 2e76 616c   = inputs[2].val
+00028890: 0a0a 2020 2020 2320 6f70 7469 6f6e 616c  ..    # optional
+000288a0: 3a20 4061 7363 656e 6469 6e67 0a20 2020  : @ascending.   
+000288b0: 2069 6620 6c65 6e28 696e 7075 7473 2920   if len(inputs) 
+000288c0: 3e20 333a 0a20 2020 2020 2020 206c 6172  > 3:.        lar
+000288d0: 6765 7374 203d 2069 6e70 7574 735b 335d  gest = inputs[3]
+000288e0: 2e76 616c 0a20 2020 2020 2020 206b 7761  .val.        kwa
+000288f0: 7267 735b 2261 7363 656e 6469 6e67 225d  rgs["ascending"]
+00028900: 203d 206e 6f74 206c 6172 6765 7374 0a0a   = not largest..
+00028910: 2020 2020 2320 6c61 7374 2069 6e70 7574      # last input
+00028920: 7320 746f 2074 6f70 6b20 6172 6520 6f70  s to topk are op
+00028930: 7469 6f6e 616c 202d 2073 6f72 7465 6420  tional - sorted 
+00028940: 616e 6420 6f75 742e 0a20 2020 2073 6f72  and out..    sor
+00028950: 7420 3d20 5472 7565 0a20 2020 2069 6620  t = True.    if 
+00028960: 6c65 6e28 696e 7075 7473 2920 3e20 343a  len(inputs) > 4:
+00028970: 0a20 2020 2020 2020 2069 6620 696e 7075  .        if inpu
+00028980: 7473 5b34 5d2e 7661 6c20 6973 2046 616c  ts[4].val is Fal
+00028990: 7365 2061 6e64 206e 6f74 2069 735f 6375  se and not is_cu
+000289a0: 7272 656e 745f 6f70 7365 745f 7665 7273  rrent_opset_vers
+000289b0: 696f 6e5f 636f 6d70 6174 6962 6c65 5f77  ion_compatible_w
+000289c0: 6974 6828 7461 7267 6574 2e69 4f53 3136  ith(target.iOS16
+000289d0: 293a 0a20 2020 2020 2020 2020 2020 2072  ):.            r
+000289e0: 6169 7365 2045 7863 6570 7469 6f6e 2822  aise Exception("
+000289f0: 466f 7220 6f70 7365 7420 3c3d 2069 4f53  For opset <= iOS
+00028a00: 3136 2c20 6f6e 6c79 2073 6f72 7465 643d  16, only sorted=
+00028a10: 5472 7565 2073 7570 706f 7274 6564 2066  True supported f
+00028a20: 6f72 2074 6865 2074 6f70 6b22 290a 2020  or the topk").  
+00028a30: 2020 2020 2020 736f 7274 203d 2069 6e70        sort = inp
+00028a40: 7574 735b 345d 2e76 616c 0a0a 2020 2020  uts[4].val..    
+00028a50: 6966 206c 656e 2869 6e70 7574 7329 203e  if len(inputs) >
+00028a60: 2035 3a0a 2020 2020 2020 2020 6966 2069   5:.        if i
+00028a70: 6e70 7574 735b 355d 2069 7320 6e6f 7420  nputs[5] is not 
+00028a80: 4e6f 6e65 3a0a 2020 2020 2020 2020 2020  None:.          
+00028a90: 2020 7261 6973 6520 4578 6365 7074 696f    raise Exceptio
+00028aa0: 6e28 0a20 2020 2020 2020 2020 2020 2020  n(.             
+00028ab0: 2020 2022 556e 7375 7070 6f72 7465 6420     "Unsupported 
+00028ac0: 7661 6c75 6520 666f 7220 6172 6775 6d65  value for argume
+00028ad0: 6e74 2027 6f75 7427 2069 6e20 746f 706b  nt 'out' in topk
+00028ae0: 2e20 5375 7070 6f72 7465 6420 7661 6c75  . Supported valu
+00028af0: 6573 3a20 4e6f 6e65 2c20 6275 7420 696e  es: None, but in
+00028b00: 7075 7420 220a 2020 2020 2020 2020 2020  put ".          
+00028b10: 2020 2020 2020 2269 7320 7b7d 222e 666f        "is {}".fo
+00028b20: 726d 6174 2869 6e70 7574 735b 355d 2e76  rmat(inputs[5].v
+00028b30: 616c 290a 2020 2020 2020 2020 2020 2020  al).            
+00028b40: 290a 0a20 2020 2069 6620 6973 5f63 7572  )..    if is_cur
+00028b50: 7265 6e74 5f6f 7073 6574 5f76 6572 7369  rent_opset_versi
+00028b60: 6f6e 5f63 6f6d 7061 7469 626c 655f 7769  on_compatible_wi
+00028b70: 7468 2874 6172 6765 742e 694f 5331 3629  th(target.iOS16)
+00028b80: 3a0a 2020 2020 2020 2020 6b77 6172 6773  :.        kwargs
+00028b90: 5b22 736f 7274 225d 203d 2073 6f72 740a  ["sort"] = sort.
+00028ba0: 0a20 2020 2069 6620 6b77 6172 6773 5b22  .    if kwargs["
+00028bb0: 6b22 5d2e 7661 6c20 6973 204e 6f6e 653a  k"].val is None:
+00028bc0: 0a20 2020 2020 2020 2072 6573 203d 2064  .        res = d
+00028bd0: 796e 616d 6963 5f74 6f70 6b28 0a20 2020  ynamic_topk(.   
+00028be0: 2020 2020 2020 2020 2020 2020 2078 3d6b               x=k
+00028bf0: 7761 7267 735b 2278 225d 2c0a 2020 2020  wargs["x"],.    
+00028c00: 2020 2020 2020 2020 2020 2020 6b3d 6b77              k=kw
+00028c10: 6172 6773 5b22 6b22 5d2c 0a20 2020 2020  args["k"],.     
+00028c20: 2020 2020 2020 2020 2020 2061 7869 733d             axis=
+00028c30: 6b77 6172 6773 5b22 6178 6973 225d 2c0a  kwargs["axis"],.
+00028c40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00028c50: 6173 6365 6e64 696e 673d 6b77 6172 6773  ascending=kwargs
+00028c60: 5b22 6173 6365 6e64 696e 6722 5d0a 2020  ["ascending"].  
+00028c70: 2020 2020 2020 290a 2020 2020 656c 7365        ).    else
+00028c80: 3a0a 2020 2020 2020 2020 7265 7320 3d20  :.        res = 
+00028c90: 6d62 2e74 6f70 6b28 2a2a 6b77 6172 6773  mb.topk(**kwargs
+00028ca0: 290a 0a20 2020 2076 616c 7565 735f 6e61  )..    values_na
+00028cb0: 6d65 203d 206e 6f64 652e 6f75 7470 7574  me = node.output
+00028cc0: 735b 305d 0a20 2020 2069 6e64 6963 6573  s[0].    indices
+00028cd0: 5f6e 616d 6520 3d20 6e6f 6465 2e6f 7574  _name = node.out
+00028ce0: 7075 7473 5b31 5d0a 2020 2020 636f 6e74  puts[1].    cont
+00028cf0: 6578 742e 6164 6428 7265 735b 305d 2c20  ext.add(res[0], 
+00028d00: 746f 7263 685f 6e61 6d65 3d76 616c 7565  torch_name=value
+00028d10: 735f 6e61 6d65 290a 2020 2020 636f 6e74  s_name).    cont
+00028d20: 6578 742e 6164 6428 7265 735b 315d 2c20  ext.add(res[1], 
+00028d30: 746f 7263 685f 6e61 6d65 3d69 6e64 6963  torch_name=indic
+00028d40: 6573 5f6e 616d 6529 0a0a 0a64 6566 205f  es_name)...def _
+00028d50: 7374 6428 782c 2061 7865 732c 206b 6565  std(x, axes, kee
+00028d60: 705f 6469 6d2c 2075 6e62 6961 7365 642c  p_dim, unbiased,
+00028d70: 2065 7073 293a 0a20 2020 206e 6565 645f   eps):.    need_
+00028d80: 7265 7363 616c 6520 3d20 4661 6c73 650a  rescale = False.
+00028d90: 2020 2020 6966 2075 6e62 6961 7365 643a      if unbiased:
+00028da0: 0a20 2020 2020 2020 2023 2049 6620 2275  .        # If "u
+00028db0: 6e62 6961 7365 6422 2069 7320 5472 7565  nbiased" is True
+00028dc0: 2c0a 2020 2020 2020 2020 2320 7468 656e  ,.        # then
+00028dd0: 2077 6520 6e65 6564 2074 6f20 6469 7669   we need to divi
+00028de0: 6465 2062 7920 224e 2d31 2220 2869 6e73  de by "N-1" (ins
+00028df0: 7465 6164 206f 6620 224e 2229 2074 6f20  tead of "N") to 
+00028e00: 636f 6d70 7574 6520 7468 6520 6d65 616e  compute the mean
+00028e10: 206f 6620 2878 2d45 5b78 5d29 5e32 0a20   of (x-E[x])^2. 
+00028e20: 2020 2020 2020 2023 2066 6f72 2061 6e20         # for an 
+00028e30: 756e 6269 6173 6564 2065 7374 696d 6174  unbiased estimat
+00028e40: 6520 6f66 2074 6865 2076 6172 6961 6e63  e of the varianc
+00028e50: 6520 2f20 2073 7461 6e64 6172 6420 6465  e /  standard de
+00028e60: 7669 6174 696f 6e2e 0a20 2020 2020 2020  viation..       
+00028e70: 2023 2049 6e20 7468 6520 7365 7175 656e   # In the sequen
+00028e80: 6365 206f 6620 4d49 4c20 6f70 7320 6164  ce of MIL ops ad
+00028e90: 6465 6420 6265 6c6f 772c 2077 6520 6669  ded below, we fi
+00028ea0: 7273 7420 636f 6d70 7574 6520 7468 6520  rst compute the 
+00028eb0: 6d65 616e 2075 7369 6e67 2022 4e22 2c20  mean using "N", 
+00028ec0: 616e 6420 6f6e 6c79 2069 6620 6974 7320  and only if its 
+00028ed0: 756e 6269 6173 6564 0a20 2020 2020 2020  unbiased.       
+00028ee0: 2023 2077 6520 7265 7363 616c 6520 6c61   # we rescale la
+00028ef0: 7465 722c 2074 6865 2066 696e 616c 2072  ter, the final r
+00028f00: 6573 756c 742e 0a20 2020 2020 2020 2023  esult..        #
+00028f10: 2057 6520 6967 6e6f 7265 2074 6865 2022   We ignore the "
+00028f20: 756e 6269 6173 6564 2220 666c 6167 2c20  unbiased" flag, 
+00028f30: 6966 2061 6e79 206f 6620 7468 6520 6469  if any of the di
+00028f40: 6d65 6e73 696f 6e73 2069 6e76 6f6c 7665  mensions involve
+00028f50: 6420 696e 2074 6869 7320 6f70 6572 6174  d in this operat
+00028f60: 696f 6e20 6172 6520 6479 6e61 6d69 630a  ion are dynamic.
+00028f70: 2020 2020 2020 2020 2320 2877 6520 636f          # (we co
+00028f80: 756c 6420 6861 7665 2073 7469 6c6c 2068  uld have still h
+00028f90: 616e 646c 6564 2074 6861 7420 6361 7365  andled that case
+00028fa0: 2062 7920 7573 696e 6720 2267 6574 5f73   by using "get_s
+00028fb0: 6861 7065 2220 6574 6320 6f70 732c 2062  hape" etc ops, b
+00028fc0: 7574 2077 6520 646f 6e27 7420 646f 2074  ut we don't do t
+00028fd0: 6861 7420 6865 7265 2c0a 2020 2020 2020  hat here,.      
+00028fe0: 2020 2320 7472 6164 696e 6720 7065 7266    # trading perf
+00028ff0: 6f72 6d61 6e63 6520 666f 7220 6e75 6d65  ormance for nume
+00029000: 7269 6361 6c20 6163 6375 7261 6379 290a  rical accuracy).
+00029010: 2020 2020 2020 2020 6966 2061 7865 7320          if axes 
+00029020: 6973 204e 6f6e 653a 0a20 2020 2020 2020  is None:.       
+00029030: 2020 2020 2069 6620 6e6f 7420 616e 795f       if not any_
+00029040: 7379 6d62 6f6c 6963 2878 2e73 6861 7065  symbolic(x.shape
+00029050: 2920 616e 6420 5f6e 702e 7072 6f64 2878  ) and _np.prod(x
+00029060: 2e73 6861 7065 2920 3e20 313a 0a20 2020  .shape) > 1:.   
+00029070: 2020 2020 2020 2020 2020 2020 204e 203d               N =
+00029080: 205f 6e70 2e70 726f 6428 782e 7368 6170   _np.prod(x.shap
+00029090: 6529 0a20 2020 2020 2020 2020 2020 2020  e).             
+000290a0: 2020 206e 6565 645f 7265 7363 616c 6520     need_rescale 
+000290b0: 3d20 5472 7565 0a20 2020 2020 2020 2065  = True.        e
+000290c0: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
+000290d0: 2064 696d 7320 3d20 5b5d 0a20 2020 2020   dims = [].     
+000290e0: 2020 2020 2020 2023 2063 6f6c 6c65 6374         # collect
+000290f0: 2064 696d 656e 7369 6f6e 7320 636f 7272   dimensions corr
+00029100: 6573 706f 6e64 696e 6720 746f 2022 6178  esponding to "ax
+00029110: 6573 220a 2020 2020 2020 2020 2020 2020  es".            
+00029120: 666f 7220 6178 6973 2069 6e20 6178 6573  for axis in axes
+00029130: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+00029140: 2020 6469 6d73 2e61 7070 656e 6428 782e    dims.append(x.
+00029150: 7368 6170 655b 6178 6973 5d29 0a20 2020  shape[axis]).   
+00029160: 2020 2020 2020 2020 2069 6620 616c 6c28           if all(
+00029170: 5b6e 6f74 2069 735f 7379 6d62 6f6c 6963  [not is_symbolic
+00029180: 2873 2920 666f 7220 7320 696e 2064 696d  (s) for s in dim
+00029190: 735d 293a 0a20 2020 2020 2020 2020 2020  s]):.           
+000291a0: 2020 2020 204e 203d 205f 6e70 2e70 726f       N = _np.pro
+000291b0: 6428 6469 6d73 290a 2020 2020 2020 2020  d(dims).        
+000291c0: 2020 2020 2020 2020 6966 204e 203e 2031          if N > 1
+000291d0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+000291e0: 2020 2020 2020 6e65 6564 5f72 6573 6361        need_resca
+000291f0: 6c65 203d 2054 7275 650a 2020 2020 6966  le = True.    if
+00029200: 206e 6565 645f 7265 7363 616c 653a 0a20   need_rescale:. 
+00029210: 2020 2020 2020 2072 6573 6361 6c65 5f66         rescale_f
+00029220: 6163 746f 7220 3d20 5f6e 702e 7371 7274  actor = _np.sqrt
+00029230: 284e 202f 2066 6c6f 6174 284e 202d 2031  (N / float(N - 1
+00029240: 2929 0a0a 2020 2020 785f 6d65 616e 203d  ))..    x_mean =
+00029250: 206d 622e 7265 6475 6365 5f6d 6561 6e28   mb.reduce_mean(
+00029260: 783d 782c 2061 7865 733d 6178 6573 2c20  x=x, axes=axes, 
+00029270: 6b65 6570 5f64 696d 733d 5472 7565 290a  keep_dims=True).
+00029280: 2020 2020 785f 6465 6d65 616e 6564 203d      x_demeaned =
+00029290: 206d 622e 7375 6228 783d 782c 2079 3d78   mb.sub(x=x, y=x
+000292a0: 5f6d 6561 6e29 0a20 2020 2078 5f64 656d  _mean).    x_dem
+000292b0: 6561 6e65 645f 7371 7561 7265 203d 206d  eaned_square = m
+000292c0: 622e 7371 7561 7265 2878 3d78 5f64 656d  b.square(x=x_dem
+000292d0: 6561 6e65 6429 0a20 2020 2078 5f64 656d  eaned).    x_dem
+000292e0: 6561 6e65 645f 7371 7561 7265 5f6d 6561  eaned_square_mea
+000292f0: 6e20 3d20 6d62 2e72 6564 7563 655f 6d65  n = mb.reduce_me
+00029300: 616e 2878 3d78 5f64 656d 6561 6e65 645f  an(x=x_demeaned_
+00029310: 7371 7561 7265 2c20 6178 6573 3d61 7865  square, axes=axe
+00029320: 732c 206b 6565 705f 6469 6d73 3d6b 6565  s, keep_dims=kee
+00029330: 705f 6469 6d29 0a20 2020 2069 6620 6570  p_dim).    if ep
+00029340: 7320 3e20 303a 0a20 2020 2020 2020 2078  s > 0:.        x
+00029350: 5f64 656d 6561 6e65 645f 7371 7561 7265  _demeaned_square
+00029360: 5f6d 6561 6e20 3d20 6d62 2e61 6464 2878  _mean = mb.add(x
+00029370: 3d78 5f64 656d 6561 6e65 645f 7371 7561  =x_demeaned_squa
+00029380: 7265 5f6d 6561 6e2c 2079 3d65 7073 290a  re_mean, y=eps).
+00029390: 2020 2020 6966 206e 6565 645f 7265 7363      if need_resc
+000293a0: 616c 653a 0a20 2020 2020 2020 2079 5f62  ale:.        y_b
+000293b0: 6566 6f72 655f 7363 616c 6520 3d20 6d62  efore_scale = mb
+000293c0: 2e73 7172 7428 783d 785f 6465 6d65 616e  .sqrt(x=x_demean
+000293d0: 6564 5f73 7175 6172 655f 6d65 616e 290a  ed_square_mean).
+000293e0: 2020 2020 2020 2020 7920 3d20 6d62 2e6d          y = mb.m
+000293f0: 756c 2878 3d79 5f62 6566 6f72 655f 7363  ul(x=y_before_sc
+00029400: 616c 652c 2079 3d72 6573 6361 6c65 5f66  ale, y=rescale_f
+00029410: 6163 746f 7229 0a20 2020 2065 6c73 653a  actor).    else:
+00029420: 0a20 2020 2020 2020 2079 203d 206d 622e  .        y = mb.
+00029430: 7371 7274 2878 3d78 5f64 656d 6561 6e65  sqrt(x=x_demeane
+00029440: 645f 7371 7561 7265 5f6d 6561 6e29 0a20  d_square_mean). 
+00029450: 2020 2072 6574 7572 6e20 790a 0a40 7265     return y..@re
+00029460: 6769 7374 6572 5f74 6f72 6368 5f6f 700a  gister_torch_op.
+00029470: 6465 6620 6e75 6d65 6c28 636f 6e74 6578  def numel(contex
+00029480: 742c 206e 6f64 6529 3a0a 2020 2020 696e  t, node):.    in
+00029490: 7075 7473 203d 205f 6765 745f 696e 7075  puts = _get_inpu
+000294a0: 7473 2863 6f6e 7465 7874 2c20 6e6f 6465  ts(context, node
+000294b0: 2c20 6578 7065 6374 6564 3d31 290a 2020  , expected=1).  
+000294c0: 2020 7820 3d20 696e 7075 7473 5b30 5d0a    x = inputs[0].
+000294d0: 2020 2020 7820 3d20 6d62 2e73 6861 7065      x = mb.shape
+000294e0: 2878 3d78 290a 2020 2020 7820 3d20 6d62  (x=x).    x = mb
+000294f0: 2e72 6564 7563 655f 7072 6f64 2878 3d78  .reduce_prod(x=x
+00029500: 2c20 6178 6573 3d5b 305d 2c20 6e61 6d65  , axes=[0], name
+00029510: 3d6e 6f64 652e 6e61 6d65 290a 2020 2020  =node.name).    
+00029520: 636f 6e74 6578 742e 6164 6428 7829 0a0a  context.add(x)..
+00029530: 4072 6567 6973 7465 725f 746f 7263 685f  @register_torch_
+00029540: 6f70 0a64 6566 2073 7464 2863 6f6e 7465  op.def std(conte
+00029550: 7874 2c20 6e6f 6465 293a 0a20 2020 2069  xt, node):.    i
+00029560: 6e70 7574 7320 3d20 5f67 6574 5f69 6e70  nputs = _get_inp
+00029570: 7574 7328 636f 6e74 6578 742c 206e 6f64  uts(context, nod
+00029580: 6529 0a20 2020 2078 203d 2069 6e70 7574  e).    x = input
+00029590: 735b 305d 0a20 2020 2069 6620 6e6f 7420  s[0].    if not 
+000295a0: 286c 656e 2869 6e70 7574 7329 203d 3d20  (len(inputs) == 
+000295b0: 3220 6f72 206c 656e 2869 6e70 7574 7329  2 or len(inputs)
+000295c0: 203d 3d20 3429 3a0a 2020 2020 2020 2020   == 4):.        
+000295d0: 7261 6973 6520 5661 6c75 6545 7272 6f72  raise ValueError
+000295e0: 2822 4e75 6d62 6572 206f 6620 696e 7075  ("Number of inpu
+000295f0: 7473 2074 6f20 7468 6520 2773 7464 2720  ts to the 'std' 
+00029600: 6f70 206d 7573 7420 6265 220a 2020 2020  op must be".    
+00029610: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00029620: 2020 2020 2022 3220 6f72 2034 2229 0a0a       "2 or 4")..
+00029630: 2020 2020 6b65 6570 5f64 696d 203d 2046      keep_dim = F
+00029640: 616c 7365 0a20 2020 2061 7865 7320 3d20  alse.    axes = 
+00029650: 4e6f 6e65 0a20 2020 2069 6620 6c65 6e28  None.    if len(
+00029660: 696e 7075 7473 2920 3d3d 2032 3a0a 2020  inputs) == 2:.  
+00029670: 2020 2020 2020 756e 6269 6173 6564 203d        unbiased =
+00029680: 2069 6e70 7574 735b 315d 2e76 616c 0a20   inputs[1].val. 
+00029690: 2020 2069 6620 6c65 6e28 696e 7075 7473     if len(inputs
+000296a0: 2920 3d3d 2034 3a0a 2020 2020 2020 2020  ) == 4:.        
+000296b0: 6178 6573 203d 2069 6e70 7574 735b 315d  axes = inputs[1]
+000296c0: 2e76 616c 0a20 2020 2020 2020 2069 6620  .val.        if 
+000296d0: 6973 696e 7374 616e 6365 2861 7865 732c  isinstance(axes,
+000296e0: 2069 6e74 293a 0a20 2020 2020 2020 2020   int):.         
+000296f0: 2020 2061 7865 7320 3d20 5b61 7865 735d     axes = [axes]
+00029700: 0a20 2020 2020 2020 2075 6e62 6961 7365  .        unbiase
+00029710: 6420 3d20 696e 7075 7473 5b32 5d2e 7661  d = inputs[2].va
+00029720: 6c0a 2020 2020 2020 2020 6b65 6570 5f64  l.        keep_d
+00029730: 696d 203d 2069 6e70 7574 735b 335d 2e76  im = inputs[3].v
+00029740: 616c 0a0a 2020 2020 7920 3d20 5f73 7464  al..    y = _std
+00029750: 2878 2c20 6178 6573 2c20 6b65 6570 5f64  (x, axes, keep_d
+00029760: 696d 2c20 756e 6269 6173 6564 2c20 3029  im, unbiased, 0)
+00029770: 0a20 2020 2063 6f6e 7465 7874 2e61 6464  .    context.add
+00029780: 2879 2c20 6e6f 6465 2e6e 616d 6529 0a0a  (y, node.name)..
+00029790: 0a40 7265 6769 7374 6572 5f74 6f72 6368  .@register_torch
+000297a0: 5f6f 700a 6465 6620 636f 7079 2863 6f6e  _op.def copy(con
+000297b0: 7465 7874 2c20 6e6f 6465 293a 0a20 2020  text, node):.   
+000297c0: 2069 6e70 7574 7320 3d20 5f67 6574 5f69   inputs = _get_i
+000297d0: 6e70 7574 7328 636f 6e74 6578 742c 206e  nputs(context, n
+000297e0: 6f64 652c 2065 7870 6563 7465 643d 5b32  ode, expected=[2
+000297f0: 2c20 335d 290a 2020 2020 636f 6e74 6578  , 3]).    contex
+00029800: 742e 6164 6428 6d62 2e69 6465 6e74 6974  t.add(mb.identit
+00029810: 7928 783d 696e 7075 7473 5b30 5d2c 206e  y(x=inputs[0], n
+00029820: 616d 653d 6e6f 6465 2e6e 616d 6529 290a  ame=node.name)).
+00029830: 0a0a 4072 6567 6973 7465 725f 746f 7263  ..@register_torc
+00029840: 685f 6f70 0a64 6566 2064 7479 7065 2863  h_op.def dtype(c
+00029850: 6f6e 7465 7874 2c20 6e6f 6465 293a 0a20  ontext, node):. 
+00029860: 2020 2069 6e70 7574 7320 3d20 5f67 6574     inputs = _get
+00029870: 5f69 6e70 7574 7328 636f 6e74 6578 742c  _inputs(context,
+00029880: 206e 6f64 652c 2065 7870 6563 7465 643d   node, expected=
+00029890: 3129 0a20 2020 2064 7479 7065 5f73 7472  1).    dtype_str
+000298a0: 203d 2069 6e70 7574 735b 305d 2e64 7479   = inputs[0].dty
+000298b0: 7065 2e5f 5f6e 616d 655f 5f0a 2020 2020  pe.__name__.    
+000298c0: 636f 6e74 6578 742e 6164 6428 6d62 2e63  context.add(mb.c
+000298d0: 6f6e 7374 2876 616c 3d64 7479 7065 5f73  onst(val=dtype_s
+000298e0: 7472 2c20 6e61 6d65 3d6e 6f64 652e 6e61  tr, name=node.na
+000298f0: 6d65 2929 0a0a 0a40 7265 6769 7374 6572  me))...@register
+00029900: 5f74 6f72 6368 5f6f 700a 6465 6620 7465  _torch_op.def te
+00029910: 6e73 6f72 2863 6f6e 7465 7874 2c20 6e6f  nsor(context, no
+00029920: 6465 293a 0a20 2020 2064 6566 205f 6d61  de):.    def _ma
+00029930: 6b65 5f74 656e 736f 7228 6c69 7374 5f6f  ke_tensor(list_o
+00029940: 665f 7465 6e73 6f72 2c20 6e61 6d65 2c20  f_tensor, name, 
+00029950: 7261 6e6b 293a 0a20 2020 2020 2020 2069  rank):.        i
+00029960: 6620 7261 6e6b 203d 3d20 363a 0a20 2020  f rank == 6:.   
+00029970: 2020 2020 2020 2020 2072 6169 7365 204e           raise N
+00029980: 6f74 496d 706c 656d 656e 7465 6445 7272  otImplementedErr
+00029990: 6f72 2822 436f 7265 204d 4c20 6f6e 6c79  or("Core ML only
+000299a0: 2073 7570 706f 7274 7320 7465 6e73 6f72   supports tensor
+000299b0: 2072 616e 6b20 3c3d 2035 2e22 290a 2020   rank <= 5.").  
+000299c0: 2020 2020 2020 6966 206e 6f74 2069 7369        if not isi
+000299d0: 6e73 7461 6e63 6528 6c69 7374 5f6f 665f  nstance(list_of_
+000299e0: 7465 6e73 6f72 2c20 6c69 7374 293a 0a20  tensor, list):. 
+000299f0: 2020 2020 2020 2020 2020 2072 6574 7572             retur
+00029a00: 6e20 6c69 7374 5f6f 665f 7465 6e73 6f72  n list_of_tensor
+00029a10: 0a20 2020 2020 2020 2076 616c 7565 7320  .        values 
+00029a20: 3d20 5b0a 2020 2020 2020 2020 2020 2020  = [.            
+00029a30: 5f6d 616b 655f 7465 6e73 6f72 2878 2c20  _make_tensor(x, 
+00029a40: 6e61 6d65 202b 2022 5f72 5f22 202b 2073  name + "_r_" + s
+00029a50: 7472 2869 292c 2072 616e 6b20 2b20 3129  tr(i), rank + 1)
+00029a60: 0a20 2020 2020 2020 2020 2020 2066 6f72  .            for
+00029a70: 2069 2c20 7820 696e 2065 6e75 6d65 7261   i, x in enumera
+00029a80: 7465 286c 6973 745f 6f66 5f74 656e 736f  te(list_of_tenso
+00029a90: 7229 0a20 2020 2020 2020 205d 0a20 2020  r).        ].   
+00029aa0: 2020 2020 2069 6620 6c65 6e28 7661 6c75       if len(valu
+00029ab0: 6573 2920 3d3d 2031 3a0a 2020 2020 2020  es) == 1:.      
+00029ac0: 2020 2020 2020 7265 7475 726e 206d 622e        return mb.
+00029ad0: 6578 7061 6e64 5f64 696d 7328 783d 7661  expand_dims(x=va
+00029ae0: 6c75 6573 5b30 5d2c 2061 7865 733d 5b30  lues[0], axes=[0
+00029af0: 5d2c 206e 616d 653d 6e61 6d65 290a 2020  ], name=name).  
+00029b00: 2020 2020 2020 7265 7475 726e 206d 622e        return mb.
+00029b10: 7374 6163 6b28 7661 6c75 6573 3d76 616c  stack(values=val
+00029b20: 7565 732c 2061 7869 733d 302c 206e 616d  ues, axis=0, nam
+00029b30: 653d 6e61 6d65 290a 0a20 2020 2069 6e70  e=name)..    inp
+00029b40: 7574 7320 3d20 5f67 6574 5f69 6e70 7574  uts = _get_input
+00029b50: 7328 636f 6e74 6578 742c 206e 6f64 652c  s(context, node,
+00029b60: 2065 7870 6563 7465 643d 3429 0a0a 2020   expected=4)..  
+00029b70: 2020 2320 4361 7365 2031 3a20 5573 696e    # Case 1: Usin
+00029b80: 6720 746f 7263 682e 7465 6e73 6f72 2074  g torch.tensor t
+00029b90: 6f20 6372 6561 7465 2061 2063 6f6e 7374  o create a const
+00029ba0: 2074 656e 736f 720a 2020 2020 2320 466f   tensor.    # Fo
+00029bb0: 7220 6578 616d 706c 653a 0a20 2020 2023  r example:.    #
+00029bc0: 2074 6f72 6368 2e74 656e 736f 7228 5b5b   torch.tensor([[
+00029bd0: 5b30 2c20 305d 2c20 5b30 2c20 3130 5d2c  [0, 0], [0, 10],
+00029be0: 205b 352c 2031 305d 2c20 5b35 2c20 305d   [5, 10], [5, 0]
+00029bf0: 5d5d 2c20 6474 7970 653d 746f 7263 682e  ]], dtype=torch.
+00029c00: 666c 6f61 7433 3229 0a20 2020 2076 616c  float32).    val
+00029c10: 203d 2069 6e70 7574 735b 305d 0a20 2020   = inputs[0].   
+00029c20: 2069 6620 6973 696e 7374 616e 6365 2876   if isinstance(v
+00029c30: 616c 2c20 6c69 7374 293a 0a20 2020 2020  al, list):.     
+00029c40: 2020 2063 6f6e 7465 7874 2e61 6464 285f     context.add(_
+00029c50: 6d61 6b65 5f74 656e 736f 7228 7661 6c2c  make_tensor(val,
+00029c60: 206e 6f64 652e 6e61 6d65 2c20 3129 290a   node.name, 1)).
+00029c70: 2020 2020 2020 2020 7265 7475 726e 0a0a          return..
+00029c80: 2020 2020 6966 2069 6e70 7574 735b 325d      if inputs[2]
+00029c90: 2069 7320 4e6f 6e65 3a0a 2020 2020 2020   is None:.      
+00029ca0: 2020 636f 6e74 6578 742e 6164 6428 6d62    context.add(mb
+00029cb0: 2e69 6465 6e74 6974 7928 783d 7661 6c2c  .identity(x=val,
+00029cc0: 206e 616d 653d 6e6f 6465 2e6e 616d 6529   name=node.name)
+00029cd0: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
+00029ce0: 0a0a 2020 2020 2320 4361 7365 2032 3a20  ..    # Case 2: 
+00029cf0: 4372 6561 7465 2061 2074 656e 736f 7220  Create a tensor 
+00029d00: 6669 6c6c 6564 2077 6974 6820 6120 7369  filled with a si
+00029d10: 6e67 6c65 2076 616c 7565 0a20 2020 2076  ngle value.    v
+00029d20: 616c 203d 2076 616c 2e76 616c 2020 2320  al = val.val  # 
+00029d30: 656c 656d 656e 7420 7661 6c20 746f 2066  element val to f
+00029d40: 696c 6c0a 2020 2020 6d73 675f 7072 6566  ill.    msg_pref
+00029d50: 6978 203d 2027 746f 7263 683a 3a74 656e  ix = 'torch::ten
+00029d60: 736f 7220 7b7d 2027 2e66 6f72 6d61 7428  sor {} '.format(
+00029d70: 6e6f 6465 2e6e 616d 6529 0a20 2020 2069  node.name).    i
+00029d80: 6620 7661 6c20 6973 204e 6f6e 653a 0a20  f val is None:. 
+00029d90: 2020 2020 2020 2072 6169 7365 2056 616c         raise Val
+00029da0: 7565 4572 726f 7228 6d73 675f 7072 6566  ueError(msg_pref
+00029db0: 6978 202b 2027 7661 6c20 6973 204e 6f6e  ix + 'val is Non
+00029dc0: 6527 290a 2020 2020 6474 7970 655f 7374  e').    dtype_st
+00029dd0: 7220 3d20 696e 7075 7473 5b31 5d2e 7661  r = inputs[1].va
+00029de0: 6c0a 2020 2020 6966 2064 7479 7065 5f73  l.    if dtype_s
+00029df0: 7472 2021 3d20 2266 7033 3222 3a0a 2020  tr != "fp32":.  
+00029e00: 2020 2020 2020 7261 6973 6520 4e6f 7449        raise NotI
+00029e10: 6d70 6c65 6d65 6e74 6564 4572 726f 7228  mplementedError(
+00029e20: 0a20 2020 2020 2020 2020 2020 206d 7367  .            msg
+00029e30: 5f70 7265 6669 7820 2b20 2255 6e73 7570  _prefix + "Unsup
+00029e40: 706f 7274 6564 2064 7479 7065 3a20 7b7d  ported dtype: {}
+00029e50: 222e 666f 726d 6174 2864 7479 7065 5f73  ".format(dtype_s
+00029e60: 7472 290a 2020 2020 2020 2020 290a 2020  tr).        ).  
+00029e70: 2020 2320 696e 7075 7473 5b33 5d20 6973    # inputs[3] is
+00029e80: 2061 2062 6f6f 6c20 286e 6f74 2073 7572   a bool (not sur
+00029e90: 6520 7768 6174 2069 7420 6973 290a 2020  e what it is).  
+00029ea0: 2020 7368 6170 6520 3d20 6d62 2e73 6861    shape = mb.sha
+00029eb0: 7065 2878 3d69 6e70 7574 735b 325d 2c20  pe(x=inputs[2], 
+00029ec0: 6e61 6d65 3d6e 6f64 652e 6e61 6d65 202b  name=node.name +
+00029ed0: 2022 5f73 6861 7065 2229 0a20 2020 2063   "_shape").    c
+00029ee0: 6f6e 7465 7874 2e61 6464 286d 622e 6669  ontext.add(mb.fi
+00029ef0: 6c6c 2873 6861 7065 3d73 6861 7065 2c20  ll(shape=shape, 
+00029f00: 7661 6c75 653d 7661 6c2c 206e 616d 653d  value=val, name=
+00029f10: 6e6f 6465 2e6e 616d 6529 290a 0a0a 2222  node.name))...""
+00029f20: 220a 5061 636b 2061 6e64 2075 6e70 6163  ".Pack and unpac
+00029f30: 6b20 6f70 2069 6e20 7079 746f 7263 682e  k op in pytorch.
+00029f40: 0a54 6865 2074 7970 6963 616c 2070 6174  .The typical pat
+00029f50: 7465 726e 2069 7320 6173 2066 6f6c 6c6f  tern is as follo
+00029f60: 7769 6e67 0a0a 3e3e 3e20 7365 7120 3d20  wing..>>> seq = 
+00029f70: 746f 7263 682e 7465 6e73 6f72 285b 5b31  torch.tensor([[1
+00029f80: 2c32 2c30 5d2c 205b 332c 302c 305d 2c20  ,2,0], [3,0,0], 
+00029f90: 5b34 2c35 2c36 5d5d 290a 3e3e 3e20 6c65  [4,5,6]]).>>> le
+00029fa0: 6e73 203d 205b 322c 2031 2c20 335d 0a3e  ns = [2, 1, 3].>
+00029fb0: 3e3e 2070 6163 6b65 6420 3d20 7061 636b  >> packed = pack
+00029fc0: 5f70 6164 6465 645f 7365 7175 656e 6365  _padded_sequence
+00029fd0: 2873 6571 2c20 6c65 6e73 2c20 6261 7463  (seq, lens, batc
+00029fe0: 685f 6669 7273 743d 5472 7565 2c20 656e  h_first=True, en
+00029ff0: 666f 7263 655f 736f 7274 6564 3d46 616c  force_sorted=Fal
+0002a000: 7365 290a 3e3e 3e20 7061 636b 6564 0a50  se).>>> packed.P
+0002a010: 6163 6b65 6453 6571 7565 6e63 6528 6461  ackedSequence(da
+0002a020: 7461 3d74 656e 736f 7228 5b34 2c20 312c  ta=tensor([4, 1,
+0002a030: 2033 2c20 352c 2032 2c20 365d 292c 2062   3, 5, 2, 6]), b
+0002a040: 6174 6368 5f73 697a 6573 3d74 656e 736f  atch_sizes=tenso
+0002a050: 7228 5b33 2c20 322c 2031 5d29 2c0a 2020  r([3, 2, 1]),.  
+0002a060: 2020 2020 2020 2020 2020 2020 2073 6f72               sor
+0002a070: 7465 645f 696e 6469 6365 733d 7465 6e73  ted_indices=tens
+0002a080: 6f72 285b 322c 2030 2c20 315d 292c 2075  or([2, 0, 1]), u
+0002a090: 6e73 6f72 7465 645f 696e 6469 6365 733d  nsorted_indices=
+0002a0a0: 7465 6e73 6f72 285b 312c 2032 2c20 305d  tensor([1, 2, 0]
+0002a0b0: 2929 0a3e 3e3e 2073 6571 5f75 6e70 6163  )).>>> seq_unpac
+0002a0c0: 6b65 642c 206c 656e 735f 756e 7061 636b  ked, lens_unpack
+0002a0d0: 6564 203d 2070 6164 5f70 6163 6b65 645f  ed = pad_packed_
+0002a0e0: 7365 7175 656e 6365 2870 6163 6b65 642c  sequence(packed,
+0002a0f0: 2062 6174 6368 5f66 6972 7374 3d54 7275   batch_first=Tru
+0002a100: 6529 0a3e 3e3e 2073 6571 5f75 6e70 6163  e).>>> seq_unpac
+0002a110: 6b65 640a 7465 6e73 6f72 285b 5b31 2c20  ked.tensor([[1, 
+0002a120: 322c 2030 5d2c 0a20 2020 2020 2020 205b  2, 0],.        [
+0002a130: 332c 2030 2c20 305d 2c0a 2020 2020 2020  3, 0, 0],.      
+0002a140: 2020 5b34 2c20 352c 2036 5d5d 290a 3e3e    [4, 5, 6]]).>>
+0002a150: 3e20 6c65 6e73 5f75 6e70 6163 6b65 640a  > lens_unpacked.
+0002a160: 7465 6e73 6f72 285b 322c 2031 2c20 335d  tensor([2, 1, 3]
+0002a170: 290a 0a73 6f75 7263 6520 6672 6f6d 2068  )..source from h
+0002a180: 7474 7073 3a2f 2f70 7974 6f72 6368 2e6f  ttps://pytorch.o
+0002a190: 7267 2f64 6f63 732f 7374 6162 6c65 2f67  rg/docs/stable/g
+0002a1a0: 656e 6572 6174 6564 2f74 6f72 6368 2e6e  enerated/torch.n
+0002a1b0: 6e2e 7574 696c 732e 726e 6e2e 7061 645f  n.utils.rnn.pad_
+0002a1c0: 7061 636b 6564 5f73 6571 7565 6e63 652e  packed_sequence.
+0002a1d0: 6874 6d6c 0a22 2222 0a0a 0a40 7265 6769  html."""...@regi
+0002a1e0: 7374 6572 5f74 6f72 6368 5f6f 700a 6465  ster_torch_op.de
+0002a1f0: 6620 5f70 6163 6b5f 7061 6464 6564 5f73  f _pack_padded_s
+0002a200: 6571 7565 6e63 6528 636f 6e74 6578 742c  equence(context,
+0002a210: 206e 6f64 6529 3a0a 2020 2020 2320 5468   node):.    # Th
+0002a220: 6520 696d 706c 656d 656e 7461 7469 6f6e  e implementation
+0002a230: 206f 6620 7468 6973 206f 7020 6973 206e   of this op is n
+0002a240: 6f74 2065 6666 6963 6965 6e74 2e20 5261  ot efficient. Ra
+0002a250: 6973 6520 6120 7761 726e 696e 672e 0a20  ise a warning.. 
+0002a260: 2020 206c 6f67 6765 722e 7761 726e 696e     logger.warnin
+0002a270: 6728 0a20 2020 2020 2020 2022 456e 636f  g(.        "Enco
+0002a280: 756e 7465 7265 6420 6120 5f70 6163 6b5f  untered a _pack_
+0002a290: 7061 6464 6564 5f73 6571 7565 6e63 6520  padded_sequence 
+0002a2a0: 6c61 7965 722e 2054 6865 2069 6d70 6c65  layer. The imple
+0002a2b0: 6d65 6e74 6174 696f 6e20 6f66 2074 7261  mentation of tra
+0002a2c0: 6e73 6c61 7469 6e67 2070 6163 6b2f 756e  nslating pack/un
+0002a2d0: 7061 636b 206f 705c 0a20 2020 2020 2020  pack op\.       
+0002a2e0: 2069 6e20 7079 746f 7263 6820 6973 206e   in pytorch is n
+0002a2f0: 6f74 2065 6666 6963 6965 6e74 2064 7565  ot efficient due
+0002a300: 2074 6f20 7468 6520 6375 7272 656e 7420   to the current 
+0002a310: 6c69 6d69 7461 7469 6f6e 206f 6620 436f  limitation of Co
+0002a320: 7265 204d 4c2e 2052 656d 6f76 696e 6720  re ML. Removing 
+0002a330: 7468 6520 7061 636b 2d75 6e70 6163 6b20  the pack-unpack 
+0002a340: 6c6f 6769 6320 5c0a 2020 2020 2020 2020  logic \.        
+0002a350: 616e 6420 7573 6520 6120 6669 7865 6420  and use a fixed 
+0002a360: 6261 7463 6820 7369 7a65 206d 6f64 656c  batch size model
+0002a370: 2069 7320 7265 636f 6d6d 656e 6465 642e   is recommended.
+0002a380: 220a 2020 2020 290a 0a20 2020 2069 6e70  ".    )..    inp
+0002a390: 7574 7320 3d20 5f67 6574 5f69 6e70 7574  uts = _get_input
+0002a3a0: 7328 636f 6e74 6578 742c 206e 6f64 652c  s(context, node,
+0002a3b0: 2065 7870 6563 7465 643d 3329 0a20 2020   expected=3).   
+0002a3c0: 2074 656e 736f 725f 6e61 6d65 2c20 6261   tensor_name, ba
+0002a3d0: 7463 685f 7369 7a65 735f 6e61 6d65 203d  tch_sizes_name =
+0002a3e0: 206e 6f64 652e 6f75 7470 7574 730a 2020   node.outputs.  
+0002a3f0: 2020 7465 6e73 6f72 5f69 6e70 7574 203d    tensor_input =
+0002a400: 2069 6e70 7574 735b 305d 0a20 2020 2062   inputs[0].    b
+0002a410: 6174 6368 5f73 697a 6573 203d 2069 6e70  atch_sizes = inp
+0002a420: 7574 735b 315d 0a20 2020 2062 6174 6368  uts[1].    batch
+0002a430: 5f66 6972 7374 203d 2069 6e70 7574 735b  _first = inputs[
+0002a440: 325d 2e76 616c 0a0a 2020 2020 2320 6279  2].val..    # by
+0002a450: 2061 7373 756d 696e 6720 7468 6174 2074   assuming that t
+0002a460: 6865 206f 7574 7075 7420 6f66 2074 6869  he output of thi
+0002a470: 7320 6f70 2069 7320 616c 7761 7973 2066  s op is always f
+0002a480: 6565 6420 696e 206c 7374 6d20 6c61 7965  eed in lstm laye
+0002a490: 722c 0a20 2020 2023 2077 6520 656e 666f  r,.    # we enfo
+0002a4a0: 7263 6520 7468 6520 6c61 796f 7574 2074  rce the layout t
+0002a4b0: 6f20 6265 2042 6174 6368 202a 2073 6571  o be Batch * seq
+0002a4c0: 5f6c 656e 6774 6820 2a20 4665 6174 7572  _length * Featur
+0002a4d0: 652e 0a20 2020 2069 6620 6e6f 7420 6261  e..    if not ba
+0002a4e0: 7463 685f 6669 7273 743a 0a20 2020 2020  tch_first:.     
+0002a4f0: 2020 2074 656e 736f 725f 696e 7075 7420     tensor_input 
+0002a500: 3d20 6d62 2e74 7261 6e73 706f 7365 2878  = mb.transpose(x
+0002a510: 3d74 656e 736f 725f 696e 7075 742c 2070  =tensor_input, p
+0002a520: 6572 6d3d 5b31 2c20 302c 2032 5d29 0a20  erm=[1, 0, 2]). 
+0002a530: 2020 2063 6f6e 7465 7874 2e61 6464 286d     context.add(m
+0002a540: 622e 6964 656e 7469 7479 2878 3d74 656e  b.identity(x=ten
+0002a550: 736f 725f 696e 7075 742c 206e 616d 653d  sor_input, name=
+0002a560: 7465 6e73 6f72 5f6e 616d 6529 290a 0a20  tensor_name)).. 
+0002a570: 2020 2023 2061 6464 2074 6865 2062 6174     # add the bat
+0002a580: 6368 5f73 697a 6573 2069 6e20 7468 6520  ch_sizes in the 
+0002a590: 636f 6e74 6578 742c 2073 6f20 7468 6174  context, so that
+0002a5a0: 205f 7061 645f 7061 636b 6564 5f73 6571   _pad_packed_seq
+0002a5b0: 7565 6e63 6520 6361 6e0a 2020 2020 2320  uence can.    # 
+0002a5c0: 6669 6e64 2069 7420 6c61 7465 722e 0a20  find it later.. 
+0002a5d0: 2020 2063 6f6e 7465 7874 2e61 6464 286d     context.add(m
+0002a5e0: 622e 6964 656e 7469 7479 2878 3d62 6174  b.identity(x=bat
+0002a5f0: 6368 5f73 697a 6573 2c20 6e61 6d65 3d62  ch_sizes, name=b
+0002a600: 6174 6368 5f73 697a 6573 5f6e 616d 6529  atch_sizes_name)
+0002a610: 290a 0a0a 4072 6567 6973 7465 725f 746f  )...@register_to
+0002a620: 7263 685f 6f70 0a64 6566 205f 7061 645f  rch_op.def _pad_
+0002a630: 7061 636b 6564 5f73 6571 7565 6e63 6528  packed_sequence(
+0002a640: 636f 6e74 6578 742c 206e 6f64 6529 3a0a  context, node):.
+0002a650: 2020 2020 2320 5468 6520 696d 706c 656d      # The implem
+0002a660: 656e 7461 7469 6f6e 206f 6620 7468 6973  entation of this
+0002a670: 206f 7020 6973 206e 6f74 2065 6666 6963   op is not effic
+0002a680: 6965 6e74 2e20 5261 6973 6520 6120 7761  ient. Raise a wa
+0002a690: 726e 696e 672e 0a20 2020 206c 6f67 6765  rning..    logge
+0002a6a0: 722e 7761 726e 696e 6728 0a20 2020 2020  r.warning(.     
+0002a6b0: 2020 2022 456e 636f 756e 7465 7265 6420     "Encountered 
+0002a6c0: 6120 5f70 6164 5f70 6163 6b65 645f 7365  a _pad_packed_se
+0002a6d0: 7175 656e 6365 206c 6179 6572 2e20 5468  quence layer. Th
+0002a6e0: 6520 696d 706c 656d 656e 7461 7469 6f6e  e implementation
+0002a6f0: 206f 6620 7472 616e 736c 6174 696e 6720   of translating 
+0002a700: 7061 636b 2f75 6e70 6163 6b20 6f70 5c0a  pack/unpack op\.
+0002a710: 2020 2020 2020 2020 696e 2070 7974 6f72          in pytor
+0002a720: 6368 2069 7320 6e6f 7420 6566 6669 6369  ch is not effici
+0002a730: 656e 7420 6475 6520 746f 2074 6865 2063  ent due to the c
+0002a740: 7572 7265 6e74 206c 696d 6974 6174 696f  urrent limitatio
+0002a750: 6e20 6f66 2043 6f72 6520 4d4c 2e20 5265  n of Core ML. Re
+0002a760: 6d6f 7669 6e67 2074 6865 2070 6163 6b2d  moving the pack-
+0002a770: 756e 7061 636b 206c 6f67 6963 205c 0a20  unpack logic \. 
+0002a780: 2020 2020 2020 2061 6e64 2075 7365 2061         and use a
+0002a790: 2066 6978 6564 2062 6174 6368 2073 697a   fixed batch siz
+0002a7a0: 6520 6d6f 6465 6c20 6973 2072 6563 6f6d  e model is recom
+0002a7b0: 6d65 6e64 6564 2e22 0a20 2020 2029 0a20  mended.".    ). 
+0002a7c0: 2020 2069 6e70 7574 7320 3d20 5f67 6574     inputs = _get
+0002a7d0: 5f69 6e70 7574 7328 636f 6e74 6578 742c  _inputs(context,
+0002a7e0: 206e 6f64 6529 0a0a 2020 2020 2320 7365   node)..    # se
+0002a7f0: 715f 6c65 6e67 7468 7320 6465 6e6f 7465  q_lengths denote
+0002a800: 7320 7468 6520 6163 7475 616c 2073 6571  s the actual seq
+0002a810: 7565 6e63 6520 6c65 6e67 7468 2066 6f72  uence length for
+0002a820: 2065 6163 6820 6261 7463 682e 0a20 2020   each batch..   
+0002a830: 2023 2070 6164 2064 656e 6f74 6573 2074   # pad denotes t
+0002a840: 6865 2070 6164 6469 6e67 2076 616c 7565  he padding value
+0002a850: 2066 6f72 2074 686f 7365 2064 6174 6120   for those data 
+0002a860: 7768 6963 6820 6861 7320 7368 6f72 7465  which has shorte
+0002a870: 7220 6c65 6e67 7468 2e0a 2020 2020 696e  r length..    in
+0002a880: 7075 745f 7465 6e73 6f72 203d 2069 6e70  put_tensor = inp
+0002a890: 7574 735b 305d 0a20 2020 2073 6571 5f6c  uts[0].    seq_l
+0002a8a0: 656e 6774 6873 203d 2069 6e70 7574 735b  engths = inputs[
+0002a8b0: 315d 0a20 2020 2062 6174 6368 5f66 6972  1].    batch_fir
+0002a8c0: 7374 203d 2069 6e70 7574 735b 325d 2e76  st = inputs[2].v
+0002a8d0: 616c 0a20 2020 2070 6164 203d 2069 6e70  al.    pad = inp
+0002a8e0: 7574 735b 335d 2e76 616c 0a0a 2020 2020  uts[3].val..    
+0002a8f0: 2320 7765 206f 6e6c 7920 7375 7070 6f72  # we only suppor
+0002a900: 7420 7061 636b 2061 6e64 2075 6e70 6163  t pack and unpac
+0002a910: 6b20 7472 616e 736c 6174 696f 6e20 666f  k translation fo
+0002a920: 7220 7374 6174 6963 2074 656e 736f 7220  r static tensor 
+0002a930: 7368 6170 652c 0a20 2020 2023 2069 2e65  shape,.    # i.e
+0002a940: 2e2c 2074 6865 2074 6872 6565 2064 696d  ., the three dim
+0002a950: 656e 7369 6f6e 7320 6172 6520 616c 6c20  ensions are all 
+0002a960: 6b6e 6f77 6e20 6475 7269 6e67 2063 6f6d  known during com
+0002a970: 7069 6c65 2074 696d 652e 0a20 2020 2069  pile time..    i
+0002a980: 6620 616e 7928 5b69 735f 7379 6d62 6f6c  f any([is_symbol
+0002a990: 6963 2878 2920 666f 7220 7820 696e 2069  ic(x) for x in i
+0002a9a0: 6e70 7574 5f74 656e 736f 722e 7368 6170  nput_tensor.shap
+0002a9b0: 655d 293a 0a20 2020 2020 2020 2072 6169  e]):.        rai
+0002a9c0: 7365 204e 6f74 496d 706c 656d 656e 7465  se NotImplemente
+0002a9d0: 6445 7272 6f72 2822 4f6e 6c79 2073 7461  dError("Only sta
+0002a9e0: 7469 6320 7368 6170 6520 6f66 2050 6163  tic shape of Pac
+0002a9f0: 6b65 6453 6571 7565 6e63 6520 6f62 6a65  kedSequence obje
+0002aa00: 6374 2069 7320 7375 7070 6f72 7465 642e  ct is supported.
+0002aa10: 2229 0a0a 2020 2020 2320 7468 6520 696e  ")..    # the in
+0002aa20: 7075 7420 616c 7761 7973 2068 6173 2062  put always has b
+0002aa30: 6174 6368 2066 6972 7374 206c 6179 6f75  atch first layou
+0002aa40: 742e 0a20 2020 2023 2070 6164 6465 645f  t..    # padded_
+0002aa50: 7365 715f 6c65 6e20 6465 6e6f 7465 7320  seq_len denotes 
+0002aa60: 7468 6520 6d61 7869 6d75 6d20 7365 7175  the maximum sequ
+0002aa70: 656e 6365 206c 656e 6774 6820 6163 726f  ence length acro
+0002aa80: 7373 2062 6174 6368 6573 2e0a 2020 2020  ss batches..    
+0002aa90: 6261 7463 682c 2070 6164 6465 645f 7365  batch, padded_se
+0002aaa0: 715f 6c65 6e2c 2069 6e70 7574 5f64 696d  q_len, input_dim
+0002aab0: 203d 2069 6e70 7574 5f74 656e 736f 722e   = input_tensor.
+0002aac0: 7368 6170 650a 2020 2020 6173 7365 7274  shape.    assert
+0002aad0: 2073 6571 5f6c 656e 6774 6873 2e72 616e   seq_lengths.ran
+0002aae0: 6b20 3d3d 2031 0a20 2020 2061 7373 6572  k == 1.    asser
+0002aaf0: 7420 6261 7463 6820 3d3d 2073 6571 5f6c  t batch == seq_l
+0002ab00: 656e 6774 6873 2e73 6861 7065 5b30 5d0a  engths.shape[0].
+0002ab10: 0a20 2020 2023 2077 6520 6974 6572 6174  .    # we iterat
+0002ab20: 6520 7468 726f 7567 6820 7468 6520 6261  e through the ba
+0002ab30: 7463 682c 2070 6164 2065 6163 6820 6461  tch, pad each da
+0002ab40: 7461 2c20 616e 6420 636f 6e63 6174 6520  ta, and concate 
+0002ab50: 7468 656d 2069 6e74 6f20 6120 7369 6e67  them into a sing
+0002ab60: 6c65 2074 656e 736f 7220 696e 2074 6865  le tensor in the
+0002ab70: 2065 6e64 2c0a 2020 2020 2320 7768 6963   end,.    # whic
+0002ab80: 6820 6973 2074 6865 2074 6f74 616c 5f74  h is the total_t
+0002ab90: 656e 736f 7220 6865 7265 2e0a 2020 2020  ensor here..    
+0002aba0: 2320 5361 7920 7468 6520 696e 7075 745f  # Say the input_
+0002abb0: 7465 6e73 6f72 2068 6173 2073 6861 7065  tensor has shape
+0002abc0: 205b 6261 7463 6820 2c20 7061 6464 6564   [batch , padded
+0002abd0: 5f73 6571 5f6c 656e 2c20 696e 7075 745f  _seq_len, input_
+0002abe0: 6469 6d5d 2c0a 2020 2020 2320 616e 6420  dim],.    # and 
+0002abf0: 7468 6520 7365 715f 6c65 6e67 7468 7320  the seq_lengths 
+0002ac00: 3d20 5b6c 656e 5f31 2c20 6c65 6e5f 322c  = [len_1, len_2,
+0002ac10: 206c 656e 5f33 5d2e 0a20 2020 2023 204e   len_3]..    # N
+0002ac20: 6f74 6520 7468 6174 2069 6e20 7079 746f  ote that in pyto
+0002ac30: 7263 682c 2074 6865 2073 6571 5f6c 656e  rch, the seq_len
+0002ac40: 6774 6873 206d 7573 7420 6265 2064 6563  gths must be dec
+0002ac50: 7265 6173 696e 6720 696e 206f 7264 6572  reasing in order
+0002ac60: 2c20 6c65 6e5f 3120 3e3d 206c 656e 5f32  , len_1 >= len_2
+0002ac70: 203e 3d20 6c65 6e5f 332e 0a20 2020 2074   >= len_3..    t
+0002ac80: 6f74 616c 5f74 656e 736f 7220 3d20 5b5d  otal_tensor = []
+0002ac90: 0a0a 2020 2020 666f 7220 6920 696e 2072  ..    for i in r
+0002aca0: 616e 6765 2862 6174 6368 293a 0a20 2020  ange(batch):.   
+0002acb0: 2020 2020 2023 2073 6c69 6365 2066 6f72       # slice for
+0002acc0: 2065 6163 6820 6461 7461 0a20 2020 2020   each data.     
+0002acd0: 2020 2023 2078 2068 6173 2073 6861 7065     # x has shape
+0002ace0: 205b 7061 6464 6564 5f73 6571 5f6c 656e   [padded_seq_len
+0002acf0: 2c20 696e 7075 745f 6469 6d5d 0a20 2020  , input_dim].   
+0002ad00: 2020 2020 2078 203d 206d 622e 736c 6963       x = mb.slic
+0002ad10: 655f 6279 5f69 6e64 6578 280a 2020 2020  e_by_index(.    
+0002ad20: 2020 2020 2020 2020 783d 696e 7075 745f          x=input_
+0002ad30: 7465 6e73 6f72 2c0a 2020 2020 2020 2020  tensor,.        
+0002ad40: 2020 2020 6265 6769 6e3d 5b69 2c20 302c      begin=[i, 0,
+0002ad50: 2030 5d2c 0a20 2020 2020 2020 2020 2020   0],.           
+0002ad60: 2065 6e64 3d5b 302c 2030 2c20 305d 2c0a   end=[0, 0, 0],.
+0002ad70: 2020 2020 2020 2020 2020 2020 7374 7269              stri
+0002ad80: 6465 3d5b 312c 2031 2c20 315d 2c0a 2020  de=[1, 1, 1],.  
+0002ad90: 2020 2020 2020 2020 2020 6265 6769 6e5f            begin_
+0002ada0: 6d61 736b 3d5b 4661 6c73 652c 2054 7275  mask=[False, Tru
+0002adb0: 652c 2054 7275 655d 2c0a 2020 2020 2020  e, True],.      
+0002adc0: 2020 2020 2020 656e 645f 6d61 736b 3d5b        end_mask=[
+0002add0: 4661 6c73 652c 2054 7275 652c 2054 7275  False, True, Tru
+0002ade0: 655d 2c0a 2020 2020 2020 2020 2020 2020  e],.            
+0002adf0: 7371 7565 657a 655f 6d61 736b 3d5b 5472  squeeze_mask=[Tr
+0002ae00: 7565 2c20 4661 6c73 652c 2046 616c 7365  ue, False, False
+0002ae10: 5d2c 0a20 2020 2020 2020 2029 0a0a 2020  ],.        )..  
+0002ae20: 2020 2020 2020 2320 6765 7420 7468 6520        # get the 
+0002ae30: 756e 7061 6464 6564 2073 6571 7565 6e63  unpadded sequenc
+0002ae40: 652c 0a20 2020 2020 2020 2023 2069 6620  e,.        # if 
+0002ae50: 7468 6520 756e 7061 6464 6564 2073 6571  the unpadded seq
+0002ae60: 7565 6e63 6520 6861 7320 6c65 6e67 7468  uence has length
+0002ae70: 2073 6571 5f6c 656e 6774 682c 0a20 2020   seq_length,.   
+0002ae80: 2020 2020 2023 2078 2077 6f75 6c64 2068       # x would h
+0002ae90: 6176 6520 7368 6170 6520 5b73 6571 5f6c  ave shape [seq_l
+0002aea0: 656e 6774 682c 2069 6e70 7574 5f64 696d  ength, input_dim
+0002aeb0: 5d2e 0a20 2020 2020 2020 2023 2046 6f72  ]..        # For
+0002aec0: 2065 7861 6d70 6c65 2c20 7468 6520 6669   example, the fi
+0002aed0: 7273 7420 6461 7461 2077 6f75 6c64 2072  rst data would r
+0002aee0: 6573 756c 7420 696e 2061 205b 6c65 6e5f  esult in a [len_
+0002aef0: 312c 2069 6e70 7574 5f64 696d 5d20 7465  1, input_dim] te
+0002af00: 6e73 6f72 2e0a 2020 2020 2020 2020 7365  nsor..        se
+0002af10: 715f 6c65 6e67 7468 203d 206d 622e 6361  q_length = mb.ca
+0002af20: 7374 2878 3d76 616c 7565 5f61 7428 7365  st(x=value_at(se
+0002af30: 715f 6c65 6e67 7468 732c 2069 292c 2064  q_lengths, i), d
+0002af40: 7479 7065 3d22 696e 7433 3222 290a 2020  type="int32").  
+0002af50: 2020 2020 2020 636f 6e63 6174 655f 7661        concate_va
+0002af60: 6c75 6573 203d 205b 7365 715f 6c65 6e67  lues = [seq_leng
+0002af70: 7468 2c20 696e 7075 745f 6469 6d5d 0a20  th, input_dim]. 
+0002af80: 2020 2020 2020 2065 6e64 5f69 6e64 6578         end_index
+0002af90: 203d 206d 622e 636f 6e63 6174 2876 616c   = mb.concat(val
+0002afa0: 7565 733d 636f 6e63 6174 655f 7661 6c75  ues=concate_valu
+0002afb0: 6573 2c20 6178 6973 3d30 290a 2020 2020  es, axis=0).    
+0002afc0: 2020 2020 7820 3d20 6d62 2e73 6c69 6365      x = mb.slice
+0002afd0: 5f62 795f 696e 6465 7828 0a20 2020 2020  _by_index(.     
+0002afe0: 2020 2020 2020 2078 3d78 2c0a 2020 2020         x=x,.    
+0002aff0: 2020 2020 2020 2020 6265 6769 6e3d 5b30          begin=[0
+0002b000: 2c20 305d 2c0a 2020 2020 2020 2020 2020  , 0],.          
+0002b010: 2020 656e 643d 656e 645f 696e 6465 782c    end=end_index,
+0002b020: 0a20 2020 2020 2020 2020 2020 2073 7472  .            str
+0002b030: 6964 653d 5b31 2c20 315d 2c0a 2020 2020  ide=[1, 1],.    
+0002b040: 2020 2020 2020 2020 6265 6769 6e5f 6d61          begin_ma
+0002b050: 736b 3d5b 5472 7565 2c20 5472 7565 5d2c  sk=[True, True],
+0002b060: 0a20 2020 2020 2020 2020 2020 2065 6e64  .            end
+0002b070: 5f6d 6173 6b3d 5b46 616c 7365 2c20 5472  _mask=[False, Tr
+0002b080: 7565 5d2c 0a20 2020 2020 2020 2029 0a0a  ue],.        )..
+0002b090: 2020 2020 2020 2020 2320 6765 7420 7468          # get th
+0002b0a0: 6520 7061 6464 696e 6720 7061 7274 206f  e padding part o
+0002b0b0: 6620 7468 6520 6461 7461 0a20 2020 2020  f the data.     
+0002b0c0: 2020 2023 204e 6f74 6520 7468 6174 2077     # Note that w
+0002b0d0: 6520 616c 7761 7973 2061 6464 206f 6e65  e always add one
+0002b0e0: 2064 756d 6d79 2070 6164 6469 6e67 2069   dummy padding i
+0002b0f0: 6e20 7468 6520 656e 6420 7769 7468 2073  n the end with s
+0002b100: 6861 7065 205b 7061 6464 6564 5f73 6571  hape [padded_seq
+0002b110: 5f6c 656e 202d 2073 6571 5f6c 656e 6774  _len - seq_lengt
+0002b120: 6820 2b20 312c 2069 6e70 7574 5f64 696d  h + 1, input_dim
+0002b130: 5d2e 0a20 2020 2020 2020 2023 2054 6865  ]..        # The
+0002b140: 2072 6561 736f 6e20 6973 2074 6861 7420   reason is that 
+0002b150: 666f 7220 7468 6520 6361 7365 2077 6865  for the case whe
+0002b160: 6e20 7365 715f 6c65 6e67 7468 203d 2070  n seq_length = p
+0002b170: 6164 6465 645f 7365 715f 6c65 6e2c 0a20  added_seq_len,. 
+0002b180: 2020 2020 2020 2023 2063 6f72 656d 6c20         # coreml 
+0002b190: 6361 6e6e 6f74 2068 616e 646c 6520 7468  cannot handle th
+0002b1a0: 6520 656d 7074 7920 7465 6e73 6f72 2e0a  e empty tensor..
+0002b1b0: 2020 2020 2020 2020 7061 645f 6c65 6e67          pad_leng
+0002b1c0: 7468 203d 206d 622e 7375 6228 783d 7061  th = mb.sub(x=pa
+0002b1d0: 6464 6564 5f73 6571 5f6c 656e 202b 2031  dded_seq_len + 1
+0002b1e0: 2c20 793d 7365 715f 6c65 6e67 7468 290a  , y=seq_length).
+0002b1f0: 2020 2020 2020 2020 636f 6e63 6174 655f          concate_
+0002b200: 7661 6c75 6573 203d 205b 7061 645f 6c65  values = [pad_le
+0002b210: 6e67 7468 2c20 696e 7075 745f 6469 6d5d  ngth, input_dim]
+0002b220: 0a20 2020 2020 2020 2073 6861 7065 203d  .        shape =
+0002b230: 206d 622e 636f 6e63 6174 2876 616c 7565   mb.concat(value
+0002b240: 733d 636f 6e63 6174 655f 7661 6c75 6573  s=concate_values
+0002b250: 2c20 6178 6973 3d30 290a 2020 2020 2020  , axis=0).      
+0002b260: 2020 7061 645f 7661 6c75 6573 203d 206d    pad_values = m
+0002b270: 622e 6669 6c6c 2873 6861 7065 3d73 6861  b.fill(shape=sha
+0002b280: 7065 2c20 7661 6c75 653d 7061 6429 0a0a  pe, value=pad)..
+0002b290: 2020 2020 2020 2020 2320 636f 6e63 6174          # concat
+0002b2a0: 6520 7468 6520 756e 7061 6464 6564 2073  e the unpadded s
+0002b2b0: 6571 7565 6e63 6520 616e 6420 7468 6520  equence and the 
+0002b2c0: 7061 6464 696e 6720 6461 7461 0a20 2020  padding data.   
+0002b2d0: 2020 2020 2023 2074 6865 2072 6573 756c       # the resul
+0002b2e0: 7469 6e67 2074 656e 736f 7220 776f 756c  ting tensor woul
+0002b2f0: 6420 6861 7665 2073 6861 7065 205b 7061  d have shape [pa
+0002b300: 6464 6564 5f73 6571 5f6c 656e 202b 2031  dded_seq_len + 1
+0002b310: 2c20 696e 7075 745f 6469 6d5d 0a20 2020  , input_dim].   
+0002b320: 2020 2020 2078 2c20 7061 645f 7661 6c75       x, pad_valu
+0002b330: 6573 203d 2070 726f 6d6f 7465 5f69 6e70  es = promote_inp
+0002b340: 7574 5f64 7479 7065 7328 5b78 2c20 7061  ut_dtypes([x, pa
+0002b350: 645f 7661 6c75 6573 5d29 0a20 2020 2020  d_values]).     
+0002b360: 2020 2063 6f6e 6361 7465 5f76 616c 7565     concate_value
+0002b370: 7320 3d20 5b78 2c20 7061 645f 7661 6c75  s = [x, pad_valu
+0002b380: 6573 5d0a 2020 2020 2020 2020 6164 645f  es].        add_
+0002b390: 7661 6c75 6573 203d 206d 622e 636f 6e63  values = mb.conc
+0002b3a0: 6174 2876 616c 7565 733d 636f 6e63 6174  at(values=concat
+0002b3b0: 655f 7661 6c75 6573 2c20 6178 6973 3d30  e_values, axis=0
+0002b3c0: 290a 0a20 2020 2020 2020 2023 2074 7269  )..        # tri
+0002b3d0: 6d20 7468 6520 6475 6d6d 7920 7061 6464  m the dummy padd
+0002b3e0: 696e 6720 7465 6e73 6f72 0a20 2020 2020  ing tensor.     
+0002b3f0: 2020 2023 2074 6865 206f 7574 7075 7420     # the output 
+0002b400: 776f 756c 6420 6861 7665 2073 6870 6165  would have shpae
+0002b410: 205b 7061 6464 6564 5f73 6571 5f6c 656e   [padded_seq_len
+0002b420: 2c20 696e 7075 745f 6469 6d5d 0a20 2020  , input_dim].   
+0002b430: 2020 2020 2078 203d 206d 622e 736c 6963       x = mb.slic
+0002b440: 655f 6279 5f69 6e64 6578 280a 2020 2020  e_by_index(.    
+0002b450: 2020 2020 2020 2020 783d 6164 645f 7661          x=add_va
+0002b460: 6c75 6573 2c0a 2020 2020 2020 2020 2020  lues,.          
+0002b470: 2020 6265 6769 6e3d 5b30 2c20 305d 2c0a    begin=[0, 0],.
+0002b480: 2020 2020 2020 2020 2020 2020 656e 643d              end=
+0002b490: 5b70 6164 6465 645f 7365 715f 6c65 6e2c  [padded_seq_len,
+0002b4a0: 2030 5d2c 0a20 2020 2020 2020 2020 2020   0],.           
+0002b4b0: 2073 7472 6964 653d 5b31 2c20 315d 2c0a   stride=[1, 1],.
+0002b4c0: 2020 2020 2020 2020 2020 2020 6265 6769              begi
+0002b4d0: 6e5f 6d61 736b 3d5b 5472 7565 2c20 5472  n_mask=[True, Tr
+0002b4e0: 7565 5d2c 0a20 2020 2020 2020 2020 2020  ue],.           
+0002b4f0: 2065 6e64 5f6d 6173 6b3d 5b46 616c 7365   end_mask=[False
+0002b500: 2c20 5472 7565 5d2c 0a20 2020 2020 2020  , True],.       
+0002b510: 2029 0a0a 2020 2020 2020 2020 2320 6164   )..        # ad
+0002b520: 6420 6974 2074 6f20 746f 7461 6c20 7465  d it to total te
+0002b530: 6e73 6f72 0a20 2020 2020 2020 2074 6f74  nsor.        tot
+0002b540: 616c 5f74 656e 736f 722e 6170 7065 6e64  al_tensor.append
+0002b550: 2878 290a 0a20 2020 2023 2074 7261 6e73  (x)..    # trans
+0002b560: 706f 7365 2074 6865 2074 656e 736f 7220  pose the tensor 
+0002b570: 6966 2062 6174 6368 5f66 6972 7374 203d  if batch_first =
+0002b580: 2046 616c 7365 0a20 2020 2069 6620 6e6f   False.    if no
+0002b590: 7420 6261 7463 685f 6669 7273 743a 0a20  t batch_first:. 
+0002b5a0: 2020 2020 2020 2078 203d 206d 622e 7374         x = mb.st
+0002b5b0: 6163 6b28 7661 6c75 6573 3d74 6f74 616c  ack(values=total
+0002b5c0: 5f74 656e 736f 722c 2061 7869 733d 3029  _tensor, axis=0)
+0002b5d0: 0a20 2020 2020 2020 2078 203d 206d 622e  .        x = mb.
+0002b5e0: 7472 616e 7370 6f73 6528 783d 782c 2070  transpose(x=x, p
+0002b5f0: 6572 6d3d 5b31 2c20 302c 2032 5d2c 206e  erm=[1, 0, 2], n
+0002b600: 616d 653d 6e6f 6465 2e6e 616d 6529 0a20  ame=node.name). 
+0002b610: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
+0002b620: 2078 203d 206d 622e 7374 6163 6b28 7661   x = mb.stack(va
+0002b630: 6c75 6573 3d74 6f74 616c 5f74 656e 736f  lues=total_tenso
+0002b640: 722c 2061 7869 733d 302c 206e 616d 653d  r, axis=0, name=
+0002b650: 6e6f 6465 2e6e 616d 6529 0a0a 2020 2020  node.name)..    
+0002b660: 636f 6e74 6578 742e 6164 6428 7829 0a0a  context.add(x)..
+0002b670: 0a40 7265 6769 7374 6572 5f74 6f72 6368  .@register_torch
+0002b680: 5f6f 700a 6465 6620 6c6f 6731 3028 636f  _op.def log10(co
+0002b690: 6e74 6578 742c 206e 6f64 6529 3a0a 2020  ntext, node):.  
+0002b6a0: 2020 696e 7075 7473 203d 205f 6765 745f    inputs = _get_
+0002b6b0: 696e 7075 7473 2863 6f6e 7465 7874 2c20  inputs(context, 
+0002b6c0: 6e6f 6465 290a 2020 2020 7820 3d20 696e  node).    x = in
+0002b6d0: 7075 7473 5b30 5d0a 2020 2020 6c6f 675f  puts[0].    log_
+0002b6e0: 7820 3d20 6d62 2e6c 6f67 2878 3d78 290a  x = mb.log(x=x).
+0002b6f0: 2020 2020 636f 6e74 6578 742e 6164 6428      context.add(
+0002b700: 6d62 2e6d 756c 2878 3d6c 6f67 5f78 2c20  mb.mul(x=log_x, 
+0002b710: 793d 3120 2f20 5f6e 702e 6c6f 6728 3130  y=1 / _np.log(10
+0002b720: 2e30 2929 2c20 6e6f 6465 2e6e 616d 6529  .0)), node.name)
+0002b730: 0a0a 0a40 7265 6769 7374 6572 5f74 6f72  ...@register_tor
+0002b740: 6368 5f6f 700a 6465 6620 6c6f 6732 2863  ch_op.def log2(c
+0002b750: 6f6e 7465 7874 2c20 6e6f 6465 293a 0a20  ontext, node):. 
+0002b760: 2020 2069 6e70 7574 7320 3d20 5f67 6574     inputs = _get
+0002b770: 5f69 6e70 7574 7328 636f 6e74 6578 742c  _inputs(context,
+0002b780: 206e 6f64 6529 0a20 2020 2078 203d 2069   node).    x = i
+0002b790: 6e70 7574 735b 305d 0a20 2020 206c 6f67  nputs[0].    log
+0002b7a0: 5f78 203d 206d 622e 6c6f 6728 783d 7829  _x = mb.log(x=x)
+0002b7b0: 0a20 2020 2063 6f6e 7465 7874 2e61 6464  .    context.add
+0002b7c0: 286d 622e 6d75 6c28 783d 6c6f 675f 782c  (mb.mul(x=log_x,
+0002b7d0: 2079 3d31 202f 205f 6e70 2e6c 6f67 2832   y=1 / _np.log(2
+0002b7e0: 2e30 2929 2c20 6e6f 6465 2e6e 616d 6529  .0)), node.name)
+0002b7f0: 0a0a 0a40 7265 6769 7374 6572 5f74 6f72  ...@register_tor
+0002b800: 6368 5f6f 700a 6465 6620 666c 6970 2863  ch_op.def flip(c
+0002b810: 6f6e 7465 7874 2c20 6e6f 6465 293a 0a20  ontext, node):. 
+0002b820: 2020 2069 6e70 7574 7320 3d20 5f67 6574     inputs = _get
+0002b830: 5f69 6e70 7574 7328 636f 6e74 6578 742c  _inputs(context,
+0002b840: 206e 6f64 652c 2065 7870 6563 7465 643d   node, expected=
+0002b850: 3229 0a20 2020 2078 203d 206d 622e 7265  2).    x = mb.re
+0002b860: 7665 7273 6528 783d 696e 7075 7473 5b30  verse(x=inputs[0
+0002b870: 5d2c 2061 7865 733d 696e 7075 7473 5b31  ], axes=inputs[1
+0002b880: 5d2c 206e 616d 653d 6e6f 6465 2e6e 616d  ], name=node.nam
+0002b890: 6529 0a20 2020 2063 6f6e 7465 7874 2e61  e).    context.a
+0002b8a0: 6464 2878 2c20 6e6f 6465 2e6e 616d 6529  dd(x, node.name)
+0002b8b0: 0a0a 0a40 7265 6769 7374 6572 5f74 6f72  ...@register_tor
+0002b8c0: 6368 5f6f 7028 746f 7263 685f 616c 6961  ch_op(torch_alia
+0002b8d0: 733d 5b22 7265 666c 6563 7469 6f6e 5f70  s=["reflection_p
+0002b8e0: 6164 3164 225d 290a 6465 6620 7265 666c  ad1d"]).def refl
+0002b8f0: 6563 7469 6f6e 5f70 6164 3264 2863 6f6e  ection_pad2d(con
+0002b900: 7465 7874 2c20 6e6f 6465 293a 0a20 2020  text, node):.   
+0002b910: 2069 6e70 7574 7320 3d20 5f67 6574 5f69   inputs = _get_i
+0002b920: 6e70 7574 7328 636f 6e74 6578 742c 206e  nputs(context, n
+0002b930: 6f64 6529 0a20 2020 2078 203d 2069 6e70  ode).    x = inp
+0002b940: 7574 735b 305d 0a20 2020 2074 6f72 6368  uts[0].    torch
+0002b950: 5f70 6164 203d 2069 6e70 7574 735b 315d  _pad = inputs[1]
+0002b960: 2e76 616c 0a20 2020 2070 6164 5f66 6c69  .val.    pad_fli
+0002b970: 7070 6564 203d 2074 6f72 6368 5f70 6164  pped = torch_pad
+0002b980: 2e72 6573 6861 7065 2828 2d31 2c20 3229  .reshape((-1, 2)
+0002b990: 295b 3a3a 2d31 5d2e 7261 7665 6c28 290a  )[::-1].ravel().
+0002b9a0: 2020 2020 7061 6420 3d20 5f6e 702e 7061      pad = _np.pa
+0002b9b0: 6428 7061 645f 666c 6970 7065 642c 2028  d(pad_flipped, (
+0002b9c0: 6c65 6e28 782e 7368 6170 6529 202a 2032  len(x.shape) * 2
+0002b9d0: 202d 206c 656e 2870 6164 5f66 6c69 7070   - len(pad_flipp
+0002b9e0: 6564 292c 2030 2929 0a20 2020 2063 6f6e  ed), 0)).    con
+0002b9f0: 7465 7874 2e61 6464 286d 622e 7061 6428  text.add(mb.pad(
+0002ba00: 783d 782c 2070 6164 3d70 6164 2c20 6d6f  x=x, pad=pad, mo
+0002ba10: 6465 3d27 7265 666c 6563 7427 292c 206e  de='reflect'), n
+0002ba20: 6f64 652e 6e61 6d65 290a 0a0a 4072 6567  ode.name)...@reg
+0002ba30: 6973 7465 725f 746f 7263 685f 6f70 2874  ister_torch_op(t
+0002ba40: 6f72 6368 5f61 6c69 6173 3d5b 2272 6570  orch_alias=["rep
+0002ba50: 6c69 6361 7469 6f6e 5f70 6164 3164 225d  lication_pad1d"]
+0002ba60: 290a 6465 6620 7265 706c 6963 6174 696f  ).def replicatio
+0002ba70: 6e5f 7061 6432 6428 636f 6e74 6578 742c  n_pad2d(context,
+0002ba80: 206e 6f64 6529 3a0a 2020 2020 696e 7075   node):.    inpu
+0002ba90: 7473 203d 205f 6765 745f 696e 7075 7473  ts = _get_inputs
+0002baa0: 2863 6f6e 7465 7874 2c20 6e6f 6465 290a  (context, node).
+0002bab0: 2020 2020 7820 3d20 696e 7075 7473 5b30      x = inputs[0
+0002bac0: 5d0a 2020 2020 746f 7263 685f 7061 6420  ].    torch_pad 
+0002bad0: 3d20 696e 7075 7473 5b31 5d2e 7661 6c0a  = inputs[1].val.
+0002bae0: 2020 2020 7061 645f 666c 6970 7065 6420      pad_flipped 
+0002baf0: 3d20 746f 7263 685f 7061 642e 7265 7368  = torch_pad.resh
+0002bb00: 6170 6528 282d 312c 2032 2929 5b3a 3a2d  ape((-1, 2))[::-
+0002bb10: 315d 2e72 6176 656c 2829 0a20 2020 2070  1].ravel().    p
+0002bb20: 6164 203d 205f 6e70 2e70 6164 2870 6164  ad = _np.pad(pad
+0002bb30: 5f66 6c69 7070 6564 2c20 286c 656e 2878  _flipped, (len(x
+0002bb40: 2e73 6861 7065 2920 2a20 3220 2d20 6c65  .shape) * 2 - le
+0002bb50: 6e28 7061 645f 666c 6970 7065 6429 2c20  n(pad_flipped), 
+0002bb60: 3029 290a 2020 2020 636f 6e74 6578 742e  0)).    context.
+0002bb70: 6164 6428 6d62 2e70 6164 2878 3d78 2c20  add(mb.pad(x=x, 
+0002bb80: 7061 643d 7061 642c 206d 6f64 653d 2772  pad=pad, mode='r
+0002bb90: 6570 6c69 6361 7465 2729 2c20 6e6f 6465  eplicate'), node
+0002bba0: 2e6e 616d 6529 0a0a 0a64 6566 205f 6272  .name)...def _br
+0002bbb0: 6f61 6463 6173 745f 7465 6e73 6f72 7328  oadcast_tensors(
+0002bbc0: 7465 6e73 6f72 7329 3a0a 2020 2020 6465  tensors):.    de
+0002bbd0: 6620 5f73 6f6c 7665 5f62 726f 6164 6361  f _solve_broadca
+0002bbe0: 7374 5f73 6861 7065 2873 6861 7065 7329  st_shape(shapes)
+0002bbf0: 3a0a 2020 2020 2020 2020 7261 6e6b 203d  :.        rank =
+0002bc00: 205f 6e70 2e6d 6178 285b 6c65 6e28 7368   _np.max([len(sh
+0002bc10: 6170 6529 2066 6f72 2073 6861 7065 2069  ape) for shape i
+0002bc20: 6e20 7368 6170 6573 5d29 0a20 2020 2020  n shapes]).     
+0002bc30: 2020 2073 6861 7065 7320 3d20 5b5b 315d     shapes = [[1]
+0002bc40: 202a 2028 7261 6e6b 202d 206c 656e 2873   * (rank - len(s
+0002bc50: 6861 7065 2929 202b 2073 6861 7065 2066  hape)) + shape f
+0002bc60: 6f72 2073 6861 7065 2069 6e20 7368 6170  or shape in shap
+0002bc70: 6573 5d0a 2020 2020 2020 2020 7265 7375  es].        resu
+0002bc80: 6c74 5f73 6861 7065 203d 205b 5d0a 2020  lt_shape = [].  
+0002bc90: 2020 2020 2020 666f 7220 6920 696e 2072        for i in r
+0002bca0: 616e 6765 2872 616e 6b29 3a0a 2020 2020  ange(rank):.    
+0002bcb0: 2020 2020 2020 2020 6469 6d73 203d 205b          dims = [
+0002bcc0: 7368 6170 6573 5b6a 5d5b 695d 2066 6f72  shapes[j][i] for
+0002bcd0: 206a 2069 6e20 7261 6e67 6528 6c65 6e28   j in range(len(
+0002bce0: 7465 6e73 6f72 7329 295d 0a20 2020 2020  tensors))].     
+0002bcf0: 2020 2020 2020 2069 6620 616e 795f 7379         if any_sy
+0002bd00: 6d62 6f6c 6963 2864 696d 7329 3a0a 2020  mbolic(dims):.  
+0002bd10: 2020 2020 2020 2020 2020 2020 2020 2320                # 
+0002bd20: 7264 6172 3a2f 2f38 3535 3539 3439 3720  rdar://85559497 
+0002bd30: 2848 616e 646c 6520 6479 6e61 6d69 6320  (Handle dynamic 
+0002bd40: 7368 6170 6573 2069 6e70 7574 7320 6272  shapes inputs br
+0002bd50: 6f61 6463 6173 7420 666f 7220 7079 746f  oadcast for pyto
+0002bd60: 7263 6829 0a20 2020 2020 2020 2020 2020  rch).           
+0002bd70: 2020 2020 2072 6169 7365 204e 6f74 496d       raise NotIm
+0002bd80: 706c 656d 656e 7465 6445 7272 6f72 280a  plementedError(.
+0002bd90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002bda0: 2020 2020 224f 6e6c 7920 7374 6174 6963      "Only static
+0002bdb0: 2073 6861 7065 6420 696e 7075 7473 2061   shaped inputs a
+0002bdc0: 7265 2073 7570 706f 7274 6564 2066 6f72  re supported for
+0002bdd0: 2074 6f72 6368 2e62 726f 6164 6361 7374   torch.broadcast
+0002bde0: 5f74 656e 736f 7273 2063 6f6e 7665 7273  _tensors convers
+0002bdf0: 696f 6e2e 220a 2020 2020 2020 2020 2020  ion.".          
+0002be00: 2020 2020 2020 290a 2020 2020 2020 2020        ).        
+0002be10: 2020 2020 7265 7375 6c74 5f73 6861 7065      result_shape
+0002be20: 2e61 7070 656e 6428 5f6e 702e 6d61 7828  .append(_np.max(
+0002be30: 6469 6d73 2929 0a20 2020 2020 2020 2072  dims)).        r
+0002be40: 6574 7572 6e20 7265 7375 6c74 5f73 6861  eturn result_sha
+0002be50: 7065 0a0a 2020 2020 6966 206c 656e 2874  pe..    if len(t
+0002be60: 656e 736f 7273 2920 3d3d 2031 3a0a 2020  ensors) == 1:.  
+0002be70: 2020 2020 2020 7265 7475 726e 2074 656e        return ten
+0002be80: 736f 7273 0a0a 2020 2020 2320 736f 6c76  sors..    # solv
+0002be90: 6520 7468 6520 6272 6f61 6463 6173 7420  e the broadcast 
+0002bea0: 7368 6170 650a 2020 2020 696e 7075 745f  shape.    input_
+0002beb0: 7368 6170 6573 203d 205b 6c69 7374 2878  shapes = [list(x
+0002bec0: 2e73 6861 7065 2920 666f 7220 7820 696e  .shape) for x in
+0002bed0: 2074 656e 736f 7273 5d0a 2020 2020 6272   tensors].    br
+0002bee0: 6f61 6463 6173 745f 7368 6170 6520 3d20  oadcast_shape = 
+0002bef0: 5f73 6f6c 7665 5f62 726f 6164 6361 7374  _solve_broadcast
+0002bf00: 5f73 6861 7065 2869 6e70 7574 5f73 6861  _shape(input_sha
+0002bf10: 7065 7329 0a0a 2020 2020 2320 646f 2074  pes)..    # do t
+0002bf20: 6865 2062 726f 6164 6361 7374 696e 670a  he broadcasting.
+0002bf30: 2020 2020 7265 7375 6c74 7320 3d20 5b5d      results = []
+0002bf40: 0a20 2020 2066 6f72 2074 656e 736f 7220  .    for tensor 
+0002bf50: 696e 2074 656e 736f 7273 3a0a 2020 2020  in tensors:.    
+0002bf60: 2020 2020 6e61 6d65 203d 2074 656e 736f      name = tenso
+0002bf70: 722e 6e61 6d65 202b 2022 5f61 6674 6572  r.name + "_after
+0002bf80: 5f62 726f 6164 6361 7374 220a 2020 2020  _broadcast".    
+0002bf90: 2020 2020 7265 7375 6c74 732e 6170 7065      results.appe
+0002bfa0: 6e64 285f 6272 6f61 6463 6173 7428 6e61  nd(_broadcast(na
+0002bfb0: 6d65 2c20 7465 6e73 6f72 2c20 6272 6f61  me, tensor, broa
+0002bfc0: 6463 6173 745f 7368 6170 6529 290a 2020  dcast_shape)).  
+0002bfd0: 2020 7265 7475 726e 2072 6573 756c 7473    return results
+0002bfe0: 0a0a 0a40 7265 6769 7374 6572 5f74 6f72  ...@register_tor
+0002bff0: 6368 5f6f 700a 6465 6620 6272 6f61 6463  ch_op.def broadc
+0002c000: 6173 745f 7465 6e73 6f72 7328 636f 6e74  ast_tensors(cont
+0002c010: 6578 742c 206e 6f64 6529 3a0a 2020 2020  ext, node):.    
+0002c020: 696e 7075 7473 203d 205f 6765 745f 696e  inputs = _get_in
+0002c030: 7075 7473 2863 6f6e 7465 7874 2c20 6e6f  puts(context, no
+0002c040: 6465 290a 2020 2020 636f 6e74 6578 742e  de).    context.
+0002c050: 6164 6428 5f62 726f 6164 6361 7374 5f74  add(_broadcast_t
+0002c060: 656e 736f 7273 2869 6e70 7574 735b 305d  ensors(inputs[0]
+0002c070: 292c 206e 6f64 652e 6e61 6d65 290a 0a0a  ), node.name)...
+0002c080: 6465 6620 5f73 6361 7474 6572 2863 6f6e  def _scatter(con
+0002c090: 7465 7874 2c20 696e 7075 7473 2c20 6d6f  text, inputs, mo
+0002c0a0: 6465 2c20 6e61 6d65 293a 0a20 2020 2064  de, name):.    d
+0002c0b0: 6174 6120 3d20 696e 7075 7473 5b30 5d0a  ata = inputs[0].
+0002c0c0: 2020 2020 6178 6973 203d 2069 6e70 7574      axis = input
+0002c0d0: 735b 315d 2e76 616c 0a20 2020 2069 6e64  s[1].val.    ind
+0002c0e0: 6963 6573 203d 2069 6e70 7574 735b 325d  ices = inputs[2]
+0002c0f0: 0a20 2020 2075 7064 6174 6573 203d 2069  .    updates = i
+0002c100: 6e70 7574 735b 335d 0a20 2020 2069 6620  nputs[3].    if 
+0002c110: 7479 7065 732e 6973 5f73 6361 6c61 7228  types.is_scalar(
+0002c120: 7570 6461 7465 732e 7379 6d5f 7479 7065  updates.sym_type
+0002c130: 293a 0a20 2020 2020 2020 2075 7064 6174  ):.        updat
+0002c140: 6573 203d 206d 622e 6669 6c6c 2873 6861  es = mb.fill(sha
+0002c150: 7065 3d69 6e64 6963 6573 2e73 6861 7065  pe=indices.shape
+0002c160: 2c20 7661 6c75 653d 7570 6461 7465 732e  , value=updates.
+0002c170: 7661 6c2c 206e 616d 653d 6e61 6d65 290a  val, name=name).
+0002c180: 2020 2020 7265 7375 6c74 203d 206d 622e      result = mb.
+0002c190: 7363 6174 7465 725f 616c 6f6e 675f 6178  scatter_along_ax
+0002c1a0: 6973 2864 6174 613d 6461 7461 2c20 696e  is(data=data, in
+0002c1b0: 6469 6365 733d 696e 6469 6365 732c 2075  dices=indices, u
+0002c1c0: 7064 6174 6573 3d75 7064 6174 6573 2c0a  pdates=updates,.
+0002c1d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002c1e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002c1f0: 2020 2061 7869 733d 6178 6973 2c20 6d6f     axis=axis, mo
+0002c200: 6465 3d6d 6f64 652c 206e 616d 653d 6e61  de=mode, name=na
+0002c210: 6d65 290a 2020 2020 636f 6e74 6578 742e  me).    context.
+0002c220: 6164 6428 7265 7375 6c74 290a 0a0a 4072  add(result)...@r
+0002c230: 6567 6973 7465 725f 746f 7263 685f 6f70  egister_torch_op
+0002c240: 0a64 6566 2073 6361 7474 6572 2863 6f6e  .def scatter(con
+0002c250: 7465 7874 2c20 6e6f 6465 293a 0a20 2020  text, node):.   
+0002c260: 2069 6e70 7574 7320 3d20 5f67 6574 5f69   inputs = _get_i
+0002c270: 6e70 7574 7328 636f 6e74 6578 742c 206e  nputs(context, n
+0002c280: 6f64 6529 0a20 2020 2061 7373 6572 7420  ode).    assert 
+0002c290: 6c65 6e28 696e 7075 7473 2920 696e 2028  len(inputs) in (
+0002c2a0: 342c 2035 290a 0a20 2020 2023 2044 6574  4, 5)..    # Det
+0002c2b0: 6572 6d69 6e65 2072 6564 7563 652f 6d6f  ermine reduce/mo
+0002c2c0: 6465 2070 6172 616d 6574 6572 0a20 2020  de parameter.   
+0002c2d0: 2069 6620 6c65 6e28 696e 7075 7473 2920   if len(inputs) 
+0002c2e0: 3d3d 2035 3a0a 2020 2020 2020 2020 6d6f  == 5:.        mo
+0002c2f0: 6465 203d 2069 6e70 7574 735b 345d 2e76  de = inputs[4].v
+0002c300: 616c 0a20 2020 2020 2020 2069 6620 6d6f  al.        if mo
+0002c310: 6465 203d 3d20 276d 756c 7469 706c 7927  de == 'multiply'
+0002c320: 3a0a 2020 2020 2020 2020 2020 2020 6d6f  :.            mo
+0002c330: 6465 203d 2027 6d75 6c27 0a20 2020 2020  de = 'mul'.     
+0002c340: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
+0002c350: 2020 2020 2061 7373 6572 7420 6d6f 6465       assert mode
+0002c360: 203d 3d20 2761 6464 270a 2020 2020 656c   == 'add'.    el
+0002c370: 7365 3a0a 2020 2020 2020 2020 6d6f 6465  se:.        mode
+0002c380: 203d 2027 7570 6461 7465 270a 0a20 2020   = 'update'..   
+0002c390: 205f 7363 6174 7465 7228 636f 6e74 6578   _scatter(contex
+0002c3a0: 742c 2069 6e70 7574 732c 206d 6f64 652c  t, inputs, mode,
+0002c3b0: 206e 6f64 652e 6e61 6d65 290a 0a0a 4072   node.name)...@r
+0002c3c0: 6567 6973 7465 725f 746f 7263 685f 6f70  egister_torch_op
+0002c3d0: 0a64 6566 2073 6361 7474 6572 5f61 6464  .def scatter_add
+0002c3e0: 2863 6f6e 7465 7874 2c20 6e6f 6465 293a  (context, node):
+0002c3f0: 0a20 2020 2069 6e70 7574 7320 3d20 5f67  .    inputs = _g
+0002c400: 6574 5f69 6e70 7574 7328 636f 6e74 6578  et_inputs(contex
+0002c410: 742c 206e 6f64 6529 0a20 2020 205f 7363  t, node).    _sc
+0002c420: 6174 7465 7228 636f 6e74 6578 742c 2069  atter(context, i
+0002c430: 6e70 7574 732c 2027 6164 6427 2c20 6e6f  nputs, 'add', no
+0002c440: 6465 2e6e 616d 6529 0a0a 0a40 7265 6769  de.name)...@regi
+0002c450: 7374 6572 5f74 6f72 6368 5f6f 700a 6465  ster_torch_op.de
+0002c460: 6620 6261 6464 626d 6d28 636f 6e74 6578  f baddbmm(contex
+0002c470: 742c 206e 6f64 6529 3a0a 2020 2020 2222  t, node):.    ""
+0002c480: 220a 2020 2020 6261 6464 626d 6d28 5465  ".    baddbmm(Te
+0002c490: 6e73 6f72 2069 6e70 7574 2c20 5465 6e73  nsor input, Tens
+0002c4a0: 6f72 2062 6174 6368 312c 2054 656e 736f  or batch1, Tenso
+0002c4b0: 7220 6261 7463 6832 2c20 5363 616c 6172  r batch2, Scalar
+0002c4c0: 2062 6574 613d 312c 2053 6361 6c61 7220   beta=1, Scalar 
+0002c4d0: 616c 7068 613d 3129 0a20 2020 206f 7574  alpha=1).    out
+0002c4e0: 7075 7420 3d20 6265 7461 202a 2069 6e70  put = beta * inp
+0002c4f0: 7574 202b 2061 6c70 6861 202a 2062 6174  ut + alpha * bat
+0002c500: 6368 3120 2a20 6261 7463 6832 0a0a 2020  ch1 * batch2..  
+0002c510: 2020 4e6f 7469 6365 2074 6861 7420 6261    Notice that ba
+0002c520: 7463 6831 2061 6e64 2062 6174 6368 3220  tch1 and batch2 
+0002c530: 6d75 7374 2062 6520 332d 4420 7465 6e73  must be 3-D tens
+0002c540: 6f72 7320 6561 6368 2063 6f6e 7461 696e  ors each contain
+0002c550: 696e 6720 7468 6520 7361 6d65 206e 756d  ing the same num
+0002c560: 6265 7220 6f66 206d 6174 7269 6365 732e  ber of matrices.
+0002c570: 0a20 2020 2049 6620 6261 7463 6831 2069  .    If batch1 i
+0002c580: 7320 6120 2862 c397 6ec3 976d 2920 7465  s a (b..n..m) te
+0002c590: 6e73 6f72 2c20 6261 7463 6832 2069 7320  nsor, batch2 is 
+0002c5a0: 6120 2862 c397 6dc3 9770 2920 7465 6e73  a (b..m..p) tens
+0002c5b0: 6f72 2c20 7468 656e 2069 6e70 7574 206d  or, then input m
+0002c5c0: 7573 7420 6265 2062 726f 6164 6361 7374  ust be broadcast
+0002c5d0: 6162 6c65 2077 6974 6820 6120 2862 c397  able with a (b..
+0002c5e0: 6ec3 9770 2920 7465 6e73 6f72 0a20 2020  n..p) tensor.   
+0002c5f0: 2061 6e64 206f 7574 2077 696c 6c20 6265   and out will be
+0002c600: 2061 2028 62c3 976e c397 7029 2074 656e   a (b..n..p) ten
+0002c610: 736f 722e 0a20 2020 2022 2222 0a20 2020  sor..    """.   
+0002c620: 2061 7373 6572 7420 6c65 6e28 6e6f 6465   assert len(node
+0002c630: 2e6f 7574 7075 7473 2920 3d3d 2031 0a20  .outputs) == 1. 
+0002c640: 2020 2069 6e70 7574 7320 3d20 5f67 6574     inputs = _get
+0002c650: 5f69 6e70 7574 7328 636f 6e74 6578 742c  _inputs(context,
+0002c660: 206e 6f64 652c 2065 7870 6563 7465 643d   node, expected=
+0002c670: 3529 0a20 2020 2062 6961 732c 2062 6174  5).    bias, bat
+0002c680: 6368 312c 2062 6174 6368 322c 2062 6574  ch1, batch2, bet
+0002c690: 612c 2061 6c70 6861 203d 2069 6e70 7574  a, alpha = input
+0002c6a0: 730a 0a20 2020 2069 6620 6265 7461 2e76  s..    if beta.v
+0002c6b0: 616c 2021 3d20 312e 303a 0a20 2020 2020  al != 1.0:.     
+0002c6c0: 2020 2023 2041 7070 6c79 2073 6361 6c69     # Apply scali
+0002c6d0: 6e67 2066 6163 746f 7220 6265 7461 2074  ng factor beta t
+0002c6e0: 6f20 7468 6520 6269 6173 2e0a 2020 2020  o the bias..    
+0002c6f0: 2020 2020 6269 6173 203d 206d 622e 6d75      bias = mb.mu
+0002c700: 6c28 783d 6265 7461 2c20 793d 6269 6173  l(x=beta, y=bias
+0002c710: 2c20 6e61 6d65 3d62 6961 732e 6e61 6d65  , name=bias.name
+0002c720: 202b 2022 5f73 6361 6c65 6422 290a 2020   + "_scaled").  
+0002c730: 2020 2020 2020 636f 6e74 6578 742e 6164        context.ad
+0002c740: 6428 6269 6173 290a 0a20 2020 2069 6620  d(bias)..    if 
+0002c750: 616c 7068 612e 7661 6c20 213d 2031 2e30  alpha.val != 1.0
+0002c760: 3a0a 2020 2020 2020 2020 2320 4170 706c  :.        # Appl
+0002c770: 7920 7363 616c 696e 6720 6661 6374 6f72  y scaling factor
+0002c780: 2061 6c70 6861 2074 6f20 7468 6520 696e   alpha to the in
+0002c790: 7075 742e 0a20 2020 2020 2020 2062 6174  put..        bat
+0002c7a0: 6368 3120 3d20 6d62 2e6d 756c 2878 3d61  ch1 = mb.mul(x=a
+0002c7b0: 6c70 6861 2c20 793d 6261 7463 6831 2c20  lpha, y=batch1, 
+0002c7c0: 6e61 6d65 3d62 6174 6368 312e 6e61 6d65  name=batch1.name
+0002c7d0: 202b 2022 5f73 6361 6c65 6422 290a 2020   + "_scaled").  
+0002c7e0: 2020 2020 2020 636f 6e74 6578 742e 6164        context.ad
+0002c7f0: 6428 6261 7463 6831 290a 0a20 2020 2062  d(batch1)..    b
+0002c800: 6d6d 5f6e 6f64 6520 3d20 6d62 2e6d 6174  mm_node = mb.mat
+0002c810: 6d75 6c28 783d 6261 7463 6831 2c20 793d  mul(x=batch1, y=
+0002c820: 6261 7463 6832 2c20 6e61 6d65 3d6e 6f64  batch2, name=nod
+0002c830: 652e 6e61 6d65 202b 2022 5f62 6d6d 2229  e.name + "_bmm")
+0002c840: 0a20 2020 2063 6f6e 7465 7874 2e61 6464  .    context.add
+0002c850: 2862 6d6d 5f6e 6f64 6529 0a0a 2020 2020  (bmm_node)..    
+0002c860: 6261 6464 626d 6d5f 6e6f 6465 203d 206d  baddbmm_node = m
+0002c870: 622e 6164 6428 783d 6269 6173 2c20 793d  b.add(x=bias, y=
+0002c880: 626d 6d5f 6e6f 6465 2c20 6e61 6d65 3d6e  bmm_node, name=n
+0002c890: 6f64 652e 6e61 6d65 290a 2020 2020 636f  ode.name).    co
+0002c8a0: 6e74 6578 742e 6164 6428 6261 6464 626d  ntext.add(baddbm
+0002c8b0: 6d5f 6e6f 6465 290a 0a0a 4072 6567 6973  m_node)...@regis
+0002c8c0: 7465 725f 746f 7263 685f 6f70 0a64 6566  ter_torch_op.def
+0002c8d0: 2067 6c75 2863 6f6e 7465 7874 2c20 6e6f   glu(context, no
+0002c8e0: 6465 293a 0a20 2020 2022 2222 0a20 2020  de):.    """.   
+0002c8f0: 2067 6c75 2854 656e 736f 7220 696e 7075   glu(Tensor inpu
+0002c900: 742c 2053 6361 6c61 7220 6469 6d3d 2d31  t, Scalar dim=-1
+0002c910: 290a 2020 2020 4170 706c 6965 7320 7468  ).    Applies th
+0002c920: 6520 6761 7465 6420 6c69 6e65 6172 2075  e gated linear u
+0002c930: 6e69 7420 6675 6e63 7469 6f6e 2047 4c55  nit function GLU
+0002c940: 2861 2c62 293d 61e2 8a97 cf83 2862 2920  (a,b)=a.....(b) 
+0002c950: 7768 6572 6520 6120 6973 2074 6865 2066  where a is the f
+0002c960: 6972 7374 2068 616c 6620 6f66 2074 6865  irst half of the
+0002c970: 2069 6e70 7574 206d 6174 7269 6365 7320   input matrices 
+0002c980: 616e 6420 6220 6973 2074 6865 0a20 2020  and b is the.   
+0002c990: 2073 6563 6f6e 6420 6861 6c66 2e0a 2020   second half..  
+0002c9a0: 2020 2222 220a 2020 2020 6173 7365 7274    """.    assert
+0002c9b0: 206c 656e 286e 6f64 652e 6f75 7470 7574   len(node.output
+0002c9c0: 7329 203d 3d20 310a 2020 2020 696e 7075  s) == 1.    inpu
+0002c9d0: 7473 203d 205f 6765 745f 696e 7075 7473  ts = _get_inputs
+0002c9e0: 2863 6f6e 7465 7874 2c20 6e6f 6465 2c20  (context, node, 
+0002c9f0: 6578 7065 6374 6564 3d32 290a 2020 2020  expected=2).    
+0002ca00: 696e 7075 742c 2061 7869 7320 3d20 696e  input, axis = in
+0002ca10: 7075 7473 0a0a 2020 2020 6669 7273 745f  puts..    first_
+0002ca20: 6861 6c66 2c20 7365 636f 6e64 5f68 616c  half, second_hal
+0002ca30: 6620 3d20 6d62 2e73 706c 6974 2878 3d69  f = mb.split(x=i
+0002ca40: 6e70 7574 2c20 6e75 6d5f 7370 6c69 7473  nput, num_splits
+0002ca50: 3d32 2c20 6178 6973 3d61 7869 732e 7661  =2, axis=axis.va
+0002ca60: 6c2c 206e 616d 653d 6e6f 6465 2e6e 616d  l, name=node.nam
+0002ca70: 6520 2b20 225f 7370 6c69 7422 290a 2020  e + "_split").  
+0002ca80: 2020 636f 6e74 6578 742e 6164 6428 6669    context.add(fi
+0002ca90: 7273 745f 6861 6c66 290a 2020 2020 636f  rst_half).    co
+0002caa0: 6e74 6578 742e 6164 6428 7365 636f 6e64  ntext.add(second
+0002cab0: 5f68 616c 6629 0a0a 2020 2020 7369 676d  _half)..    sigm
+0002cac0: 6f69 645f 7365 636f 6e64 5f68 616c 6620  oid_second_half 
+0002cad0: 3d20 6d62 2e73 6967 6d6f 6964 2878 3d73  = mb.sigmoid(x=s
+0002cae0: 6563 6f6e 645f 6861 6c66 2c20 6e61 6d65  econd_half, name
+0002caf0: 3d73 6563 6f6e 645f 6861 6c66 2e6e 616d  =second_half.nam
+0002cb00: 6520 2b20 225f 7369 676d 6f69 6422 290a  e + "_sigmoid").
+0002cb10: 2020 2020 636f 6e74 6578 742e 6164 6428      context.add(
+0002cb20: 7369 676d 6f69 645f 7365 636f 6e64 5f68  sigmoid_second_h
+0002cb30: 616c 6629 0a0a 2020 2020 676c 755f 6e6f  alf)..    glu_no
+0002cb40: 6465 203d 206d 622e 6d75 6c28 783d 6669  de = mb.mul(x=fi
+0002cb50: 7273 745f 6861 6c66 2c20 793d 7369 676d  rst_half, y=sigm
+0002cb60: 6f69 645f 7365 636f 6e64 5f68 616c 662c  oid_second_half,
+0002cb70: 206e 616d 653d 6e6f 6465 2e6e 616d 6529   name=node.name)
+0002cb80: 0a20 2020 2063 6f6e 7465 7874 2e61 6464  .    context.add
+0002cb90: 2867 6c75 5f6e 6f64 6529 0a0a 0a40 7265  (glu_node)...@re
+0002cba0: 6769 7374 6572 5f74 6f72 6368 5f6f 700a  gister_torch_op.
+0002cbb0: 6465 6620 6873 7461 636b 2863 6f6e 7465  def hstack(conte
+0002cbc0: 7874 2c20 6e6f 6465 293a 0a20 2020 2022  xt, node):.    "
+0002cbd0: 2222 0a20 2020 2068 7374 6163 6b28 4c69  "".    hstack(Li
+0002cbe0: 7374 5b54 656e 736f 725d 2074 656e 736f  st[Tensor] tenso
+0002cbf0: 7273 2c20 4f70 7469 6f6e 616c 5b54 656e  rs, Optional[Ten
+0002cc00: 736f 725d 206f 7574 290a 2020 2020 5374  sor] out).    St
+0002cc10: 6163 6b20 7465 6e73 6f72 7320 696e 2073  ack tensors in s
+0002cc20: 6571 7565 6e63 6520 686f 7269 7a6f 6e74  equence horizont
+0002cc30: 616c 6c79 2028 636f 6c75 6d6e 2077 6973  ally (column wis
+0002cc40: 6529 2e20 5468 6973 2069 7320 6571 7569  e). This is equi
+0002cc50: 7661 6c65 6e74 2074 6f20 636f 6e63 6174  valent to concat
+0002cc60: 656e 6174 696f 6e20 616c 6f6e 6720 7468  enation along th
+0002cc70: 6520 6669 7273 7420 6178 6973 2066 6f72  e first axis for
+0002cc80: 0a20 2020 2031 2d44 2074 656e 736f 7273  .    1-D tensors
+0002cc90: 2c20 616e 6420 616c 6f6e 6720 7468 6520  , and along the 
+0002cca0: 7365 636f 6e64 2061 7869 7320 666f 7220  second axis for 
+0002ccb0: 616c 6c20 6f74 6865 7220 7465 6e73 6f72  all other tensor
+0002ccc0: 732e 0a20 2020 2022 2222 0a20 2020 2069  s..    """.    i
+0002ccd0: 6e70 7574 7320 3d20 5f67 6574 5f69 6e70  nputs = _get_inp
+0002cce0: 7574 7328 636f 6e74 6578 742c 206e 6f64  uts(context, nod
+0002ccf0: 6529 0a20 2020 2074 656e 736f 7273 203d  e).    tensors =
+0002cd00: 2069 6e70 7574 735b 305d 0a20 2020 2069   inputs[0].    i
+0002cd10: 6e70 7574 5f73 6861 7065 7320 3d20 5b6c  nput_shapes = [l
+0002cd20: 6973 7428 782e 7368 6170 6529 2066 6f72  ist(x.shape) for
+0002cd30: 2078 2069 6e20 7465 6e73 6f72 735d 0a20   x in tensors]. 
+0002cd40: 2020 2023 2043 6f6e 6361 7465 6e61 7465     # Concatenate
+0002cd50: 7320 616c 6f6e 6720 7468 6520 6669 7273  s along the firs
+0002cd60: 7420 6178 6973 2066 6f72 2031 2d44 2074  t axis for 1-D t
+0002cd70: 656e 736f 7273 2c20 616e 6420 616c 6f6e  ensors, and alon
+0002cd80: 6720 7468 6520 7365 636f 6e64 2061 7869  g the second axi
+0002cd90: 7320 666f 7220 616c 6c20 6f74 6865 7220  s for all other 
+0002cda0: 7465 6e73 6f72 732e 0a20 2020 2061 7869  tensors..    axi
+0002cdb0: 7320 3d20 3020 6966 206c 656e 2869 6e70  s = 0 if len(inp
+0002cdc0: 7574 5f73 6861 7065 735b 305d 2920 3d3d  ut_shapes[0]) ==
+0002cdd0: 2031 2065 6c73 6520 310a 2020 2020 6873   1 else 1.    hs
+0002cde0: 7461 636b 5f6e 6f64 6520 3d20 6d62 2e63  tack_node = mb.c
+0002cdf0: 6f6e 6361 7428 7661 6c75 6573 3d74 656e  oncat(values=ten
+0002ce00: 736f 7273 2c20 6178 6973 3d61 7869 732c  sors, axis=axis,
+0002ce10: 206e 616d 653d 6e6f 6465 2e6e 616d 6529   name=node.name)
+0002ce20: 0a20 2020 2063 6f6e 7465 7874 2e61 6464  .    context.add
+0002ce30: 2868 7374 6163 6b5f 6e6f 6465 290a 0a0a  (hstack_node)...
+0002ce40: 4072 6567 6973 7465 725f 746f 7263 685f  @register_torch_
+0002ce50: 6f70 0a64 6566 2072 656d 6169 6e64 6572  op.def remainder
+0002ce60: 2863 6f6e 7465 7874 2c20 6e6f 6465 293a  (context, node):
+0002ce70: 0a20 2020 2022 2222 0a20 2020 2072 656d  .    """.    rem
+0002ce80: 6169 6e64 6572 2854 656e 736f 7220 6469  ainder(Tensor di
+0002ce90: 7669 6465 6e64 2c20 5465 6e73 6f72 2064  vidend, Tensor d
+0002cea0: 6976 6973 6f72 2c20 4f70 7469 6f6e 616c  ivisor, Optional
+0002ceb0: 5b54 656e 736f 725d 206f 7574 290a 2020  [Tensor] out).  
+0002cec0: 2020 436f 6d70 7574 6573 2050 7974 686f    Computes Pytho
+0002ced0: 6ee2 8099 7320 6d6f 6475 6c75 7320 6f70  n...s modulus op
+0002cee0: 6572 6174 696f 6e20 656e 7472 7977 6973  eration entrywis
+0002cef0: 652e 2054 6865 2072 6573 756c 7420 6861  e. The result ha
+0002cf00: 7320 7468 6520 7361 6d65 2073 6967 6e20  s the same sign 
+0002cf10: 6173 2074 6865 2064 6976 6973 6f72 2061  as the divisor a
+0002cf20: 6e64 2069 7473 2061 6273 6f6c 7574 6520  nd its absolute 
+0002cf30: 7661 6c75 650a 2020 2020 6973 206c 6573  value.    is les
+0002cf40: 7320 7468 616e 2074 6861 7420 6f66 2064  s than that of d
+0002cf50: 6976 6973 6f72 2e20 4974 206d 6179 2061  ivisor. It may a
+0002cf60: 6c73 6f20 6265 2064 6566 696e 6564 2069  lso be defined i
+0002cf70: 6e20 7465 726d 7320 6f66 2074 6f72 6368  n terms of torch
+0002cf80: 2e64 6976 2829 2061 733a 0a20 2020 2072  .div() as:.    r
+0002cf90: 656d 6169 6e64 6572 2861 2c20 6229 203d  emainder(a, b) =
+0002cfa0: 3d20 6120 2d20 612e 6469 7628 622c 2072  = a - a.div(b, r
+0002cfb0: 6f75 6e64 696e 675f 6d6f 6465 3d22 666c  ounding_mode="fl
+0002cfc0: 6f6f 7222 2920 2a20 620a 2020 2020 2222  oor") * b.    ""
+0002cfd0: 220a 2020 2020 2320 446f 6e27 7420 7370  ".    # Don't sp
+0002cfe0: 6563 6966 7920 6065 7870 6563 7465 6460  ecify `expected`
+0002cff0: 2062 6563 6175 7365 2074 6865 2070 6172   because the par
+0002d000: 616d 6574 6572 2060 6f75 7460 2069 7320  ameter `out` is 
+0002d010: 6f70 7469 6f6e 616c 2e0a 2020 2020 696e  optional..    in
+0002d020: 7075 7473 203d 205f 6765 745f 696e 7075  puts = _get_inpu
+0002d030: 7473 2863 6f6e 7465 7874 2c20 6e6f 6465  ts(context, node
+0002d040: 290a 2020 2020 6469 7669 6465 6e64 2c20  ).    dividend, 
+0002d050: 6469 7669 736f 7220 3d20 7072 6f6d 6f74  divisor = promot
+0002d060: 655f 696e 7075 745f 6474 7970 6573 285b  e_input_dtypes([
+0002d070: 696e 7075 7473 5b30 5d2c 2069 6e70 7574  inputs[0], input
+0002d080: 735b 315d 5d29 0a20 2020 2064 6976 5f6e  s[1]]).    div_n
+0002d090: 6f64 6520 3d20 6d62 2e66 6c6f 6f72 5f64  ode = mb.floor_d
+0002d0a0: 6976 2878 3d64 6976 6964 656e 642c 2079  iv(x=dividend, y
+0002d0b0: 3d64 6976 6973 6f72 2c20 6e61 6d65 3d6e  =divisor, name=n
+0002d0c0: 6f64 652e 6e61 6d65 202b 2022 5f64 6976  ode.name + "_div
+0002d0d0: 2229 0a20 2020 2063 6f6e 7465 7874 2e61  ").    context.a
+0002d0e0: 6464 2864 6976 5f6e 6f64 6529 0a20 2020  dd(div_node).   
+0002d0f0: 2073 6361 6c65 645f 6469 7620 3d20 6d62   scaled_div = mb
+0002d100: 2e6d 756c 2878 3d64 6976 5f6e 6f64 652c  .mul(x=div_node,
+0002d110: 2079 3d64 6976 6973 6f72 2c20 6e61 6d65   y=divisor, name
+0002d120: 3d64 6976 5f6e 6f64 652e 6e61 6d65 202b  =div_node.name +
+0002d130: 2022 5f73 6361 6c65 6422 290a 2020 2020   "_scaled").    
+0002d140: 636f 6e74 6578 742e 6164 6428 7363 616c  context.add(scal
+0002d150: 6564 5f64 6976 290a 2020 2020 7265 6d61  ed_div).    rema
+0002d160: 696e 6465 725f 6e6f 6465 203d 206d 622e  inder_node = mb.
+0002d170: 7375 6228 783d 6469 7669 6465 6e64 2c20  sub(x=dividend, 
+0002d180: 793d 7363 616c 6564 5f64 6976 2c20 6e61  y=scaled_div, na
+0002d190: 6d65 3d6e 6f64 652e 6e61 6d65 290a 2020  me=node.name).  
+0002d1a0: 2020 636f 6e74 6578 742e 6164 6428 7265    context.add(re
+0002d1b0: 6d61 696e 6465 725f 6e6f 6465 290a 0a0a  mainder_node)...
+0002d1c0: 4072 6567 6973 7465 725f 746f 7263 685f  @register_torch_
+0002d1d0: 6f70 0a64 6566 2068 616e 6e5f 7769 6e64  op.def hann_wind
+0002d1e0: 6f77 2863 6f6e 7465 7874 2c20 6e6f 6465  ow(context, node
+0002d1f0: 293a 0a20 2020 2069 6e70 7574 7320 3d20  ):.    inputs = 
+0002d200: 5f67 6574 5f69 6e70 7574 7328 636f 6e74  _get_inputs(cont
+0002d210: 6578 742c 206e 6f64 652c 2065 7870 6563  ext, node, expec
+0002d220: 7465 643d 5b35 2c20 365d 290a 2020 2020  ted=[5, 6]).    
+0002d230: 6966 2069 6e70 7574 735b 305d 2e76 616c  if inputs[0].val
+0002d240: 2069 7320 4e6f 6e65 3a0a 2020 2020 2020   is None:.      
+0002d250: 2020 7261 6973 6520 4e6f 7449 6d70 6c65    raise NotImple
+0002d260: 6d65 6e74 6564 4572 726f 7228 2276 6172  mentedError("var
+0002d270: 6961 626c 6520 2777 696e 646f 775f 6c65  iable 'window_le
+0002d280: 6e67 7468 2720 6e6f 7420 7375 7070 6f72  ngth' not suppor
+0002d290: 7465 642e 2229 0a0a 2020 2020 7065 7269  ted.")..    peri
+0002d2a0: 6f64 6963 203d 2054 7275 650a 2020 2020  odic = True.    
+0002d2b0: 6966 206c 656e 2869 6e70 7574 7329 203d  if len(inputs) =
+0002d2c0: 3d20 363a 0a20 2020 2020 2020 2069 6620  = 6:.        if 
+0002d2d0: 696e 7075 7473 5b31 5d2e 7661 6c20 6973  inputs[1].val is
+0002d2e0: 204e 6f6e 653a 0a20 2020 2020 2020 2020   None:.         
+0002d2f0: 2020 2072 6169 7365 204e 6f74 496d 706c     raise NotImpl
+0002d300: 656d 656e 7465 6445 7272 6f72 2822 7661  ementedError("va
+0002d310: 7269 6162 6c65 2027 7065 7269 6f64 6963  riable 'periodic
+0002d320: 2720 6e6f 7420 7375 7070 6f72 7465 642e  ' not supported.
+0002d330: 2229 0a20 2020 2020 2020 2069 6620 6e6f  ").        if no
+0002d340: 7420 696e 7075 7473 5b31 5d2e 7661 6c3a  t inputs[1].val:
+0002d350: 0a20 2020 2020 2020 2020 2020 2070 6572  .            per
+0002d360: 696f 6469 6320 3d20 4661 6c73 650a 0a20  iodic = False.. 
+0002d370: 2020 2073 697a 6520 3d20 2869 6e70 7574     size = (input
+0002d380: 735b 305d 2e76 616c 2c29 0a20 2020 2069  s[0].val,).    i
+0002d390: 6620 696e 7075 7473 5b30 5d2e 7661 6c20  f inputs[0].val 
+0002d3a0: 3c3d 2031 3a0a 2020 2020 2020 2020 6f6e  <= 1:.        on
+0002d3b0: 6520 3d20 6d62 2e66 696c 6c28 7368 6170  e = mb.fill(shap
+0002d3c0: 653d 7369 7a65 2c20 7661 6c75 653d 312e  e=size, value=1.
+0002d3d0: 302c 206e 616d 653d 6e6f 6465 2e6e 616d  0, name=node.nam
+0002d3e0: 6529 0a20 2020 2020 2020 2063 6f6e 7465  e).        conte
+0002d3f0: 7874 2e61 6464 286f 6e65 290a 2020 2020  xt.add(one).    
+0002d400: 2020 2020 7265 7475 726e 0a0a 2020 2020      return..    
+0002d410: 6f6e 6573 203d 206d 622e 6669 6c6c 2873  ones = mb.fill(s
+0002d420: 6861 7065 3d73 697a 652c 2076 616c 7565  hape=size, value
+0002d430: 3d31 2e30 290a 2020 2020 6375 6d20 3d20  =1.0).    cum = 
+0002d440: 6d62 2e63 756d 7375 6d28 783d 6f6e 6573  mb.cumsum(x=ones
+0002d450: 2c20 6178 6973 3d30 290a 2020 2020 7365  , axis=0).    se
+0002d460: 7120 3d20 6d62 2e73 7562 2878 3d63 756d  q = mb.sub(x=cum
+0002d470: 2c20 793d 6f6e 6573 290a 2020 2020 7069  , y=ones).    pi
+0002d480: 203d 206d 622e 6669 6c6c 2873 6861 7065   = mb.fill(shape
+0002d490: 3d73 697a 652c 2076 616c 7565 3d5f 6d61  =size, value=_ma
+0002d4a0: 7468 2e70 6929 0a20 2020 2077 696e 646f  th.pi).    windo
+0002d4b0: 775f 6c65 6e67 7468 5f66 6c6f 6174 203d  w_length_float =
+0002d4c0: 206d 622e 6361 7374 2878 3d69 6e70 7574   mb.cast(x=input
+0002d4d0: 735b 305d 2c20 6474 7970 653d 2266 7033  s[0], dtype="fp3
+0002d4e0: 3222 290a 2020 2020 6966 206e 6f74 2070  2").    if not p
+0002d4f0: 6572 696f 6469 633a 0a20 2020 2020 2020  eriodic:.       
+0002d500: 2077 696e 646f 775f 6c65 6e67 7468 5f66   window_length_f
+0002d510: 6c6f 6174 203d 206d 622e 7375 6228 783d  loat = mb.sub(x=
+0002d520: 7769 6e64 6f77 5f6c 656e 6774 685f 666c  window_length_fl
+0002d530: 6f61 742c 2079 3d6f 6e65 7329 0a20 2020  oat, y=ones).   
+0002d540: 2064 656e 6f6d 696e 6174 6f72 203d 206d   denominator = m
+0002d550: 622e 6669 6c6c 2873 6861 7065 3d73 697a  b.fill(shape=siz
+0002d560: 652c 2076 616c 7565 3d77 696e 646f 775f  e, value=window_
+0002d570: 6c65 6e67 7468 5f66 6c6f 6174 290a 2020  length_float).  
+0002d580: 2020 6e75 6d65 7261 746f 7220 3d20 6d62    numerator = mb
+0002d590: 2e6d 756c 2878 3d73 6571 2c20 793d 7069  .mul(x=seq, y=pi
+0002d5a0: 290a 2020 2020 6672 6163 203d 206d 622e  ).    frac = mb.
+0002d5b0: 7265 616c 5f64 6976 2878 3d6e 756d 6572  real_div(x=numer
+0002d5c0: 6174 6f72 2c20 793d 6465 6e6f 6d69 6e61  ator, y=denomina
+0002d5d0: 746f 7229 0a20 2020 2073 696e 203d 206d  tor).    sin = m
+0002d5e0: 622e 7369 6e28 783d 6672 6163 290a 2020  b.sin(x=frac).  
+0002d5f0: 2020 7369 6e5f 7371 203d 206d 622e 6d75    sin_sq = mb.mu
+0002d600: 6c28 783d 7369 6e2c 2079 3d73 696e 2c20  l(x=sin, y=sin, 
+0002d610: 6e61 6d65 3d6e 6f64 652e 6e61 6d65 290a  name=node.name).
+0002d620: 2020 2020 636f 6e74 6578 742e 6164 6428      context.add(
+0002d630: 7369 6e5f 7371 290a 0a40 7265 6769 7374  sin_sq)..@regist
+0002d640: 6572 5f74 6f72 6368 5f6f 700a 6465 6620  er_torch_op.def 
+0002d650: 6d73 655f 6c6f 7373 2863 6f6e 7465 7874  mse_loss(context
+0002d660: 2c20 6e6f 6465 293a 0a20 2020 2069 6e70  , node):.    inp
+0002d670: 7574 7320 3d20 5f67 6574 5f69 6e70 7574  uts = _get_input
+0002d680: 7328 636f 6e74 6578 742c 206e 6f64 652c  s(context, node,
+0002d690: 2065 7870 6563 7465 643d 3329 0a20 2020   expected=3).   
+0002d6a0: 2078 203d 2069 6e70 7574 735b 305d 0a20   x = inputs[0]. 
+0002d6b0: 2020 2079 203d 2069 6e70 7574 735b 315d     y = inputs[1]
+0002d6c0: 0a20 2020 2072 6564 7563 7469 6f6e 203d  .    reduction =
+0002d6d0: 2069 6e70 7574 735b 325d 2e76 616c 0a0a   inputs[2].val..
+0002d6e0: 2020 2020 6469 6666 203d 206d 622e 7375      diff = mb.su
+0002d6f0: 6228 783d 782c 2079 3d79 290a 0a20 2020  b(x=x, y=y)..   
+0002d700: 2069 6620 7265 6475 6374 696f 6e20 3d3d   if reduction ==
+0002d710: 2030 3a0a 2020 2020 2020 2020 2320 7265   0:.        # re
+0002d720: 6475 6374 696f 6e20 6973 2022 6e6f 6e65  duction is "none
+0002d730: 220a 2020 2020 2020 2020 7265 7320 3d20  ".        res = 
+0002d740: 6d62 2e6d 756c 2878 3d64 6966 662c 2079  mb.mul(x=diff, y
+0002d750: 3d64 6966 662c 206e 616d 653d 6e6f 6465  =diff, name=node
+0002d760: 2e6e 616d 6529 0a20 2020 2020 2020 2063  .name).        c
+0002d770: 6f6e 7465 7874 2e61 6464 2872 6573 290a  ontext.add(res).
+0002d780: 2020 2020 2020 2020 7265 7475 726e 0a0a          return..
+0002d790: 2020 2020 7371 7561 7265 203d 206d 622e      square = mb.
+0002d7a0: 6d75 6c28 783d 6469 6666 2c20 793d 6469  mul(x=diff, y=di
+0002d7b0: 6666 290a 2020 2020 6966 2072 6564 7563  ff).    if reduc
+0002d7c0: 7469 6f6e 203d 3d20 313a 0a20 2020 2020  tion == 1:.     
+0002d7d0: 2020 2023 2072 6564 7563 7469 6f6e 2069     # reduction i
+0002d7e0: 7320 226d 6561 6e22 0a20 2020 2020 2020  s "mean".       
+0002d7f0: 2072 6573 203d 206d 622e 7265 6475 6365   res = mb.reduce
+0002d800: 5f6d 6561 6e28 783d 7371 7561 7265 2c20  _mean(x=square, 
+0002d810: 6178 6573 3d4e 6f6e 652c 206e 616d 653d  axes=None, name=
+0002d820: 6e6f 6465 2e6e 616d 6529 0a0a 2020 2020  node.name)..    
+0002d830: 656c 6966 2072 6564 7563 7469 6f6e 203d  elif reduction =
+0002d840: 3d20 323a 0a20 2020 2020 2020 2023 2072  = 2:.        # r
+0002d850: 6564 7563 7469 6f6e 2069 7320 2273 756d  eduction is "sum
+0002d860: 220a 2020 2020 2020 2020 7265 7320 3d20  ".        res = 
+0002d870: 6d62 2e72 6564 7563 655f 7375 6d28 783d  mb.reduce_sum(x=
+0002d880: 7371 7561 7265 2c20 6178 6573 3d4e 6f6e  square, axes=Non
+0002d890: 652c 206e 616d 653d 6e6f 6465 2e6e 616d  e, name=node.nam
+0002d8a0: 6529 0a20 2020 2065 6c73 653a 0a20 2020  e).    else:.   
+0002d8b0: 2020 2020 2072 6169 7365 2056 616c 7565       raise Value
+0002d8c0: 4572 726f 7228 2252 6564 7563 7469 6f6e  Error("Reduction
+0002d8d0: 2069 7320 6e6f 7420 7375 7070 6f72 7465   is not supporte
+0002d8e0: 6422 290a 0a20 2020 2063 6f6e 7465 7874  d")..    context
+0002d8f0: 2e61 6464 2872 6573 290a 0a40 7265 6769  .add(res)..@regi
+0002d900: 7374 6572 5f74 6f72 6368 5f6f 700a 6465  ster_torch_op.de
+0002d910: 6620 7472 6163 6528 636f 6e74 6578 742c  f trace(context,
+0002d920: 206e 6f64 6529 3a0a 2020 2020 696e 7075   node):.    inpu
+0002d930: 7473 203d 205f 6765 745f 696e 7075 7473  ts = _get_inputs
+0002d940: 2863 6f6e 7465 7874 2c20 6e6f 6465 2c20  (context, node, 
+0002d950: 6578 7065 6374 6564 3d31 290a 2020 2020  expected=1).    
+0002d960: 7820 3d20 696e 7075 7473 5b30 5d0a 2020  x = inputs[0].  
+0002d970: 2020 6469 6d73 203d 206d 622e 7368 6170    dims = mb.shap
+0002d980: 6528 783d 7829 0a20 2020 2064 696d 3020  e(x=x).    dim0 
+0002d990: 3d20 7661 6c75 655f 6174 2864 696d 732c  = value_at(dims,
+0002d9a0: 2030 290a 2020 2020 6469 6d31 203d 2076   0).    dim1 = v
+0002d9b0: 616c 7565 5f61 7428 6469 6d73 2c20 3129  alue_at(dims, 1)
+0002d9c0: 0a20 2020 206d 696e 5f64 696d 203d 206d  .    min_dim = m
+0002d9d0: 622e 6d69 6e69 6d75 6d28 783d 6469 6d30  b.minimum(x=dim0
+0002d9e0: 2c20 793d 6469 6d31 290a 2020 2020 696e  , y=dim1).    in
+0002d9f0: 6469 6365 7320 3d20 6d62 2e72 616e 6765  dices = mb.range
+0002da00: 5f31 6428 656e 643d 6d69 6e5f 6469 6d2c  _1d(end=min_dim,
+0002da10: 2073 7461 7274 3d30 2c20 7374 6570 3d31   start=0, step=1
+0002da20: 290a 2020 2020 696e 6469 6365 7320 3d20  ).    indices = 
+0002da30: 6d62 2e73 7461 636b 2876 616c 7565 733d  mb.stack(values=
+0002da40: 5b69 6e64 6963 6573 2c20 696e 6469 6365  [indices, indice
+0002da50: 735d 2c20 6178 6973 3d31 290a 2020 2020  s], axis=1).    
+0002da60: 6469 6167 6f6e 616c 203d 206d 622e 6761  diagonal = mb.ga
+0002da70: 7468 6572 5f6e 6428 783d 782c 2069 6e64  ther_nd(x=x, ind
+0002da80: 6963 6573 3d69 6e64 6963 6573 290a 2020  ices=indices).  
+0002da90: 2020 7472 6163 6520 3d20 6d62 2e72 6564    trace = mb.red
+0002daa0: 7563 655f 7375 6d28 783d 6469 6167 6f6e  uce_sum(x=diagon
+0002dab0: 616c 2c20 6e61 6d65 3d6e 6f64 652e 6e61  al, name=node.na
+0002dac0: 6d65 290a 2020 2020 636f 6e74 6578 742e  me).    context.
+0002dad0: 6164 6428 7472 6163 6529 0a0a 4072 6567  add(trace)..@reg
+0002dae0: 6973 7465 725f 746f 7263 685f 6f70 0a64  ister_torch_op.d
+0002daf0: 6566 2072 6f6c 6c28 636f 6e74 6578 742c  ef roll(context,
+0002db00: 206e 6f64 6529 3a0a 2020 2020 696e 7075   node):.    inpu
+0002db10: 7473 203d 205f 6765 745f 696e 7075 7473  ts = _get_inputs
+0002db20: 2863 6f6e 7465 7874 2c20 6e6f 6465 2c20  (context, node, 
+0002db30: 6578 7065 6374 6564 3d33 290a 2020 2020  expected=3).    
+0002db40: 7820 3d20 696e 7075 7473 5b30 5d0a 2020  x = inputs[0].  
+0002db50: 2020 7368 6966 7420 3d20 696e 7075 7473    shift = inputs
+0002db60: 5b31 5d2e 7661 6c0a 2020 2020 6469 6d73  [1].val.    dims
+0002db70: 203d 2069 6e70 7574 735b 325d 2e76 616c   = inputs[2].val
+0002db80: 0a20 2020 206f 7269 6769 6e5f 7368 6170  .    origin_shap
+0002db90: 6520 3d20 6d62 2e73 6861 7065 2878 3d78  e = mb.shape(x=x
+0002dba0: 290a 0a20 2020 206e 6565 645f 666c 6174  )..    need_flat
+0002dbb0: 7465 6e20 3d20 6c65 6e28 6469 6d73 2920  ten = len(dims) 
+0002dbc0: 3d3d 2030 0a0a 2020 2020 6966 206e 6565  == 0..    if nee
+0002dbd0: 645f 666c 6174 7465 6e3a 0a20 2020 2020  d_flatten:.     
+0002dbe0: 2020 2023 2054 6865 2074 656e 736f 7220     # The tensor 
+0002dbf0: 6973 2066 6c61 7474 656e 6564 2062 6566  is flattened bef
+0002dc00: 6f72 6520 726f 6c6c 696e 670a 2020 2020  ore rolling.    
+0002dc10: 2020 2020 7820 3d20 6d62 2e72 6573 6861      x = mb.resha
+0002dc20: 7065 2878 3d78 2c20 7368 6170 653d 5b2d  pe(x=x, shape=[-
+0002dc30: 315d 290a 2020 2020 2020 2020 6469 6d73  1]).        dims
+0002dc40: 203d 205b 305d 0a0a 2020 2020 7368 6170   = [0]..    shap
+0002dc50: 6520 3d20 6d62 2e73 6861 7065 2878 3d78  e = mb.shape(x=x
+0002dc60: 290a 0a20 2020 2066 6f72 2073 2c20 6920  )..    for s, i 
+0002dc70: 696e 207a 6970 2873 6869 6674 2c20 6469  in zip(shift, di
+0002dc80: 6d73 293a 0a20 2020 2020 2020 2064 696d  ms):.        dim
+0002dc90: 203d 2076 616c 7565 5f61 7428 7368 6170   = value_at(shap
+0002dca0: 652c 2069 290a 2020 2020 2020 2020 7320  e, i).        s 
+0002dcb0: 3d20 6d62 2e6d 6f64 2878 3d73 2c20 793d  = mb.mod(x=s, y=
+0002dcc0: 6469 6d29 0a20 2020 2020 2020 2073 7461  dim).        sta
+0002dcd0: 7274 5f69 6478 203d 206d 622e 7375 6228  rt_idx = mb.sub(
+0002dce0: 783d 6469 6d2c 2079 3d73 290a 2020 2020  x=dim, y=s).    
+0002dcf0: 2020 2020 696e 6469 6365 7330 203d 206d      indices0 = m
+0002dd00: 622e 7261 6e67 655f 3164 2865 6e64 3d64  b.range_1d(end=d
+0002dd10: 696d 2c20 7374 6172 743d 7374 6172 745f  im, start=start_
+0002dd20: 6964 782c 2073 7465 703d 3129 0a20 2020  idx, step=1).   
+0002dd30: 2020 2020 2069 6e64 6963 6573 3120 3d20       indices1 = 
+0002dd40: 6d62 2e72 616e 6765 5f31 6428 656e 643d  mb.range_1d(end=
+0002dd50: 7374 6172 745f 6964 782c 2073 7461 7274  start_idx, start
+0002dd60: 3d30 2c20 7374 6570 3d31 290a 2020 2020  =0, step=1).    
+0002dd70: 2020 2020 696e 6469 6365 7320 3d20 6d62      indices = mb
+0002dd80: 2e63 6f6e 6361 7428 7661 6c75 6573 3d5b  .concat(values=[
+0002dd90: 696e 6469 6365 7330 2c20 696e 6469 6365  indices0, indice
+0002dda0: 7331 5d2c 2061 7869 733d 3029 0a20 2020  s1], axis=0).   
+0002ddb0: 2020 2020 2078 203d 206d 622e 6761 7468       x = mb.gath
+0002ddc0: 6572 2878 3d78 2c20 696e 6469 6365 733d  er(x=x, indices=
+0002ddd0: 696e 6469 6365 732c 2061 7869 733d 6929  indices, axis=i)
+0002dde0: 0a0a 2020 2020 6966 206e 6565 645f 666c  ..    if need_fl
+0002ddf0: 6174 7465 6e3a 0a20 2020 2020 2020 2078  atten:.        x
+0002de00: 203d 206d 622e 7265 7368 6170 6528 783d   = mb.reshape(x=
+0002de10: 782c 2073 6861 7065 3d6f 7269 6769 6e5f  x, shape=origin_
+0002de20: 7368 6170 6529 0a0a 2020 2020 636f 6e74  shape)..    cont
+0002de30: 6578 742e 6164 6428 782c 206e 6f64 652e  ext.add(x, node.
+0002de40: 6e61 6d65 290a 0a0a 4072 6567 6973 7465  name)...@registe
+0002de50: 725f 746f 7263 685f 6f70 0a64 6566 2069  r_torch_op.def i
+0002de60: 6d32 636f 6c28 636f 6e74 6578 742c 206e  m2col(context, n
+0002de70: 6f64 6529 3a0a 2020 2020 2222 220a 2020  ode):.    """.  
+0002de80: 2020 4578 7472 6163 7420 736c 6964 696e    Extract slidin
+0002de90: 6720 6c6f 6361 6c20 626c 6f63 6b73 2066  g local blocks f
+0002dea0: 726f 6d20 6120 6261 7463 6865 6420 696e  rom a batched in
+0002deb0: 7075 7420 7465 6e73 6f72 2028 7261 6e6b  put tensor (rank
+0002dec0: 3d34 292e 0a0a 2020 2020 746f 7263 682e  =4)...    torch.
+0002ded0: 6e6e 2e66 756e 6374 696f 6e61 6c2e 756e  nn.functional.un
+0002dee0: 666f 6c64 2061 696d 7320 746f 2062 6520  fold aims to be 
+0002def0: 7468 6520 6765 6e65 7261 6c20 7665 7273  the general vers
+0002df00: 696f 6e3a 2069 6d32 636f 6c20 6973 2074  ion: im2col is t
+0002df10: 6865 2072 616e 6b3d 3420 6361 7365 206f  he rank=4 case o
+0002df20: 6620 756e 666f 6c64 2e0a 2020 2020 5079  f unfold..    Py
+0002df30: 546f 7263 6820 6375 7272 656e 746c 7920  Torch currently 
+0002df40: 6f6e 6c79 2073 7570 706f 7274 7320 7261  only supports ra
+0002df50: 6e6b 3d34 2069 6e70 7574 3a20 746f 7263  nk=4 input: torc
+0002df60: 682e 6e6e 2e66 756e 6374 696f 6e61 6c2e  h.nn.functional.
+0002df70: 756e 666f 6c64 2072 6564 6973 7061 7463  unfold redispatc
+0002df80: 6865 7320 746f 2061 743a 3a69 6d32 636f  hes to at::im2co
+0002df90: 6c2c 0a20 2020 2077 6869 6368 2069 7320  l,.    which is 
+0002dfa0: 7768 7920 636f 7265 6d6c 746f 6f6c 7320  why coremltools 
+0002dfb0: 6e65 6564 7320 696d 3263 6f6c 2074 6f20  needs im2col to 
+0002dfc0: 636f 6e76 6572 7420 746f 7263 682e 6e6e  convert torch.nn
+0002dfd0: 2e66 756e 6374 696f 6e61 6c2e 756e 666f  .functional.unfo
+0002dfe0: 6c64 2e0a 0a20 2020 2057 6520 6375 7272  ld...    We curr
+0002dff0: 656e 746c 7920 6f6e 6c79 2073 7570 706f  ently only suppo
+0002e000: 7274 2072 616e 6b3d 3420 696e 7075 7420  rt rank=4 input 
+0002e010: 2863 6f6e 7369 7374 656e 7420 7769 7468  (consistent with
+0002e020: 2050 7954 6f72 6368 2920 616e 6420 6469   PyTorch) and di
+0002e030: 6c61 7469 6f6e 2073 6574 2074 6f20 312e  lation set to 1.
+0002e040: 0a20 2020 204d 6f72 6520 666c 6578 6269  .    More flexbi
+0002e050: 626c 6520 6469 6c61 7469 6f6e 2073 7570  ble dilation sup
+0002e060: 706f 7274 2077 696c 6c20 6265 2061 6464  port will be add
+0002e070: 6564 2069 6e20 7468 6520 6675 7475 7265  ed in the future
+0002e080: 2e0a 0a20 2020 2052 6566 6572 656e 6365  ...    Reference
+0002e090: 2068 7474 7073 3a2f 2f70 7974 6f72 6368   https://pytorch
+0002e0a0: 2e6f 7267 2f64 6f63 732f 7374 6162 6c65  .org/docs/stable
+0002e0b0: 2f67 656e 6572 6174 6564 2f74 6f72 6368  /generated/torch
+0002e0c0: 2e6e 6e2e 556e 666f 6c64 2e68 746d 6c0a  .nn.Unfold.html.
+0002e0d0: 2020 2020 2222 220a 2020 2020 696e 7075      """.    inpu
+0002e0e0: 7473 203d 205f 6765 745f 696e 7075 7473  ts = _get_inputs
+0002e0f0: 2863 6f6e 7465 7874 2c20 6e6f 6465 2c20  (context, node, 
+0002e100: 6578 7065 6374 6564 3d35 290a 2020 2020  expected=5).    
+0002e110: 7820 3d20 696e 7075 7473 5b30 5d0a 2020  x = inputs[0].  
+0002e120: 2020 6b65 726e 656c 5f73 697a 6520 3d20    kernel_size = 
+0002e130: 696e 7075 7473 5b31 5d2e 7661 6c0a 2020  inputs[1].val.  
+0002e140: 2020 6469 6c61 7469 6f6e 203d 2069 6e70    dilation = inp
+0002e150: 7574 735b 325d 2e76 616c 0a20 2020 2070  uts[2].val.    p
+0002e160: 6164 6469 6e67 203d 2069 6e70 7574 735b  adding = inputs[
+0002e170: 335d 2e76 616c 0a20 2020 2073 7472 6964  3].val.    strid
+0002e180: 6520 3d20 696e 7075 7473 5b34 5d2e 7661  e = inputs[4].va
+0002e190: 6c0a 0a20 2020 2069 6620 782e 7261 6e6b  l..    if x.rank
+0002e1a0: 2021 3d20 343a 0a20 2020 2020 2020 2072   != 4:.        r
+0002e1b0: 6169 7365 2056 616c 7565 4572 726f 7228  aise ValueError(
+0002e1c0: 224f 6e6c 7920 7375 7070 6f72 7473 2072  "Only supports r
+0002e1d0: 616e 6b3d 3420 696e 7075 7420 6461 7461  ank=4 input data
+0002e1e0: 2066 6f72 2069 6d32 636f 6c20 2875 6e66   for im2col (unf
+0002e1f0: 6f6c 6429 2e22 290a 2020 2020 6966 206e  old).").    if n
+0002e200: 6f74 2028 6469 6c61 7469 6f6e 5b30 5d20  ot (dilation[0] 
+0002e210: 3d3d 2031 2061 6e64 2064 696c 6174 696f  == 1 and dilatio
+0002e220: 6e5b 315d 203d 3d20 3129 3a0a 2020 2020  n[1] == 1):.    
+0002e230: 2020 2020 7261 6973 6520 5661 6c75 6545      raise ValueE
+0002e240: 7272 6f72 2822 4f6e 6c79 2073 7570 706f  rror("Only suppo
+0002e250: 7274 7320 6469 6c61 7469 6f6e 3d31 2066  rts dilation=1 f
+0002e260: 6f72 2069 6d32 636f 6c20 2875 6e66 6f6c  or im2col (unfol
+0002e270: 6429 2e22 290a 0a20 2020 2023 2066 6f72  d).")..    # for
+0002e280: 2073 696d 706c 6963 6974 792c 2077 6520   simplicity, we 
+0002e290: 6578 706c 6963 6974 6c79 2070 6164 3b20  explicitly pad; 
+0002e2a0: 544f 444f 3a20 696d 706c 6963 6974 2070  TODO: implicit p
+0002e2b0: 6164 6469 6e67 2077 6f75 6c64 2062 6520  adding would be 
+0002e2c0: 6d6f 7265 2065 6666 6963 6965 6e74 0a20  more efficient. 
+0002e2d0: 2020 2023 2074 6f72 6368 2e75 6e66 6f6c     # torch.unfol
+0002e2e0: 6420 7061 6464 696e 6720 6861 7320 6469  d padding has di
+0002e2f0: 6666 6572 656e 7420 7365 6d61 6e74 6963  fferent semantic
+0002e300: 730a 2020 2020 2320 2a20 666f 7220 746f  s.    # * for to
+0002e310: 7263 682e 756e 666f 6c64 0a20 2020 2023  rch.unfold.    #
+0002e320: 2020 2078 2e73 6861 7065 5b69 202b 2078     x.shape[i + x
+0002e330: 2e72 616e 6b20 2d20 7061 6464 696e 672e  .rank - padding.
+0002e340: 7261 6e6b 5d20 3d20 7061 6464 696e 675b  rank] = padding[
+0002e350: 695d 202b 2078 2e73 6861 7065 5b69 202b  i] + x.shape[i +
+0002e360: 2078 2e72 616e 6b20 2d20 7061 6464 696e   x.rank - paddin
+0002e370: 672e 7261 6e6b 5d20 2b20 7061 6464 696e  g.rank] + paddin
+0002e380: 675b 695d 0a20 2020 2023 2020 2074 616b  g[i].    #   tak
+0002e390: 696e 6720 782e 7261 6e6b 203d 2034 2061  ing x.rank = 4 a
+0002e3a0: 6e64 2070 6164 6469 6e67 2e72 616e 6b20  nd padding.rank 
+0002e3b0: 3d20 3220 6173 2061 6e20 6578 616d 706c  = 2 as an exampl
+0002e3c0: 653a 0a20 2020 2023 2020 2020 2020 2078  e:.    #       x
+0002e3d0: 2e73 6861 7065 5b30 202b 2034 202d 2032  .shape[0 + 4 - 2
+0002e3e0: 5d20 3d20 7061 6464 696e 675b 305d 202b  ] = padding[0] +
+0002e3f0: 2078 2e73 6861 7065 5b30 202b 2034 202d   x.shape[0 + 4 -
+0002e400: 2032 5d20 2b20 7061 6464 696e 675b 305d   2] + padding[0]
+0002e410: 0a20 2020 2023 2020 2020 2020 2078 2e73  .    #       x.s
+0002e420: 6861 7065 5b31 202b 2034 202d 2032 5d20  hape[1 + 4 - 2] 
+0002e430: 3d20 7061 6464 696e 675b 315d 202b 2078  = padding[1] + x
+0002e440: 2e73 6861 7065 5b31 202b 2034 202d 2032  .shape[1 + 4 - 2
+0002e450: 5d20 2b20 7061 6464 696e 675b 315d 0a20  ] + padding[1]. 
+0002e460: 2020 2023 202a 2066 6f72 206d 622e 7061     # * for mb.pa
+0002e470: 6428 783d 782c 2070 6164 3d70 6164 2c20  d(x=x, pad=pad, 
+0002e480: 6d6f 6465 3d22 636f 6e73 7461 6e74 2229  mode="constant")
+0002e490: 0a20 2020 2023 2020 2078 2e73 6861 7065  .    #   x.shape
+0002e4a0: 5b69 5d20 3d20 7061 645b 3220 2a20 695d  [i] = pad[2 * i]
+0002e4b0: 202b 2078 2e73 6861 7065 5b69 5d20 2b20   + x.shape[i] + 
+0002e4c0: 7061 645b 3220 2a20 6920 2b20 315d 0a20  pad[2 * i + 1]. 
+0002e4d0: 2020 2023 202a 2066 6f72 2074 6f72 6368     # * for torch
+0002e4e0: 2e6e 6e2e 6675 6e63 7469 6f6e 616c 2e70  .nn.functional.p
+0002e4f0: 6164 0a20 2020 2023 2020 2078 2e73 6861  ad.    #   x.sha
+0002e500: 7065 5b2d 315d 203d 2070 6164 6469 6e67  pe[-1] = padding
+0002e510: 5b30 5d20 2b78 2e73 6861 7065 5b2d 315d  [0] +x.shape[-1]
+0002e520: 202b 2070 6164 6469 6e67 5b31 5d0a 2020   + padding[1].  
+0002e530: 2020 2320 2020 782e 7368 6170 655b 2d32    #   x.shape[-2
+0002e540: 5d20 3d20 7061 6464 696e 675b 325d 202b  ] = padding[2] +
+0002e550: 782e 7368 6170 655b 2d31 5d20 2b20 7061  x.shape[-1] + pa
+0002e560: 6464 696e 675b 335d 0a20 2020 2023 2020  dding[3].    #  
+0002e570: 202e 2e2e 0a20 2020 2023 2020 2078 2e73   ....    #   x.s
+0002e580: 6861 7065 5b2d 695d 203d 2070 6164 6469  hape[-i] = paddi
+0002e590: 6e67 5b32 202a 2069 202d 2032 5d20 2b20  ng[2 * i - 2] + 
+0002e5a0: 782e 7368 6170 655b 2d69 5d20 2b20 7061  x.shape[-i] + pa
+0002e5b0: 6464 696e 675b 3220 2a20 6920 2d20 315d  dding[2 * i - 1]
+0002e5c0: 0a20 2020 2023 2073 6f20 7765 206e 6565  .    # so we nee
+0002e5d0: 6420 746f 2063 6f6e 7665 7274 2074 6f72  d to convert tor
+0002e5e0: 6368 2e75 6e66 6f6c 6420 7061 6464 696e  ch.unfold paddin
+0002e5f0: 6720 746f 206d 622e 7061 6428 6d6f 6465  g to mb.pad(mode
+0002e600: 3d22 636f 6e73 7461 6e74 2229 2070 6164  ="constant") pad
+0002e610: 0a20 2020 206d 6973 7369 6e67 5f64 696d  .    missing_dim
+0002e620: 7320 3d20 782e 7261 6e6b 202d 206c 656e  s = x.rank - len
+0002e630: 2870 6164 6469 6e67 290a 2020 2020 7061  (padding).    pa
+0002e640: 6420 3d20 5b30 2c20 305d 202a 206d 6973  d = [0, 0] * mis
+0002e650: 7369 6e67 5f64 696d 7320 2b20 5f6e 702e  sing_dims + _np.
+0002e660: 6172 7261 7928 7061 6464 696e 6729 2e72  array(padding).r
+0002e670: 6570 6561 7428 3229 2e74 6f6c 6973 7428  epeat(2).tolist(
+0002e680: 290a 2020 2020 7820 3d20 6d62 2e70 6164  ).    x = mb.pad
+0002e690: 2878 3d78 2c20 7061 643d 7061 642c 206d  (x=x, pad=pad, m
+0002e6a0: 6f64 653d 2263 6f6e 7374 616e 7422 290a  ode="constant").
+0002e6b0: 0a20 2020 204e 2c20 432c 2048 2c20 5720  .    N, C, H, W 
+0002e6c0: 3d20 782e 7368 6170 650a 0a20 2020 2023  = x.shape..    #
+0002e6d0: 2047 6574 2074 6f74 616c 206e 756d 6265   Get total numbe
+0002e6e0: 7220 6f66 2062 6c6f 636b 732e 2049 7420  r of blocks. It 
+0002e6f0: 666f 6c6c 6f77 7320 7468 6520 666f 726d  follows the form
+0002e700: 756c 6120 6174 2074 6f72 6368 2e6e 6e2e  ula at torch.nn.
+0002e710: 556e 666f 6c64 2064 6f63 756d 656e 7461  Unfold documenta
+0002e720: 7469 6f6e 2e0a 2020 2020 7370 7469 616c  tion..    sptial
+0002e730: 5f73 697a 6520 3d20 2848 2c20 5729 0a20  _size = (H, W). 
+0002e740: 2020 2062 6c6f 636b 5f63 6f75 6e74 203d     block_count =
+0002e750: 2031 0a20 2020 2066 6f72 2069 2069 6e20   1.    for i in 
+0002e760: 7261 6e67 6528 3229 3a0a 2020 2020 2020  range(2):.      
+0002e770: 2020 626c 6f63 6b5f 636f 756e 7420 2a3d    block_count *=
+0002e780: 2028 0a20 2020 2020 2020 2020 2020 205f   (.            _
+0002e790: 6e70 2e66 6c6f 6f72 280a 2020 2020 2020  np.floor(.      
+0002e7a0: 2020 2020 2020 2020 2020 2320 7468 6520            # the 
+0002e7b0: 6f72 6967 696e 616c 2066 6f72 6d75 6c61  original formula
+0002e7c0: 2069 730a 2020 2020 2020 2020 2020 2020   is.            
+0002e7d0: 2020 2020 2320 2020 2020 2873 7074 6961      #     (sptia
+0002e7e0: 6c5f 7369 7a65 5b69 5d20 2b20 3220 2a20  l_size[i] + 2 * 
+0002e7f0: 7061 6464 696e 675b 695d 202d 2064 696c  padding[i] - dil
+0002e800: 6174 696f 6e5b 695d 202a 2028 6b65 726e  ation[i] * (kern
+0002e810: 656c 5f73 697a 655b 695d 202d 2031 2920  el_size[i] - 1) 
+0002e820: 2d20 3129 202f 2073 7472 6964 655b 695d  - 1) / stride[i]
+0002e830: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0002e840: 2023 2073 696e 6365 2077 6520 6861 7665   # since we have
+0002e850: 2065 7870 6c69 6369 746c 7920 7061 6464   explicitly padd
+0002e860: 6564 2c20 7765 206e 6f20 6c6f 6e67 6572  ed, we no longer
+0002e870: 2061 6464 2032 202a 2070 6164 6469 6e67   add 2 * padding
+0002e880: 5b69 5d20 746f 2073 7074 6961 6c5f 7369  [i] to sptial_si
+0002e890: 7a65 5b69 5d0a 2020 2020 2020 2020 2020  ze[i].          
+0002e8a0: 2020 2020 2020 2873 7074 6961 6c5f 7369        (sptial_si
+0002e8b0: 7a65 5b69 5d20 2d20 6469 6c61 7469 6f6e  ze[i] - dilation
+0002e8c0: 5b69 5d20 2a20 286b 6572 6e65 6c5f 7369  [i] * (kernel_si
+0002e8d0: 7a65 5b69 5d20 2d20 3129 202d 2031 2920  ze[i] - 1) - 1) 
+0002e8e0: 2f20 7374 7269 6465 5b69 5d0a 2020 2020  / stride[i].    
+0002e8f0: 2020 2020 2020 2020 292e 6173 7479 7065          ).astype
+0002e900: 285f 6e70 2e69 6e74 3332 290a 2020 2020  (_np.int32).    
+0002e910: 2020 2020 2020 2020 2b20 310a 2020 2020          + 1.    
+0002e920: 2020 2020 290a 0a20 2020 2022 2222 0a20      )..    """. 
+0002e930: 2020 2054 6865 2069 6d70 6c65 6d65 6e74     The implement
+0002e940: 6174 696f 6e20 6265 6c6f 7720 6173 7375  ation below assu
+0002e950: 6d65 7320 7820 746f 2062 6520 636f 6e74  mes x to be cont
+0002e960: 6967 756f 7573 0a20 2020 2022 2222 0a0a  iguous.    """..
+0002e970: 2020 2020 2320 4765 7420 6261 7463 6820      # Get batch 
+0002e980: 626c 6f63 6b20 696e 6469 6365 732e 0a20  block indices.. 
+0002e990: 2020 2062 6174 6368 5f69 6478 203d 205f     batch_idx = _
+0002e9a0: 6e70 2e61 7261 6e67 6528 4e29 5b3a 2c20  np.arange(N)[:, 
+0002e9b0: 4e6f 6e65 2c20 4e6f 6e65 5d20 2a20 4320  None, None] * C 
+0002e9c0: 2a20 4820 2a20 570a 0a20 2020 2023 2047  * H * W..    # G
+0002e9d0: 6574 2073 7461 7274 696e 6720 626c 6f63  et starting bloc
+0002e9e0: 6b20 696e 6469 6365 732e 0a20 2020 2073  k indices..    s
+0002e9f0: 7461 7274 5f69 6478 203d 205f 6e70 2e61  tart_idx = _np.a
+0002ea00: 7261 6e67 6528 6b65 726e 656c 5f73 697a  range(kernel_siz
+0002ea10: 655b 305d 295b 4e6f 6e65 2c20 3a2c 204e  e[0])[None, :, N
+0002ea20: 6f6e 655d 202a 2057 202b 205f 6e70 2e61  one] * W + _np.a
+0002ea30: 7261 6e67 6528 0a20 2020 2020 2020 206b  range(.        k
+0002ea40: 6572 6e65 6c5f 7369 7a65 5b31 5d0a 2020  ernel_size[1].  
+0002ea50: 2020 290a 0a20 2020 2023 2047 656e 6572    )..    # Gener
+0002ea60: 6174 6520 6465 7074 6820 696e 6469 6365  ate depth indice
+0002ea70: 732e 0a20 2020 2063 6861 6e6e 656c 5f69  s..    channel_i
+0002ea80: 6e64 6578 203d 2048 202a 2057 202a 205f  ndex = H * W * _
+0002ea90: 6e70 2e61 7261 6e67 6528 4329 0a20 2020  np.arange(C).   
+0002eaa0: 2073 7461 7274 5f69 6478 203d 2028 6368   start_idx = (ch
+0002eab0: 616e 6e65 6c5f 696e 6465 785b 4e6f 6e65  annel_index[None
+0002eac0: 2c20 3a2c 204e 6f6e 655d 202b 205f 6e70  , :, None] + _np
+0002ead0: 2e72 6176 656c 2873 7461 7274 5f69 6478  .ravel(start_idx
+0002eae0: 2929 2e72 6573 6861 7065 280a 2020 2020  )).reshape(.    
+0002eaf0: 2020 2020 282d 312c 206b 6572 6e65 6c5f      (-1, kernel_
+0002eb00: 7369 7a65 5b30 5d2c 206b 6572 6e65 6c5f  size[0], kernel_
+0002eb10: 7369 7a65 5b31 5d29 0a20 2020 2029 0a0a  size[1]).    )..
+0002eb20: 2020 2020 2320 4765 7420 6f66 6673 6574      # Get offset
+0002eb30: 7465 6420 696e 6469 6365 7320 6163 726f  ted indices acro
+0002eb40: 7373 2074 6865 2068 6569 6768 7420 616e  ss the height an
+0002eb50: 6420 7769 6474 6820 6f66 2069 6e70 7574  d width of input
+0002eb60: 2061 7272 6179 2e0a 2020 2020 726f 775f   array..    row_
+0002eb70: 6578 7465 6e74 203d 2048 202d 206b 6572  extent = H - ker
+0002eb80: 6e65 6c5f 7369 7a65 5b30 5d20 2b20 310a  nel_size[0] + 1.
+0002eb90: 2020 2020 636f 6c5f 6578 7465 6e74 203d      col_extent =
+0002eba0: 2057 202d 206b 6572 6e65 6c5f 7369 7a65   W - kernel_size
+0002ebb0: 5b31 5d20 2b20 310a 2020 2020 6f66 6673  [1] + 1.    offs
+0002ebc0: 6574 5f69 6478 203d 205f 6e70 2e61 7261  et_idx = _np.ara
+0002ebd0: 6e67 6528 302c 2072 6f77 5f65 7874 656e  nge(0, row_exten
+0002ebe0: 742c 2073 7472 6964 655b 305d 295b 4e6f  t, stride[0])[No
+0002ebf0: 6e65 2c20 3a2c 204e 6f6e 655d 202a 2057  ne, :, None] * W
+0002ec00: 202b 205f 6e70 2e61 7261 6e67 6528 302c   + _np.arange(0,
+0002ec10: 2063 6f6c 5f65 7874 656e 742c 2073 7472   col_extent, str
+0002ec20: 6964 655b 315d 290a 2020 2020 696e 6469  ide[1]).    indi
+0002ec30: 6365 7320 3d20 5f6e 702e 7261 7665 6c28  ces = _np.ravel(
+0002ec40: 7374 6172 745f 6964 7829 5b3a 2c20 4e6f  start_idx)[:, No
+0002ec50: 6e65 5d20 2b20 5f6e 702e 7261 7665 6c28  ne] + _np.ravel(
+0002ec60: 6f66 6673 6574 5f69 6478 290a 0a20 2020  offset_idx)..   
+0002ec70: 2023 2047 6174 6865 7220 6261 7463 6865   # Gather batche
+0002ec80: 7320 746f 6765 7468 6572 2e0a 2020 2020  s together..    
+0002ec90: 696e 6469 6365 7320 3d20 6261 7463 685f  indices = batch_
+0002eca0: 6964 7820 2b20 696e 6469 6365 730a 2020  idx + indices.  
+0002ecb0: 2020 7820 3d20 6d62 2e72 6573 6861 7065    x = mb.reshape
+0002ecc0: 2878 3d78 2c20 7368 6170 653d 5b2d 315d  (x=x, shape=[-1]
+0002ecd0: 290a 2020 2020 6761 7468 6572 6564 5f64  ).    gathered_d
+0002ece0: 6174 6120 3d20 6d62 2e67 6174 6865 725f  ata = mb.gather_
+0002ecf0: 616c 6f6e 675f 6178 6973 2878 3d78 2c20  along_axis(x=x, 
+0002ed00: 696e 6469 6365 733d 696e 6469 6365 732e  indices=indices.
+0002ed10: 7265 7368 6170 6528 2d31 292c 2061 7869  reshape(-1), axi
+0002ed20: 733d 3029 0a20 2020 2062 6c6f 636b 5f73  s=0).    block_s
+0002ed30: 697a 6520 3d20 4320 2a20 6b65 726e 656c  ize = C * kernel
+0002ed40: 5f73 697a 655b 305d 202a 206b 6572 6e65  _size[0] * kerne
+0002ed50: 6c5f 7369 7a65 5b31 5d0a 2020 2020 6f75  l_size[1].    ou
+0002ed60: 7470 7574 203d 206d 622e 7265 7368 6170  tput = mb.reshap
+0002ed70: 6528 0a20 2020 2020 2020 2078 3d67 6174  e(.        x=gat
+0002ed80: 6865 7265 645f 6461 7461 2c20 7368 6170  hered_data, shap
+0002ed90: 653d 284e 2c20 626c 6f63 6b5f 7369 7a65  e=(N, block_size
+0002eda0: 2c20 626c 6f63 6b5f 636f 756e 7429 2c20  , block_count), 
+0002edb0: 6e61 6d65 3d6e 6f64 652e 6e61 6d65 0a20  name=node.name. 
+0002edc0: 2020 2029 0a0a 2020 2020 636f 6e74 6578     )..    contex
+0002edd0: 742e 6164 6428 6f75 7470 7574 290a 0a0a  t.add(output)...
+0002ede0: 4072 6567 6973 7465 725f 746f 7263 685f  @register_torch_
+0002edf0: 6f70 0a64 6566 2063 6f6d 706c 6578 2863  op.def complex(c
+0002ee00: 6f6e 7465 7874 2c20 6e6f 6465 293a 0a20  ontext, node):. 
+0002ee10: 2020 2072 6561 6c5f 7061 7274 2c20 696d     real_part, im
+0002ee20: 6167 5f70 6172 7420 3d20 5f67 6574 5f69  ag_part = _get_i
+0002ee30: 6e70 7574 7328 636f 6e74 6578 742c 206e  nputs(context, n
+0002ee40: 6f64 652c 2065 7870 6563 7465 643d 3229  ode, expected=2)
+0002ee50: 0a20 2020 2072 6573 756c 7420 3d20 6d62  .    result = mb
+0002ee60: 2e63 6f6d 706c 6578 2872 6561 6c5f 6461  .complex(real_da
+0002ee70: 7461 3d72 6561 6c5f 7061 7274 2c20 696d  ta=real_part, im
+0002ee80: 6167 5f64 6174 613d 696d 6167 5f70 6172  ag_data=imag_par
+0002ee90: 7429 0a20 2020 2063 6f6e 7465 7874 2e61  t).    context.a
+0002eea0: 6464 2872 6573 756c 742c 206e 6f64 652e  dd(result, node.
+0002eeb0: 6e61 6d65 290a 0a0a 4072 6567 6973 7465  name)...@registe
+0002eec0: 725f 746f 7263 685f 6f70 0a64 6566 2072  r_torch_op.def r
+0002eed0: 6561 6c28 636f 6e74 6578 742c 206e 6f64  eal(context, nod
+0002eee0: 6529 3a0a 2020 2020 696e 7075 745f 6461  e):.    input_da
+0002eef0: 7461 203d 205f 6765 745f 696e 7075 7473  ta = _get_inputs
+0002ef00: 2863 6f6e 7465 7874 2c20 6e6f 6465 2c20  (context, node, 
+0002ef10: 6578 7065 6374 6564 3d31 295b 305d 0a20  expected=1)[0]. 
+0002ef20: 2020 2069 6620 7479 7065 732e 6973 5f63     if types.is_c
+0002ef30: 6f6d 706c 6578 2869 6e70 7574 5f64 6174  omplex(input_dat
+0002ef40: 612e 6474 7970 6529 3a0a 2020 2020 2020  a.dtype):.      
+0002ef50: 2020 7265 616c 5f70 6172 7420 3d20 6d62    real_part = mb
+0002ef60: 2e63 6f6d 706c 6578 5f72 6561 6c28 6461  .complex_real(da
+0002ef70: 7461 3d69 6e70 7574 5f64 6174 6129 0a20  ta=input_data). 
+0002ef80: 2020 2020 2020 2063 6f6e 7465 7874 2e61         context.a
+0002ef90: 6464 2872 6561 6c5f 7061 7274 2c20 6e6f  dd(real_part, no
+0002efa0: 6465 2e6e 616d 6529 0a20 2020 2065 6c73  de.name).    els
+0002efb0: 653a 0a20 2020 2020 2020 2063 6f6e 7465  e:.        conte
+0002efc0: 7874 2e61 6464 2869 6e70 7574 5f64 6174  xt.add(input_dat
+0002efd0: 612c 206e 6f64 652e 6e61 6d65 290a 0a0a  a, node.name)...
+0002efe0: 4072 6567 6973 7465 725f 746f 7263 685f  @register_torch_
+0002eff0: 6f70 0a64 6566 2069 6d61 6728 636f 6e74  op.def imag(cont
+0002f000: 6578 742c 206e 6f64 6529 3a0a 2020 2020  ext, node):.    
+0002f010: 696e 7075 745f 6461 7461 203d 205f 6765  input_data = _ge
+0002f020: 745f 696e 7075 7473 2863 6f6e 7465 7874  t_inputs(context
+0002f030: 2c20 6e6f 6465 2c20 6578 7065 6374 6564  , node, expected
+0002f040: 3d31 295b 305d 0a20 2020 2069 6620 6e6f  =1)[0].    if no
+0002f050: 7420 7479 7065 732e 6973 5f63 6f6d 706c  t types.is_compl
+0002f060: 6578 2869 6e70 7574 5f64 6174 612e 6474  ex(input_data.dt
+0002f070: 7970 6529 3a0a 2020 2020 2020 2020 2320  ype):.        # 
+0002f080: 4b65 6570 2063 6f6e 7369 7374 656e 7420  Keep consistent 
+0002f090: 7769 7468 2050 7954 6f72 6368 2e0a 2020  with PyTorch..  
+0002f0a0: 2020 2020 2020 7261 6973 6520 5661 6c75        raise Valu
+0002f0b0: 6545 7272 6f72 2822 5468 6520 6069 6d61  eError("The `ima
+0002f0c0: 6760 206f 7020 6f6e 6c79 2073 7570 706f  g` op only suppo
+0002f0d0: 7274 7320 636f 6d70 6c65 7820 696e 7075  rts complex inpu
+0002f0e0: 742e 2229 0a20 2020 2072 6561 6c5f 7061  t.").    real_pa
+0002f0f0: 7274 203d 206d 622e 636f 6d70 6c65 785f  rt = mb.complex_
+0002f100: 696d 6167 2864 6174 613d 696e 7075 745f  imag(data=input_
+0002f110: 6461 7461 290a 2020 2020 636f 6e74 6578  data).    contex
+0002f120: 742e 6164 6428 7265 616c 5f70 6172 742c  t.add(real_part,
+0002f130: 206e 6f64 652e 6e61 6d65 290a 0a0a 4072   node.name)...@r
+0002f140: 6567 6973 7465 725f 746f 7263 685f 6f70  egister_torch_op
+0002f150: 0a64 6566 2066 6674 5f66 6674 2863 6f6e  .def fft_fft(con
+0002f160: 7465 7874 2c20 6e6f 6465 293a 0a20 2020  text, node):.   
+0002f170: 2022 2222 4c6f 7765 7273 2074 6f72 6368   """Lowers torch
+0002f180: 2e66 6674 2e66 6674 2062 7920 7468 6520  .fft.fft by the 
+0002f190: 6469 616c 6563 7420 6f70 2060 636f 6d70  dialect op `comp
+0002f1a0: 6c65 785f 6666 7460 2066 726f 6d20 636f  lex_fft` from co
+0002f1b0: 6d70 6c65 785f 6469 616c 6563 745f 6f70  mplex_dialect_op
+0002f1c0: 732e 7079 2e22 2222 0a20 2020 2069 6e70  s.py.""".    inp
+0002f1d0: 7574 5f64 6174 612c 206e 2c20 6469 6d2c  ut_data, n, dim,
+0002f1e0: 206e 6f72 6d20 3d20 5f67 6574 5f69 6e70   norm = _get_inp
+0002f1f0: 7574 7328 636f 6e74 6578 742c 206e 6f64  uts(context, nod
+0002f200: 652c 2065 7870 6563 7465 643d 5b34 5d29  e, expected=[4])
+0002f210: 0a20 2020 2066 6674 5f72 6573 203d 206d  .    fft_res = m
+0002f220: 622e 636f 6d70 6c65 785f 6666 7428 6461  b.complex_fft(da
+0002f230: 7461 3d69 6e70 7574 5f64 6174 612c 206e  ta=input_data, n
+0002f240: 3d6e 2c20 6469 6d3d 6469 6d2c 206e 6f72  =n, dim=dim, nor
+0002f250: 6d3d 6e6f 726d 290a 2020 2020 636f 6e74  m=norm).    cont
+0002f260: 6578 742e 6164 6428 6666 745f 7265 732c  ext.add(fft_res,
+0002f270: 206e 6f64 652e 6e61 6d65 290a 0a0a 4072   node.name)...@r
+0002f280: 6567 6973 7465 725f 746f 7263 685f 6f70  egister_torch_op
+0002f290: 0a64 6566 2066 6674 5f66 6674 6e28 636f  .def fft_fftn(co
+0002f2a0: 6e74 6578 742c 206e 6f64 6529 3a0a 2020  ntext, node):.  
+0002f2b0: 2020 2222 224c 6f77 6572 7320 746f 7263    """Lowers torc
+0002f2c0: 682e 6666 742e 6666 746e 2062 7920 7468  h.fft.fftn by th
+0002f2d0: 6520 6469 616c 6563 7420 6f70 2060 636f  e dialect op `co
+0002f2e0: 6d70 6c65 785f 6666 746e 6020 6672 6f6d  mplex_fftn` from
+0002f2f0: 2063 6f6d 706c 6578 5f64 6961 6c65 6374   complex_dialect
+0002f300: 5f6f 7073 2e70 792e 2222 220a 2020 2020  _ops.py.""".    
+0002f310: 696e 7075 745f 6461 7461 2c20 7368 6170  input_data, shap
+0002f320: 6573 2c20 6469 6d73 2c20 6e6f 726d 203d  es, dims, norm =
+0002f330: 205f 6765 745f 696e 7075 7473 2863 6f6e   _get_inputs(con
+0002f340: 7465 7874 2c20 6e6f 6465 2c20 6578 7065  text, node, expe
+0002f350: 6374 6564 3d5b 345d 290a 2020 2020 6666  cted=[4]).    ff
+0002f360: 745f 7265 7320 3d20 6d62 2e63 6f6d 706c  t_res = mb.compl
+0002f370: 6578 5f66 6674 6e28 6461 7461 3d69 6e70  ex_fftn(data=inp
+0002f380: 7574 5f64 6174 612c 2073 6861 7065 733d  ut_data, shapes=
+0002f390: 7368 6170 6573 2c20 6469 6d73 3d64 696d  shapes, dims=dim
+0002f3a0: 732c 206e 6f72 6d3d 6e6f 726d 290a 2020  s, norm=norm).  
+0002f3b0: 2020 636f 6e74 6578 742e 6164 6428 6666    context.add(ff
+0002f3c0: 745f 7265 732c 206e 6f64 652e 6e61 6d65  t_res, node.name
+0002f3d0: 290a 0a0a 4072 6567 6973 7465 725f 746f  )...@register_to
+0002f3e0: 7263 685f 6f70 0a64 6566 2066 6674 5f72  rch_op.def fft_r
+0002f3f0: 6666 7428 636f 6e74 6578 742c 206e 6f64  fft(context, nod
+0002f400: 6529 3a0a 2020 2020 2222 224c 6f77 6572  e):.    """Lower
+0002f410: 7320 746f 7263 682e 6666 742e 7266 6674  s torch.fft.rfft
+0002f420: 2062 7920 7468 6520 6469 616c 6563 7420   by the dialect 
+0002f430: 6f70 2060 636f 6d70 6c65 785f 7266 6674  op `complex_rfft
+0002f440: 6020 6672 6f6d 2063 6f6d 706c 6578 5f64  ` from complex_d
+0002f450: 6961 6c65 6374 5f6f 7073 2e70 792e 2222  ialect_ops.py.""
+0002f460: 220a 2020 2020 696e 7075 745f 6461 7461  ".    input_data
+0002f470: 2c20 6e2c 2064 696d 2c20 6e6f 726d 203d  , n, dim, norm =
+0002f480: 205f 6765 745f 696e 7075 7473 2863 6f6e   _get_inputs(con
+0002f490: 7465 7874 2c20 6e6f 6465 2c20 6578 7065  text, node, expe
+0002f4a0: 6374 6564 3d5b 345d 290a 2020 2020 7266  cted=[4]).    rf
+0002f4b0: 6674 5f72 6573 203d 206d 622e 636f 6d70  ft_res = mb.comp
+0002f4c0: 6c65 785f 7266 6674 2864 6174 613d 696e  lex_rfft(data=in
+0002f4d0: 7075 745f 6461 7461 2c20 6e3d 6e2c 2064  put_data, n=n, d
+0002f4e0: 696d 3d64 696d 2c20 6e6f 726d 3d6e 6f72  im=dim, norm=nor
+0002f4f0: 6d29 0a20 2020 2063 6f6e 7465 7874 2e61  m).    context.a
+0002f500: 6464 2872 6666 745f 7265 732c 206e 6f64  dd(rfft_res, nod
+0002f510: 652e 6e61 6d65 290a 0a0a 4072 6567 6973  e.name)...@regis
+0002f520: 7465 725f 746f 7263 685f 6f70 0a64 6566  ter_torch_op.def
+0002f530: 2066 6674 5f72 6666 746e 2863 6f6e 7465   fft_rfftn(conte
+0002f540: 7874 2c20 6e6f 6465 293a 0a20 2020 2022  xt, node):.    "
+0002f550: 2222 4c6f 7765 7273 2074 6f72 6368 2e66  ""Lowers torch.f
+0002f560: 6674 2e72 6666 746e 2062 7920 7468 6520  ft.rfftn by the 
+0002f570: 6469 616c 6563 7420 6f70 2060 636f 6d70  dialect op `comp
+0002f580: 6c65 785f 7266 6674 6e60 2066 726f 6d20  lex_rfftn` from 
+0002f590: 636f 6d70 6c65 785f 6469 616c 6563 745f  complex_dialect_
+0002f5a0: 6f70 732e 7079 2e22 2222 0a20 2020 2069  ops.py.""".    i
+0002f5b0: 6e70 7574 5f64 6174 612c 2073 6861 7065  nput_data, shape
+0002f5c0: 732c 2064 696d 732c 206e 6f72 6d20 3d20  s, dims, norm = 
+0002f5d0: 5f67 6574 5f69 6e70 7574 7328 636f 6e74  _get_inputs(cont
+0002f5e0: 6578 742c 206e 6f64 652c 2065 7870 6563  ext, node, expec
+0002f5f0: 7465 643d 5b34 5d29 0a20 2020 2072 6666  ted=[4]).    rff
+0002f600: 745f 7265 7320 3d20 6d62 2e63 6f6d 706c  t_res = mb.compl
+0002f610: 6578 5f72 6666 746e 2864 6174 613d 696e  ex_rfftn(data=in
+0002f620: 7075 745f 6461 7461 2c20 7368 6170 6573  put_data, shapes
+0002f630: 3d73 6861 7065 732c 2064 696d 733d 6469  =shapes, dims=di
+0002f640: 6d73 2c20 6e6f 726d 3d6e 6f72 6d29 0a20  ms, norm=norm). 
+0002f650: 2020 2063 6f6e 7465 7874 2e61 6464 2872     context.add(r
+0002f660: 6666 745f 7265 732c 206e 6f64 652e 6e61  fft_res, node.na
+0002f670: 6d65 290a 0a0a 4072 6567 6973 7465 725f  me)...@register_
+0002f680: 746f 7263 685f 6f70 0a64 6566 2066 6674  torch_op.def fft
+0002f690: 5f69 6666 7428 636f 6e74 6578 742c 206e  _ifft(context, n
+0002f6a0: 6f64 6529 3a0a 2020 2020 2222 224c 6f77  ode):.    """Low
+0002f6b0: 6572 7320 746f 7263 682e 6666 742e 6966  ers torch.fft.if
+0002f6c0: 6674 2062 7920 7468 6520 6469 616c 6563  ft by the dialec
+0002f6d0: 7420 6f70 2060 636f 6d70 6c65 785f 6966  t op `complex_if
+0002f6e0: 6674 6020 6672 6f6d 2063 6f6d 706c 6578  ft` from complex
+0002f6f0: 5f64 6961 6c65 6374 5f6f 7073 2e70 792e  _dialect_ops.py.
+0002f700: 2222 220a 2020 2020 696e 7075 745f 6461  """.    input_da
+0002f710: 7461 2c20 6e2c 2064 696d 2c20 6e6f 726d  ta, n, dim, norm
+0002f720: 203d 205f 6765 745f 696e 7075 7473 2863   = _get_inputs(c
+0002f730: 6f6e 7465 7874 2c20 6e6f 6465 2c20 6578  ontext, node, ex
+0002f740: 7065 6374 6564 3d5b 345d 290a 2020 2020  pected=[4]).    
+0002f750: 6966 6674 5f72 6573 203d 206d 622e 636f  ifft_res = mb.co
+0002f760: 6d70 6c65 785f 6966 6674 2864 6174 613d  mplex_ifft(data=
+0002f770: 696e 7075 745f 6461 7461 2c20 6e3d 6e2c  input_data, n=n,
+0002f780: 2064 696d 3d64 696d 2c20 6e6f 726d 3d6e   dim=dim, norm=n
+0002f790: 6f72 6d29 0a20 2020 2063 6f6e 7465 7874  orm).    context
+0002f7a0: 2e61 6464 2869 6666 745f 7265 732c 206e  .add(ifft_res, n
+0002f7b0: 6f64 652e 6e61 6d65 290a 0a0a 4072 6567  ode.name)...@reg
+0002f7c0: 6973 7465 725f 746f 7263 685f 6f70 0a64  ister_torch_op.d
+0002f7d0: 6566 2066 6674 5f69 6666 746e 2863 6f6e  ef fft_ifftn(con
+0002f7e0: 7465 7874 2c20 6e6f 6465 293a 0a20 2020  text, node):.   
+0002f7f0: 2022 2222 4c6f 7765 7273 2074 6f72 6368   """Lowers torch
+0002f800: 2e66 6674 2e69 6666 746e 2062 7920 7468  .fft.ifftn by th
+0002f810: 6520 6469 616c 6563 7420 6f70 2060 636f  e dialect op `co
+0002f820: 6d70 6c65 785f 6966 6674 6e60 2066 726f  mplex_ifftn` fro
+0002f830: 6d20 636f 6d70 6c65 785f 6469 616c 6563  m complex_dialec
+0002f840: 745f 6f70 732e 7079 2e22 2222 0a20 2020  t_ops.py.""".   
+0002f850: 2069 6e70 7574 5f64 6174 612c 2073 6861   input_data, sha
+0002f860: 7065 732c 2064 696d 732c 206e 6f72 6d20  pes, dims, norm 
+0002f870: 3d20 5f67 6574 5f69 6e70 7574 7328 636f  = _get_inputs(co
+0002f880: 6e74 6578 742c 206e 6f64 652c 2065 7870  ntext, node, exp
+0002f890: 6563 7465 643d 5b34 5d29 0a20 2020 2069  ected=[4]).    i
+0002f8a0: 6666 746e 5f72 6573 203d 206d 622e 636f  fftn_res = mb.co
+0002f8b0: 6d70 6c65 785f 6966 6674 6e28 6461 7461  mplex_ifftn(data
+0002f8c0: 3d69 6e70 7574 5f64 6174 612c 2073 6861  =input_data, sha
+0002f8d0: 7065 733d 7368 6170 6573 2c20 6469 6d73  pes=shapes, dims
+0002f8e0: 3d64 696d 732c 206e 6f72 6d3d 6e6f 726d  =dims, norm=norm
+0002f8f0: 290a 2020 2020 636f 6e74 6578 742e 6164  ).    context.ad
+0002f900: 6428 6966 6674 6e5f 7265 732c 206e 6f64  d(ifftn_res, nod
+0002f910: 652e 6e61 6d65 290a 0a0a 4072 6567 6973  e.name)...@regis
+0002f920: 7465 725f 746f 7263 685f 6f70 0a64 6566  ter_torch_op.def
+0002f930: 2066 6674 5f69 7266 6674 2863 6f6e 7465   fft_irfft(conte
+0002f940: 7874 2c20 6e6f 6465 293a 0a20 2020 2022  xt, node):.    "
+0002f950: 2222 4c6f 7765 7273 2074 6f72 6368 2e66  ""Lowers torch.f
+0002f960: 6674 2e69 7266 6674 2062 7920 7468 6520  ft.irfft by the 
+0002f970: 6469 616c 6563 7420 6f70 2060 636f 6d70  dialect op `comp
+0002f980: 6c65 785f 6972 6666 7460 2066 726f 6d20  lex_irfft` from 
+0002f990: 636f 6d70 6c65 785f 6469 616c 6563 745f  complex_dialect_
+0002f9a0: 6f70 732e 7079 2e22 2222 0a20 2020 2069  ops.py.""".    i
+0002f9b0: 6e70 7574 5f64 6174 612c 206e 2c20 6469  nput_data, n, di
+0002f9c0: 6d2c 206e 6f72 6d20 3d20 5f67 6574 5f69  m, norm = _get_i
+0002f9d0: 6e70 7574 7328 636f 6e74 6578 742c 206e  nputs(context, n
+0002f9e0: 6f64 652c 2065 7870 6563 7465 643d 5b34  ode, expected=[4
+0002f9f0: 5d29 0a20 2020 2069 7266 6674 5f72 6573  ]).    irfft_res
+0002fa00: 203d 206d 622e 636f 6d70 6c65 785f 6972   = mb.complex_ir
+0002fa10: 6666 7428 6461 7461 3d69 6e70 7574 5f64  fft(data=input_d
+0002fa20: 6174 612c 206e 3d6e 2c20 6469 6d3d 6469  ata, n=n, dim=di
+0002fa30: 6d2c 206e 6f72 6d3d 6e6f 726d 290a 2020  m, norm=norm).  
+0002fa40: 2020 636f 6e74 6578 742e 6164 6428 6972    context.add(ir
+0002fa50: 6666 745f 7265 732c 206e 6f64 652e 6e61  fft_res, node.na
+0002fa60: 6d65 290a 0a0a 4072 6567 6973 7465 725f  me)...@register_
+0002fa70: 746f 7263 685f 6f70 0a64 6566 2066 6674  torch_op.def fft
+0002fa80: 5f69 7266 6674 6e28 636f 6e74 6578 742c  _irfftn(context,
+0002fa90: 206e 6f64 6529 3a0a 2020 2020 2222 224c   node):.    """L
+0002faa0: 6f77 6572 7320 746f 7263 682e 6666 742e  owers torch.fft.
+0002fab0: 6972 6666 746e 2062 7920 7468 6520 6469  irfftn by the di
+0002fac0: 616c 6563 7420 6f70 2060 636f 6d70 6c65  alect op `comple
+0002fad0: 785f 6972 6666 746e 6020 6672 6f6d 2063  x_irfftn` from c
+0002fae0: 6f6d 706c 6578 5f64 6961 6c65 6374 5f6f  omplex_dialect_o
+0002faf0: 7073 2e70 792e 2222 220a 2020 2020 696e  ps.py.""".    in
+0002fb00: 7075 745f 6461 7461 2c20 7368 6170 6573  put_data, shapes
+0002fb10: 2c20 6469 6d73 2c20 6e6f 726d 203d 205f  , dims, norm = _
+0002fb20: 6765 745f 696e 7075 7473 2863 6f6e 7465  get_inputs(conte
+0002fb30: 7874 2c20 6e6f 6465 2c20 6578 7065 6374  xt, node, expect
+0002fb40: 6564 3d5b 345d 290a 2020 2020 6972 6666  ed=[4]).    irff
+0002fb50: 746e 5f72 6573 203d 206d 622e 636f 6d70  tn_res = mb.comp
+0002fb60: 6c65 785f 6972 6666 746e 2864 6174 613d  lex_irfftn(data=
+0002fb70: 696e 7075 745f 6461 7461 2c20 7368 6170  input_data, shap
+0002fb80: 6573 3d73 6861 7065 732c 2064 696d 733d  es=shapes, dims=
+0002fb90: 6469 6d73 2c20 6e6f 726d 3d6e 6f72 6d29  dims, norm=norm)
+0002fba0: 0a20 2020 2063 6f6e 7465 7874 2e61 6464  .    context.add
+0002fbb0: 2869 7266 6674 6e5f 7265 732c 206e 6f64  (irfftn_res, nod
+0002fbc0: 652e 6e61 6d65 290a 0a40 7265 6769 7374  e.name)..@regist
+0002fbd0: 6572 5f74 6f72 6368 5f6f 700a 6465 6620  er_torch_op.def 
+0002fbe0: 7374 6674 2863 6f6e 7465 7874 2c20 6e6f  stft(context, no
+0002fbf0: 6465 293a 0a20 2020 2022 2222 0a20 2020  de):.    """.   
+0002fc00: 204c 6f77 6572 7320 746f 7263 682e 7374   Lowers torch.st
+0002fc10: 6674 2077 6974 6820 7468 6520 6469 616c  ft with the dial
+0002fc20: 6563 7420 6f70 2060 636f 6d70 6c65 785f  ect op `complex_
+0002fc30: 7374 6674 6020 6672 6f6d 2063 6f6d 706c  stft` from compl
+0002fc40: 6578 5f64 6961 6c65 6374 5f6f 7073 2e70  ex_dialect_ops.p
+0002fc50: 790a 2020 2020 2222 220a 2020 2020 696e  y.    """.    in
+0002fc60: 7075 745f 6461 7461 2c20 6e5f 6666 742c  put_data, n_fft,
+0002fc70: 2068 6f70 5f6c 656e 6774 682c 2077 696e   hop_length, win
+0002fc80: 5f6c 656e 6774 682c 2077 696e 646f 772c  _length, window,
+0002fc90: 206e 6f72 6d61 6c69 7a65 642c 206f 6e65   normalized, one
+0002fca0: 7369 6465 642c 205f 203d 205f 6765 745f  sided, _ = _get_
+0002fcb0: 696e 7075 7473 2863 6f6e 7465 7874 2c20  inputs(context, 
+0002fcc0: 6e6f 6465 2c20 6d69 6e5f 6578 7065 6374  node, min_expect
+0002fcd0: 6564 3d32 290a 2020 2020 6966 2074 7970  ed=2).    if typ
+0002fce0: 6573 2e69 735f 636f 6d70 6c65 7828 696e  es.is_complex(in
+0002fcf0: 7075 745f 6461 7461 2e64 7479 7065 293a  put_data.dtype):
+0002fd00: 0a20 2020 2020 2020 206f 6e65 7369 6465  .        oneside
+0002fd10: 6420 3d20 4661 6c73 6520 2320 7079 746f  d = False # pyto
+0002fd20: 7263 6820 6465 6661 756c 7473 206f 6e65  rch defaults one
+0002fd30: 7369 6465 6420 746f 2046 616c 7365 2066  sided to False f
+0002fd40: 6f72 2063 6f6d 706c 6578 2069 6e70 7574  or complex input
+0002fd50: 730a 2020 2020 7374 6674 5f72 6573 203d  s.    stft_res =
+0002fd60: 206d 622e 636f 6d70 6c65 785f 7374 6674   mb.complex_stft
+0002fd70: 280a 2020 2020 2020 2020 696e 7075 743d  (.        input=
+0002fd80: 696e 7075 745f 6461 7461 2c20 0a20 2020  input_data, .   
+0002fd90: 2020 2020 206e 5f66 6674 3d6e 5f66 6674       n_fft=n_fft
+0002fda0: 2c20 0a20 2020 2020 2020 2068 6f70 5f6c  , .        hop_l
+0002fdb0: 656e 6774 683d 686f 705f 6c65 6e67 7468  ength=hop_length
+0002fdc0: 2c20 0a20 2020 2020 2020 2077 696e 5f6c  , .        win_l
+0002fdd0: 656e 6774 683d 7769 6e5f 6c65 6e67 7468  ength=win_length
+0002fde0: 2c20 0a20 2020 2020 2020 2077 696e 646f  , .        windo
+0002fdf0: 773d 7769 6e64 6f77 2c20 0a20 2020 2020  w=window, .     
+0002fe00: 2020 206e 6f72 6d61 6c69 7a65 643d 6e6f     normalized=no
+0002fe10: 726d 616c 697a 6564 2c20 0a20 2020 2020  rmalized, .     
+0002fe20: 2020 206f 6e65 7369 6465 643d 6f6e 6573     onesided=ones
+0002fe30: 6964 6564 290a 2020 2020 636f 6e74 6578  ided).    contex
+0002fe40: 742e 6164 6428 7374 6674 5f72 6573 2c20  t.add(stft_res, 
+0002fe50: 6e6f 6465 2e6e 616d 6529 0a0a 4072 6567  node.name)..@reg
+0002fe60: 6973 7465 725f 746f 7263 685f 6f70 2874  ister_torch_op(t
+0002fe70: 6f72 6368 5f61 6c69 6173 3d5b 2274 6f72  orch_alias=["tor
+0002fe80: 6368 7669 7369 6f6e 3a3a 6e6d 7322 5d29  chvision::nms"])
+0002fe90: 0a64 6566 2074 6f72 6368 7669 7369 6f6e  .def torchvision
+0002fea0: 5f6e 6d73 2863 6f6e 7465 7874 2c20 6e6f  _nms(context, no
+0002feb0: 6465 293a 0a20 2020 2069 6e70 7574 7320  de):.    inputs 
+0002fec0: 3d20 5f67 6574 5f69 6e70 7574 7328 636f  = _get_inputs(co
+0002fed0: 6e74 6578 742c 206e 6f64 652c 2065 7870  ntext, node, exp
+0002fee0: 6563 7465 643d 3329 0a20 2020 2062 6f78  ected=3).    box
+0002fef0: 6573 2c20 7363 6f72 6573 203d 2070 726f  es, scores = pro
+0002ff00: 6d6f 7465 5f69 6e70 7574 5f64 7479 7065  mote_input_dtype
+0002ff10: 7328 5b69 6e70 7574 735b 305d 2c20 696e  s([inputs[0], in
+0002ff20: 7075 7473 5b31 5d5d 290a 2020 2020 696f  puts[1]]).    io
+0002ff30: 755f 7468 7265 7368 6f6c 6420 3d20 696e  u_threshold = in
+0002ff40: 7075 7473 5b32 5d2e 7661 6c0a 2020 2020  puts[2].val.    
+0002ff50: 2320 5573 6520 666c 6f61 7420 6d69 6e20  # Use float min 
+0002ff60: 746f 2061 766f 6964 2062 6f78 6573 2062  to avoid boxes b
+0002ff70: 6569 6e67 2070 7275 6e65 6420 6279 2073  eing pruned by s
+0002ff80: 636f 7265 7320 696e 204d 494c 204e 4d53  cores in MIL NMS
+0002ff90: 206f 702e 0a20 2020 2073 636f 7265 5f74   op..    score_t
+0002ffa0: 6872 6573 686f 6c64 203d 2028 0a20 2020  hreshold = (.   
+0002ffb0: 2020 2020 205f 6e70 2e66 696e 666f 285f       _np.finfo(_
+0002ffc0: 6e70 2e66 6c6f 6174 3136 292e 6d69 6e20  np.float16).min 
+0002ffd0: 6966 2062 6f78 6573 2e64 7479 7065 2e5f  if boxes.dtype._
+0002ffe0: 7769 6474 6820 3d3d 2031 3620 656c 7365  width == 16 else
+0002fff0: 205f 6e70 2e66 696e 666f 285f 6e70 2e66   _np.finfo(_np.f
+00030000: 6c6f 6174 3332 292e 6d69 6e0a 2020 2020  loat32).min.    
+00030010: 290a 0a20 2020 2062 6f78 5f6e 756d 203d  )..    box_num =
+00030020: 2062 6f78 6573 2e73 6861 7065 5b30 5d0a   boxes.shape[0].
+00030030: 2020 2020 6966 2069 735f 7379 6d62 6f6c      if is_symbol
+00030040: 6963 2862 6f78 5f6e 756d 293a 0a20 2020  ic(box_num):.   
+00030050: 2020 2020 2023 2057 6865 6e20 7468 6520       # When the 
+00030060: 6e75 6d62 6572 206f 6620 626f 7865 7320  number of boxes 
+00030070: 6973 2075 6e6b 6e6f 776e 2061 7420 636f  is unknown at co
+00030080: 6d70 696c 6520 7469 6d65 2c20 7573 6520  mpile time, use 
+00030090: 6120 6c61 7267 6520 6e75 6d62 6572 2074  a large number t
+000300a0: 6f20 6176 6f69 6420 7661 6c69 640a 2020  o avoid valid.  
+000300b0: 2020 2020 2020 2320 626f 7865 7320 676f        # boxes go
+000300c0: 7420 7072 756e 6564 2e20 5765 2064 6f6e  t pruned. We don
+000300d0: 2774 2075 7365 205f 6e70 2e69 696e 666f  't use _np.iinfo
+000300e0: 285f 6e70 2e69 6e74 3332 292e 6d61 7820  (_np.int32).max 
+000300f0: 6865 7265 2062 6563 6175 7365 2069 7420  here because it 
+00030100: 7472 6967 6765 7273 2074 6865 204d 494c  triggers the MIL
+00030110: 0a20 2020 2020 2020 2023 204e 4d53 206f  .        # NMS o
+00030120: 7020 7365 676d 656e 7420 6661 756c 742e  p segment fault.
+00030130: 0a20 2020 2020 2020 2062 6f78 5f6e 756d  .        box_num
+00030140: 203d 2031 3030 3030 0a0a 2020 2020 2320   = 10000..    # 
+00030150: 5468 6520 626f 7865 7327 2063 6f6f 7264  The boxes' coord
+00030160: 696e 6174 6573 2066 726f 6d20 5079 546f  inates from PyTo
+00030170: 7263 6820 696e 7075 7420 6973 2028 7831  rch input is (x1
+00030180: 2c20 7931 2c20 7832 2c20 7932 2920 666f  , y1, x2, y2) fo
+00030190: 726d 6174 2077 6974 6820 3020 3c3d 2078  rmat with 0 <= x
+000301a0: 3120 3c20 7832 2061 6e64 0a20 2020 2023  1 < x2 and.    #
+000301b0: 2030 203c 3d20 7931 203c 2079 322e 2048   0 <= y1 < y2. H
+000301c0: 6f77 6576 6572 2c20 7468 6520 4d49 4c20  owever, the MIL 
+000301d0: 4e4d 5320 6f70 2065 7870 6563 7473 2043  NMS op expects C
+000301e0: 454e 5445 525f 5349 5a45 5f57 4944 5448  ENTER_SIZE_WIDTH
+000301f0: 5f46 4952 5354 2066 6f72 6d61 742c 2077  _FIRST format, w
+00030200: 6869 6368 2069 730a 2020 2020 2320 2878  hich is.    # (x
+00030210: 2c20 792c 2077 6964 7468 2c20 6865 6967  , y, width, heig
+00030220: 6874 2920 7768 6572 6520 2878 2c20 7929  ht) where (x, y)
+00030230: 2069 7320 7468 6520 6365 6e74 6572 2063   is the center c
+00030240: 6f6f 7264 696e 6174 652e 0a20 2020 2078  oordinate..    x
+00030250: 312c 2079 312c 2078 322c 2079 3220 3d20  1, y1, x2, y2 = 
+00030260: 6d62 2e73 706c 6974 2878 3d62 6f78 6573  mb.split(x=boxes
+00030270: 2c20 6e75 6d5f 7370 6c69 7473 3d34 2c20  , num_splits=4, 
+00030280: 6178 6973 3d2d 3129 0a20 2020 2023 2046  axis=-1).    # F
+00030290: 6f72 206e 756d 6572 6963 616c 2073 7461  or numerical sta
+000302a0: 6269 6c69 7479 2c20 7573 6520 7831 2b28  bility, use x1+(
+000302b0: 7832 2d78 3129 2f32 2069 6e73 7465 6164  x2-x1)/2 instead
+000302c0: 206f 6620 2878 312b 7832 292f 3220 746f   of (x1+x2)/2 to
+000302d0: 2063 616c 6375 6c61 7465 2063 656e 7465   calculate cente
+000302e0: 7220 636f 6f72 6469 6e61 7465 2e0a 2020  r coordinate..  
+000302f0: 2020 7769 6474 6820 3d20 6d62 2e73 7562    width = mb.sub
+00030300: 2878 3d78 322c 2079 3d78 3129 0a20 2020  (x=x2, y=x1).   
+00030310: 2068 6569 6768 7420 3d20 6d62 2e73 7562   height = mb.sub
+00030320: 2878 3d79 322c 2079 3d79 3129 0a20 2020  (x=y2, y=y1).   
+00030330: 2063 656e 7465 725f 7820 3d20 6d62 2e61   center_x = mb.a
+00030340: 6464 2878 3d78 312c 2079 3d6d 622e 7265  dd(x=x1, y=mb.re
+00030350: 616c 5f64 6976 2878 3d77 6964 7468 2c20  al_div(x=width, 
+00030360: 793d 322e 3029 290a 2020 2020 6365 6e74  y=2.0)).    cent
+00030370: 6572 5f79 203d 206d 622e 6164 6428 783d  er_y = mb.add(x=
+00030380: 7931 2c20 793d 6d62 2e72 6561 6c5f 6469  y1, y=mb.real_di
+00030390: 7628 783d 6865 6967 6874 2c20 793d 322e  v(x=height, y=2.
+000303a0: 3029 290a 2020 2020 626f 7865 7320 3d20  0)).    boxes = 
+000303b0: 6d62 2e63 6f6e 6361 7428 7661 6c75 6573  mb.concat(values
+000303c0: 3d5b 6365 6e74 6572 5f78 2c20 6365 6e74  =[center_x, cent
+000303d0: 6572 5f79 2c20 7769 6474 682c 2068 6569  er_y, width, hei
+000303e0: 6768 745d 2c20 6178 6973 3d2d 3129 0a0a  ght], axis=-1)..
+000303f0: 2020 2020 2320 4578 7061 6e64 2064 696d      # Expand dim
+00030400: 7320 746f 2063 6f6e 7374 7275 6374 2074  s to construct t
+00030410: 6865 2062 6174 6368 2064 696d 2061 6e64  he batch dim and
+00030420: 2073 636f 7265 2063 6c61 7373 2064 696d   score class dim
+00030430: 2065 7870 6563 7465 6420 6279 204d 494c   expected by MIL
+00030440: 204e 4d53 206f 702e 0a20 2020 2062 6f78   NMS op..    box
+00030450: 6573 203d 206d 622e 6578 7061 6e64 5f64  es = mb.expand_d
+00030460: 696d 7328 783d 626f 7865 732c 2061 7865  ims(x=boxes, axe
+00030470: 733d 5b30 5d29 0a20 2020 2073 636f 7265  s=[0]).    score
+00030480: 7320 3d20 6d62 2e65 7870 616e 645f 6469  s = mb.expand_di
+00030490: 6d73 2878 3d73 636f 7265 732c 2061 7865  ms(x=scores, axe
+000304a0: 733d 5b30 2c20 2d31 5d29 0a0a 2020 2020  s=[0, -1])..    
+000304b0: 6966 206e 6f74 2069 735f 6375 7272 656e  if not is_curren
+000304c0: 745f 6f70 7365 745f 7665 7273 696f 6e5f  t_opset_version_
+000304d0: 636f 6d70 6174 6962 6c65 5f77 6974 6828  compatible_with(
+000304e0: 7461 7267 6574 2e69 4f53 3137 293a 0a20  target.iOS17):. 
+000304f0: 2020 2020 2020 205f 2c20 5f2c 2069 6e64         _, _, ind
+00030500: 6963 6573 2c20 7661 6c69 645f 6f75 7470  ices, valid_outp
+00030510: 7574 7320 3d20 6d62 2e6e 6f6e 5f6d 6178  uts = mb.non_max
+00030520: 696d 756d 5f73 7570 7072 6573 7369 6f6e  imum_suppression
+00030530: 280a 2020 2020 2020 2020 2020 2020 626f  (.            bo
+00030540: 7865 733d 626f 7865 732c 0a20 2020 2020  xes=boxes,.     
+00030550: 2020 2020 2020 2073 636f 7265 733d 7363         scores=sc
+00030560: 6f72 6573 2c0a 2020 2020 2020 2020 2020  ores,.          
+00030570: 2020 6d61 785f 626f 7865 733d 626f 785f    max_boxes=box_
+00030580: 6e75 6d2c 0a20 2020 2020 2020 2020 2020  num,.           
+00030590: 2069 6f75 5f74 6872 6573 686f 6c64 3d69   iou_threshold=i
+000305a0: 6f75 5f74 6872 6573 686f 6c64 2c0a 2020  ou_threshold,.  
+000305b0: 2020 2020 2020 2020 2020 7363 6f72 655f            score_
+000305c0: 7468 7265 7368 6f6c 643d 7363 6f72 655f  threshold=score_
+000305d0: 7468 7265 7368 6f6c 642c 0a20 2020 2020  threshold,.     
+000305e0: 2020 2029 0a0a 2020 2020 2020 2020 696e     )..        in
+000305f0: 6469 6365 7320 3d20 6d62 2e73 7175 6565  dices = mb.squee
+00030600: 7a65 2878 3d69 6e64 6963 6573 2c20 6178  ze(x=indices, ax
+00030610: 6573 3d5b 305d 290a 2020 2020 2020 2020  es=[0]).        
+00030620: 7661 6c69 645f 6f75 7470 7574 7320 3d20  valid_outputs = 
+00030630: 6d62 2e73 7175 6565 7a65 2878 3d76 616c  mb.squeeze(x=val
+00030640: 6964 5f6f 7574 7075 7473 2c20 6178 6573  id_outputs, axes
+00030650: 3d5b 305d 290a 2020 2020 2020 2020 7261  =[0]).        ra
+00030660: 6e67 6520 3d20 6d62 2e72 616e 6765 5f31  nge = mb.range_1
+00030670: 6428 656e 643d 7661 6c69 645f 6f75 7470  d(end=valid_outp
+00030680: 7574 732c 2073 7461 7274 3d30 2c20 7374  uts, start=0, st
+00030690: 6570 3d31 290a 2020 2020 2020 2020 696e  ep=1).        in
+000306a0: 6469 6365 7320 3d20 6d62 2e63 6173 7428  dices = mb.cast(
+000306b0: 783d 696e 6469 6365 732c 2064 7479 7065  x=indices, dtype
+000306c0: 3d22 6670 3332 2229 0a20 2020 2020 2020  ="fp32").       
+000306d0: 2076 616c 6964 5f69 6e64 6963 6573 203d   valid_indices =
+000306e0: 206d 622e 6761 7468 6572 2878 3d69 6e64   mb.gather(x=ind
+000306f0: 6963 6573 2c20 696e 6469 6365 733d 7261  ices, indices=ra
+00030700: 6e67 652c 2061 7869 733d 3029 0a20 2020  nge, axis=0).   
+00030710: 2020 2020 2076 616c 6964 5f69 6e64 6963       valid_indic
+00030720: 6573 203d 206d 622e 6361 7374 2878 3d76  es = mb.cast(x=v
+00030730: 616c 6964 5f69 6e64 6963 6573 2c20 6474  alid_indices, dt
+00030740: 7970 653d 2269 6e74 3332 222c 206e 616d  ype="int32", nam
+00030750: 653d 6e6f 6465 2e6e 616d 6529 0a20 2020  e=node.name).   
+00030760: 2020 2020 2063 6f6e 7465 7874 2e61 6464       context.add
+00030770: 2876 616c 6964 5f69 6e64 6963 6573 290a  (valid_indices).
+00030780: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
+00030790: 2020 2320 496e 2049 4f53 3137 2c20 7468    # In IOS17, th
+000307a0: 6520 4d49 4c20 4e4d 5320 6f70 2773 2069  e MIL NMS op's i
+000307b0: 6e70 7574 7320 6172 6520 6f72 6465 7265  nputs are ordere
+000307c0: 6420 7769 7468 206e 756d 6265 7220 6f66  d with number of
+000307d0: 2062 6f78 6573 2069 6e20 7468 6520 6c61   boxes in the la
+000307e0: 7374 2064 696d 656e 7369 6f6e 2e0a 2020  st dimension..  
+000307f0: 2020 2020 2020 626f 7865 7320 3d20 6d62        boxes = mb
+00030800: 2e74 7261 6e73 706f 7365 2878 3d62 6f78  .transpose(x=box
+00030810: 6573 2c20 7065 726d 3d5b 302c 2032 2c20  es, perm=[0, 2, 
+00030820: 315d 290a 2020 2020 2020 2020 7363 6f72  1]).        scor
+00030830: 6573 203d 206d 622e 7472 616e 7370 6f73  es = mb.transpos
+00030840: 6528 783d 7363 6f72 6573 2c20 7065 726d  e(x=scores, perm
+00030850: 3d5b 302c 2032 2c20 315d 290a 0a20 2020  =[0, 2, 1])..   
+00030860: 2020 2020 2023 2049 6e20 494f 5331 372c       # In IOS17,
+00030870: 2074 6865 204d 494c 204e 4d53 206f 7027   the MIL NMS op'
+00030880: 7320 6c61 7374 206f 7574 7075 7420 286e  s last output (n
+00030890: 756d 6265 7220 6f66 2076 616c 6964 2062  umber of valid b
+000308a0: 6f78 6573 2069 6e20 6561 6368 2062 6174  oxes in each bat
+000308b0: 6368 2920 6765 7473 2072 656d 6f76 6564  ch) gets removed
+000308c0: 2e0a 2020 2020 2020 2020 5f2c 205f 2c20  ..        _, _, 
+000308d0: 696e 6469 6365 7320 3d20 6d62 2e6e 6f6e  indices = mb.non
+000308e0: 5f6d 6178 696d 756d 5f73 7570 7072 6573  _maximum_suppres
+000308f0: 7369 6f6e 280a 2020 2020 2020 2020 2020  sion(.          
+00030900: 2020 626f 7865 733d 626f 7865 732c 0a20    boxes=boxes,. 
+00030910: 2020 2020 2020 2020 2020 2073 636f 7265             score
+00030920: 733d 7363 6f72 6573 2c0a 2020 2020 2020  s=scores,.      
+00030930: 2020 2020 2020 6d61 785f 626f 7865 733d        max_boxes=
+00030940: 626f 785f 6e75 6d2c 0a20 2020 2020 2020  box_num,.       
+00030950: 2020 2020 2069 6f75 5f74 6872 6573 686f       iou_thresho
+00030960: 6c64 3d69 6f75 5f74 6872 6573 686f 6c64  ld=iou_threshold
+00030970: 2c0a 2020 2020 2020 2020 290a 0a20 2020  ,.        )..   
+00030980: 2020 2020 2023 2052 656d 6f76 6520 696e       # Remove in
+00030990: 7661 6c69 6420 696e 6469 6365 7320 2874  valid indices (t
+000309a0: 6865 2070 6164 6465 6420 2d31 2069 6e64  he padded -1 ind
+000309b0: 6963 6573 292e 0a20 2020 2020 2020 2076  ices)..        v
+000309c0: 616c 6964 5f6f 7574 7075 7473 203d 206d  alid_outputs = m
+000309d0: 622e 7265 6475 6365 5f73 756d 280a 2020  b.reduce_sum(.  
+000309e0: 2020 2020 2020 2020 2020 783d 6d62 2e63            x=mb.c
+000309f0: 6173 7428 783d 6d62 2e67 7265 6174 6572  ast(x=mb.greater
+00030a00: 2878 3d69 6e64 6963 6573 2c20 793d 2d31  (x=indices, y=-1
+00030a10: 292c 2064 7479 7065 3d22 696e 7433 3222  ), dtype="int32"
+00030a20: 292c 2061 7865 733d 5b2d 315d 0a20 2020  ), axes=[-1].   
+00030a30: 2020 2020 2029 0a20 2020 2020 2020 2076       ).        v
+00030a40: 616c 6964 5f69 6e64 6963 6573 203d 206d  alid_indices = m
+00030a50: 622e 736c 6963 655f 6279 5f73 697a 6528  b.slice_by_size(
+00030a60: 0a20 2020 2020 2020 2020 2020 2078 3d6d  .            x=m
+00030a70: 622e 7371 7565 657a 6528 783d 696e 6469  b.squeeze(x=indi
+00030a80: 6365 732c 2061 7865 733d 5b30 5d29 2c0a  ces, axes=[0]),.
+00030a90: 2020 2020 2020 2020 2020 2020 6265 6769              begi
+00030aa0: 6e3d 6d62 2e66 696c 6c5f 6c69 6b65 2872  n=mb.fill_like(r
+00030ab0: 6566 5f74 656e 736f 723d 7661 6c69 645f  ef_tensor=valid_
+00030ac0: 6f75 7470 7574 732c 2076 616c 7565 3d30  outputs, value=0
+00030ad0: 292c 0a20 2020 2020 2020 2020 2020 2073  ),.            s
+00030ae0: 697a 653d 7661 6c69 645f 6f75 7470 7574  ize=valid_output
+00030af0: 732c 0a20 2020 2020 2020 2020 2020 206e  s,.            n
+00030b00: 616d 653d 6e6f 6465 2e6e 616d 652c 0a20  ame=node.name,. 
+00030b10: 2020 2020 2020 2029 0a20 2020 2020 2020         ).       
+00030b20: 2063 6f6e 7465 7874 2e61 6464 2876 616c   context.add(val
+00030b30: 6964 5f69 6e64 6963 6573 290a 0a0a 4072  id_indices)...@r
+00030b40: 6567 6973 7465 725f 746f 7263 685f 6f70  egister_torch_op
+00030b50: 0a64 6566 2074 7570 6c65 696e 6465 7828  .def tupleindex(
+00030b60: 636f 6e74 6578 742c 206e 6f64 6529 3a0a  context, node):.
+00030b70: 2020 2020 7475 706c 655f 696e 7075 742c      tuple_input,
+00030b80: 2069 6e64 6578 5f69 6e70 7574 203d 205f   index_input = _
+00030b90: 6765 745f 696e 7075 7473 2863 6f6e 7465  get_inputs(conte
+00030ba0: 7874 2c20 6e6f 6465 2c20 6578 7065 6374  xt, node, expect
+00030bb0: 6564 3d32 290a 2020 2020 636f 6e74 6578  ed=2).    contex
+00030bc0: 742e 6164 6428 7475 706c 655f 696e 7075  t.add(tuple_inpu
+00030bd0: 745b 696e 6465 785f 696e 7075 742e 7661  t[index_input.va
+00030be0: 6c5d 2c20 6e6f 6465 2e6e 616d 6529 0a0a  l], node.name)..
+00030bf0: 0a64 6566 205f 6765 745f 6174 746e 5f6d  .def _get_attn_m
+00030c00: 6173 6b28 6973 5f63 6175 7361 6c3a 2056  ask(is_causal: V
+00030c10: 6172 2c20 6174 746e 5f6d 6173 6b3a 2056  ar, attn_mask: V
+00030c20: 6172 2c20 7175 6572 795f 7661 723a 2056  ar, query_var: V
+00030c30: 6172 2c20 6b65 795f 7661 723a 2056 6172  ar, key_var: Var
+00030c40: 2920 2d3e 2056 6172 3a0a 2020 2020 6966  ) -> Var:.    if
+00030c50: 2069 735f 6361 7573 616c 2e76 616c 3a0a   is_causal.val:.
+00030c60: 2020 2020 2020 2020 2320 6372 6561 7465          # create
+00030c70: 206d 6173 6b20 6f66 2073 6861 7065 2028   mask of shape (
+00030c80: 7461 7267 6574 5f73 6571 2c20 736f 7572  target_seq, sour
+00030c90: 6365 5f73 6571 290a 2020 2020 2020 2020  ce_seq).        
+00030ca0: 2320 732e 7420 7468 6520 6469 6167 6f6e  # s.t the diagon
+00030cb0: 616c 2061 6e64 206c 6f77 6572 2074 7269  al and lower tri
+00030cc0: 616e 6775 6c61 7220 6f66 2074 6865 206d  angular of the m
+00030cd0: 6174 7269 7820 6973 2061 6c6c 2031 730a  atrix is all 1s.
+00030ce0: 2020 2020 2020 2020 2320 616e 6420 7570          # and up
+00030cf0: 7065 7220 7472 6961 6e67 756c 6172 2069  per triangular i
+00030d00: 7320 6120 6c61 7267 6520 6e65 6761 7469  s a large negati
+00030d10: 7665 206e 756d 6265 7220 2865 2e67 2e20  ve number (e.g. 
+00030d20: 2d33 306b 290a 2020 2020 2020 2020 7461  -30k).        ta
+00030d30: 7267 6574 5f73 6571 203d 2071 7565 7279  rget_seq = query
+00030d40: 5f76 6172 2e73 6861 7065 5b2d 325d 0a20  _var.shape[-2]. 
+00030d50: 2020 2020 2020 2073 6f75 7263 655f 7365         source_se
+00030d60: 7120 3d20 6b65 795f 7661 722e 7368 6170  q = key_var.shap
+00030d70: 655b 2d32 5d0a 2020 2020 2020 2020 6966  e[-2].        if
+00030d80: 2069 735f 7379 6d62 6f6c 6963 2874 6172   is_symbolic(tar
+00030d90: 6765 745f 7365 7129 206f 7220 6973 5f73  get_seq) or is_s
+00030da0: 796d 626f 6c69 6328 736f 7572 6365 5f73  ymbolic(source_s
+00030db0: 6571 293a 0a20 2020 2020 2020 2020 2020  eq):.           
+00030dc0: 2072 6169 7365 204e 6f74 496d 706c 656d   raise NotImplem
+00030dd0: 656e 7465 6445 7272 6f72 280a 2020 2020  entedError(.    
+00030de0: 2020 2020 2020 2020 2020 2020 2273 6361              "sca
+00030df0: 6c65 645f 646f 745f 7072 6f64 7563 745f  led_dot_product_
+00030e00: 6174 7465 6e74 696f 6e20 6f70 3a20 220a  attention op: ".
+00030e10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00030e20: 2269 735f 6361 7573 616c 2066 6c61 6720  "is_causal flag 
+00030e30: 6e6f 7420 6861 6e64 6c65 6420 7768 656e  not handled when
+00030e40: 2073 6571 7565 6e63 6520 6c65 6e67 7468   sequence length
+00030e50: 2069 7320 7379 6d62 6f6c 6963 220a 2020   is symbolic".  
+00030e60: 2020 2020 2020 2020 2020 290a 0a20 2020            )..   
+00030e70: 2020 2020 2061 6c6c 5f6f 6e65 7320 3d20       all_ones = 
+00030e80: 6d62 2e66 696c 6c28 7661 6c75 653d 312e  mb.fill(value=1.
+00030e90: 302c 2073 6861 7065 3d28 7461 7267 6574  0, shape=(target
+00030ea0: 5f73 6571 2c20 736f 7572 6365 5f73 6571  _seq, source_seq
+00030eb0: 2929 0a20 2020 2020 2020 2061 6c6c 5f6e  )).        all_n
+00030ec0: 6567 6174 6976 655f 696e 6620 3d20 6d62  egative_inf = mb
+00030ed0: 2e66 696c 6c28 7661 6c75 653d 2d33 6534  .fill(value=-3e4
+00030ee0: 2c20 7368 6170 653d 2874 6172 6765 745f  , shape=(target_
+00030ef0: 7365 712c 2073 6f75 7263 655f 7365 7129  seq, source_seq)
+00030f00: 290a 2020 2020 2020 2020 616c 6c5f 6f6e  ).        all_on
+00030f10: 6573 5f6c 6f77 6572 203d 206d 622e 6261  es_lower = mb.ba
+00030f20: 6e64 5f70 6172 7428 0a20 2020 2020 2020  nd_part(.       
+00030f30: 2020 2020 2078 3d61 6c6c 5f6f 6e65 732c       x=all_ones,
+00030f40: 206c 6f77 6572 3d2d 312c 2075 7070 6572   lower=-1, upper
+00030f50: 3d30 0a20 2020 2020 2020 2029 2020 2320  =0.        )  # 
+00030f60: 7769 6c6c 2030 206f 7574 2075 7070 6572  will 0 out upper
+00030f70: 2074 7269 616e 676c 652c 2065 7863 6c75   triangle, exclu
+00030f80: 6469 6e67 2064 6961 670a 2020 2020 2020  ding diag.      
+00030f90: 2020 616c 6c5f 6e65 6761 7469 7665 5f69    all_negative_i
+00030fa0: 6e66 5f75 7070 6572 203d 206d 622e 6261  nf_upper = mb.ba
+00030fb0: 6e64 5f70 6172 7428 0a20 2020 2020 2020  nd_part(.       
+00030fc0: 2020 2020 2078 3d61 6c6c 5f6e 6567 6174       x=all_negat
+00030fd0: 6976 655f 696e 662c 206c 6f77 6572 3d30  ive_inf, lower=0
+00030fe0: 2c20 7570 7065 723d 2d31 0a20 2020 2020  , upper=-1.     
+00030ff0: 2020 2029 2020 2320 7769 6c6c 2030 206f     )  # will 0 o
+00031000: 7574 206c 6f77 6572 2074 7269 616e 676c  ut lower triangl
+00031010: 652c 2065 7863 6c75 6469 6e67 2064 6961  e, excluding dia
+00031020: 670a 2020 2020 2020 2020 616c 6c5f 6e65  g.        all_ne
+00031030: 6761 7469 7665 5f69 6e66 5f64 6961 675f  gative_inf_diag_
+00031040: 6f6e 6c79 203d 206d 622e 6261 6e64 5f70  only = mb.band_p
+00031050: 6172 7428 783d 616c 6c5f 6e65 6761 7469  art(x=all_negati
+00031060: 7665 5f69 6e66 5f75 7070 6572 2c20 6c6f  ve_inf_upper, lo
+00031070: 7765 723d 302c 2075 7070 6572 3d30 290a  wer=0, upper=0).
+00031080: 2020 2020 2020 2020 616c 6c5f 6e65 6761          all_nega
+00031090: 7469 7665 5f69 6e66 5f75 7070 6572 5f6e  tive_inf_upper_n
+000310a0: 6f5f 6469 6167 203d 206d 622e 7375 6228  o_diag = mb.sub(
+000310b0: 0a20 2020 2020 2020 2020 2020 2078 3d61  .            x=a
+000310c0: 6c6c 5f6e 6567 6174 6976 655f 696e 665f  ll_negative_inf_
+000310d0: 7570 7065 722c 2079 3d61 6c6c 5f6e 6567  upper, y=all_neg
+000310e0: 6174 6976 655f 696e 665f 6469 6167 5f6f  ative_inf_diag_o
+000310f0: 6e6c 790a 2020 2020 2020 2020 290a 2020  nly.        ).  
+00031100: 2020 2020 2020 7265 7475 726e 206d 622e        return mb.
+00031110: 6164 6428 783d 616c 6c5f 6f6e 6573 5f6c  add(x=all_ones_l
+00031120: 6f77 6572 2c20 793d 616c 6c5f 6e65 6761  ower, y=all_nega
+00031130: 7469 7665 5f69 6e66 5f75 7070 6572 5f6e  tive_inf_upper_n
+00031140: 6f5f 6469 6167 290a 2020 2020 656c 6966  o_diag).    elif
+00031150: 2069 735f 626f 6f6c 2861 7474 6e5f 6d61   is_bool(attn_ma
+00031160: 736b 2e64 7479 7065 293a 0a20 2020 2020  sk.dtype):.     
+00031170: 2020 2022 2222 0a20 2020 2020 2020 2063     """.        c
+00031180: 6f6d 7075 7465 2066 6c6f 6174 206d 6173  ompute float mas
+00031190: 6b20 6173 3a0a 2020 2020 2020 2020 6d61  k as:.        ma
+000311a0: 736b 203d 2063 6173 7428 626f 6f6c 5f6d  sk = cast(bool_m
+000311b0: 6173 6b29 202b 2028 312d 6361 7374 2862  ask) + (1-cast(b
+000311c0: 6f6f 6c5f 6d61 736b 2929 202a 202d 3330  ool_mask)) * -30
+000311d0: 6b2a 6f6e 6573 2873 6861 7065 2862 6f6f  k*ones(shape(boo
+000311e0: 6c5f 6d61 736b 2929 0a20 2020 2020 2020  l_mask)).       
+000311f0: 2022 2222 0a20 2020 2020 2020 2073 6861   """.        sha
+00031200: 7065 203d 206d 622e 7368 6170 6528 783d  pe = mb.shape(x=
+00031210: 6174 746e 5f6d 6173 6b29 0a20 2020 2020  attn_mask).     
+00031220: 2020 206e 6567 6174 6976 655f 696e 6620     negative_inf 
+00031230: 3d20 6d62 2e66 696c 6c28 0a20 2020 2020  = mb.fill(.     
+00031240: 2020 2020 2020 2073 6861 7065 3d73 6861         shape=sha
+00031250: 7065 2c20 7661 6c75 653d 5f6e 702e 6172  pe, value=_np.ar
+00031260: 7261 7928 5b2d 3365 345d 292e 6173 7479  ray([-3e4]).asty
+00031270: 7065 2874 7970 6573 2e6e 7074 7970 655f  pe(types.nptype_
+00031280: 6672 6f6d 5f62 7569 6c74 696e 2871 7565  from_builtin(que
+00031290: 7279 5f76 6172 2e64 7479 7065 2929 0a20  ry_var.dtype)). 
+000312a0: 2020 2020 2020 2029 0a20 2020 2020 2020         ).       
+000312b0: 206d 6173 6b20 3d20 6d62 2e63 6173 7428   mask = mb.cast(
+000312c0: 783d 6174 746e 5f6d 6173 6b2c 2064 7479  x=attn_mask, dty
+000312d0: 7065 3d74 7970 6573 2e62 7569 6c74 696e  pe=types.builtin
+000312e0: 5f74 6f5f 7374 7269 6e67 2871 7565 7279  _to_string(query
+000312f0: 5f76 6172 2e64 7479 7065 2929 0a20 2020  _var.dtype)).   
+00031300: 2020 2020 2063 6f6d 706c 696d 656e 745f       compliment_
+00031310: 6f66 5f6d 6173 6b20 3d20 6d62 2e73 7562  of_mask = mb.sub
+00031320: 280a 2020 2020 2020 2020 2020 2020 783d  (.            x=
+00031330: 5f6e 702e 6172 7261 7928 5b31 2e30 5d29  _np.array([1.0])
+00031340: 2e61 7374 7970 6528 7479 7065 732e 6e70  .astype(types.np
+00031350: 7479 7065 5f66 726f 6d5f 6275 696c 7469  type_from_builti
+00031360: 6e28 6d61 736b 2e64 7479 7065 2929 2c20  n(mask.dtype)), 
+00031370: 793d 6d61 736b 0a20 2020 2020 2020 2029  y=mask.        )
+00031380: 0a20 2020 2020 2020 2063 6f6d 706c 696d  .        complim
+00031390: 656e 745f 6f66 5f6d 6173 6b20 3d20 6d62  ent_of_mask = mb
+000313a0: 2e6d 756c 2878 3d6e 6567 6174 6976 655f  .mul(x=negative_
+000313b0: 696e 662c 2079 3d63 6f6d 706c 696d 656e  inf, y=complimen
+000313c0: 745f 6f66 5f6d 6173 6b29 0a20 2020 2020  t_of_mask).     
+000313d0: 2020 2072 6574 7572 6e20 6d62 2e61 6464     return mb.add
+000313e0: 2878 3d6d 6173 6b2c 2079 3d63 6f6d 706c  (x=mask, y=compl
+000313f0: 696d 656e 745f 6f66 5f6d 6173 6b29 0a20  iment_of_mask). 
+00031400: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
+00031410: 2072 6574 7572 6e20 6174 746e 5f6d 6173   return attn_mas
+00031420: 6b0a 0a0a 0a40 7265 6769 7374 6572 5f74  k....@register_t
+00031430: 6f72 6368 5f6f 700a 6465 6620 7363 616c  orch_op.def scal
+00031440: 6564 5f64 6f74 5f70 726f 6475 6374 5f61  ed_dot_product_a
+00031450: 7474 656e 7469 6f6e 2863 6f6e 7465 7874  ttention(context
+00031460: 2c20 6e6f 6465 293a 0a20 2020 2022 2222  , node):.    """
+00031470: 0a20 2020 2049 6e70 7574 2073 6861 7065  .    Input shape
+00031480: 732f 7479 7065 733a 0a20 2020 202d 2071  s/types:.    - q
+00031490: 7565 7279 203a 2028 7461 7267 6574 5f73  uery : (target_s
+000314a0: 6571 2c20 6429 206f 7220 2842 2c20 7461  eq, d) or (B, ta
+000314b0: 7267 6574 5f73 6571 2c20 6429 206f 7220  rget_seq, d) or 
+000314c0: 2842 2c20 682c 2074 6172 6765 745f 7365  (B, h, target_se
+000314d0: 712c 2064 2920 6f72 2028 422c 2e2e 2c20  q, d) or (B,.., 
+000314e0: 7461 7267 6574 5f73 6571 2c20 6429 0a20  target_seq, d). 
+000314f0: 2020 202d 206b 6579 203a 2028 736f 7572     - key : (sour
+00031500: 6365 5f73 6571 2c20 6429 206f 7220 2842  ce_seq, d) or (B
+00031510: 2c20 736f 7572 6365 5f73 6571 2c20 6429  , source_seq, d)
+00031520: 206f 7220 2842 2c20 682c 2073 6f75 7263   or (B, h, sourc
+00031530: 655f 7365 712c 2064 2920 6f72 2028 422c  e_seq, d) or (B,
+00031540: 2e2e 2c20 736f 7572 6365 5f73 6571 2c20  .., source_seq, 
+00031550: 6429 0a20 2020 202d 2076 616c 7565 3a20  d).    - value: 
+00031560: 2873 6f75 7263 655f 7365 712c 2064 5f76  (source_seq, d_v
+00031570: 2920 6f72 2028 422c 2073 6f75 7263 655f  ) or (B, source_
+00031580: 7365 712c 2064 5f76 2920 6f72 2028 422c  seq, d_v) or (B,
+00031590: 2068 2c20 736f 7572 6365 5f73 6571 2c20   h, source_seq, 
+000315a0: 645f 7629 206f 7220 2842 2c2e 2e2c 2073  d_v) or (B,.., s
+000315b0: 6f75 7263 655f 7365 712c 2064 5f76 290a  ource_seq, d_v).
+000315c0: 2020 2020 2d20 6174 746e 5f6d 6173 6b20      - attn_mask 
+000315d0: 3a20 2874 6172 6765 745f 7365 712c 2073  : (target_seq, s
+000315e0: 6f75 7263 655f 7365 7129 206f 7220 2842  ource_seq) or (B
+000315f0: 2c20 7461 7267 6574 5f73 6571 2c20 736f  , target_seq, so
+00031600: 7572 6365 5f73 6571 2920 6f72 2028 422c  urce_seq) or (B,
+00031610: 2068 2c20 7461 7267 6574 5f73 6571 2c20   h, target_seq, 
+00031620: 736f 7572 6365 5f73 6571 2920 6f72 0a20  source_seq) or. 
+00031630: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00031640: 2028 422c 202e 2e2e 2c20 7461 7267 6574   (B, ..., target
+00031650: 5f73 6571 2c20 736f 7572 6365 5f73 6571  _seq, source_seq
+00031660: 290a 2020 2020 2d20 6973 5f63 6175 7361  ).    - is_causa
+00031670: 6c20 3a20 626f 6f6c 0a0a 2020 2020 4f75  l : bool..    Ou
+00031680: 7470 7574 2073 6861 7065 3a20 2874 6172  tput shape: (tar
+00031690: 6765 745f 7365 712c 2064 5f76 2920 6f72  get_seq, d_v) or
+000316a0: 2028 422c 2e2e 2e2c 7461 7267 6574 5f73   (B,...,target_s
+000316b0: 6571 2c20 645f 7629 0a0a 2020 2020 6f75  eq, d_v)..    ou
+000316c0: 7470 7574 203d 2073 6f66 746d 6178 2873  tput = softmax(s
+000316d0: 6361 6c65 2a51 2a4b 5e74 7261 6e73 706f  cale*Q*K^transpo
+000316e0: 7365 202b 206d 6173 6b29 202a 2056 0a0a  se + mask) * V..
+000316f0: 2020 2020 5365 6520 6465 7461 696c 7320      See details 
+00031700: 6174 3a0a 2020 2020 6874 7470 733a 2f2f  at:.    https://
+00031710: 7079 746f 7263 682e 6f72 672f 646f 6373  pytorch.org/docs
+00031720: 2f73 7461 626c 652f 6765 6e65 7261 7465  /stable/generate
+00031730: 642f 746f 7263 682e 6e6e 2e66 756e 6374  d/torch.nn.funct
+00031740: 696f 6e61 6c2e 7363 616c 6564 5f64 6f74  ional.scaled_dot
+00031750: 5f70 726f 6475 6374 5f61 7474 656e 7469  _product_attenti
+00031760: 6f6e 2e68 746d 6c0a 2020 2020 2222 220a  on.html.    """.
+00031770: 2020 2020 712c 206b 2c20 762c 2061 7474      q, k, v, att
+00031780: 6e5f 6d61 736b 2c20 6472 6f70 6f75 742c  n_mask, dropout,
+00031790: 2069 735f 6361 7573 616c 203d 205f 6765   is_causal = _ge
+000317a0: 745f 696e 7075 7473 2863 6f6e 7465 7874  t_inputs(context
+000317b0: 2c20 6e6f 6465 2c20 6578 7065 6374 6564  , node, expected
+000317c0: 3d36 290a 2020 2020 6966 2061 7474 6e5f  =6).    if attn_
+000317d0: 6d61 736b 2069 7320 6e6f 7420 4e6f 6e65  mask is not None
+000317e0: 2061 6e64 2069 735f 6361 7573 616c 2e76   and is_causal.v
+000317f0: 616c 3a0a 2020 2020 2020 2020 7261 6973  al:.        rais
+00031800: 6520 5661 6c75 6545 7272 6f72 280a 2020  e ValueError(.  
+00031810: 2020 2020 2020 2020 2020 2273 6361 6c65            "scale
+00031820: 645f 646f 745f 7072 6f64 7563 745f 6174  d_dot_product_at
+00031830: 7465 6e74 696f 6e20 6f70 3a20 6174 746e  tention op: attn
+00031840: 5f6d 6173 6b20 6361 6e6e 6f74 2062 6520  _mask cannot be 
+00031850: 7072 6f76 6964 6564 2077 6865 6e20 6973  provided when is
+00031860: 5f63 6175 7361 6c20 6973 2073 6574 2074  _causal is set t
+00031870: 6f20 5472 7565 2e22 0a20 2020 2020 2020  o True.".       
+00031880: 2029 0a0a 2020 2020 2320 6368 6563 6b20   )..    # check 
+00031890: 7468 6174 2072 616e 6b73 206f 6620 712c  that ranks of q,
+000318a0: 206b 2c20 7620 616e 6420 6174 746e 5f6d   k, v and attn_m
+000318b0: 6173 6b20 6d61 7463 680a 2020 2020 6966  ask match.    if
+000318c0: 206b 2e72 616e 6b20 213d 2071 2e72 616e   k.rank != q.ran
+000318d0: 6b3a 0a20 2020 2020 2020 2072 6169 7365  k:.        raise
+000318e0: 2056 616c 7565 4572 726f 7228 0a20 2020   ValueError(.   
+000318f0: 2020 2020 2020 2020 2022 5261 6e6b 206f           "Rank o
+00031900: 6620 7175 6572 7920 616e 6420 6b65 7920  f query and key 
+00031910: 646f 206e 6f74 206d 6174 6368 2069 6e20  do not match in 
+00031920: 7363 616c 6564 5f64 6f74 5f70 726f 6475  scaled_dot_produ
+00031930: 6374 5f61 7474 656e 7469 6f6e 2074 6f72  ct_attention tor
+00031940: 6368 206f 7022 0a20 2020 2020 2020 2029  ch op".        )
+00031950: 0a20 2020 2069 6620 762e 7261 6e6b 2021  .    if v.rank !
+00031960: 3d20 712e 7261 6e6b 3a0a 2020 2020 2020  = q.rank:.      
+00031970: 2020 7261 6973 6520 5661 6c75 6545 7272    raise ValueErr
+00031980: 6f72 280a 2020 2020 2020 2020 2020 2020  or(.            
+00031990: 2252 616e 6b20 6f66 2071 7565 7279 2061  "Rank of query a
+000319a0: 6e64 2076 616c 7565 2064 6f20 6e6f 7420  nd value do not 
+000319b0: 6d61 7463 6820 696e 2073 6361 6c65 645f  match in scaled_
+000319c0: 646f 745f 7072 6f64 7563 745f 6174 7465  dot_product_atte
+000319d0: 6e74 696f 6e20 746f 7263 6820 6f70 220a  ntion torch op".
+000319e0: 2020 2020 2020 2020 290a 0a20 2020 2069          )..    i
+000319f0: 735f 6d61 736b 5f70 7265 7365 6e74 203d  s_mask_present =
+00031a00: 2046 616c 7365 0a20 2020 2069 6620 6973   False.    if is
+00031a10: 5f63 6175 7361 6c2e 7661 6c20 6f72 2061  _causal.val or a
+00031a20: 7474 6e5f 6d61 736b 2069 7320 6e6f 7420  ttn_mask is not 
+00031a30: 4e6f 6e65 3a0a 2020 2020 2020 2020 6973  None:.        is
+00031a40: 5f6d 6173 6b5f 7072 6573 656e 7420 3d20  _mask_present = 
+00031a50: 5472 7565 0a20 2020 2020 2020 206d 6173  True.        mas
+00031a60: 6b20 3d20 5f67 6574 5f61 7474 6e5f 6d61  k = _get_attn_ma
+00031a70: 736b 2869 735f 6361 7573 616c 2c20 6174  sk(is_causal, at
+00031a80: 746e 5f6d 6173 6b2c 2071 2c20 6b29 0a0a  tn_mask, q, k)..
+00031a90: 2020 2020 2320 7363 616c 6520 7468 6520      # scale the 
+00031aa0: 7175 6572 7920 696e 7075 740a 2020 2020  query input.    
+00031ab0: 656d 6265 645f 7369 7a65 203d 2071 2e73  embed_size = q.s
+00031ac0: 6861 7065 5b2d 315d 0a20 2020 2069 6620  hape[-1].    if 
+00031ad0: 6973 5f73 796d 626f 6c69 6328 656d 6265  is_symbolic(embe
+00031ae0: 645f 7369 7a65 293a 0a20 2020 2020 2020  d_size):.       
+00031af0: 2072 6169 7365 2056 616c 7565 4572 726f   raise ValueErro
+00031b00: 7228 0a20 2020 2020 2020 2020 2020 2022  r(.            "
+00031b10: 5468 6520 656d 6265 6464 696e 6720 7369  The embedding si
+00031b20: 7a65 2c20 692e 652e 206c 6173 7420 6469  ze, i.e. last di
+00031b30: 6d65 6e73 696f 6e20 6f66 2074 6865 2073  mension of the s
+00031b40: 6861 7065 206f 6620 7175 6572 7920 7465  hape of query te
+00031b50: 6e73 6f72 220a 2020 2020 2020 2020 2020  nsor".          
+00031b60: 2020 2220 6361 6e6e 6f74 2062 6520 7379    " cannot be sy
+00031b70: 6d62 6f6c 6963 2c20 696e 2073 6361 6c65  mbolic, in scale
+00031b80: 645f 646f 745f 7072 6f64 7563 745f 6174  d_dot_product_at
+00031b90: 7465 6e74 696f 6e20 6f70 220a 2020 2020  tention op".    
+00031ba0: 2020 2020 290a 2020 2020 6d75 6c74 6970      ).    multip
+00031bb0: 6c69 6361 7469 7665 5f73 6361 6c65 5f66  licative_scale_f
+00031bc0: 6163 746f 7220 3d20 3120 2f20 5f6d 6174  actor = 1 / _mat
+00031bd0: 682e 7371 7274 2865 6d62 6564 5f73 697a  h.sqrt(embed_siz
+00031be0: 6529 0a20 2020 2071 203d 206d 622e 6d75  e).    q = mb.mu
+00031bf0: 6c28 783d 712c 2079 3d6d 756c 7469 706c  l(x=q, y=multipl
+00031c00: 6963 6174 6976 655f 7363 616c 655f 6661  icative_scale_fa
+00031c10: 6374 6f72 290a 0a20 2020 2023 206d 756c  ctor)..    # mul
+00031c20: 7469 706c 7920 7175 6572 7920 616e 6420  tiply query and 
+00031c30: 6b65 7920 696e 7075 7420 7465 6e73 6f72  key input tensor
+00031c40: 730a 2020 2020 2320 7368 6170 6520 6f66  s.    # shape of
+00031c50: 206f 7574 7075 743a 2028 7461 7267 6574   output: (target
+00031c60: 5f73 6571 2c20 736f 7572 6365 5f73 6571  _seq, source_seq
+00031c70: 2920 6f72 2028 422c 2e2e 2e2c 7461 7267  ) or (B,...,targ
+00031c80: 6574 5f73 6571 2c20 736f 7572 6365 5f73  et_seq, source_s
+00031c90: 6571 290a 2020 2020 6174 746e 5f77 6569  eq).    attn_wei
+00031ca0: 6768 7473 203d 206d 622e 6d61 746d 756c  ghts = mb.matmul
+00031cb0: 2878 3d71 2c20 793d 6b2c 2074 7261 6e73  (x=q, y=k, trans
+00031cc0: 706f 7365 5f79 3d54 7275 6529 0a0a 2020  pose_y=True)..  
+00031cd0: 2020 2320 6164 6420 6d61 736b 2069 6620    # add mask if 
+00031ce0: 6170 706c 6963 6162 6c65 0a20 2020 2069  applicable.    i
+00031cf0: 6620 6973 5f6d 6173 6b5f 7072 6573 656e  f is_mask_presen
+00031d00: 743a 0a20 2020 2020 2020 2061 7474 6e5f  t:.        attn_
+00031d10: 7765 6967 6874 7320 3d20 6d62 2e61 6464  weights = mb.add
+00031d20: 2878 3d61 7474 6e5f 7765 6967 6874 732c  (x=attn_weights,
+00031d30: 2079 3d6d 6173 6b29 0a0a 2020 2020 2320   y=mask)..    # 
+00031d40: 646f 2073 6f66 746d 6178 0a20 2020 2061  do softmax.    a
+00031d50: 7474 6e5f 7765 6967 6874 735f 6e6f 726d  ttn_weights_norm
+00031d60: 616c 697a 6564 203d 206d 622e 736f 6674  alized = mb.soft
+00031d70: 6d61 7828 783d 6174 746e 5f77 6569 6768  max(x=attn_weigh
+00031d80: 7473 2c20 6178 6973 3d2d 3129 0a0a 2020  ts, axis=-1)..  
+00031d90: 2020 2320 6d75 6c74 6970 6c79 2061 7474    # multiply att
+00031da0: 6e5f 7765 6967 6874 7320 616e 6420 7661  n_weights and va
+00031db0: 6c75 6520 7465 6e73 6f72 0a20 2020 2072  lue tensor.    r
+00031dc0: 6573 203d 206d 622e 6d61 746d 756c 2878  es = mb.matmul(x
+00031dd0: 3d61 7474 6e5f 7765 6967 6874 735f 6e6f  =attn_weights_no
+00031de0: 726d 616c 697a 6564 2c20 793d 762c 206e  rmalized, y=v, n
+00031df0: 616d 653d 6e6f 6465 2e6e 616d 6529 0a20  ame=node.name). 
+00031e00: 2020 2063 6f6e 7465 7874 2e61 6464 2872     context.add(r
+00031e10: 6573 290a                                es).
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/torch/ssa_passes/torch_tensor_assign_to_core.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/torch/ssa_passes/torch_tensor_assign_to_core.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/torch/ssa_passes/torch_upsample_to_core_upsample.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/torch/ssa_passes/torch_upsample_to_core_upsample.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/torch/test/test_api.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/torch/test/test_api.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/torch/test/test_custom_ops.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/torch/test/test_custom_ops.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/torch/test/test_examples.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/torch/test/test_examples.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/torch/test/test_internal_graph.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/torch/test/test_internal_graph.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/torch/test/test_passes.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/torch/test/test_passes.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/torch/test/test_torch_conversion_api.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/torch/test/test_torch_conversion_api.py`

 * *Files 4% similar despite different names*

```diff
@@ -8,28 +8,36 @@
 
 import numpy as np
 import pytest
 from PIL import Image
 
 import coremltools as ct
 from coremltools._deps import _HAS_TORCH, MSG_TORCH_NOT_FOUND
-from coremltools.converters.mil.frontend.torch.test.testing_utils import \
-    _copy_input_data
+from coremltools.converters.mil.frontend.torch.test.testing_utils import _copy_input_data
 from coremltools.converters.mil.testing_utils import (
-    assert_cast_ops_count, assert_input_dtype, assert_ops_in_mil_program,
-    assert_output_dtype, assert_prog_input_type, assert_prog_output_type,
-    assert_spec_input_image_type, assert_spec_output_image_type,
-    verify_prediction)
+    assert_cast_ops_count,
+    assert_input_dtype,
+    assert_ops_in_mil_program,
+    assert_output_dtype,
+    assert_prog_input_type,
+    assert_prog_output_type,
+    assert_spec_input_image_type,
+    assert_spec_output_image_type,
+    get_op_types_in_program,
+    verify_prediction,
+)
 from coremltools.proto import FeatureTypes_pb2 as ft
 from coremltools.test.api.test_api_examples import TestInputs as _TestInputs
 
 if _HAS_TORCH:
     import torch
     import torchvision
 
+    torch.manual_seed(1818)
+
 #################################################################################
 # Note: all tests are also used as examples in https://coremltools.readme.io/docs
 # as a reference.
 # Whenever any of the following test fails, we should update API documentations
 #################################################################################
 
 @pytest.mark.skipif(not _HAS_TORCH, reason=MSG_TORCH_NOT_FOUND)
@@ -94,15 +102,15 @@
 
         """
         Running predict() is only supported on macOS.
         """
         if ct.utils._is_macos():
             results = mlmodel.predict({"input": example_input.numpy()})
             assert isinstance(results, dict)
-            
+
     @staticmethod
     def test_convert_torch_traced_model_to_milinternal(tmpdir):
         from torch import nn
         class Network(nn.Module):
             def __init__(self):
                 super(Network, self).__init__()
                 self.hidden = nn.Linear(100, 10)
@@ -123,15 +131,15 @@
         traced_model = torch.jit.trace(torch_model, example_input)
         model = ct.convert(
             traced_model,
             inputs=[ct.TensorType(name="input", shape=example_input.shape)],
             convert_to='milinternal'
         )
         assert isinstance(model, ct.converters.mil.Program)
-        
+
     @staticmethod
     def test_torch_classifier():
         class Net(torch.nn.Module):
             def __init__(self):
                 super(Net, self).__init__()
                 self.linear1 = torch.nn.Linear(28 * 28, 100)
                 self.linear2 = torch.nn.Linear(100, 50)
@@ -174,15 +182,15 @@
                 key_type = str if class_type == "str" else int
                 assert isinstance(coreml_out["classLabel"], key_type)
 
         for class_type in ("str", "int"):
             _test_classifier(traced_model, example_input, class_type, "neuralnetwork")
             if ct.utils._macos_version() >= (12, 0):
                 _test_classifier(traced_model, example_input, class_type, "mlprogram")
-                
+
     @staticmethod
     @pytest.mark.parametrize("convert_to", ['neuralnetwork', 'mlprogram'])
     def test_convert_to_argument_with_torch_model(tmpdir, convert_to):
         class Network(torch.nn.Module):
             def __init__(self):
                 super(Network, self).__init__()
                 self.hidden = torch.nn.Linear(30, 5)
@@ -203,15 +211,15 @@
         )
         assert isinstance(model, ct.models.MLModel)
         spec = model.get_spec()
         if convert_to == "mlprogram":
             assert spec.WhichOneof('Type') == 'mlProgram'
         else:
             assert spec.WhichOneof('Type') == 'neuralNetwork'
-            
+
     @staticmethod
     def test_deployment_target_argument_with_torch_model():
         class Network(torch.nn.Module):
             def __init__(self):
                 super(Network, self).__init__()
                 self.hidden = torch.nn.Linear(30, 5)
                 self.relu = torch.nn.ReLU()
@@ -262,15 +270,15 @@
                 inputs=[ct.TensorType(name="input", shape=example_input.shape)],
                 convert_to="mlprogram",
                 minimum_deployment_target=ct.target.iOS14,
             )
         expected_error = "When 'convert_to' is mlprogram, the minimum deployment target " \
                          "must be at least iOS15/macOS12/watchOS8/tvOS15"
         assert expected_error == str(e.value)
-        
+
     @staticmethod
     def test_get_milprogram_method_with_torch_model():
         class Network(torch.nn.Module):
             def __init__(self):
                 super(Network, self).__init__()
                 self.hidden = torch.nn.Linear(100, 10)
                 self.relu = torch.nn.ReLU()
@@ -286,15 +294,15 @@
         traced_model = torch.jit.trace(torch_model, example_input)
         model = ct.convert(
             traced_model,
             inputs=[ct.TensorType(shape=example_input.shape)],
             convert_to='mlprogram'
         )
         assert isinstance(model._get_mil_internal(), ct.converters.mil.Program)
-        
+
     @staticmethod
     @pytest.mark.skipif(ct.utils._macos_version() < (12, 0), reason='Model produces specification 6.')
     @pytest.mark.parametrize(
         "convert_to, provide_prob_output_argument",
         itertools.product(
             ["neuralnetwork", "mlprogram"],
             [False, True],
@@ -338,15 +346,15 @@
 @pytest.mark.skipif(ct.utils._macos_version() < (10, 15), reason='Model produces specification 4.')
 @pytest.mark.skipif(not _HAS_TORCH, reason=MSG_TORCH_NOT_FOUND)
 class TestTorchInputs(_TestInputs):
     @staticmethod
     @pytest.mark.skipif(not ct.utils._is_macos(), reason="test needs predictions")
     def test_torch_predict_input():
         TestTorchInputs._test_variant_input_type_prediction(torch.tensor)
-        
+
     @staticmethod
     def test_int64_inputs():
 
         num_tokens = 3
         embedding_size = 5
 
         class TestModule(torch.nn.Module):
@@ -412,15 +420,15 @@
                         name="input",
                         shape=example_input.shape,
                         dtype=example_input.numpy().dtype,
                     ),
                 ],
                 outputs=["output"],
             )
-            
+
     @staticmethod
     def test_fully_dynamic_inputs():
         """
         All dims of the inputs are dynamic, and write to slice to one of the
         inputs.
         """
 
@@ -437,15 +445,15 @@
         model = Model(torch.tensor(3))
         scripted_model = torch.jit.script(model)
 
         mlmodel = ct.convert(
             scripted_model,
             inputs=[
                 ct.TensorType("x", shape=(ct.RangeDim(), ct.RangeDim())),
-                ct.TensorType("y", shape=(ct.RangeDim(), ct.RangeDim()))
+                ct.TensorType("y", shape=(ct.RangeDim(), ct.RangeDim())),
             ],
         )
 
         # running predict() is supported on macOS
         if ct.utils._is_macos():
             x, y = torch.rand(2, 4), torch.rand(1, 2)
             torch_input = _copy_input_data([x, y])
@@ -458,15 +466,15 @@
             x, y = torch.rand(1, 6), torch.rand(2, 3)
             torch_input = _copy_input_data([x, y])
             torch_res = model(*torch_input)
             results = mlmodel.predict({"x": x.cpu().detach().numpy(),
               "y": y.cpu().detach().numpy()})
             for i, name in enumerate(mlmodel.output_description):
                 np.testing.assert_allclose(torch_res[i], results[name])
-                
+
     @staticmethod
     def test_rank0_inputs_torch():
         """Similar to TestPyTorchConverterExamples::test_int64_inputs but
         using rank-0 int input.
         """
 
         num_tokens = 3
@@ -493,15 +501,15 @@
                     ct.TensorType(
                         name="input",
                         shape=example_input.shape,
                         dtype=example_input.numpy().dtype,
                     )
                 ],
             )
-        
+
     @staticmethod
     @pytest.mark.parametrize("variable_length", [True, False])
     def test_torch_range_dim_lstm(variable_length):
         """
         This example shows how to run LSTM with previous hidden / cell states
         """
 
@@ -534,16 +542,15 @@
         rand_c0 = torch.rand(*h_shape)
 
         traced_model = torch.jit.trace(model, (rand_input, rand_h0, rand_c0))
 
         # ct.RangeDim() tells coremltools that this dimension can change for
         # each inference example (aka "runtime-determined"). If the sequence
         # length is always the same (e.g., 2 step LSTM would have seq_len == 2)
-        # Note that fixed-length models usually run slightly faster
-        # than variable length models.
+        # Note that fixed-length models usually run slightly faster than variable length models.
         ct_seq_len = ct.RangeDim() if variable_length else seq_len
         seq_input = ct.TensorType(shape=(ct_seq_len, batch, input_size),
             name="seq_input")
         h_input = ct.TensorType(shape=h_shape, name="h_input")
         c_input = ct.TensorType(shape=h_shape, name="c_input")
 
         mlmodel = ct.convert(
@@ -743,15 +750,16 @@
         example_input = [
             torch.randint(high=num_tokens, size=(2,), dtype=torch.int64),
             torch.rand(1),
             ]
         traced_model = torch.jit.trace(model, example_input)
 
         required_input = ct.TensorType(
-            name="required_input", shape=(ct.RangeDim(),), dtype=np.int64)
+            name="required_input", shape=(ct.RangeDim(),), dtype=np.int64
+        )
         default_value = np.array([3]).astype(np.float32)
         optional_input = ct.TensorType(name="optional_input", shape=(1,),
             default_value=default_value)
 
         for compute_units in ct.ComputeUnit:
             if compute_units == ct.ComputeUnit.CPU_AND_NE and ct.utils._macos_version() < (13, 0):
                 continue
@@ -1395,7 +1403,157 @@
         model_output_pil_image = mlmodel.predict({"input": sample_input})['output_image']
         assert isinstance(model_output_pil_image, Image.Image)
         assert model_output_pil_image.mode == "F"
         model_output_as_numpy = np.array(model_output_pil_image)
         reference_output = rank4_grayscale_input_model(torch.from_numpy(sample_input)).detach().numpy()
         reference_output = np.squeeze(reference_output)
         np.testing.assert_allclose(reference_output, model_output_as_numpy, rtol=1e-2, atol=1e-2)
+
+
+@pytest.mark.skipif(
+    ct.utils._macos_version() < (14, 0), reason="Tests are for deployment target ios17/macos14"
+)
+class TestQuantizationConversionAPI:
+    def test_dynamic_quantization(self):
+        torch.backends.quantized.engine = "qnnpack"
+
+        class Model(torch.nn.Module):
+            def __init__(self):
+                super().__init__()
+                self.fc = torch.nn.Linear(3, 2)
+
+            def forward(self, x):
+                x = self.fc(x)
+                return x
+
+        SHAPE = (4, 3)
+        x = torch.randn(SHAPE)
+
+        model_fp32 = Model()
+        model_int8 = torch.ao.quantization.quantize_dynamic(
+            model_fp32,
+            {torch.nn.Linear},  # a set of layers to dynamically quantize
+            dtype=torch.qint8,
+        )
+        model_int8.eval()
+
+        traced_model = torch.jit.trace(model_int8, x)
+
+        with pytest.raises(
+            RuntimeError,
+            match=(
+                r"PyTorch convert function for op '.*_dynamic' not implemented\.\n"
+                r"Dynamic quantized models are not supported by Core ML.\n"
+                r"Please use static quantization or the APIs in coremltools.optimize to quantize/compress models."
+            ),
+        ):
+            ct.convert(traced_model, inputs=[ct.TensorType(shape=SHAPE)])
+
+    def test_static_quantization_as_activation_quantization(self):
+        torch.backends.quantized.engine = "qnnpack"
+
+        class Model(torch.nn.Module):
+            def __init__(self):
+                super().__init__()
+                self.quant = torch.ao.quantization.QuantStub()
+                self.conv = torch.nn.Conv2d(3, 2, 5)
+                self.relu = torch.nn.ReLU()
+                self.dequant = torch.ao.quantization.DeQuantStub()
+
+            def forward(self, x):
+                x = self.quant(x)
+                x = self.conv(x)
+                x = self.relu(x)
+                x = self.dequant(x)
+                return x
+
+        SHAPE = (4, 3, 8, 16)
+        x = torch.randn(SHAPE)
+
+        model_fp32 = Model()
+        model_fp32.eval()
+
+        model_fp32.qconfig = torch.ao.quantization.get_default_qconfig("qnnpack")
+        model_fp32_fused = torch.ao.quantization.fuse_modules(model_fp32, [["conv", "relu"]])
+        model_fp32_prepared = torch.ao.quantization.prepare(model_fp32_fused)
+        model_fp32_prepared(x)
+        model_int8 = torch.ao.quantization.convert(model_fp32_prepared)
+
+        traced_model = torch.jit.trace(model_int8, x)
+        coreml_model = ct.convert(
+            traced_model,
+            inputs=[ct.TensorType(name="x", shape=SHAPE)],
+            outputs=[ct.TensorType(name="y")],
+            minimum_deployment_target=ct.target.iOS17,
+        )
+
+        ops = get_op_types_in_program(coreml_model._mil_program)
+        # constexpr_affine_dequantize and cast -> quantize can have arbitrary order
+        assert ops[:3] == ["cast", "quantize", "constexpr_affine_dequantize"] or ops[:3] == [
+            "constexpr_affine_dequantize",
+            "cast",
+            "quantize",
+        ]
+        # these ops have well-defined order
+        assert ops[3:] == [
+            # quantized ConvRelu op
+            "dequantize",
+            "conv",
+            "relu",
+            "quantize",
+            # dequantize and output
+            "dequantize",
+            "cast",
+        ]
+
+        output = traced_model(x)
+        coreml_output = coreml_model.predict({"x": x})["y"]
+        np.testing.assert_allclose(output, coreml_output, rtol=1e-2, atol=2e-2)
+
+    def test_static_quantization_as_weight_compression(self):
+        torch.backends.quantized.engine = "qnnpack"
+
+        weight = torch.rand(5, 3, 2, 4)
+
+        class Model(torch.nn.Module):
+            def __init__(self):
+                super().__init__()
+                self.quant = torch.ao.quantization.QuantStub()
+                self.dequant = torch.ao.quantization.DeQuantStub()
+
+            def forward(self, x):
+                quantized_weight = self.quant(weight)
+                dequantized_weight = self.dequant(quantized_weight)
+                y = torch.nn.functional.conv2d(x, dequantized_weight)
+                return y
+
+        SHAPE = (4, 3, 16, 32)
+        x = torch.randn(SHAPE)
+
+        model_fp32 = Model()
+        model_fp32.eval()
+
+        model_fp32.qconfig = torch.ao.quantization.get_default_qconfig("qnnpack")
+        model_fp32_prepared = torch.ao.quantization.prepare(model_fp32)
+        model_fp32_prepared(x)
+        model_int8 = torch.ao.quantization.convert(model_fp32_prepared)
+
+        traced_model = torch.jit.trace(model_int8, x)
+        coreml_model = ct.convert(
+            traced_model,
+            inputs=[ct.TensorType(name="x", shape=SHAPE)],
+            outputs=[ct.TensorType(name="y")],
+            minimum_deployment_target=ct.target.iOS17,
+        )
+
+        ops = get_op_types_in_program(coreml_model._mil_program)
+        # constexpr_affine_dequantize and cast can have arbitrary order
+        assert ops[:2] == ["cast", "constexpr_affine_dequantize"] or ops[:2] == [
+            "constexpr_affine_dequantize",
+            "cast",
+        ]
+        # these ops have well-defined order
+        assert ops[2:] == ["conv", "cast"]
+
+        output = traced_model(x)
+        coreml_output = coreml_model.predict({"x": x})["y"]
+        np.testing.assert_allclose(output, coreml_output, rtol=1e-2, atol=2e-2)
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/torch/test/test_torch_ops.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/torch/test/test_torch_ops.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,26 +1,32 @@
 #  Copyright (c) 2020, Apple Inc. All rights reserved.
 #
 #  Use of this source code is governed by a BSD-3-clause license that can be
 #  found in the LICENSE.txt file or at https://opensource.org/licenses/BSD-3-Clause
 
 import itertools
 import platform
-from typing import List, Tuple
+from typing import List, Optional, Tuple
 from unittest.mock import patch
 
 import numpy as np
 import pytest
 import torch.nn as nn
+import torchaudio
 import torchvision
 
 import coremltools as ct
 from coremltools import RangeDim, Shape, TensorType
 from coremltools._deps import version_lt
 from coremltools.converters.mil import testing_reqs
+from coremltools.converters.mil.frontend.torch.ops import (
+    NUM_TO_TORCH_DTYPE,
+    NUMPY_DTYPE_TO_TORCH_NUM,
+)
+from coremltools.converters.mil.mil import Operation, Program, types
 from coremltools.converters.mil.mil.var import Var
 from coremltools.converters.mil.testing_utils import einsum_equations, gen_input_shapes_einsum
 from coremltools.models.utils import _macos_version, _python_version
 
 from .testing_utils import ModuleWrapper, TorchBaseTest, contains_op, generate_input_data
 
 backends = testing_reqs.backends
@@ -227,16 +233,27 @@
 
         class Model(nn.Module):
             def forward(self, x):
                 return torch.mean(x, dim=(2, 3), keepdim=True)
 
         model = Model()
         shape = (1, 3, 256, 256)
+        upper_bound = 512 if backend[0] == "mlprogram" else -1
         converter_input_type = [
-            TensorType(shape=Shape(shape=[1, 3, RangeDim(), RangeDim()], default=shape))
+            TensorType(
+                shape=Shape(
+                    shape=[
+                        1,
+                        3,
+                        RangeDim(upper_bound=upper_bound),
+                        RangeDim(upper_bound=upper_bound),
+                    ],
+                    default=shape,
+                )
+            )
         ]
 
         self.run_compare_torch(
             shape,
             model,
             backend=backend,
             compute_unit=compute_unit,
@@ -253,15 +270,20 @@
             def forward(self, x):
                 return torch.mean(x, dim=(2, 3), keepdim=True)
 
         model = Network()
         x = torch.rand(1, 3, 256, 256)
         traced_model = torch.jit.trace(model, x)
         input_x = ct.TensorType(
-            shape=(1, 3, ct.RangeDim(default=256), ct.RangeDim(default=256)),
+            shape=(
+                1,
+                3,
+                ct.RangeDim(upper_bound=512, default=256),
+                ct.RangeDim(upper_bound=512, default=256),
+            ),
             name="input",
         )
         cml = ct.convert(
             traced_model,
             inputs=[input_x],
             outputs=[ct.TensorType(name="out")],
             convert_to="mlprogram",
@@ -1814,17 +1836,18 @@
             dilation=3,
         )
         in_height = 256
         in_width = 512
         input_shape = (1, in_channels, in_height, in_width)
 
         if dynamic_input:
+            upper_bound = 4096 if backend[0] == "mlprogram" else -1
             converter_input_type = [
                 TensorType(
-                    shape=(1, in_channels, RangeDim(256, -1), RangeDim(256, -1)),
+                    shape=(1, in_channels, RangeDim(256, upper_bound), RangeDim(256, upper_bound)),
                     dtype=np.float32,
                 )
             ]
             self.run_compare_torch(
                 input_shape,
                 model,
                 backend=backend,
@@ -2086,15 +2109,22 @@
                 "scale_factor": scales,
                 "mode": "linear",
                 "align_corners": align_corners,
                 "recompute_scale_factor": recompute_scale_factor,
             },
         )
         converter_input_type = [
-            TensorType(shape=(1, 3, RangeDim(default=22)), dtype=np.float32)
+            TensorType(
+                shape=(
+                    1,
+                    3,
+                    RangeDim(default=22, upper_bound=22 if backend[0] == "mlprogram" else -1),
+                ),
+                dtype=np.float32,
+            )
         ]
         mlmodel = self.run_compare_torch(
             input_shape,
             model,
             backend=backend,
             compute_unit=compute_unit,
             converter_input_type=converter_input_type,
@@ -2162,15 +2192,20 @@
             nn.functional.interpolate,
             {
                 "scale_factor": scales,
                 "mode": "nearest",
                 "recompute_scale_factor": True,
             },
         )
-        converter_input_type = [TensorType(shape=(1, 3, RangeDim()), dtype=np.float32)]
+        converter_input_type = [
+            TensorType(
+                shape=(1, 3, RangeDim(upper_bound=10 if backend[0] == "mlprogram" else -1)),
+                dtype=np.float32,
+            )
+        ]
         mlmodel = self.run_compare_torch(
             input_shape,
             model,
             backend=backend,
             compute_unit=compute_unit,
             converter_input_type=converter_input_type,
         )[1]
@@ -2323,16 +2358,20 @@
             nn.functional.interpolate,
             {
                 "scale_factor": (scales_h, scales_w),
                 "mode": "nearest",
                 "recompute_scale_factor": True,
             },
         )
+        upper_bound = 10 if backend[0] == "mlprogram" else -1
         converter_input_type = [
-            TensorType(shape=(1, 3, RangeDim(), RangeDim()), dtype=np.float32)
+            TensorType(
+                shape=(1, 3, RangeDim(upper_bound=upper_bound), RangeDim(upper_bound=upper_bound)),
+                dtype=np.float32,
+            )
         ]
         mlmodel = self.run_compare_torch(
             input_shape,
             model,
             backend=backend,
             compute_unit=compute_unit,
             converter_input_type=converter_input_type,
@@ -2381,17 +2420,23 @@
             {
                 "scale_factor": (scales_h, scales_w),
                 "mode": "bilinear",
                 "align_corners": align_corners,
                 "recompute_scale_factor": recompute_scale_factor,
             },
         )
+        dim_upper_bound = 30 if backend[0] == "mlprogram" else -1
         converter_input_type = [
             TensorType(
-                shape=(1, 3, RangeDim(default=9), RangeDim(default=22)),
+                shape=(
+                    1,
+                    3,
+                    RangeDim(default=9, upper_bound=dim_upper_bound),
+                    RangeDim(default=22, upper_bound=dim_upper_bound),
+                ),
                 dtype=np.float32,
             )
         ]
         mlmodel = self.run_compare_torch(
             input_shape,
             model,
             backend=backend,
@@ -2893,49 +2938,67 @@
         model = TestModel()
         self.run_compare_torch(
             input_shapes, model, backend=backend, compute_unit=compute_unit
         )
 
 
 class TestPoolSymbolicInput(TorchBaseTest):
-    def test_max_pool(self):
+    @pytest.mark.parametrize(
+        "compute_unit, backend",
+        itertools.product(compute_units, backends),
+    )
+    def test_max_pool(self, compute_unit, backend):
         model = nn.MaxPool2d(
             kernel_size=1,
             stride=2,
             padding=0,
             dilation=1,
             ceil_mode=True,
         )
         input_shape = (1, 1, 11, 11)
+        upper_bound = 20 if backend[0] == "mlprogram" else -1
         converter_input_type = [
-            TensorType(shape=(1, 1, RangeDim(), RangeDim()), dtype=np.float32)
+            TensorType(
+                shape=(1, 1, RangeDim(upper_bound=upper_bound), RangeDim(upper_bound=upper_bound)),
+                dtype=np.float32,
+            )
         ]
         self.run_compare_torch(
             input_shape,
             model,
-            backend=backends[0],
+            backend=backend,
+            compute_unit=compute_unit,
             converter_input_type=converter_input_type,
         )
 
-    def test_avg_pool(self):
+    @pytest.mark.parametrize(
+        "compute_unit, backend",
+        itertools.product(compute_units, backends),
+    )
+    def test_avg_pool(self, compute_unit, backend):
         model = nn.AvgPool2d(
             kernel_size=2,
             stride=2,
             padding=1,
             count_include_pad=True,
             ceil_mode=True,
         )
         input_shape = (1, 2, 15, 15)
+        upper_bound = 20 if backend[0] == "mlprogram" else -1
         converter_input_type = [
-            TensorType(shape=(1, 2, RangeDim(), RangeDim()), dtype=np.float32)
+            TensorType(
+                shape=(1, 2, RangeDim(upper_bound=upper_bound), RangeDim(upper_bound=upper_bound)),
+                dtype=np.float32,
+            )
         ]
         self.run_compare_torch(
             input_shape,
             model,
-            backend=backends[0],
+            backend=backend,
+            compute_unit=compute_unit,
             converter_input_type=converter_input_type,
         )
 
 
 class TestLSTM(TorchBaseTest):
     @pytest.mark.parametrize(
         ",".join(
@@ -3190,14 +3253,18 @@
         compute_unit,
         backend,
         pack_batch_first,
         pad_batch_first,
         LSTM_batch_first,
         pad_value,
     ):
+        if backend[0] == "mlprogram":
+            pytest.xfail(
+                "rdar://109081548 ([Bug] TestLSTMWithPackedSequence is failing through E5ML)"
+            )
         from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence
 
         input_size = 4
         hidden_size = 6
         num_layers = 1
 
         class Encoder(torch.nn.Module):
@@ -3442,14 +3509,36 @@
             (1, 3, 16, 16),
             model,
             backend=backend,
             compute_unit=compute_unit,
         )
 
 
+class TestTile(TorchBaseTest):
+    @pytest.mark.parametrize(
+        "compute_unit, backend, dims",
+        itertools.product(
+            compute_units,
+            backends,
+            [(1, 2, 4), (3, 2), (2,)],
+        ),
+    )
+    def test_tile(self, compute_unit, backend, dims):
+        class TestModel(nn.Module):
+            def forward(self, x):
+                return torch.tile(x, dims)
+
+        self.run_compare_torch(
+            (2, 3, 5),
+            TestModel(),
+            backend=backend,
+            compute_unit=compute_unit,
+        )
+
+
 class TestBitwiseNot(TorchBaseTest):
     @pytest.mark.parametrize(
         "compute_unit, backend, input_type",
         itertools.product(
             compute_units,
             backends,
             ["int", "bool"],
@@ -3530,14 +3619,37 @@
             shape, FullStaticModel().eval(), backend=backend, compute_unit=compute_unit
         )
 
     @pytest.mark.parametrize(
         "compute_unit, backend, shape_val",
         itertools.product(
             compute_units,
+            backends,
+            [
+                [(1,), 0.0],
+                [(2, 3), 3.1415],
+                [(1, 1, 2, 5, 1), -2.0],
+            ],
+        ),
+    )
+    def test_full_scalar(self, compute_unit, backend, shape_val):
+        shape, val = shape_val
+
+        class FullScalarModel(nn.Module):
+            def forward(self, x):
+                return x / torch.full([], fill_value=val)
+
+        self.run_compare_torch(
+            shape, FullScalarModel().eval(), backend=backend, compute_unit=compute_unit
+        )
+
+    @pytest.mark.parametrize(
+        "compute_unit, backend, shape_val",
+        itertools.product(
+            compute_units,
             [
                 ["neuralnetwork", "fp32", ct.target.iOS14],
                 ["mlprogram", "fp16", ct.target.iOS15],
                 ["mlprogram", "fp32", ct.target.iOS15],
                 ["mlprogram", "fp16", ct.target.iOS16],
                 ["mlprogram", "fp32", ct.target.iOS16],
             ],
@@ -3799,14 +3911,54 @@
                 return torch.Tensor([len(y)])
 
         self.run_compare_torch(
             shape, TestModel(), backend=backend, compute_unit=compute_unit
         )
 
 
+class TestRandn(TorchBaseTest):
+    @pytest.mark.parametrize(
+        "compute_unit, backend, shape",
+        itertools.product(
+            compute_units,
+            backends,
+            [(1,), (2, 3)],
+        ),
+    )
+    def test_randn(self, compute_unit, backend, shape):
+        class TestModel(nn.Module):
+            def forward(self, x):
+                y = torch.randn(*x.shape)
+                return torch.Tensor([len(y)])
+
+        self.run_compare_torch(
+            shape, TestModel(), backend=backend, compute_unit=compute_unit
+        )
+
+
+class TestRandnLike(TorchBaseTest):
+    @pytest.mark.parametrize(
+        "compute_unit, backend, shape",
+        itertools.product(
+            compute_units,
+            backends,
+            [(1,), (2, 3)],
+        ),
+    )
+    def test_randn_like(self, compute_unit, backend, shape):
+        class TestModel(nn.Module):
+            def forward(self, x):
+                y = torch.randn_like(torch.randn(shape))
+                return torch.Tensor([len(y)])
+
+        self.run_compare_torch(
+            shape, TestModel(), backend=backend, compute_unit=compute_unit
+        )
+
+
 class TestTypeAs(TorchBaseTest):
     @pytest.mark.parametrize(
         "compute_unit, backend, type",
         itertools.product(compute_units, backends, ["int32", "float32", "bool"]),
     )
     def test_type_as(self, compute_unit, backend, type):
         class TestNet(nn.Module):
@@ -4005,51 +4157,65 @@
         model = TestModel()
 
         self.run_compare_torch(
             input_shape, model, backend=backend, compute_unit=compute_unit
         )
 
     @pytest.mark.parametrize(
-        "compute_unit, backend",
+        "compute_unit, backend, minimum_deployment_target",
         itertools.product(
             compute_units,
             backends,
+            [None, ct.target.iOS17],
         ),
     )
-    def test_expand_dynamic_shape0(self, compute_unit, backend):
+    def test_expand_dynamic_shape0(self, compute_unit, backend, minimum_deployment_target):
         class TestModel(nn.Module):
             def forward(self, x):
                 return x.expand(x.shape[1], x.shape[1])
 
         self.run_compare_torch(
             torch.arange(20).reshape((1, 20)),
             TestModel(),
             input_as_shape=False,
-            converter_input_type=[TensorType(shape=[1, ct.RangeDim()])],
+            converter_input_type=[
+                TensorType(
+                    shape=[1, ct.RangeDim(upper_bound=20 if backend[0] == "mlprogram" else -1)]
+                )
+            ],
             backend=backend,
             compute_unit=compute_unit,
+            minimum_deployment_target=minimum_deployment_target,
         )
 
     @pytest.mark.parametrize(
         "compute_unit, backend",
         itertools.product(
             compute_units,
             backends,
         ),
     )
     def test_expand_dynamic_shape1(self, compute_unit, backend):
         class TestModel(nn.Module):
             def forward(self, x):
                 return x.expand(x.shape[0], 1, x.shape[-1], x.shape[-1])
 
+        upper_bound = 20 if backend[0] == "mlprogram" else -1
         self.run_compare_torch(
             torch.arange(20).reshape((1, 20)),
             TestModel(),
             input_as_shape=False,
-            converter_input_type=[TensorType(shape=[ct.RangeDim(), ct.RangeDim()])],
+            converter_input_type=[
+                TensorType(
+                    shape=[
+                        ct.RangeDim(upper_bound=upper_bound),
+                        ct.RangeDim(upper_bound=upper_bound),
+                    ]
+                )
+            ],
             backend=backend,
             compute_unit=compute_unit,
         )
 
     @pytest.mark.parametrize(
         "compute_unit, backend",
         itertools.product(
@@ -4058,19 +4224,20 @@
         ),
     )
     def test_expand_dynamic_shape2(self, compute_unit, backend):
         class TestModel(nn.Module):
             def forward(self, x):
                 return x.expand(x.shape[-1], 1, x.shape[-1], x.shape[-1])
 
+        upper_bound = 20 if backend[0] == "mlprogram" else -1
         self.run_compare_torch(
             torch.arange(20).reshape((1, 20)),
             TestModel(),
             input_as_shape=False,
-            converter_input_type=[TensorType(shape=[1, ct.RangeDim()])],
+            converter_input_type=[TensorType(shape=[1, ct.RangeDim(upper_bound=upper_bound)])],
             backend=backend,
             compute_unit=compute_unit,
         )
 
     @pytest.mark.parametrize(
         "compute_unit, backend",
         itertools.product(
@@ -4079,19 +4246,27 @@
         ),
     )
     def test_expand_dynamic_shape3(self, compute_unit, backend):
         class TestModel(nn.Module):
             def forward(self, x):
                 return x.expand(x.shape[0], 10)
 
+        upper_bound = 20 if backend[0] == "mlprogram" else -1
         self.run_compare_torch(
             torch.arange(20).reshape((20, 1)),
             TestModel(),
             input_as_shape=False,
-            converter_input_type=[TensorType(shape=[ct.RangeDim(), ct.RangeDim()])],
+            converter_input_type=[
+                TensorType(
+                    shape=[
+                        ct.RangeDim(upper_bound=upper_bound),
+                        ct.RangeDim(upper_bound=upper_bound),
+                    ]
+                )
+            ],
             backend=backend,
             compute_unit=compute_unit,
         )
 
     @pytest.mark.parametrize(
         "compute_unit, backend",
         itertools.product(
@@ -4104,15 +4279,19 @@
             def forward(self, x, y):
                 return x.expand(int(y[0]), int(y[1]))
 
         self.run_compare_torch(
             [torch.arange(20).reshape((20, 1)), torch.Tensor([20, 20])],
             TestModel(),
             input_as_shape=False,
-            converter_input_type=[TensorType(shape=[ct.RangeDim(), 1])],
+            converter_input_type=[
+                TensorType(
+                    shape=[ct.RangeDim(upper_bound=20 if backend[0] == "mlprogram" else -1), 1]
+                )
+            ],
             backend=backend,
             compute_unit=compute_unit,
         )
 
     @pytest.mark.parametrize(
         "compute_unit, backend, input_shapes",
         itertools.product(
@@ -4329,14 +4508,15 @@
             inputs,
             model,
             backend=backend,
             compute_unit=compute_unit,
             input_as_shape=False,
         )
 
+
 class TestEinsum(TorchBaseTest):
     @pytest.mark.parametrize(
         "compute_unit, backend, equation, reverse_input_order, dynamic",
         itertools.product(
             compute_units,
             backends,
             einsum_equations,
@@ -4344,44 +4524,16 @@
             [False, True],
         ),
     )
     def test_einsum(self, compute_unit, backend, equation, reverse_input_order, dynamic):
         class TestEinsum(nn.Module):
             def forward(self, x, y):
                 return torch.einsum(equation, x, y)
-        if backend == ("mlprogram", "fp16"):
-            if equation in [
-                "abc,cde->abde",
-                "abcd,cde->abe",
-                "iji,ji->j",
-                "jii,ijk->jk",
-                "ija,la->ijal",
-                "ia,ia->a",
-                "ai,ia->a",
-                "abi,abi->ab",
-                "iab,iab->ab",
-                "abi,bai->ba",
-                "ij,j->i",
-                "i,ij->j",
-                "ai,ija->aj",
-                "aibj,bi->jba",
-                "ij,jk->ik",
-                "abij,abjk->abik",
-                "aijb,bajk->abik",
-                "aij,aij->a",
-                "ija,ija->a",
-                "ija,jia->a",
-                "aijb,ajbi->ab",
-                "aibj,cdij->cadb",
-                "ijk,lmj->iklm",
-                "ijak,akl->aijl",
-            ] and dynamic:
-                pytest.xfail("rdar://106631543 ([Infra]Re-enable the unittests for torch einsum ops)")
 
-        input_shapes, converter_input_type = gen_input_shapes_einsum(equation, dynamic)
+        input_shapes, converter_input_type = gen_input_shapes_einsum(equation, dynamic, backend)
 
         if reverse_input_order:
             input_output_strings = equation.split("->")
             input_strings = input_output_strings[0].split(",")
             equation = (
                 input_strings[1]
                 + ","
@@ -4396,15 +4548,15 @@
         model = TestEinsum()
         self.run_compare_torch(
             input_shapes,
             model,
             backend=backend,
             compute_unit=compute_unit,
             input_as_shape=True,
-            converter_input_type=converter_input_type
+            converter_input_type=converter_input_type,
         )
 
     @pytest.mark.parametrize(
         "compute_unit, backend",
         itertools.product(
             compute_units,
             backends,
@@ -4483,30 +4635,35 @@
         self.run_compare_torch(
             input_shape, model, backend=backend, compute_unit=compute_unit
         )
 
 
 class TestReshape(TorchBaseTest):
     @pytest.mark.parametrize(
-        "compute_unit, backend, output_shape",
+        "compute_unit, backend, output_shape, minimum_deployment_target",
         itertools.product(
             compute_units,
             backends,
             [
                 (3, 2),
                 (2, -1),
                 (2, 1, 1, 3),
             ],
+            [None, ct.target.iOS17],
         ),
     )
-    def test_reshape(self, compute_unit, backend, output_shape):
+    def test_reshape(self, compute_unit, backend, output_shape, minimum_deployment_target):
         input_shape = (2, 3)
         model = ModuleWrapper(function=torch.reshape, kwargs={"shape": output_shape})
         self.run_compare_torch(
-            input_shape, model, backend=backend, compute_unit=compute_unit
+            input_shape,
+            model,
+            backend=backend,
+            compute_unit=compute_unit,
+            minimum_deployment_target=minimum_deployment_target,
         )
 
 
 class TestReshapeAs(TorchBaseTest):
     @pytest.mark.parametrize(
         "compute_unit, backend, input_output_shape",
         itertools.product(
@@ -4538,17 +4695,23 @@
         "compute_unit, backend, start_dim, end_dim, is_dynamic",
         itertools.product(compute_units, backends, [2, -2, 0], [3, -1], [False, True]),
     )
     def test_flatten(self, compute_unit, backend, start_dim, end_dim, is_dynamic):
         input_shape = (2, 3, 4, 5)
         converter_input_type = None
         if is_dynamic:
+            dim_upper_bound = 8 if backend[0] == "mlprogram" else -1
             converter_input_type = [
                 TensorType(
-                    shape=(2, 3, RangeDim(default=4), RangeDim(default=5)),
+                    shape=(
+                        2,
+                        3,
+                        RangeDim(default=4, upper_bound=dim_upper_bound),
+                        RangeDim(default=5, upper_bound=dim_upper_bound),
+                    ),
                     dtype=np.float32,
                 )
             ]
         model = ModuleWrapper(
             function=torch.flatten, kwargs={"start_dim": start_dim, "end_dim": end_dim}
         )
         self.run_compare_torch(
@@ -4578,16 +4741,48 @@
             function=torch.gather,
             kwargs={"dim": axis, "index": torch.from_numpy(indices)},
         )
         self.run_compare_torch(
             [params_shape], model, backend=backend, compute_unit=compute_unit
         )
 
+    def test_gather_along_axis_invalid_indices(self):
+        """This test is to verify that PyTorch gather op doesn't allow negative and out-of-range
+        indices, so we don't need to add mb.select for IOS17 mb.gather op when lowering torch.gather."""
+        data = torch.tensor([[1, 2], [3, 4]])
+        with pytest.raises(RuntimeError, match="index -1 is out of bounds"):
+            torch.gather(data, 1, torch.tensor([[-1, 0], [1, 0]]))
+        with pytest.raises(RuntimeError, match="index 2 is out of bounds"):
+            torch.gather(data, 1, torch.tensor([[0, 0], [2, 0]]))
+
 
 class TestActivation(TorchBaseTest):
+    @staticmethod
+    def run_compare_torch(input_data, model, target_op: Optional[str] = None, **kwargs):
+        """Override compare method for Activation ops tests, as we want to verify the mixed
+        precision support for alpha/beta in IOS17 Activation Ops."""
+        results = TorchBaseTest.run_compare_torch(input_data, model, **kwargs)
+
+        if target_op and kwargs.get("backend", (None, None))[1] == "fp16":
+            prog: Program = results[1]._mil_program
+            activation_op: Operation = prog.find_ops(op_type=target_op, exactly_one=True)[0]
+            assert activation_op.x.dtype == types.fp16
+
+            # Before IOS17, both alpha and input/output are converted to fp16.
+            # After IOS17, alpha is kept as fp32 because it supports mixed precision.
+            expected_alpha_beta_dtype = types.fp16
+            if kwargs.get("minimum_deployment_target", None) == ct.target.iOS17:
+                expected_alpha_beta_dtype = types.fp32
+            if hasattr(activation_op, "alpha"):
+                assert activation_op.alpha.dtype == expected_alpha_beta_dtype
+            if hasattr(activation_op, "beta"):
+                assert activation_op.beta.dtype == expected_alpha_beta_dtype
+
+        return results
+
     @pytest.mark.parametrize(
         "compute_unit, backend, shape",
         itertools.product(compute_units, backends, COMMON_SHAPES_ALL),
     )
     def test_relu(self, compute_unit, backend, shape):
         model = nn.ReLU().eval()
         self.run_compare_torch(
@@ -4604,56 +4799,75 @@
         itertools.product(compute_units, backends, COMMON_SHAPES_ALL),
     )
     def test_relu6(self, compute_unit, backend, shape):
         model = nn.ReLU6().eval()
         self.run_compare_torch(shape, model, backend=backend, compute_unit=compute_unit)
 
     @pytest.mark.parametrize(
-        "compute_unit, backend, alpha, shape, single_alpha",
+        "compute_unit, backend, alpha, shape, single_alpha, minimum_deployment_target",
         itertools.product(
             compute_units,
             backends,
             [0.25, 2.0],
             [(3,), (2, 6), (2, 3, 4), (2, 5, 6, 7), (2, 3, 4, 5, 6)],
             [True, False],
+            [None, ct.target.iOS17],
         ),
     )
-    def test_prelu(self, compute_unit, backend, alpha, shape, single_alpha):
+    def test_prelu(
+        self, compute_unit, backend, alpha, shape, single_alpha, minimum_deployment_target
+    ):
         if backend[0] == "mlprogram" and backend[1] == "fp16" or (len(shape) == 5):
             pytest.xfail(
                 "rdar://92175249 ([MIL] TestActivation::test_prelu[backend=(mlprogram, fp16)] CI failure)"
             )
         input_shape = shape
         num_parameters = input_shape[1] if len(input_shape) >= 2 else 1
         if single_alpha:
             num_parameters = 1
         model = nn.PReLU(num_parameters, alpha).eval()
         mlmodel = self.run_compare_torch(
-            input_shape, model, backend=backend, compute_unit=compute_unit
+            input_shape,
+            model,
+            backend=backend,
+            compute_unit=compute_unit,
+            minimum_deployment_target=minimum_deployment_target,
+            target_op="leaky_relu",  # prelu got fused to lrelu
         )
         prog = mlmodel[1]._mil_program
         # Unfortunately since all these tests result in a prelu with a common leakage factor, the
         # prelu_to_lrelu pass optimizes them to contain leaky_relu instead.
         assert len(prog.find_ops(op_type="leaky_relu")) == 1
         assert len(prog.find_ops(op_type="prelu")) == 0
 
     @pytest.mark.parametrize(
-        "compute_unit, backend, shape, alpha",
-        itertools.product(compute_units, backends, COMMON_SHAPES_ALL, [0.1, 2.0, 1.4]),
+        "compute_unit, backend, shape, alpha, minimum_deployment_target",
+        itertools.product(
+            compute_units, backends, COMMON_SHAPES_ALL, [0.1, 2.0], [None, ct.target.iOS17]
+        ),
     )
-    def test_leaky_relu(self, compute_unit, backend, shape, alpha):
+    def test_leaky_relu(self, compute_unit, backend, shape, alpha, minimum_deployment_target):
         model = nn.LeakyReLU(negative_slope=alpha).eval()
         self.run_compare_torch(
             shape,
             model,
             backend=backend,
+            minimum_deployment_target=minimum_deployment_target,
+            target_op="leaky_relu",
         )
 
         model = ModuleWrapper(nn.functional.leaky_relu_, {"negative_slope": alpha})
-        self.run_compare_torch(shape, model, backend=backend, compute_unit=compute_unit)
+        self.run_compare_torch(
+            shape,
+            model,
+            backend=backend,
+            compute_unit=compute_unit,
+            minimum_deployment_target=minimum_deployment_target,
+            target_op="leaky_relu",
+        )
 
     @pytest.mark.parametrize(
         "compute_unit, backend, shape",
         itertools.product(
             compute_units,
             backends,
             COMMON_SHAPES_ALL,
@@ -4688,20 +4902,44 @@
             nn.functional.hardtanh_, {"min_val": range_val[0], "max_val": range_val[1]}
         )
         self.run_compare_torch(
             input_shape, model, backend=backend, compute_unit=compute_unit
         )
 
     @pytest.mark.parametrize(
-        "compute_unit, backend, shape, alpha",
-        itertools.product(compute_units, backends, COMMON_SHAPES_ALL, [0.1, 2.0, 1.4]),
+        "compute_unit, backend, shape, alpha, minimum_deployment_target",
+        itertools.product(
+            compute_units, backends, COMMON_SHAPES_ALL, [0.1, 2.0], [None, ct.target.iOS17]
+        ),
     )
-    def test_elu(self, compute_unit, backend, shape, alpha):
+    def test_elu(self, compute_unit, backend, shape, alpha, minimum_deployment_target):
         model = nn.ELU(alpha).eval()
-        self.run_compare_torch(shape, model, backend=backend, compute_unit=compute_unit)
+        self.run_compare_torch(
+            shape,
+            model,
+            backend=backend,
+            compute_unit=compute_unit,
+            minimum_deployment_target=minimum_deployment_target,
+            target_op="elu",
+        )
+
+    @pytest.mark.parametrize(
+        "compute_unit, backend, shape, minimum_deployment_target",
+        itertools.product(compute_units, backends, COMMON_SHAPES_ALL, [None, ct.target.iOS17]),
+    )
+    def test_hardswish(self, compute_unit, backend, shape, minimum_deployment_target):
+        model = nn.Hardswish().eval()
+        self.run_compare_torch(
+            shape,
+            model,
+            backend=backend,
+            compute_unit=compute_unit,
+            minimum_deployment_target=minimum_deployment_target,
+            target_op="thresholded_relu",
+        )
 
     @pytest.mark.parametrize(
         "compute_unit, backend, shape",
         itertools.product(compute_units, backends, COMMON_SHAPES_ALL),
     )
     def test_gelu(self, compute_unit, backend, shape):
         model = nn.GELU().eval()
@@ -4726,34 +4964,46 @@
         ),
     )
     def test_sigmoid(self, compute_unit, backend, shape):
         model = nn.Sigmoid().eval()
         self.run_compare_torch(shape, model, backend=backend, compute_unit=compute_unit)
 
     @pytest.mark.parametrize(
-        "compute_unit, backend, shape",
-        itertools.product(compute_units, backends, COMMON_SHAPES_ALL),
+        "compute_unit, backend, shape, minimum_deployment_target",
+        itertools.product(compute_units, backends, COMMON_SHAPES_ALL, [None, ct.target.iOS17]),
     )
-    def test_sigmoid_hard(self, compute_unit, backend, shape):
+    def test_sigmoid_hard(self, compute_unit, backend, shape, minimum_deployment_target):
         model = nn.Hardsigmoid().eval()
-        self.run_compare_torch(shape, model, backend=backend, compute_unit=compute_unit)
+        self.run_compare_torch(
+            shape,
+            model,
+            backend=backend,
+            compute_unit=compute_unit,
+            minimum_deployment_target=minimum_deployment_target,
+            target_op="sigmoid_hard",
+        )
 
     @pytest.mark.parametrize(
-        "compute_unit, backend, beta, threshold",
-        itertools.product(compute_units, backends, [1, 2, 5], [5, 10, 20]),
+        "compute_unit, backend, beta, threshold, minimum_deployment_target",
+        itertools.product(compute_units, backends, [1, 2, 5], [5, 10, 20], [None, ct.target.iOS17]),
     )
     @pytest.mark.skipif(
         _macos_version() <= (10, 15),
         reason="Parametric SoftPlus segfaults on macOS 10.15 and below.",
     )
-    def test_softplus(self, compute_unit, backend, beta, threshold):
+    def test_softplus(self, compute_unit, backend, beta, threshold, minimum_deployment_target):
         input_shape = (1, 10, 5, 15)
         model = nn.Softplus(beta, threshold).eval()
         self.run_compare_torch(
-            input_shape, model, backend=backend, compute_unit=compute_unit
+            input_shape,
+            model,
+            backend=backend,
+            compute_unit=compute_unit,
+            minimum_deployment_target=minimum_deployment_target,
+            target_op="softplus_parametric",
         )
 
     @pytest.mark.parametrize(
         "compute_unit, backend, shape",
         itertools.product(
             compute_units,
             backends,
@@ -4786,23 +5036,23 @@
         itertools.product(compute_units, backends, [(1, 10), (1, 3, 4), (1, 4, 5, 6)]),
     )
     def test_silu(self, compute_unit, backend, shape):
         model = ModuleWrapper(function=torch.nn.functional.silu)
         self.run_compare_torch([shape], model, backend=backend)
 
     @pytest.mark.parametrize(
-        "compute_unit, backend, rounding_mode",
-        itertools.product(compute_units, backends, [None, "floor", "trunc"]),
+        "compute_unit, backend, rounding_mode, x2_type",
+        itertools.product(compute_units, backends, [None, "floor", "trunc"], [np.float32, np.int32]),
     )
-    def test_div(self, compute_unit, backend, rounding_mode):
+    def test_div(self, compute_unit, backend, rounding_mode, x2_type):
         model = ModuleWrapper(
             function=torch.div, kwargs={"rounding_mode": rounding_mode}
         )
         x1 = torch.from_numpy(np.array([2.3, 2.6, -3.6, -3.2], dtype=np.float32))
-        x2 = torch.from_numpy(np.array([1.0, 1.0, 1.0, 1.0], dtype=np.float32))
+        x2 = torch.from_numpy(np.array([1.0, 1.0, 1.0, 1.0], dtype=x2_type))
         out = torch.div(x1, x2, rounding_mode=rounding_mode)
         self.run_compare_torch(
             [x1, x2],
             model,
             backend=backend,
             compute_unit=compute_unit,
             input_as_shape=False,
@@ -4845,41 +5095,47 @@
             pytest.skip("sqrt on GPU producing nan.")
 
         op_func = getattr(torch, op_string)
         model = ModuleWrapper(function=op_func)
         self.run_compare_torch(shape, model, backend=backend, compute_unit=compute_unit)
 
     @pytest.mark.parametrize(
-        "compute_unit, backend, shape, clamp_range",
+        "compute_unit, backend, shape, clamp_range, minimum_deployment_target",
         itertools.product(
             compute_units,
             backends,
             [(1, 3, 5, 8)],
             [
                 (0.0, 1.0),
                 (-1.0, 0.5),
                 (0.2, 0.7),
                 (None, 4.0),
                 (-3.0, None),
                 (1, 2),
                 (1, 3.5),
                 (1, -1),
             ],
+            [None, ct.target.iOS17],
         ),
     )
-    def test_clamp(self, compute_unit, backend, shape, clamp_range):
+    def test_clamp(self, compute_unit, backend, shape, clamp_range, minimum_deployment_target):
         params_dict = {}
         if clamp_range[0] is not None:
             params_dict["min"] = clamp_range[0]
         if clamp_range[1] is not None:
             params_dict["max"] = clamp_range[1]
 
         model = ModuleWrapper(torch.clamp, params_dict)
         self.run_compare_torch(
-            shape, model, backend=backend, compute_unit=compute_unit, rand_range=(-5, 5)
+            shape,
+            model,
+            backend=backend,
+            compute_unit=compute_unit,
+            rand_range=(-5, 5),
+            minimum_deployment_target=minimum_deployment_target,
         )
 
     @pytest.mark.parametrize(
         "compute_unit, backend",
         itertools.product(
             compute_units,
             backends,
@@ -4895,36 +5151,38 @@
             backend=backend,
             compute_unit=compute_unit,
             input_as_shape=False,
             converter_input_type=[TensorType(shape=input_data.shape, dtype=np.int32)],
         )
 
     @pytest.mark.parametrize(
-        "compute_unit, backend, shape, threshold",
+        "compute_unit, backend, shape, threshold, minimum_deployment_target",
         itertools.product(
             compute_units,
             backends,
             [(1, 3, 5, 8)],
             [(0.0, 0.0), (0.5, 0.5), (0.5, 10), (0.9, 0.0)],
+            [None, ct.target.iOS17],
         ),
     )
-    def test_threshold(self, compute_unit, backend, shape, threshold):
+    def test_threshold(self, compute_unit, backend, shape, threshold, minimum_deployment_target):
         model = torch.nn.Threshold(threshold[0], threshold[1]).eval()
         input_value = torch.rand(np.prod(shape))
         # make sure the values are not too close to the threshold
         for i in range(len(input_value)):
             if abs(input_value[i] - threshold[0]) < 0.005:
                 input_value[i] += 0.05
         input_value = torch.reshape(input_value, shape)
         self.run_compare_torch(
             input_value,
             model,
             backend=backend,
             compute_unit=compute_unit,
             input_as_shape=False,
+            minimum_deployment_target=minimum_deployment_target,
         )
 
     @pytest.mark.parametrize(
         "compute_unit, backend, shape, op_string",
         itertools.product(
             compute_units,
             backends,
@@ -5129,14 +5387,56 @@
             function=torch.split_with_sizes,
             kwargs={"split_sizes": split_sizes, "dim": dim},
         )
         self.run_compare_torch(
             input_shape, model, backend=backend, compute_unit=compute_unit
         )
 
+    @pytest.mark.parametrize(
+        "compute_unit, backend, dim",
+        itertools.product(compute_units, backends, [-1]),
+    )
+    def test_split_with_dynamic_sizes(self, compute_unit, backend, dim):
+        class TestModel(torch.nn.Module):
+            def forward(self, x):
+                size = x[0]
+                return torch.split(x, size, dim=dim)
+
+        input_shape = np.random.randint(low=2, high=6, size=20)
+        torch_in = torch.tensor(input_shape)
+        model = TestModel()
+        torch_out = model(torch_in)
+        self.run_compare_torch(
+            torch_in,
+            model,
+            expected_results=torch_out,
+            input_as_shape=False,
+            backend=backend,
+            compute_unit=compute_unit,
+        )
+
+        if backends[0] == "mlprogram":
+            with patch.object(Var, "_is_nonreplaceable_var") as mocked_is_nonreplaceable_var:
+                # Mock that shape op is non-replaceable, so the gather op will be kept.
+                mocked_is_nonreplaceable_var.side_effect = (
+                    lambda var: var.op and "shape" in var.op.op_type
+                )
+                with pytest.raises(
+                    RuntimeError,
+                    match="in operation of type split: Param 'split_sizes' must be const",
+                ):
+                    self.run_compare_torch(
+                        torch_in,
+                        model,
+                        expected_results=torch_out,
+                        input_as_shape=False,
+                        backend=backend,
+                        compute_unit=compute_unit,
+                    )
+
 
 class TestUnbind(TorchBaseTest):
     @pytest.mark.parametrize(
         "compute_unit, backend, dim",
         itertools.product(compute_units, backends, [0, 1, 2]),
     )
     def test_unbind(self, compute_unit, backend, dim):
@@ -5443,20 +5743,26 @@
     def test_repeats_with_symbolic_shape(self, compute_unit, backend):
         class Model(nn.Module):
             def forward(self, x, y):
                 return y.repeat([x.shape[-1], 1, x.shape[0]])
 
         module = Model()
         inputs = [torch.tensor([[1], [2]]), torch.tensor([2])]
+        upper_bound = 10 if backend[0] == "mlprogram" else -1
         self.run_compare_torch(
             inputs,
             module,
             input_as_shape=False,
             converter_input_type=[
-                ct.TensorType(shape=(ct.RangeDim(), ct.RangeDim())),
+                ct.TensorType(
+                    shape=(
+                        ct.RangeDim(upper_bound=upper_bound),
+                        ct.RangeDim(upper_bound=upper_bound),
+                    )
+                ),
                 ct.TensorType(shape=(1,)),
             ],
             backend=backend,
             compute_unit=compute_unit,
         )
 
 
@@ -5642,29 +5948,14 @@
             backend=backend,
             compute_unit=compute_unit
         )
         prog = mlmodel[1]._mil_program
         # The empty_like op is folded to const, so there is no fill nor fill_like op.
         assert len(prog.find_ops(op_type="fill")) + len(prog.find_ops(op_type="fill_like")) == 0
 
-        with patch.object(Var, '_is_nonreplaceable_var') as mocked_is_nonreplaceable_var:
-            # Mock that only shape op is not replaceable.
-            mocked_is_nonreplaceable_var.side_effect = (
-                lambda var: var.op and var.op.op_type == "shape"
-            )
-            mlmodel = self.run_compare_torch(
-                [(1, 2, 3)],
-                model,
-                backend=backend,
-                compute_unit=compute_unit
-            )
-            prog = mlmodel[1]._mil_program
-            # The shape op is not folded to const.
-            assert len(prog.find_ops(op_type="fill")) + len(prog.find_ops(op_type="fill_like")) == 1
-
     @pytest.mark.parametrize(
         "compute_unit, backend, rank",
         itertools.product(
             compute_units,
             backends,
             [1, 3],
         ),
@@ -5763,15 +6054,15 @@
             backends,
             [True, False],
             [True, False],
             [True, False],
             [((4, 6, 7, 3), -1, 2), ((10, 3, 4), 2, 2), ((5,), 0, 2)],
         ),
     )
-    def test_topk(self, compute_unit, backend, largest, sort, shape_dim_k, dynamic):
+    def test_topk(self, compute_unit, backend, largest, sort, dynamic, shape_dim_k):
         if not sort and backend[0] == "neuralnetwork":
             pytest.xfail("iOS16 version topk needed for sort = False")
         if not sort and _macos_version() < (13, 0):
             pytest.skip("New functionality in macOS13/iOS16")
 
         input_shape = shape_dim_k[0]
         dim = shape_dim_k[1]
@@ -5800,14 +6091,57 @@
             expected_results=expected_results,
             input_as_shape=False,
             backend=backend,
             compute_unit=compute_unit,
             minimum_deployment_target=ct.target.iOS16 if not sort else None,
         )
 
+    @pytest.mark.parametrize(
+        "compute_unit, backend, x_dtype",
+        itertools.product(
+            compute_units,
+            [("mlprogram", "fp16")],
+            [np.float32, np.float16, np.int32, np.int16, np.uint16],
+        ),
+    )
+    def test_topk_ios17(self, compute_unit, backend, x_dtype):
+        if x_dtype == np.float16:
+            pytest.skip("PyTorch doesn't support fp16 topk.")
+        if x_dtype == np.uint16:
+            pytest.skip("PyTorch doesn't have uint16 data type.")
+
+        x_torch_dtype = NUM_TO_TORCH_DTYPE[NUMPY_DTYPE_TO_TORCH_NUM[x_dtype]]
+
+        class TopkModel(nn.Module):
+            def forward(self, x, y):
+                topk = torch.topk(x.to(x_torch_dtype), k=2, dim=-1, largest=True, sorted=True)
+                return topk.values + y
+
+        input_data_x = torch.randint(low=0, high=100, size=(2, 3, 4))
+        input_data_y = torch.randint(low=0, high=100, size=(1,))
+
+        model = TopkModel()
+        expected_results = model(input_data_x, input_data_y)
+        mlmodel = self.run_compare_torch(
+            [input_data_x, input_data_y],
+            model,
+            expected_results=expected_results,
+            input_as_shape=False,
+            backend=backend,
+            compute_unit=compute_unit,
+            minimum_deployment_target=ct.target.iOS17,
+        )
+        prog = mlmodel[1]._mil_program
+        topk_op = prog.find_ops(op_type="topk", exactly_one=True)[0]
+        expected_topk_x_dtype = types.type_mapping.numpy_type_to_builtin_type(x_dtype)
+        if backend[1] == "fp16" and x_dtype == np.float32:
+            # For fp16 precision the fp32 input/output will be cast to fp16.
+            expected_topk_x_dtype = types.fp16
+        assert topk_op.x.dtype == expected_topk_x_dtype
+
 
 class TestLog10(TorchBaseTest):
     @pytest.mark.parametrize(
         "compute_unit, backend, rank",
         itertools.product(compute_units, backends, range(1, 6)),
     )
     def test_log10(self, compute_unit, backend, rank):
@@ -6423,15 +6757,24 @@
                 x[:2, 2:8:2, 1:2] = torch.tensor([1.0, 2.0, 3.0, 4.0, 5.0, 6.0]).view(2, 3, 1)
                 x[:, 1:10:8, 1:3] = torch.tensor([1.0, 2.0, 3.0, 4.0]).view(2, 1, 2)
                 return x
 
         shape = (2, 10, 3)
         model = TensorAssignModel()
         if dynamic:
-            converter_input_type = [ct.TensorType(shape=(ct.RangeDim(), ct.RangeDim(), ct.RangeDim()))]
+            upper_bound = 10 if backend[0] == "mlprogram" else -1
+            converter_input_type = [
+                ct.TensorType(
+                    shape=(
+                        ct.RangeDim(upper_bound=upper_bound),
+                        ct.RangeDim(upper_bound=upper_bound),
+                        ct.RangeDim(upper_bound=upper_bound),
+                    )
+                )
+            ]
         else:
             converter_input_type = None
         self.run_compare_torch(
             shape,
             model,
             converter_input_type=converter_input_type,
             backend=backend,
@@ -6453,16 +6796,23 @@
                 x[:1, begin_0:begin_0+5:2, 2] = torch.tensor([1.0, 2.0, 3.0]).view(1, 3)
                 x[:, 4, begin_1:end_1] = torch.tensor([1.0]).view(1, 1)
                 return x
 
         shape = (2, 10, 3)
         model = TensorAssignModel()
         if dynamic:
+            upper_bound = 10 if backend[0] == "mlprogram" else -1
             converter_input_type = [
-                ct.TensorType(shape=(ct.RangeDim(), ct.RangeDim(), ct.RangeDim())),
+                ct.TensorType(
+                    shape=(
+                        ct.RangeDim(upper_bound=upper_bound),
+                        ct.RangeDim(upper_bound=upper_bound),
+                        ct.RangeDim(upper_bound=upper_bound),
+                    )
+                ),
                 ct.TensorType(shape=(1,), dtype=np.int32),
                 ct.TensorType(shape=(1,), dtype=np.int32),
                 ct.TensorType(shape=(1,), dtype=np.int32),
             ]
         else:
             converter_input_type = None
 
@@ -6502,64 +6852,71 @@
         shape = (2, 3)
         model = TensorAssignModel()
         self.run_compare_torch(shape, model, backend=backend, compute_unit=compute_unit)
 
 
 class TestIndexPut(TorchBaseTest):
     @pytest.mark.parametrize(
-        "compute_unit, backend",
+        "compute_unit, backend, minimum_deployment_target",
         itertools.product(
             compute_units,
             backends,
+            [None, ct.target.iOS17],
         ),
     )
-    def test_index_put_case_1(self, compute_unit, backend):
+    def test_index_put_case_1(self, compute_unit, backend, minimum_deployment_target):
         class IndexPutModel(torch.nn.Module):
             def forward(self, x, y):
                 y = x + 1
                 mask = torch.tensor([True, False, False, False, True, True]).view(3, 2)
                 x[mask] = y[mask]
                 return x
 
         shape = (3, 2)
-        model = IndexPutModel()
         self.run_compare_torch(
-            [shape, shape], model, backend=backend, compute_unit=compute_unit
+            [shape, shape],
+            IndexPutModel(),
+            backend=backend,
+            compute_unit=compute_unit,
+            minimum_deployment_target=minimum_deployment_target,
         )
 
     @pytest.mark.parametrize(
-        "compute_unit, backend, rank",
+        "compute_unit, backend, rank, minimum_deployment_target",
         itertools.product(
             compute_units,
             backends,
             [0, 1],
+            [None, ct.target.iOS17],
         ),
     )
-    def test_index_put_case_2(self, compute_unit, backend, rank):
+    def test_index_put_case_2(self, compute_unit, backend, rank, minimum_deployment_target):
         class IndexPutModel(torch.nn.Module):
             def forward(self, x):
                 mask = torch.tensor([True, False, False, False, True, True]).view(3, 2)
                 if rank == 0:
                     x[mask] = 0.0
                 if rank == 1:
                     x[mask] = torch.tensor([1.0])
                 return x
 
         shape = (3, 2)
         model = IndexPutModel()
-        self.run_compare_torch(shape, model, backend=backend, compute_unit=compute_unit)
+        self.run_compare_torch(shape, model, backend=backend, compute_unit=compute_unit,
+                               minimum_deployment_target=minimum_deployment_target)
 
     @pytest.mark.parametrize(
-        "compute_unit, backend",
+        "compute_unit, backend, minimum_deployment_target",
         itertools.product(
             compute_units,
             backends,
+            [None, ct.target.iOS17],
         ),
     )
-    def test_index_put_case_3(self, compute_unit, backend):
+    def test_index_put_case_3(self, compute_unit, backend, minimum_deployment_target):
         if _macos_version() < (13, 0):
             pytest.skip("Issue fixed in iOS16/macOS13")
 
         class IndexPutModel(torch.nn.Module):
             def forward(self, x, y):
                 mask = y > 1
                 x[y > 1] = 0.0
@@ -6572,21 +6929,22 @@
         model = IndexPutModel()
         self.run_compare_torch(
             inputs,
             model,
             backend=backend,
             compute_unit=compute_unit,
             input_as_shape=False,
+            minimum_deployment_target=minimum_deployment_target,
         )
 
     @pytest.mark.parametrize(
-        "compute_unit, backend, rank, accumulate",
-        itertools.product(compute_units, backends, [1, 2], [True, False]),
+        "compute_unit, backend, rank, accumulate, minimum_deployment_target",
+        itertools.product(compute_units, backends, [3], [True, False], [None, ct.target.iOS17]),
     )
-    def test_index_put_case_4(self, compute_unit, backend, rank, accumulate):
+    def test_index_put_case_4(self, compute_unit, backend, rank, accumulate, minimum_deployment_target):
         class IndexPutModel(torch.nn.Module):
             def forward(self, x, indices, values):
                 x.index_put_(tuple(indices.t()), values, accumulate=accumulate)
                 return x
 
         if rank == 1:
             inputs = [
@@ -6596,38 +6954,113 @@
             ]
         elif rank == 2:
             inputs = [
                 torch.ones([3, 4]),
                 torch.LongTensor([[0, 1], [1, 2], [2, 2]]),
                 torch.Tensor([1.0, 5.0, 8.0]),
             ]
+        elif rank == 3:
+            inputs = [
+                torch.ones([2, 3, 4]),
+                torch.LongTensor([[0, 1], [1, 1], [0, 0]]),
+                torch.tensor([[1.0, 2.0, 3.0, 4.0], [5.0, 6.0, 7.0, 8.0], [9.0, 6.0, 2.0, 1.0]]),
+            ]
+
+        model = IndexPutModel()
+        self.run_compare_torch(
+            inputs,
+            model,
+            backend=backend,
+            compute_unit=compute_unit,
+            input_as_shape=False,
+            minimum_deployment_target=minimum_deployment_target,
+        )
+
+    @pytest.mark.parametrize(
+        "compute_unit, backend, accumulate, minimum_deployment_target",
+        itertools.product(compute_units, backends, [True, False], [None, ct.target.iOS17]),
+    )
+    def test_index_put_negative_indices_case_1(
+        self, compute_unit, backend, accumulate, minimum_deployment_target
+    ):
+        class IndexPutModel(torch.nn.Module):
+            def forward(self, x):
+                x.index_put_(
+                    indices=(torch.LongTensor([0, -1]), torch.LongTensor([-2, 1])),
+                    values=torch.Tensor([1.0, 5.0]),
+                    accumulate=accumulate,
+                )
+                return x
+
+        self.run_compare_torch(
+            (3, 4),
+            IndexPutModel(),
+            backend=backend,
+            compute_unit=compute_unit,
+            minimum_deployment_target=minimum_deployment_target,
+        )
+
+    @pytest.mark.parametrize(
+        "compute_unit, backend, rank, accumulate, minimum_deployment_target",
+        itertools.product(
+            compute_units, backends, [1, 2, 3], [True, False], [None, ct.target.iOS17]
+        ),
+    )
+    def test_index_put_negative_indices_case_2(
+        self, compute_unit, backend, rank, accumulate, minimum_deployment_target
+    ):
+        class IndexPutModel(torch.nn.Module):
+            def forward(self, x, indices, values):
+                x.index_put_(tuple(indices.t()), values, accumulate=accumulate)
+                return x
+
+        if rank == 1:
+            inputs = [
+                torch.Tensor([1.0, 2.0, 3.0, 4.0, 5.0, 6]),
+                torch.LongTensor([[-1], [-4]]),
+                torch.Tensor([3.0, 7.0]),
+            ]
+        elif rank == 2:
+            inputs = [
+                torch.ones([3, 4]),
+                torch.LongTensor([[-2, -1], [-2, 0], [-1, 1]]),
+                torch.Tensor([1.0, 5.0, 8.0]),
+            ]
+        elif rank == 3:
+            inputs = [
+                torch.ones([2, 3, 4]),
+                torch.LongTensor([[-1, -1], [-2, 0], [0, 1]]),
+                torch.tensor([[1.0, 2.0, 3.0, 4.0], [5.0, 6.0, 7.0, 8.0], [9.0, 6.0, 2.0, 1.0]]),
+            ]
 
         model = IndexPutModel()
         self.run_compare_torch(
             inputs,
             model,
             backend=backend,
             compute_unit=compute_unit,
             input_as_shape=False,
+            minimum_deployment_target=minimum_deployment_target,
         )
 
 
 class TestIndex(TorchBaseTest):
     @pytest.mark.parametrize(
-        "compute_unit, backend, shape",
+        "compute_unit, backend, shape, minimum_deployment_target",
         itertools.product(
             compute_units,
             backends,
             [
                 (10,),
                 (3, 4, 5, 6),
             ],
+            [None, ct.target.iOS17],
         ),
     )
-    def test_index_bool_indices(self, compute_unit, backend, shape):
+    def test_index_bool_indices(self, compute_unit, backend, shape, minimum_deployment_target):
         rank = len(shape)
         class IndexModel(torch.nn.Module):
             def __init__(self, axis):
                 super().__init__()
                 self.axis = axis
 
             def forward(self, x, y):
@@ -6654,271 +7087,336 @@
                 model = IndexModel(axis=axis)
                 self.run_compare_torch(
                     [input_data, ref_data],
                     model,
                     backend=backend,
                     compute_unit=compute_unit,
                     input_as_shape=False,
+                    minimum_deployment_target=minimum_deployment_target,
                 )
 
     @pytest.mark.parametrize(
-        "compute_unit, backend, shape",
+        "compute_unit, backend, shape, minimum_deployment_target",
         itertools.product(
             compute_units,
             backends,
             [
                 (1, 2),
                 (3, 4, 5, 6),
             ],
+            [None, ct.target.iOS17],
         ),
     )
-    def test_index_int_index_case_1(self, compute_unit, backend, shape):
+    def test_index_int_index_case_1(self, compute_unit, backend, shape, minimum_deployment_target):
         # all elements are selected
         class IndexModel(torch.nn.Module):
             def forward(self, x):
                 if len(shape) == 2:
                     return x[:, :]
                 elif len(shape) == 4:
                     return x[:]
 
         model = IndexModel()
-        self.run_compare_torch(shape, model, backend=backend, compute_unit=compute_unit)
+        self.run_compare_torch(
+            shape,
+            model,
+            backend=backend,
+            compute_unit=compute_unit,
+            minimum_deployment_target=minimum_deployment_target,
+        )
 
     @pytest.mark.parametrize(
-        "compute_unit, backend, shape",
+        "compute_unit, backend, shape, minimum_deployment_target",
         itertools.product(
             compute_units,
             backends,
             [
                 (1, 2),
                 (3, 4, 5, 6),
             ],
+            [None, ct.target.iOS17],
         ),
     )
-    def test_index_int_index_case_2(self, compute_unit, backend, shape):
-        # only one axis is sliced
+    def test_index_int_index_case_2(self, compute_unit, backend, shape, minimum_deployment_target):
+        """Only one axis is sliced."""
         class IndexModel(torch.nn.Module):
             def forward(self, x):
                 if len(shape) == 2:
                     index = torch.tensor([0])
                     return x[index, :]
                 elif len(shape) == 4:
-                    index = torch.tensor([1, 2])
+                    index = torch.tensor([1, -2])
                     return x[:, :, index]
 
         model = IndexModel()
-        self.run_compare_torch(shape, model, backend=backend, compute_unit=compute_unit)
+        self.run_compare_torch(
+            shape,
+            model,
+            backend=backend,
+            compute_unit=compute_unit,
+            minimum_deployment_target=minimum_deployment_target,
+        )
 
     @pytest.mark.parametrize(
-        "compute_unit, backend, shape",
+        "compute_unit, backend, shape, minimum_deployment_target",
         itertools.product(
             compute_units,
             backends,
             [
                 (1, 2, 3),
                 (2, 3, 4, 5),
             ],
+            [None, ct.target.iOS17],
         ),
     )
-    def test_index_int_index_case_3(self, compute_unit, backend, shape):
-        # only two axes are sliced, and connected
+    def test_index_int_index_case_3(self, compute_unit, backend, shape, minimum_deployment_target):
+        """Only two axes are sliced, and connected."""
         class IndexModel(torch.nn.Module):
             def forward(self, x):
                 if len(shape) == 3:
                     index_1 = torch.tensor([0])
                     index_2 = torch.tensor([1])
                     return x[index_1, index_2, :]
 
                 elif len(shape) == 4:
                     index_1 = torch.tensor([0, 1, 1])
                     index_2 = torch.tensor([2, 1, 0])
                     return x[:, index_1, index_2, :]
 
         model = IndexModel()
-        self.run_compare_torch(shape, model, backend=backend, compute_unit=compute_unit)
+        self.run_compare_torch(
+            shape,
+            model,
+            backend=backend,
+            compute_unit=compute_unit,
+            minimum_deployment_target=minimum_deployment_target,
+        )
 
     @pytest.mark.parametrize(
-        "compute_unit, backend, shape",
+        "compute_unit, backend, shape, minimum_deployment_target",
         itertools.product(
             compute_units,
             backends,
             [
                 (1, 2, 3),
                 (2, 3, 4, 5),
             ],
+            [None, ct.target.iOS17],
         ),
     )
-    def test_index_int_index_case_4(self, compute_unit, backend, shape):
-        # only two axes are sliced, and not connected
+    def test_index_int_index_case_4(self, compute_unit, backend, shape, minimum_deployment_target):
+        """Only two axes are sliced, and not connected."""
         class IndexModel(torch.nn.Module):
             def forward(self, x):
                 if len(shape) == 3:
                     index_1 = torch.tensor([0])
                     index_2 = torch.tensor([1])
                     return x[index_1, :, index_2]
 
                 elif len(shape) == 4:
                     index_1 = torch.tensor([0, 1, 1])
                     index_2 = torch.tensor([3, 3, 4])
                     return x[index_1, :, :, index_2]
 
         model = IndexModel()
-        self.run_compare_torch(shape, model, backend=backend, compute_unit=compute_unit)
+        self.run_compare_torch(
+            shape,
+            model,
+            backend=backend,
+            compute_unit=compute_unit,
+            minimum_deployment_target=minimum_deployment_target,
+        )
 
     @pytest.mark.parametrize(
-        "compute_unit, backend, shape",
+        "compute_unit, backend, shape, minimum_deployment_target",
         itertools.product(
             compute_units,
             backends,
             [
                 (1, 2, 3),
                 (2, 3, 4, 5),
             ],
+            [None, ct.target.iOS17],
         ),
     )
-    def test_index_int_index_case_5(self, compute_unit, backend, shape):
-        # all axes are sliced
+    def test_index_int_index_case_5(self, compute_unit, backend, shape, minimum_deployment_target):
+        """All axes are sliced."""
         class IndexModel(torch.nn.Module):
             def forward(self, x):
                 if len(shape) == 3:
                     index_1 = torch.tensor([0])
                     index_2 = torch.tensor([1])
-                    index_3 = torch.tensor([2])
+                    index_3 = torch.tensor([-1])  # Test negative indices.
                     return x[index_1, index_2, index_3]
 
                 elif len(shape) == 4:
                     index_1 = torch.tensor([0, 1, 1, 0, 0])
                     index_2 = torch.tensor([1, 2, 0, 0, 0])
-                    index_3 = torch.tensor([0, 1, 2, 3, 3])
+                    index_3 = torch.tensor([0, 1, -2, 3, 3])  # Test negative indices.
                     index_4 = torch.tensor([2, 1, 0, 4, 4])
                     return x[index_1, index_2, index_3, index_4]
 
         model = IndexModel()
-        self.run_compare_torch(shape, model, backend=backend, compute_unit=compute_unit)
+        self.run_compare_torch(
+            shape,
+            model,
+            backend=backend,
+            compute_unit=compute_unit,
+            minimum_deployment_target=minimum_deployment_target,
+        )
 
     @pytest.mark.parametrize(
-        "compute_unit, backend, shape",
+        "compute_unit, backend, shape, minimum_deployment_target",
         itertools.product(
             compute_units,
             backends,
             [
                 (1, 2),
                 (3, 4, 5, 6),
             ],
+            [None, ct.target.iOS17],
         ),
     )
-    def test_index_int_index_case_6(self, compute_unit, backend, shape):
-        # only one axis is sliced + nd mode
+    def test_index_int_index_case_6(self, compute_unit, backend, shape, minimum_deployment_target):
+        """Only one axis is sliced + nd mode."""
         class IndexModel(torch.nn.Module):
             def forward(self, x):
                 if len(shape) == 2:
                     index = torch.tensor([0, 0, 0, 0, 0, 0])
                     index = index.view(2, 3)
                     return x[index, :]
                 elif len(shape) == 4:
                     index = torch.tensor([0, 1, 2, 3, 0, 1])
                     index = index.view(3, 2)
                     return x[:, index]
 
         model = IndexModel()
-        self.run_compare_torch(shape, model, backend=backend, compute_unit=compute_unit)
+        self.run_compare_torch(
+            shape,
+            model,
+            backend=backend,
+            compute_unit=compute_unit,
+            minimum_deployment_target=minimum_deployment_target,
+        )
 
     @pytest.mark.parametrize(
-        "compute_unit, backend, shape",
+        "compute_unit, backend, shape, minimum_deployment_target",
         itertools.product(
             compute_units,
             backends,
             [
                 (1, 2, 3),
                 (2, 3, 4, 5),
             ],
+            [None, ct.target.iOS17],
         ),
     )
-    def test_index_int_index_case_7(self, compute_unit, backend, shape):
-        # two axes are sliced, and connected + nd mode
+    def test_index_int_index_case_7(self, compute_unit, backend, shape, minimum_deployment_target):
+        """Two axes are sliced, and connected + nd mode."""
         class IndexModel(torch.nn.Module):
             def forward(self, x):
                 if len(shape) == 3:
                     index_1 = torch.tensor([0, 0, 0, 0, 0, 0, 0, 0]).view(4, 2)
                     index_2 = torch.tensor([1, 0, 0, 0, 1, 1, 1, 1]).view(4, 2)
                     return x[index_1, index_2, :]
 
                 elif len(shape) == 4:
                     index_1 = torch.tensor([0, 0, 2, 2, 1, 1, 2, 0]).view(2, 4)
                     index_2 = torch.tensor([0, 1, 2, 3, 0, 1, 2, 3]).view(2, 4)
                     return x[:, index_1, index_2, :]
 
         model = IndexModel()
-        self.run_compare_torch(shape, model, backend=backend, compute_unit=compute_unit)
+        self.run_compare_torch(
+            shape,
+            model,
+            backend=backend,
+            compute_unit=compute_unit,
+            minimum_deployment_target=minimum_deployment_target,
+        )
 
     @pytest.mark.parametrize(
-        "compute_unit, backend, shape",
+        "compute_unit, backend, shape, minimum_deployment_target",
         itertools.product(
             compute_units,
             backends,
             [
                 (1, 2, 3),
                 (2, 3, 4, 5),
             ],
+            [None, ct.target.iOS17],
         ),
     )
-    def test_index_int_index_case_8(self, compute_unit, backend, shape):
-        # two axes are sliced, and not connected + nd mode
+    def test_index_int_index_case_8(self, compute_unit, backend, shape, minimum_deployment_target):
+        """Two axes are sliced, and not connected + nd mode."""
         class IndexModel(torch.nn.Module):
             def forward(self, x):
                 if len(shape) == 3:
                     index_1 = torch.tensor([0, 0, 0, 0, 0, 0, 0, 0]).view(2, 4)
                     index_2 = torch.tensor([1, 0, 0, 2, 2, 1, 1, 1]).view(2, 4)
                     return x[index_1, :, index_2]
 
                 elif len(shape) == 4:
                     index_1 = torch.tensor([0, 1, 1, 1, 1, 1, 0, 0]).view(4, 2)
                     index_2 = torch.tensor([0, 1, 2, 3, 4, 0, 1, 2]).view(4, 2)
                     return x[index_1, :, :, index_2]
 
         model = IndexModel()
-        self.run_compare_torch(shape, model, backend=backend, compute_unit=compute_unit)
+        self.run_compare_torch(
+            shape,
+            model,
+            backend=backend,
+            compute_unit=compute_unit,
+            minimum_deployment_target=minimum_deployment_target,
+        )
 
     @pytest.mark.parametrize(
-        "compute_unit, backend, shape",
+        "compute_unit, backend, shape, minimum_deployment_target",
         itertools.product(
             compute_units,
             backends,
             [
                 (1, 2, 3),
                 (2, 3, 4, 5),
             ],
+            [None, ct.target.iOS17],
         ),
     )
-    def test_index_int_index_case_9(self, compute_unit, backend, shape):
-        # one axis is sliced through bool mask
+    def test_index_int_index_case_9(self, compute_unit, backend, shape, minimum_deployment_target):
+        """One axis is sliced through bool mask."""
         class IndexModel(torch.nn.Module):
             def forward(self, x):
                 if len(shape) == 3:
                     return x[:, [True, False], :]
 
                 elif len(shape) == 4:
                     return x[[True, False], :, :, :]
 
         model = IndexModel()
-        self.run_compare_torch(shape, model, backend=backend, compute_unit=compute_unit)
+        self.run_compare_torch(
+            shape,
+            model,
+            backend=backend,
+            compute_unit=compute_unit,
+            minimum_deployment_target=minimum_deployment_target,
+        )
 
     @pytest.mark.parametrize(
-        "compute_unit, backend, shape",
+        "compute_unit, backend, shape, minimum_deployment_target",
         itertools.product(
             compute_units,
             backends,
             [
                 (1, 2, 3),
                 (2, 3, 4, 5),
             ],
+            [None, ct.target.iOS17],
         ),
     )
-    def test_index_int_index_case_10(self, compute_unit, backend, shape):
-        # multiple axes are sliced through bool masks with possible broadcasting
+    def test_index_int_index_case_10(self, compute_unit, backend, shape, minimum_deployment_target):
+        """Multiple axes are sliced through bool masks with possible broadcasting."""
         class IndexModel(torch.nn.Module):
             def forward(self, x):
                 if len(shape) == 3:
                     return x[[True], [True, False], [False, True, False]]
 
                 else:
                     assert len(shape) == 4
@@ -6935,72 +7433,144 @@
                         :,
                         [False, False, True, False],
                         [True, False, False, True, False],
                     ]
                     return output_1, output_2
 
         model = IndexModel()
-        self.run_compare_torch(shape, model, backend=backend, compute_unit=compute_unit)
+        self.run_compare_torch(
+            shape,
+            model,
+            backend=backend,
+            compute_unit=compute_unit,
+            minimum_deployment_target=minimum_deployment_target,
+        )
 
     @pytest.mark.parametrize(
-        "compute_unit, backend, shape",
+        "compute_unit, backend, shape, minimum_deployment_target",
         itertools.product(
             compute_units,
             backends,
             [
                 (3, 4),
                 (3, 4, 5, 6)
             ],
+            [None, ct.target.iOS17],
         ),
     )
-    def test_index_int_index_case_11(self, compute_unit, backend, shape):
-        # broadcasable indices
+    def test_index_int_index_case_11(self, compute_unit, backend, shape, minimum_deployment_target):
+        """Broadcastable indices."""
         class IndexModel(torch.nn.Module):
             def forward(self, x):
                 if len(shape) == 2:
                     index_1 = torch.tensor([0, 1])
                     index_2 = torch.tensor([0])
                     return x[index_1, index_2]
                 else:
                     assert len(shape) == 4
                     index_1 = torch.tensor([0, 1, 1, 1, 1, 1, 0, 0]).view(4, 2)
                     index_2 = torch.tensor([0, 1, 2, 3]).view(4, 1)
                     index_3 = torch.tensor([2]).view(1,)
                     return x[index_1, :, index_3, index_2]
 
         model = IndexModel()
-        self.run_compare_torch(shape, model, backend=backend, compute_unit=compute_unit)
+        self.run_compare_torch(
+            shape,
+            model,
+            backend=backend,
+            compute_unit=compute_unit,
+            minimum_deployment_target=minimum_deployment_target,
+        )
 
     @pytest.mark.parametrize(
-        "compute_unit, backend, shape",
+        "compute_unit, backend, shape, minimum_deployment_target",
         itertools.product(
             compute_units,
             backends,
             [
                 (1, 2, 3),
                 (2, 3, 4, 5),
             ],
+            [None, ct.target.iOS17],
         ),
     )
-    def test_index_int_index_case_12(self, compute_unit, backend, shape):
-        # Another broadcastable indices test case
+    def test_index_int_index_case_12(self, compute_unit, backend, shape, minimum_deployment_target):
+        """Another broadcastable indices test case."""
         class IndexModel(torch.nn.Module):
             def forward(self, x):
                 index_1 = torch.tensor([0, 1])
                 index_2 = torch.tensor([0])
                 return (
                     x[:, index_1, index_2]
                     if len(shape) == 3
                     else x[:, index_1, index_2, :]
                 )
 
         self.run_compare_torch(
-            shape, IndexModel(), backend=backend, compute_unit=compute_unit
+            shape,
+            IndexModel(),
+            backend=backend,
+            compute_unit=compute_unit,
+            minimum_deployment_target=minimum_deployment_target,
         )
 
+    @pytest.mark.parametrize(
+        "compute_unit, backend, shape, minimum_deployment_target",
+        itertools.product(
+            compute_units,
+            backends,
+            [
+                (1, 2, 3),
+                (2, 3, 4, 5),
+            ],
+            [None, ct.target.iOS17],
+        ),
+    )
+    def test_index_int_index_case_13(self, compute_unit, backend, shape, minimum_deployment_target):
+        """Another broadcastable indices (negative) test case."""
+
+        class IndexModel(torch.nn.Module):
+            def forward(self, x):
+                index_1 = torch.tensor([-1, 1])
+                index_2 = torch.tensor([-1])
+                return x[:, index_1, index_2] if len(shape) == 3 else x[:, index_1, index_2, :]
+
+        self.run_compare_torch(
+            shape,
+            IndexModel(),
+            backend=backend,
+            compute_unit=compute_unit,
+            minimum_deployment_target=minimum_deployment_target,
+        )
+
+
+class TestIndexSelect(TorchBaseTest):
+    @pytest.mark.parametrize(
+        "compute_unit, backend, dim",
+        itertools.product(compute_units, backends, [0, -1]),
+    )
+    def test_index_select(self, compute_unit, backend, dim):
+        class TestModel(torch.nn.Module):
+            def forward(self, x):
+                indices = torch.tensor([0, 2])
+                return torch.index_select(x, dim, indices)
+
+        self.run_compare_torch((3, 4), TestModel(), backend=backend, compute_unit=compute_unit)
+
+    def test_index_select_invalid_indices(self):
+        """This test is to verify that PyTorch index_select op doesn't allow negative nor
+        out-of-range indices, so we don't need to add mb.select for IOS17 mb.gather when lowering
+        PyTorch index_select op."""
+        x = torch.randn(3, 4)
+        with pytest.raises(IndexError, match="index out of range"):
+            torch.index_select(x, 0, torch.tensor([0, -1]))
+        with pytest.raises(IndexError, match="index out of range"):
+            torch.index_select(x, 0, torch.tensor([0, 3]))
+
+
 class TestLoss(TorchBaseTest):
     @pytest.mark.parametrize(
         "compute_unit, backend, rank, reduction",
         itertools.product(
             compute_units, backends, range(1, 4), ["none", "mean", "sum"]
         ),
     )
@@ -7106,14 +7676,34 @@
         input_shape = (3, 4, 5, 6, 2)
         model = torch.nn.ConstantPad3d((5, 6, 3, 8, 2, 4), 3.5).eval()
         self.run_compare_torch(
             input_shape, model, backend=backend, compute_unit=compute_unit
         )
 
 
+class TestMaskedFill(TorchBaseTest):
+    @pytest.mark.parametrize(
+        "compute_unit, backend",
+        itertools.product(compute_units, backends),
+    )
+    def test_masked_fill(self, compute_unit, backend):
+        SHAPE = (2, 3)
+        MASK = torch.bernoulli(torch.rand(SHAPE[-1])).to(torch.bool)
+        VALUE = 10.0
+
+        model = ModuleWrapper(torch.masked_fill, {"mask": MASK, "value": VALUE})
+
+        TorchBaseTest.run_compare_torch(
+            SHAPE,
+            model,
+            backend=backend,
+            compute_unit=compute_unit,
+        )
+
+
 class TestMeshgrid(TorchBaseTest):
     @pytest.mark.parametrize(
         "compute_unit, backend, x, y, z, dtype, inp_mode, indexing",
         itertools.product(
             compute_units,
             backends,
             [1, 2],
@@ -7159,133 +7749,182 @@
             backend=backend,
             compute_unit=compute_unit,
         )
 
 
 class TestScatter(TorchBaseTest):
     @pytest.mark.parametrize(
-        "compute_unit, backend, shapes_dims",
+        "compute_unit, backend, shapes_dims, minimum_deployment_target",
         itertools.product(
             compute_units,
             backends,
             [
                 [(10,), (0, -1)],
                 [(2, 3), (1, -1)],
                 [(2, 3, 4, 5), (0, -2)],
             ],
+            [None, ct.target.iOS17],
         ),
     )
-    def test_scatter(self, compute_unit, backend, shapes_dims):
+    def test_scatter(self, compute_unit, backend, shapes_dims, minimum_deployment_target):
         class TestModel(nn.Module):
             def __init__(self, dim, shapes):
                 super(TestModel, self).__init__()
                 self.dim = dim
                 self.source = torch.rand(*(shapes))
                 self.index = torch.randint(0, shapes[dim], size=shapes)
 
             def forward(self, x):
                 return x.scatter_(self.dim, self.index, self.source)
 
         shapes, dims = shapes_dims
         for dim in dims:
-            m = TestModel(0, shapes)
+            m = TestModel(dim, shapes)
             self.run_compare_torch(
-                shapes, m, backend=backend, compute_unit=compute_unit
+                shapes, m, backend=backend, compute_unit=compute_unit,
+                minimum_deployment_target=minimum_deployment_target,
             )
 
     @pytest.mark.parametrize(
-        "compute_unit, backend, shapes_dims",
+        "compute_unit, backend, shapes_dims, minimum_deployment_target",
         itertools.product(
             compute_units,
             backends,
             [
                 [(10,), (0, -1)],
                 [(2, 3), (1, -1)],
                 [(2, 3, 4, 5), (0, -2)],
             ],
+            [None, ct.target.iOS17],
         ),
     )
-    def test_scatter_with_scalar_source(self, compute_unit, backend, shapes_dims):
+    def test_scatter_with_scalar_source(self, compute_unit, backend, shapes_dims, minimum_deployment_target):
         class TestModel(nn.Module):
             def __init__(self, dim, shapes):
                 super(TestModel, self).__init__()
                 self.dim = dim
                 self.source = 1.0
                 self.index = torch.randint(0, shapes[dim], size=shapes)
 
             def forward(self, x):
                 return x.scatter_(self.dim, self.index, self.source)
 
         shapes, dims = shapes_dims
         for dim in dims:
-            m = TestModel(0, shapes)
+            m = TestModel(dim, shapes)
             self.run_compare_torch(
-                shapes, m, backend=backend, compute_unit=compute_unit
+                shapes, m, backend=backend, compute_unit=compute_unit,
+                minimum_deployment_target=minimum_deployment_target,
             )
 
     @pytest.mark.parametrize(
-        "compute_unit, backend, shapes_dims, mode",
+        "compute_unit, backend, shapes_dims, mode, minimum_deployment_target",
         itertools.product(
             compute_units,
             backends,
             [
                 [(10,), (0, -1)],
                 [(2, 3), (1, -1)],
                 [(2, 3, 4, 5), (0, -2)],
             ],
             ["add", "multiply"],
+            [None, ct.target.iOS17],
         ),
     )
-    def test_scatter_with_reduce(self, compute_unit, backend, shapes_dims, mode):
+    def test_scatter_with_reduce(self, compute_unit, backend, shapes_dims, mode, minimum_deployment_target):
         class TestModel(nn.Module):
             def __init__(self, dim, shapes, mode):
                 super(TestModel, self).__init__()
                 self.dim = dim
                 self.mode = mode
                 self.source = torch.rand(*(shapes))
                 self.index = torch.randint(0, shapes[dim], size=shapes)
 
             def forward(self, x):
                 return x.scatter_(self.dim, self.index, self.source, reduce=self.mode)
 
         shapes, dims = shapes_dims
         for dim in dims:
-            m = TestModel(0, shapes, mode)
+            m = TestModel(dim, shapes, mode)
             self.run_compare_torch(
-                shapes, m, backend=backend, compute_unit=compute_unit
+                shapes, m, backend=backend, compute_unit=compute_unit,
+                minimum_deployment_target=minimum_deployment_target,
             )
 
     @pytest.mark.parametrize(
-        "compute_unit, backend, shapes_dims",
+        "compute_unit, backend, shapes_dims, minimum_deployment_target",
         itertools.product(
             compute_units,
             backends,
             [
                 [(10,), (0, -1)],
                 [(2, 3), (1, -1)],
                 [(2, 3, 4, 5), (0, -2)],
             ],
+            [None, ct.target.iOS17],
         ),
     )
-    def test_scatter_add(self, compute_unit, backend, shapes_dims):
+    def test_scatter_add(self, compute_unit, backend, shapes_dims, minimum_deployment_target):
         class TestModel(nn.Module):
             def __init__(self, dim, shapes):
                 super(TestModel, self).__init__()
                 self.dim = dim
                 self.source = torch.rand(*(shapes))
                 self.index = torch.randint(0, shapes[dim], size=shapes)
 
             def forward(self, x):
                 return x.scatter_add_(self.dim, self.index, self.source)
 
         shapes, dims = shapes_dims
         for dim in dims:
             m = TestModel(dim, shapes)
             self.run_compare_torch(
-                shapes, m, backend=backend, compute_unit=compute_unit
+                shapes, m, backend=backend, compute_unit=compute_unit,
+                minimum_deployment_target=minimum_deployment_target,
+            )
+
+    @pytest.mark.parametrize(
+        "compute_unit, backend",
+        itertools.product(
+            compute_units,
+            [("mlprogram", "fp16")],
+        ),
+    )
+    def test_scatter_with_invalid_indices(self, compute_unit, backend):
+        """
+        As PyTorch's `scatter_` and `scatter_add_` do verify indices and error out for negative
+        and out-of-bound indices, it doesn't involve the PyMIL validation.
+        """
+
+        class ScatterModel(nn.Module):
+            def forward(self, x):
+                index = torch.tensor([[-1, 1, 2, 0]])
+                return torch.zeros(1, 4, dtype=x.dtype).scatter_(1, index, x)
+
+        class ScatterAddModel(nn.Module):
+            def forward(self, x):
+                index = torch.tensor([[0, 5, 2, 0]])
+                return torch.zeros(1, 4, dtype=x.dtype).scatter_add_(1, index, x)
+
+        with pytest.raises(RuntimeError, match="index -1 is out of bounds for dimension 1"):
+            self.run_compare_torch(
+                (1, 4),
+                ScatterModel(),
+                backend=backend,
+                compute_unit=compute_unit,
+                minimum_deployment_target=ct.target.iOS17,
+            )
+
+        with pytest.raises(RuntimeError, match="index 5 is out of bounds for dimension 1"):
+            self.run_compare_torch(
+                (1, 4),
+                ScatterAddModel(),
+                backend=backend,
+                compute_unit=compute_unit,
+                minimum_deployment_target=ct.target.iOS17,
             )
 
 
 class TestBroadcastTensors(TorchBaseTest):
     @pytest.mark.parametrize(
         "compute_unit, backend, shapes",
         itertools.product(
@@ -7384,14 +8023,23 @@
             expected_results=expected_results,
             input_as_shape=False,
             backend=backend,
             compute_unit=compute_unit,
             converter_input_type=converter_input_type,
         )
 
+    def test_embedding_invalid_indices(self):
+        """This test is to verify that PyTorch embedding op doesn't allow negative and out-of-range
+        indices, so we don't need to add mb.select for IOS17 mb.gather op."""
+        embedding_matrix = torch.rand(10, 3)
+        with pytest.raises(IndexError, match="index out of range"):
+            torch.nn.functional.embedding(torch.tensor([[-1, 2], [4, 3]]), embedding_matrix)
+        with pytest.raises(IndexError, match="index out of range"):
+            torch.nn.functional.embedding(torch.tensor([[1, 2], [4, 10]]), embedding_matrix)
+
 
 class TestDuplicateOutputTensors(TorchBaseTest):
     @pytest.mark.parametrize(
         "compute_unit, backend, input_dtype",
         itertools.product(
             compute_units,
             backends,
@@ -7873,14 +8521,34 @@
         with pytest.raises(
             ValueError, match="MIL doesn't support complex data as model's output"
         ):
             TorchBaseTest.run_compare_torch(
                 (2, 3, 4), ComplexModel(), backend=backend, compute_unit=compute_unit
             )
 
+    @pytest.mark.parametrize(
+        "compute_unit, backend",
+        itertools.product(
+            compute_units,
+            backends,
+        )
+    )
+    def test_abs(self, compute_unit, backend):
+        class AbsModel(torch.nn.Module):
+            def forward(self, x):
+                x = torch.complex(x, x)
+                return torch.abs(x)
+
+        TorchBaseTest.run_compare_torch(
+            (1, 16),
+            AbsModel(),
+            backend=backend,
+            compute_unit=compute_unit,
+        )
+
 
 class TestReal(TorchBaseTest):
     @pytest.mark.parametrize(
         "compute_unit, backend",
         itertools.product(
             compute_units,
             backends,
@@ -8095,33 +8763,123 @@
                 x = torch.complex(x, x)
                 return torch.fft.irfftn(x, s=x.shape[-3:], dim=(-3, -2, -1))
 
         TorchBaseTest.run_compare_torch(
             (2, 3, 4), FftnModel(), backend=backend, compute_unit=compute_unit
         )
 
+class TestSTFT(TorchBaseTest):
+    @pytest.mark.slow
+    @pytest.mark.parametrize(
+        "compute_unit, backend, input_shape, complex, n_fft, hop_length, win_length, window, center, pad_mode, normalized, onesided",
+        itertools.product(
+            compute_units,
+            backends,
+            [(1, 32), (32,), (3, 32)], # input shape
+            [False, True], # complex
+            [16], # n_fft
+            [None, 4, 5], # hop_length
+            [None, 16, 9], # win_length
+            [None, torch.hann_window], # window
+            [None, False, True], # center
+            ["constant", "reflect", "replicate"], # pad mode
+            [False, True], # normalized
+            [None, False, True], # onesided
+        )
+    )
+    def test_stft(self, compute_unit, backend, input_shape, complex, n_fft, hop_length, win_length, window, center, pad_mode, normalized, onesided):
+        if complex and onesided:
+            pytest.skip("Onesided stft not possible for complex inputs")
+
+        class STFTModel(torch.nn.Module):
+            def forward(self, x):
+                applied_window = window(win_length) if window and win_length else None
+                x = torch.complex(x, x) if complex else x
+                x = torch.stft(
+                    x,
+                    n_fft=n_fft,
+                    hop_length=hop_length,
+                    win_length=win_length,
+                    window=applied_window,
+                    center=center,
+                    pad_mode=pad_mode,
+                    normalized=normalized,
+                    onesided=onesided,
+                    return_complex=True)
+                x = torch.stack([torch.real(x), torch.imag(x)], dim=0)
+                return x
+
+        TorchBaseTest.run_compare_torch(
+            input_shape,
+            STFTModel(),
+            backend=backend,
+            compute_unit=compute_unit
+        )
+
+class TestSpectrogram(TorchBaseTest):
+    @pytest.mark.parametrize(
+        "compute_unit, backend, input_shape, spec, power",
+        itertools.product(
+            compute_units,
+            backends,
+            [(1, 1000), (1000,), (3, 1000)], # input shape
+            [torchaudio.transforms.Spectrogram, torchaudio.transforms.MelSpectrogram],
+            [None, 1, 2] # magnitude or power
+        )
+    )
+    def test_spectrogram(self, compute_unit, backend, input_shape, spec, power):
+        if platform.machine() != "arm64":
+            pytest.xfail("rdar://108001659 ([PyTorch] Torchaudio Spectrogram Failed on Intel Machine)")
+
+        if spec is torchaudio.transforms.MelSpectrogram and power is None:
+            pytest.skip("power or magnitude required for melspec")
+
+        class SpectrogramModel(torch.nn.Module):
+            def __init__(self) -> None:
+                super().__init__()
+                # the other spectrogram options are passed through to stft
+                # and are tested in TestSTFT
+                self.spec = spec(power=power, n_fft=128)
+
+            def forward(self, x):
+                x = self.spec(x)
+                if power is None:
+                    # complex: stack them
+                    x = torch.stack([torch.real(x), torch.imag(x)], dim=0)
+                return x
+
+        TorchBaseTest.run_compare_torch(
+            input_shape,
+            SpectrogramModel(),
+            backend=backend,
+            compute_unit=compute_unit,
+            rtol=1e-4,
+            atol=1e-4,
+        )
 
 class TestNms(TorchBaseTest):
     @pytest.mark.parametrize(
-        "compute_unit, backend, box_num, iou_threshold, dynamic_input",
+        "compute_unit, backend, box_num, iou_threshold, dynamic_input, minimum_deployment_target",
         itertools.product(
             compute_units,
             backends,
             [1, 5, 20, 1000],
             [0.0, 0.2, 0.8],
             [True, False],
+            [None, ct.target.iOS17],
         ),
     )
     def test_nms(
         self,
         compute_unit,
         backend: Tuple[str, str],
         box_num: int,
         iou_threshold: float,
         dynamic_input: bool,
+        minimum_deployment_target: ct.target,
     ):
         if box_num >= 1000 and backend == ("mlprogram", "fp16"):
             pytest.xfail(
                 "rdar://103891349 ([TensorFlow] [PyTorch] NMS discrepancy in Fp16 when "
                 "number of boxes is large)"
             )
 
@@ -8147,17 +8905,18 @@
         # When the input score is too close, the returned index order is not guaranteed (same
         # behaviour as PyTorch). So instead of generating random scores by torch.rand, use shuffle.
         input_scores = np.arange(box_num)
         np.random.shuffle(input_scores)
         input_scores = torch.tensor(input_scores, dtype=torch.float32)
 
         if dynamic_input:
+            upper_bound = 4096 if backend[0] == "mlprogram" else -1
             converter_input_type = [
-                ct.TensorType(shape=(RangeDim(1, -1), 4)),
-                ct.TensorType(shape=(RangeDim(1, -1),)),
+                ct.TensorType(shape=(RangeDim(1, upper_bound), 4)),
+                ct.TensorType(shape=(RangeDim(1, upper_bound),)),
             ]
         else:
             converter_input_type = [
                 ct.TensorType(shape=input_boxes.shape),
                 ct.TensorType(shape=input_scores.shape),
             ]
 
@@ -8168,27 +8927,30 @@
             [input_boxes, input_scores],
             nms_model,
             expected_results=expected_results,
             input_as_shape=False,
             backend=backend,
             converter_input_type=converter_input_type,
             compute_unit=compute_unit,
+            minimum_deployment_target=minimum_deployment_target,
         )
 
     @pytest.mark.parametrize(
-        "compute_unit, backend",
+        "compute_unit, backend, minimum_deployment_target",
         itertools.product(
             compute_units,
             backends,
+            [None, ct.target.iOS17],
         ),
     )
     def test_nms_corner_case_iou_equal_threshold(
         self,
         compute_unit,
         backend: Tuple[str, str],
+        minimum_deployment_target: ct.target,
     ):
         class NmsModel(torch.nn.Module):
             def forward(self, boxes, scores):
                 return torchvision.ops.nms(boxes, scores, iou_threshold=0.2)
 
         input_boxes = torch.tensor([[3., 2., 3., 0.],
                                     [0., 0., 2., 2.],
@@ -8200,45 +8962,72 @@
             ct.TensorType(shape=input_boxes.shape),
             ct.TensorType(shape=input_scores.shape),
         ]
 
         nms_model = NmsModel()
         nms_model.eval()
         expected_results = nms_model(input_boxes, input_scores)
-        with pytest.raises(AssertionError, match="Items are not equal"):
-            # TODO: rdar://104966206 ([PyTorch] Re-enable NMS Corner Case Tests After PyTorch Fixes Bugs).
-            # This is because the IOU between the last box ([1., 1., 2., 3.]) and the second box ([0., 0., 2., 2.]) is
-            # exactly 0.2 (IOU threshold), which leads to a corner case that PyTorch will remove the second box while
-            # CoreML keeps it. According to PyTorch's doc, only boxes with `greater than iou_threshold` should be
-            # removed, so it's a bug in PyTorch's side.
+
+        if backend[1] == "fp32" and minimum_deployment_target != ct.target.iOS17:
+            with pytest.raises(AssertionError, match="Items are not equal"):
+                # TODO: rdar://104966206 ([PyTorch] Re-enable NMS Corner Case Tests After PyTorch Fixes Bugs).
+                # This is because the IOU between the last box ([1., 1., 2., 3.]) and the 2nd box ([0., 0., 2., 2.]) is
+                # exactly 0.2 (IOU threshold), which leads to a corner case that PyTorch will remove the second box while
+                # CoreML keeps it. According to PyTorch's doc, only boxes with `greater than iou_threshold` should be
+                # removed, so it's a bug in PyTorch's side.
+                #
+                # The reason of the PyTorch bug is:
+                #     They always use fp64 for the IOU theshold in their c++ backend,
+                #     even if the boxes and the scores can be fp32,
+                #     so the IOU threshold (fp64 0.2) rounds to 0.20000000000000001 and
+                #     the IOU between the last and the 2nd boxes (fp32 0.2) rounds to 0.20000000298023224,
+                #     leading to fp32 0.2 > fp64 0.2 and the removal happens
+                TorchBaseTest.run_compare_torch(
+                    [input_boxes, input_scores],
+                    nms_model,
+                    expected_results=expected_results,
+                    input_as_shape=False,
+                    backend=backend,
+                    converter_input_type=converter_input_type,
+                    compute_unit=compute_unit,
+                    minimum_deployment_target=minimum_deployment_target,
+                )
+        else:
+            # In fp16, the IOU threshold (fp16 0.2) rounds to 0.199951171875.
+            # On CPU, espresso computes everything in fp32, so the IOU between
+            # the last and the 2nd boxes (fp32 0.2) rounds to 0.20000000298023224,
+            # leading to fp32 0.2 > fp16 0.2 and the removal happens
+            #
+            # In IOS17, the CoreML and PyTorch have same results for the corner case.
             TorchBaseTest.run_compare_torch(
                 [input_boxes, input_scores],
                 nms_model,
                 expected_results=expected_results,
                 input_as_shape=False,
                 backend=backend,
                 converter_input_type=converter_input_type,
                 compute_unit=compute_unit,
+                minimum_deployment_target=minimum_deployment_target,
             )
 
         # Change the last input box to make IOU slightly larger than 0.2, the output of CoreML will match PyTorch.
-        input_boxes[-1][-1] = 2.999
+        input_boxes[-1][-1] = 2.997
         expected_results = nms_model(input_boxes, input_scores)
         TorchBaseTest.run_compare_torch(
             [input_boxes, input_scores],
             nms_model,
             expected_results=expected_results,
             input_as_shape=False,
             backend=backend,
             converter_input_type=converter_input_type,
             compute_unit=compute_unit,
         )
 
         # Change the last input box to make IOU slightly smaller than 0.2, the output of CoreML will match PyTorch.
-        input_boxes[-1][-1] = 3.0001
+        input_boxes[-1][-1] = 3.003
         expected_results = nms_model(input_boxes, input_scores)
         TorchBaseTest.run_compare_torch(
             [input_boxes, input_scores],
             nms_model,
             expected_results=expected_results,
             input_as_shape=False,
             backend=backend,
@@ -8260,56 +9049,44 @@
             def forward(self, x):
                 return x.size()
 
         self.run_compare_torch(
             [(1, 2, 3)],
             TestModel(),
             backend=backend,
-            compute_unit=compute_unit
+            compute_unit=compute_unit,
         )
 
     @pytest.mark.parametrize(
-        "compute_unit, backend",
+        "compute_unit, backend, dim, minimum_deployment_target",
         itertools.product(
             compute_units,
             [('mlprogram', "fp16")],
+            [2, -1],
+            [None, ct.target.iOS17],
         )
     )
-    def test_tensor_size_with_dim(self, compute_unit: ct.ComputeUnit.CPU_ONLY,
-                                  backend: List[Tuple[str]]):
+    def test_tensor_size_with_dim(
+        self,
+        compute_unit: ct.ComputeUnit.CPU_ONLY,
+        backend: List[Tuple[str]],
+        dim: int,
+        minimum_deployment_target: ct.target,
+    ):
         class TestModel(torch.nn.Module):
             def forward(self, x):
-                return x.size(dim=-1)
+                return x.size(dim=dim)
 
-        model = TestModel()
-
-        mlmodel = self.run_compare_torch(
+        self.run_compare_torch(
             [(1, 2, 3)],
-            model,
+            TestModel(),
             backend=backend,
-            compute_unit=compute_unit
+            compute_unit=compute_unit,
+            minimum_deployment_target=minimum_deployment_target,
         )
-        prog = mlmodel[1]._mil_program
-        # The shape op is folded to const.
-        assert len(prog.find_ops(op_type="shape")) == 0
-
-        with patch.object(Var, '_is_nonreplaceable_var') as mocked_is_nonreplaceable_var:
-            # Mock that shape op is non-replaceable.
-            mocked_is_nonreplaceable_var.side_effect = (
-                lambda var: var.op and "shape" in var.op.op_type
-            )
-            mlmodel = self.run_compare_torch(
-                [(1, 2, 3)],
-                model,
-                backend=backend,
-                compute_unit=compute_unit
-            )
-            prog = mlmodel[1]._mil_program
-            # The shape op is not folded to const.
-            assert len(prog.find_ops(op_type="shape")) == 1
 
 
 class TestBitwiseAnd(TorchBaseTest):
     @pytest.mark.parametrize(
         "compute_unit, backend",
         itertools.product(
             compute_units,
@@ -8436,7 +9213,221 @@
                 inner = self.innermodel(x)
                 return inner[0]
 
         x = torch.rand(1, 3, 640, 640)
         self.run_compare_torch(x, OuterModel(),
                                input_as_shape=False, use_scripting=True,
                                backend=backend, compute_unit=compute_unit)
+
+class TestScaledDotProductAttention(TorchBaseTest):
+    """
+    Tests for torch.nn.functional.scaled_dot_product_attention op
+    (https://pytorch.org/docs/stable/generated/torch.nn.functional.scaled_dot_product_attention.html)
+    """
+
+    @pytest.mark.parametrize(
+        "compute_unit, backend, rank",
+        itertools.product(
+            compute_units,
+            backends,
+            [2, 3, 4, 5],
+        ),
+    )
+    def test_different_input_ranks_no_mask(self, compute_unit, backend, rank):
+        """
+        The query/key/value inputs can be any rank 2 or greater.
+        """
+        batch_size, seq_len, n_heads_1, n_heads_2, d = 2, 10, 3, 4, 7
+        if rank == 2:
+            input_shape = (seq_len, d)
+        elif rank == 3:
+            input_shape = (batch_size, seq_len, d)
+        elif rank == 4:
+            input_shape = (batch_size, n_heads_1, seq_len, d)
+        elif rank == 5:
+            input_shape = (batch_size, n_heads_1, n_heads_1, seq_len, d)
+        else:
+            raise ValueError("invalid rank")
+
+        model = ModuleWrapper(
+            function=nn.functional.scaled_dot_product_attention,
+            kwargs={
+                "attn_mask": None,
+                "dropout_p": 0.0,
+                "is_causal": False,
+            },
+        )
+
+        self.run_compare_torch(
+            [input_shape] * 3,
+            model,
+            backend=backend,
+            compute_unit=compute_unit,
+        )
+
+    @pytest.mark.parametrize(
+        "compute_unit, backend, seq_lengths, include_heads",
+        itertools.product(
+            compute_units,
+            backends,
+            [(5, 5), (5, 7), (6, 4)],
+            [False, True],
+        ),
+    )
+    def test_is_causal_flag(self, compute_unit, backend, seq_lengths, include_heads):
+        source_seq_len, target_seq_len = seq_lengths
+        query_shape = (2, 2, target_seq_len, 7) if include_heads else (2, target_seq_len, 7)
+        key_shape = (2, 2, source_seq_len, 7) if include_heads else (2, source_seq_len, 7)
+        value_shape = key_shape
+
+        model = ModuleWrapper(
+            function=nn.functional.scaled_dot_product_attention,
+            kwargs={
+                "attn_mask": None,
+                "is_causal": True,
+            },
+        )
+        res = self.run_compare_torch(
+            [query_shape, key_shape, value_shape],
+            model,
+            backend=backend,
+            compute_unit=compute_unit,
+        )
+        # check that "fill" and "band_part" ops, which are needed to compute mask, have been constant folded
+        mil_prog = res[1]._get_mil_internal()
+        # assert that "lstm" ops are present in the mil program
+        assert len(mil_prog.find_ops(op_type="fill")) == 0
+        assert len(mil_prog.find_ops(op_type="band_part")) == 0
+
+    @pytest.mark.parametrize(
+        "compute_unit, backend, seq_lengths, bool_mask",
+        itertools.product(
+            compute_units,
+            backends,
+            [(5, 5), (7, 5)],
+            [False, True],
+        ),
+    )
+    def test_attn_mask(self, compute_unit, backend, seq_lengths, bool_mask):
+        source_seq_len, target_seq_len = seq_lengths
+        query_shape = (2, 3, target_seq_len, 7)
+        key_shape = (2, 3, source_seq_len, 7)
+        value_shape = key_shape
+        mask_shape = (target_seq_len, source_seq_len)
+
+        query = generate_input_data(query_shape)
+        key = generate_input_data(key_shape)
+        value = generate_input_data(value_shape)
+        if bool_mask:
+            mask = torch.rand(mask_shape) > 0.5
+            mask = mask.bool()
+        else:
+            mask = generate_input_data(mask_shape)
+
+        model = ModuleWrapper(function=nn.functional.scaled_dot_product_attention)
+        self.run_compare_torch(
+            (query, key, value, mask),
+            model,
+            backend=backend,
+            compute_unit=compute_unit,
+            input_as_shape=False,
+        )
+
+    @pytest.mark.parametrize(
+        "compute_unit, backend, mask_as_input",
+        itertools.product(
+            compute_units,
+            backends,
+            [True, False],
+        ),
+    )
+    def test_toy_xformer_with_sdpa(self, compute_unit, backend, mask_as_input):
+        embedding_size = 32
+        seq_length = 16
+        n_heads = 4
+        batch_size = 2
+        num_blocks = 3
+
+        class AttentionBlock(nn.Module):
+            def __init__(self, embed_dim=embedding_size, n_head=n_heads):
+                super().__init__()
+                self.query_proj_op = nn.Linear(embed_dim, embed_dim)
+                self.key_proj_op = nn.Linear(embed_dim, embed_dim)
+                self.value_proj_op = nn.Linear(embed_dim, embed_dim)
+                self.out_proj_op = nn.Linear(embed_dim, embed_dim)
+                self.n_head = n_head
+
+            def forward(self, x, mask=None):
+                # in comments below for shapes, using following notation:
+                # B: batch_size, S: seq_length, E: embedding_size, h: n_heads
+                # x: (B,S,E)
+                # mask: (S,S)
+                batch_size, seq_len, dim = x.shape
+                query_proj = self.query_proj_op(x)  # (B,S,E)
+                key_proj = self.key_proj_op(x)  # (B,S,E)
+                value_proj = self.value_proj_op(x)  # (B,S,E)
+                # reshape to (B, h, S, E/h)
+                query_proj = query_proj.reshape(
+                    batch_size, seq_len, self.n_head, dim // self.n_head
+                ).permute(
+                    0, 2, 1, 3
+                )  # (B, h, S, E/h)
+                key_proj = key_proj.reshape(
+                    batch_size, seq_len, self.n_head, dim // self.n_head
+                ).permute(
+                    0, 2, 1, 3
+                )  # (B, h, S, E/h)
+                value_proj = value_proj.reshape(
+                    batch_size, seq_len, self.n_head, dim // self.n_head
+                ).permute(
+                    0, 2, 1, 3
+                )  # (B, h, S, E/h)
+                # now do scaled dot produce attention
+                if mask is None:
+                    out = nn.functional.scaled_dot_product_attention(
+                        query_proj, key_proj, value_proj, is_causal=True
+                    )  # (B, h, S, E/h)
+                else:
+                    out = nn.functional.scaled_dot_product_attention(
+                        query_proj, key_proj, value_proj, mask
+                    )  # (B, h, S, E/h)
+                # reshape back to (B, S, E)
+                out = out.permute(0, 2, 1, 3).reshape(batch_size, seq_len, dim)  # (B, S, E)
+                return self.out_proj_op(out)
+
+        class MLPBlock(nn.Module):
+            def __init__(self, embed_dim=embedding_size):
+                super().__init__()
+                self.fc1 = nn.Linear(embed_dim, embed_dim)
+                self.activation = nn.GELU()
+                self.fc2 = nn.Linear(embed_dim, embed_dim)
+
+            def forward(self, x):
+                x = self.fc1(x)
+                x = self.activation(x)
+                return self.fc2(x)
+
+        class ToyTransformer(nn.Module):
+            def __init__(self, n_blocks=num_blocks, embed_dim=embedding_size):
+                super().__init__()
+                self.attn_block = AttentionBlock(embed_dim=embed_dim)
+                self.mlp = MLPBlock(embed_dim=embed_dim)
+                self.n_blocks = n_blocks
+                self.lnorm = nn.LayerNorm(embed_dim)
+
+            def forward(self, x, mask=None):
+                for i in range(self.n_blocks):
+                    x = self.attn_block(x, mask) + x
+                    x = self.lnorm(x)
+                    x = self.mlp(x) + x
+                    x = self.lnorm(x)
+                return x
+
+        model = ToyTransformer()
+        self.run_compare_torch(
+            [(batch_size, seq_length, embedding_size), (seq_length, seq_length)]
+            if mask_as_input
+            else [(batch_size, seq_length, embedding_size)],
+            model,
+            backend=backend,
+            compute_unit=compute_unit,
+        )
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/torch/test/testing_utils.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/torch/test/testing_utils.py`

 * *Files 4% similar despite different names*

```diff
@@ -8,17 +8,16 @@
 import torch
 import torch.nn as nn
 
 import coremltools as ct
 import coremltools.models.utils as coremltoolsutils
 from coremltools import RangeDim, TensorType
 from coremltools._deps import _IS_MACOS
-from coremltools.converters.mil.mil.types.type_mapping import \
-    nptype_from_builtin
-from coremltools.converters.mil.testing_utils import ct_convert
+from coremltools.converters.mil.mil.types.type_mapping import nptype_from_builtin
+from coremltools.converters.mil.testing_utils import ct_convert, validate_minimum_deployment_target
 
 from ..converter import torch_to_mil_types
 
 
 class ModuleWrapper(nn.Module):
     """
     Helper class to transform torch function into torch nn module.
@@ -144,15 +143,15 @@
     model_spec,
     expected_results=None,
     atol=1e-4,
     rtol=1e-05,
     backend=("neuralnetwork", "fp32"),
     converter_input_type=None,
     compute_unit=ct.ComputeUnit.CPU_ONLY,
-    minimum_deployment_target=None
+    minimum_deployment_target=None,
 ):
     """
     If expected results is not set, it will by default
     be set to the flattened output of the torch model.
 
     Inputs:
 
@@ -184,19 +183,16 @@
     if mlmodel.compute_unit != ct.ComputeUnit.CPU_ONLY or (dtype == "fp16"):
         atol = max(atol * 100.0, 5e-1)
         rtol = max(rtol * 100.0, 5e-2)
 
     if not coremltoolsutils._has_custom_layer(mlmodel._spec):
         coreml_preds = mlmodel.predict(coreml_inputs)
         coreml_outputs = mlmodel._spec.description.output
-        coreml_results = [
-            coreml_preds[output.name] for output in coreml_outputs
-        ]
-        for torch_result, coreml_result in zip(expected_results,
-                                               coreml_results):
+        coreml_results = [coreml_preds[output.name] for output in coreml_outputs]
+        for torch_result, coreml_result in zip(expected_results, coreml_results):
 
             if torch_result.shape == ():
                 torch_result = np.array([torch_result])
             np.testing.assert_equal(coreml_result.shape, torch_result.shape)
             np.testing.assert_allclose(coreml_result, torch_result, atol=atol, rtol=rtol)
     return model_spec, mlmodel, coreml_inputs, coreml_preds
 
@@ -208,52 +204,54 @@
     @pytest.fixture(autouse=True)
     def store_testname_with_args(self, request):
         TorchBaseTest.testclassname = type(self).__name__
         TorchBaseTest.testmodelname = request.node.name
 
     @staticmethod
     def run_compare_torch(
-            input_data,
-            model,
-            expected_results=None,
-            atol=1e-04,
-            rtol=1e-05,
-            input_as_shape=True,
-            backend=("neuralnetwork", "fp32"),
-            rand_range=(-1.0, 1.0),
-            use_scripting=False,
-            converter_input_type=None,
-            compute_unit=ct.ComputeUnit.CPU_ONLY,
-            minimum_deployment_target=None,
+        input_data,
+        model,
+        expected_results=None,
+        atol=1e-04,
+        rtol=1e-05,
+        input_as_shape=True,
+        backend=("neuralnetwork", "fp32"),
+        rand_range=(-1.0, 1.0),
+        use_scripting=False,
+        converter_input_type=None,
+        compute_unit=ct.ComputeUnit.CPU_ONLY,
+        minimum_deployment_target=None,
     ):
         """
         Traces a model and runs a numerical test.
         Args:
             input_as_shape <bool>: If true generates random input data with shape.
             expected_results <iterable, optional>: Expected result from running pytorch model.
             converter_input_type: If not None, then pass it to the "inputs" argument to the
                 ct.convert() call.
         """
+        if minimum_deployment_target is not None:
+            validate_minimum_deployment_target(minimum_deployment_target, backend)
+
         model.eval()
         if input_as_shape:
             input_data = generate_input_data(input_data, rand_range)
 
         if use_scripting:
             model_spec = torch.jit.script(model)
         else:
             model_spec = trace_model(model, _copy_input_data(input_data))
 
-        model_spec, mlmodel, coreml_inputs, coreml_results = \
-            convert_and_compare(
-                input_data,
-                model_spec,
-                expected_results=expected_results,
-                atol=atol,
-                rtol=rtol,
-                backend=backend,
-                converter_input_type=converter_input_type,
-                compute_unit=compute_unit,
-                minimum_deployment_target=minimum_deployment_target,
-            )
+        model_spec, mlmodel, coreml_inputs, coreml_results = convert_and_compare(
+            input_data,
+            model_spec,
+            expected_results=expected_results,
+            atol=atol,
+            rtol=rtol,
+            backend=backend,
+            converter_input_type=converter_input_type,
+            compute_unit=compute_unit,
+            minimum_deployment_target=minimum_deployment_target,
+        )
 
         return model_spec, mlmodel, coreml_inputs, coreml_results, \
             TorchBaseTest.testclassname, TorchBaseTest.testmodelname
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/torch/torch_op_registry.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/torch/torch_op_registry.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/frontend/torch/torchir_passes.py` & `coremltools-7.0b1/coremltools/converters/mil/frontend/torch/torchir_passes.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/input_types.py` & `coremltools-7.0b1/coremltools/converters/mil/input_types.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,21 +1,20 @@
 #  Copyright (c) 2020, Apple Inc. All rights reserved.
 #
 #  Use of this source code is governed by a BSD-3-clause license that can be
 #  found in the LICENSE.txt file or at https://opensource.org/licenses/BSD-3-Clause
 
 from enum import Enum
+from typing import Optional
 
 import numpy as np
 
 from coremltools.converters.mil.mil import types
 from coremltools.converters.mil.mil.types.symbolic import is_symbolic
-from coremltools.converters.mil.mil.types.type_mapping import (
-    is_builtin, numpy_type_to_builtin_type)
-
+from coremltools.converters.mil.mil.types.type_mapping import is_builtin, numpy_type_to_builtin_type
 
 
 class ColorLayout(Enum):
     RGB = "RGB"
     BGR = "BGR"
     GRAYSCALE = "G"
     GRAYSCALE_FLOAT16 = "G_FLOAT16"
@@ -102,15 +101,15 @@
             * If ``color_layout`` is ``ct.colorlayout.GRAYSCALE`` or
               ``ct.colorlayout.GRAYSCALE_FLOAT16``, bias would be a ``float``.
             * If ``color_layout`` is ``ct.colorlayout.RGB`` or ``ct.colorlayout.BGR``,
               bias would be a list of ``float``.
 
         color_layout: string or enumeration of type ``ct.colorlayout``
             Color layout of the image. Valid values are as follows:
-            
+
             Enumeration (recommended):
                 * ``ct.colorlayout.RGB``
                 * ``ct.colorlayout.BGR``
                 * ``ct.colorlayout.GRAYSCALE``
                 * ``ct.colorlayout.GRAYSCALE_FLOAT16``
 
             String values (older way to specify):
@@ -260,60 +259,64 @@
     def __str__(self):
         return 'TensorType[name={}, shape={}, dtype={}]'.format(self.name,
                                                                 self.shape,
                                                                 self.dtype)
 
 
 class RangeDim:
-    def __init__(self, lower_bound=1, upper_bound=-1, default=None,
-            symbol=None):
+    def __init__(
+        self,
+        lower_bound: int = 1,
+        upper_bound: int = -1,
+        default: Optional[int] = None,
+        symbol: Optional[str] = None,
+    ):
         """
         A class for providing a range of accepted shapes.
 
         Parameters
         ----------
-        lower_bound: (int)
+        lower_bound:
             The minimum valid value for the shape.
 
-        upper_bound: (int)
+        upper_bound:
             The maximum valid value for the shape.
 
-            Set to ``-1`` if there is no upper limit.
-
-        default: (int) or None
-            The default value that is used for initiating the model, and set in the input shape field of the model file.
+            Set to ``-1`` if there is no upper limit (only works if backend is set to "neuralnetwork").
+            When backend is set to "mlprogram" during conversion, -1 is not allowed. A finite
+            positive upper bound must be provided.
+
+        default:
+            The default value that is used for initiating the model, and set in the input shape
+            field of the model file.
 
             If set to ``None``, ``lower_bound`` would be used as default.
 
-        symbol: (str)
-            Optional symbol name for the dim. Autogenerate a symbol name if
-            not specified.
+        symbol:
+            Optional symbol name for the dim. Autogenerate a symbol name if not specified.
         """
         if symbol is None:
             from coremltools.converters.mil.mil import get_new_symbol
             self.symbol = get_new_symbol()
         else:
             from coremltools.converters.mil.mil import Symbol
             self.symbol = Symbol(symbol)
         self.lower_bound = lower_bound
         self.upper_bound = upper_bound
+
         if default is None:
             self.default = lower_bound
         else:
             if default < lower_bound:
                 raise ValueError(
-                    "Default value {} is less than minimum value ({}) for range".format(
-                        default, lower_bound
-                    )
+                    f"Default value {default} is less than minimum value ({lower_bound}) for range"
                 )
-            if upper_bound > 0 and default > upper_bound:
+            if default > upper_bound > 0:
                 raise ValueError(
-                    "Default value {} is greater than maximum value ({}) for range".format(
-                        default, upper_bound
-                    )
+                    f"Default value {default} is greater than maximum value ({upper_bound}) for range"
                 )
             self.default = default
 
     def __repr__(self):
         return self.__str__()
 
     def __str__(self):
@@ -326,19 +329,19 @@
         """
         The basic shape class to be set in InputType.
 
         Parameters
         ----------
         shape: list of (int), symbolic values, RangeDim object
             The valid shape of the input.
-        
+
         default: tuple of int or None
             The default shape that is used for initiating the model, and set in
             the metadata of the model file.
-            
+
             If None, then ``shape`` is used.
         """
         from coremltools.converters.mil.mil import get_new_symbol
 
         if not isinstance(shape, (list, tuple)):
             msg = "Shape should be list or tuple, got type {} instead"
             raise ValueError(msg.format(type(shape)))
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/__init__.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/__init__.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/block.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/block.py`

 * *Files 0% similar despite different names*

```diff
@@ -448,21 +448,23 @@
                 new_var.name = old_var.name
 
     def try_replace_uses_of_var_after_op(
         self,
         anchor_op,
         old_var,
         new_var,
+        end_op=None,
         no_check_var_types=False,
         no_check_var_visibility=False,
     ):
         """
         :param anchor_op: Operation
         :param old_var: Var
         :param new_var: Var
+        :param end_op: Operation
         :param no_check_var_types: bool
         :param no_check_var_visibility: bool
         :return: True if the old_var can be replaced by new_var. False otherwsie.
 
         This helper function guards the replace_uses_of_var_after_op function,
         by first checking if the old_var could be replaced by the new_var.
 
@@ -470,14 +472,15 @@
         and returns True. 2. Return False if the replacement is not allow.
         """
         if not old_var.can_be_replaced_by_var(new_var):
             return False
 
         self.replace_uses_of_var_after_op(
             anchor_op=anchor_op,
+            end_op=end_op,
             old_var=old_var,
             new_var=new_var,
             no_check_var_types=no_check_var_types,
             no_check_var_visibility=no_check_var_visibility,
         )
         return True
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/builder.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/builder.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/input_type.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/input_type.py`

 * *Files 0% similar despite different names*

```diff
@@ -281,15 +281,15 @@
 
     @property
     def type_domain(self):
         return self._type_domain
 
     @type_domain.setter
     def type_domain(self, val):
-        msg = "type_domain must be a tuple of builtin types"
+        msg = f"type_domain {val} must be a tuple of builtin types"
         if not isinstance(val, tuple) or any(map(lambda t: t not in _SUPPORT_TYPES, val)):
             raise ValueError(msg)
         self._type_domain = val
 
     @property
     def type_domain_id(self):
         return self._type_domain_id
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/operation.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/operation.py`

 * *Files 1% similar despite different names*

```diff
@@ -481,20 +481,19 @@
                 raise RuntimeError(
                     "Unknown input '{}' for op '{}'".format(key, self.op_type)
                 )
 
         def check_and_detach(v_new, v_old, op, no_check_var_types):
             # Check new var's sym_type is compatible with the
             # existing's sym_type.
-            if (
-                not is_compatible_type(v_new.sym_type, v_old.sym_type)
-                and not no_check_var_types
-            ):
-                msg = "New var type {} not a subtype of " + "existing var type {}"
-                raise ValueError(msg.format(v_new.sym_type, v_old.sym_type))
+            if not is_compatible_type(v_new.sym_type, v_old.sym_type) and not no_check_var_types:
+                raise ValueError(
+                    f"New var type `{types.builtin_to_string(v_new.sym_type)}` not a "
+                    f"subtype of existing var type `{types.builtin_to_string(v_old.sym_type)}`."
+                )
             v_old.remove_child_op(op, no_check_var_types)
 
         self.input_spec.validate_inputs(self.name, self.op_type, input_kvs)
 
         for name, var in input_kvs.items():
             # Remove this operation itself from existing input
             # Var's child_ops
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/_utils.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/_utils.py`

 * *Files 4% similar despite different names*

```diff
@@ -68,14 +68,38 @@
                 ret_shapes.append(get_new_symbol())
             else:
                 raise_incompatible_dim_exception()
 
     return tuple(ret_shapes)
 
 
+def infer_type_with_broadcast(typea, typeb, primitive_type):
+    """
+    Given 2 primitive types `typea` and `typeb`, and their promotion `primitive_type`,
+    return the type after broadcast
+    """
+
+    # broadcast
+    if not types.is_tensor(typea) and not types.is_tensor(typeb):
+        # both typea and typeb are not tensors
+        return primitive_type
+    if types.is_tensor(typea) and not types.is_tensor(typeb):
+        # a is tensor, b is not
+        return types.tensor(primitive_type, typea.get_shape())
+    if not types.is_tensor(typea) and types.is_tensor(typeb):
+        # a is not tensor, b is
+        return types.tensor(primitive_type, typeb.get_shape())
+
+    # both a, b are tensors
+    shapea = list(typea.get_shape())
+    shapeb = list(typeb.get_shape())
+    ret_shape = broadcast_shapes(shapea, shapeb)
+    return types.tensor(primitive_type, ret_shape)
+
+
 def promoted_primitive_type(type1, type2):
     """
     Given a pair of tensor or primitive types, find the smallest type that can store an instance
     of their primitive type.
     """
     ptype1 = type1.get_primitive() if types.is_tensor(type1) else type1
     ptype2 = type2.get_primitive() if types.is_tensor(type2) else type2
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/complex_dialect_ops.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/complex_dialect_ops.py`

 * *Files 6% similar despite different names*

```diff
@@ -725,20 +725,139 @@
 
     input_spec = InputSpec(x=TensorInputType(type_domain="T"))
 
     type_domains = {
         "T": (types.complex64,),
     }
 
+    # If type_inference or value_inference is invoked when the graph is being constructed, 
+    # x.real and x.imag may not be set since the complex lowering pass hasn't yet been invoked.
+    # self.x should already have the shape set, so use that instead.
+
     def type_inference(self):
         if not isinstance(self.x, ComplexVar):
             raise ValueError("x must be a ComplexVar.")
-        input_rank = self.x.real.rank
+        input_rank = self.x.rank
         return types.tensor(types.int32, tuple([input_rank]))
 
     def value_inference(self):
-        if any_symbolic(self.x.real.shape):
+        if any_symbolic(self.x.shape):
             # convert elements in shape to int32
-            res = [x if is_symbolic(x) else np.int32(x) for x in self.x.real.shape]
+            res = [x if is_symbolic(x) else np.int32(x) for x in self.x.shape]
             return np.array(res)
         else:
-            return np.array(self.x.real.shape).astype(np.int32)
+            return np.array(self.x.shape).astype(np.int32)
+
+@register_op(namespace="complex")
+class complex_abs(Operation):
+    """
+    Returns the absolute value of a complex tensor.
+
+    Parameters
+    ----------
+    x: tensor<[*d], T> (Required)
+    
+    Returns
+    -------
+    tensor<[*d], fp32>
+        * A float tensor with the same shape as ``x``
+
+    Attributes
+    ----------
+    T: complex64
+    """
+
+    input_spec = InputSpec(x=TensorInputType(type_domain="T"))
+
+    type_domains = {
+        "T": (types.complex64,),
+    }
+
+    def type_inference(self):
+        if not isinstance(self.x, ComplexVar):
+            raise ValueError("x must be a ComplexVar.")
+        return types.tensor(infer_fp_dtype_from_complex(self.x.dtype), self.x.shape)
+
+@register_op(namespace="complex")
+class complex_stft(Operation):
+    """
+    Dialect op for 1-D STFT.
+
+    Parameters
+    ----------
+    input: tensor<\*D, T> (Required)
+        * The input tensor.
+    n_fft: const i32 (Required)
+        * Size of the fourier transform.
+    hop_length: const i32 (Optional)
+        * Stride between window frames of the input tensor.
+    win_length: const i32 (optional)
+        * The size of the window frame.
+    window: tensor<1, win_length> (optional)
+        * The window to apply to the input signal before performing the fourier transform.
+    normalized: const bool (optional, Default=``false``)
+        * Whether to normalize the results of the STFT
+    onesided: const bool (optional, Default=``true``)
+        * For real-valued inputs, whether to return the first half of the results.
+
+    Returns
+    -------
+    tensor<\*V, complex64>
+        * A complex tensor where real and imag parts have the same shape.
+
+    Attributes
+    ----------
+    T: fp32, complex64
+
+    References
+    ----------
+    See `torch.stft <https://pytorch.org/docs/stable/generated/torch.stft.html>`_.
+    """
+
+    input_spec = InputSpec(
+        input=TensorInputType(type_domain="T"),
+        n_fft=TensorInputType(const=True, type_domain=types.int32),
+        hop_length=TensorInputType(const=True, optional=True, type_domain=types.int32),
+        win_length=TensorInputType(const=True, optional=True, type_domain=types.int32),
+        window=TensorInputType(const=True, optional=True, type_domain=types.fp32),
+        normalized=TensorInputType(const=True, optional=True, type_domain=types.bool),
+        onesided=TensorInputType(const=True, optional=True, type_domain=types.bool),
+    )
+
+    type_domains = {
+        "T": (types.fp32, types.complex64),
+    }
+
+    def default_inputs(self):
+        return DefaultInputs(
+            hop_length = None,
+            win_length = None,
+            window = None,
+            normalized = False,
+            onesided = True,
+        )
+
+    def type_inference(self):
+        output_type = (types.complex64)
+        
+        # STFT shape is [B x N x T], where N is the number of frequency bins
+        # and T is the number of windows
+        # B is 1 for a time series or 2 for a batch of time series
+
+        window_length = self.n_fft.val
+        hop = self.hop_length.val if self.hop_length else self.n_fft.val // 4
+
+        # if onesided is true, the input is real valued
+        # because of Hermitian symmetry, we only need to calculate the FFT
+        # for the first half of the frequences
+        if self.onesided and self.onesided.val:
+            window_length = window_length // 2 + 1
+
+        frames = (self.input.shape[-1] - self.n_fft.val) // hop + 1
+        output_shape = [window_length, frames]
+
+        # add back rank if needed
+        if self.input.rank == 2:
+            output_shape = [self.input.shape[0]] + output_shape
+        
+        return types.tensor(output_type, tuple(output_shape))
+
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/iOS15/__init__.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS15/__init__.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/iOS15/activation.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS15/activation.py`

 * *Files 2% similar despite different names*

```diff
@@ -242,33 +242,36 @@
 class prelu(activation_with_alpha):
     """
     Where ``i = 1 ... C``, if ``x_i > 0``, return ``x_i`` , otherwise return ``alpha_i * x_i``.
 
     Parameters
     ----------
     x: tensor<[B, C, 1..3], T> (Required)
-        * x must have rank 4 or rank 3 or rank 5, i.e. a shape of (B,C,H) or (B,C,H,W) or (B,C,D,H,W)
+        * ``x`` must have rank 4, rank 3, or rank 5; that is, a shape of
+          ``(B,C,H)``, ``(B,C,H,W)``, or ``(B,C,D,H,W)``.
     alpha: const tensor<[C], T>, (Required)
-        * The length of alpha must match the second dimension of x (channel dimension)
+        * The length of ``alpha`` must match the second dimension of ``x`` (channel dimension).
 
     Returns
     -------
     tensor<[B, C, 1..3], T>
         * A tensor of the same shape as ``x``.
 
     Attributes
     ----------
     T: fp32, fp16
     """
 
     @precondition(allow=VALUE)
     def value_inference(self):
+        # Expends alpha on all dims besides the channel (2nd) dim.
         alpha_br = self.alpha.val
-        for i in range(1, len(self.x.shape)):
-            alpha_br = np.expand_dims(alpha_br, i)
+        for i in range(len(self.x.shape)):
+            if i != 1:
+                alpha_br = np.expand_dims(alpha_br, i)
         x_pos = np.maximum(self.x.val, 0)
         b = np.minimum(self.x.val, 0)
         return x_pos + b * alpha_br
 
     def type_inference(self):
         if self.x.rank not in (3, 4, 5):
             raise ValueError(
@@ -276,16 +279,16 @@
                     len(self.x.shape)
                 )
             )
         if len(self.alpha.val.shape) != 1:
             raise ValueError("alpha should be rank 1")
         if self.x.shape[1] != self.alpha.val.shape[0]:
             raise ValueError(
-                "Size of dimension 1 of alpha should be the same as "
-                + "the size of dimension 1 of x."
+                f"Size of dimension 0 of alpha ({self.alpha.val.shape[0]}) should be "
+                f"the same as the size of dimension 1 of x ({self.x.shape[1]})."
             )
         if self.x.rank in (3, 5):
             # check whether all alpha values are the same or not
             are_values_same = (
                 np.where(np.abs(self.alpha.val - self.alpha.val[0]) > 1e-5)[0].size == 0
             )
             if not are_values_same:
@@ -489,17 +492,19 @@
     T: fp16, fp32
     """
 
     @precondition(allow=VALUE)
     def value_inference(self):
         alpha_br = np.copy(self.alpha.val)
         beta_br = np.copy(self.beta.val)
-        for i in range(1, len(self.x.val.shape)):
-            alpha_br = np.expand_dims(alpha_br, i)
-            beta_br = np.expand_dims(beta_br, i)
+        # Expends alpha and beta on all dims besides the channel (2nd) dim.
+        for i in range(len(self.x.val.shape)):
+            if i != 1:
+                alpha_br = np.expand_dims(alpha_br, i)
+                beta_br = np.expand_dims(beta_br, i)
         return alpha_br * np.log(1 + np.exp(self.x.val * beta_br))
 
     def type_inference(self):
         if len(self.x.shape) < 3:
             raise ValueError("x should be at least rank 3")
         if len(self.alpha.val.shape) != 1:
             raise ValueError("alpha should be rank 1")
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/iOS15/classify.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS15/classify.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/iOS15/control_flow.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS15/control_flow.py`

 * *Files 2% similar despite different names*

```diff
@@ -4,31 +4,45 @@
 #  found in the LICENSE.txt file or at https://opensource.org/licenses/BSD-3-Clause
 
 import copy
 
 import numpy as np
 
 from coremltools import _logger as logger
-from coremltools.converters.mil.mil import (Block, get_existing_symbol,
-                                            get_new_symbol, types)
-from coremltools.converters.mil.mil.input_type import (DefaultInputs,
-                                                       InputSpec,
-                                                       InternalInputType,
-                                                       ListInputType,
-                                                       PyFunctionInputType,
-                                                       TensorInputType,
-                                                       TupleInputType)
-from coremltools.converters.mil.mil.operation import (NONE, SYMBOL, VALUE,
-                                                      Operation, mil_list,
-                                                      precondition)
+from coremltools.converters.mil.mil import Block, get_existing_symbol, get_new_symbol, types
+from coremltools.converters.mil.mil.input_type import (
+    DefaultInputs,
+    InputSpec,
+    InternalInputType,
+    ListInputType,
+    PyFunctionInputType,
+    TensorInputType,
+    TupleInputType,
+)
+from coremltools.converters.mil.mil.operation import (
+    NONE,
+    SYMBOL,
+    VALUE,
+    Operation,
+    mil_list,
+    precondition,
+)
 from coremltools.converters.mil.mil.ops.defs._op_reqs import register_op
+from coremltools.converters.mil.mil.ops.defs._utils import (
+    infer_type_with_broadcast,
+    promoted_primitive_type,
+)
 from coremltools.converters.mil.mil.types import is_compatible_type
+from coremltools.converters.mil.mil.types.type_list import list as types_list
 from coremltools.converters.mil.mil.types.type_mapping import (
-    builtin_to_string, is_subtype, numpy_type_to_builtin_type,
-    numpy_val_to_builtin_val)
+    builtin_to_string,
+    is_subtype,
+    numpy_type_to_builtin_type,
+    numpy_val_to_builtin_val,
+)
 
 
 @register_op
 class cond(Operation):
     """
     Perform a conditional execution. The return types must be identical
     between the true and false branches.
@@ -188,16 +202,14 @@
             list_value = value.ls
             if len(list_value) == 0:
                 raise ValueError("'mil_list' points to an empty list")
             builtin_elem_type, _ = self._get_type_val(list_value[0])
             # mil_list is a special case that we want to preserve the int64 element type
             if isinstance(list_value[0], np.int64):
                 builtin_elem_type = types.int64
-            from coremltools.converters.mil.mil.types.type_list import \
-                list as types_list
             builtin_type = types_list(builtin_elem_type, init_length=len(list_value), dynamic_length=False)
             return builtin_type, value
 
 
         if not isinstance(value, (np.generic, np.ndarray, str, bool, mil_list)):
             raise ValueError("Unknown value for constant: {}".format(value))
 
@@ -272,31 +284,29 @@
     )
 
     type_domains = {
         "T": (types.fp16, types.fp32, types.bool, types.int32),
     }
 
     def type_inference(self):
-        a_type = self.a.sym_type
-        b_type = self.b.sym_type
-        if all([a_type, b_type]):
-            compatible, ret_type = types.is_tensor_and_is_compatible_general_shape(
-                a_type, b_type
-            )
-            if compatible:
-                return ret_type
-            elif a_type == b_type:
-                return a_type
-            else:
-                raise ValueError("Type mismatch {} vs. {}".format(a_type, b_type))
-        return a_type if a_type is not None else b_type
+        typea = self.a.sym_type
+        typeb = self.b.sym_type
+        primitive_type = promoted_primitive_type(typea, typeb)
+        if primitive_type is None:
+            raise ValueError("Incompatible primitive types in broadcast operation")
+
+        return infer_type_with_broadcast(typea, typeb, primitive_type)
 
     @precondition(allow=VALUE)
     def value_inference(self):
-        return np.where(self.cond.val, self.a.val, self.b.val)
+        res = np.where(self.cond.val, self.a.val, self.b.val)
+        sym_type = self.type_inference()
+        if types.is_scalar(sym_type) and not np.isscalar(res):
+            res = getattr(np, str(res.dtype))(res.item())
+        return res
 
 
 @register_op
 class while_loop(Operation):
     """
     Perform the body repeatedly while the condition ``cond`` is true.
 
@@ -524,15 +534,15 @@
     ----------
     init_length: <i32> (Optional, Default=1)
         * Initial length for the list.
         * If ``dynamic_length`` is ``False``,
           ``init_length`` is the fixed length of the list throughout runtime.
 
     dynamic_length: <bool> (Optional, Default is True)
-    
+
     elem_shape: Tuple[const<T>] (Required)
         * 1-D vector denoting the shape of elements.
         * If ``T = int32``, the element shape is known at compile time.
         * ``T = string`` denotes the symbolic shape, in which the shape is determined
           at runtime.
         * If not provided, the resulting ``List`` won’t have the elementary shape
           info, which may cause backend errors. Remedy this with SSA passes.
@@ -540,15 +550,15 @@
     dtype: const (Optional, Default is fp32)
         * Possible values: ``{"bool", "fp16", "fp32", "int32"}``
         * Element tensor’s ``dtype``.
 
     Returns
     -------
     List[*]
-    
+
     Attributes
     ----------
     T: i32, string
     """
 
     input_spec = InputSpec(
         init_length=TensorInputType(optional=True, type_domain=types.int32),
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/iOS15/conv.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS15/conv.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/iOS15/elementwise_binary.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS15/elementwise_binary.py`

 * *Files 8% similar despite different names*

```diff
@@ -2,21 +2,27 @@
 #
 #  Use of this source code is governed by a BSD-3-clause license that can be
 #  found in the LICENSE.txt file or at https://opensource.org/licenses/BSD-3-Clause
 import operator
 
 import numpy as np
 
-from coremltools.converters.mil.mil import (InputSpec, Operation,
-                                            TensorInputType, precondition,
-                                            types)
+from coremltools.converters.mil.mil import (
+    InputSpec,
+    Operation,
+    TensorInputType,
+    precondition,
+    types,
+)
 from coremltools.converters.mil.mil.operation import VALUE
 from coremltools.converters.mil.mil.ops.defs._op_reqs import register_op
 from coremltools.converters.mil.mil.ops.defs._utils import (
-    broadcast_shapes, promoted_primitive_type)
+    infer_type_with_broadcast,
+    promoted_primitive_type,
+)
 
 
 class elementwise_binary(Operation):
     """
     Elementwise Binary Op Superclass
     """
     input_spec = InputSpec(
@@ -32,30 +38,15 @@
         typea = self.x.sym_type
         typeb = self.y.sym_type
         primitive_type = promoted_primitive_type(typea, typeb)
         if primitive_type is None:
             raise ValueError("Incompatible primitive types in broadcast operation")
         primitive_type = self.get_dtype(primitive_type)
 
-        # broadcast
-        if not types.is_tensor(typea) and not types.is_tensor(typeb):
-            # both typea and typeb are not tensors
-            return primitive_type
-        if types.is_tensor(typea) and not types.is_tensor(typeb):
-            # a is tensor, b is not
-            return types.tensor(primitive_type, typea.get_shape())
-        if not types.is_tensor(typea) and types.is_tensor(typeb):
-            # a is not tensor, b is
-            return types.tensor(primitive_type, typeb.get_shape())
-
-        # both a, b are tensors
-        shapea = list(typea.get_shape())
-        shapeb = list(typeb.get_shape())
-        ret_shape = broadcast_shapes(shapea, shapeb)
-        return types.tensor(primitive_type, ret_shape)
+        return infer_type_with_broadcast(typea, typeb, primitive_type)
 
     @precondition(allow=VALUE)
     def value_inference(self):
         return self._cast_check_value_inferene(self.x.val, self.y.val)
 
     def get_operator(self):
         """
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/iOS15/elementwise_unary.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS15/elementwise_unary.py`

 * *Files 8% similar despite different names*

```diff
@@ -814,19 +814,22 @@
 
 
 @register_op
 class cast(Operation):
     """
     Cast the input ``x`` to the new type ``dtype``.
 
+    Notice that the underlying Core MIL op doesn't support int64 and fp64. We support them in PyMIL
+    by mapping int64 to int32, and mapping fp64 to fp32.
+
     Parameters
     ----------
     x: tensor<[\*d], T> (Required)
     dtype: const str (Required)
-        * Can be one of the following types: ``int32``, ``int64``, ``fp32``, ``fp64``.
+        * Can be one of the following types: ``int32``, ``int64``, ``fp32``, ``fp64``, ``bool``.
 
     Returns
     -------
     tensor<[\*d], dtype>
         * A tensor of the same shape as ``x``, with type ``dtype``.
 
     Attributes
@@ -839,60 +842,69 @@
         dtype=TensorInputType(const=True, type_domain=types.str)
     )
 
     type_domains = {
         "T": (types.fp16, types.fp32, types.fp64, types.int32, types.int64, types.bool),
     }
 
-    def type_inference(self):
-        type_map = {
-            "int32": types.int32,
-            "int64": types.int32,
-            "fp16": types.fp16,
-            "fp32": types.fp32,
-            "fp64": types.fp32,
-            "bool": types.bool,
-        }
+    str_to_types_map = {
+        "int32": types.int32,
+        "int64": types.int32,
+        "fp16": types.fp16,
+        "fp32": types.fp32,
+        "fp64": types.fp32,
+        "bool": types.bool,
+    }
 
-        if self.dtype.val not in type_map.keys():
+    str_to_numpy_type_map = {
+        "int32": np.int32,
+        "int64": np.int32,
+        "fp16": np.float16,
+        "fp32": np.float32,
+        "fp64": np.float32,
+        "bool": bool,
+    }
+
+    def type_inference(self):
+        if self.dtype.val not in self.str_to_types_map.keys():
             raise NotImplementedError(
                 "Parameter dtype of the cast operation can be one of the {}. "
-                "Provided {}".format(type_map.keys(), self.dtype.val)
+                "Provided {}".format(self.str_to_types_map.keys(), self.dtype.val)
             )
 
         if not types.is_tensor(self.x.sym_type):
-            return type_map[self.dtype.val]
+            return self.str_to_types_map[self.dtype.val]
 
         ret_shape = self.x.shape
-        return types.tensor(type_map[self.dtype.val], ret_shape)
+        return types.tensor(self.str_to_types_map[self.dtype.val], ret_shape)
 
     @precondition(allow=VALUE | SYMBOL)
     def value_inference(self):
         return self.get_cast_value(self.x, self.dtype.val)
 
-    @staticmethod
-    def get_cast_value(input_var, dtype_val):
-        type_map = {
-            "int32": np.int32,
-            "int64": np.int32,
-            "fp16": np.float16,
-            "fp32": np.float32,
-            "fp64": np.float32,
-            "bool": bool,
-        }
-
-        if dtype_val not in type_map.keys():
+    @classmethod
+    def get_cast_value(cls, input_var, dtype_val):
+        if dtype_val not in cls.str_to_numpy_type_map.keys():
             raise NotImplementedError(
                 "Parameter dtype of the cast operation can be one of the {}. "
-                "Provided {}".format(type_map.keys(), dtype_val)
+                "Provided {}".format(cls.str_to_numpy_type_map.keys(), dtype_val)
             )
 
         if input_var.val is None:
-            if input_var.sym_val is not None and not is_symbolic(input_var.sym_val) and len(input_var.sym_val.shape) == 1:
-                result = [np.array(val).astype(dtype=type_map[dtype_val]).item() if not is_symbolic(val) else val for val in input_var.sym_val]
+            if (
+                input_var.sym_val is not None
+                and not is_symbolic(input_var.sym_val)
+                and len(input_var.sym_val.shape) == 1
+            ):
+                result = [
+                    np.array(val).astype(dtype=cls.str_to_numpy_type_map[dtype_val]).item()
+                    if not is_symbolic(val)
+                    else val
+                    for val in input_var.sym_val
+                ]
                 return np.array(result)
             return None
 
         if not types.is_tensor(input_var.sym_type):
-            return input_var.val.astype(dtype=type_map[dtype_val])
+            return input_var.val.astype(dtype=cls.str_to_numpy_type_map[dtype_val])
         else:
-            return np.array(input_var.val).astype(dtype=type_map[dtype_val])
+            return np.array(input_var.val).astype(dtype=cls.str_to_numpy_type_map[dtype_val])
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/iOS15/image_resizing.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS15/image_resizing.py`

 * *Files 3% similar despite different names*

```diff
@@ -52,15 +52,15 @@
         ),
         scale_factor_width=TensorInputType(
             const=True,
             optional=True,
             type_domain="U"
         ),
     )
-    
+
     type_domains = {
         "T": (types.fp16, types.fp32),
         "U": (types.fp32, types.int32),
     }
 
     def default_inputs(self):
         return DefaultInputs(
@@ -118,15 +118,15 @@
     """
 
     input_spec = InputSpec(
         x=TensorInputType(type_domain="T"),
         target_size_height=TensorInputType(const=True, type_domain=types.int32),
         target_size_width=TensorInputType(const=True, type_domain=types.int32),
     )
-    
+
     type_domains = {
         "T": (types.fp16, types.fp32),
     }
 
     def type_inference(self):
         if self.x.rank < 3:
             raise ValueError(
@@ -140,18 +140,18 @@
 
 
 @register_op
 class upsample_bilinear(Operation):
     """
     Upsample the spatial dimensions (last two dimensions) of the input
     by scale factors using bilinear interpolation.
-    The upsample_bilinear operation in MIL corresponds to the recompute_scale_factor=True
+    The upsample_bilinear operation in MIL corresponds to the ``recompute_scale_factor=True``
     mode in the pyorch bilinear interpolation op. That is,
     the scale factor is recomputed by the output size.
-    Note that when the scale_factor_height and scale_factor_width are floating point, this
+    Note that when the ``scale_factor_height`` and ``scale_factor_width`` are floating point, this
     could result in a different scale factor due to rounding.
 
     Parameters
     ----------
     x: tensor<[\*D, H1, W1], T>  (Required)
         * Must be at least rank ``3``.
     scale_factor_height: const<U> (Optional, default=1)
@@ -232,15 +232,15 @@
             type_domain="U",
         ),
         align_corners=TensorInputType(
             const=True,
             optional=True,
             type_domain=types.bool),
     )
-    
+
     type_domains = {
         "T": (types.fp16, types.fp32),
         "U": (types.int32, types.fp32),
     }
 
     def default_inputs(self):
         return DefaultInputs(
@@ -371,15 +371,15 @@
         ),
         sampling_mode=TensorInputType(
             const=True,
             optional=True,
             type_domain=types.str
         ),
     )
-    
+
     type_domains = {
         "T": (types.fp16, types.fp32),
     }
 
     def default_inputs(self):
         return DefaultInputs(
             target_size_height=1,
@@ -441,18 +441,18 @@
     target_height: const<i32> (Optional, Default=1)
         * Target height for resizing each patch.
 
     target_width: const<i32> (Optional, Default=1)
         * Target width for resizing each patch.
 
     normalized_coordinates : const<bool> (Optional, default=False)
-        * If true, the bounding box coordinates must be in the
+        * If ``True``, the bounding box coordinates must be in the
           interval ``[0, 1]``. Scaling is based on the input spatial
           dimensions: ``(H_in - 1)`` for height and ``(W_in - 1)`` for width.
-        * If false, the bounding box coordinates must be in the interval
+        * If ``False``, the bounding box coordinates must be in the interval
           ``[0, H_in - 1]`` for height dimensions and ``[0, W_in - 1]`` for
           width dimensions.
 
     spatial_scale : const<fp32> (Optional, default=1.0)
         * Additional spatial scale that multiplies the bounding box coordinates.
           You would use this to implement the RoI Align layer, which typically
           uses unnormalized RoI coordinates along with a spatial scale that is
@@ -506,57 +506,63 @@
         target_height=TensorInputType(const=True, optional=True, type_domain=types.int32),
         target_width=TensorInputType(const=True, optional=True, type_domain=types.int32),
         normalized_coordinates=TensorInputType(const=True, optional=True, type_domain=types.bool),
         spatial_scale=TensorInputType(const=True, optional=True, type_domain=types.fp32),
         box_coordinate_mode=TensorInputType(const=True, optional=True, type_domain=types.str),
         sampling_mode=TensorInputType(const=True, optional=True, type_domain=types.str),
     )
-    
+
     type_domains = {
         "T": (types.fp16, types.fp32),
     }
 
+    _VALID_SAMPLING_MODES = {
+        "STRICT_ALIGN_CORNERS",
+        "ALIGN_CORNERS",
+        "UNALIGN_CORNERS",
+        "DEFAULT",
+        "OFFSET_CORNERS",
+    }
+    _VALID_BOX_COORDINATE_MODES = {
+        "CORNERS_HEIGHT_FIRST",
+        "CORNERS_WIDTH_FIRST",
+        "CENTER_SIZE_HEIGHT_FIRST",
+        "CENTER_SIZE_WIDTH_FIRST",
+    }
+
     def default_inputs(self):
         return DefaultInputs(
             target_height=1,
             target_width=1,
             normalized_coordinates=False,
             spatial_scale=1.,
             box_coordinate_mode="CONRNERS_HEIGHT_FIRST",
             sampling_mode="DEFAULT",
         )
 
-    def type_inference(self):
+    def _validate_input(self):
         if self.x.rank != 4:
             raise ValueError(
-                'input to the "crop_resize" op must be of rank 4. Provided {}'.format(
-                    self.x.rank
-                )
+                f'input to the "crop_resize" op must be of rank 4. Provided {self.x.rank}'
             )
-
         if self.roi.rank != 5:
             raise ValueError(
-                'ROI input to the "crop_resize" op must be of rank 5, provided {}'.format(
-                    self.roi.rank
-                )
+                f'ROI input to the "crop_resize" op must be of rank 5, provided {self.roi.rank}'
             )
-
-        if self.sampling_mode.val not in {
-            "STRICT_ALIGN_CORNERS",
-            "ALIGN_CORNERS",
-            "UNALIGN_CORNERS",
-            "DEFAULT",
-            "OFFSET_CORNERS",
-        }:
+        if self.box_coordinate_mode.val not in self._VALID_BOX_COORDINATE_MODES:
             raise ValueError(
-                '"crop_resize" op: unrecognized sampling mode "{}"'.format(
-                    self.sampling_mode
-                )
+                f'"crop_resize" op: unrecognized box_coordinate_mode "{self.box_coordinate_mode.val}"'
+            )
+        if self.sampling_mode.val not in self._VALID_SAMPLING_MODES:
+            raise ValueError(
+                f'"crop_resize" op: unrecognized sampling mode "{self.sampling_mode.val}"'
             )
 
+    def type_inference(self):
+        self._validate_input()
         # ret_shape: [N] + [B, C, h_out, w_out]
         N, B, C = self.roi.shape[0], self.x.shape[0], self.x.shape[1]
         ret_shape = [N, B, C, self.target_height.val, self.target_width.val]
         return types.tensor(self.x.dtype, ret_shape)
 
 
 @register_op
@@ -588,15 +594,15 @@
     """
 
     input_spec = InputSpec(
         x=TensorInputType(type_domain="T"),
         crop_height=TensorInputType(const=True, type_domain=types.int32),
         crop_width=TensorInputType(const=True, type_domain=types.int32),
     )
-    
+
     type_domains = {
         "T": (types.fp16, types.fp32),
     }
 
     def type_inference(self):
         if self.x.rank < 3:
             raise ValueError(
@@ -705,15 +711,15 @@
         output_width=TensorInputType(const=True, type_domain=types.int32),
         sampling_mode=TensorInputType(const=True, type_domain=types.str),
         padding_mode=TensorInputType(const=True, type_domain=types.str),
         padding_value=TensorInputType(const=True, type_domain="T"),
         coordinates_mode=TensorInputType(const=True, type_domain=types.str),
         align_corners=TensorInputType(const=True, type_domain=types.bool),
     )
-    
+
     type_domains = {
         "T": (types.fp16, types.fp32),
     }
 
     def type_inference(self):
         if self.x.rank != 4:
             raise ValueError(
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/iOS15/linear.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS15/linear.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/iOS15/normalization.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS15/normalization.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/iOS15/pool.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS15/pool.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/iOS15/random.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS15/random.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/iOS15/recurrent.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS15/recurrent.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,18 +1,14 @@
 #  Copyright (c) 2020, Apple Inc. All rights reserved.
 #
 #  Use of this source code is governed by a BSD-3-clause license that can be
 #  found in the LICENSE.txt file or at https://opensource.org/licenses/BSD-3-Clause
 
-from coremltools.converters.mil.mil import Operation, types
-from coremltools.converters.mil.mil.input_type import (
-    DefaultInputs,
-    InputSpec,
-    TensorInputType
-)
+from coremltools.converters.mil.mil import Operation, Var, types
+from coremltools.converters.mil.mil.input_type import DefaultInputs, InputSpec, TensorInputType
 from coremltools.converters.mil.mil.ops.defs._op_reqs import register_op
 
 
 @register_op
 class gru(Operation):
     r"""
     Gated Recurrent Unit (GRU)
@@ -287,20 +283,23 @@
         * Must match ``DIRECTIONAL`` in initial states and weight parameters.
 
     output_sequence: const<bool> (Optional) [Default=False]
         * Outputs every step if ``True``.
 
     recurrent_activation: const<str> (Optional) [Default=sigmoid]
         * Activation applied on input, forget, and output gates.
+        * Supported values: ``hard_sigmoid``, ``linear``, ``relu``, ``scaled_tanh``, ``sigmoid``, ``tanh``
 
     cell_activation: const<str> (Optional) [Default=tanh]
         * Activation applied on cell gate.
+        * Supported values: ``hard_sigmoid``, ``linear``, ``relu``, ``scaled_tanh``, ``sigmoid``, ``tanh``
 
     activation: const<str> (Optional) [Default=tanh]
         * Activation applied on output gate.
+        * Supported values: ``hard_sigmoid``, ``linear``, ``relu``, ``scaled_tanh``, ``sigmoid``, ``tanh``
 
     clip: const<T> (optional) [Default=None]
         * Cell gate is clipped to ``[-clip, +clip]``.
 
     Returns
     -------
     <s, b, DIRECTIONS*H, T> or <1, b, DIRECTIONS*H, T>
@@ -349,66 +348,76 @@
             recurrent_activation="sigmoid",
             cell_activation="tanh",
             activation="tanh",
             peephole=None,
             clip=None)
 
     def type_inference(self):
-        if self.x.rank != 3:
-            raise ValueError(
-                "Invalid input shape. Expecting Rank 3 input, got {}".format(
-                    len(self.x.rank)
-                )
-            )
-        sequence_length, batch_size, input_size = self.x.shape
-
-        def weight_shape_check(wt_ih, wt_hh):
-            if wt_ih.rank != 2 or wt_hh.rank != 2:
-                raise ValueError(
-                    "Expecting Rank 2 input, got weight_ih rank: {}, weight_hh rank: {}".format(
-                        wt_ih.rank, wt_hh.rank
-                    )
-                )
-
-            hidden_size = wt_hh.shape[1]
-            if wt_hh.shape[0] // hidden_size != 4 or wt_ih.shape[0] // hidden_size != 4:
-                raise ValueError(
-                    "Incorrect weight matrix: hidden dim size mismatch. \
-                                Provided weight_ih {}, weight_hh {}. Expecting <4*H, H>".format(
-                        wt_ih.shape, wt_hh.shape
-                    )
-                )
-
-        direction = self.direction.val
-        valid_directions = {"forward", "reverse", "bidirectional"}
-        if direction not in valid_directions:
-            raise ValueError(
-                "Direction {} not supported. Supported directions: {}".format(
-                    direction, valid_directions
-                )
-            )
-
-        weight_shape_check(self.weight_ih, self.weight_hh)
-        if direction == "bidirectional":
-            weight_shape_check(self.weight_ih_back, self.weight_hh_back)
+        self._validate_inputs()
 
+        sequence_length, batch_size, input_size = self.x.shape
         hidden_dim, hidden_size = self.weight_hh.shape
-
-        dim_factor = 8 if direction == "bidirectional" else 4
+        dim_factor = 8 if self.direction.val == "bidirectional" else 4
         out_seq_len = sequence_length if self.output_sequence.val else 1
         num_directions = dim_factor // 4
         output_shape = [out_seq_len, batch_size, num_directions * hidden_size]
         output_h_shape = [batch_size, num_directions * hidden_size]
         output_c_shape = [batch_size, num_directions * hidden_size]
         return (
             types.tensor(self.x.dtype, tuple(output_shape)),
             types.tensor(self.x.dtype, tuple(output_h_shape)),
             types.tensor(self.x.dtype, tuple(output_c_shape)),
         )
 
+    def _validate_inputs(self):
+        _ALLOWED_DIRECTIONS = {"forward", "reverse", "bidirectional"}
+        _ALLOWED_ACTIVATIONS = {"tanh", "scaled_tanh", "sigmoid", "hard_sigmoid", "relu", "linear"}
+
+        def check_activation(activation: str):
+            if activation.lower() not in _ALLOWED_ACTIVATIONS:
+                raise ValueError(
+                    f"Activation `{activation}` not supported. Supported activations: {_ALLOWED_ACTIVATIONS}"
+                )
+
+        if self.x.rank != 3:
+            raise ValueError(f"Invalid input shape. Expecting Rank 3 input, got {len(self.x.rank)}")
+
+        direction = self.direction.val
+        if direction not in _ALLOWED_DIRECTIONS:
+            raise ValueError(
+                f"Direction {direction} not supported. Supported directions: {_ALLOWED_DIRECTIONS}"
+            )
+
+        self._weight_shape_check(self.weight_ih, self.weight_hh)
+        if direction == "bidirectional":
+            if self.weight_ih_back is None or self.weight_hh_back is None:
+                raise ValueError(
+                    "For bidirectional LSTM, the `weight_ih_back` and `weight_hh_back`"
+                    " must be provided."
+                )
+            self._weight_shape_check(self.weight_ih_back, self.weight_hh_back)
+
+        check_activation(self.recurrent_activation.val)
+        check_activation(self.cell_activation.val)
+        check_activation(self.activation.val)
+
+    @staticmethod
+    def _weight_shape_check(wt_ih: Var, wt_hh: Var):
+        if wt_ih.rank != 2 or wt_hh.rank != 2:
+            raise ValueError(
+                f"Expecting Rank 2 input, got weight_ih rank: {wt_ih.rank}, "
+                f"weight_hh rank: {wt_hh.rank}"
+            )
+        hidden_size = wt_hh.shape[1]
+        if wt_hh.shape[0] // hidden_size != 4 or wt_ih.shape[0] // hidden_size != 4:
+            raise ValueError(
+                f"Incorrect weight matrix: hidden dim size mismatch. Provided "
+                f"weight_ih {wt_ih.shape}, weight_hh {wt_hh.shape}. Expecting <4*H, H>"
+            )
+
 
 @register_op
 class rnn(Operation):
     r"""
     Recurrent Neural Network (RNN)
 
     .. math::
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/iOS15/reduction.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS15/reduction.py`

 * *Files 3% similar despite different names*

```diff
@@ -17,15 +17,15 @@
     Reduction Op Superclasses
     """
     input_spec = InputSpec(
         x=TensorInputType(type_domain="T"),
         axes=TensorInputType(const=True, optional=True, type_domain=types.int32),
         keep_dims=TensorInputType(const=True, optional=True, type_domain=types.bool),
     )
-    
+
     type_domains = {
         "T": (types.fp16, types.fp32, types.int32),
     }
 
     def default_inputs(self):
         return DefaultInputs(
             axes=None,
@@ -65,15 +65,15 @@
 
 class ReductionAxis(Operation):
     input_spec = InputSpec(
         x=TensorInputType(type_domain="T"),
         axis=TensorInputType(const=True, optional=True, type_domain=types.int32),
         keep_dims=TensorInputType(const=True, optional=True, type_domain=types.bool),
     )
-    
+
     type_domains = {
         "T": (types.fp16, types.fp32, types.int32),
     }
 
     def default_inputs(self):
         return DefaultInputs(
             axis=-1,
@@ -110,24 +110,15 @@
 
 
 class reduce_arg(ReductionAxis):
     def __init__(self, **kwargs):
         super().__init__(**kwargs)
 
     def type_inference(self):
-        x_shape = self.x.shape
-        axis = self.axis.val
-
-        reduced_shape = list(x_shape)
-        axis = axis if axis >= 0 else axis + len(reduced_shape)
-        if self.keep_dims.val:
-            reduced_shape[axis] = 1
-        else:
-            reduced_shape.pop(axis)
-
+        reduced_shape = self._find_reduced_shape()
         return types.tensor(types.int32, tuple(reduced_shape))
 
 
 """
 Reduction op implementations
 """
 
@@ -202,71 +193,71 @@
         return np.argmin
 
 
 @register_op
 class reduce_l1_norm(ReductionAxes):
     """
     Computes the L1 normalization of elements across given dimensions of the input tensor.
-    
+
     Parameters
     ----------
     x: <\*,T> (Required)
         * Must be 1-dimensional or higher.
-    
+
     axes: const<K,i32> (Optional, default="None", reduce on all axes.)
         * The dimensions to reduce.
-    
+
     keep_dims: const<bool> (Optional, default=False)
         * If ``False``, the rank is reduced by ``1`` for each entry in ``axes``,
           otherwise retain reduced axes with length ``1``.
-    
+
     Returns
     -------
     <\*,T>
         * Scalar or tensor: The reduced tensor.
-    
+
     Attributes
     ----------
     T: i32, fp16, fp32
-    
+
     References
     ----------
     See `reduce_mean <https://www.tensorflow.org/api_docs/python/tf/math/reduce_mean?version=stable>`_.
-    
+
     """
 
     def get_operator(self):
         def l1_norm(x, axis=None, keepdims=False):
             return np.sum(np.abs(x), axis=axis, keepdims=keepdims)
 
         return l1_norm
 
 
 @register_op
 class reduce_l2_norm(ReductionAxes):
     """
     Computes the L2 normalization of elements across given dimensions of the input tensor.
-    
+
     Parameters
     ----------
     x: <\*,T> (Required)
         * Must be 1-dimensional or higher.
-    
+
     axes: const<K,i32> (Optional, default="None", reduce on all axes.)
         * The dimensions to reduce.
-    
+
     keep_dims: const<bool> (Optional, default=False)
         * If ``False``, the rank is reduced by ``1`` for each entry in ``axes``,
           otherwise retain reduced axes with length ``1``.
-    
+
     Returns
     -------
     <\*,T>
         * Scalar or tensor: The reduced tensor.
-    
+
     Attributes
     ----------
     T: i32, fp16, fp32
     """
 
     def get_operator(self):
         def l2_norm(x, axis=None, keepdims=False):
@@ -276,32 +267,32 @@
 
 
 @register_op
 class reduce_log_sum(ReductionAxes):
     """
     Computes the natural logarithm of the sum of all the elements across given dimensions
     of the input tensor.
-    
+
     Parameters
     ----------
     x: <\*,T> (Required)
         * Must be 1-dimensional or higher.
-    
+
     axes: const<K,i32> (Optional, default="None", reduce on all axes.)
         * The dimensions to reduce.
-    
+
     keep_dims: const<bool> (Optional, default=False)
         * If ``False``, the rank is reduced by ``1`` for each entry in ``axes``,
           otherwise retain reduced axes with length ``1``.
-    
+
     Returns
     -------
     <\*,T>
         * Scalar or tensor: The reduced tensor.
-    
+
     Attributes
     ----------
     T: i32, fp16, fp32
     """
 
     def get_operator(self):
         def log_sum(x, axis=None, keepdims=False):
@@ -314,40 +305,40 @@
 class reduce_log_sum_exp(ReductionAxes):
     """
     Computes the natural logarithm of the sum of the exponentials of the elements across
     given dimensions of the input tensor. It is a smooth approximation of the maximum
     function, more numerically stable than ``log(sum(exp(input)))``. It avoids
     overflows caused by taking the ``exp`` of large inputs and underflows caused by
     taking the ``log`` of small inputs.
-    
+
     Parameters
     ----------
     x: <\*,T> (Required)
         * Must be 1-dimensional or higher.
-    
+
     axes: const<K,i32> (Optional, default="None", reduce on all axes.)
         * The dimensions to reduce.
-    
+
     keep_dims: const<bool> (Optional, default=False)
         * If ``False``, the rank is reduced by ``1`` for each entry in ``axes``,
           otherwise retain reduced axes with length ``1``.
-    
+
     Returns
     -------
     <\*,T>
         * Scalar or tensor: The reduced tensor.
-    
+
     Attributes
     ----------
     T: i32, fp16, fp32
-    
+
     References
     ----------
     See `tf.math.reduce_logsumexp <https://www.tensorflow.org/api_docs/python/tf/math/reduce_logsumexp>`_.
-    
+
     """
 
     def get_operator(self):
         def operator(a, axis=None, keepdims=False):
             max_values = np.amax(a, axis=axis, keepdims=True)
             temp = np.exp(a - max_values)
 
@@ -361,101 +352,101 @@
         return operator
 
 
 @register_op
 class reduce_max(ReductionAxes):
     """
     Computes the maximum of elements across given dimensions of the input tensor.
-    
+
     Parameters
     ----------
     x: <\*,T> (Required)
         * Must be 1-dimensional or higher.
-    
+
     axes: const<K,i32> (Optional, default="None", reduce on all axes.)
         * The dimensions to reduce.
-    
+
     keep_dims: const<bool> (Optional, default=False)
         * If ``False``, the rank is reduced by ``1`` for each entry in ``axes``,
           otherwise retain reduced axes with length ``1``.
-    
+
     Returns
     -------
     <\*,T>
         * Scalar or tensor: The reduced tensor.
-    
+
     Attributes
     ----------
     T: i32, fp16, fp32
     """
-    
+
     def __init__(self, **kwargs):
         super().__init__(**kwargs)
 
     def get_operator(self):
         return np.max
 
 
 @register_op
 class reduce_mean(ReductionAxes):
     """
     Computes the mean of elements across given dimensions of the input tensor.
-    
+
     Parameters
     ----------
     x: <\*,T> (Required)
         * Must be 1-dimensional or higher.
-    
+
     axes: const<K,i32> (Optional, default="None", reduce on all axes.)
         * The dimensions to reduce.
-    
+
     keep_dims: const<bool> (Optional, default=False)
         * If ``False``, the rank is reduced by ``1`` for each entry in ``axes``,
           otherwise retain reduced axes with length ``1``.
-    
+
     Returns
     -------
     <\*,T>
         * Scalar or tensor: The reduced tensor.
-    
+
     Attributes
     ----------
     T: i32, fp16, fp32
-    
+
     References
     ----------
     For an example, see `tf.math.reduce_mean <https://www.tensorflow.org/api_docs/python/tf/math/reduce_mean?version=stable>`_.
     """
 
     def get_operator(self):
         return np.mean
 
 
 @register_op
 class reduce_min(ReductionAxes):
     """
     Computes the minimum of elements across given dimensions of the input tensor.
-    
+
     Parameters
     ----------
     x: <\*,T> (Required)
         * Must be 1-dimensional or higher.
-    
+
     axes: const<K,i32> (Optional, default="None", reduce on all axes.)
         * The dimensions to reduce.
-    
+
     keep_dims: const<bool> (Optional, default=False)
         * If ``False``, the rank is reduced by ``1`` for each entry in ``axes``,
           otherwise retain reduced axes with length ``1``.
-    
+
     Returns
     -------
     <\*,T>
         * Scalar or tensor: The reduced tensor.
-    
+
     Attributes
     ----------
     T: i32, fp16, fp32
     """
 
     def get_operator(self):
         return np.min
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/iOS15/scatter_gather.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS15/scatter_gather.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/iOS15/tensor_operation.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS15/tensor_operation.py`

 * *Files 2% similar despite different names*

```diff
@@ -35,15 +35,19 @@
 )
 
 
 @register_op
 class band_part(Operation):
     """
     Returns a tensor setting everything outside a center band to zeros for the innermost
-    matrix. Special cases:
+    matrix. That is,
+    band(m, n) = (lower < 0 || (m-n) <= lower) && (upper < 0 || (n-m) <= upper)
+    output[i, j, k, ..., m, n] = band(m, n) * input[i, j, k, ..., m, n]
+
+    Special cases:
 
     - ``band_part(x, 0, -1)`` returns upper triangular part.
     - ``band_part(x, -1, 0)`` returns lower triangular part.
     - ``band_part(x, 0, 0)`` returns diagonal.
 
     Parameters
     ----------
@@ -82,14 +86,27 @@
         return DefaultInputs(
             lower=-1,
             upper=-1)
 
     def type_inference(self):
         return self.x.sym_type
 
+    @precondition(allow=VALUE)
+    def value_inference(self):
+        M, N = self.x.val.shape[-2:]
+        band = np.zeros((M, N), dtype=types.nptype_from_builtin(self.x.sym_type))
+        num_lower = self.lower.val
+        num_upper = self.upper.val
+        for m in range(M):
+            for n in range(N):
+                band[m, n] = (num_lower < 0 or (m - n) <= num_lower) and (
+                    num_upper < 0 or (n - m) <= num_upper
+                )
+        return np.multiply(band, self.x.val)
+
 
 @register_op
 class cumsum(Operation):
     """
     Returns the cumulative sum of the input along the given axis.
 
     Parameters
@@ -483,15 +500,15 @@
 
     def type_inference(self):
         in_shape = self.x.shape
         ret_shape = list(in_shape)
         pad = self.pad
         if len(pad.shape) != 1:
             raise ValueError("Pad should be a 1D tensor!")
-        if self.mode and not self.mode.val in {'constant', 'reflect', 'replicate'}:
+        if self.mode and self.mode.val not in {"constant", "reflect", "replicate"}:
             raise ValueError("Pad mode should be one of {'constant', 'reflect', 'replicate'}")
 
         if pad.val is None:
             for i in range(self.pad.shape[0] // 2):
                 ret_shape[-self.pad.shape[0] // 2 + i] = get_new_symbol()
         else:
             pad = pad.val
@@ -1263,14 +1280,17 @@
                     "same data type. Got {}."
                 ).format(self.name, [x.dtype for x in self.values])
                 raise ValueError(msg)
 
         axis = self.axis.val
         if axis < 0:
             axis += (self.values[0].rank + 1)
+        rank = self.values[0].rank
+        if axis > rank:
+            raise ValueError(f"axis must in range [{-rank}, {rank}). Got {axis}")
         ret_shape = list(t_shape)
         ret_shape.insert(axis, num_tensors)
         return types.tensor(self.values[0].dtype, ret_shape)
 
     @precondition(allow=VALUE | SYMBOL | NONE)
     def value_inference(self):
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/iOS15/tensor_transformation.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS15/tensor_transformation.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,30 +1,35 @@
 #  Copyright (c) 2020, Apple Inc. All rights reserved.
 #
 #  Use of this source code is governed by a BSD-3-clause license that can be
 #  found in the LICENSE.txt file or at https://opensource.org/licenses/BSD-3-Clause
 
+from typing import List
+
 import numpy as np
 import sympy as sm
 
 from coremltools import _logger as logger
-from coremltools.converters.mil.mil import (Operation, get_new_symbol,
-                                            get_new_variadic_symbol,
-                                            precondition, types)
-from coremltools.converters.mil.mil.input_type import (DefaultInputs,
-                                                       InputSpec,
-                                                       TensorInputType)
+from coremltools.converters.mil.mil import (
+    Operation,
+    get_new_symbol,
+    get_new_variadic_symbol,
+    precondition,
+    types,
+)
+from coremltools.converters.mil.mil.input_type import DefaultInputs, InputSpec, TensorInputType
 from coremltools.converters.mil.mil.operation import SYMBOL, VALUE
 from coremltools.converters.mil.mil.ops.defs._op_reqs import register_op
-from coremltools.converters.mil.mil.ops.defs._utils import \
-    solve_slice_by_index_shape
-from coremltools.converters.mil.mil.types.symbolic import (any_symbolic,
-                                                           any_variadic,
-                                                           is_symbolic,
-                                                           isscalar)
+from coremltools.converters.mil.mil.ops.defs._utils import solve_slice_by_index_shape
+from coremltools.converters.mil.mil.types.symbolic import (
+    any_symbolic,
+    any_variadic,
+    is_symbolic,
+    isscalar,
+)
 
 
 @register_op
 class depth_to_space(Operation):
     """
     Rearrange elements in a tensor from depth (channel) into spatial dimensions.
 
@@ -210,47 +215,89 @@
 
     @precondition(allow=VALUE | SYMBOL)
     def value_inference(self):
         _, val = self._get_type_val()
         return val
 
     def _get_type_val(self):
-        x_type = self.x.dtype
-        x_shape = self.x.shape
-        x_vol = np.prod(x_shape)
+        count_neg_one = np.count_nonzero(self.shape.sym_val == -1)
+        if count_neg_one > 1:
+            raise ValueError(
+                f"Reshape op supports only one dimension to be -1, "
+                f"but got {count_neg_one} dimensions be -1."
+            )
+
+        if not any_symbolic(self.x.shape) and self.shape.val is not None:
+            ret_shape = self._infer_shape_static()
+        else:
+            ret_shape = self._infer_shape_dynamic()
+
+        ret_val = None
+        if self.x.val is not None and all(isscalar(a) and not is_symbolic(a) for a in ret_shape):
+            ret_val = reshape_with_symbol(self.x.val, ret_shape)
+        return types.tensor(self.x.dtype, tuple(ret_shape)), ret_val
+
+    @staticmethod
+    def replace_zeros_in_shape(from_shape: List[int], to_shape: List[int]) -> List[int]:
+        """Replaces 0s in `to_shape` by the corresponding dims in `from_shape`."""
+        if to_shape.count(0):
+            if len(from_shape) != len(to_shape):
+                raise ValueError(
+                    f"When there is 0 in shape, the rank of x ({len(from_shape)}) "
+                    f"must equal to the target shape len ({len(to_shape)})."
+                )
+            to_shape = [s if s != 0 else from_shape[dim] for dim, s in enumerate(to_shape)]
+        return to_shape
+
+    @staticmethod
+    def replace_neg_one_in_shape(from_shape: List[int], to_shape: List[int]) -> List[int]:
+        """Replaces -1 in `to_shape` by the corresponding dims in `from_shape`."""
+        if to_shape.count(-1):
+            neg_one_idx = to_shape.index(-1)
+            total_element_num = np.prod(from_shape)
+            remain_element_num = np.prod(
+                [dim for idx, dim in enumerate(to_shape) if idx != neg_one_idx]
+            )
+            infer_dim = total_element_num // remain_element_num
+            to_shape[neg_one_idx] = infer_dim
+        return to_shape
+
+    def _infer_shape_static(self):
+        from_shape = list(self.x.shape)
+        to_shape = list(self.shape.val)
+        to_shape = self.replace_zeros_in_shape(from_shape, to_shape)
+        to_shape = self.replace_neg_one_in_shape(from_shape, to_shape)
+        if np.prod(from_shape) != np.prod(to_shape):
+            raise ValueError(
+                f"Invalid target shape in `reshape` op ({from_shape} to {list(self.shape.val)})."
+            )
+        return to_shape
+
+    def _infer_shape_dynamic(self):
+        x_vol = np.prod(self.x.shape)
         # shape is const, and thus sym_val is not None
         sym_shape = self.shape.sym_val
         sym_shape = [get_new_symbol() if d == -1 else d for d in sym_shape]
         try:
             ret_shape = reshape.enforce_volumetric_constraint(x_vol, sym_shape)
         except:
             ret_shape = sym_shape
-        ret_val = None
-        if self.x.val is not None and all(isscalar(a) and not is_symbolic(a) for a in ret_shape):
-            ret_val = reshape_with_symbol(self.x.val, ret_shape)
-        return types.tensor(x_type, tuple(ret_shape)), ret_val
+        return ret_shape
 
     @staticmethod
     def enforce_volumetric_constraint(left_volume, inshape):
         left_symbols = set()
         if is_symbolic(left_volume):
             left_symbols = left_volume.free_symbols
         # Generally, we want to solve for right in terms of left. But this
         # is kinda annoying actually.
         shape = list(inshape)
 
         # Handling when reshape is given 0 instead of actual input
         # input tensor shape: [4, 3, 2], reshape:[0, -1], output tensor shape: [4, 6]
-        if shape.count(-1) > 1:
-            raise ValueError(
-                "Reshape op supports only one dimension to be -1. Given {}".format(
-                    shape.count(-1)
-                )
-            )
-
         infer_dim_index = shape.index(-1) if -1 in shape else None
         right_volume = 1
         for i in shape:
             if i != -1:
                 right_volume = right_volume * i
 
         if infer_dim_index:
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/iOS16/__init__.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS16/__init__.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,11 +1,12 @@
 #  Copyright (c) 2022, Apple Inc. All rights reserved.
 #
 #  Use of this source code is governed by a BSD-3-clause license that can be
 #  found in the LICENSE.txt file or at https://opensource.org/licenses/BSD-3-Clause
+
 from coremltools.converters.mil._deployment_compatibility import \
     AvailableTarget as target
 
 _IOS16_TARGET = target.iOS16
 
 from .constexpr_ops import (constexpr_affine_dequantize, constexpr_cast,
                             constexpr_lut_to_dense, constexpr_sparse_to_dense)
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/iOS16/constexpr_ops.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS16/constexpr_ops.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,12 @@
-# Copyright (c) 2022, Apple Inc. All rights reserved.
+#  Copyright (c) 2023, Apple Inc. All rights reserved.
+#
+#  Use of this source code is governed by a BSD-3-clause license that can be
+#  found in the LICENSE.txt file or at https://opensource.org/licenses/BSD-3-Clause
+
 import numpy as np
 
 from coremltools.converters.mil.mil import types
 from coremltools.converters.mil.mil.input_type import (InputSpec,
                                                        TensorInputType)
 from coremltools.converters.mil.mil.operation import Operation
 from coremltools.converters.mil.mil.ops.defs._op_reqs import register_op
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/iOS16/image_resizing.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS16/image_resizing.py`

 * *Files 25% similar despite different names*

```diff
@@ -17,18 +17,18 @@
     upsample_bilinear as _upsample_bilinear_iOS15
 from coremltools.converters.mil.mil.ops.defs.iOS16 import _IOS16_TARGET
 
 
 @register_op(opset_version=_IOS16_TARGET)
 class resample(_resample_iOS15):
     """
-    The iOS 16 version of ``resample`` supports float 16 coordinates.
-    
-    For the complete documentation, see the 
-    `iOS 15 version <#module-coremltools.converters.mil.mil.ops.defs.iOS15.image_resizing>`_.
+    This version of ``resample`` supports float 16 coordinates.
+
+    For complete documentation, see the
+    iOS 15 :py:class:`~.iOS15.image_resizing.resample`.
     """
     input_spec = InputSpec(
         x=TensorInputType(type_domain="T"),
         coordinates=TensorInputType(type_domain="U"),
         sampling_mode=TensorInputType(const=True, type_domain=types.str),
         padding_mode=TensorInputType(const=True, type_domain=types.str),
         padding_value=TensorInputType(const=True, type_domain="T"),
@@ -43,44 +43,47 @@
 
     def type_inference(self):
         return super().type_inference()
 
 @register_op(opset_version=_IOS16_TARGET)
 class upsample_bilinear(_upsample_bilinear_iOS15):
     """
-    iOS16 version of upsample_bilinear supports half_pixel_centers
+    This version of ``upsample_bilinear`` supports ``half_pixel_centers``.
+    For complete documentation, see the
+    iOS 15 :py:class:`~.iOS15.image_resizing.upsample_bilinear`.
 
-    Additional Parameters
+    Parameters
     ----------
     half_pixel_centers: const<bool> (Optional)
-        * Default to !align_corners if not provided
+        * Defaults to ``!align_corners`` if not provided.
     """
 
     input_spec = _upsample_bilinear_iOS15.input_spec + InputSpec(
         half_pixel_centers=TensorInputType(const=True, optional=True, type_domain=types.bool),
     )
 
     def default_inputs(self):
         return super().default_inputs() + DefaultInputs(half_pixel_centers=not self.align_corners.val)
 
 @register_op(opset_version=_IOS16_TARGET)
 class crop_resize(_crop_resize_iOS15):
     """
-    iOS16 version of crop_resize, which supports ``pad_value``
-    
-    Additional Parameters
+    This version differs from the iOS 15 :py:class:`~.iOS15.image_resizing.crop_resize`
+    by supporting ``pad_value`` as an additional parameter.
+
+    Parameters
     ----------
-    pad_value : const<T> (Optional, default=1.0)
-        * If the box indexes go beyond the input boundary, the input image is padded with pad_value.
-        * Defaults to 0.
-        * It is the same as extrapolation_value in tf.image.crop_and_resize.
+    pad_value : const<T> (Optional, default=0.0)
+        * If the box indexes go beyond the input boundary, the input image is padded with ``pad_value``.
+        * Defaults to ``0``.
+        * It is the same as ``extrapolation_value`` in `tf.image.crop_and_resize <https://www.tensorflow.org/api_docs/python/tf/image/crop_and_resize>`_.
 
     Attributes
     ----------
     T: fp16, fp32
     """
     input_spec = _crop_resize_iOS15.input_spec + InputSpec(
         pad_value=TensorInputType(const=True, optional=True, type_domain="T"),
     )
 
     def default_inputs(self):
-        return super().default_inputs() + DefaultInputs(pad_value=1.0)
+        return super().default_inputs() + DefaultInputs(pad_value=0.0)
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/iOS16/scatter_gather.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS16/scatter_gather.py`

 * *Files 6% similar despite different names*

```diff
@@ -13,28 +13,29 @@
 from coremltools.converters.mil.mil.ops.defs._utils import compute_gather
 from coremltools.converters.mil.mil.ops.defs.iOS16 import _IOS16_TARGET
 
 
 @register_op(opset_version=_IOS16_TARGET)
 class gather(Operation):
     """
-    An iOS16 version of gather
+    The iOS16 version.
+    This section documents only the differences between this version and the
+    iOS 15 :py:class:`~.iOS15.scatter_gather.gather`.
     
-    The new gather op supports `batch_dims`
-    similar to `tf.gather <https://www.tensorflow.org/api_docs/python/tf/gather>`_.
+    This version supports ``batch_dims``, similar to `tf.gather <https://www.tensorflow.org/api_docs/python/tf/gather>`_.
 
     Parameters
     ----------
     x: tensor<\*D, U> (Required)
     indices: tensor<\*N, I> (Required)
         * Indices values may be negative. More precisely, ``-D[axis]<= v < D[axis]`` for ``v`` in ``indices``.
     axis: const i32 (Optional. Default=``0``)
         * Negative axis is supported.
     batch_dims: const i32 (Optional. Default=``0``)
-        * The number of batch dimensions
+        * The number of batch dimensions.
 
     Returns
     -------
     tensor<\*K, T>
         * Where ``K = D[:axis] + N[batch_dims:] + D[axis+1:]``.
 
     Attributes
@@ -113,23 +114,26 @@
         out_shape = self.x.shape[:axis] + self.indices.shape[batch_dims:] + self.x.shape[axis + 1 :]
 
         return types.tensor(self.x.dtype, out_shape)
 
 @register_op(opset_version=_IOS16_TARGET)
 class gather_nd(Operation):
     """
-    An iOS16 version of gather_nd
-    The new gather_nd op supports `batch_dims`
+    The iOS16 version.
+    This section documents only the differences between this version and the
+    iOS 15 :py:class:`~.iOS15.scatter_gather.gather_nd`.
+
+    This version supports ``batch_dims``.
 
     Parameters
     ----------
     x: tensor<\*D, T> (Required)
     indices: tensor<\*K, i32> (Required)
     batch_dims: const i32 (Optional. Default=``0``)
-        * The number of batch dimensions
+        * The number of batch dimensions.
 
     Returns
     -------
     tensor<\*V, T>
         * ``V = K[:-1] + D[batch_dims + K[-1]:]``, where ``D = x.shape`` and ``K = indices.shape``.
 
     Attributes
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/iOS16/tensor_operation.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS16/tensor_operation.py`

 * *Files 0% similar despite different names*

```diff
@@ -16,15 +16,15 @@
     topk as _topk_iOS15
 from coremltools.converters.mil.mil.ops.defs.iOS16 import _IOS16_TARGET
 
 
 @register_op(opset_version=_IOS16_TARGET)
 class fill_like(Operation):
     """
-    Returns a tensor with the same size as the input tensor filled with a constant value.
+    Returns a tensor with the same shape as the input tensor filled with a constant value.
 
     Parameters
     ----------
     ref_tensor: tensor<\*?, T> (Required)
         * Input tensor.
     value: const<U> (Optional)
         * Default is ``0.0``.
@@ -41,15 +41,15 @@
     U: fp16, fp32, int32, bool
     """
 
     input_spec = InputSpec(
         ref_tensor=TensorInputType(type_domain="T"),
         value=TensorInputType(const=True, optional=True, type_domain="U"),
     )
-    
+
     type_domains = {
         "T": (types.fp16, types.fp32, types.int32, types.bool),
         "U": (types.fp16, types.fp32, types.int32, types.bool),
     }
 
     def default_inputs(self):
         return DefaultInputs(
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/ops/defs/iOS16/tensor_transformation.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/ops/defs/iOS16/tensor_transformation.py`

 * *Files 1% similar despite different names*

```diff
@@ -140,29 +140,29 @@
 
         return types.tensor(self.x.dtype, out_shape)
 
 @register_op(opset_version=_IOS16_TARGET)
 class pixel_unshuffle(Operation):
     """
     Rearrange elements in a tensor from spatial dimensions into depth (channel).
-    It is basically the inverse operation of `pixel_shuffle <#coremltools.converters.mil.mil.ops.defs.iOS15.tensor_transformation.pixel_shuffle>`_.
-    Equivalent to PyTorch's ``PixelUnshuffle``.
+    It is basically the inverse operation of :py:class:`~.iOS15.tensor_transformation.pixel_shuffle`.
+    Equivalent to `PyTorch PixelUnshuffle <https://pytorch.org/docs/stable/generated/torch.nn.PixelUnshuffle.html#pixelunshuffle>`_.
 
     Parameters
     ----------
     x: tensor<[n, C, H / f , W / f], T> (Required)
         * Input tensor of rank ``4``.
 
     downscale_factor: const<i32>
         * Factor to decrease spatial resolution by.
 
     Returns
     -------
     tensor<[n, C * f^2, H, W], T>
-        * Where ``f`` is the downscale factor.
+        * In which ``f`` is the downscale factor.
 
     Attributes
     ----------
     T: fp16, fp32
 
     References
     ----------
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/ops/registry.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/ops/registry.py`

 * *Files 1% similar despite different names*

```diff
@@ -52,15 +52,16 @@
     (3) custom_ops: dict[str, Operation]
         - These are the custom ops, in which an additional ``bindings`` which should be specificed in operator
     """
     SUPPORTED_OPSET_VERSIONS = (
         target.iOS13,
         target.iOS14,
         target.iOS15,
-        target.iOS16
+        target.iOS16,
+        target.iOS17,
     )
     core_ops = defaultdict(dict)
     dialect_ops = {}
     custom_ops = {}
 
     @staticmethod
     def _get_core_op_cls(op_type=None):
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/ops/tests/test_activation.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/ops/tests/test_activation.py`

 * *Files 19% similar despite different names*

```diff
@@ -5,14 +5,15 @@
 
 import itertools
 
 import numpy as np
 import pytest
 import scipy
 
+import coremltools as ct
 from coremltools.converters.mil import testing_reqs
 from coremltools.converters.mil.mil import Builder as mb
 from coremltools.converters.mil.mil import types
 from coremltools.converters.mil.testing_utils import ssa_fn
 
 from .testing_utils import run_compare_builder
 
@@ -388,22 +389,19 @@
     @ssa_fn
     def test_builder_eval(self):
         x_val = np.array([[[[-1, 3, 6]], [[-1, 2, -3]], [[4, -5, 6]]]], dtype=np.float32)
         alpha = np.array([1, 2, 3], dtype=np.float32)
         v = mb.prelu(x=x_val, alpha=alpha)
 
         alpha_br = alpha
-
-        for i in range(1, len(x_val.shape)):
-            alpha_br = np.expand_dims(alpha_br, i)
-
-        x_pos = np.maximum(x_val, 0)
-        b = np.minimum(x_val, 0)
-
-        np.testing.assert_allclose(x_pos + b * alpha_br, v.val, atol=1e-04, rtol=1e-05)
+        for i in range(len(x_val.shape)):
+            if i != 1:
+                alpha_br = np.expand_dims(alpha_br, i)
+        expected_res = np.maximum(x_val, 0) + np.minimum(x_val, 0) * alpha_br
+        np.testing.assert_allclose(expected_res, v.val, atol=1e-04, rtol=1e-05)
 
     @ssa_fn
     def test_builder_eval1(self):
         x_val = np.array([[[-1, 3, 6]], [[-1, 2, -3]], [[4, -5, 6]]], dtype=np.float32)
         with pytest.raises(ValueError, match=r".* dimension 1 .*"):
             mb.prelu(x=x_val, alpha=np.array([1, 2], dtype=np.float32))
 
@@ -818,20 +816,21 @@
             x=x_val,
             alpha=np.array([1, 2, 3], dtype=np.float32),
             beta=np.array([4, 5, 6], dtype=np.float32),
         )
 
         alpha_br = np.array([1, 2, 3], dtype=np.float32)
         beta_br = np.array([4, 5, 6], dtype=np.float32)
-        for i in range(1, len(x_val.shape)):
-            alpha_br = np.expand_dims(alpha_br, i)
-            beta_br = np.expand_dims(beta_br, i)
-        out = alpha_br * np.log(np.exp(x_val * beta_br) + 1)
+        for i in range(len(x_val.shape)):
+            if i != 1:
+                alpha_br = np.expand_dims(alpha_br, i)
+                beta_br = np.expand_dims(beta_br, i)
+        expected_res = alpha_br * np.log(np.exp(x_val * beta_br) + 1)
 
-        np.testing.assert_allclose(out, v.val, atol=1e-04, rtol=1e-05)
+        np.testing.assert_allclose(expected_res, v.val, atol=1e-04, rtol=1e-05)
 
     @ssa_fn
     def test_builder_eval2(self):
         x_val = np.array([[[-1, 3, 6]], [[-1, 2, -3]], [[4, -5, 6]]], dtype=np.float32)
         with pytest.raises(ValueError, match=r".* dimension 1 .*"):
             mb.softplus_parametric(
                 x=x_val,
@@ -1074,7 +1073,177 @@
             input_placeholders,
             input_values,
             expected_output_types,
             expected_outputs=expected_outputs,
             compute_unit=compute_unit,
             backend=backend,
         )
+
+
+class TestInputWeightDifferentDtypes:
+    """
+    Starting from IOS17 the alpha/beta can have different dtypes from the input/output, so this
+    test class is mainly to verify the behaviour of those alpha/beta related activations.
+    """
+
+    @pytest.mark.parametrize(
+        "opset_version, different_dtype, op_name",
+        itertools.product(
+            [None, ct.target.iOS17],
+            [True, False],
+            ["elu", "leaky_relu", "prelu", "thresholded_relu"],
+        ),
+    )
+    def test_builder_eval_alpha(self, opset_version, different_dtype, op_name):
+        x = np.array([[[-1, 2, -3], [4, -5, 6]]], dtype=np.float32)
+        alpha = np.float16(2.0) if different_dtype else np.float32(2.0)
+        if op_name == "prelu":
+            alpha = np.array([2.0, 2.0], dtype=alpha.dtype)  # prelu requires alpha to be rank 1.
+
+        def prog():
+            return getattr(mb, op_name)(x=x, alpha=alpha)
+
+        if different_dtype and opset_version != ct.target.iOS17:
+            # Before iOS17 it should raise error when alpha has different dtype than input/output.
+            with pytest.raises(ValueError, match="must have the same data type"):
+                mb.program(input_specs=[], opset_version=opset_version)(prog)
+        else:
+            mb.program(input_specs=[], opset_version=opset_version)(prog)
+
+    @pytest.mark.parametrize(
+        "opset_version, different_dtype, op_name",
+        itertools.product(
+            [None, ct.target.iOS17],
+            [True, False],
+            [
+                "clamped_relu",
+                "linear_activation",
+                "scaled_tanh",
+                "sigmoid_hard",
+                "softplus_parametric",
+            ],
+        ),
+    )
+    def test_builder_eval_alpha_beta(self, opset_version, different_dtype, op_name):
+        x = np.array([[[-1, 2, -3], [4, -5, 6]]], dtype=np.float32)
+        alpha = np.float16(2.0) if different_dtype else np.float32(2.0)
+        beta = np.float16(1.0) if different_dtype else np.float32(1.0)
+        if op_name == "softplus_parametric":
+            alpha = np.array([2.0, 2.0], dtype=alpha.dtype)
+            beta = np.array([1.0, 1.0], dtype=beta.dtype)
+
+        def prog():
+            return getattr(mb, op_name)(x=x, alpha=alpha, beta=beta)
+
+        if different_dtype and opset_version != ct.target.iOS17:
+            with pytest.raises(ValueError, match="must have the same data type"):
+                mb.program(input_specs=[], opset_version=opset_version)(prog)
+        else:
+            mb.program(input_specs=[], opset_version=opset_version)(prog)
+
+    @pytest.mark.parametrize(
+        "compute_unit, different_dtype, op_name",
+        itertools.product(
+            compute_units, [True, False], ["elu", "leaky_relu", "prelu", "thresholded_relu"]
+        ),
+    )
+    def test_builder_to_backend_numerical_alpha(self, compute_unit, different_dtype, op_name):
+        x = np.array([[[-1, 2, -3], [4, -5, 6]]], dtype=np.float32)
+        alpha = np.float16(2.0) if different_dtype else np.float32(2.0)
+        if op_name == "prelu":
+            alpha = np.array([2.0, 2.0], dtype=alpha.dtype)
+
+        def calculate_by_np():
+            if op_name == "elu":
+                res = np.copy(x)
+                res[res < 0] = alpha * (np.exp(res[res < 0]) - 1)
+                return res
+            elif op_name == "leaky_relu":
+                res = np.copy(x)
+                res[res < 0] *= 2.0
+                return res
+            elif op_name == "prelu":
+                alpha_br = np.copy(alpha)
+                for i in range(len(x.shape)):
+                    if i != 1:
+                        alpha_br = np.expand_dims(alpha_br, i)
+                res = np.maximum(x, 0) + np.minimum(x, 0) * alpha_br
+                return res
+            elif op_name == "thresholded_relu":
+                res = np.copy(x)
+                res[res < alpha] = 0.0
+                return res
+            else:
+                raise ValueError(f"Invalid op_name: {op_name}")
+
+        def build(x):
+            return getattr(mb, op_name)(x=x, alpha=alpha)
+
+        run_compare_builder(
+            build,
+            input_placeholders={"x": mb.placeholder(shape=x.shape)},
+            input_values={"x": x},
+            expected_output_types=x.shape + (types.fp32,),
+            expected_outputs=calculate_by_np(),
+            compute_unit=compute_unit,
+            backend=("mlprogram", "fp16"),
+            minimum_deployment_target=ct.target.iOS17,
+        )
+
+    @pytest.mark.parametrize(
+        "compute_unit, different_dtype, op_name",
+        itertools.product(
+            compute_units,
+            [True, False],
+            [
+                "clamped_relu",
+                "linear_activation",
+                "scaled_tanh",
+                "sigmoid_hard",
+                "softplus_parametric",
+            ],
+        ),
+    )
+    def test_builder_to_backend_numerical_alpha_beta(self, compute_unit, different_dtype, op_name):
+        x = np.array([[[-1, 2, -3], [4, -5, 6]]], dtype=np.float32)
+        alpha = np.float16(2.0) if different_dtype else np.float32(2.0)
+        beta = np.float16(1.0) if different_dtype else np.float32(1.0)
+        if op_name == "softplus_parametric":
+            alpha = np.array([2.0, 2.0], dtype=alpha.dtype)
+            beta = np.array([1.0, 1.0], dtype=beta.dtype)
+
+        def calculate_by_np():
+            if op_name == "clamped_relu":
+                return np.minimum(np.maximum(x, 0), beta) + np.minimum(
+                    np.minimum(x, 0) * alpha, beta
+                )
+            elif op_name == "linear_activation":
+                return x * alpha + beta
+            elif op_name == "scaled_tanh":
+                return alpha * np.tanh(x * beta)
+            elif op_name == "sigmoid_hard":
+                return np.minimum(np.maximum((alpha * x) + beta, 0), 1)
+            elif op_name == "softplus_parametric":
+                alpha_br = alpha
+                beta_br = beta
+                for i in range(len(x.shape)):
+                    if i != 1:
+                        alpha_br = np.expand_dims(alpha_br, i)
+                        beta_br = np.expand_dims(beta_br, i)
+                res = alpha_br * np.log(np.exp(x * beta_br) + 1)
+                return res
+            else:
+                raise ValueError(f"Invalid op_name: {op_name}")
+
+        def build(x):
+            return getattr(mb, op_name)(x=x, alpha=alpha, beta=beta)
+
+        run_compare_builder(
+            build,
+            input_placeholders={"x": mb.placeholder(shape=x.shape)},
+            input_values={"x": x},
+            expected_output_types=x.shape + (types.fp32,),
+            expected_outputs=calculate_by_np(),
+            compute_unit=compute_unit,
+            backend=("mlprogram", "fp16"),
+            minimum_deployment_target=ct.target.iOS17,
+        )
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/ops/tests/test_const.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/ops/tests/test_const.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/ops/tests/test_constexpr_ops.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/ops/tests/test_constexpr_ops.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/ops/tests/test_control_flow.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/ops/tests/test_control_flow.py`

 * *Files 8% similar despite different names*

```diff
@@ -5,19 +5,19 @@
 
 import itertools
 
 import numpy as np
 import pytest
 
 from coremltools.converters.mil.mil import Builder as mb
-from coremltools.converters.mil.mil import types
+from coremltools.converters.mil.mil import get_new_symbol, types
 from coremltools.converters.mil.testing_reqs import backends, compute_units
 from coremltools.converters.mil.testing_utils import random_gen, ssa_fn
 
-from .testing_utils import UNK_SYM, run_compare_builder
+from .testing_utils import UNK_SYM, construct_inputs_from_placeholders, run_compare_builder
 
 
 class TestSelect:
     @pytest.mark.parametrize(
         "compute_unit, backend", itertools.product(compute_units, backends)
     )
     def test_builder_to_backend_smoke(self, compute_unit, backend):
@@ -50,19 +50,20 @@
             expected_output_types,
             expected_outputs,
             compute_unit=compute_unit,
             backend=backend,
         )
 
     @pytest.mark.parametrize(
-        "compute_unit, backend", itertools.product(compute_units, backends)
+        "compute_unit, backend",
+        itertools.product(compute_units, backends),
     )
     def test_builder_to_backend_smoke_broadcast(self, compute_unit, backend):
         cond_val = np.array([[1], [0], [2]], dtype=np.float32)
-        a_val = np.array([[3, 1, 1], [1, 4, 1], [5, 6, 1]], dtype=np.float32)
+        a_val = np.array([1, 7, 8], dtype=np.float32)
         b_val = np.array([[3, 2, 2], [2, 4, 2], [5, 6, 2]], dtype=np.float32)
         input_placeholders = {
             "cond": mb.placeholder(shape=cond_val.shape),
             "a": mb.placeholder(shape=a_val.shape),
             "b": mb.placeholder(shape=b_val.shape),
         }
         input_values = {"cond": cond_val, "a": a_val, "b": b_val}
@@ -70,45 +71,112 @@
         def build(cond, a, b):
             if not types.is_bool(cond.dtype):
                 cond = mb.cast(x=cond, dtype="bool")
             return [mb.select(cond=cond, a=a, b=b)]
 
         expected_output_types = [(3, 3, types.fp32)]
         expected_outputs = [
-            np.array(
-                [[3.0, 1.0, 1.0], [2.0, 4.0, 2.0], [5.0, 6.0, 1.0]], dtype=np.float32
-            )
+            np.array([[1.0, 7.0, 8.0], [2.0, 4.0, 2.0], [1.0, 7.0, 8.0]], dtype=np.float32)
         ]
 
         run_compare_builder(
             build,
             input_placeholders,
             input_values,
             expected_output_types,
             expected_outputs,
             compute_unit=compute_unit,
             backend=backend,
         )
 
+    @pytest.mark.parametrize(
+        "compute_unit, backend",
+        itertools.product(compute_units, backends),
+    )
+    def test_builder_to_backend_smoke_scalar_and_tensor(self, compute_unit, backend):
+        cond_val = np.array([[1], [0], [2]], dtype=np.float32)
+        a_val = np.float32(1.0)
+        b_val = np.array([[3, 2, 2], [2, 4, 2], [5, 6, 2]], dtype=np.float32)
+        input_placeholders = {
+            "cond": mb.placeholder(shape=cond_val.shape),
+            "b": mb.placeholder(shape=b_val.shape),
+        }
+        input_values = {"cond": cond_val, "b": b_val}
+
+        def build(cond, b):
+            if not types.is_bool(cond.dtype):
+                cond = mb.cast(x=cond, dtype="bool")
+            return [mb.select(cond=cond, a=a_val, b=b)]
+
+        expected_output_types = [(3, 3, types.fp32)]
+        expected_outputs = [
+            np.array([[1.0, 1.0, 1.0], [2.0, 4.0, 2.0], [1.0, 1.0, 1.0]], dtype=np.float32)
+        ]
+
+        run_compare_builder(
+            build,
+            input_placeholders,
+            input_values,
+            expected_output_types,
+            expected_outputs,
+            compute_unit=compute_unit,
+            backend=backend,
+        )
+
+    @pytest.mark.parametrize(
+        "compute_unit, backend",
+        itertools.product(compute_units, backends),
+    )
+    def test_builder_to_backend_smoke_symbolic(self, compute_unit, backend):
+        SYMBOLIC_SHAPE = tuple([get_new_symbol() for _ in range(5)])
+        VALUE = 100.0
+
+        input_placeholders = {"a": mb.placeholder(shape=SYMBOLIC_SHAPE)}
+
+        def build(a):
+            return [mb.select(cond=False, a=a, b=np.float32(VALUE))]
+
+        shape = tuple(np.random.randint(1, 5, size=len(SYMBOLIC_SHAPE)))
+        a = np.random.rand(*shape)
+        input_values = {"a": a}
+
+        run_compare_builder(
+            build,
+            input_placeholders,
+            input_values,
+            expected_output_types=[SYMBOLIC_SHAPE + (types.fp32,)],
+            expected_outputs=[VALUE],
+            inputs=construct_inputs_from_placeholders(input_placeholders, upper_bound=10),
+            compute_unit=compute_unit,
+            backend=backend,
+        )
+
     @ssa_fn
     def test_builder_eval(self):
         cond = np.random.randint(low=0, high=2, size=(6, 1, 7)).astype(bool)
         a = random_gen(shape=(6, 1, 7), rand_min=-1962.0, rand_max=0.0)
         b = random_gen(shape=(6, 1, 7), rand_min=0.0, rand_max=1964.0)
         res = mb.select(cond=cond, a=a, b=b)
         np.testing.assert_allclose(np.where(cond, a, b), res.val, atol=1e-04, rtol=1e-05)
 
     @ssa_fn
     def test_builder_eval_broadcast(self):
         cond = np.array([[True], [False], [True]])
         a = np.array([[1, 2], [3, 4], [5, 6]], dtype=np.float32)
-        b = np.array([[7, 8], [9, 10], [11, 12]], dtype=np.float32)
+        b = np.array([7, 8], dtype=np.float32)
         res = mb.select(cond=cond, a=a, b=b)
-        np.testing.assert_allclose(np.array([[1, 2], [9, 10], [5, 6]], dtype=np.float32), res.val, atol=1e-04, rtol=1e-05)
+        np.testing.assert_allclose(
+            np.array([[1, 2], [7, 8], [5, 6]], dtype=np.float32), res.val, atol=1e-04, rtol=1e-05
+        )
 
+    @ssa_fn
+    def test_builder_eval_scalar(self):
+        res = mb.select(cond=True, a=np.float32(1), b=np.float32(2))
+        assert isinstance(res.val, np.float32)
+        np.testing.assert_allclose(np.float32(1), res.val)
 
 class TestCond:
     @pytest.mark.parametrize(
         "compute_unit, backend", itertools.product(compute_units, backends,)
     )
     def test_builder_to_backend_smoke(self, compute_unit, backend):
         input_placeholders = {
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/ops/tests/test_conv.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/ops/tests/test_conv.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/ops/tests/test_elementwise_binary.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/ops/tests/test_elementwise_binary.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/ops/tests/test_elementwise_unary.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/ops/tests/test_elementwise_unary.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,24 +1,26 @@
 #  Copyright (c) 2020, Apple Inc. All rights reserved.
 #
 #  Use of this source code is governed by a BSD-3-clause license that can be
 #  found in the LICENSE.txt file or at https://opensource.org/licenses/BSD-3-Clause
 
 import itertools
+from unittest.mock import patch
 
 import numpy as np
 import pytest
 import scipy
 
+import coremltools as ct
 from coremltools.converters.mil import testing_reqs
 from coremltools.converters.mil.mil import Builder as mb
-from coremltools.converters.mil.mil import (Function, get_new_symbol,
-                                            types)
-from coremltools.converters.mil.mil.types.symbolic import \
-    is_compatible_symbolic_vector
+from coremltools.converters.mil.mil import Function, get_new_symbol, types
+from coremltools.converters.mil.mil.passes.pass_pipeline import PassPipeline
+from coremltools.converters.mil.mil.types.symbolic import is_compatible_symbolic_vector
+from coremltools.converters.mil.mil.var import Var
 from coremltools.converters.mil.testing_utils import ssa_fn
 
 from .testing_utils import run_compare_builder
 
 backends = testing_reqs.backends
 compute_units = testing_reqs.compute_units
 
@@ -667,14 +669,95 @@
             input_value_dict,
             expected_output_type,
             numpy_pred,
             compute_unit=compute_unit,
             backend=backend,
         )
 
+    @pytest.mark.parametrize(
+        "compute_unit, backend, src_dtype, dst_dtype",
+        itertools.product(
+            compute_units,
+            [("mlprogram", "fp16")],
+            [np.float16, np.float32, np.float64, np.int64, np.int32, np.int16, np.uint16],
+            [np.float16, np.float32, np.float64, np.int64, np.int32, np.int16, np.uint16],
+        ),
+    )
+    def test_builder_eval_cast_ios17(self, compute_unit, backend, src_dtype, dst_dtype):
+        x = np.array([[1, 2, 3], [4, 5, 6]], dtype=src_dtype)
+        dst_dtype_str = types.builtin_to_string(
+            types.type_mapping.numpy_type_to_builtin_type(dst_dtype)
+        )
+        expected_res = x.astype(dtype=np.float16)
+
+        @mb.program(input_specs=[], opset_version=ct.target.iOS17)
+        def prog():
+            return mb.cast(x=x, dtype=dst_dtype_str)
+
+        main_func = prog.functions["main"]
+        cast_op = main_func.find_ops(op_type="cast")[0]
+        np.testing.assert_allclose(expected_res, cast_op.outputs[0].val, atol=1e-04, rtol=1e-05)
+
+    @pytest.mark.parametrize(
+        "compute_unit, backend, src_dtype, dst_dtype",
+        itertools.product(
+            compute_units,
+            [("mlprogram", "fp16")],
+            [np.float16, np.float32, np.int16, np.int32, np.uint16],
+            [np.float16, np.float32, np.int16, np.int32, np.uint16],
+        ),
+    )
+    def test_builder_to_backend_cast_ios17(self, compute_unit, backend, src_dtype, dst_dtype):
+        _SUPPORTED_IO_DTYPES = {types.fp16, types.fp32, types.int32}
+        x = np.array([[1, 2, 3], [4, 5, 6]], dtype=src_dtype)
+        src_builtin_dtype = types.type_mapping.numpy_type_to_builtin_type(src_dtype)
+        dst_builtin_dtype = types.type_mapping.numpy_type_to_builtin_type(dst_dtype)
+        expected_res = x.astype(dtype=np.float16)
+
+        expected_cast_num = 1
+        if src_builtin_dtype not in _SUPPORTED_IO_DTYPES:
+            # A cast will be inserted for unsupported dtypes inputs.
+            expected_cast_num += 1
+
+        # As CoreML IO only allows fp16/32 and int32, the output will be further cast.
+        expected_res_builtin_dtype = dst_builtin_dtype
+        if dst_builtin_dtype not in _SUPPORTED_IO_DTYPES:
+            expected_res_builtin_dtype = (
+                types.int32 if types.is_int(dst_builtin_dtype) else types.fp32
+            )
+            expected_cast_num += 1
+
+        def build(x):
+            return mb.cast(x=x, dtype=types.builtin_to_string(dst_builtin_dtype))
+
+        with patch.object(Var, "_is_nonreplaceable_var") as mocked_is_nonreplaceable_var:
+            # Mock that the cast is non-replaceable, to make sure it's kept in the graph.
+            mocked_is_nonreplaceable_var.side_effect = (
+                lambda var: var.op and var.op.op_type == "cast"
+            )
+            # Remove the cast optimization pass to make sure all cast are kept in the graph.
+            pass_pipeline: PassPipeline = PassPipeline.DEFAULT
+            pass_pipeline.remove_passes(
+                ["common::cast_optimization", "common::topological_reorder"]
+            )
+            mlmodel = run_compare_builder(
+                build,
+                {"x": mb.placeholder(shape=x.shape, dtype=src_builtin_dtype)},
+                input_values={"x": x},
+                expected_output_types=x.shape + (expected_res_builtin_dtype,),
+                expected_outputs=expected_res,
+                compute_unit=compute_unit,
+                backend=backend,
+                minimum_deployment_target=ct.target.iOS17,
+                pass_pipeline=pass_pipeline,
+            )
+            prog = mlmodel._mil_program
+            cast_ops = prog["main"].find_ops(op_type="cast")
+            assert len(cast_ops) == expected_cast_num
+
     def test_erf_value_inference(self):
         INPUT_SIZE=(2, 3, 4)
         rs = np.random.RandomState(1234)
         x = rs.random(INPUT_SIZE)
 
         @mb.program(input_specs=[])
         def prog():
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/ops/tests/test_image_resizing.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/ops/tests/test_image_resizing.py`

 * *Files 3% similar despite different names*

```diff
@@ -257,15 +257,15 @@
 class TestUpsampleNearestNeighborFractionalScales:
     @pytest.mark.parametrize(
         "compute_unit, backend", itertools.product(compute_units, backends)
     )
     def test_builder_to_backend_smoke(self, compute_unit, backend):
         if backend[0] == "neuralnetwork":
             pytest.skip("nn backend not supported")
-        
+
         if backend[0] == "mlprogram" and compute_unit != ct.ComputeUnit.CPU_ONLY:
             pytest.xfail("rdar://97398448 (TestUpsampleNearestNeighborFractionalScales failing on GPU)")
 
         x_val = np.array([1.5, -2.5, 3.5], dtype=np.float32).reshape([1, 1, 1, 3])
         input_placeholder_dict = {"x": mb.placeholder(shape=x_val.shape)}
         input_value_dict = {"x": x_val}
 
@@ -486,15 +486,15 @@
                 scale_factor_height=2,
                 scale_factor_width=3,
                 align_corners=align_corners,
                 half_pixel_centers=half_pixel_centers,
             )
 
         expected_output_type = (1, 1, 2, 6, types.fp32)
-        
+
         if align_corners and not half_pixel_centers:
             expected_output = [1., 1.2, 1.4, 1.6, 1.8, 2., 1., 1.2, 1.4, 1.6, 1.8, 2.]
         elif not align_corners and half_pixel_centers:
             expected_output = [1., 1., 1.33334, 1.66667, 2., 2., 1., 1., 1.33334, 1.66667, 2., 2.]
         elif not align_corners and not half_pixel_centers:
             expected_output = [1., 1.33334, 1.66667, 2., 2., 2., 1., 1.33334, 1.66667, 2., 2., 2.]
         else:
@@ -699,52 +699,63 @@
             compute_unit=compute_unit,
             backend=backend,
         )
 
 
 class TestCropResize:
     @pytest.mark.parametrize(
-        "compute_unit, backend",
-        itertools.product(compute_units, backends),
+        "compute_unit, backend, pad_value",
+        itertools.product(compute_units, backends, [0.0, 1.0, 10.0]),
     )
-    def test_builder_to_backend_smoke_pad_value(self, compute_unit, backend):
-        if backend[0] == "neuralnetwork":
-            pytest.skip("pad_mode only supported on iOS16 or above")
-            
-        if ct.utils._macos_version() < (13, 0):
-            pytest.skip("pad_value not supported in macOS12 or older.")
-
+    def test_builder_to_backend_ios16(self, compute_unit, backend, pad_value):
+        """For iOS16+ the crop_resize op supports pad_value."""
         x = np.array(
             [[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15, 16]],
             dtype=np.float32,
         ).reshape(1, 1, 4, 4)
 
         roi = np.array([
             [0, 0.1, 0.3, 1.3, 1],
             [0, 0.5, 1.8, 1., 0.3],
             [0, 0.0, 0.4, 0.6, 0.7],
         ], dtype=np.float32).reshape(3, 1, 5, 1, 1)
-        
+
         def build(x):
             return mb.crop_resize(
-                    x=x,
-                    roi=roi,
-                    target_width=2,
-                    target_height=2,
-                    normalized_coordinates=True,
-                    box_coordinate_mode="CORNERS_HEIGHT_FIRST",
-                    sampling_mode="ALIGN_CORNERS",
-                    pad_value=10.0,
+                x=x,
+                roi=roi,
+                target_width=2,
+                target_height=2,
+                normalized_coordinates=True,
+                box_coordinate_mode="CORNERS_HEIGHT_FIRST",
+                sampling_mode="ALIGN_CORNERS",
+                pad_value=pad_value,
             )
-        
+
         expected_output_type = [
             (3, 1, 1, 2, 2, types.fp32),
         ]
         expected_output = [
-            np.array([ 3.1, 5.2, 10, 10, 10, 7.899, 10, 13.9, 2.2, 3.1, 9.4, 10.3], dtype=np.float32).reshape(3, 1, 1, 2, 2),
+            np.array(
+                [
+                    3.1,
+                    5.2,
+                    pad_value,
+                    pad_value,
+                    pad_value,
+                    7.899,
+                    pad_value,
+                    13.9,
+                    2.2,
+                    3.1,
+                    9.4,
+                    10.3,
+                ],
+                dtype=np.float32,
+            ).reshape(3, 1, 1, 2, 2),
         ]
 
         input_placeholder_dict = {"x": mb.placeholder(shape=(1, 1, 4, 4))}
         input_value_dict = {"x": x}
 
         run_compare_builder(
             build,
@@ -752,19 +763,18 @@
             input_value_dict,
             expected_output_type,
             expected_output,
             compute_unit=compute_unit,
             backend=backend,
             minimum_deployment_target=ct.target.iOS16,
         )
-        
-        
+
     @pytest.mark.parametrize(
         "compute_unit, backend, is_symbolic",
-        itertools.product(compute_units, backends, compute_units),
+        itertools.product(compute_units, backends, [True, False]),
     )
     def test_builder_to_backend_smoke(self, compute_unit, backend, is_symbolic):
         if backend[0] == "mlprogram" and compute_unit != ct.ComputeUnit.CPU_ONLY:
             pytest.xfail("rdar://97398582 (TestCropResize failing on mlprogram + GPU)")
         x = np.array(
             [[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15, 16]],
             dtype=np.float32,
@@ -917,18 +927,123 @@
             np.array([8.5], dtype=np.float32).reshape(1, 1, 1, 1, 1),
             np.array([1, 2, 5, 6], dtype=np.float32).reshape(1, 1, 1, 2, 2),
             np.array([11, 10, 7, 6], dtype=np.float32).reshape(1, 1, 1, 2, 2),
             np.array([3.5, 5.5, 11.5, 13.5], dtype=np.float32).reshape(1, 1, 1, 2, 2),
         ]
 
         for mode in range(6):
-            # nn-proto does not support UNALIGN_CORNERS
-            if not (backend[0] == 'neuralnetwork' and mode == 5):
-                run_compare_builder(
-                    functools.partial(build, mode=mode),
-                    input_placeholder_dict,
-                    input_value_dict,
-                    expected_output_type[mode],
-                    expected_output[mode],
-                    compute_unit=compute_unit,
-                    backend=backend,
-                )
+            if backend[0] == "neuralnetwork" and mode == 5:
+                pytest.skip("nn-proto does not support UNALIGN_CORNERS")
+            run_compare_builder(
+                functools.partial(build, mode=mode),
+                input_placeholder_dict,
+                input_value_dict,
+                expected_output_type[mode],
+                expected_output[mode],
+                compute_unit=compute_unit,
+                backend=backend,
+            )
+
+    @pytest.mark.parametrize(
+        "compute_unit, backend, N",
+        itertools.product(compute_units, backends, [1, 3]),
+    )
+    def test_builder_to_backend_ios17(self, compute_unit, backend, N):
+        """For iOS17+ the `roi` input is replaced by `boxes` and `box_indices`."""
+        x = np.arange(1, 17, dtype=np.float32).reshape(1, 1, 4, 4)
+        boxes = np.array([1, 1, 2, 2], dtype=np.float32).reshape(1, 4)
+        box_indices = None
+        normalized_coordinates = False
+        if N == 3:
+            boxes = np.array(
+                [
+                    [0.1, 0.3, 1.3, 1.0],
+                    [0.5, 1.8, 1.0, 0.3],
+                    [0.0, 0.4, 0.6, 0.7],
+                ],
+                dtype=np.float32,
+            )
+            box_indices = np.array([0] * 3, dtype=np.int32)
+            normalized_coordinates = True
+
+        def build(x):
+            return mb.crop_resize(
+                x=x,
+                boxes=boxes,
+                box_indices=box_indices,
+                target_width=2,
+                target_height=2,
+                normalized_coordinates=normalized_coordinates,
+                box_coordinate_mode="CORNERS_HEIGHT_FIRST",
+                sampling_mode="ALIGN_CORNERS",
+                pad_value=10.0,
+            )
+
+        expected_outputs = [np.array([6, 7, 10, 11], dtype=np.float32).reshape(1, 1, 2, 2)]
+        if N == 3:
+            expected_outputs = [
+                np.array(
+                    [3.1, 5.2, 10.0, 10.0, 10.0, 7.899, 10.0, 13.9, 2.2, 3.1, 9.4, 10.3],
+                    dtype=np.float32,
+                ).reshape(3, 1, 2, 2)
+            ]
+
+        run_compare_builder(
+            build,
+            input_placeholders={"x": mb.placeholder(shape=(1, 1, 4, 4))},
+            input_values={"x": x},
+            expected_output_types=[(N, 1, 2, 2, types.fp32)],
+            expected_outputs=expected_outputs,
+            compute_unit=compute_unit,
+            backend=backend,
+            minimum_deployment_target=ct.target.iOS17,
+        )
+
+    def test_builder_eval_ios17_invalid(self):
+        x = np.arange(1, 17, dtype=np.float32).reshape(1, 1, 4, 4)
+        three_boxes = np.array(
+            [
+                [0.1, 0.3, 1.3, 1.0],
+                [0.5, 1.8, 1.0, 0.3],
+                [0.0, 0.4, 0.6, 0.7],
+            ],
+            dtype=np.float32,
+        )
+        with pytest.raises(
+            ValueError,
+            match='N dimension of "boxes" \(3\) should not be greater '
+            'than the B dimension of "x" \(1\)',
+        ):
+
+            @mb.program(input_specs=[], opset_version=ct.target.iOS17)
+            def prog():
+                return mb.crop_resize(x=x, boxes=three_boxes)
+
+        one_box = np.array([1, 1, 2, 2], dtype=np.float32).reshape(1, 4)
+        indices_out_of_bound = np.array([10], dtype=np.int32)
+        with pytest.raises(
+            ValueError,
+            match='input "box_indices" should not have values >= B '
+            "dimension of x \(1\), but got \[10\]",
+        ):
+
+            @mb.program(input_specs=[], opset_version=ct.target.iOS17)
+            def prog():
+                return mb.crop_resize(x=x, boxes=one_box, box_indices=indices_out_of_bound)
+
+        indices_two_dim = np.array([[0]], dtype=np.int32)
+        with pytest.raises(
+            ValueError, match='input "box_indices" must has shape \[1\], but got \(1, 1\)'
+        ):
+
+            @mb.program(input_specs=[], opset_version=ct.target.iOS17)
+            def prog():
+                return mb.crop_resize(x=x, boxes=one_box, box_indices=indices_two_dim)
+
+        x_rank5 = np.arange(1, 17, dtype=np.float32).reshape(1, 1, 4, 4, 1)
+        with pytest.raises(
+            ValueError, match='input to the "crop_resize" op must be of rank 4, but got 5'
+        ):
+
+            @mb.program(input_specs=[], opset_version=ct.target.iOS17)
+            def prog():
+                return mb.crop_resize(x=x_rank5, boxes=one_box)
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/ops/tests/test_linear.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/ops/tests/test_linear.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/ops/tests/test_normalization.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/ops/tests/test_normalization.py`

 * *Files 1% similar despite different names*

```diff
@@ -6,22 +6,21 @@
 import itertools
 import platform
 
 import numpy as np
 import pytest
 
 import coremltools as ct
-from coremltools._deps import (_HAS_TF_2, _HAS_TORCH, MSG_TF2_NOT_FOUND,
-                               MSG_TORCH_NOT_FOUND)
+from coremltools._deps import _HAS_TF_2, _HAS_TORCH, MSG_TF2_NOT_FOUND, MSG_TORCH_NOT_FOUND
 from coremltools.converters.mil.mil import Builder as mb
 from coremltools.converters.mil.mil import Function, get_new_symbol, types
 from coremltools.converters.mil.testing_reqs import backends, compute_units
 from coremltools.converters.mil.testing_utils import random_gen
 
-from .testing_utils import UNK_SYM, run_compare_builder
+from .testing_utils import UNK_SYM, construct_inputs_from_placeholders, run_compare_builder
 
 if _HAS_TORCH:
     import torch
 
 if _HAS_TF_2:
     import tensorflow as tf
 
@@ -522,14 +521,17 @@
 
         run_compare_builder(
             build,
             input_placeholders,
             input_values,
             expected_output_types,
             expected_outputs,
+            inputs=construct_inputs_from_placeholders(input_placeholders, 10)
+            if backend[0] == "mlprogram"
+            else None,
             compute_unit=compute_unit,
             backend=backend,
         )
 
     @pytest.mark.parametrize(
         "compute_unit, backend, rank_and_axes, epsilon, provides_gamma_beta",
         itertools.product(
@@ -546,15 +548,15 @@
             [True, False]
         ),
         )
     def test_builder_to_backend_stress_numpy(self, compute_unit, backend, rank_and_axes, epsilon, provides_gamma_beta):
 
         if backend == ("mlprogram", "fp16") and compute_unit != ct.ComputeUnit.CPU_ONLY:
             pytest.xfail("rdar://80662357 ([GPU failures] LayerNorm FP16 tests failing on GPU with numerical errors)")
-            
+
         if backend[0] == "neuralnetwork" and compute_unit != ct.ComputeUnit.CPU_ONLY and platform.machine() == "arm64":
             pytest.xfail("rdar://98015195 ([M1 native tests] Some MIL unittests are failing on M1 native)")
 
         rank, axes = rank_and_axes
         shape = np.random.randint(low=2, high=6, size=rank)
         x_val = random_gen(shape=shape, rand_min=-100.0, rand_max=100.0)
         input_placeholders = {"x": mb.placeholder(shape=x_val.shape)}
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/ops/tests/test_pool.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/ops/tests/test_pool.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/ops/tests/test_random.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/ops/tests/test_random.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/ops/tests/test_recurrent.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/ops/tests/test_recurrent.py`

 * *Files 22% similar despite different names*

```diff
@@ -4,20 +4,22 @@
 #  found in the LICENSE.txt file or at https://opensource.org/licenses/BSD-3-Clause
 
 import itertools
 
 import numpy as np
 import pytest
 
+import coremltools as ct
 from coremltools._deps import _HAS_TORCH, MSG_TORCH_NOT_FOUND
 from coremltools.converters.mil.mil import Builder as mb
 from coremltools.converters.mil.mil import get_new_symbol, types
 from coremltools.converters.mil.testing_reqs import backends, compute_units
+from coremltools.converters.mil.testing_utils import ssa_fn
 
-from .testing_utils import run_compare_builder
+from .testing_utils import construct_inputs_from_placeholders, run_compare_builder
 
 if _HAS_TORCH:
     import torch
 
 
 class TestGRU:
     @pytest.mark.parametrize(
@@ -42,16 +44,16 @@
             # output(always 0) for second batch onwards
             [1, 2],
             [1, 2],
             [True, False],
             [True, False],
             ["forward", "reverse"],
             [
-                ["TANH", "SIGMOID"],
-                ["SIGMOID", "TANH"],
+                ["tanh", "sigmoid"],
+                ["sigmoid", "tanh"],
             ],
             [True, False],
         ),
     )
     def test_builder_to_backend_smoke(
         self,
         compute_unit,
@@ -75,25 +77,29 @@
         W_r = 2 * np.random.rand(hidden_size, input_size) - 1
         W_o = 2 * np.random.rand(hidden_size, input_size) - 1
         b_z = 2 * np.random.rand(hidden_size) - 1 if has_bias else np.zeros((hidden_size))
         b_r = 2 * np.random.rand(hidden_size) - 1 if has_bias else np.zeros((hidden_size))
         b_o = 2 * np.random.rand(hidden_size) - 1 if has_bias else np.zeros((hidden_size))
 
         def apply_act(x, option):
-            if option == 'TANH':
+            if option == "tanh":
                 return np.tanh(x)
-            elif option == 'SIGMOID':
-                return 1. / (1 + np.exp(-x))
+            elif option == "sigmoid":
+                return 1.0 / (1 + np.exp(-x))
             else:
                 raise ValueError("activation invalid")
 
-        def get_numpy_prediction_gru(X, H, return_seq, direction,
-                                     inner_activation_str='SIGMOID',
-                                     activation_str='TANH',
-                                     ):
+        def get_numpy_prediction_gru(
+            X,
+            H,
+            return_seq,
+            direction,
+            inner_activation_str="sigmoid",
+            activation_str="tanh",
+        ):
             """
             shape of X : (B, Seq, input_size)
 
             shape of H : (B, hidden_size)
 
             shape of return = (B, 1, hidden_size) if return_seq=False else (B, Seq, hidden_size)
             """
@@ -113,17 +119,17 @@
                         activation_str=activation_str,
                     )
                 )
             output = np.stack(out, axis=0)
             output = np.transpose(output, (1, 0, 2))
             return output, output[-1, :, :]
 
-        def get_numpy_prediction_gru_single_batch(X, h, return_seq, direction,
-                                                  inner_activation_str='SIGMOID',
-                                                  activation_str='TANH'):
+        def get_numpy_prediction_gru_single_batch(
+            X, h, return_seq, direction, inner_activation_str="sigmoid", activation_str="tanh"
+        ):
             np_out = np.zeros((seq_len, hidden_size))
             batch_x = X if direction == "forward" else X[::-1, :]
             for k in range(seq_len):
                 x = batch_x[k, :]
                 z = apply_act(np.dot(W_z, x) + np.dot(R_z, h) + b_z, inner_activation_str)
                 r = apply_act(np.dot(W_r, x) + np.dot(R_r, h) + b_r, inner_activation_str)
                 c = h * r
@@ -189,14 +195,17 @@
 
         run_compare_builder(
             build,
             input_placeholders,
             input_values,
             expected_output_types,
             expected_outputs,
+            inputs=construct_inputs_from_placeholders(input_placeholders, upper_bound=10)
+            if symbolic and backend[0] == "mlprogram"
+            else None,
             compute_unit=compute_unit,
             backend=backend,
         )
 
 
 class TestLSTM:
     @pytest.mark.parametrize(
@@ -218,17 +227,17 @@
             ]
         ),
         itertools.product(
             compute_units,
             backends,
             [[8, 32, 32]],
             [1, 4],
-            ["SIGMOID"],
-            ["TANH"],
-            ["TANH", "SIGMOID"],
+            ["sigmoid"],
+            ["tanh"],
+            ["relu", "scaled_tanh", "hard_sigmoid", "linear"],
             [False, True],
             [False, True],
             [False, True],
             [True, False],
             [False],  # We have not exposed this option yet!
             [50.0, 0.2, 0.01],
         ),
@@ -246,23 +255,25 @@
         has_bias,
         forget_bias,
         has_peephole,
         coupled_input_forget,
         clip,
     ):
         def _apply_act(x, option):
-            if option == "TANH":
+            # All activation functions use their standard default values.
+            # This makes `tanh` equivalent to `scaled_tanh`, and makes `linear` a pass through.
+            if option == "tanh" or option == "scaled_tanh":
                 return np.tanh(x)
-            elif option == "RELU":
+            elif option == "relu":
                 return np.maximum(0, x)
-            elif option == "SIGMOID":
+            elif option == "sigmoid":
                 return 1.0 / (1 + np.exp(-x))
-            elif option == "SIGMOID_HARD":
+            elif option == "hard_sigmoid":
                 return np.minimum(np.maximum(0.2 * x + 0.5, 0), 1)
-            elif option == "LINEAR":
+            elif option == "linear":
                 return x
             else:
                 raise ValueError("activation invalid")
 
         def _clip(x, threshold=500.0):
             return np.maximum(np.minimum(x, threshold), -threshold)
 
@@ -513,14 +524,17 @@
 
         run_compare_builder(
             build,
             input_placeholders,
             input_values,
             expected_output_types,
             expected_outputs,
+            inputs=construct_inputs_from_placeholders(input_placeholders, upper_bound=64)
+            if symbolic and backend[0] == "mlprogram"
+            else None,
             compute_unit=compute_unit,
             backend=backend,
         )
 
     @pytest.mark.skipif(not _HAS_TORCH, reason=MSG_TORCH_NOT_FOUND)
     @pytest.mark.parametrize(
         argnames=[
@@ -666,18 +680,65 @@
 
         run_compare_builder(
             build,
             input_placeholders,
             input_values,
             expected_output_types,
             expected_outputs,
+            inputs=construct_inputs_from_placeholders(input_placeholders, upper_bound=64)
+            if symbolic and backend[0] == "mlprogram"
+            else None,
             compute_unit=compute_unit,
             backend=backend,
         )
 
+    @ssa_fn
+    def test_invalid_bidirectional_lstm(self):
+        with pytest.raises(
+            ValueError,
+            match="For bidirectional LSTM, the `weight_ih_back` and "
+            "`weight_hh_back` must be provided.",
+        ):
+            seq_len = 3
+            batch = 2
+            input_size = 4
+            hidden_size = 5
+            mb.lstm(
+                x=np.random.rand(seq_len, batch, input_size),
+                initial_h=np.zeros((batch, hidden_size)).astype(np.float32),
+                initial_c=np.zeros((batch, hidden_size)).astype(np.float32),
+                weight_ih=np.random.rand(4 * hidden_size, input_size),
+                weight_hh=np.random.rand(4 * hidden_size, hidden_size),
+                direction="bidirectional",
+            )
+
+    @ssa_fn
+    def test_invalid_activation_lstm(self):
+        seq_len = 3
+        batch = 2
+        input_size = 4
+        hidden_size = 5
+        arguments = {
+            "x": np.random.rand(seq_len, batch, input_size),
+            "initial_h": np.zeros((batch, hidden_size)).astype(np.float32),
+            "initial_c": np.zeros((batch, hidden_size)).astype(np.float32),
+            "weight_ih": np.random.rand(4 * hidden_size, input_size),
+            "weight_hh": np.random.rand(4 * hidden_size, hidden_size),
+            "direction": "forward",
+        }
+
+        with pytest.raises(ValueError, match="Activation `dummy` not supported."):
+            mb.lstm(recurrent_activation="dummy", **arguments)
+
+        with pytest.raises(ValueError, match="Activation `dummy` not supported."):
+            mb.lstm(cell_activation="dummy", **arguments)
+
+        with pytest.raises(ValueError, match="Activation `dummy` not supported."):
+            mb.lstm(activation="dummy", **arguments)
+
 
 class TestRNN:
     @pytest.mark.skipif(not _HAS_TORCH, reason=MSG_TORCH_NOT_FOUND)
     @pytest.mark.parametrize(
         argnames=[
             "compute_unit",
             "backend",
@@ -781,10 +842,13 @@
 
         run_compare_builder(
             build,
             input_placeholders,
             input_values,
             expected_output_types,
             expected_outputs,
+            inputs=construct_inputs_from_placeholders(input_placeholders, upper_bound=64)
+            if symbolic and backend[0] == "mlprogram"
+            else None,
             compute_unit=compute_unit,
             backend=backend,
         )
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/ops/tests/test_reduction.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/ops/tests/test_reduction.py`

 * *Files 7% similar despite different names*

```diff
@@ -5,19 +5,19 @@
 
 import itertools
 
 import numpy as np
 import pytest
 import scipy
 
+import coremltools as ct
 from coremltools.converters.mil import testing_reqs
 from coremltools.converters.mil.mil import Builder as mb
 from coremltools.converters.mil.mil import get_new_symbol, types
-from coremltools.converters.mil.mil.ops.tests.testing_utils import \
-    run_compare_builder
+from coremltools.converters.mil.mil.ops.tests.testing_utils import run_compare_builder
 from coremltools.converters.mil.testing_utils import random_gen, ssa_fn
 
 backends = testing_reqs.backends
 compute_units = testing_reqs.compute_units
 
 
 class TestReduction:
@@ -350,7 +350,51 @@
             assert op.op_type == 'reduce_log_sum_exp'
             np.testing.assert_allclose(
                 op.value_inference(),
                 scipy.special.logsumexp(x, axis=axis),
                 atol=1e-04,
                 rtol=1e-05
             )
+
+    @pytest.mark.parametrize(
+        "compute_unit, backend, op_name, output_dtype",
+        itertools.product(
+            compute_units, backends, ["reduce_argmax", "reduce_argmin"], ["int32", "uint16", None]
+        ),
+    )
+    def test_reduce_arg_ios17_output_dtype(self, compute_unit, backend, op_name, output_dtype):
+        def build(x):
+            return getattr(mb, op_name)(x=x, axis=1, keep_dims=False, output_dtype=output_dtype)
+
+        val = np.array([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]], dtype=np.float32)
+        input_placeholders = {"x": mb.placeholder(shape=val.shape)}
+        input_values = {"x": val}
+        output_np_type = np.uint16 if output_dtype == "uint16" else np.int32
+        output_type = types.uint16 if output_dtype == "uint16" else types.int32
+        expected_output_types = (2, output_type)
+        expected_outputs = np.array(
+            [2, 2] if op_name == "reduce_argmax" else [0, 0], dtype=output_np_type
+        )
+
+        run_compare_builder(
+            build,
+            input_placeholders,
+            input_values,
+            expected_output_types,
+            expected_outputs,
+            compute_unit=compute_unit,
+            backend=backend,
+            minimum_deployment_target=ct.target.iOS17,
+        )
+
+    @pytest.mark.parametrize(
+        "op_name",
+        ["reduce_argmax", "reduce_argmin"],
+    )
+    def test_reduce_arg_ios17_output_dtype_invalid(self, op_name):
+        x = np.array([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]], dtype=np.float32)
+
+        def prog():
+            return getattr(mb, op_name)(x=x, axis=1, keep_dims=False, output_dtype="dummy")
+
+        with pytest.raises(ValueError, match='Invalid "output_dtype" dummy'):
+            mb.program(input_specs=[], opset_version=ct.target.iOS17)(prog)
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/ops/tests/test_slice.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/ops/tests/test_slice.py`

 * *Files 2% similar despite different names*

```diff
@@ -145,18 +145,18 @@
     @ssa_fn
     def test_builder_eval_scalar_output_corner_cases(self):
         x1 = np.array([2.])
         x2 = np.array([[[[1.],[3.]]]])
         v = [
             mb.slice_by_index(
                 x=x1, begin=[0,], end=[0], squeeze_mask=[True],
-            ), 
+            ),
             mb.slice_by_index(
                 x=x2, begin=[0, 0, 0, 0], end=[0, 0, 0, 0], squeeze_mask=[True, True, True, True],
-            ), 
+            ),
         ]
         assert v[0].val.shape == ()
         assert v[0].val == 2
         assert v[1].val.shape == ()
         assert v[1].val == 1
 
     @ssa_fn
@@ -349,16 +349,25 @@
         # slice by index is x[begin[0]: end[0]: stride[0], begin[1]: end[1]: stride[1], ...]
         y_numpy = x[0:1:1, 0:2:1, 0:8:2, 0:12:2]
 
         model = ct.convert(prog, source="milinternal", convert_to="neuralnetwork")
         y_neuralnetwork = list(model.predict({'x': x}).values())[0]
         np.testing.assert_allclose(y_numpy, y_neuralnetwork)
 
-        model = ct.convert(prog, source="milinternal", convert_to="mlprogram")
-        y_mlprogram = list(model.predict({'x': x}).values())[0]
+        model = ct.convert(
+            prog,
+            source="milinternal",
+            convert_to="mlprogram",
+            compute_units=ct.ComputeUnit.CPU_ONLY,
+        )
+
+        # rdar://109080828 ([Bug] slice_by_index is throwing expection through E5ML stack) need to be fixed
+        # The above radar fixed the CPU case,
+        # the non-CPU is still failing, which is tracked in rdar://109854221 ([Bug][Regression] slice_by_index is throwing expection through E5ML - Follow up radar)
+        # y_mlprogram = list(model.predict({'x': x}).values())[0]
         # rdar://102217935 needs to be fixed before mlprogram will pass
         # np.testing.assert_allclose(y_numpy, y_mlprogram)
 
     @staticmethod
     def test_slice_by_index_slice_squeeze_separate():
         INPUT_SHAPE = (1, 2, 8, 16)
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/ops/tests/test_tensor_operation.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/ops/tests/test_tensor_operation.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,36 +1,41 @@
 #  Copyright (c) 2020, Apple Inc. All rights reserved.
 #
 #  Use of this source code is governed by a BSD-3-clause license that can be
 #  found in the LICENSE.txt file or at https://opensource.org/licenses/BSD-3-Clause
 
 import itertools
 import platform
+from unittest.mock import patch
 
 import numpy as np
 import pytest
 
 import coremltools as ct
 from coremltools._deps import _HAS_TF_2, MSG_TF2_NOT_FOUND
 from coremltools.converters.mil import testing_reqs
 from coremltools.converters.mil.mil import Builder as mb
-from coremltools.converters.mil.mil import get_new_symbol, types
-from coremltools.converters.mil.testing_utils import (get_op_types_in_program,
-                                                      random_gen, ssa_fn)
-from coremltools.models.utils import _macos_version
-
-from .testing_utils import UNK_SYM, UNK_VARIADIC, run_compare_builder
+from coremltools.converters.mil.mil import Function, get_new_symbol, types
+from coremltools.converters.mil.mil.passes.pass_pipeline import PassPipeline
+from coremltools.converters.mil.mil.var import Var
+from coremltools.converters.mil.testing_utils import get_op_types_in_program, random_gen, ssa_fn
+
+from .testing_utils import (
+    UNK_SYM,
+    UNK_VARIADIC,
+    construct_inputs_from_placeholders,
+    run_compare_builder,
+)
 
 if _HAS_TF_2:
     import tensorflow as tf
 
 backends = testing_reqs.backends
 compute_units = testing_reqs.compute_units
 
-
 class TestBandPart:
     @pytest.mark.parametrize(
         "compute_unit, backend",
         itertools.product(
             compute_units,
             backends,
         ),
@@ -108,14 +113,55 @@
             input_values,
             expected_output_types,
             expected_outputs,
             compute_unit=compute_unit,
             backend=backend,
         )
 
+    def get_output_from_mlmodel(
+        self, x_val: np.ndarray, num_lower: int, num_upper: int
+    ) -> np.ndarray:
+        @mb.program(input_specs=[mb.TensorSpec(shape=(3, 4))])
+        def prog(x):
+            return mb.band_part(x=x, lower=num_lower, upper=num_upper, name="out")
+
+        mlmodel = ct.convert(
+            prog,
+            convert_to="mlprogram",
+            compute_precision=ct.precision.FLOAT32,
+            compute_units=ct.ComputeUnit.CPU_ONLY,
+        )
+        out = mlmodel.predict({"x": x_val})["out"]
+        return out
+
+    def get_value_inference_output(
+        self, x_val: np.ndarray, num_lower: int, num_upper: int
+    ) -> np.ndarray:
+        func_inputs = {"x": mb.placeholder(shape=[3, 4])}
+        with Function(func_inputs) as ssa_fun:
+            x = ssa_fun.inputs["x"]
+            v = mb.band_part(x=x_val, lower=num_lower, upper=num_upper)
+        return v.val
+
+    @pytest.mark.skipif(
+        ct.utils._macos_version() < (10, 15), reason="needs mlprogram, skip on macos < 10.15"
+    )
+    @pytest.mark.parametrize(
+        "lower_upper",
+        [(0, -1), (-1, 0), (0, 0), (1, 1), (1, 2), (2, 1)],
+    )
+    def test_value_inference(self, lower_upper):
+        num_lower, num_upper = lower_upper
+        test_input = np.random.rand(3, 4).astype(np.float32)
+        out_value_inference = self.get_value_inference_output(test_input, num_lower, num_upper)
+        out_from_model_prediction = self.get_output_from_mlmodel(test_input, num_lower, num_upper)
+        np.testing.assert_allclose(
+            out_value_inference, out_from_model_prediction, atol=1e-3, rtol=1e-3
+        )
+
 
 class TestCumSum:
     @pytest.mark.parametrize(
         "compute_unit, backend",
         itertools.product(
             compute_units,
             backends,
@@ -342,14 +388,17 @@
 
         run_compare_builder(
             build,
             input_placeholders,
             input_values,
             expected_output_types,
             expected_outputs,
+            inputs=construct_inputs_from_placeholders(input_placeholders, 3)
+            if backend[0] == "mlprogram"
+            else None,
             compute_unit=compute_unit,
             backend=backend,
         )
 
 
 @pytest.mark.skipif(not _HAS_TF_2, reason=MSG_TF2_NOT_FOUND)
 class TestNonMaximumSuppression:
@@ -668,15 +717,15 @@
         )
 
     @ssa_fn
     def test_builder_eval(self):
         x_val = np.random.randint(low=-1, high=2, size=(6, 1, 7))
         res = mb.non_zero(x=x_val)
         np.testing.assert_allclose(np.transpose(np.nonzero(x_val)), res.val, atol=1e-04, rtol=1e-05)
-        
+
     @ssa_fn
     def test_shape_inference_for_deterministic_input(self):
         # If the input is compile time known, the builder should be able to infer the shape from value
         x_val = np.array([[0, 2], [1, 1]])
         res = mb.non_zero(x=x_val)
         assert res.shape == (3, 2)
 
@@ -1217,24 +1266,14 @@
             compute_units,
             backends,
             [True, False],
             [True, False],
         )
     )
     def test_builder_to_backend_smoke_iOS16(self, compute_unit, backend, return_indices, sort):
-        if backend[0] == "neuralnetwork":
-            pytest.skip("nn backend not supported")
-        if _macos_version() < (13, 0):
-            pytest.skip("New functionality in macOS13/iOS16")
-
-        if not return_indices:
-            pytest.xfail(
-                "rdar://92880117 (Topk with return_indices = False error out at the MIL->EIR stage)"
-            )
-
         val = np.array([[-1.0, 2.0, -3.0], [4.0, -5.0, 6.0]], dtype=np.float32)
         input_placeholders = {"x": mb.placeholder(shape=val.shape)}
         input_values = {"x": val}
 
         def build(x):
             return mb.topk(x=x, k=2, axis=1, return_indices=return_indices, sort=sort)
 
@@ -1258,14 +1297,69 @@
             expected_output_types,
             expected_outputs,
             compute_unit=compute_unit,
             backend=backend,
             minimum_deployment_target=ct.target.iOS16,
         )
 
+    @pytest.mark.parametrize(
+        "compute_unit, backend, x_dtype, k_dtype",
+        itertools.product(
+            compute_units,
+            [("mlprogram", "fp16")],
+            [np.float32, np.float16, np.int32, np.int16, np.uint16],
+            [np.int32, np.int16],
+        ),
+    )
+    def test_ios17_different_dtypes(self, compute_unit, backend, x_dtype, k_dtype):
+        def build(x):
+            return mb.topk(x=x, k=k_dtype(2), axis=1)
+
+        if k_dtype == np.int16:
+            pytest.xfail("k with dtype int16 will trigger backend error.")
+
+        val = np.array([[2, 3, 1], [5, 4, 6]], dtype=x_dtype)
+        x_mb_dtype = types.type_mapping.numpy_type_to_builtin_type(x_dtype)
+        input_placeholders = {"x": mb.placeholder(shape=val.shape, dtype=x_mb_dtype)}
+        input_values = {"x": val}
+        # As int16 is not in CoreML I/O supported dtypes, it will be cast to int32.
+        expected_output_types = [(2, 2, x_mb_dtype), (2, 2, types.int32)]
+        expected_outputs = [
+            np.array([[3, 2], [6, 5]], dtype=x_dtype),
+            np.array([[1, 0], [2, 0]], dtype=np.int32),
+        ]
+
+        with patch.object(Var, "_is_nonreplaceable_var") as mocked_is_nonreplaceable_var:
+            # Mock that the cast is non-replaceable, to make sure it's kept in the graph.
+            mocked_is_nonreplaceable_var.side_effect = (
+                lambda var: var.op and var.op.op_type == "cast"
+            )
+            # Remove the cast optimization pass to make sure all cast are kept in the graph.
+            pass_pipeline: PassPipeline = PassPipeline.DEFAULT
+            pass_pipeline.remove_passes(
+                ["common::cast_optimization", "common::topological_reorder"]
+            )
+            mlmodel = run_compare_builder(
+                build,
+                input_placeholders,
+                input_values,
+                expected_output_types,
+                expected_outputs,
+                compute_unit=compute_unit,
+                backend=backend,
+                minimum_deployment_target=ct.target.iOS17,
+                pass_pipeline=pass_pipeline,
+            )
+        prog = mlmodel._mil_program
+        topk_op = prog["main"].find_ops(op_type="topk")[0]
+        expected_x_dtype = x_mb_dtype
+        if backend[1] == "fp16" and types.is_float(x_mb_dtype):
+            expected_x_dtype = types.fp16
+        assert types.builtin_to_string(topk_op.x.dtype) == types.builtin_to_string(expected_x_dtype)
+
     @ssa_fn
     def test_builder_eval(self):
         def np_topk(x, k, axis, ascending=False):
             indices = np.argsort(x, axis=axis)
             if not ascending:
                 indices = np.argsort(-x, axis=axis)
             slc = [slice(None)] * len(x.shape)
@@ -1436,14 +1530,17 @@
         input_values = {"x": input}
         run_compare_builder(
             build,
             input_placeholders,
             input_values,
             expected_output_types,
             expected_outputs,
+            inputs=construct_inputs_from_placeholders(input_placeholders, 10)
+            if backend[0] == "mlprogram"
+            else None,
             compute_unit=compute_unit,
             backend=backend,
         )
 
 
 class TestShape:
     @pytest.mark.parametrize(
@@ -1518,14 +1615,17 @@
         input_values = {"x": input}
         run_compare_builder(
             build,
             input_placeholders,
             input_values,
             expected_output_types,
             expected_outputs,
+            inputs=construct_inputs_from_placeholders(input_placeholders, 10)
+            if backend[0] == "mlprogram"
+            else None,
             compute_unit=compute_unit,
             backend=backend,
         )
 
 
 class TestIdentity:
     @pytest.mark.parametrize(
@@ -1639,7 +1739,56 @@
 
     @ssa_fn
     def test_builder_eval(self):
         x_val = random_gen(shape=(1, 3, 2, 2), rand_min=-100, rand_max=100)
         res = mb.argsort(x=x_val, axis=-3)
         # The default np argsort mode is ascending, which is opposite to MIL's argsort op.
         np.testing.assert_allclose(np.argsort(-x_val, axis=-3), res.val, atol=1e-04, rtol=1e-05)
+
+
+class TestConcat:
+    @pytest.mark.parametrize(
+        "compute_unit, backend, axis",
+        itertools.product(
+            compute_units,
+            backends,
+            [0, 1],
+        ),
+    )
+    def test_builder_to_backend_numerical(self, compute_unit, backend, axis):
+        def build(x1, x2):
+            return mb.concat(values=[x1, x2], axis=axis)
+
+        val1 = np.array([[-1.0, 2.0, -3.0], [4.0, -5.0, 6.0]], dtype=np.float32)
+        val2 = -val1
+        input_placeholders = {
+            "x1": mb.placeholder(shape=val1.shape),
+            "x2": mb.placeholder(shape=val2.shape),
+        }
+        input_values = {"x1": val1, "x2": val2}
+        expected_res = np.concatenate([val1, val2], axis=axis)
+
+        run_compare_builder(
+            build,
+            input_placeholders,
+            input_values,
+            expected_output_types=[expected_res.shape + (types.fp32,)],
+            expected_outputs=expected_res,
+            compute_unit=compute_unit,
+            backend=backend,
+        )
+
+    def test_builder_eval_different_dtypes_error_out(self):
+        """If the input to the concat op has different dtypes, it will error out."""
+        with pytest.raises(
+            ValueError,
+            match="Tensors in 'values' of the concat op \(concat_0\) should share the same data type",
+        ):
+
+            @mb.program(
+                input_specs=[
+                    mb.TensorSpec(shape=(2, 3), dtype=types.fp32),
+                    mb.TensorSpec(shape=(2, 3), dtype=types.int32),
+                ]
+            )
+            def prog(x1, x2):
+                return mb.concat(values=[x1, x2], axis=0)
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/ops/tests/test_tensor_transformation.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/ops/tests/test_tensor_transformation.py`

 * *Files 3% similar despite different names*

```diff
@@ -13,15 +13,20 @@
 from coremltools.converters.mil import testing_reqs
 from coremltools.converters.mil.mil import Builder as mb
 from coremltools.converters.mil.mil import get_new_symbol, types
 from coremltools.converters.mil.mil.types import nptype_from_builtin
 from coremltools.converters.mil.testing_reqs import backends, compute_units
 from coremltools.converters.mil.testing_utils import ssa_fn
 
-from .testing_utils import UNK_SYM, UNK_VARIADIC, run_compare_builder
+from .testing_utils import (
+    UNK_SYM,
+    UNK_VARIADIC,
+    construct_inputs_from_placeholders,
+    run_compare_builder,
+)
 
 if _HAS_TORCH:
     import torch
 
 
 class TestDepthToSpace:
     @pytest.mark.parametrize(
@@ -86,15 +91,15 @@
             backend=backend,
         )
 
 
 class TestBatchToSpace:
     @pytest.mark.parametrize(
         "compute_unit, backend", itertools.product(compute_units, backends,)
-    )    
+    )
     def test_builder_to_backend_smoke(self, compute_unit, backend):
         # original input type is (8, 1, 1, 3, fp32)
         val = np.array([[[[ 0,  1,  3]]],
                        [[[ 0,  9, 11]]],
                        [[[ 0,  2,  4]]],
                        [[[ 0, 10, 12]]],
                        [[[ 0,  5,  7]]],
@@ -200,14 +205,17 @@
         }
         run_compare_builder(
             build,
             input_placeholders,
             input_values,
             expected_output_types,
             expected_outputs,
+            inputs=construct_inputs_from_placeholders(input_placeholders, 10)
+            if backend[0] == "mlprogram"
+            else None,
             compute_unit=compute_unit,
             backend=backend,
         )
 
     @ssa_fn
     def test_builder_eval(self):
         x_val = np.random.rand(1, 6)
@@ -307,14 +315,15 @@
             input_values,
             expected_output_types,
             expected_outputs,
             compute_unit=compute_unit,
             backend=backend,
         )
 
+
 class TestReshapeLike:
     @pytest.mark.parametrize(
         "compute_unit, backend, InputShape_RefShapes_Begins_Ends_EndMasks, InputType_RefType",
         itertools.product(
             compute_units,
             backends,
             [
@@ -330,48 +339,48 @@
             compute_unit,
             backend,
             InputShape_RefShapes_Begins_Ends_EndMasks,
             InputType_RefType,
         ):
         if backend[0] == "neuralnetwork":
             pytest.skip("reshape_like not supoprted in neuralnetwork backend.")
-            
+
         if ct.utils._macos_version() < (13, 0):
             pytest.skip("reshape_like not supported in macOS12 or older.")
-            
+
         input_shape, ref_shapes, begins, ends, end_masks = InputShape_RefShapes_Begins_Ends_EndMasks
         ref_shape_1, ref_shape_2 = ref_shapes
         input_type, ref_type = InputType_RefType
-        
+
         t = np.random.rand(*input_shape).astype(np.float32)
         ref_tensor_1 = np.random.rand(*ref_shape_1).astype(np.float32)
         ref_tensor_2 = np.random.rand(*ref_shape_2).astype(np.float32)
 
         input_placeholders = {
-            "x": mb.placeholder(shape=t.shape), 
+            "x": mb.placeholder(shape=t.shape),
             "ref_tensor_1": mb.placeholder(shape=ref_shape_1),
             "ref_tensor_2": mb.placeholder(shape=ref_shape_2),
         }
         input_values = {
             "x": t,
             "ref_tensor_1": ref_tensor_1,
             "ref_tensor_2": ref_tensor_2,
         }
 
         def build(x, ref_tensor_1, ref_tensor_2):
             if input_type == types.bool:
                 x = mb.cast(x=x, dtype="bool")
-                
+
             if ref_type == types.bool:
                 ref_tensor_1 = mb.cast(x=ref_tensor_1, dtype="bool")
                 ref_tensor_2 = mb.cast(x=ref_tensor_2, dtype="bool")
-                
+
             ref_tensors = (ref_tensor_1, ref_tensor_2)
             return mb.reshape_like(x=x, ref_tensors=ref_tensors, begins=begins, ends=ends, end_masks=end_masks)
-            
+
         output_shape = ()
         for ref_shape, begin, end, end_mask in zip((ref_shape_1, ref_shape_2), begins, ends, end_masks):
             if end_mask:
                 output_shape += tuple(ref_shape[begin:])
             else:
                 output_shape += tuple(ref_shape[begin:end])
 
@@ -479,24 +488,206 @@
         ]
 
         input_values = {
             "x": np.array([[1, 2, 3], [4, 5, 6]], dtype=np.float32),
             "shape": np.array([2, 1, 3], dtype=np.float32),
             "shape2": np.array([2, 1, 3], dtype=np.float32),
         }
+
+        run_compare_builder(
+            build,
+            input_placeholders,
+            input_values,
+            expected_output_types,
+            expected_outputs,
+            inputs=construct_inputs_from_placeholders(input_placeholders, 10)
+            if backend[0] == "mlprogram"
+            else None,
+            compute_unit=compute_unit,
+            backend=backend,
+        )
+
+    @ssa_fn
+    def test_too_many_neg_ones(self):
+        x = np.array([[1, 2, 3], [4, 5, 6]], dtype=np.float32)
+        with pytest.raises(ValueError, match="Reshape op supports only one dimension to be -1"):
+            mb.reshape(x=x, shape=[-1, -1])
+
+    @ssa_fn
+    def test_invalid_target_shape(self):
+        x = np.array([[1, 2, 3], [4, 5, 6]], dtype=np.float32)
+        with pytest.raises(ValueError, match="Invalid target shape in `reshape` op"):
+            mb.reshape(x=x, shape=[4, -1])
+
+    @ssa_fn
+    def test_invalid_target_shape_with_zero(self):
+        x = np.array([[1, 2, 3], [4, 5, 6]], dtype=np.float32)
+        with pytest.raises(ValueError, match="Invalid target shape in `reshape` op"):
+            mb.reshape(x=x, shape=[0, 7])
+
+    @pytest.mark.parametrize(
+        "compute_unit, backend",
+        itertools.product(
+            compute_units,
+            backends,
+        ),
+    )
+    def test_reshape_with_zero(self, compute_unit, backend):
+        if backend[0] == "neuralnetwork":
+            pytest.skip("Reshape with 0 is not supported in neuralnetwork.")
+
+        t = np.array([[1, 2, 3], [4, 5, 6]], dtype=np.float32)
+        input_placeholders = {"x": mb.placeholder(shape=t.shape)}
+        input_values = {"x": t}
+
+        def build(x):
+            return [
+                mb.reshape(x=x, shape=[0, -1]),
+                mb.reshape(x=x, shape=[0, 3]),
+                mb.reshape(x=x, shape=[-1, 0]),
+            ]
+
+        expected_output_types = [
+            (2, 3, types.fp32),
+            (2, 3, types.fp32),
+            (2, 3, types.fp32),
+        ]
+        expected_outputs = [
+            np.array([[1, 2, 3], [4, 5, 6]], dtype=np.float32),
+            np.array([[1, 2, 3], [4, 5, 6]], dtype=np.float32),
+            np.array([[1, 2, 3], [4, 5, 6]], dtype=np.float32),
+        ]
+
         run_compare_builder(
             build,
             input_placeholders,
             input_values,
             expected_output_types,
             expected_outputs,
             compute_unit=compute_unit,
             backend=backend,
         )
 
+    @pytest.mark.parametrize(
+        "compute_unit, backend",
+        itertools.product(
+            compute_units,
+            backends,
+        ),
+    )
+    def test_reshape_with_zero_different_len(self, compute_unit, backend):
+        if backend[0] == "neuralnetwork":
+            pytest.skip("Reshape with 0 is not supported in neuralnetwork.")
+
+        t = np.array([[1, 2, 3], [4, 5, 6]], dtype=np.float32)
+        input_placeholders = {"x": mb.placeholder(shape=t.shape)}
+        input_values = {"x": t}
+
+        def build(x):
+            return [
+                mb.reshape(x=x, shape=[1, 0, -1, 0]),
+            ]
+
+        expected_output_types = [
+            (1, 1, 2, 3, types.fp32),
+        ]
+        expected_outputs = [
+            np.array([[[[1, 2, 3], [4, 5, 6]]]], dtype=np.float32),
+        ]
+
+        with pytest.raises(
+            ValueError,
+            match="When there is 0 in shape, the rank of x .* must "
+            "equal to the target shape len",
+        ):
+            run_compare_builder(
+                build,
+                input_placeholders,
+                input_values,
+                expected_output_types,
+                expected_outputs,
+                compute_unit=compute_unit,
+                backend=backend,
+            )
+
+    @pytest.mark.parametrize(
+        "compute_unit, backend",
+        itertools.product(
+            compute_units,
+            backends,
+        ),
+    )
+    def test_reshape_with_zero_different_len(self, compute_unit, backend):
+        if backend[0] == "neuralnetwork":
+            pytest.skip("Reshape with 0 is not supported in neuralnetwork.")
+
+        t = np.array([[1, 2, 3], [4, 5, 6]], dtype=np.float32)
+        input_placeholders = {"x": mb.placeholder(shape=t.shape)}
+        input_values = {"x": t}
+
+        def build(x):
+            return [mb.reshape(x=x, shape=[1, 0, -1, 0])]
+
+        # In IOS15/16 it will error out because rank of x needs to have same length as shape.
+        with pytest.raises(
+            ValueError,
+            match="When there is 0 in shape, the rank of x .* must "
+            "equal to the target shape len",
+        ):
+            run_compare_builder(
+                build,
+                input_placeholders,
+                input_values,
+                compute_unit=compute_unit,
+                backend=backend,
+            )
+
+        # In IOS17 it accepts different length.
+        expected_output_types = [(1, 1, 2, 3, types.fp32)]
+        expected_outputs = [np.array([[[[1, 2, 3], [4, 5, 6]]]], dtype=np.float32)]
+        run_compare_builder(
+            build,
+            input_placeholders,
+            input_values,
+            expected_output_types,
+            expected_outputs,
+            compute_unit=compute_unit,
+            backend=backend,
+            minimum_deployment_target=ct.target.iOS17,
+        )
+
+    @pytest.mark.parametrize(
+        "compute_unit, backend",
+        itertools.product(
+            compute_units,
+            backends,
+        ),
+    )
+    def test_reshape_invalid_with_zero(self, compute_unit, backend):
+        if backend[0] == "neuralnetwork":
+            pytest.skip("Reshape with 0 is not supported in neuralnetwork.")
+
+        t = np.array([[1, 2, 3], [4, 5, 6]], dtype=np.float32)
+        input_placeholders = {"x": mb.placeholder(shape=t.shape)}
+        input_values = {"x": t}
+
+        def build(x):
+            return [mb.reshape(x=x, shape=[4, 0, -1, 0])]
+
+        with pytest.raises(ValueError, match="Invalid target shape in `reshape` op"):
+            run_compare_builder(
+                build,
+                input_placeholders,
+                input_values,
+                compute_unit=compute_unit,
+                backend=backend,
+                minimum_deployment_target=ct.target.iOS17,
+            )
+
+
 
 class TestReverse:
     @pytest.mark.parametrize(
         "compute_unit, backend", itertools.product(compute_units, backends,)
     )
     def test_builder_to_backend_smoke(self, compute_unit, backend):
         val = np.array([[-1.0, 2.0, -3.0], [4.0, -5.0, 6.0]], dtype=np.float32)
@@ -655,14 +846,17 @@
 
         run_compare_builder(
             build,
             input_placeholders,
             input_values,
             expected_output_types,
             expected_outputs,
+            inputs=construct_inputs_from_placeholders(input_placeholders, 10)
+            if backend[0] == "mlprogram"
+            else None,
             compute_unit=compute_unit,
             backend=backend,
         )
 
 
 class TestSliceBySize:
     @pytest.mark.parametrize(
@@ -844,14 +1038,17 @@
 
         run_compare_builder(
             build,
             input_placeholders,
             input_values,
             expected_output_types,
             expected_outputs,
+            inputs=construct_inputs_from_placeholders(input_placeholders, 10)
+            if backend[0] == "mlprogram"
+            else None,
             compute_unit=compute_unit,
             backend=backend,
         )
 
     @ssa_fn
     def test_builder_eval(self):
         x = np.array([[1, 2, 3], [4, 5, 6]], dtype=np.float32)
@@ -879,20 +1076,24 @@
         expected_outputs = [
             np.array([[1, 4], [2, 5], [3, 6]], dtype=np.float32),
         ]
 
         input_values = {
             "x": np.array([[1, 2, 3], [4, 5, 6]], dtype=np.float32),
         }
+
         run_compare_builder(
             build,
             input_placeholders,
             input_values,
             expected_output_types,
             expected_outputs,
+            inputs=construct_inputs_from_placeholders(input_placeholders, 10)
+            if backend[0] == "mlprogram"
+            else None,
             compute_unit=compute_unit,
             backend=backend,
         )
 
 
 class TestPixelShuffle:
     @pytest.mark.parametrize(
@@ -995,15 +1196,15 @@
         ),
     )
     def test_builder_to_backend_stress(
         self, compute_unit, backend, shape, downscale_factor,
     ):
         if backend[0] == "neuralnetwork":
             pytest.skip("nn backend not supported")
-            
+
         val = np.random.rand(*shape)
         input_placeholders = {"x": mb.placeholder(shape=val.shape)}
         input_values = {"x": val}
 
         def build(x):
             return [mb.pixel_unshuffle(x=x, downscale_factor=np.uint32(downscale_factor))]
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/ops/tests/test_utils.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/ops/tests/test_utils.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/ops/tests/testing_utils.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/ops/tests/testing_utils.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,19 +1,25 @@
 #  Copyright (c) 2020, Apple Inc. All rights reserved.
 #
 #  Use of this source code is governed by a BSD-3-clause license that can be
 #  found in the LICENSE.txt file or at https://opensource.org/licenses/BSD-3-Clause
 
+from typing import Dict, List, Optional
+
 import coremltools as ct
 from coremltools import _logger as logger
-from coremltools.converters.mil.mil import Function, Program
+from coremltools.converters.mil.input_types import TensorType
+from coremltools.converters.mil.mil import Function, Placeholder, Program
+from coremltools.converters.mil.mil.passes.pass_pipeline import PassPipeline
 from coremltools.converters.mil.mil.types.symbolic import is_symbolic
-from coremltools.converters.mil.testing_utils import (compare_backend,
-                                                      ct_convert)
-
+from coremltools.converters.mil.testing_utils import (
+    compare_backend,
+    ct_convert,
+    validate_minimum_deployment_target,
+)
 
 UNK_VARIADIC = "*s_unk"
 UNK_SYM = "s_unk"
 
 
 def run_compare_builder(
     build,
@@ -26,14 +32,15 @@
     backend=("neuralnetwork", "fp32"),
     atol=1e-04,
     rtol=1e-05,
     inputs=None,
     also_compare_shapes=False,
     converter=ct.convert,
     minimum_deployment_target=None,
+    pass_pipeline: Optional[PassPipeline] = None,
 ):
     """
     Inputs:
         - build: python function taking input of Vars and returning Var or
           list[Var]. Each input argument in build must match a key in
           input_values / input_placeholders.
 
@@ -62,14 +69,17 @@
 
         - minimum_deployment_target : coremltools.target enumeration (optional)
             A member of the ``coremltools.target`` enum.
 
     Returns:
         The converted mlmodel
     """
+    if minimum_deployment_target is not None:
+        validate_minimum_deployment_target(minimum_deployment_target, backend)
+
     if not isinstance(expected_output_types, list):
         expected_output_types = [expected_output_types]
 
     if expected_outputs is not None and not isinstance(expected_outputs, list):
         expected_outputs = [expected_outputs]
 
     prog = Program()
@@ -90,21 +100,16 @@
         "Provided expected outputs types {} should match number of output"
         + " variables {}"
     )
     assert_msg = msg.format(len(expected_output_types), len(output_vars))
     assert len(output_vars) == len(expected_output_types), assert_msg
 
     for out_var, s in zip(output_vars, expected_output_types):
-        if out_var.dtype != s[-1]:
-            raise ValueError(
-                "Output {} type: expect {}, got {}. Program:\n{}".format(
-                    out_var.name, s[-1].__type_info__(),
-                    out_var.dtype.__type_info__(), prog
-                )
-            )
+        # The output type will be casted by the `adjust_io_to_supported_types` pass, so we don't
+        # check the output var dtype matching here.
         if UNK_VARIADIC in s[:-1]:
             msg = "Skip type checking for UNK_VARIADIC. Output shape: {} vs expected shape: {}"
             logger.debug(msg.format(out_var.shape, s[:-1]))
             continue
         expected_shape = s[:-1]
         msg = "Output {} shape: expect {}, got {}. Program:\n{}".format(
             out_var.name, expected_shape, out_var.shape, prog
@@ -119,21 +124,23 @@
         expected_shape = [0 if es == UNK_SYM else es for es in expected_shape]
         # convert float etc to int.
         output_shape = [i if is_symbolic(i) else int(i) for i in output_shape]
         expected_shape = [i if is_symbolic(i) else int(i) for i in expected_shape]
         if output_shape != expected_shape:
             raise ValueError(msg)
 
-    mlmodel = ct_convert(prog,
-                         converter=converter,
-                         source="milinternal",
-                         convert_to=backend,
-                         inputs=inputs,
-                         compute_units=compute_unit,
-                         minimum_deployment_target=minimum_deployment_target
+    mlmodel = ct_convert(
+        prog,
+        converter=converter,
+        source="milinternal",
+        convert_to=backend,
+        inputs=inputs,
+        compute_units=compute_unit,
+        minimum_deployment_target=minimum_deployment_target,
+        pass_pipeline=pass_pipeline,
     )
 
     if frontend_only:
         return mlmodel
 
     if expected_outputs:
         assert len(output_vars) == len(expected_outputs), (
@@ -149,11 +156,26 @@
     compare_backend(
         mlmodel=mlmodel,
         input_key_values=input_values,
         expected_outputs=expected_outputs,
         atol=atol,
         rtol=rtol,
         also_compare_shapes=also_compare_shapes,
-        dtype=backend[1]
+        dtype=backend[1],
     )
 
     return mlmodel
+
+
+def construct_inputs_from_placeholders(
+    input_placeholders: Dict[str, Placeholder], upper_bound: int
+) -> [List[TensorType]]:
+    """Construct the `inputs` param from placeholders with upper_bound."""
+    inputs: [List[TensorType]] = []
+    for input_name, placeholder in input_placeholders.items():
+        input_shape = [
+            ct.RangeDim(upper_bound=upper_bound) if is_symbolic(shape) else shape
+            for shape in placeholder.sym_shape
+        ]
+        input_tensor_type = TensorType(name=input_name, shape=input_shape)
+        inputs.append(input_tensor_type)
+    return inputs
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/passes/__init__.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/passes/__init__.py`

 * *Files 5% similar despite different names*

```diff
@@ -33,11 +33,12 @@
     cleanup,
     lower_complex_dialect_ops,
     optimize_activation,
     optimize_conv,
     optimize_elementwise_binary,
     optimize_linear,
     optimize_normalization,
+    optimize_quantization,
     optimize_repeat_ops,
     optimize_tensor_operation,
     preprocess,
 )
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/passes/defs/cleanup/__init__.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/passes/defs/cleanup/__init__.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,12 +1,13 @@
 #  Copyright (c) 2023, Apple Inc. All rights reserved.
 #
 #  Use of this source code is governed by a BSD-3-clause license that can be
 #  found in the LICENSE.txt file or at https://opensource.org/licenses/BSD-3-Clause
 
+from .const_deduplication import const_deduplication
 from .const_elimination import const_elimination
 from .dead_code_elimination import dead_code_elimination
 from .dedup_op_and_var_names import dedup_op_and_var_names
 from .fuse_reduce_mean import fuse_reduce_mean
 from .loop_invariant_elimination import loop_invariant_elimination
 from .noop_elimination import noop_elimination
 from .remove_redundant_ops import remove_redundant_ops
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/passes/defs/cleanup/const_elimination.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/passes/defs/cleanup/const_elimination.py`

 * *Files 12% similar despite different names*

```diff
@@ -24,15 +24,16 @@
 
         Result:
             _, %3 = non_const_op(...)  # _ is the ignored output
             %2_const = const()         # %2_const name is for illustration only
             %4 = other_op(%2_const, %3)
 
     Support options:
-    - skip_const_by_size: Skip folding consts that have larger number of elements than a threshold.
+
+    - ``skip_const_by_size``: Skip folding ``const`` ops that have larger number of elements than a threshold.
     """
 
     _skip_const_by_size = None
 
     @property
     def skip_const_by_size(self):
         return self._skip_const_by_size
@@ -92,12 +93,29 @@
                         old_var=output,
                         new_var=res,
                     ):
                         # rename the const output
                         output.set_name(output.name + "_ignored")
                     else:
                         all_outputs_are_replaced = False
+                # force const folding of the shape op
+                elif output.val is not None and op.op_type == "shape":
+                    res = mb.const(
+                        val=output.val,
+                        before_op=op,
+                        # same var name, but different python
+                        # instance does not violate SSA property.
+                        name=output.name,
+                    )
+                    op.enclosing_block.replace_uses_of_var_after_op(
+                        anchor_op=op,
+                        old_var=output,
+                        new_var=res,
+                        force_replace=True,
+                    )
+                    # rename the const output
+                    output.set_name(output.name + "_ignored")
                 else:
                     all_outputs_are_replaced = False
 
             if all_outputs_are_replaced:
                 op.remove_from_block()
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/passes/defs/cleanup/dead_code_elimination.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/passes/defs/cleanup/dead_code_elimination.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/passes/defs/cleanup/dedup_op_and_var_names.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/passes/defs/cleanup/dedup_op_and_var_names.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/passes/defs/cleanup/fuse_reduce_mean.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/passes/defs/cleanup/fuse_reduce_mean.py`

 * *Files 6% similar despite different names*

```diff
@@ -14,26 +14,29 @@
 from coremltools.converters.mil.mil.passes.pass_registry import register_pass
 from coremltools.converters.mil.mil.types.symbolic import is_symbolic
 
 
 @register_pass(namespace="common")
 class fuse_reduce_mean(AbstractGraphPass):
     """
-    Detect the "``reduce_sum``--->``mul/real_div``" pattern than can be mapped to ``reduce_mean``.
+    Detect the ``reduce_sum`` ---> ``mul/real_div`` pattern than can be mapped to ``reduce_mean``.
     That is, the operation ``reduce_sum/count == reduce_mean``.
 
-    .. code-block::
+    `Input graph`
 
-        Input graph:
+    .. code-block::
 
                                     const (scalar)
                                         |
         input ----> reduce_sum ----> mul/real_div -----------> output
 
-        Output graph:
+
+    `Output graph`
+
+    .. code-block::
 
         input --------> reduce_mean ---------> output
 
     """
 
     def apply(self, prog):
         for f in prog.functions.values():
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/passes/defs/cleanup/loop_invariant_elimination.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/passes/defs/cleanup/loop_invariant_elimination.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/passes/defs/cleanup/noop_elimination.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/passes/defs/cleanup/noop_elimination.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/passes/defs/cleanup/remove_redundant_ops.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/passes/defs/cleanup/remove_redundant_ops.py`

 * *Files 3% similar despite different names*

```diff
@@ -132,19 +132,22 @@
         if len(ops_to_remove) == 0:
             return False
 
         # remove uses of output vars of the ops to be removed.
         # This can be safely done, since all the ops in ops_to_remove
         # appear after first_op, hence first_op.outputs[0] variable is in
         # scope before the op's output var
+        ops_removed = []
         for op in ops_to_remove:
-            op.enclosing_block.replace_uses_of_var_after_op(
-                anchor_op=op, old_var=op.outputs[0], new_var=first_op.outputs[0]
-            )
-        block.remove_ops(ops_to_remove)
+            if op.enclosing_block.try_replace_uses_of_var_after_op(
+                anchor_op=op, old_var=op.outputs[0], new_var=first_op.outputs[0]):
+                ops_removed.append(op)
+        if len(ops_removed) == 0:
+            return False
+        block.remove_ops(ops_removed)
         return True
 
     @staticmethod
     def _try_to_transform(parent_var):
         """
         scan the children ops to parent_var, to find and remove indentical ops, if any.
         Returns True, if succesful in finding such redundant ops.
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/passes/defs/cleanup/remove_symbolic_reshape.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/passes/defs/cleanup/remove_symbolic_reshape.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/passes/defs/cleanup/topological_reorder.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/passes/defs/cleanup/topological_reorder.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/passes/defs/lower_complex_dialect_ops.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/passes/defs/lower_complex_dialect_ops.py`

 * *Files 16% similar despite different names*

```diff
@@ -135,39 +135,70 @@
             values=[imag_data, imag_part_mirror_values],
             axis=dim.val,
             before_op=before_op,
         )
 
     return real_data, imag_data
 
-
-def _fft_1d(
-    input_real: Var,
-    input_imag: Var,
-    n: Optional[Var],
-    dim: Optional[Var],
-    norm: Optional[Var],
-    before_op: Operation,
-    inverse: bool = False,  # For inverse FFT.
+def _calculate_dft_matrix(
+    n_fft: Var,
+    onesided: bool = False,
+    before_op: Operation = None,
 ) -> Tuple[Var, Var]:
     """
-    1-D FFT by DFT Matrix Multiplication.
-
     The core issue is how to derive the DFT matrix. As the DFT matrix is consist of different powers
     of `w`, where w=e^(2pi/N i), we need to separate the real and imaginary part of w. To achieve
     that, we need to find a way to construct the following matrix (from the power of `w` in DFT):
         0    0    0      ...    0
         0    1    2      ...    N-1
         0    2    4      ...    2(N-1)
         ...    ....      ...
         0   N-1  2(N-1)  ...    (N-1)(N-1)
     This matrix could be derived by outer product of two range tensors.
 
     After getting that base matrix, we can take sin and cos to get the corresponding `sin_base` and
-    `cos_base` matrix. Now based on some math formulas including:
+    `cos_base` matrix.
+
+    If the onesided flag is passed, we can take advantage of Hermitian symmetry and return a
+    weight matrix consisting of only the first (n_fft // 2 + 1) values.
+    """
+    n_fft = mb.cast(x=n_fft, dtype="fp32", before_op=before_op)
+    half = mb.floor_div(x=n_fft, y=2., before_op=before_op)
+    half = mb.add(x=half, y=1., before_op=before_op)
+
+    tmp_x = mb.range_1d(start=0.0, end=(half if onesided else n_fft), step=1.0, before_op=before_op)
+    tmp_y = mb.range_1d(start=0.0, end=n_fft, step=1.0, before_op=before_op)
+
+     # Use MIL ops to calculate base = torch.outer(tmp, tmp) * (2 * torch.pi / N).
+    tmp_x = mb.reshape(x=tmp_x, shape=[-1, 1], before_op=before_op)
+    tmp_y = mb.reshape(x=tmp_y, shape=[1, -1], before_op=before_op)
+    
+    base = mb.matmul(x=tmp_x, y=tmp_y, before_op=before_op)
+    base = mb.mul(x=base, y=2 * np.pi, before_op=before_op)
+    base = mb.real_div(x=base, y=n_fft, before_op=before_op)
+    
+    # Get real part and imaginary part separately.
+    cos_base = mb.cos(x=base, before_op=before_op)
+    sin_base = mb.sin(x=base, before_op=before_op)
+    
+    return cos_base, sin_base
+
+def _fft_1d(
+    input_real: Var,
+    input_imag: Var,
+    n: Optional[Var],
+    dim: Optional[Var],
+    norm: Optional[Var],
+    before_op: Operation,
+    inverse: bool = False,  # For inverse FFT.
+) -> Tuple[Var, Var]:
+    """
+    1-D FFT by DFT Matrix Multiplication.
+
+    Now based on some math formulas including:
         * The addition of complex numbers is: (a+bi)+(c+di)=(a+c)+(b+d)i.
         * The multiplication of complex numbers is: (a+bi)(c+di)=ac+adi+bci−bd=(ac−bd)+(ad+bc)i.
         * Euler’s formula: e^xi=cosx+isinx.
         * Cosine is an even function: cos(−x)=cosx.
         * Sine is an odd function: sin(−x)=−(sinx).
     We can get
         * The real part output is: cos_base * input_real + sin_base * input_imag
@@ -198,26 +229,17 @@
     )
 
     # Calculate DFT matrix.
     original_shape = transposed_input_real.shape
     N = transposed_input_real.shape[0]
     reshaped_input_real = mb.reshape(x=transposed_input_real, shape=[N, -1], before_op=before_op)
     reshaped_input_imag = mb.reshape(x=transposed_input_imag, shape=[N, -1], before_op=before_op)
-    tmp = mb.range_1d(start=0, end=N, step=1, before_op=before_op)
-    # Use MIL ops to calculate base = torch.outer(tmp, tmp) * (2 * torch.pi / N).
-    tmp_x = mb.reshape(x=tmp, shape=[-1, 1], before_op=before_op)
-    tmp_y = mb.reshape(x=tmp, shape=[1, -1], before_op=before_op)
-    base = mb.matmul(x=tmp_x, y=tmp_y, before_op=before_op)
-    base = mb.cast(x=base, dtype="fp32", before_op=before_op)
-    base = mb.mul(x=base, y=2 * np.pi, before_op=before_op)
+    
     N = mb.cast(x=N, dtype="fp32", before_op=before_op)
-    base = mb.real_div(x=base, y=N, before_op=before_op)
-    # Get real part and imaginary part separately.
-    cos_base = mb.cos(x=base, before_op=before_op)
-    sin_base = mb.sin(x=base, before_op=before_op)
+    cos_base, sin_base = _calculate_dft_matrix(N, onesided=False, before_op=before_op)
 
     if not inverse:
         real_part = mb.add(
             x=mb.matmul(x=cos_base, y=reshaped_input_real, before_op=before_op),
             y=mb.matmul(x=sin_base, y=reshaped_input_imag, before_op=before_op),
             before_op=before_op,
         )
@@ -284,14 +306,100 @@
     remain_len = real_data.shape[dim.val] // 2 + 1
     remain_indices = mb.range_1d(start=0, end=remain_len, step=1, before_op=before_op)
     real_data = mb.gather(x=real_data, indices=remain_indices, axis=dim.val, before_op=before_op)
     imag_data = mb.gather(x=imag_data, indices=remain_indices, axis=dim.val, before_op=before_op)
 
     return real_data, imag_data
 
+def _stft(
+    input_real: Var,
+    input_imaginary: Optional[Var],
+    n_fft: Var,
+    hop_length: Optional[Var],
+    win_length: Optional[Var],
+    window: Optional[Var],
+    normalized: Optional[Var],
+    onesided: Optional[Var],
+    before_op: Operation,
+) -> Tuple[Var, Var]:
+    """
+    We can write STFT in terms of convolutions with a DFT kernel.
+    At the end:
+        * The real part output is: cos_base * input_real + sin_base * input_imag
+        * The imaginary part output is: - (sin_base * input_real - cos_base * input_imag)
+    Adapted from: https://github.com/adobe-research/convmelspec/blob/main/convmelspec/mil.py
+    """
+    hop_length = hop_length or mb.floor_div(x=n_fft, y=4, before_op=before_op)
+
+    # input should always be 2D
+    should_increase_rank = input_real.rank == 1
+    if should_increase_rank:
+        input_real = mb.expand_dims(x=input_real, axes=(0,), before_op=before_op)
+        if input_imaginary:
+            input_imaginary = mb.expand_dims(x=input_imaginary, axes=(0,), before_op=before_op)
+
+    is_onesided = onesided and onesided.val
+    cos_base, sin_base = _calculate_dft_matrix(
+        n_fft,
+        onesided=is_onesided,
+        before_op=before_op)
+    
+    # create a window of centered 1s of the requested size
+    if win_length:
+        n_left = (n_fft.val - win_length.val) // 2
+        n_right = n_fft.val - win_length.val - n_left
+
+        left = mb.fill(shape=(n_left,), value=0., before_op=before_op)
+        if not window:
+            window = mb.fill(shape=(win_length.val,), value=1., before_op=before_op)
+        right = mb.fill(shape=(n_right,), value=0., before_op=before_op)
+        
+        # concatenate
+        window = mb.concat(values=(left, window, right), axis=0, before_op=before_op)
+
+    # apply time window
+    if window:
+        cos_base = mb.mul(x=window, y=cos_base, before_op=before_op)
+        sin_base = mb.mul(x=window, y=sin_base, before_op=before_op)
+
+    # conv with DFT kernel across the input signal
+    sin_base = mb.sub(x=0., y=sin_base, before_op=before_op)
+    cos_base = mb.expand_dims(x=cos_base, axes=(1,), before_op=before_op)
+    sin_base = mb.expand_dims(x=sin_base, axes=(1,), before_op=before_op)
+    hop_size = mb.expand_dims(x=hop_length, axes=(0,), before_op=before_op)
+
+    signal_real = mb.expand_dims(x=input_real, axes=(1,), before_op=before_op)
+    cos_windows_real = mb.conv(x=signal_real, weight=cos_base, strides=hop_size, pad_type='valid', before_op=before_op)
+    sin_windows_real = mb.conv(x=signal_real, weight=sin_base, strides=hop_size, pad_type='valid', before_op=before_op)
+
+    if input_imaginary:
+        signal_imaginary = mb.expand_dims(x=input_imaginary, axes=(1,), before_op=before_op)
+        cos_windows_imag = mb.conv(x=signal_imaginary, weight=cos_base, strides=hop_size, pad_type='valid', before_op=before_op)
+        sin_windows_imag = mb.conv(x=signal_imaginary, weight=sin_base, strides=hop_size, pad_type='valid', before_op=before_op)
+
+    # add everything together
+    if input_imaginary:
+        # sin base is already negative so subtract
+        real_result = mb.sub(x=cos_windows_real, y=sin_windows_imag, before_op=before_op)
+        imag_result = mb.add(x=sin_windows_real, y=cos_windows_imag, before_op=before_op)
+    else:
+        real_result = cos_windows_real
+        imag_result = sin_windows_real
+
+    # reduce the rank of the output
+    if should_increase_rank:
+        real_result = mb.squeeze(x=real_result, axes=(0,), before_op=before_op)
+        imag_result = mb.squeeze(x=imag_result, axes=(0,), before_op=before_op)
+
+    if normalized and normalized.val:
+        divisor = mb.sqrt(x=mb.cast(x=n_fft, dtype="fp32", before_op=before_op), before_op=before_op)
+        real_result = mb.real_div(x=real_result, y=divisor, before_op=before_op)
+        imag_result = mb.real_div(x=imag_result, y=divisor, before_op=before_op)
+
+    return real_result, imag_result
 
 def _wrap_complex_output(original_output: Var, real_data: Var, imag_data: Var) -> ComplexVar:
     return ComplexVar(
         name=original_output.name + "_lowered",
         sym_type=original_output.sym_type,
         real=real_data,
         imag=imag_data,
@@ -479,19 +587,41 @@
     real_data, imag_data = _fft_1d(
         real_data, imag_data, n, dim, op.norm, before_op=op, inverse=True
     )
     real_data = _resize_data(real_data, dims=(dim.val,), sizes=(n.val,), before_op=op)
 
     return real_data
 
+@LowerComplex.register_lower_func(op_type="complex_stft")
+def _lower_complex_stft(op: Operation):
+    is_complex = types.is_complex(op.input.dtype)
+
+    # check parameters for validity
+    if op.win_length and op.win_length.val > op.n_fft.val:
+        raise ValueError("Window length must be less than or equal to n_fft")
+    if is_complex and op.onesided and op.onesided.val:
+        raise ValueError("Onesided is only valid for real inputs")
+
+    real, imag = _stft(
+        op.input.real if is_complex else op.input, 
+        op.input.imag if is_complex else None, 
+        op.n_fft, op.hop_length, op.win_length, op.window, op.normalized, op.onesided, before_op=op)
+   
+    return _wrap_complex_output(op.outputs[0], real, imag)
+
 
 @LowerComplex.register_lower_func(op_type="complex_shape")
 def _lower_complex_shape(op: Operation):
     return mb.shape(x=op.data.real, before_op=op)
 
+@LowerComplex.register_lower_func(op_type="complex_abs")
+def _lower_complex_abs(op: Operation):
+    mag_r, mag_i = (mb.square(x=x, before_op=op) for x in (op.x.real, op.x.imag))
+    mag = mb.add(x=mag_r, y=mag_i, before_op=op)
+    return mb.sqrt(x=mag, before_op=op)
 
 def _match_and_replace_dialect_op(block, op):
     if not LowerComplex.has_lower_func(op.op_type):
         return False
 
     lower_res = LowerComplex.get_lower_func(op.op_type)(op)
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/passes/defs/optimize_activation.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/passes/defs/optimize_activation.py`

 * *Files 6% similar despite different names*

```diff
@@ -175,14 +175,41 @@
     """
     Identify the pattern that corresponds to the ``tanh`` approximate version of ``gelu``, and replace it
     with a single ``gelu`` layer with ``mode=TANH_APPROXIMATION``.
 
     The implementation of this pass uses the generic graph pattern matching and transform algorithm
     implemented in ``coremltools.converters.mil.experimental.passes.generic_pass_infrastructure`` and
     documented in ``coremltools/converters/mil/experimental/passes/readme.md``.
+    
+    `Graph for` ``get_gelu_pattern1()``
+    
+    ``y = x * (0.5 * (tanh(((.0447)x^3 + x ) * sqrt(2/pi)) + 1))``
+
+    .. code-block::
+
+	    [...] -----> pow (3) ----> mul (.044715) ---> add -----> mul (sqrt(2/pi)) ---> tanh ----> add (1) ----> mul (0.5) -----> mul ---> [...]
+	      |                                            ^                                                                          ^
+	      |                                            |                                                                          |
+	      |------------------------------------------------------------------------------------------------------------------------
+
+
+    `Graph for` ``get_gelu_pattern2()``
+    
+    ``y = (0.5 * x) * (tanh(((.0447)x^3 + x ) * sqrt(2/pi)) + 1)``
+
+    .. code-block::
+
+                       --------------------------------------------------------------------------------------------------------
+                       ^                                                                                                      |
+                       |                                                                                                      V
+        [...] -----> mul(0.5)    pow (3) ----> mul (.044715) ---> add -----> mul (sqrt(2/pi)) ---> tanh ----> add (1) -----> mul ---> [...]
+          |                        ^                               ^
+          |                        |                               |
+          |---------------------------------------------------------
+
     """
 
     def apply(self, prog):
         fuse_all_blocks(
             ops_arrangement=self.get_gelu_pattern1(),
             var_constraints=self.is_var_constraint_satisifed,
             transform_pattern=self.transform_pattern,
@@ -273,21 +300,21 @@
     @staticmethod
     def get_gelu_pattern2():
         """
         ``y = (0.5 * x) * (tanh(((.0447)x^3 + x ) * sqrt(2/pi)) + 1)``
 
         .. code-block::
 
-							---------------------------------------------------------------------------------------------------------
-							^                                                                                                       |
-							|                                                                                                       V
-			 [...] -----> mul(0.5)    pow (3) ----> mul (.044715) ---> add -----> mul (sqrt(2/pi)) ---> tanh ----> add (1) -----> mul ---> [...]
-			  |                         ^                               ^
-			  |                         |                               |
-			  |------------------------------------------------------------
+                           --------------------------------------------------------------------------------------------------------
+                           ^                                                                                                      |
+                           |                                                                                                      V
+            [...] -----> mul(0.5)    pow (3) ----> mul (.044715) ---> add -----> mul (sqrt(2/pi)) ---> tanh ----> add (1) -----> mul ---> [...]
+              |                        ^                               ^
+              |                        |                               |
+              |---------------------------------------------------------
 		
         """
 
         @mb.program(
             input_specs=[
                 mb.TensorSpec(shape=([get_new_symbol(), get_new_symbol(), get_new_symbol()])),
             ]
@@ -307,40 +334,44 @@
 
 
 @register_pass(namespace="common")
 class fuse_leaky_relu(AbstractGraphPass):
     """
     Detect the ``mul`` ---> ``max`` pattern than can be mapped to ``leaky_relu``.
 
+    `In code form - Input`
+    
     .. code-block::
 
-        In code form:
-        ------------
+       %2 = const(value = alpha) # where 0 <= alpha <= 1
+       %3 = mul(%1, %2) # alpha * x
+       %4 = max(%3, %1) # max(alpha * x, x)
 
-        Input:
-            %2 = const(value = alpha) # where 0 <= alpha <= 1
-            %3 = mul(%1, %2) # alpha * x
-            %4 = max(%3, %1) # max(alpha * x, x)
 
-        Output:
-            %4 = leaky_relu(x=%1, alpha=%2)
+    `In code form - Output`
+    
+    .. code-block::
 
+       %4 = leaky_relu(x=%1, alpha=%2)
 
-        In graphical form:
-        -----------------
 
-        Input graph:
+    `In graphical form - Input graph`
+    
+    .. code-block::
 
-                const (val = alpha)
-                    |
+                 const (val = alpha)
+                     |
         input ----> mul ---------------> maximum -----------> output
           |                                 |
           |----------------------------------
 
-        Output graph:
+
+    `In graphical form - Output graph`
+    
+    .. code-block::
 
         input --------> leaky_relu ---------> output
 
     """
 
     def apply(self, prog):
         for f in prog.functions.values():
@@ -553,44 +584,53 @@
 class fuse_prelu(AbstractGraphPass):
     """
     Detect the following patterns that can be mapped to a ``prelu`` op.
     Essentially, the ``prelu`` op can be broken down into the following ops:
     
     ``y = a * relu(-1 * x) + relu(x)``
 
-    .. code-block::
-
-        Pattern 1:
+    `Pattern 1`
 
+    .. code-block::
 
                           | ------------> relu --------------------|
                           |                                        V
            x (BCHW) ------|                                       add -----> y (BCHW)
                           |                                        ^
                           --------> mul -------> relu -----> mul---|
-                                    ^                         ^
-                                    |                         |
-                                Const(val=-1)               Const(name=a, shape=(C,1,1) or (1,C,1,1))
+                                     ^                        ^
+                                     |                        |
+                                Const(val=-1)            Const(name=a, shape=(C,1,1) or (1,C,1,1))
+
+
+    This will be mapped to:
+
+    .. code-block::
 
-        This will be mapped to:
             x (BCHW) ------> prelu(alpha=a, shape=(C,)) ---------> y (BCHW)
 
 
-        Pattern 2:
+    `Pattern 2`
+
+    .. code-block::
 
                                           | ------------> relu --------------------|
                                           |                                        V
           x (BCHW) -->transpose(BHWC)---->|                                       add -----> y (BHWC)
                                           |                                        ^
                                           --------> mul -------> relu -----> mul---|
                                                      ^                        ^
                                                      |                        |
                                             Const(val=-1)    Const(shape=(C,) or (1,C) or (1,1,C) or (1,1,1,C))
 
-        This will be mapped to:
+
+    This will be mapped to:
+
+    .. code-block::
+
             x (BCHW) ------> prelu ---------> transpose ------> y (BHWC)
     """
 
     def apply(self, prog):
         for pattern in (FusePreluPattern1, FusePreluPattern2):
             fuse_all_blocks(
                 ops_arrangement=pattern.get_prelu_pattern(),
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/passes/defs/optimize_conv.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/passes/defs/optimize_conv.py`

 * *Files 1% similar despite different names*

```diff
@@ -123,17 +123,15 @@
             self._compose_conv1d_block(f)
 
     @block_context_manager
     def _compose_conv1d_block(self, block: Block):
         def help_compose_conv1d_block(block: Block) -> bool:
             for op in list(block.operations):
                 for b in op.blocks:
-                    block_changed = True
-                    while block_changed:
-                        block_changed = help_compose_conv1d_block(b)
+                    self._compose_conv1d_block(b)
 
                 # must start with expanding a 3-D tensor,
                 # who has batch, channel, length dimensions
                 if op.op_type != "expand_dims" or op.x.rank != 3:
                     continue
 
                 # try pattern `expand_dim` -> `conv2d` -> `squeeze`
@@ -324,15 +322,15 @@
             return True
         return False
 
 
 @register_pass(namespace="common")
 class fuse_conv_batchnorm(AbstractGraphPass):
     """
-    Fuse the following ``batch_norm`` layer into ``conv`` and ``conv_transpose``. 
+    Fuse the following ``batch_norm`` layer into ``conv`` and ``conv_transpose``.
     That is, convert ``conv + batch_norm`` to ``conv``, by modifying the weight and bias in the ``conv`` layer.
 
     .. code-block::
 
         Given:
             %2 = conv(%1)
             ...
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/passes/defs/optimize_elementwise_binary.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/passes/defs/optimize_elementwise_binary.py`

 * *Files 1% similar despite different names*

```diff
@@ -189,39 +189,43 @@
 class rank0_expand_dims_swap(AbstractGraphPass):
     """
     Identify the pattern of a ``rank-0`` binary elementwise operation followed by an ``expand_dims`` op.
     In the MIL backend, the output of the ``elementwise`` op becomes rank 1. Hence, an ``expand_dims`` op
     should be added after both of the ``rank-0`` tensors, and the final ``expand_dims`` should be removed.
     If the output var of the binary elementwise op is consumed by more than one op, a ``squeeze`` op
     is inserted.
+    
+    `Input`
 
     .. code-block::
 
-        Input:
-
             [...](rank-0) --> sub --> expand_dims (axes=[0]) --> [...]
                                ^   |
                                |   |--> op2
                                |   |
                                |   |--> op3
                                |
                          [scalar const]
 
-        Output:
+    `Output`
+
+    .. code-block::
+
             [...](rank-0) --> expand_dims (axes=[0]) --> sub --> [...]
                                                           ^   |
                                                           |   |--> squeeze ---> op2
                                                           |                |
                                                           |                |--> op3
                                                           |
                                                     expand_dims (axes=[0])
                                                           ^
                                                           |
                                                           |
                                                     [scalar const]
+
     """
 
     def apply(self, prog):
         for f in prog.functions.values():
             block_changed = True
             while block_changed:
                 block_changed = self._rank0_expand_dims_swap(f)
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/passes/defs/optimize_linear.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/passes/defs/optimize_linear.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/passes/defs/optimize_normalization.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/passes/defs/optimize_normalization.py`

 * *Files 1% similar despite different names*

```diff
@@ -20,15 +20,17 @@
 
 
 @register_pass(namespace="common")
 class fuse_layernorm_or_instancenorm(AbstractGraphPass):
     """
     A graph optimization pass on PyMIL to detect and fuse several variants of ``layer_norm`` or
     ``instance_norm``. Pattern 1 corresponds to either ``layer_norm`` or ``instance_norm``. Patterns 2-4
-    are ``instance_norm``.
+    are ``instance_norm``. You can find these patterns in the methods for this class in the source code.
+    To quickly view the source code, click the **[source]** button at the end of the class definition.
+    
     """
 
     _DEBUG = False  # set to true to plot the block before and after the transformation
 
     def apply(self, prog: Program):
         for f in prog.functions.values():
             block_changed = True
@@ -267,15 +269,16 @@
             - ``axes`` of ``reduce_mean`` is ``[-2, -1]`` or ``[-3, -2]``
               (when ``[-3, -2]``, a channel first to channel last transpose would be inserted).
             - ``gamma`` and ``beta`` are rank 1, after ``squeeze``.
 
         It is ``layer_norm`` if all of the following are true:
             - ``axes`` is either ``[-1]``, ``[-1, -2]``, or ``[-1, -2, -3]``, and so on.
             - ``rank`` of ``gamma`` and ``beta`` is equal to the length of the ``axes``.
-        """
+        
+         """
         ops_to_remove = []
         root_var = reduce_op.x
 
         if root_var.shape is None:
             return False
 
         # check that root_var feeds into exactly 3 ops
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/passes/defs/optimize_repeat_ops.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/passes/defs/optimize_repeat_ops.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/passes/defs/optimize_tensor_operation.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/passes/defs/optimize_tensor_operation.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,28 +1,32 @@
 #  Copyright (c) 2023, Apple Inc. All rights reserved.
 #
 #  Use of this source code is governed by a BSD-3-clause license that can be
 #  found in the LICENSE.txt file or at https://opensource.org/licenses/BSD-3-Clause
 
 import numpy as np
 
+from coremltools.converters.mil._deployment_compatibility import AvailableTarget
+from coremltools.converters.mil.frontend._utils import value_at
 from coremltools.converters.mil.mil import Builder as mb
+from coremltools.converters.mil.mil.block import is_current_opset_version_compatible_with
 from coremltools.converters.mil.mil.passes.graph_pass import AbstractGraphPass
 from coremltools.converters.mil.mil.passes.helper import (
     _check_child_op_type,
     _check_var_scalar_value,
     block_context_manager,
 )
 from coremltools.converters.mil.mil.passes.pass_registry import register_pass
 from coremltools.converters.mil.mil.types.symbolic import any_symbolic
 
+
 @register_pass(namespace="common")
 class expand_high_rank_reshape_and_transpose(AbstractGraphPass):
     """
-    Detect the pattern ``reshape_1-->transpose-->reshape_2``, where ``reshape_1`` has 
+    Detect the pattern ``reshape_1-->transpose-->reshape_2``, where ``reshape_1`` has
     a output tensor with rank >= 6, and the reshape_2 produces a tensor with rank <= 5.
 
     In general, we can expand this pattern into a sequence of rank 4 ``reshape`` and ``transpose`` ops,
     which is supported by Core ML runtime.
 
     .. code-block::
 
@@ -44,15 +48,15 @@
         for f in prog.functions.values():
             block_changed = True
             while block_changed:
                 block_changed = self.expand_high_rank_reshape_and_transpose_block(f)
 
     @staticmethod
     def _match_pattern(op):
-        # We are detecting the 
+        # We are detecting the
         # reshape(>= rank 6) -> transpose -> reshape(<= rank 5) pattern
         ops = [op]
         if op.op_type != "reshape":
             return None
         if op.outputs[0].rank <= 5:
             return None
         if any_symbolic(op.outputs[0].shape):
@@ -85,15 +89,15 @@
                 res *= arr[i]
             return res
 
         reshape_op, transpose_op, last_reshape_op = ops[0], ops[1], ops[2]
         original_shape = reshape_op.outputs[0].shape
         original_perm = transpose_op.perm.val.tolist()
 
-        # Group the consecutive axes in the perm, sometimes this could directly lower the 
+        # Group the consecutive axes in the perm, sometimes this could directly lower the
         # rank under 6.
         #
         # For instance:
         #
         # reshape = mb.reshape(x=x, shape=[1, 2, 3, 4, 5, 6])
         # transpose = mb.transpose(x=reshape, perm=[4, 5, 3, 2, 0, 1])
         # output = mb.reshape(x=transpose, shape=[6, 20, 6])
@@ -106,15 +110,15 @@
         # output = mb.reshape(x=new_transpose, shape=[6, 20, 6])
         #
         # Note that, the output of new_transpose have different rank than transpose,
         # however, they have the same data layout, so the final output is still unchanged.
         group_axes = []
         i = 0
         res = []
-        for i in range(len(original_perm)):  
+        for i in range(len(original_perm)):
             if i > 0 and original_perm[i] == original_perm[i-1] + 1:
                 res.append(original_perm[i])
             else:
                 if len(res) > 0:
                     group_axes.append(res)
                 res = [original_perm[i]]
             if i == len(original_perm) - 1:
@@ -136,15 +140,15 @@
         x = reshape_op.x
 
         if rank < 6:
             # If the intermediate tensors have rank < 6,
             # we can directly use them to replace the original pattern
             x = mb.reshape(x=x, shape=shape, before_op=reshape_op)
             x = mb.transpose(x=x, perm=perm, before_op=reshape_op)
-        
+
         else:
             # Otherwise, we need to expand the rank-N tensor into N reshape, and N transpose ops.
             # Note that all intrermediate tensors have rank 4.
             #
             # The algorithm is as followed:
             #
             # reshape shape: [d_1, d_2, ..., d_n]
@@ -162,17 +166,17 @@
             leading_dim = 1
             memo = set()
             for i in range(rank):
                 axis = perm[i]
                 dim = shape[axis]
                 memo.add(axis)
                 reshape_shape = [
-                    leading_dim, 
-                    _get_prod(0, axis, shape, memo), 
-                    dim, 
+                    leading_dim,
+                    _get_prod(0, axis, shape, memo),
+                    dim,
                     _get_prod(axis + 1, rank, shape, memo)
                 ]
                 x = mb.reshape(x=x, shape=reshape_shape, before_op=reshape_op)
                 x = mb.transpose(x=x, perm=[0, 2, 1, 3], before_op=reshape_op)
                 leading_dim *= dim
 
 
@@ -543,16 +547,29 @@
         W_var = matmul_op.y
         if W_var.val is None:
             return False
         if len(W_var.val.shape) != 2:
             return False
 
         # remove onehot and matmul and replace with gather op
-        out_name = matmul_op.outputs[0].name
-        x = mb.gather(x=W_var, indices=root_var, axis=0, name=out_name, before_op=matmul_op)
+        if is_current_opset_version_compatible_with(AvailableTarget.iOS17):
+            # IOS17 `gather` requires non-negative indices.
+            root_var = mb.select(
+                cond=mb.greater_equal(x=root_var, y=0, before_op=matmul_op),
+                a=root_var,
+                b=mb.add(
+                    x=root_var,
+                    y=value_at(mb.shape(x=W_var, before_op=matmul_op), 0, before_op=matmul_op),
+                    before_op=matmul_op,
+                ),
+                before_op=matmul_op,
+            )
+        x = mb.gather(
+            x=W_var, indices=root_var, axis=0, name=matmul_op.outputs[0].name, before_op=matmul_op
+        )
 
         matmul_op.enclosing_block.replace_uses_of_var_after_op(
             anchor_op=matmul_op, old_var=matmul_op.outputs[0], new_var=x
         )
         # Remove all the ops at once
         block.remove_ops([onehot_op, matmul_op])
         return True
@@ -715,22 +732,26 @@
 class use_reflection_padding(AbstractGraphPass):
     """
     Identify a reflection padding layer composed out of `slices` and `concats`.
 
     .. code-block::
 
         Input graph:
+
                 ------------------------------------------------------------------------------------- |
                 |                                                                                     v
         input(1, 2, 6, 8) ------> slice_by_index(begin=[0, 0, 0, 1], end=[0, 0, 0, 2]) -----> concat(axis=3) ---> out(1, 2, 6, 10)
                 |                                                                                     ^
                 ----------------> slice_by_index(begin=[0, 0, 0, -2], end=[0, 0, 0, -1]) -------------|
 
+
         Output graph:
+
         input(1, 2, 6, 8) -----0> pad(mode=reflect, size=[0, 0, 1, 1]) -----> out(1, 2, 6, 10)
+
     """
 
     def apply(self, prog):
         for f in prog.functions.values():
             self._reflection_padding_block(f)
 
     @staticmethod
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/passes/defs/preprocess.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/passes/defs/preprocess.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/passes/defs/quantization.py` & `coremltools-7.0b1/coremltools/optimize/coreml/_quantization_passes.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,426 +1,380 @@
-#  Copyright (c) 2020, Apple Inc. All rights reserved.
+# Copyright (c) 2023, Apple Inc. All rights reserved.
 #
-#  Use of this source code is governed by a BSD-3-clause license that can be
-#  found in the LICENSE.txt file or at https://opensource.org/licenses/BSD-3-Clause
-
-from enum import Enum as _Enum
-from typing import Set, Text
+# Use of this source code is governed by a BSD-3-clause license that can be
+# found in the LICENSE.txt file or at https://opensource.org/licenses/BSD-3-Clause
 
 import numpy as np
+from tqdm import tqdm
 
 from coremltools import _logger as logger
 from coremltools.converters.mil.backend.mil.load import should_use_weight_file
 from coremltools.converters.mil.mil import Builder as mb
-from coremltools.converters.mil.mil import types
+from coremltools.converters.mil.mil import Operation, Program, types
 from coremltools.converters.mil.mil.ops.defs.iOS16 import (
     constexpr_affine_dequantize,
     constexpr_lut_to_dense,
     constexpr_sparse_to_dense,
 )
-from coremltools.converters.mil.mil.passes.graph_pass import AbstractGraphPass
+from coremltools.converters.mil.mil.passes.defs.quantization import AbstractQuantizationPass
 from coremltools.converters.mil.mil.passes.helper import block_context_manager
 from coremltools.converters.mil.mil.passes.pass_registry import register_pass
-from coremltools.converters.mil.mil.program import Program
-from coremltools.converters.mil.mil.types.type_mapping import (
-    is_builtin,
-    nptype_from_builtin,
-    numpy_type_to_builtin_type,
-)
+from coremltools.converters.mil.mil.types.type_mapping import nptype_from_builtin
 from coremltools.models.neural_network.quantization_utils import _get_kmeans_lookup_table_and_weight
+from coremltools.optimize.coreml._config import (
+    OpLinearQuantizerConfig,
+    OpMagnitudePrunerConfig,
+    OpPalettizerConfig,
+    OpThresholdPrunerConfig,
+    OptimizationConfig,
+)
 
+"""
+--------------------------------
+Compression parameters wrapper -
+--------------------------------
+"""
+class SparseParams:
+    def __init__(self, nonzero_data=None, mask=None, shape=None):
+        self.nonzero_data = nonzero_data
+        self.mask = mask
+        self.shape = shape
 
-class ComputePrecision(_Enum):
-    FLOAT16 = "float16"
-    FLOAT32 = "float32"
+class LutParams:
+    def __init__(self, lut=None, indices=None, shape=None):
+        self.lut = lut
+        self.indices = indices
+        self.shape = shape
 
+class AffineQuantParams:
+    def __init__(self, quantized_data=None, zero_point=None, scale=None, axis=None):
+        self.quantized_data = quantized_data
+        self.zero_point = zero_point
+        self.scale = scale
+        self.axis = axis
 
-class AbstractQuantizationPass(AbstractGraphPass):
-    """
-    Base class for Post-Training Quantization transforms.
+"""
+------------------------
+Compression graph pass -
+------------------------
+"""
+class AbstractCompressionPass(AbstractQuantizationPass):
+    """
+    The abstract class for the compression graph passes.
+    """
+    def __init__(self, config: OptimizationConfig = None, fake_compression: bool = False):
+        if not isinstance(config, (OptimizationConfig, type(None))):
+            raise ValueError(f"config must be of type OptimizationConfig. Got {type(config)}.")
 
-    Derived class needs to implement following two methods:
-        - is_valid_op(op)
-        - transform_op(op)
-    """
+        op_selector = None if config is None else config._op_selector
 
-    type_eps = {}
-    type_min = {}
-    type_negmin = {}
-
-    def __init__(self, op_selector=None):
-        super().__init__()
-        if op_selector is not None and not callable(op_selector):
-            raise TypeError(
-                "Argument `op_selector` needs to be a callable function which accepts "
-                "a MIL operation object and returns a boolean value."
-            )
-        self.op_selector = op_selector
+        super().__init__(op_selector=op_selector)
 
-    def apply(self, prog):
-        """
-        Walks over each operation in the graph and performs following two steps,
-        1. Checks whether an operation is valid for that quantized transform using `is_valid_op` method.
-        2. If yes, calls `transform_op` method of the derived quantized transform class.
+        self.fake_compression = fake_compression
+        self._config = config
+        if config is not None:
+            self._check_config_type(config)
 
-        :param prog: MIL program
-        :return: Transformed MIL program
-        """
+    def apply(self, prog):
         if not isinstance(prog, Program):
             raise TypeError('Transform "{}" can only be applied on PyMIL programs.'.format(self))
 
-        if getattr(self, "skip_ops_by_type", set()) and self.op_selector is not None:
-            raise ValueError(
-                "The graph pass option `skip_ops_by_type` cannot be set along with "
-                "the `op_selector` in FP16ComputePrecision. Please only use one "
-                "method to control which ops to operate on."
-            )
-
         @block_context_manager
         def apply_block(block):
+            valid_consts = []
             for op in list(block.operations):
                 for b in op.blocks:
                     apply_block(b)
 
                 if self.is_valid_op(op):
-                    need_transform: bool
+                    need_transform = True
                     if self.op_selector is not None:
                         need_transform = self.op_selector(op)
-                    else:
-                        need_transform = op.op_type not in getattr(self, "skip_ops_by_type", set())
+
                     if need_transform:
-                        self.transform_op(op)
+                        valid_consts.append(op)
+
+            for op in tqdm(
+                valid_consts,
+                desc=f"Running compression pass {self.__class__.__name__}",
+                unit=" ops",
+            ):
+                self.transform_op(op)
 
         for f in prog.functions.values():
             apply_block(f)
 
-    def transform_op(self, op):
-        """
-        Replaces an op with a transformed op.
+    @property
+    def config(self):
+        return self._config
 
-        :param op: MIL operation
-        :return: None
-        """
-        raise NotImplementedError(
-            'Op transformation for quantization mode "{}" not implemented.'.format(self)
-        )
+    @config.setter
+    def config(self, value):
+        self._check_config_type(value)
+        self._config = value
 
-    def is_valid_op(self, op):
+    @staticmethod
+    def need_compress_const(op: Operation, _is_deprecated: bool, weight_threshold: float):
         """
-        Checks whether an operation is valid for given quantized transform.
-
-        :param op: MIL operation
-        :return: true | false
+        The utility function is checking whether a const op can be compressed.
+        If ``_is_deprecated = True``, the user is using the ``ct.compression_utils``, in which the ops are already filtered by ``op_selector``.
+        For the new ``ct.optimize.coreml`` API, ``op_selector`` is no longer supported, so the ``weight_threshold`` is checked explicitly instead.
         """
-        raise NotImplementedError(
-            'Operation Preconditions for quantization mode "{}" not implemented.'.format(self)
-        )
-
-    @classmethod
-    def _close_to_zero(cls, val, np_type):
-        if np_type not in cls.type_eps:
-            cls.type_eps[np_type] = np.finfo(np_type).eps
-            cls.type_min[np_type] = np.nextafter(0.0, 1.0, dtype=np_type)
-            cls.type_negmin[np_type] = np.nextafter(0.0, -1.0, dtype=np_type)
-
-        return np.isclose(val, 0, atol=cls.type_min[np_type], rtol=cls.type_eps[np_type])
-
-    def __repr__(self):
-        return str(self)
+        val = op.outputs[0].val
+        if _is_deprecated and weight_threshold != None:
+            raise ValueError("weight_threshold cannot be set through the deprecated ct.compression_util API")
 
-    def __str__(self):
-        return type(self).__name__
+        if _is_deprecated:
+            return should_use_weight_file(val)
 
-
-class FP16ComputePrecision(AbstractQuantizationPass):
-    """
-    This transform does the following, for each valid op and if the "op_selector" return True:
-    - For each input of dtype float32, inject a "cast" op to change it to float16 dtype
-    - For each output of dtype float16, inject a "cast" op to change it back to float32
-    """
-
-    def __init__(self, op_selector=None):
-        super(FP16ComputePrecision, self).__init__(op_selector=op_selector)
-        self.target_dtype = "fp16"
-
-        # Var that feeds into multiple ops will be casted once and cached into this dict
-        # For reference: Checkout test_single_input_to_multiple_operations in `TestFP16CastTransform`.
-        self.cache_vars = {}
-
-    def fp16_overflow(self, op):
-        # Constants with values more than 65504 or less than -65504 overflows in FP16
-        for _, inputs in op.inputs.items():
-            is_list_input = isinstance(inputs, (list, tuple))
-            if not is_list_input:
-                inputs = [inputs]
-            for var in inputs:
-                if (
-                    var.op is not None
-                    and var.op.op_type == "const"
-                    and var.is_tensor_or_scalar_of(dtype="fp32")
-                ):
-                    if np.max(np.abs(var.op.val.val), initial=0.0) > 65504:
-                        return True
-        return False
-
-    def is_valid_op(self, op):
-
-        if op.op_type in ["cast", "while_loop", "cond"]:
-            return False
-
-        if op.op_type in [
-            "make_list",
-            "list_gather",
-            "list_scatter",
-            "list_read",
-            "list_write",
-            "list_length",
-        ]:
-            return False  #  rdar://74458192
-
-        if op.op_type in ["gru", "rnn", "lstm"]:
+        # const fed into constexpr ops cannot be compressed
+        if any([child_op.op_type.startswith("constexpr") for child_op in op.outputs[0].child_ops]):
             return False
 
-        if self.fp16_overflow(op):
-            return False
-
-        return True
-
-    def is_valid_parameter(self, op, param_name):
-        type_domain = getattr(op.input_spec.input_types[param_name], "type_domain", None)
-        if type_domain is not None:
-            if len(type_domain) == 0:
-                return True
-            return types.fp16 in type_domain
-        return True
-
-    def _check_underflow_to_zero(self, new_var, var):
-        # We check whether there are casted values that "becomes" 0 which is not ideal for eps purposes.
-        # However we skip arrays with more than 400 in case we compare through a large sparse matrix.
-        if (
-            new_var.val is not None
-            and len(var.val.flatten()) < 400
-            and self._close_to_zero(new_var.val, np.float16).any()
-        ):
-            value_modified = False
-            original_val = var.val.flatten()
-            new_val = new_var.val.flatten()
-
-            for idx in range(len(original_val)):
-                if not self._close_to_zero(original_val[idx], np.float32) and self._close_to_zero(
-                    new_val[idx], np.float16
-                ):
-                    new_val[idx] = (
-                        self.type_min[np.float16]
-                        if np.sign(original_val[idx]) > 0
-                        else self.type_negmin[np.float16]
-                    )
-                    value_modified = True
-
-            if value_modified:
-                if np.isscalar(new_var.val):
-                    new_var._sym_val.val = new_val[0]
-                else:
-                    new_var._sym_val.val = new_val.reshape(new_var.val.shape)
+        if weight_threshold is None:
+            raise ValueError("weight_threshold cannot be None")
 
-    def transform_op(self, op):
-        block = op.enclosing_block
-        casted_inputs = {}
-        inputs_modified = False
-
-        for param, inputs in op.inputs.items():
-            # First loop, iterates over all the input parameters of an operation.
-            if not self.is_valid_parameter(op, param):
-                continue
-
-            is_list_input = isinstance(inputs, (list, tuple))
-            if not is_list_input:
-                inputs = [inputs]
-
-            casted_inputs[param] = list(inputs[:])
-            for i, var in enumerate(inputs):
-                # Second loop, iterates over all the vars of a python list corresponding to an input parameter.
-                if not var.is_tensor_or_scalar_of(dtype="fp32"):
-                    continue
-
-                inputs_modified = True
-                casted_var_name = var.name + "_to_fp16"
-                if (
-                    len(var._child_ops) > 1
-                    and casted_var_name in self.cache_vars
-                    and (block.is_var_visible_in_block(self.cache_vars[casted_var_name]))
-                ):
-                    casted_inputs[param][i] = self.cache_vars[casted_var_name]
-                else:
-                    x = mb.cast(x=var, dtype="fp16", name=casted_var_name, before_op=op)
-                    self._check_underflow_to_zero(x, var)
-
-                    casted_inputs[param][i] = x
-                    if len(var._child_ops) > 1:
-                        self.cache_vars[casted_var_name] = casted_inputs[param][i]
-
-            if not is_list_input:
-                casted_inputs[param] = casted_inputs[param][0]
-
-        if inputs_modified:
-            casted_inputs.update({k: v for k, v in op.inputs.items() if k not in casted_inputs})
-            casted_inputs["name"] = op.name + "_cast"
-            casted_inputs["before_op"] = op
-            quant_output = getattr(mb, op.op_type)(**casted_inputs)
-
-            if not isinstance(quant_output, (list, tuple)):
-                quant_output = [quant_output]
-
-            for old_output_var, new_output_var in zip(op.outputs, quant_output):
-                if old_output_var.is_tensor_or_scalar_of(dtype="fp32") and (
-                    not new_output_var.is_tensor_or_scalar_of(dtype="fp32")
-                ):
-                    x = mb.cast(
-                        x=new_output_var,
-                        dtype="fp32",
-                        name=new_output_var.name + "_to_fp32",
-                        before_op=op,
-                    )
-                    op.enclosing_block.replace_uses_of_var_after_op(
-                        anchor_op=op,
-                        old_var=old_output_var,
-                        new_var=x,
-                        force_replace=True,
-                    )
-                else:
-                    op.enclosing_block.replace_uses_of_var_after_op(
-                        anchor_op=op,
-                        old_var=old_output_var,
-                        new_var=new_output_var,
-                        force_replace=True,
-                    )
-
-            block.remove_ops([op])
+        return should_use_weight_file(val) and val.size > weight_threshold
 
+    def _check_config_type(self, config: OptimizationConfig):
+        """
+        The utility function is checking the OptimizationConfig is holding correct type of op config.
+        """
+        def get_supported_types_as_str(supported_type):
+            if not isinstance(supported_type, (tuple, list)):
+                supported_type = [supported_type]
+            return ", ".join([f"{val.__name__}" for val in supported_type])
+
+        all_configs = []
+        if config.global_config is not None:
+            all_configs.append(config.global_config)
+        all_configs.extend(list(config.op_type_configs.values()))
+        all_configs.extend(list(config.op_name_configs.values()))
+
+        for config in all_configs:
+            if not isinstance(config, self._SUPPORTED_CONFIG_TYPE) and config is not None:
+                supported_type_str = get_supported_types_as_str(self._SUPPORTED_CONFIG_TYPE)
+                raise ValueError(f"{self.__class__.__name__} only accept {supported_type_str} type config. Got {config.__class__.__name__}.")
 
-@register_pass(namespace="common")
-class add_fp16_cast(FP16ComputePrecision):
+@register_pass(namespace="compression")
+class prune_weights(AbstractCompressionPass):
     """
-    For each input of dtype float32, inject a ``cast`` op to change it to float16 dtype.
+    This transform works for each ``const`` op if:
     
-    For each output of dtype float16, inject a ``cast`` op to change it back to float32.
-
-    This pass is the registered interface for FP16ComputePrecision, which makes it consistent with
-    other passes' interfaces.
+    - ``_is_deprecated=True`` and the ``op_selector`` returns ``True``.
+    - ``_is_deprecated=False`` and the ``const`` value size ``> weight_threshold``.
 
-    Support options:
+    The transform performs the following:
     
-    - ``skip_ops_by_type``: Skip op types specified by comma-separated string; for example, ``"mul,const"``.
-    """
-
-    _skip_ops_by_type: Set[Text] = set()
-
-    @property
-    def skip_ops_by_type(self):
-        return self._skip_ops_by_type
-
-    @skip_ops_by_type.setter
-    def skip_ops_by_type(self, criteria: Text):
-        self._skip_ops_by_type = set(criteria.split(","))
-
-
-class SparseParams:
-    def __init__(self, nonzero_data=None, mask=None, shape=None):
-        self.nonzero_data = nonzero_data
-        self.mask = mask
-        self.shape = shape
-
-
-class WeightSparsifier(AbstractQuantizationPass):
+    - The fraction of values with the least absolute value are zeroed out (self.sparsity).
+    - If ``fake_compression=False``, the zeroed-out value is encoded using the ``constexpr_sparse_to_dense`` op.
+    - If ``fake_compression=True``, the zeroed-out value is encoded using the ``const`` op.
+    - Old ``const`` is replaced by a new operation with zeroed-out value.
     """
-    This transform does the following, for each const op and if the "op_selector" return True:
-    - (self.sparsity) fraction of values with the least absolute value are zeroed out.
-    - If fake_compression=False,  Zeroed-Out Value is encoded via constexpr_sparse_to_dense op
-    - If fake_compression=True,   Zeroed-Out Value is encoded via const op
-    - Old const is replaced by a new operation with zeroed-out value.
-    """
-
-    WEIGHT_SPARSIFICATION_MODES = ("THRESHOLD_BASED", "PERCENTILE_BASED")
-
-    def __init__(
-        self,
-        mode="threshold_based",
-        threshold=1e-3,
-        target_percentile=1.0,
-        fake_compression=False,
-        op_selector=None,
-    ):
-        super().__init__(op_selector=op_selector)
-        self.fake_compression = fake_compression
-        self.mode = mode.upper()
-        self.threshold = threshold
-        self.target_percentile = target_percentile
-
-        if not self.mode in WeightSparsifier.WEIGHT_SPARSIFICATION_MODES:
-            msg = "Only mode {} supported for weight sparsification. Got mode {}.".format(
-                WeightSparsifier.WEIGHT_SPARSIFICATION_MODES, self.mode
-            )
-            raise ValueError(msg)
-
-        if self.mode == "PERCENTILE_BASED" and (
-            self.target_percentile < 0 or self.target_percentile > 1
-        ):
-            raise ValueError(
-                "Invalid value of target_percentile: {}. Needs to be in [0, 1]".format(
-                    self.target_percentile
-                )
-            )
-
-        if self.mode == "THRESHOLD_BASED" and self.threshold < 0:
-            raise ValueError(
-                "Invalid value of threshold: {}. Needs to be in [0, inf)".format(self.threshold)
-            )
+    _SUPPORTED_CONFIG_TYPE = (OpMagnitudePrunerConfig, OpThresholdPrunerConfig)
 
-    def is_valid_op(self, op):
-        if op.op_type == "const" and should_use_weight_file(op.val.val):
+    def is_valid_op(self, op: Operation):
+        if op.op_type == "const" and should_use_weight_file(op.outputs[0].val):
             return True
         return False
 
     @staticmethod
-    def compress(val, mode, target_percentile=None, threshold=None):
-
-        mode = mode.upper()
-
-        def sparsify_with_percentile(val, target_percentile):
-            q = target_percentile * 100
-            return np.where(np.abs(val) <= np.percentile(np.abs(val), q), 0, val)
-
-        def sparsify_with_thresohld(val, threshold):
-            return np.where(np.abs(val) <= threshold, 0, val)
-
-        if not isinstance(val, (np.ndarray, np.generic)):
-            raise ValueError("Only numpy arrays are supported")
-
+    def _pack_val_to_sparse_param(val):
         flattened_val = val.flatten()
-
-        if mode == "PERCENTILE_BASED":
-            flattened_val = sparsify_with_percentile(flattened_val, target_percentile)
-        elif mode == "THRESHOLD_BASED":
-            flattened_val = sparsify_with_thresohld(flattened_val, threshold)
-
         params = SparseParams()
         params.nonzero_data = flattened_val[np.where(flattened_val != 0)]
         params.mask = np.packbits(np.where(flattened_val != 0, 1, 0), bitorder="little")
         params.shape = val.shape
         return params
 
     @staticmethod
+    def compress_by_threshold(val, threshold, minimum_sparsity_percentile):
+        val = np.where(np.abs(val) <= threshold, 0, val)
+        sparsity_percentile = np.sum(val == 0.0) / val.size
+        if sparsity_percentile < minimum_sparsity_percentile:
+            msg = (f"weight value has sparsity of {sparsity_percentile} < "
+                   f"minimum_sparsity_percentile {minimum_sparsity_percentile}. Skipped."
+                  )
+            logger.warning(msg)
+            return None
+        return prune_weights._pack_val_to_sparse_param(val)
+
+    @staticmethod
+    def compress_by_magnitude(val, target_sparsity, block_size=None, dim=None):
+        def _apply_block_sparsity(val, block_size, dim):
+            shape = val.shape
+            rank = len(shape)
+            assert dim in [0, 1], "bock sparsity pruning only supports dim [0, 1]."
+            assert rank in [2, 3, 4, 5], "block sparsity only supports weights of rank [2, 3, 4, 5]"
+            """
+            Block sparsity follows these steps:
+            
+            1. Input tensor with shape of ``[C_out, Cin, *K]``.
+            2. If ``dim = 1``, the tensor is transposed to ``[Cin, C_out, *K]``. The following example assumes ``dim = 0``.
+            3. Pad ``C_out`` so that it can be divided by ``block_size``: ``[C_out_pad, Cin, *K]``.
+            4. Divide the output channel by ``block_size`` and reshape: ``[C_out_pad // block_size, block_size, C_in, *K]``.
+            5. Compute the magnitude for each block: ``[C_out_pad // block_size, 1, C_in, *K]``.
+            6. Replicate the magnitude values for each block: ``[C_out_pad // block_size, block_size, C_in, *K]``.
+            7. Reshape the tensor back to ``[Cout_pad, C_in, *K]``.
+            8. Crop the tensor to ``[C_out, C_in, *K]``.
+            9. If ``dim = 1``, tranpose the tensor back to the original layout.
+            """
+            if dim == 1:
+                perm = [1, 0] + list(range(2, rank))
+                val = np.transpose(val, axes=perm)
+
+            channel = val.shape[0]
+            if channel % block_size != 0:
+                pad_size = block_size - channel % block_size
+                pad_value = [(0, pad_size)] + [(0, 0)] * (rank - 1)
+                val = np.pad(val, pad_value)
+            shape_padded = val.shape
+            assert shape_padded[0] % block_size == 0
+
+            new_shape = list(shape_padded)
+            new_shape.insert(1, block_size)
+            new_shape[0] = new_shape[0] // block_size
+            val = np.reshape(val, (new_shape))
+
+            val = val * val
+            val = np.sum(val, axis=1, keepdims=True)
+            val = np.sqrt(val)
+
+            reps = [1] * (rank + 1)
+            reps[1] = block_size
+            val = np.tile(val, reps)
+            val =  np.reshape(val, shape_padded)
+            val = val[:channel]
+
+            if dim == 1:
+                val = np.transpose(val, axes=perm)
+
+            return val
+
+        magnitude_map = np.abs(val)
+        if block_size is not None:
+            channel = magnitude_map.shape[dim]
+            if block_size > channel / 2:
+                logger.warning(
+                    f"block_size > channel / 2 is not applicable for block sparsity. Got block_size = {block_size}, channel = {channel}. Skipped."
+                )
+                return None
+
+            magnitude_map = _apply_block_sparsity(magnitude_map, block_size, dim)
+        q = target_sparsity * 100
+        if q == 100:
+            val = 0 * val
+        elif q != 0:
+            val = np.where(magnitude_map <= np.percentile(magnitude_map, q), 0, val)
+        return prune_weights._pack_val_to_sparse_param(val)
+
+    @staticmethod
+    def compress_by_nm_sparsity(val, n_m_ratio, dim):
+        n, m = n_m_ratio
+        assert n <= m
+        shape = val.shape
+        rank = len(shape)
+        assert dim in [0, 1], "n:m pruning only supports dim [0, 1]."
+        assert rank in [2, 3, 4, 5], "m:m pruning only supports weights of rank [2, 3, 4, 5]"
+        """
+        The `n-m` pruning process follows these steps:
+        1. Input tensor with shape of ``[C_out, C_in, *K]``, where ``K`` is the spatial dimension from ``0`` to ``3``.
+        2. If ``axis = 1``, tranpose the tensor to shape ``[*K, C_out, C_in]``; otherwise, ``(axis = 0)`` to ``[*K, C_in, C_out]``.
+        3. For the case of ``axis = 1``, reshape input to a 2D tensor ``[*K*C_out, C_in]``. Similar for ``axis = 0``.
+        4. Pad the last dimension with ``0`` so that it can be divided by ``m``: ``[*K*C_out, C_in_pad]``.
+        5. Reshape the tensor to have the last dimension ``m``: ``[*K*C_out*C_in_pad//m, m]``.
+        6. For each vector of length ``m``, we set the lowest ``n`` magnitute elements to ``0``.
+        7. Reshape the tensor back to the shape of ``[*K*C_out, C_in_pad]``.
+        8. Crop the last dimension to match the original shape of ``[*K*C_out, C_in]``.
+        9. Reshape the tensor to shape ``[*K, C_out, C_in]``.
+        10. Tranpose the tensor back to ``[C_out, C_in, K]``.
+        """
+        perm = list(range(2, rank)) + [0, 1]
+        if dim == 0:
+            perm[-2], perm[-1] = 1, 0
+        weight = np.copy(np.transpose(val, axes=perm))
+        shape_begin = weight.shape
+
+        weight = np.reshape(weight, (-1, weight.shape[-1]))
+        channel = weight.shape[-1]
+        if m > channel / 2:
+            logger.warning(
+                f"m > channel / 2 is not applicable for n:m pruning. Got m = {m}, channel = {channel}. Skipped."
+            )
+            return None
+        if channel % m != 0:
+            pad_size = m - channel % m
+            weight = np.pad(weight, ((0, 0), (0, pad_size)))
+        shape_padded = weight.shape
+        assert shape_padded[-1] % m == 0
+
+        weight = np.reshape(weight, (-1, m))
+        magnitute = np.abs(weight)
+        indices = np.argsort(magnitute, axis=-1)[:, :n]
+
+        n_m_mask = np.zeros(weight.shape).astype(val.dtype)
+        np.put_along_axis(n_m_mask, indices, 1.0, axis=-1)
+        n_m_mask = np.reshape(n_m_mask, shape_padded)
+        n_m_mask = n_m_mask[:, :channel]
+
+        n_m_mask = np.reshape(n_m_mask, shape_begin)
+        perm_back = [perm.index(i) for i in range(rank)]
+        n_m_mask = np.transpose(n_m_mask, axes=perm_back)
+
+        val = val * (1 - n_m_mask)
+        return prune_weights._pack_val_to_sparse_param(val)
+
+    @staticmethod
     def decompress(params):
         if not isinstance(params, SparseParams):
             raise ValueError("Invalid type of params")
         return constexpr_sparse_to_dense.decompress(params.nonzero_data, params.mask, params.shape)
 
-    def transform_op(self, op):
-        block = op.enclosing_block
-        sparse_params = self.compress(op.val.val, self.mode, self.target_percentile, self.threshold)
+    def transform_op(self, op: Operation):
+        op_config = self.config._get_const_op_config(op)
+        if op_config is None:
+            return
+        if not self.need_compress_const(op, self.config._is_deprecated, op_config.weight_threshold):
+            return
+
+        if not isinstance(op.outputs[0].val, (np.ndarray, np.generic)):
+            raise ValueError("Only numpy arrays are supported")
+
+        if isinstance(op_config, OpThresholdPrunerConfig):
+            sparse_params = self.compress_by_threshold(
+                                val=op.outputs[0].val,
+                                threshold=op_config.threshold,
+                                minimum_sparsity_percentile=op_config.minimum_sparsity_percentile
+                            )
+        elif isinstance(op_config, OpMagnitudePrunerConfig):
+            # Structural sparsity can only be applied to conv / linear weight
+            # For non applicable constant, we skip the compression,
+            # we do allow the user to do structural pruning for non applicable constant,
+            # if it is explicitly set by set_op_name,
+            if not op_config._check_const_op_is_valid(op):
+                if op.name not in self.config.op_name_configs:
+                    logger.warning(f"op named {op.name} not applicable for {OpMagnitudePrunerConfig} configuration. Skipped.")
+                    return
+
+            if op_config.target_sparsity is not None:
+                sparse_params = self.compress_by_magnitude(
+                                    val=op.outputs[0].val,
+                                    target_sparsity=op_config.target_sparsity,
+                                    block_size=op_config.block_size,
+                                    dim=op_config.dim,
+                                )
+            elif op_config.n_m_ratio is not None:
+                sparse_params = self.compress_by_nm_sparsity(
+                                    val=op.outputs[0].val,
+                                    n_m_ratio=op_config.n_m_ratio,
+                                    dim=op_config.dim,
+                                )
+
+        if sparse_params is None:
+            return
 
         if not self.fake_compression:
             new_var = mb.constexpr_sparse_to_dense(
                 nonzero_data=sparse_params.nonzero_data,
                 mask=sparse_params.mask,
                 shape=np.uint32(sparse_params.shape),
                 before_op=op,
@@ -437,85 +391,41 @@
         op.enclosing_block.replace_uses_of_var_after_op(
             anchor_op=op,
             old_var=op.outputs[0],
             new_var=new_var,
             no_check_var_types=True,
         )
 
-        block.remove_ops([op])
-
+        op.enclosing_block.remove_ops([op])
 
-class LutParams:
-    def __init__(self, lut=None, indices=None, shape=None):
-        self.lut = lut
-        self.indices = indices
-        self.shape = shape
-
-
-class WeightPalettizer(AbstractQuantizationPass):
-    """
-    This transform does the following, for each const op and if the "op_selector" return True:
-    - A linear look up table with 2**(nbits) entries is created and value is represented via indexing into this look up table.
-    - If fake_compression=False,  compressed value is encoded via constexpr_lut_to_dense op
-    - If fake_compression=True,   compressed value is decompressed and then encoded via const op
-    - Old const op is replaced by a newly created operation.
+@register_pass(namespace="compression")
+class palettize_weights(AbstractCompressionPass):
     """
+    This transform works for each ``const`` op if:
 
-    WEIGHT_PALETTIZATION_MODES = ("KMEANS", "UNIFORM", "UNIQUE", "CUSTOM")
+    - ``_is_deprecated=True`` and the ``op_selector`` returns ``True``.
+    - ``_is_deprecated=False`` and the ``const`` value size ``> weight_threshold``.
 
-    def __init__(
-        self, nbits, fake_compression=False, op_selector=None, mode="kmeans", lut_function=None
-    ):
-        super().__init__(op_selector=op_selector)
-        self.fake_compression = fake_compression
-        self.nbits = nbits
-        self.mode = mode.upper()
-        self.lut_function = lut_function
-
-        if not self.mode in WeightPalettizer.WEIGHT_PALETTIZATION_MODES:
-            msg = "Only mode {} supported for weight palettization. Got mode {}.".format(
-                WeightPalettizer.WEIGHT_PALETTIZATION_MODES, self.mode
-            )
-            raise ValueError(msg)
-
-        if nbits is None and self.mode in ("KMEANS", "UNIFORM"):
-            msg = "nbits must be provided for mode {}".format(mode)
-            raise ValueError(msg)
-
-        if nbits is not None and self.mode in ("UNIQUE", "CUSTOM"):
-            msg = "nbits must NOT be provided for mode {}".format(mode)
-            raise ValueError(msg)
-
-        if self.nbits is not None and self.nbits not in (1, 2, 4, 6, 8):
-            raise ValueError(
-                "Invalid value of nbits ({}) for palettization. Supported bits are {{1, 2, 4, 6, 8}}".format(
-                    nbits
-                )
-            )
-
-        if (self.mode == "CUSTOM") ^ (lut_function is not None):
-            msg = "lut_function must be None if mode is not custom, and that it cannot be None when the mode is custom."
-            raise ValueError(msg)
-
-        if self.mode == "CUSTOM" and not callable(self.lut_function):
-            msg = "A function object must be provided as lut_function. Got a lut_functions as type {}".format(
-                type(self.lut_function)
-            )
-            raise ValueError(msg)
+    The transform performs the following:
+    
+    - A linear look-up table (LUT) with 2\ :sup:`nbits` entries is created with values represented by indexing into this LUT.
+    - If ``fake_compression=False``, compressed value is encoded using the ``constexpr_lut_to_dense`` op.
+    - If ``fake_compression=True``,  compressed value is decompressed and then encoded using the ``const`` op.
+    - Old ``const`` op is replaced by a newly created operation.
+    """
+    _SUPPORTED_CONFIG_TYPE = OpPalettizerConfig
 
-    def is_valid_op(self, op):
-        if op.op_type == "const" and should_use_weight_file(op.val.val):
+    def is_valid_op(self, op: Operation):
+        if op.op_type == "const" and should_use_weight_file(op.outputs[0].val):
             return True
         return False
 
     @staticmethod
     def compress(val, mode, nbits=None, lut_function=None):
 
-        mode = mode.upper()
-
         def compress_kmeans(val, nbits):
             lut, indices = _get_kmeans_lookup_table_and_weight(nbits, val)
             lut = lut.astype(val.dtype)
             indices = indices.astype(np.uint8)
             return lut, indices
 
         def compress_uniform(val, nbits):
@@ -585,15 +495,15 @@
             if lut.dtype != val.dtype:
                 msg = "Dtype mismatched between LUT ({}) and weight ({})".format(
                     lut.dtype, val.dtype
                 )
                 raise ValueError(msg)
 
         if not isinstance(val, (np.ndarray, np.generic)):
-            raise ValueError("Only numpy arrays are supported")
+            raise ValueError(f"Only numpy arrays are supported. Got {type(val)}")
 
         if mode == "KMEANS":
             lut, indices = compress_kmeans(val, nbits)
         elif mode == "UNIFORM":
             lut, indices = compress_uniform(val, nbits)
         elif mode == "UNIQUE":
             nbits = get_nbits_for_unique_mode(val)
@@ -613,17 +523,27 @@
 
     @staticmethod
     def decompress(params):
         if not isinstance(params, LutParams):
             raise ValueError("Invalid type of params")
         return constexpr_lut_to_dense.decompress(params.lut, params.indices, params.shape)
 
-    def transform_op(self, op):
-        block = op.enclosing_block
-        lut_params = self.compress(op.val.val, self.mode, self.nbits, self.lut_function)
+    def transform_op(self, op: Operation):
+        op_config = self.config._get_const_op_config(op)
+        if op_config is None:
+            return
+        if not self.need_compress_const(op, self.config._is_deprecated, op_config.weight_threshold):
+            return
+
+        lut_params = self.compress(
+            op.outputs[0].val,
+            op_config.mode,
+            op_config.nbits,
+            op_config.lut_function
+        )
 
         if lut_params is None:
             return
 
         if not self.fake_compression:
             new_var = mb.constexpr_lut_to_dense(
                 indices=lut_params.indices,
@@ -643,64 +563,34 @@
         op.enclosing_block.replace_uses_of_var_after_op(
             anchor_op=op,
             old_var=op.outputs[0],
             new_var=new_var,
             no_check_var_types=True,
         )
 
-        block.remove_ops([op])
+        op.enclosing_block.remove_ops([op])
 
+@register_pass(namespace="compression")
+class linear_quantize_weights(AbstractCompressionPass):
+    """
+    This transform works for each ``const`` op if:
 
-class AffineQuantParams:
-    def __init__(self, quantized_data=None, zero_point=None, scale=None, axis=None):
-        self.quantized_data = quantized_data
-        self.zero_point = zero_point
-        self.scale = scale
-        self.axis = axis
+    - ``_is_deprecated=True`` and the ``op_selector`` returns ``True``.
+    - ``_is_deprecated=False`` and the ``const`` value size ``> weight_threshold``.
 
+    The transform performs the following:
 
-class WeightAffineQuantizer(AbstractQuantizationPass):
-    """
-    This transform does the following, for each const op and if the "op_selector" return True:
     - Values are linearly quantized into unsigned 8-bits.
-    - If fake_compression=False,  compressed value is encoded via constexpr_affine_dequantize op
-    - If fake_compression=True,   compressed value is decompressed and then encoded via const op
-    - Old const is replaced by a newly created operation.
+    - If ``fake_compression=False``, compressed value is encoded using the ``constexpr_affine_dequantize`` op.
+    - If ``fake_compression=True``, compressed value is decompressed and then encoded using the ``const`` op.
     """
+    _SUPPORTED_CONFIG_TYPE = OpLinearQuantizerConfig
 
-    WEIGHT_AFFINE_QUANTIZATION_MODES = ("LINEAR_SYMMETRIC", "LINEAR")
-    WEIGHT_AFFINE_DTYPES = (types.int8, types.uint8)
-
-    def __init__(self, fake_compression=False, op_selector=None, mode="linear", dtype=np.int8):
-        super().__init__(op_selector=op_selector)
-        self.fake_compression = fake_compression
-        self.mode = mode.upper()
-
-        # check mode
-        if not self.mode in WeightAffineQuantizer.WEIGHT_AFFINE_QUANTIZATION_MODES:
-            msg = "Only mode {} supported for weight affine quantization. Got mode {}.".format(
-                WeightAffineQuantizer.WEIGHT_AFFINE_QUANTIZATION_MODES, self.mode
-            )
-            raise ValueError(msg)
-
-        # check dtype
-        msg = f"dtype={dtype} is unsupported for affine_quantize_weights."
-        if is_builtin(dtype):
-            self.dtype = dtype
-        else:
-            try:
-                self.dtype = numpy_type_to_builtin_type(dtype)
-            except TypeError:
-                raise ValueError(msg)
-
-        if self.dtype not in WeightAffineQuantizer.WEIGHT_AFFINE_DTYPES:
-            raise ValueError(msg)
-
-    def is_valid_op(self, op):
-        if op.op_type == "const" and should_use_weight_file(op.val.val):
+    def is_valid_op(self, op: Operation):
+        if op.op_type == "const" and should_use_weight_file(op.outputs[0].val):
             return True
         return False
 
     @staticmethod
     def _get_axis(op):
         axis = 0
         var = op.outputs[0]
@@ -716,15 +606,14 @@
             For instance, after rounding and addition, we might get `128` for the int8 quantization.
             This utility function ensures the val in the data range before doing the cast.
             '''
             val = np.minimum(val, high)
             val = np.maximum(val, low)
             return val.astype(np_dtype)
 
-        mode = mode.upper()
         mode_dtype_to_range = {
             (types.int8, "LINEAR"): (-128, 127),
             (types.int8, "LINEAR_SYMMETRIC"): (-127, 127),
             (types.uint8, "LINEAR"): (0, 255),
             (types.uint8, "LINEAR_SYMMETRIC"): (0, 254),
         }
 
@@ -782,17 +671,22 @@
     def decompress(params):
         if not isinstance(params, AffineQuantParams):
             raise ValueError("Invalid type of params")
         return constexpr_affine_dequantize.decompress(
             params.quantized_data, params.zero_point, params.scale, params.axis
         )
 
-    def transform_op(self, op):
-        block = op.enclosing_block
-        quant_params = self.compress(op.val.val, self._get_axis(op), self.mode, self.dtype)
+    def transform_op(self, op: Operation):
+        op_config = self.config._get_const_op_config(op)
+        if op_config is None:
+            return
+        if not self.need_compress_const(op, self.config._is_deprecated, op_config.weight_threshold):
+            return
+
+        quant_params = self.compress(op.outputs[0].val, self._get_axis(op), op_config.mode, op_config.dtype)
 
         if not self.fake_compression:
             new_var = mb.constexpr_affine_dequantize(
                 quantized_data=quant_params.quantized_data,
                 zero_point=quant_params.zero_point,
                 scale=quant_params.scale,
                 axis=quant_params.axis,
@@ -810,39 +704,38 @@
         op.enclosing_block.replace_uses_of_var_after_op(
             anchor_op=op,
             old_var=op.outputs[0],
             new_var=new_var,
             no_check_var_types=True,
         )
 
-        block.remove_ops([op])
-
+        op.enclosing_block.remove_ops([op])
 
+@register_pass(namespace="compression")
 class WeightDecompressor(AbstractQuantizationPass):
     """
-    This graph pass transforms the constexpr ops back into mb.const op.
-    constexpr ops includes:
-    (1) constexpr_affine_dequantize
-    (2) constexpr_lut_to_dense
-    (3) constexpr_sparse_to_dense
+    This graph pass transforms the ``constexpr`` op back into ``mb.const`` op.
+    The ``constexpr`` op includes:
+
+    - ``constexpr_affine_dequantize``
+    - ``constexpr_lut_to_dense``
+    - ``constexpr_sparse_to_dense``
     """
 
     def __init__(self, op_selector):
         super().__init__(op_selector=op_selector)
 
     def is_valid_op(self, op):
         return op.op_type in (
             "constexpr_affine_dequantize",
             "constexpr_lut_to_dense",
             "constexpr_sparse_to_dense",
         )
 
     def transform_op(self, op):
-        block = op.enclosing_block
-
         decompressed_val = op.value_inference()
         new_var = mb.const(
             val=decompressed_val,
             before_op=op,
             name=op.name,
         )
 
@@ -850,8 +743,8 @@
             anchor_op=op,
             old_var=op.outputs[0],
             new_var=new_var,
             no_check_var_types=True,
             force_replace=True,
         )
 
-        block.remove_ops([op])
+        op.enclosing_block.remove_ops([op])
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/passes/graph_pass.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/passes/graph_pass.py`

 * *Files 8% similar despite different names*

```diff
@@ -17,18 +17,14 @@
     Available options are documented in each pass's docstring.
     """
 
     # The Callable option_val is for op_selector backward compatibility only.
     def __init__(self, option_name: Text, option_val: Union[Text, Callable[[Operation], bool]]):
         if not isinstance(option_name, Text):
             raise ValueError(f"The option name should be text, but got {type(option_name)}")
-        if not isinstance(option_val, Text) and not isinstance(option_val, Callable):
-            raise ValueError(
-                f"The option value should be text or callable, but got {type(option_val)}"
-            )
         self._option_name = option_name
         self._option_val = option_val
 
     def __str__(self):
         return f"{self.option_name}: {self.option_val}"
 
     @property
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/passes/helper.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/passes/helper.py`

 * *Files 3% similar despite different names*

```diff
@@ -6,14 +6,20 @@
 from typing import List
 
 import numpy as np
 
 from coremltools.converters.mil.mil import Block, Operation, Var
 from coremltools.converters.mil.mil.passes.graph_pass import AbstractGraphPass
 
+class classproperty(property):
+    """
+    A decorator class that allow us to have a class-level property
+    """
+    def __get__(self, owner, cls):
+        return self.fget(cls)
 
 def block_context_manager(func):
     """
     This decorator executes a function under the context manager `with block`.
     For instance, given a function `func` with an input block and other arguments:
 
     def func(block, *args):
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/passes/pass_pipeline.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/passes/pass_pipeline.py`

 * *Files 16% similar despite different names*

```diff
@@ -9,25 +9,40 @@
 
 from tqdm import tqdm
 
 from coremltools import _logger as logger
 from coremltools.converters._profile_utils import _profile
 from coremltools.converters.mil import Program
 from coremltools.converters.mil.mil.passes.graph_pass import PassOption
+from coremltools.converters.mil.mil.passes.helper import classproperty as _classproperty
 from coremltools.converters.mil.mil.passes.pass_registry import PASS_REGISTRY
 
 _COMMON_PASSES: List[Text] = [
     "common::lower_complex_dialect_ops",
     "common::update_output_dtypes",
     "common::cast_optimization",
+    "common::noop_elimination",
+    # quantization pass 1: canonicalize zero point
+    # always start quantization passes with canonicalizations
+    "common::nullify_redundant_quantization_zero_point",
+    # quantization pass 2: remove redundancy
+    # remove redundancy after canonicalization but before anything else
+    "common::dequantize_quantize_pair_elimination",
+    # the main quantization passes
+    "common::distributive_quantized_binary_op_scale_normalization",
+    # the last quantization pass: replace const dequantize with constexpr
+    # after all quantization passes, since constexpr will not be further optimized
+    # before const elimination, otherwise const dequantize would get bloated
+    "common::dequantize_to_constexpr",
     "common::const_elimination",
     "common::sanitize_input_output_names",
     "common::divide_to_multiply",
     "common::add_conv_transpose_output_shape",
     "common::const_elimination",
+    "common::const_deduplication",  # after all consts have been settled
     "common::loop_invariant_elimination",
     "common::remove_symbolic_reshape",
     "common::noop_elimination",
     "common::fuse_matmul_weight_bias",
     "common::fuse_linear_bias",
     "common::fuse_gelu_tanh_approximation",
     "common::fuse_gelu_exact",
@@ -78,45 +93,54 @@
 ]
 
 _CLEANUP_PASSES: List[Text] = [
     "common::dead_code_elimination",
     "common::const_elimination",
     "common::cast_optimization",
     "common::const_elimination",
+    "common::const_deduplication",  # after all consts have been settled
     "common::loop_invariant_elimination",
     "common::noop_elimination",
     "common::dedup_op_and_var_names",
     "common::reduce_transposes",  # fuse_layernorm_or_instancenorm can potentially add transposes
     "common::remove_redundant_ops",
     "common::topological_reorder",
     "common::dead_code_elimination",  # always end with dce
 ]
 
-_FRONTEND_TORCH_PASSES = [
+_PALETTIZATION_PASSES: List[Text] = [
+    "compression::palettize_weights",
+]
+
+_SPARSIFICATION_PASSES: List[Text] = [
+    "compression::prune_weights",
+]
+
+_FRONTEND_TORCH_PASSES: List[Text] = [
     "common::dead_code_elimination",
     "common::loop_invariant_elimination",
     "common::dead_code_elimination",
     "torch::torch_upsample_to_core_upsample",
     "torch::torch_tensor_assign_to_core",
 ]
 
-_FRONTEND_TF1_PASSES = [
+_FRONTEND_TF1_PASSES: List[Text] = [
     "common::dead_code_elimination",
     "common::loop_invariant_elimination",
     "tensorflow::backfill_make_list_elem_type",
     # DCE to reduce tf_lstm_block outputs and allow lstm_rewrite to
     # ssa lstm
     "common::dead_code_elimination",
     # tensorflow::tf_lstm_to_core_lstm must come before
     # tensorflow::expand_tf_lstm
     "tensorflow::tf_lstm_to_core_lstm",
     "tensorflow::expand_tf_lstm",
 ]
 
-_FRONTEND_TF2_PASSES = [
+_FRONTEND_TF2_PASSES: List[Text] = [
     "common::dead_code_elimination",
     "common::loop_invariant_elimination",
     # tensorflow2::remove_vacuous_cond should come before
     # tensorflow::backfill_make_list_elem_type.
     "tensorflow2::remove_vacuous_cond",
     "tensorflow::backfill_make_list_elem_type",
     # DCE to reduce tf_lstm_block outputs and allow lstm_rewrite to
@@ -124,32 +148,34 @@
     "common::dead_code_elimination",
     # tensorflow::tf_lstm_to_core_lstm must come before
     # tensorflow::expand_tf_lstm
     "tensorflow::tf_lstm_to_core_lstm",
     "tensorflow::expand_tf_lstm",
 ]
 
-_BACKEND_MIL_PASSES = [
+_BACKEND_MIL_PASSES: List[Text] = [
     "common::const_elimination",
     "mil_backend::adjust_io_to_supported_types",
     "mil_backend::insert_image_preprocessing_ops",
     "mil_backend::fuse_activation_silu",
     "common::const_elimination",  # rank0_expand_dims_swap might introduce some new const tensor
+    "common::const_deduplication",  # after all consts have been settled
     "common::cast_optimization",
     "common::dead_code_elimination",
     "mil_backend::sanitize_name_strings",
     "common::dedup_op_and_var_names",
     "nn_backend::handle_unused_inputs",  # must come after dce.
 ]
 
-_BACKEND_NN_PASSES = [
+_BACKEND_NN_PASSES: List[Text] = [
     "nn_backend::decompose_conv1d",  # at the beginning of nn pass
     "nn_backend::commingle_loop_vars",
     "nn_backend::handle_return_inputs_as_outputs",
     "common::const_elimination",
+    "common::const_deduplication",  # after all consts have been settled
     # "remove_redundant_ops" pass should be applied towards the end, once other graph passes have done their optimizations.
     # For instance, it should come after passes such as "reduce_transpose" that can introduce redundant transposes
     # in the network (while reducing the total number of transposes), and after passes such as "fuse_layernorm_or_instancenorm"
     # which detects patterns that involve redundant ops ("sub") etc.
     "common::remove_redundant_ops",
     "common::dead_code_elimination",
     "nn_backend::handle_unused_inputs",  # must come after dce.
@@ -161,27 +187,27 @@
     """
     A pipeline that contains graph passes.
 
     Create a default pipeline (with all default graph passes that will operate on the program):
 
     .. sourcecode:: python
 
-        pipeline = PassPipeline()
+        pipeline = ct.PassPipeline.DEFAULT
 
     Create an empty pipeline (this will result in no graph passes being applied to the model):
 
     .. sourcecode:: python
 
-        pipeline = PassPipeline.get_empty_pipeline()
+        pipeline = ct.PassPipeline.EMPTY
 
     Add passes to pipeline:
 
     .. sourcecode:: python
 
-        pipeline=ct.PassPipeline()
+        pipeline = ct.PassPipeline.DEFAULT
         pipeline.append_pass("common::reduce_transposes")
         pipeline.insert_pass(index=0, pass_name="common::reduce_transposes")
         # Can also specify all passes by setting the passes of the pipeline.
         pipeline.passes = ["common::reduce_transposes", "common::add_fp16_cast"]
 
     Remove passes:
 
@@ -195,27 +221,36 @@
     Inspect passes in the pipeline:
 
     .. sourcecode:: python
 
         # Get all passes.
         pass_names = pipeline.passes
         # Find indexes of a specific pass.
-        pass_indexes = [idx for idx, pass_name in enumerate(pass_names) if pass_names[idx] == "common::reduce_transposes"]
+        pass_indexes = [
+            idx
+            for idx, pass_name in enumerate(pass_names)
+            if pass_names[idx] == "common::reduce_transposes"
+        ]
 
     Set options for a specific pass:
 
     .. sourcecode:: python
 
-        pipeline=ct.PassPipeline()
-        pipeline.set_options(pass_name="common::const_elimination", options={"skip_const_by_size":
-            "100000"}, override=False)
+        pipeline = ct.PassPipeline.DEFAULT
+        pipeline.set_options(
+            pass_name="common::const_elimination",
+            options={"skip_const_by_size": "100000"},
+        )
     """
 
     _PIPELINE_NAME_TO_PASSES = {
         "default": _COMMON_PASSES + _CLEANUP_PASSES,
+        "cleanup": _CLEANUP_PASSES,
+        "default_palettization": _PALETTIZATION_PASSES + _COMMON_PASSES + _CLEANUP_PASSES,
+        "default_sparsification": _SPARSIFICATION_PASSES + _COMMON_PASSES + _CLEANUP_PASSES,
         "empty": [],
         # Frontend pipelines.
         "frontend_milinternal": [],
         "frontend_pytorch": _FRONTEND_TORCH_PASSES,
         "frontend_tensorflow": _FRONTEND_TF1_PASSES,
         "frontend_tensorflow2": _FRONTEND_TF2_PASSES,
         # Backend pipelines.
@@ -282,25 +317,24 @@
         """
         return self._pass_options.get(pass_name, None)
 
     def get_all_options(self) -> Dict[Text, List[PassOption]]:
         """Gets all options in the pipeline."""
         return self._pass_options
 
-    def set_options(self, pass_name: Text, options: Dict[Text, Text], override: bool = False):
+    def set_options(self, pass_name: Text, options: Dict[Text, Text], override: bool = True):
         """Sets options for a specific pass."""
-        if self._pass_options.get(pass_name, None) and not override:
-            raise ValueError(f"The pass {pass_name} already has associated options.")
+        if self._pass_options.get(pass_name, None):
+            if not override:
+                raise ValueError(f"The pass {pass_name} already has associated options.")
+            else:
+                logger.warning(f"The pass {pass_name} already has associated options. Override the existing options.")
+
         pass_options: List[PassOption] = []
         for option_name, option_val in options.items():
-            if not (isinstance(option_name, str) and isinstance(option_val, str)):
-                raise ValueError(
-                    f"The options must be specified by Dict[Text, Text], but got "
-                    f"Dict[{type(option_name)}, {type(option_val)}]"
-                )
             pass_option = PassOption(option_name=option_name, option_val=option_val)
             pass_options.append(pass_option)
         self._pass_options[pass_name] = pass_options
 
     def set_options_by_another_pipeline(self, other_pipeline: PassPipeline):
         """
         Convenience method for setting options from another pipeline's options.
@@ -318,42 +352,75 @@
                 raise ValueError(
                     f"This pass pipeline is not valid. The pass {pass_name} has "
                     f"associated options but it's not in the passes. Passes in this "
                     f"pipeline: {self._pass_names}"
                 )
 
     @staticmethod
-    def get_empty_pipeline() -> PassPipeline:
-        """Creates an empty pipeline without any pass."""
-        return PassPipeline(pass_names=[])
-
-    @staticmethod
     def get_pipeline(pipeline_name: Text) -> PassPipeline:
         """
         Gets a pipeline based on the name. Raises an error if no pipeline is found.
-        Available Pipelines:
-        - "default": _COMMON_PASSES + _CLEANUP_PASSES
-        - "empty": empty
-        - "frontend_pytorch": _FRONTEND_TORCH_PASSES
-        - "frontend_tensorflow": _FRONTEND_TF1_PASSES
-        - "frontend_tensorflow2": _FRONTEND_TF2_PASSES
-        - "frontend_milinternal": empty
-        - "backend_mlprogram": _BACKEND_MIL_PASSES
-        - "backend_neuralnetwork": _BACKEND_NN_PASSES
-        - "backend_milinternal": empty
+        Available Pipelines are defined in _PIPELINE_NAME_TO_PASSES
         """
         if pipeline_name not in PassPipeline._PIPELINE_NAME_TO_PASSES:
             raise ValueError(
                 f"There is no pipeline for `{pipeline_name}`. "
                 f"Available pipelines: {PassPipeline._PIPELINE_NAME_TO_PASSES.keys()}"
             )
         return PassPipeline(PassPipeline._PIPELINE_NAME_TO_PASSES[pipeline_name], pipeline_name)
 
+    """
+    =======================================
+    Pre-defined PassPipeline configurations
+    =======================================
+    """
+    @_classproperty
+    def EMPTY(cls) -> PassPipeline:
+        """Creates an empty pipeline without any pass."""
+        return PassPipeline(pass_names=[])
+
+    @_classproperty
+    def DEFAULT(cls) -> PassPipeline:
+        """Creates a pipeline that the converter uses by default."""
+        return PassPipeline.get_pipeline("default")
+
+    @_classproperty
+    def CLEANUP(cls) -> PassPipeline:
+        """Create a pipeline that contains cleanup passes."""
+        return PassPipeline.get_pipeline("cleanup")
+
+    @_classproperty
+    def DEFAULT_PALETTIZATION(cls) -> PassPipeline:
+        """Create a default palettization pipeline to convert a compressed source model"""
+        # We use delayed import to avoid circular import
+        from coremltools.optimize.coreml import OpPalettizerConfig, OptimizationConfig
+        pipeline = PassPipeline.get_pipeline("default_palettization")
+
+        # set default palettization
+        config = OptimizationConfig(global_config=OpPalettizerConfig(mode="unique"))
+        pipeline.set_options("compression::palettize_weights", {"config": config})
+        return pipeline
+
+    @_classproperty
+    def DEFAULT_PRUNING(cls) -> PassPipeline:
+        """Create a default sparsification pipeline to convert a compressed source model"""
+        # We use delayed import to avoid circular import
+        from coremltools.optimize.coreml import OpThresholdPrunerConfig, OptimizationConfig
+        pipeline = PassPipeline.get_pipeline("default_sparsification")
+
+        # set default sparsification
+        config = OptimizationConfig(
+            global_config=OpThresholdPrunerConfig(
+                threshold=1e-3,
+            )
+        )
+        pipeline.set_options("compression::prune_weights", {"config": config})
+        return pipeline
 
-class PipelineManager:
+class PassPipelineManager:
     @staticmethod
     @_profile
     def apply_pipeline(prog: Program, pass_pipeline: PassPipeline):
         """Apply a pass pipeline to a program, which modifies the program in-place."""
         if pass_pipeline is None:
             raise ValueError("The pass_pipeline cannot be None.")
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/passes/pass_registry.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/passes/pass_registry.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/passes/tests/test_pass_pipeline.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/passes/tests/test_pass_pipeline.py`

 * *Files 9% similar despite different names*

```diff
@@ -3,15 +3,15 @@
 #  Use of this source code is governed by a BSD-3-clause license that can be
 #  found in the LICENSE.txt file or at https://opensource.org/licenses/BSD-3-Clause
 
 import numpy as np
 import pytest
 
 from coremltools.converters.mil.mil import Builder as mb
-from coremltools.converters.mil.mil.passes.pass_pipeline import PassPipeline, PipelineManager
+from coremltools.converters.mil.mil.passes.pass_pipeline import PassPipeline, PassPipelineManager
 from coremltools.converters.mil.testing_utils import assert_model_is_valid, get_op_types_in_program
 
 np.random.seed(1984)
 
 
 class TestPassPipeline:
     def test_add_pass(self):
@@ -19,51 +19,51 @@
         def prog(x):
             x = mb.relu(x=x)
             x = mb.relu(x=x)
             x = mb.add(x=x, y=1.0)
             return x
 
         assert get_op_types_in_program(prog) == ["relu", "relu", "add"]
-        pipeline = PassPipeline.get_empty_pipeline()
+        pipeline = PassPipeline.EMPTY
         pipeline.append_pass("common::merge_consecutive_relus")
         assert pipeline.passes == ["common::merge_consecutive_relus"]
-        PipelineManager.apply_pipeline(prog, pipeline)
+        PassPipelineManager.apply_pipeline(prog, pipeline)
         assert get_op_types_in_program(prog) == ["relu", "add"]
 
         inputs = {"x": (2, 3)}
         assert_model_is_valid(
             prog,
             inputs,
             expected_output_shapes={prog.functions["main"].outputs[0].name: (2, 3)},
         )
 
     def test_insert_pass_at_index(self):
-        pipeline = PassPipeline.get_empty_pipeline()
+        pipeline = PassPipeline.EMPTY
         pipeline.insert_pass(index=0, pass_name="common::merge_consecutive_relus")
         pipeline.insert_pass(index=0, pass_name="common::noop_elimination")
         pipeline.insert_pass(index=1, pass_name="common::noop_elimination")
         pipeline.insert_pass(index=1, pass_name="common::merge_consecutive_reshapes")
         assert pipeline.passes == [
             "common::noop_elimination",
             "common::merge_consecutive_reshapes",
             "common::noop_elimination",
             "common::merge_consecutive_relus",
         ]
 
     def test_insert_invalid_pass(self):
-        pipeline = PassPipeline.get_empty_pipeline()
+        pipeline = PassPipeline.EMPTY
         with pytest.raises(ValueError, match="The pass test_pass is not registered."):
             pipeline.append_pass("test_pass")
         with pytest.raises(ValueError, match="The pass test_pass is not registered."):
             pipeline.insert_pass(0, "test_pass")
         with pytest.raises(ValueError, match="The pass invalid_pass is not registered."):
             pipeline.passes = ["invalid_pass"]
 
     def test_remove_passes(self):
-        pipeline = PassPipeline.get_empty_pipeline()
+        pipeline = PassPipeline.EMPTY
         pipeline.passes = [
             "common::noop_elimination",
             "common::merge_consecutive_reshapes",
             "common::noop_elimination",
             "common::merge_consecutive_relus",
         ]
         pipeline.remove_passes(passes_names=["common::noop_elimination"])
@@ -71,36 +71,36 @@
             "common::merge_consecutive_reshapes",
             "common::merge_consecutive_relus",
         ]
         pipeline.remove_pass(index=1)
         assert pipeline.passes == ["common::merge_consecutive_reshapes"]
 
     def test_set_pass_options(self):
-        pipeline = PassPipeline.get_empty_pipeline()
+        pipeline = PassPipeline.EMPTY
         pipeline.append_pass("common::add_fp16_cast")
         assert pipeline.get_options("common::add_fp16_cast") is None
         pipeline.set_options("common::add_fp16_cast", {"skip_ops_by_type": "matmul,const"})
         assert len(pipeline.get_options("common::add_fp16_cast")) == 1
         assert pipeline.get_options("common::add_fp16_cast")[0].option_name == "skip_ops_by_type"
         assert pipeline.get_options("common::add_fp16_cast")[0].option_val == "matmul,const"
 
     def test_set_pass_options_already_exist(self):
         pipeline = PassPipeline()
         pipeline.set_options("common::add_fp16_cast", {"skip_ops_by_type": "matmul,const"})
         with pytest.raises(
             ValueError, match="The pass common::add_fp16_cast already has associated options."
         ):
-            pipeline.set_options("common::add_fp16_cast", {"skip_ops_by_type": "concat"})
+            pipeline.set_options("common::add_fp16_cast", {"skip_ops_by_type": "concat"}, override=False)
         # Override the options.
-        pipeline.set_options("common::add_fp16_cast", {"skip_ops_by_type": "concat"}, override=True)
+        pipeline.set_options("common::add_fp16_cast", {"skip_ops_by_type": "concat"})
         assert pipeline.get_options("common::add_fp16_cast")[0].option_name == "skip_ops_by_type"
         assert pipeline.get_options("common::add_fp16_cast")[0].option_val == "concat"
 
     def test_set_pass_options_for_pass_not_in_pipeline(self):
-        pipeline = PassPipeline.get_empty_pipeline()
+        pipeline = PassPipeline.EMPTY
         pipeline.set_options("common::add_fp16_cast", {"skip_ops_by_type": "matmul,const"})
         with pytest.raises(
             ValueError,
             match="This pass pipeline is not valid. The pass common::add_fp16_cast "
             "has associated options but it's not in the passes.",
         ):
             pipeline.validate()
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/passes/tests/test_passes.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/passes/tests/test_passes.py`

 * *Files 2% similar despite different names*

```diff
@@ -14,33 +14,191 @@
 import coremltools as ct
 from coremltools._deps import _IS_MACOS
 from coremltools.converters.mil.experimental.passes.generic_pass_infrastructure import (
     register_generic_pass,
 )
 from coremltools.converters.mil.mil import Builder as mb
 from coremltools.converters.mil.mil import Function, Program, Symbol, get_new_symbol, types
-from coremltools.converters.mil.mil.passes.defs import quantization
 from coremltools.converters.mil.mil.passes.defs.cleanup import topological_reorder
 from coremltools.converters.mil.mil.passes.helper import _check_var_scalar_value
 from coremltools.converters.mil.mil.passes.pass_registry import PASS_REGISTRY
 from coremltools.converters.mil.mil.types import numpy_type_to_builtin_type
 from coremltools.converters.mil.testing_reqs import backends
 from coremltools.converters.mil.testing_utils import (
     apply_pass_and_basic_check,
     assert_model_is_valid,
     assert_op_count_match,
     assert_same_output_names,
     get_op_names_in_program,
     get_op_types_in_program,
 )
+from coremltools.models.utils import _macos_version
+
+import coremltools.optimize as cto
 
 np.random.seed(1984)
 _VALIDATE_MODEL = True
 
 
+class TestConstDeduplication:
+    def test_const_deduplication(self):
+        BATCH_DIM = 5
+        SEQUENCE_LENGTH = 4
+        ENCODING_DIM = 256
+        EMBEDDING_DIM = 128
+        weight = np.random.rand(EMBEDDING_DIM, ENCODING_DIM)
+        bias = np.random.rand(EMBEDDING_DIM)
+
+        @mb.program(
+            input_specs=[
+                mb.TensorSpec(shape=(BATCH_DIM, SEQUENCE_LENGTH, ENCODING_DIM)),
+                mb.TensorSpec(shape=(BATCH_DIM, SEQUENCE_LENGTH, ENCODING_DIM)),
+            ]
+        )
+        def prog(q, k):
+            q_e = mb.linear(x=q, weight=weight, bias=bias)
+            k_e = mb.linear(x=k, weight=weight, bias=bias)
+            attention = mb.matmul(x=q_e, y=k_e, transpose_y=True)
+            return attention
+
+        prev_prog, _, _ = apply_pass_and_basic_check(prog, "common::const_deduplication")
+        assert_op_count_match(prev_prog, expect=6, op="const")
+        assert_op_count_match(prog, expect=4, op="const")
+
+    def test_constexpr_deduplication(self):
+        BATCH_DIM = 5
+        SEQUENCE_LENGTH = 4
+        ENCODING_DIM = 256
+        EMBEDDING_DIM = 128
+        quantized_weight = np.random.randint(
+            -128, 128, size=(EMBEDDING_DIM, ENCODING_DIM), dtype=np.int8
+        )
+        quantized_bias = np.random.randint(-128, 128, size=EMBEDDING_DIM, dtype=np.int8)
+
+        @mb.program(
+            input_specs=[
+                mb.TensorSpec(shape=(BATCH_DIM, SEQUENCE_LENGTH, ENCODING_DIM)),
+                mb.TensorSpec(shape=(BATCH_DIM, SEQUENCE_LENGTH, ENCODING_DIM)),
+            ]
+        )
+        def prog(q, k):
+            weight_q = mb.constexpr_affine_dequantize(
+                quantized_data=quantized_weight,
+                zero_point=np.int8(0),
+                scale=np.float32(1.0),
+                axis=0,
+            )
+            weight_k = mb.constexpr_affine_dequantize(
+                quantized_data=quantized_weight,
+                zero_point=np.int8(0),
+                scale=np.float32(1.0),
+                axis=0,
+            )
+            bias_q = mb.constexpr_affine_dequantize(
+                quantized_data=quantized_bias,
+                zero_point=np.int8(0),
+                scale=np.float32(1.0),
+                axis=0,
+            )
+            bias_k = mb.constexpr_affine_dequantize(
+                quantized_data=quantized_bias,
+                zero_point=np.int8(0),
+                scale=np.float32(1.0),
+                axis=0,
+            )
+            q_e = mb.linear(x=q, weight=weight_q, bias=bias_q)
+            k_e = mb.linear(x=k, weight=weight_k, bias=bias_k)
+            attention = mb.matmul(x=q_e, y=k_e, transpose_y=True)
+            return attention
+
+        prev_prog, _, _ = apply_pass_and_basic_check(prog, "common::const_deduplication")
+        assert_op_count_match(prev_prog, expect=4, op="constexpr_affine_dequantize")
+        assert_op_count_match(prog, expect=2, op="constexpr_affine_dequantize")
+
+    def test_const_deduplication_as_outputs(self):
+        """
+        If the duplicated constants are block outputs, we should not remove them.
+        """
+        # case 1:
+        # const_2 can be eliminated since it is not block output
+        const = np.random.rand(40, 20, 30)
+
+        @mb.program(
+            input_specs=[
+                mb.TensorSpec(
+                    shape=(
+                        40,
+                        20,
+                        30,
+                    )
+                )
+            ]
+        )
+        def prog(x):
+            const_1 = mb.const(val=const, name="const_1")
+            const_2 = mb.const(val=const, name="const_2")
+            x = mb.relu(x=x)
+            x = mb.add(x=x, y=const_2)
+            return x, const_1
+
+        prev_prog, _, _ = apply_pass_and_basic_check(prog, "common::const_deduplication")
+        assert_op_count_match(prev_prog, expect=2, op="const")
+        assert_op_count_match(prog, expect=1, op="const")
+        assert prog.functions["main"].outputs[1].name == "const_1"
+
+        # case 2:
+        # const_2 can not be eliminated since it is a block output
+        const = np.random.rand(40, 20, 30)
+
+        @mb.program(
+            input_specs=[
+                mb.TensorSpec(
+                    shape=(
+                        40,
+                        20,
+                        30,
+                    )
+                )
+            ]
+        )
+        def prog(x):
+            const_1 = mb.const(val=const, name="const_1")
+            const_2 = mb.const(val=const, name="const_2")
+            x = mb.relu(x=x)
+            x = mb.add(x=x, y=const_2)
+            return x, const_1, const_2
+
+        prev_prog, _, _ = apply_pass_and_basic_check(prog, "common::const_deduplication")
+        assert_op_count_match(prev_prog, expect=2, op="const")
+        assert_op_count_match(prog, expect=2, op="const")
+        assert prog.functions["main"].outputs[1].name == "const_1"
+        assert prog.functions["main"].outputs[2].name == "const_2"
+
+    @pytest.mark.skip("rdar://109374995 consts are not shared across blocks")
+    def test_const_deduplication_multiple_blocks(self):
+        weight = np.random.rand(5, 3, 2, 2)
+
+        @mb.program(input_specs=[mb.TensorSpec(shape=(4, 3, 8, 8))])
+        def prog(x):
+            def _true_fn():
+                return mb.conv(x=x, weight=weight, pad_type="valid")
+
+            def _false_fn():
+                y = mb.mul(x=x, y=2.0)
+                return mb.conv(x=y, weight=weight, pad_type="valid")
+
+            x_gt_0_tensor = mb.greater(x=x, y=0.0)
+            x_gt_0 = mb.slice_by_index(x=x_gt_0_tensor, begin=(0, 0, 0, 0), end=(1, 1, 1, 1))
+            return mb.cond(pred=x_gt_0, _true_fn=_true_fn, _false_fn=_false_fn)
+
+        prev_prog, _, _ = apply_pass_and_basic_check(prog, "common::const_deduplication")
+        assert_op_count_match(prev_prog, expect=8, op="const")
+        assert_op_count_match(prog, expect=6, op="const")
+
+
 class TestConstElimination:
     def test_const_elimination(self):
         @mb.program(input_specs=[mb.TensorSpec(shape=(2, 4))])
         def prog(x):
             a = np.random.rand(2, 4).astype(np.float32)
             double_a = mb.add(x=a, y=a)
             return mb.add(x=x, y=double_a)
@@ -63,14 +221,35 @@
             return mb.add(x=x, y=double_a)
 
         prev_prog, _, _ = apply_pass_and_basic_check(prog, "common::const_elimination")
         assert get_op_types_in_program(prev_prog) == ["constexpr_cast", "add", "add"]
         # Not fold into const because the upstream constexpr_cast op is non-replaceable.
         assert get_op_types_in_program(prog) == ["constexpr_cast", "add", "add"]
 
+    def test_force_const_eliminate_nonreplaceable_ops(self):
+        @mb.program(input_specs=[mb.TensorSpec(shape=(3,), dtype=types.int32)])
+        def prog(x):
+            a = np.random.rand(2, 3, 5).astype(np.float16)
+            constexpr_a = mb.constexpr_cast(source_val=a, output_dtype="fp32")
+            double_a = mb.add(x=constexpr_a, y=a.astype(np.float32))
+            a_shape = mb.shape(x=double_a)
+            return mb.add(x=x, y=a_shape)
+
+        assert get_op_types_in_program(prog) == ["constexpr_cast", "add", "shape", "add"]
+
+        apply_pass_and_basic_check(prog, "common::const_elimination")
+        # still fold shape into const regardless the non-replaceable upstream
+        # constexpr_cast op, since it only provides a shape
+        assert get_op_types_in_program(prog) == ["constexpr_cast", "add", "add"]
+
+        apply_pass_and_basic_check(prog, "common::dead_code_elimination")
+        # constexpr_cast(a) and add(a, a) no longer contributes to output,
+        # so they should get dead code eliminated
+        assert get_op_types_in_program(prog) == ["add"]
+
     @patch(
         "coremltools.converters.mil.mil.passes.defs.cleanup.const_elimination._skip_const_by_size",
         1000,
     )
     def test_const_elimination_larger_than_threshold(self):
         @mb.program(input_specs=[mb.TensorSpec(shape=(2, 3))])
         def prog(x):
@@ -1457,14 +1636,46 @@
             "cast",
             "random_uniform",
             "random_uniform",
             "add",
         ]
         assert get_op_types_in_program(prog) == ["cast", "random_uniform", "random_uniform", "add"]
 
+    def test_nonreplaceable_vars(self):
+        """
+        Nonreplaceable vars shouldn't be removed, e.g. palettized weights
+
+        const_1----->add---->add_1------|
+                      |                 |
+                    input              add---->output
+                      |                 |
+        const_2----->add---->add_2------|
+        """
+        def _constexpr_lut_to_dense():
+            lut_data = np.array(
+                [-19.0, 4.0, 0.0, -1.0, 1.0, 3.0, 5.0, -8.0, 19, 13, 42, 4.5, 5.4, 2.0, -6, -7]
+            ).astype(np.float32)
+            indices = np.array([212, 21]).astype(np.uint8)
+            shape = np.array([4, 1]).astype(np.uint32)
+            return mb.constexpr_lut_to_dense(lut=lut_data, indices=indices, shape=shape)
+
+        @mb.program(input_specs=[mb.TensorSpec(shape=(4, 1))])
+        def prog(x):
+            constexpr_1 = _constexpr_lut_to_dense()
+            constexpr_2 = _constexpr_lut_to_dense()
+            c = mb.add(x=constexpr_1, y=x)
+            d = mb.add(x=constexpr_2, y=x)
+            return mb.add(x=c, y=d)
+
+        prev_prog, _, _ = apply_pass_and_basic_check(
+            prog,
+            "common::remove_redundant_ops",
+        )
+        assert get_op_types_in_program(prev_prog) == get_op_types_in_program(prog)
+
 
 class TestTopologicalReorder:
     def test_move_sink_casts_to_the_end(self):
         """
         Input graph:
             x (input) ---> square ---> cast (output)
             |
@@ -1951,14 +2162,41 @@
         assert get_op_types_in_program(prog) == ["gelu"]
         assert_model_is_valid(
             prog,
             {"x": (3, 5, 6)},
             expected_output_shapes={block.outputs[0].name: (3, 5, 6)},
         )
 
+    def test_gelu_tanh_multiple_final_operations(self):
+        """
+        The generic pattern matching only supports one final output operation. For multiple final
+        operations, we want to make sure it just skip the pattern matching instead of failing the
+        whole conversion.
+        """
+
+        @mb.program(input_specs=[mb.TensorSpec(shape=(3, 5, 6))])
+        def prog(x):
+            x_1 = mb.mul(x=x, y=0.5)
+            x_2 = mb.pow(x=x, y=3.0)
+            x_2 = mb.mul(x=x_2, y=0.044715)
+            x_2 = mb.add(x=x, y=x_2)
+            x_2 = mb.mul(x=x_2, y=np.sqrt(2 / np.pi))
+            x_2 = mb.tanh(x=x_2)
+            x_2 = mb.add(x=x_2, y=1.0)
+            x_2 = mb.mul(x=x_1, y=x_2)
+            x_2 = mb.mul(x=x_2, y=1.0)
+            return x_2
+
+        with pytest.warns(
+            UserWarning,
+            match="User defined pattern matched to more than one final operation. "
+            "Skipped the pattern matching.",
+        ):
+            apply_pass_and_basic_check(prog, "common::fuse_gelu_tanh_approximation")
+
     @pytest.mark.parametrize(
         "op_type, is_first_op1, is_first_op2, is_first_op3, is_first_op4, const_mul_first",
         itertools.product(
             ["real_div", "mul"],
             [True, False],
             [True, False],
             [True, False],
@@ -2312,37 +2550,37 @@
     def _get_constexpr_cast(shape):
         val = np.random.rand(*shape).astype(np.float16)
         return mb.constexpr_cast(source_val=val, output_dtype="fp32")
 
     @staticmethod
     def _get_constexpr_sparse_to_dense(shape):
         val = np.random.rand(*shape)
-        sparse_params = quantization.WeightSparsifier.compress(
-            val=val, mode="PERCENTILE_MODE", target_percentile=0.4
+        sparse_params = cto.coreml._quantization_passes.prune_weights.compress_by_magnitude(
+            val=val, target_sparsity=0.4
         )
         return mb.constexpr_sparse_to_dense(
             nonzero_data=sparse_params.nonzero_data,
             mask=sparse_params.mask,
             shape=np.uint32(sparse_params.shape),
         )
 
     @staticmethod
     def _get_constexpr_lut_to_dense(shape):
         val = np.random.rand(*shape)
-        lut_params = quantization.WeightPalettizer.compress(val=val, nbits=4, mode="UNIFORM")
+        lut_params = cto.coreml._quantization_passes.palettize_weights.compress(val=val, nbits=4, mode="UNIFORM")
         return mb.constexpr_lut_to_dense(
             indices=lut_params.indices,
             lut=lut_params.lut,
             shape=np.uint32(lut_params.shape),
         )
 
     @staticmethod
     def _get_constexpr_affine_dequantize(shape):
         val = np.random.rand(*shape)
-        quant_params = quantization.WeightAffineQuantizer.compress(
+        quant_params = cto.coreml._quantization_passes.linear_quantize_weights.compress(
             val=val, axis=0, mode="LINEAR_SYMMETRIC", dtype=types.uint8
         )
         return mb.constexpr_affine_dequantize(
             quantized_data=quant_params.quantized_data,
             zero_point=quant_params.zero_point,
             scale=quant_params.scale,
             axis=quant_params.axis,
@@ -2776,16 +3014,16 @@
         Output:
               |--> transpose_6 -> output_1
             x -
               |--> transpose_7 -> output_2
         """
         @mb.program(input_specs=[mb.TensorSpec(shape=(1, 2, 3, 4))])
         def prog(x):
-            x1 = mb.transpose(x=x, perm=[0, 2, 1, 3]) 
-            x1 = mb.transpose(x=x1, perm=[3, 2, 0, 1]) 
+            x1 = mb.transpose(x=x, perm=[0, 2, 1, 3])
+            x1 = mb.transpose(x=x1, perm=[3, 2, 0, 1])
             x2 = mb.transpose(x=x, perm=[3, 2, 1, 0])
             x2 = mb.transpose(x=x2, perm=[2, 3, 0, 1])
             x2 = mb.transpose(x=x2, perm=[0, 2, 1, 3])
 
             return x1, x2
 
         prev_prog, _, block = apply_pass_and_basic_check(prog, "common::merge_consecutive_transposes")
@@ -2805,15 +3043,15 @@
     def test_success_reduce_consecutive_transposes_with_output_constrain(self):
         """
         Input:
             x --> transpose_1 -> transpose_2 -> transpose_3 -> transpose_4 -> transpose_5 -> add -> output_3
                        |                            |
                        v                            v
                     output_1                     output_2
-              
+
         Output:
             x --> transpose_1 -> transpose_6 -> transpose_7-> add -> output_1
                        |             |
                        v             v
                     output_2       output_3
         """
         @mb.program(input_specs=[mb.TensorSpec(shape=(1, 2, 3, 4))])
@@ -2845,15 +3083,15 @@
         assert block.outputs[1].name == "output_2"
         assert block.outputs[2].name == "output_3"
 
     def test_not_merge_transposes(self):
         """
         Input:
             x --> transpose_1 -> add -> transpose_2 -> output
-              
+
         Output:
             x --> transpose_1 -> add -> transpose_2 -> output
         """
         @mb.program(input_specs=[mb.TensorSpec(shape=(1, 2, 3, 4))])
         def prog(x):
             x = mb.transpose(x=x, perm=[3, 2, 1, 0])
             x = mb.add(x=x, y=1.)
@@ -2874,20 +3112,20 @@
 class TestExpandHighRankReshapeAndTranspose:
     @staticmethod
     def _test_numerical(prog, input_shape, reshape_shape, perm, output_shape):
         x = np.random.rand(*input_shape)
         coreml_input = {"x": x}
         mlmodel = ct.convert(prog, source="milinternal")
         coreml_output = list(mlmodel.predict(coreml_input).values())[0]
-        
+
         gt = np.reshape(x, reshape_shape)
         gt = np.transpose(gt, perm)
         gt = np.reshape(gt, output_shape)
-        np.testing.assert_allclose(gt, coreml_output, rtol=1e-03, atol=1e-05)    
-    
+        np.testing.assert_allclose(gt, coreml_output, rtol=1e-03, atol=1e-05)
+
     def test_rank6(self):
         input_shape = (1, 2, 3, 4, 5)
         reshape_shape = (1, 2, 3, 2, 2, 5)
         perm = (4, 5, 3, 2, 0, 1)
         output_shape = (5, 24)
 
         @mb.program(input_specs=[mb.TensorSpec(shape=input_shape)])
@@ -2911,15 +3149,15 @@
         @mb.program(input_specs=[mb.TensorSpec(shape=input_shape)])
         def prog(x):
             x = mb.reshape(x=x, shape=reshape_shape)
             x = mb.transpose(x=x, perm=perm)
             x = mb.reshape(x=x, shape=output_shape)
             return x
         prev_prog, _, block = apply_pass_and_basic_check(prog, "common::expand_high_rank_reshape_and_transpose")
-       
+
         prog._check_invalid_tensor_rank()
         assert get_op_types_in_program(prog) == ["reshape", "transpose", "reshape"]
         TestExpandHighRankReshapeAndTranspose._test_numerical(prev_prog, input_shape, reshape_shape, perm, output_shape)
 
     def test_rank20(self):
         input_shape = (4, 6, 8, 20, 40)
         reshape_shape = (1, 2, 2, 1, 2, 3, 2, 2, 2, 2, 2, 1, 1, 1, 5, 2, 2, 2, 1, 5)
@@ -2930,15 +3168,15 @@
         def prog(x):
             x = mb.reshape(x=x, shape=reshape_shape)
             x = mb.transpose(x=x, perm=perm)
             x = mb.reshape(x=x, shape=output_shape)
             return x
 
         prev_prog, _, block = apply_pass_and_basic_check(prog, "common::expand_high_rank_reshape_and_transpose")
-       
+
         prog._check_invalid_tensor_rank()
         assert get_op_types_in_program(prog) == ["reshape", "transpose"] * 16 + ["reshape"]
         TestExpandHighRankReshapeAndTranspose._test_numerical(prev_prog, input_shape, reshape_shape, perm, output_shape)
 
     def test_negative_case(self):
         input_shape = (4, 6, 8, 20, 40)
         reshape_shape = (1, 2, 2, 1, 2, 3, 2, 2, 2, 2, 2, 1, 1, 1, 5, 2, 2, 2, 1, 5)
@@ -2949,15 +3187,15 @@
         def prog(x):
             x1 = mb.reshape(x=x, shape=reshape_shape)
             x2 = mb.transpose(x=x1, perm=perm)
             x3 = mb.reshape(x=x2, shape=output_shape)
             return x, x1
 
         prev_prog, _, block = apply_pass_and_basic_check(prog, "common::expand_high_rank_reshape_and_transpose")
-        
+
         with pytest.raises(ValueError, match="Core ML only supports tensors with rank <= 5"):
             prog._check_invalid_tensor_rank()
 
 
 class TestMergeConsecutiveRelus:
     @pytest.mark.parametrize(
         "relu_num",
@@ -5515,47 +5753,71 @@
             prog,
             {"x": (B, C, H, W), "y": (B, C, H, W)},
             expected_output_shapes={block.outputs[0].name: (B, 2 * C, H, W)},
         )
 
 
 class TestFuseOnehotMatmulToGather:
-    @pytest.mark.parametrize("rank", [1, 2, 3, 4])
-    def test_fuse_onehot_matmul_to_gather(self, rank):
+    @pytest.mark.parametrize(
+        "backend, rank, opset_version",
+        itertools.product(backends, [1, 2, 3, 4], [None, ct.target.iOS17]),
+    )
+    def test_fuse_onehot_matmul_to_gather(self, backend, rank, opset_version):
         """
         Input:
             %2 = one_hot(%1, on_value=1, off_value=0, axis=-1)
             %3 = const() # rank 2
             %4  = matmul(%2, %3)
 
         Output:
             %4 = gather(%3, %2, axis=0)
         """
         rank4_shape = (10, 3, 6, 7)
         input_shape = rank4_shape[-rank:]
         vocab_size = 15
         embedding_size = 12
 
-        @mb.program(input_specs=[mb.TensorSpec(shape=input_shape, dtype=types.int32)])
+        @mb.program(
+            input_specs=[mb.TensorSpec(shape=input_shape, dtype=types.int32)],
+            opset_version=opset_version,
+        )
         def prog(x):
             x = mb.one_hot(
                 indices=x, on_value=1.0, off_value=0.0, axis=-1, one_hot_vector_size=vocab_size
             )
             x = mb.matmul(x=x, y=np.random.rand(vocab_size, embedding_size))
             return x
 
         prev_prog, prev_block, block = apply_pass_and_basic_check(
             prog, "common::fuse_onehot_matmul_to_gather"
         )
         assert get_op_types_in_program(prev_prog) == ["one_hot", "matmul"]
-        assert get_op_types_in_program(prog) == ["gather"]
+        if opset_version == ct.target.iOS17:
+            # Several ops added to make sure indices in iOS17 gather is non-negative.
+            assert get_op_types_in_program(prog) == [
+                "greater_equal",
+                "shape",
+                "slice_by_index",
+                "add",
+                "select",
+                "gather",
+            ]
+        else:
+            assert get_op_types_in_program(prog) == ["gather"]
+
+        if opset_version == ct.target.iOS17:
+            if backend[0] != "mlprogram" or _macos_version() < (14, 0):
+                pytest.skip("IOS17 target available only on macOS 14+ with mlprogram.")
+
         assert_model_is_valid(
             prog,
             {"x": input_shape},
+            backend=backend,
             expected_output_shapes={block.outputs[0].name: input_shape + (embedding_size,)},
+            minimum_deployment_target=opset_version,
         )
 
 
 class TestReplaceStackReshape(unittest.TestCase):
     def test_with_interleave(self):
         """
         input1(1, 5, 3, 4) -----> stack(axis=2) -----> reshape(shape=(1, 10, 3, 4)) ---> out(1, 10, 3, 4)
@@ -5587,15 +5849,15 @@
             prog,
             inputs,
             expected_output_shapes={block.outputs[0].name: (1, 10, 3, 4)},
         )
 
         concat_ops = [op for op in block.operations if op.op_type == "concat"]
         concat_op = concat_ops[0]
-        assert concat_op.interleave.val == True
+        assert concat_op.interleave.val == True  # noqa: E712
 
         output_name = block.outputs[0].name
 
         mlmodel = ct.convert(
             prog,
             source="milinternal",
             convert_to="neuralnetwork",
@@ -5649,15 +5911,15 @@
             prog,
             inputs,
             expected_output_shapes={block.outputs[0].name: (1, 10, 3, 4)},
         )
 
         concat_ops = [op for op in block.operations if op.op_type == "concat"]
         concat_op = concat_ops[0]
-        assert concat_op.interleave.val == False
+        assert concat_op.interleave.val == False  # noqa: E712
 
         output_name = block.outputs[0].name
 
         mlmodel = ct.convert(
             prog,
             source="milinternal",
             convert_to="neuralnetwork",
@@ -7085,391 +7347,7 @@
         PASS_REGISTRY["common::fuse_matmul_weight_bias"](prog)
         assert_same_output_names(prev_prog, prog)
         assert_op_count_match(prog, expect=0, op="matmul")
         assert_op_count_match(prog, expect=1, op="linear")
 
         if _VALIDATE_MODEL:
             assert_model_is_valid(prog, {"x": (2, 4)})
-
-
-class TestCompressionGraphPass:
-    """
-    Most of the numerical tests are already convered in coremltools.tests.ml_program.test_compression_utils.
-    This test is checking the basic behavior of the graph pass classes.
-    """
-
-    @staticmethod
-    def _get_conv_program():
-        @mb.program(
-            input_specs=[mb.TensorSpec(shape=(1, 30, 10, 10))], opset_version=ct.target.iOS16
-        )
-        def prog(x):
-            conv_weight = np.random.rand(90, 30, 2, 2).astype(np.float32)
-            x = mb.conv(x=x, weight=conv_weight)
-            return x
-
-        return prog
-
-    @pytest.mark.parametrize(
-        "fake_compression",
-        [True, False],
-    )
-    def test_affine_quantizer(self, fake_compression):
-        quantizer = quantization.WeightAffineQuantizer(
-            fake_compression=fake_compression, op_selector=lambda const: True
-        )
-        prog = self._get_conv_program()
-        quantizer.apply(prog)
-        expected_ops = ["constexpr_affine_dequantize", "conv"] if not fake_compression else ["conv"]
-        assert get_op_types_in_program(prog) == expected_ops
-
-    @pytest.mark.parametrize(
-        "fake_compression",
-        [True, False],
-    )
-    def test_weight_sparsifier(self, fake_compression):
-        quantizer = quantization.WeightSparsifier(
-            fake_compression=fake_compression,
-            op_selector=lambda const: True,
-            mode="percentile_based",
-            target_percentile=0.75,
-        )
-        prog = self._get_conv_program()
-        quantizer.apply(prog)
-        expected_ops = ["constexpr_sparse_to_dense", "conv"] if not fake_compression else ["conv"]
-        assert get_op_types_in_program(prog) == expected_ops
-
-    @pytest.mark.parametrize(
-        "fake_compression",
-        [True, False],
-    )
-    def test_weight_palettization(self, fake_compression):
-        quantizer = quantization.WeightPalettizer(
-            fake_compression=fake_compression,
-            op_selector=lambda const: True,
-            mode="uniform",
-            nbits=4,
-        )
-        prog = self._get_conv_program()
-        quantizer.apply(prog)
-        expected_ops = ["constexpr_lut_to_dense", "conv"] if not fake_compression else ["conv"]
-        assert get_op_types_in_program(prog) == expected_ops
-
-    @pytest.mark.parametrize(
-        "axis, mode, source_dtype, target_dtype, data_range",
-        itertools.product(
-            [0, 1, 2, 3, -1],
-            ["linear", "linear_symmetric"],
-            [np.float16, np.float32],
-            [types.uint8, types.int8],
-            [
-                [-1., 1.],
-                [-3., -1.],
-                [1., 3.],
-                # Test corner case of same values
-                [0., 0.],
-                [1., 1.],
-                [-1., -1.],
-            ]
-        ),
-    ) 
-    def test_affine_quantizer_compression(self, axis, mode, source_dtype, target_dtype, data_range):
-        input_shape = (10, 20, 30, 40)
-        low, high = data_range
-        val = np.random.uniform(low, high, input_shape).astype(source_dtype)
-        
-        params = quantization.WeightAffineQuantizer.compress(val, axis, mode, target_dtype)
-        decompressed_val = quantization.WeightAffineQuantizer.decompress(params)
-        
-        np.testing.assert_allclose(val, decompressed_val, rtol=1e-02, atol=1e-02)
-
-    @pytest.mark.parametrize(
-        "mode, nbits, shape",
-        itertools.product(
-            ["KMEANS", "UNIFORM", "UNIQUE"],
-            [1, 2, 4, 6, 8],
-            [
-                (1,),
-                (1, 1),
-                (1, 10),
-                (2, 20),
-                (3, 7, 9),
-                (17, 17, 17),
-            ]
-        ),
-    ) 
-    def test_palettizer_compression(self, mode, nbits, shape):
-        val_size = np.prod(shape)
-        max_val = 2 ** nbits
-        val = np.arange(max_val).tolist()
-        val = np.array(val * (val_size // max_val + 1))[:val_size].astype(np.float32)
-        params = quantization.WeightPalettizer.compress(val, mode=mode, nbits=nbits)
-        decompressed_val = quantization.WeightPalettizer.decompress(params)
-
-        # For
-        # 1. UNIQUE / KMEANS mode
-        # 2. UNIFORM mode with the data range <= tensor size
-        # We can perfecting re-construct the original value
-        if (mode in ["UNIQUE", "KMEANS"]) or (mode == "UNIFORM" and max_val <= val_size): 
-            np.testing.assert_allclose(val, decompressed_val, rtol=1e-02, atol=1e-02)
-
-class TestFP16CastTransform(unittest.TestCase):
-    """"""
-
-    """
-    Input graph:
-        input -----> square -----> out
-
-    Output graph:
-        input -----> cast(dtype="fp16") -----> square -----> cast(dtype="fp32") ---> out
-    """
-
-    def test_single_input_to_single_operation(self):
-        @mb.program(input_specs=[mb.TensorSpec(shape=(10, 20))])
-        def prog(x):
-            x = mb.square(x=x)
-            return x
-
-        self.assertEqual(get_op_types_in_program(prog), ["square"])
-
-        apply_pass_and_basic_check(
-            prog, quantization.FP16ComputePrecision(op_selector=lambda op: True)
-        )
-        _, _, block = apply_pass_and_basic_check(prog, "common::dead_code_elimination")
-
-        self.assertEqual(get_op_types_in_program(prog), ["cast", "square", "cast"])
-
-        # Asserting first cast configuration
-        cast_1 = block.find_ops(op_type="cast")[0]
-        self.assertEqual(cast_1.dtype.val, "fp16")
-        self.assertEqual(len(cast_1.outputs), 1)
-        self.assertEqual(len(cast_1.outputs[0].child_ops), 1)
-        self.assertEqual(cast_1.outputs[0].child_ops[0].op_type, "square")
-
-        # Asserting second cast configuration
-        cast_2 = block.find_ops(op_type="cast")[1]
-        self.assertEqual(cast_2.dtype.val, "fp32")
-        self.assertEqual(len(cast_2.outputs), 1)
-        self.assertEqual(len(cast_2.outputs[0].child_ops), 0)
-
-        assert_model_is_valid(
-            prog,
-            {"x": (10, 20)},
-            expected_output_shapes={block.outputs[0].name: (10, 20)},
-        )
-
-    """
-    Input graph:
-        input -----> div -----> out
-                      ^
-        const(eps) ---|
-
-    Output graph:
-        input --------> cast(dtype="fp16") -----> div -----> cast(dtype="fp32") ---> out
-                                                   ^
-        const(eps) ---> cast(dtype="fp16") --------|
-    """
-
-    def test_divide_by_zero_operation(self):
-        @mb.program(input_specs=[mb.TensorSpec(shape=(10, 20))])
-        def prog(x):
-            eps = mb.const(val=1e-10)
-            x = mb.real_div(x=x, y=eps)
-            return x
-
-        prev_prog, prev_block, block = apply_pass_and_basic_check(
-            prog, quantization.FP16ComputePrecision(op_selector=lambda op: True)
-        )
-
-        mlmodel = ct.convert(prog, source="milinternal", compute_units=ct.ComputeUnit.CPU_ONLY)
-        input_dict = {"x": np.random.rand(10, 20)}
-
-        if _IS_MACOS:
-            prediction = mlmodel.predict(input_dict)
-            assert not np.isnan(prediction["real_div_0"]).any()
-            assert np.isfinite(prediction["real_div_0"]).all()
-
-    """
-    Input graph:
-        input1 ----->|
-                     concat -----> out
-        input2 ----->|
-
-    Output graph:
-        input1 -----> cast(dtype="fp16") ----->|
-                                               concat -----> cast(dtype="fp32") ---> out
-        input2 -----> cast(dtype="fp16") ----->|
-
-    """
-
-    def test_multiple_inputs_to_single_operation(self):
-        @mb.program(input_specs=[mb.TensorSpec(shape=(10, 20)), mb.TensorSpec(shape=(10, 20))])
-        def prog(x, y):
-            x = mb.concat(values=(x, y), axis=0)
-            return x
-
-        self.assertEqual(get_op_types_in_program(prog), ["concat"])
-
-        apply_pass_and_basic_check(
-            prog, quantization.FP16ComputePrecision(op_selector=lambda op: True)
-        )
-        _, _, block = apply_pass_and_basic_check(prog, "common::dead_code_elimination")
-
-        self.assertEqual(get_op_types_in_program(prog), ["cast", "cast", "concat", "cast"])
-
-        # Asserting first cast configuration
-        cast_1 = block.find_ops(op_type="cast")[0]
-        self.assertEqual(cast_1.dtype.val, "fp16")
-        self.assertEqual(len(cast_1.outputs), 1)
-        self.assertEqual(len(cast_1.outputs[0].child_ops), 1)
-        self.assertEqual(cast_1.outputs[0].child_ops[0].op_type, "concat")
-
-        # Asserting second cast configuration
-        cast_2 = block.find_ops(op_type="cast")[1]
-        self.assertEqual(cast_2.dtype.val, "fp16")
-        self.assertEqual(len(cast_2.outputs), 1)
-        self.assertEqual(len(cast_2.outputs[0].child_ops), 1)
-        self.assertEqual(cast_2.outputs[0].child_ops[0].op_type, "concat")
-
-        # Asserting third cast configuration
-        cast_3 = block.find_ops(op_type="cast")[2]
-        self.assertEqual(cast_3.dtype.val, "fp32")
-        self.assertEqual(len(cast_3.outputs), 1)
-        self.assertEqual(len(cast_3.outputs[0].child_ops), 0)
-
-        assert_model_is_valid(
-            prog,
-            {"x": (10, 20), "y": (10, 20)},
-            expected_output_shapes={block.outputs[0].name: (20, 20)},
-        )
-
-    """
-    Input graph:
-                            |-----> output_1
-          input -----> split
-                            |-----> output_2
-
-    Output graph:
-
-                                                     |-----> cast(dtype="fp32") ---> output_1
-          input -----> cast(dtype="fp16") -----> split
-                                                     |-----> cast(dtype="fp32") ---> output_2
-
-    """
-
-    def test_multiple_outputs_from_single_operation(self):
-        @mb.program(input_specs=[mb.TensorSpec(shape=(10, 20))])
-        def prog(x):
-            x = mb.split(x=x, axis=0, num_splits=2)
-            return x
-
-        self.assertEqual(get_op_types_in_program(prog), ["split"])
-
-        apply_pass_and_basic_check(
-            prog, quantization.FP16ComputePrecision(op_selector=lambda op: True)
-        )
-        _, _, block = apply_pass_and_basic_check(prog, "common::dead_code_elimination")
-
-        self.assertEqual(get_op_types_in_program(prog), ["cast", "split", "cast", "cast"])
-
-        # Asserting first cast configuration
-        cast_1 = block.find_ops(op_type="cast")[0]
-        self.assertEqual(cast_1.dtype.val, "fp16")
-        self.assertEqual(len(cast_1.outputs), 1)
-        self.assertEqual(len(cast_1.outputs[0].child_ops), 1)
-        self.assertEqual(cast_1.outputs[0].child_ops[0].op_type, "split")
-
-        # Asserting second cast configuration
-        cast_2 = block.find_ops(op_type="cast")[1]
-        self.assertEqual(cast_2.dtype.val, "fp32")
-        self.assertEqual(len(cast_2.outputs), 1)
-        self.assertEqual(len(cast_2.outputs[0].child_ops), 0)
-
-        # Asserting third cast configuration
-        cast_3 = block.find_ops(op_type="cast")[2]
-        self.assertEqual(cast_3.dtype.val, "fp32")
-        self.assertEqual(len(cast_3.outputs), 1)
-        self.assertEqual(len(cast_3.outputs[0].child_ops), 0)
-
-        assert_model_is_valid(
-            prog,
-            {"x": (10, 20)},
-            expected_output_shapes={block.outputs[0].name: (5, 20), block.outputs[1].name: (5, 20)},
-        )
-
-    """
-    Input graph:
-
-         |----> square ---> output_1
-    input|
-         |----> relu   ---> output_2
-
-    Output graph:
-
-                                        |---->square-----> cast(dtype="fp32") ---> output_1
-          input -----> cast(dtype="fp16")
-                                        |----> relu -----> cast(dtype="fp32") ---> output_2
-
-    """
-
-    def test_single_input_to_multiple_operations(self):
-        @mb.program(input_specs=[mb.TensorSpec(shape=(10, 20))])
-        def prog(x):
-            y = mb.square(x=x)
-            z = mb.relu(x=x)
-            return y, z
-
-        self.assertEqual(get_op_types_in_program(prog), ["square", "relu"])
-
-        apply_pass_and_basic_check(
-            prog, quantization.FP16ComputePrecision(op_selector=lambda op: True)
-        )
-        _, _, block = apply_pass_and_basic_check(prog, "common::dead_code_elimination")
-
-        self.assertEqual(get_op_types_in_program(prog), ["cast", "square", "cast", "relu", "cast"])
-
-        # Asserting first cast configuration
-        cast_1 = block.find_ops(op_type="cast")[0]
-        self.assertEqual(cast_1.dtype.val, "fp16")
-        self.assertEqual(len(cast_1.outputs), 1)
-        self.assertEqual(len(cast_1.outputs[0].child_ops), 2)
-        self.assertEqual(cast_1.outputs[0].child_ops[0].op_type, "square")
-        self.assertEqual(cast_1.outputs[0].child_ops[1].op_type, "relu")
-
-        # Asserting second cast configuration
-        cast_2 = block.find_ops(op_type="cast")[1]
-        self.assertEqual(cast_2.dtype.val, "fp32")
-        self.assertEqual(len(cast_2.outputs), 1)
-        self.assertEqual(len(cast_2.outputs[0].child_ops), 0)
-
-        # Asserting third cast configuration
-        cast_3 = block.find_ops(op_type="cast")[2]
-        self.assertEqual(cast_3.dtype.val, "fp32")
-        self.assertEqual(len(cast_3.outputs), 1)
-        self.assertEqual(len(cast_3.outputs[0].child_ops), 0)
-
-        assert_model_is_valid(
-            prog,
-            {"x": (10, 20)},
-            expected_output_shapes={
-                block.outputs[0].name: (10, 20),
-                block.outputs[1].name: (10, 20),
-            },
-        )
-
-    def test_duplicate_output_vars(self):
-        @mb.program(input_specs=[mb.TensorSpec(shape=(1, 2))])
-        def prog(x):
-            relu1 = mb.relu(x=x)
-            return relu1, relu1
-
-        _, _, block = apply_pass_and_basic_check(
-            prog, quantization.FP16ComputePrecision(op_selector=lambda op: True)
-        )
-        self.assertEqual(get_op_types_in_program(prog), ["cast", "relu", "cast"])
-
-        assert_model_is_valid(
-            prog,
-            {"x": (1, 2)},
-            expected_output_shapes={block.outputs[0].name: (1, 2), block.outputs[1].name: (1, 2)},
-            backend=("mlprogram", "fp16"),
-        )
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/passes/tests/test_reduce_transposes_pass.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/passes/tests/test_reduce_transposes_pass.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/program.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/program.py`

 * *Files 10% similar despite different names*

```diff
@@ -16,14 +16,18 @@
 from . import types
 from .block import Function
 from .types.symbolic import k_num_internal_syms, k_used_symbols
 from .var import Var
 
 
 class Program:
+    @staticmethod
+    def _get_opset_str_value(op):
+        return f"coremltools.target.{op.name}"
+
     def __init__(self):
         self.main_input_types = []
         self.main_output_types = None
         self.functions = {}
         self.parameters = {}
         self.skip_all_passes = False
 
@@ -51,40 +55,50 @@
                 for b in op.blocks:
                     check_version_compatibility_block(b)
                 if not hasattr(op, "_op_variants") or not isinstance(op._op_variants, dict):
                     continue
                 expected_op_cls = _get_version_of_op(op._op_variants, max_opset_version)
                 if type(op) is not expected_op_cls:
                     msg = (
-                        "Op {} with an out of date version {!s} is detected. Please use @mb.program(input_specs=..., "
-                        "opset_version={!s})"
-                    ).format(op.op_type, op.opset_version, max_opset_version)
+                        "Op {} with an out of date version {} is detected. Please use @mb.program(input_specs=..., "
+                        "opset_version={})"
+                    ).format(
+                        op.op_type,
+                        self._get_opset_str_value(op.opset_version),
+                        self._get_opset_str_value(max_opset_version),
+                    )
                     raise ValueError(msg)
         for func in self.functions.values():
             check_version_compatibility_block(func)
 
     def _check_or_set_functions_opset_version(self, max_opset_version):
         funcs = list(self.functions.values())
         for func in funcs:
             if func.opset_version is None:
                 func.opset_version = max_opset_version
             else:
                 if func.opset_version < max_opset_version:
-                    msg = "function should have at least opset_version {!s}. Got {!s}".format(max_opset_version, func.opset_version)
+                    msg = "function should have at least opset_version {}. Got {}".format(
+                        self._get_opset_str_value(max_opset_version),
+                        self._get_opset_str_value(func.opset_version),
+                    )
                     raise ValueError(msg)
         for func in funcs:
             if func.opset_version != funcs[0].opset_version:
-                msg = "all functions must have the same opset_version. Got {!s} and {!s}.".format(func.opset_version, funcs[0].opset_version)
+                msg = "all functions must have the same opset_version. Got {} and {}.".format(
+                    self._get_opset_str_value(func.opset_version),
+                    self._get_opset_str_value(funcs[0].opset_version),
+                )
                 raise ValueError(msg)
 
     def _check_program_opset_version(self):
         max_opset_version, _ = self._get_max_opset_version_and_op()
         self._check_ops_version_compatibility(max_opset_version)
         self._check_or_set_functions_opset_version(max_opset_version)
-        
+
     def _check_invalid_tensor_rank(self):
         '''
         Early error out for tensor with rank >= 6
         '''
         def _check_invalid_tensor_rank_block(block):
             for op in block.operations:
                 for b in op.blocks:
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/tests/test_block.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/tests/test_block.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/tests/test_debug.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/tests/test_debug.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/tests/test_programs.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/tests/test_programs.py`

 * *Files 4% similar despite different names*

```diff
@@ -142,15 +142,17 @@
         assert len(prediction) == 2
 
 def test_reserved_node_names():
     @mb.program(input_specs=[mb.TensorSpec(shape=(10, 20))])
     def prog(x):
         return mb.square(x=x, name="tensor")
 
-    mlmodel = ct.convert(prog, source="milinternal", convert_to="mlprogram")
+    mlmodel = ct.convert(
+        prog, source="milinternal", convert_to="mlprogram", compute_units=ct.ComputeUnit.CPU_ONLY
+    )
 
     feed_dict = {
         "x": np.random.rand(10, 20).astype(np.float32),
     }
     assert mlmodel is not None
 
     if ct.utils._is_macos():
@@ -220,15 +222,17 @@
         main_func = prog.functions["main"]
         topk_op = main_func.find_ops(op_type="topk")[0]
         assert topk_op.opset_version == ct.target.iOS16
 
     @staticmethod
     def test_pymil_front_end_conversion():
         prog = get_simple_topk_pixel_unshuffle_program(opset_version=ct.target.iOS16)
-        mlmodel = ct.convert(prog, minimum_deployment_target=ct.target.iOS16)
+        mlmodel = ct.convert(
+            prog, minimum_deployment_target=ct.target.iOS16, compute_units=ct.ComputeUnit.CPU_ONLY
+        )
 
     @staticmethod
     def test_nested_block_opset_version_selection():
         # pick up the oldest version (iOS13) topk by default
         prog = get_simple_nested_block_program()
         main_func = prog.functions["main"]
         topk_ops = main_func.find_ops(op_type="topk")
@@ -249,25 +253,31 @@
         assert prog.functions["main"].opset_version == ct.target.iOS16
 
         expected_err_str = (
             "Please update the minimum_deployment_target to coremltools.target.iOS16, "
             "since op pixel_unshuffle is only available in opset coremltools.target.iOS16 or newer."
         )
         with pytest.raises(ValueError, match=expected_err_str):
-            mlmodel = ct.convert(prog, convert_to="mlprogram")
+            mlmodel = ct.convert(
+                prog, convert_to="mlprogram", compute_units=ct.ComputeUnit.CPU_ONLY
+            )
 
     @staticmethod
     def test_pymil_front_end_conversion_early_error_out():
         prog = get_simple_topk_pixel_unshuffle_program(opset_version=ct.target.iOS16)
         expected_err_str = (
             "Please update the minimum_deployment_target to coremltools.target.iOS16, "
             "since op pixel_unshuffle is only available in opset coremltools.target.iOS16 or newer."
         )
         with pytest.raises(ValueError, match=expected_err_str):
-            mlmodel = ct.convert(prog, minimum_deployment_target=ct.target.iOS15)
+            mlmodel = ct.convert(
+                prog,
+                minimum_deployment_target=ct.target.iOS15,
+                compute_units=ct.ComputeUnit.CPU_ONLY,
+            )
 
     @staticmethod
     def test_unsupported_op_early_error_out():
         '''
         We should error out at the point when Builder tries to add an op which is only supported in a newer spec version
         '''
         expected_err_str = (
@@ -318,16 +328,17 @@
             "Core ML only supports tensors with rank <= 5. Layer \"reshape_0\", with type \"reshape\", outputs a rank 6 tensor"
         )
         with pytest.raises(ValueError, match=expected_err_str):
             @mb.program(input_specs=[mb.TensorSpec(shape=(1,), dtype=types.fp32)])
             def prog(x):
                 res = mb.reshape(x=x, shape=(1, 1, 1, 1, 1, 1), name="reshape_0")
                 return res
-            ct.convert(prog, source="milinternal")
-                
+
+            ct.convert(prog, source="milinternal", compute_units=ct.ComputeUnit.CPU_ONLY)
+
     @staticmethod
     def test_rank5_list_early_error_out():
         '''
         The builder should error out early when detecting a list of rank 5 (or higher) tensors is created
         '''
         expected_err_str = (
             "Core ML only supports list of elements with rank <= 4. Layer \"list_0\", with type \"make_list\", outputs a list of rank 5 tensors."
@@ -339,9 +350,7 @@
                     init_length=1,
                     dtype="fp32",
                     elem_shape=(1, 1, 1, 1, 1),
                     dynamic_length=True,
                     name="list_0",
                 )
                 return ls
-
-
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/tests/test_types.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/tests/test_types.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/types/__init__.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/types/__init__.py`

 * *Files 9% similar despite different names*

```diff
@@ -20,14 +20,13 @@
                            np_dtype_to_py_type, nptype_from_builtin,
                            numpy_type_to_builtin_type,
                            numpy_val_to_builtin_val, promote_dtypes,
                            promote_types, proto_to_builtin_types,
                            string_to_builtin, type_to_builtin_type)
 from .type_str import str
 from .type_tensor import (is_compatible_type, is_tensor_and_is_compatible,
-                          is_tensor_and_is_compatible_general_shape, tensor,
-                          tensor_has_complete_shape)
+                          tensor, tensor_has_complete_shape)
 from .type_tuple import tuple
 from .type_unknown import unknown
 from .type_void import void
 
 apply_delayed_types()
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/types/annotate.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/types/annotate.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/types/get_type_info.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/types/get_type_info.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/types/global_methods.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/types/global_methods.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/types/symbolic.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/types/symbolic.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/types/type_bool.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/types/type_bool.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/types/type_complex.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/types/type_complex.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/types/type_dict.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/types/type_dict.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/types/type_double.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/types/type_double.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/types/type_int.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/types/type_int.py`

 * *Files 4% similar despite different names*

```diff
@@ -32,42 +32,38 @@
             return self._val
 
         @val.setter
         def val(self, v):
             from .type_mapping import (builtin_to_string, nptype_from_builtin,
                                        numpy_type_to_builtin_type)
 
-            if not isinstance(v, (np.generic, sm.Basic)):
+            if not isinstance(v, (np.generic, np.ndarray, sm.Basic)):
                 raise ValueError(
-                    "types should have value of numpy type or Symbols, got {} instead".format(
-                        type(v)
-                    )
+                    f"types should have value of numpy type or Symbols, got {type(v)} instead"
                 )
 
             if isinstance(v, sm.Basic):
                 self._val = v
             elif isinstance(v, np.integer):
                 v_type = numpy_type_to_builtin_type(v.dtype)
                 if v_type.get_bitwidth() <= self.get_bitwidth() and (
                     v >= 0 or v < 0 and not self.is_unsigned()
                 ):
                     self._val = v
                 else:
                     self._val = v.astype(nptype_from_builtin(self.__class__))
                     logger.warning(
-                        "Saving value type of {} into a builtin type of {}, might overflow or loses precision!".format(
-                            v.dtype, builtin_to_string(self.__class__)
-                        )
+                        f"Saving value type of {v.dtype} into a builtin type of "
+                        f"{builtin_to_string(self.__class__)}, might overflow or loses precision!"
                     )
             else:
                 self._val = v.astype(nptype_from_builtin(self.__class__))
                 logger.warning(
-                    "Saving value type of {} into a builtin type of {}, might be incompatible or loses precision!".format(
-                        v.dtype, builtin_to_string(self.__class__)
-                    )
+                    f"Saving value type of {v.dtype} into a builtin type of "
+                    f"{builtin_to_string(self.__class__)}, might be incompatible or loses precision!"
                 )
 
         @classmethod
         def __type_info__(cls):
             return Type(cls._unsigned + "int" + str(cls._width), python_class=cls)
 
         @classmethod
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/types/type_list.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/types/type_list.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/types/type_mapping.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/types/type_mapping.py`

 * *Files 1% similar despite different names*

```diff
@@ -412,15 +412,15 @@
 
     Given: val = np.array(32, dtype=np.int32)
     Returns 32
     """
     if not isinstance(val, (_np.ndarray, _np.generic)):
         return val
 
-    if val.dtype in [_np.float16, _np.uint8, _np.int8, _np.uint32]:
+    if val.dtype in (_np.float16, _np.uint8, _np.int8, _np.uint16, _np.int16, _np.uint32):
         return val.tobytes()
     else:
         # val is np.ndarray or np.generic
         is_np_scalar = isinstance(val, _np.generic) or val.shape == ()
         py_type = np_dtype_to_py_type(val.dtype)
         return py_type(val) if is_np_scalar else tuple(py_type(v) for v in val.flatten())
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/types/type_spec.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/types/type_spec.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/types/type_str.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/types/type_str.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/types/type_tensor.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/types/type_tensor.py`

 * *Files 13% similar despite different names*

```diff
@@ -181,52 +181,14 @@
         elif shape1[i] == shape2[i]:
             most_specific_shape.append(shape1[i])
         elif shape1[i] != shape2[i]:
             return False, None
 
     return True, tensor(primitive_type, most_specific_shape)
 
-def is_tensor_and_is_compatible_general_shape(tensor_type1, tensor_type2):
-    # returns a pair of (bool, type)
-    # If Both are tensors, and have compatible shape, the first return is true
-    # The return will be the most general version of the tensor type.
-    # Note that this may not be either tensor types. i.e.
-    #
-    # is_tensor_and_is_compatible(tensor[fp32,[10,-1]] ,tensor[fp32,[-1,20]])
-    # will return True, tensor[fp32, [-1,-1]]
-
-    if not is_tensor(tensor_type1) or not is_tensor(tensor_type2):
-        return False, None
-    shape1 = tensor_type1.get_shape()
-    shape2 = tensor_type2.get_shape()
-
-    if tensor_type1.get_primitive() != tensor_type2.get_primitive():
-        return False, None
-
-    if len(shape1) == 0:
-        return True, tensor_type2
-    if len(shape2) == 0:
-        return True, tensor_type1
-
-    if len(shape1) != len(shape2):
-        return False, None
-
-    most_general_shape = []
-    for i in range(len(shape1)):
-        if shape1[i] == -1 or issubclass(type(shape1[i]), sm.Basic):
-            most_general_shape.append(shape1[i])
-        elif shape2[i] == -1 or issubclass(type(shape2[i]), sm.Basic):
-            most_general_shape.append(shape2[i])
-        elif shape1[i] == shape2[i]:
-            most_general_shape.append(shape1[i])
-        elif shape1[i] != shape2[i]:
-            return False, None
-
-    return True, tensor(tensor_type1.get_primitive(), most_general_shape)
-
 def is_compatible_type(type1, type2):
     """
     Return if type1 and type2 are compatible.
     """
     if not is_subtype(type1, type2):
         is_comp, _ = is_tensor_and_is_compatible(type1, type2)
         return is_comp
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/types/type_tuple.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/types/type_tuple.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/var.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/var.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/mil/visitors/dot_visitor.py` & `coremltools-7.0b1/coremltools/converters/mil/mil/visitors/dot_visitor.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/mil/testing_reqs.py` & `coremltools-7.0b1/coremltools/converters/mil/testing_reqs.py`

 * *Files 14% similar despite different names*

```diff
@@ -4,16 +4,15 @@
 #  found in the LICENSE.txt file or at https://opensource.org/licenses/BSD-3-Clause
 import os
 
 import numpy as np
 import pytest
 
 import coremltools as ct
-from coremltools._deps import (_HAS_TF_1, _HAS_TF_2, _HAS_TORCH)
-
+from coremltools._deps import _HAS_TF_1, _HAS_TF_2, _HAS_TORCH
 
 # Setting up backend / precision
 backends = []
 if 'PYMIL_TEST_TARGETS' in os.environ:
     targets = os.environ['PYMIL_TEST_TARGETS'].split(',')
     for i in range(len(targets)):
         targets[i] = targets[i].strip()
@@ -27,19 +26,19 @@
 
     if not backends:
         raise ValueError("PYMIL_TEST_TARGETS can be set to one or more of: neuralnetwork, mlprogram")
 else:
     backends = [('mlprogram', "fp16"), ('neuralnetwork', "fp32")]
     if os.getenv('INCLUDE_MIL_FP32_UNIT_TESTS') == '1':
         backends.append(('mlprogram', 'fp32'))
-        
+
 # Setting up compute unit
 compute_units = []
-if 'COMPUTE_UNITS' in os.environ:
-    for i, cur_str_val in enumerate(os.environ['COMPUTE_UNITS'].split(',')):
+if "COMPUTE_UNITS" in os.environ:
+    for cur_str_val in os.environ["COMPUTE_UNITS"].split(","):
         cur_str_val = cur_str_val.strip().upper()
         if cur_str_val not in ct.ComputeUnit.__members__:
             raise ValueError("Compute unit \"{}\" not supported in coremltools.".format(cur_str_val))
         compute_units.append(ct.ComputeUnit[cur_str_val])
 else:
     compute_units = [ct.ComputeUnit.CPU_ONLY]
 
@@ -48,7 +47,10 @@
 if _HAS_TF_1:
     tf = pytest.importorskip("tensorflow")
     tf.compat.v1.set_random_seed(1234)
 
 if _HAS_TF_2:
     tf = pytest.importorskip("tensorflow")
     tf.random.set_seed(1234)
+
+if _HAS_TORCH:
+    torch = pytest.importorskip("torch")
```

### Comparing `coremltools-6.3.0/coremltools/converters/mil/testing_utils.py` & `coremltools-7.0b1/coremltools/converters/mil/testing_utils.py`

 * *Files 4% similar despite different names*

```diff
@@ -4,34 +4,45 @@
 #  found in the LICENSE.txt file or at https://opensource.org/licenses/BSD-3-Clause
 
 import copy
 import os
 import re
 from functools import partial
 from pathlib import Path
+from typing import Dict, List, Tuple
 
 import numpy as np
+import pytest
 from PIL import Image
 
 import coremltools as ct
 import coremltools.models.utils as coremltoolsutils
 from coremltools._deps import _IS_MACOS
 from coremltools.converters.mil.mil import Function, Program
 from coremltools.converters.mil.mil.passes.defs.quantization import AbstractQuantizationPass
 from coremltools.converters.mil.mil.passes.pass_registry import PASS_REGISTRY
 from coremltools.proto import FeatureTypes_pb2 as ft
 
 np.random.seed(10)
 
-DTYPE_TO_FEATURE_TYPE_MAP = {"int32": ft.ArrayFeatureType.INT32,
-                             "fp32": ft.ArrayFeatureType.FLOAT32,
-                             "fp16": ft.ArrayFeatureType.FLOAT16,
-                             }
+DTYPE_TO_FEATURE_TYPE_MAP: Dict[str, ft.ArrayFeatureType] = {
+    "int32": ft.ArrayFeatureType.INT32,
+    "fp32": ft.ArrayFeatureType.FLOAT32,
+    "fp16": ft.ArrayFeatureType.FLOAT16,
+}
+
+# The minimum macOS version for an IOS target. For example, iOS16 target requires macOS13+.
+IOS_TO_MINIMUM_MACOS_VERSION: Dict[ct.target, int] = {
+    ct.target.iOS14: 11,
+    ct.target.iOS15: 12,
+    ct.target.iOS16: 13,
+    ct.target.iOS17: 14,
+}
 
-einsum_equations = [
+einsum_equations: List[str] = [
     # hardcoded cases
     "abcd,adce->abce",
     "abc,cbd->abd",
     "bnqd,bnkd->bnqk",
     "abc,cd->abd",
     "abc,cde->abde",
     "btnh,bfnh->bnft",
@@ -98,33 +109,46 @@
                 count += 1
             elif o.op_type.lower() == op.lower():
                 count += 1
         np.testing.assert_equal(count, expect)
 
 
 def assert_model_is_valid(
-    program, inputs, backend=("neuralnetwork", "fp32"), verbose=True, expected_output_shapes=None
+    program,
+    inputs,
+    backend=("neuralnetwork", "fp32"),
+    verbose=True,
+    expected_output_shapes=None,
+    minimum_deployment_target: ct.target = None,
 ):
     """
     Assert Core ML model is valid.
 
     Inputs:
 
     - input: str -> shape tuple. All program input names need to appear in str.
       shape tuple can only contain positive integers.
     """
+    if minimum_deployment_target is not None:
+        validate_minimum_deployment_target(minimum_deployment_target, backend)
+
     # Avoid circular import
     from coremltools.converters.mil.testing_reqs import ct
 
     input_dict = dict()
     for name, shape in inputs.items():
         input_dict[name] = np.random.rand(*shape)
 
-    mlmodel = ct_convert(program, source="milinternal", convert_to=backend,
-                         compute_units=ct.ComputeUnit.CPU_ONLY)
+    mlmodel = ct_convert(
+        program,
+        source="milinternal",
+        convert_to=backend,
+        compute_units=ct.ComputeUnit.CPU_ONLY,
+        minimum_deployment_target=minimum_deployment_target,
+    )
     assert mlmodel is not None
 
     if verbose:
         from coremltools.models.neural_network.printer import print_network_spec
         print_network_spec(mlmodel.get_spec(), style="coding")
 
     if _IS_MACOS and (not mlmodel.is_package or coremltoolsutils._macos_version() >= (12, 0)):
@@ -241,15 +265,15 @@
     else:
         raise KeyError("{} output not found in Core ML outputs".format(out_name))
 
 def compare_backend(
     mlmodel,
     input_key_values,
     expected_outputs,
-    dtype = "fp32",
+    dtype="fp32",
     atol=1e-04,
     rtol=1e-05,
     also_compare_shapes=True,
 ):
     """
     Inputs:
         - mlmodel: MLModel.
@@ -288,17 +312,15 @@
             else:
                 assert coreml_out == expected
 
         return pred
     return None
 
 
-def compare_shapes(
-    mlmodel, input_key_values, expected_outputs, pred=None
-):
+def compare_shapes(mlmodel, input_key_values, expected_outputs, pred=None):
     """
     Inputs:
         - mlmodel: MLModel.
 
         - input_key_values: str -> np.array or PIL.Image. Keys must match those in
           input_placeholders.
 
@@ -495,26 +517,30 @@
             x = np.random.rand(*shape)
             return Image.fromarray(x.astype(np.float32), 'F')
         else:
             raise ValueError("unrecognized image type")
     else:
         raise ValueError('unsupported type')
 
-def gen_input_shapes_einsum(equation, dynamic):
+
+def gen_input_shapes_einsum(equation: str, dynamic: bool, backend: Tuple[str, str]):
     equation = equation.replace(" ", "")
     left = equation.split("->")[0]
     a_desc, b_desc = left.split(",")
     converter_shapes = {}
     shapes = {}
     cur_default_shape = 2
     for symbol in a_desc + b_desc:
         if symbol not in shapes:
             shapes[symbol] = cur_default_shape
             if dynamic:
-                converter_shapes[symbol] = ct.RangeDim(default=cur_default_shape)
+                converter_shapes[symbol] = ct.RangeDim(
+                    default=cur_default_shape,
+                    upper_bound=cur_default_shape if backend[0] == "mlprogram" else -1,
+                )
             else:
                 converter_shapes[symbol] = cur_default_shape
             cur_default_shape += 1
     a_shape = [shapes[symbol] for symbol in a_desc]
     b_shape = [shapes[symbol] for symbol in b_desc]
     a_converter_shape = [converter_shapes[symbol] for symbol in a_desc]
     b_converter_shape = [converter_shapes[symbol] for symbol in b_desc]
@@ -539,7 +565,23 @@
 
 def assert_cast_ops_count(mlmodel, expected_count):
     block = mlmodel._mil_program.functions["main"]
     assert len(block.find_ops(op_type="cast")) == expected_count
 
 def assert_ops_in_mil_program(mlmodel, expected_op_list):
     assert expected_op_list == get_op_types_in_program(mlmodel._mil_program)
+
+
+def validate_minimum_deployment_target(
+    minimum_deployment_target: ct.target, backend: Tuple[str, str]
+):
+    """
+    Validates the minimum deployment target based on backend and macOS version. Only used in tests.
+    """
+    if minimum_deployment_target >= ct.target.iOS15 and backend[0] != "mlprogram":
+        pytest.skip("IOS15+ target only compatible with mlprogram.")
+    if coremltoolsutils._is_macos():
+        macos_major_version = coremltoolsutils._macos_version()[0]
+        if macos_major_version < IOS_TO_MINIMUM_MACOS_VERSION[minimum_deployment_target]:
+            pytest.skip(
+                f"IOS{minimum_deployment_target} target requires macOS {macos_major_version}+."
+            )
```

### Comparing `coremltools-6.3.0/coremltools/converters/sklearn/_LinearSVC.py` & `coremltools-7.0b1/coremltools/converters/sklearn/_LinearSVC.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/sklearn/_LinearSVR.py` & `coremltools-7.0b1/coremltools/converters/sklearn/_LinearSVR.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/sklearn/_NuSVC.py` & `coremltools-7.0b1/coremltools/converters/sklearn/_NuSVC.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/sklearn/_NuSVR.py` & `coremltools-7.0b1/coremltools/converters/sklearn/_NuSVR.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/sklearn/_SVC.py` & `coremltools-7.0b1/coremltools/converters/sklearn/_SVC.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/sklearn/_SVR.py` & `coremltools-7.0b1/coremltools/converters/sklearn/_SVR.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/sklearn/_converter.py` & `coremltools-7.0b1/coremltools/converters/sklearn/_converter.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/sklearn/_converter_internal.py` & `coremltools-7.0b1/coremltools/converters/sklearn/_converter_internal.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/sklearn/_decision_tree_classifier.py` & `coremltools-7.0b1/coremltools/converters/sklearn/_decision_tree_classifier.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/sklearn/_decision_tree_regressor.py` & `coremltools-7.0b1/coremltools/converters/sklearn/_decision_tree_regressor.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/sklearn/_dict_vectorizer.py` & `coremltools-7.0b1/coremltools/converters/sklearn/_dict_vectorizer.py`

 * *Files 2% similar despite different names*

```diff
@@ -65,22 +65,22 @@
     is_str = None
     for feature_name in model.feature_names_:
         if isinstance(feature_name, str):
             if is_str is False:
                 raise ValueError("Mapping of DictVectorizer mixes int and str types.")
 
             tr_spec.stringToIndex.vector.append(feature_name)
-            is_str == True
+            is_str is True
 
         if isinstance(feature_name, int):
             if is_str is True:
                 raise ValueError("Mapping of DictVectorizer mixes int and str types.")
 
             tr_spec.int64ToIndex.vector.append(feature_name)
-            is_str == False
+            is_str is False
 
     intermediate_features = [
         (_INTERMEDIATE_FEATURE_NAME, datatypes.Dictionary(key_type=int))
     ]
 
     # Set the interface for the dict vectorizer with the input and the
     # intermediate output
```

### Comparing `coremltools-6.3.0/coremltools/converters/sklearn/_gradient_boosting_classifier.py` & `coremltools-7.0b1/coremltools/converters/sklearn/_gradient_boosting_classifier.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/sklearn/_gradient_boosting_regressor.py` & `coremltools-7.0b1/coremltools/converters/sklearn/_gradient_boosting_regressor.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/sklearn/_imputer.py` & `coremltools-7.0b1/coremltools/converters/sklearn/_imputer.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/sklearn/_k_neighbors_classifier.py` & `coremltools-7.0b1/coremltools/converters/sklearn/_k_neighbors_classifier.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/sklearn/_linear_regression.py` & `coremltools-7.0b1/coremltools/converters/sklearn/_linear_regression.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/sklearn/_logistic_regression.py` & `coremltools-7.0b1/coremltools/converters/sklearn/_logistic_regression.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/sklearn/_normalizer.py` & `coremltools-7.0b1/coremltools/converters/sklearn/_normalizer.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/sklearn/_one_hot_encoder.py` & `coremltools-7.0b1/coremltools/converters/sklearn/_one_hot_encoder.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/sklearn/_random_forest_classifier.py` & `coremltools-7.0b1/coremltools/converters/sklearn/_random_forest_classifier.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/sklearn/_random_forest_regressor.py` & `coremltools-7.0b1/coremltools/converters/sklearn/_random_forest_regressor.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/sklearn/_ridge_regression.py` & `coremltools-7.0b1/coremltools/converters/sklearn/_ridge_regression.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/sklearn/_sklearn_util.py` & `coremltools-7.0b1/coremltools/converters/sklearn/_sklearn_util.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/sklearn/_standard_scaler.py` & `coremltools-7.0b1/coremltools/converters/sklearn/_standard_scaler.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/sklearn/_svm_common.py` & `coremltools-7.0b1/coremltools/converters/sklearn/_svm_common.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/sklearn/_tree_ensemble.py` & `coremltools-7.0b1/coremltools/converters/sklearn/_tree_ensemble.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/xgboost/_tree.py` & `coremltools-7.0b1/coremltools/converters/xgboost/_tree.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/converters/xgboost/_tree_ensemble.py` & `coremltools-7.0b1/coremltools/converters/xgboost/_tree_ensemble.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/models/__init__.py` & `coremltools-7.0b1/coremltools/models/__init__.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/models/_feature_management.py` & `coremltools-7.0b1/coremltools/models/_feature_management.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/models/_interface_management.py` & `coremltools-7.0b1/coremltools/models/_interface_management.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/models/array_feature_extractor.py` & `coremltools-7.0b1/coremltools/models/array_feature_extractor.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/models/datatypes.py` & `coremltools-7.0b1/coremltools/models/datatypes.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/models/feature_vectorizer.py` & `coremltools-7.0b1/coremltools/models/feature_vectorizer.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/models/model.py` & `coremltools-7.0b1/coremltools/models/model.py`

 * *Files 8% similar despite different names*

```diff
@@ -16,19 +16,27 @@
 from coremltools import ComputeUnit as _ComputeUnit
 from coremltools._deps import _HAS_TF_1, _HAS_TF_2, _HAS_TORCH
 from coremltools.converters.mil.mil.program import Program as _Program
 
 from ..proto import FeatureTypes_pb2 as _ft
 from ..proto import MIL_pb2 as _MIL_pb2
 from ..proto import Model_pb2 as _Model_pb2
-from .utils import (_MLMODEL_EXTENSION, _MLPACKAGE_AUTHOR_NAME,
-                    _MLPACKAGE_EXTENSION, _WEIGHTS_DIR_NAME, _create_mlpackage,
-                    _has_custom_layer, _is_macos, _macos_version,
-                    load_spec as _load_spec, save_spec as _save_spec,
-                    )
+from .utils import (
+    _MLMODEL_EXTENSION,
+    _MLPACKAGE_AUTHOR_NAME,
+    _MLPACKAGE_EXTENSION,
+    _MODEL_FILE_NAME,
+    _WEIGHTS_DIR_NAME,
+    _create_mlpackage,
+    _has_custom_layer,
+    _is_macos,
+    _macos_version,
+)
+from .utils import load_spec as _load_spec
+from .utils import save_spec as _save_spec
 
 if _HAS_TORCH:
     import torch as _torch
 
 if _HAS_TF_1 or _HAS_TF_2:
     import tensorflow as _tf
 
@@ -279,14 +287,16 @@
         compute_units: coremltools.ComputeUnit
             An enum with three possible values:
                 - ``coremltools.ComputeUnit.ALL``: Use all compute units available, including the
                   neural engine.
                 - ``coremltools.ComputeUnit.CPU_ONLY``: Limit the model to only use the CPU.
                 - ``coremltools.ComputeUnit.CPU_AND_GPU``: Use both the CPU and GPU,
                   but not the neural engine.
+                - ``coremltools.ComputeUnit.CPU_AND_NE``: Use both the CPU and neural engine, but
+                  not the GPU. Available only for macOS >= 13.0.
 
         weights_dir: str
             Path to the weight directory, required when loading an MLModel of type mlprogram,
             from a spec object, i.e. when the argument ``model`` is of type ``Model_pb2``
 
         Notes
         -----
@@ -307,14 +317,39 @@
         loaded_model = MLModel("my_model.mlpackage")
         """
 
         def cleanup(package_path):
             if _os.path.exists(package_path):
                 _shutil.rmtree(package_path)
 
+        def does_model_contain_mlprogram(model) -> bool:
+            """
+            Is this an mlprogram or is it a pipeline with at least one mlprogram?
+            """
+            model_type = model.WhichOneof("Type")
+
+            if model_type == "mlProgram":
+                return True
+            elif model_type not in ("pipeline", "pipelineClassifier", "pipelineRegressor"):
+                return False
+
+            # Does this pipeline contain an mlprogram?
+            if model_type == "pipeline":
+                pipeline_models = model.pipeline.models
+            elif model_type == "pipelineClassifier":
+                pipeline_models = model.pipelineClassifier.pipeline.models
+            else:
+                assert model_type == "pipelineRegressor"
+                pipeline_models = model.pipelineRegressor.pipeline.models
+
+            for m in pipeline_models:
+                if does_model_contain_mlprogram(m):
+                    return True
+            return False
+
         if not isinstance(compute_units, _ComputeUnit):
             raise TypeError('"compute_units" parameter must be of type: coremltools.ComputeUnit')
         elif (compute_units == _ComputeUnit.CPU_AND_NE
               and _is_macos()
               and _macos_version() < (13, 0)
         ):
             raise ValueError(
@@ -337,20 +372,21 @@
                 self.package_path = model
                 self.is_temp_package = is_temp_package
                 self._weights_dir = _try_get_weights_dir_path(model)
             self.__proxy__, self._spec, self._framework_error = _get_proxy_and_spec(
                 model, compute_units, skip_model_load=skip_model_load,
             )
         elif isinstance(model, _Model_pb2.Model):
-            model_type = model.WhichOneof('Type')
-            if model_type in ("mlProgram", 'pipelineClassifier', 'pipelineRegressor', 'pipeline'):
-                if model_type == "mlProgram" and weights_dir is None:
-                    raise Exception('MLModel of type mlProgram cannot be loaded just from the model spec object. '
-                                    'It also needs the path to the weights file. Please provide that as well, '
-                                    'using the \'weights_dir\' argument.')
+            if does_model_contain_mlprogram(model):
+                if model.WhichOneof("Type") == "mlProgram" and weights_dir is None:
+                    raise Exception(
+                        "MLModel of type mlProgram cannot be loaded just from the model spec object. "
+                        "It also needs the path to the weights file. Please provide that as well, "
+                        "using the 'weights_dir' argument."
+                    )
                 self.is_package = True
                 self.is_temp_package = True
                 filename = _create_mlpackage(model, weights_dir)
                 self.package_path = filename
                 self._weights_dir = _try_get_weights_dir_path(filename)
             else:
                 filename = _tempfile.mktemp(suffix=_MLMODEL_EXTENSION)
@@ -454,14 +490,19 @@
         if self.is_package:
             name, ext = _os.path.splitext(save_path)
             if not ext:
                 save_path = "{}{}".format(save_path, _MLPACKAGE_EXTENSION)
             elif ext != _MLPACKAGE_EXTENSION:
                 raise Exception("For an ML Program, extension must be {} (not {})".format(_MLPACKAGE_EXTENSION, ext))
             _shutil.copytree(self.package_path, save_path)
+
+            saved_spec_path = _os.path.join(
+                save_path, "Data", _MLPACKAGE_AUTHOR_NAME, _MODEL_FILE_NAME
+            )
+            _save_spec(self._spec, saved_spec_path)
         else:
             _save_spec(self._spec, save_path)
 
     def get_spec(self):
         """
         Get a deep copy of the protobuf specification of the model.
 
@@ -479,48 +520,63 @@
 
     def predict(self, data):
         """
         Return predictions for the model.
 
         Parameters
         ----------
-        data: dict[str, value]
-            Dictionary of data to make predictions from where the keys are
-            the names of the input features.
-            If value is array type, numpy.ndarray, tensorflow.Tensor and torch.Tensor are acceptable.
+        data: dict[str, value] or list[dict[str, value]]
+            Dictionary of data to use for predictions, where the keys are the names of the input features.
+            For batch predictons, use a list of such dictionaries.
+
+            The following dictionary values types are acceptable: list, array, numpy.ndarray, tensorflow.Tensor
+            and torch.Tensor.
 
         Returns
         -------
         dict[str, value]
-            Predictions as a dictionary where each key is the output feature
-            name.
+            Predictions as a dictionary where each key is the output feature name.
+
+        list[dict[str, value]]
+            For batch prediction, returns a list of the above dictionaries.
 
         Examples
         --------
         data = {'bedroom': 1.0, 'bath': 1.0, 'size': 1240}
         predictions = model.predict(data)
-        data = {'array': numpy.array([[1.0, 2.0], [3.0, 4.0]])}
-        predictions = model.predict(data)
-        data = {'array': torch.Tensor([[1.0, 2.0], [3.0, 4.0]])}
-        predictions = model.predict(data)
-        data = {'array': tensorflow.Tensor([[1.0, 2.0], [3.0, 4.0]])}
-        predictions = model.predict(data)
+
+        data = [ {'bedroom': 1.0, 'bath': 1.0, 'size': 1240},
+                 {'bedroom': 4.0, 'bath': 2.5, 'size': 2400} ]
+        batch_predictions = model.predict(data)
         """
+        def verify_and_convert_input_dict(d):
+            self._verify_input_dict(d)
+            self._convert_tensor_to_numpy(d)
+            # TODO: remove the following call when this is fixed: rdar://92239209
+            self._update_float16_multiarray_input_to_float32(d)
+
         if self.is_package and _is_macos() and _macos_version() < (12, 0):
             raise Exception(
                 "predict() for .mlpackage is not supported in macOS version older than 12.0."
             )
+        if type(data) not in (list, dict):
+            raise TypeError("\"data\" parameter must be either a dict or list of dict.")
+        if type(data) == list and not all(map(lambda x: type(x) == dict, data)):
+            raise TypeError("\"data\" list must contain only dictionaries")
 
         if self.__proxy__:
-            self._verify_input_dict(data)
-            self._convert_tensor_to_numpy(data)
-            # TODO: remove the following call when this is fixed: rdar://92239209
-            self._update_float16_multiarray_input_to_float32(data)
-            return self.__proxy__.predict(data)
-        else:
+            if type(data) == dict:
+                verify_and_convert_input_dict(data)
+                return self.__proxy__.predict(data)
+            else:
+                assert type(data) == list
+                for i in data:
+                    verify_and_convert_input_dict(i)
+                return self.__proxy__.batchPredict(data)
+        else:   # Error case
             if _macos_version() < (10, 13):
                 raise Exception(
                     "Model prediction is only supported on macOS version 10.13 or later."
                 )
 
             try:
                 from ..libcoremlpython import _MLModelProxy
@@ -551,14 +607,21 @@
                 )
             else:
                 if self._framework_error:
                     raise self._framework_error
                 else:
                     raise Exception("Unable to load CoreML.framework. Cannot make predictions.")
 
+    def _input_has_infinite_upper_bound(self) -> bool:
+        """Check if any input has infinite upper bound (-1)."""
+        for input_spec in self.input_description._fd_spec:
+            for size_range in input_spec.type.multiArrayType.shapeRange.sizeRanges:
+                if size_range.upperBound == -1:
+                    return True
+        return False
 
     def _set_build_info_mil_attributes(self, metadata):
         if self._spec.WhichOneof('Type') != "mlProgram":
             # No MIL attributes to set
             return
 
         ml_program_attributes = self._spec.mlProgram.attributes
@@ -595,24 +658,26 @@
 
         Examples
         --------
         mil_prog = model._get_mil_internal()
         """
         return _deepcopy(self._mil_program)
 
+
     def _verify_input_dict(self, input_dict):
         # Check if the input name given by the user is valid.
         # Although this is checked during prediction inside CoreML Framework,
         # we still check it here to return early and
         # return a more verbose error message
         self._verify_input_name_exists(input_dict)
 
         # verify that the pillow image modes are correct, for image inputs
         self._verify_pil_image_modes(input_dict)
 
+
     def _verify_pil_image_modes(self, input_dict):
         if not _HAS_PIL:
             return
         for input_desc in self._spec.description.input:
             if input_desc.type.WhichOneof("Type") == "imageType":
                 input_val = input_dict.get(input_desc.name, None)
                 if not isinstance(input_val, _PIL_IMAGE.Image):
@@ -661,10 +726,10 @@
         for inp in self._spec.description.input:
             type_value = inp.type.multiArrayType.dataType
             type_name = inp.type.multiArrayType.ArrayDataType.Name(type_value)
             if type_name != "INVALID_ARRAY_DATA_TYPE":
                 model_input_to_types[inp.name] = type_name
 
         for given_input_name, given_input in input_dict.items():
-            if not given_input_name in model_input_to_types:
+            if given_input_name not in model_input_to_types:
                 continue
             input_dict[given_input_name] = convert(given_input)
```

### Comparing `coremltools-6.3.0/coremltools/models/nearest_neighbors/builder.py` & `coremltools-7.0b1/coremltools/models/nearest_neighbors/builder.py`

 * *Files 0% similar despite different names*

```diff
@@ -359,15 +359,15 @@
         	For kd_tree indexes, the leaf size to use (default = 30).
         
         Returns
         -------
         None
         """
         index_type = index_type.lower()
-        if not index_type in self._VALID_INDEX_TYPES:
+        if index_type not in self._VALID_INDEX_TYPES:
             raise TypeError("Invalid index type")
 
         if index_type == "kd_tree":
             if leaf_size <= 0:
                 raise TypeError("leaf_size must be > 0")
             self.spec.kNearestNeighborsClassifier.nearestNeighborsIndex.singleKdTreeIndex.leafSize = (
                 leaf_size
```

### Comparing `coremltools-6.3.0/coremltools/models/neural_network/builder.py` & `coremltools-7.0b1/coremltools/models/neural_network/builder.py`

 * *Files 2% similar despite different names*

```diff
@@ -38,15 +38,16 @@
 
     if activation == "SIGMOID":
         param.sigmoid.MergeFromString(b"")
     elif activation == "TANH":
         param.tanh.MergeFromString(b"")
     elif activation == "LINEAR":
         param.linear.MergeFromString(b"")
-    elif activation == "SIGMOID_HARD":
+    elif activation == "SIGMOID_HARD" or activation == "HARD_SIGMOID":
+        # The standard name is "hard_sigmoid", but in nn there are still usages of "sigmoid_hard".
         param.sigmoidHard.MergeFromString(b"")
     elif activation == "SCALED_TANH":
         param.scaledTanh.MergeFromString(b"")
     elif activation == "RELU":
         param.ReLU.MergeFromString(b"")
     else:
         raise TypeError(
@@ -219,42 +220,50 @@
 
     The NeuralNetworkBuilder constructs a Core ML neural network specification
     layer by layer. The layers should be added in such an order that the inputs
     to each layer (referred to as blobs of each layer) have been previously
     defined. The builder can also set preprocessing steps to handle
     specialized input formats (such as images), and set class labels for neural
     network classifiers.
-    
-    Refer to the protobuf messages in the specification (NeuralNetwork.proto) 
+
+    Refer to the protobuf messages in the specification (NeuralNetwork.proto)
     for more details.
 
     Examples
     --------
     .. sourcecode:: python
 
         from coremltools.models.neural_network import datatypes, NeuralNetworkBuilder
         from coremltools.models.utils import save_spec
 
         # Create a neural network binary classifier that classifies
         # 3-dimensional data points
         # Specify input and output dimensions
-        >>> input_dim = (3,)
-        >>> output_dim = (2,)
+        input_dim = (3,)
+        output_dim = (2,)
 
         # Specify input and output features
-        >>> input_features = [('data', datatypes.Array(*input_dim))]
-        >>> output_features = [('probs', datatypes.Array(*output_dim))]
+        input_features = [("data", datatypes.Array(*input_dim))]
+        output_features = [("probs", datatypes.Array(*output_dim))]
 
         # Build a simple neural network with 1 inner product layer
-        >>> builder = NeuralNetworkBuilder(input_features, output_features)
-        >>> builder.add_inner_product(name='ip_layer', W=weights, b=bias, input_channels=3, output_channels=2,
-        ... has_bias=True, input_name='data', output_name='probs')
+        builder = NeuralNetworkBuilder(input_features, output_features)
+        builder.add_inner_product(
+            name="ip_layer",
+            W=weights,
+            b=bias,
+            input_channels=3,
+            output_channels=2,
+            has_bias=True,
+            input_name="data",
+            output_name="probs",
+        )
 
         # save the spec by the builder
-        >>> save_spec(builder.spec, 'network.mlmodel')
+        save_spec(builder.spec, "network.mlmodel")
     """
 
     def __init__(
         self,
         input_features=None,
         output_features=None,
         mode=None,
@@ -269,77 +278,77 @@
         model interface, or a NeuralNetwork protobuf message, either from scratch or using an
         existing specification.
 
         Parameters
         ----------
 
         input_features: [(str, datatypes.Array)] or None
-            List of input feature of the network. 
-            Each feature is a ``(name, array)`` tuple, where ``name`` is the 
-            name of the feature, and ``array`` is a ``datatype.Array`` object 
+            List of input feature of the network.
+            Each feature is a ``(name, array)`` tuple, where ``name`` is the
+            name of the feature, and ``array`` is a ``datatype.Array`` object
             describing the feature type.
-            
+
             * When ``spec`` is ``None`` (building from scratch), ``input_features`` must not be ``None``.
 
         output_features: [(str, datatypes.Array or None)] or None
-            List of output feature of the network. Each feature is a 
-            ``(name, array)`` tuple, where ``name`` is the name of the feature, 
+            List of output feature of the network. Each feature is a
+            ``(name, array)`` tuple, where ``name`` is the name of the feature,
             and ``array`` is a ``datatypes.Array`` object describing the feature type.
-            
+
             * The ``array`` can be ``None`` if not known.
-            
+
             * When ``spec`` is ``None`` (building from scratch), ``output_features`` must not be ``None``.
-            
+
         mode: str ('classifier', 'regressor' or None)
             Mode (one of ``'classifier'``, ``'regressor'``, or ``None``).
 
             When ``mode = 'classifier'``, a NeuralNetworkClassifier spec will be
             constructed.  When ``mode = 'regressor'``, a NeuralNetworkRegressor
             spec will be constructed.
 
         disable_rank5_shape_mapping: bool
             Only applicable for neural networks.
-            
+
             If True, inputs are no longer forced to map to rank 5 tensors
             (rank is equal to the length of the shape of the tensor).
             Instead, for multi-array inputs ``"EXACT_ARRAY_MAPPING"`` mapping is used, whereas
-            for image inputs ``"RANK4_IMAGE_MAPPING"`` is used. For details, 
+            for image inputs ``"RANK4_IMAGE_MAPPING"`` is used. For details,
             see description of enums ``NeuralNetworkMultiArrayShapeMapping``
             and ``NeuralNetworkImageShapeMapping`` in NeuralNetwork.proto.
-            
+
             When ``spec`` is not ``None``, this argument will be ignored.
 
         spec: None or coremltools.proto.Model_pb2
-            If ``None``, a new MLModel spec will be created by the builder with 
+            If ``None``, a new MLModel spec will be created by the builder with
             input and output features.
-            
-            Otherwise, the builder will continue to build on ``spec``. 
+
+            Otherwise, the builder will continue to build on ``spec``.
             This is useful when the MLModel is built incrementally.
 
         nn_spec: None or coremltools.proto.NeuralNetwork_pb2
             If ``None``, a new, empty NeuralNetwork proto will be created for spec.
-            
-            If ``nn_spec`` is not ``None`` and ``spec`` is ``None``, the builder will 
-            build a NeuralNetwork spec without wrapping it within an MLModel. 
+
+            If ``nn_spec`` is not ``None`` and ``spec`` is ``None``, the builder will
+            build a NeuralNetwork spec without wrapping it within an MLModel.
             This is useful to create nested NeuralNetworks for models
             with control flow operations.
 
         use_float_arraytype: bool
             If true, the datatype of input/output multiarrays is set to Float32 instead
             of double.
 
         Examples
         --------
         .. sourcecode:: python
 
             # Construct a builder that builds a neural network classifier with a 299 x 299 x 3
             # dimensional input and 1000 dimensional output
-            >>> input_features = [('data', datatypes.Array((299, 299, 3)))]
-            >>> output_features = [('probs', datatypes.Array((1000,)))]
-            >>> builder = NeuralNetworkBuilder(input_features, output_features, mode='classifier')
+            input_features = [("data", datatypes.Array((299, 299, 3)))]
+            output_features = [("probs", datatypes.Array((1000,)))]
+            builder = NeuralNetworkBuilder(input_features, output_features, mode="classifier")
 
         See Also
         --------
         set_input, set_output, set_class_labels
         """
         self.spec = spec
         self.nn_spec = nn_spec
@@ -444,15 +453,15 @@
 
         Examples
         --------
         .. sourcecode:: python
 
             # Set the neural network spec inputs to be 3 dimensional vector data1 and
             # 4 dimensional vector data2.
-            >>> builder.set_input(input_names=['data1', 'data2'], input_dims=[(3,), (4,)])
+            builder.set_input(input_names=["data1", "data2"], input_dims=[(3,), (4,)])
 
         See Also
         --------
         set_output, set_class_labels
         """
 
         if len(input_names) != len(input_dims):
@@ -505,15 +514,15 @@
 
         Examples
         --------
         .. sourcecode:: python
 
             # Set the neural network spec outputs to be 3 dimensional vector feature1 and
             # 4 dimensional vector feature2.
-            >>> builder.set_output(output_names=['feature1', 'feature2'], output_dims=[(3,), (4,)])
+            builder.set_output(output_names=["feature1", "feature2"], output_dims=[(3,), (4,)])
 
         See Also
         --------
         set_input, set_class_labels
         """
 
         if len(output_names) != len(output_dims):
@@ -540,15 +549,15 @@
 
         Examples
         --------
         .. sourcecode:: python
 
             # Set the neural network spec training inputs to be 3 dimensional vector for 'input' and
             # Double for 'target'.
-            >>> builder.set_training_input([('input', datatypes.Array(3)), ('target', 'Double')])
+            builder.set_training_input([("input", datatypes.Array(3)), ("target", "Double")])
         """
         spec = self.spec
         set_training_features(spec, training_input)
 
     def set_class_labels(
         self, class_labels, predicted_feature_name="classLabel", prediction_blob=""
     ):
@@ -929,27 +938,27 @@
                 elif type(field) == _NeuralNetwork_pb2.WeightParams:
                     field.isUpdatable = True
                 else:
                     pass
 
     def set_categorical_cross_entropy_loss(self, name, input):
         r"""
-        Categorical Cross Entropy is used for single label categorization 
+        Categorical Cross Entropy is used for single label categorization
         (only one category is applicable for each data point).
 
         Parameters
         ----------
         name: The name of the loss layer
         input: The name of the input
-        	The ``input`` should be a vector of length N representing the 
-        	distribution over N categories. This must be the output of a softmax.
+                The ``input`` should be a vector of length N representing the
+                distribution over N categories. This must be the output of a softmax.
 
         Notes
         -----
-        
+
         .. math::
            Loss_ {CCE}(input, target) = -\sum_{i = 1} ^ {N}(target == i) log(input[i]) = - log(input[target])
         """
         if self.spec is None:
             return
 
         if name in self.layer_specs:
@@ -1034,24 +1043,24 @@
                 target
             )
         )
 
     def set_mean_squared_error_loss(self, name, input_feature=None):
         """
         input_feature: [(str, datatypes.Array)] or None
-            The input feature of the loss layer. Each feature is a 
-            ``(name, array)`` tuple, where ``name`` is the name of the model's 
-            tensor our loss will be attached to, and ``array`` is a 
+            The input feature of the loss layer. Each feature is a
+            ``(name, array)`` tuple, where ``name`` is the name of the model's
+            tensor our loss will be attached to, and ``array`` is a
             ``datatypes.Array`` object describing the shape of that tensor.
             Both the name and the array's shape must be provided in the tuple.
-            
+
         Examples
         --------
-        
-            >>> feature = [('output_tensor', datatypes.Array((299, 299, 3)))]
+
+            feature = [('output_tensor', datatypes.Array((299, 299, 3)))]
         """
         if self.spec is None:
             return
 
         if name in self.layer_specs:
             raise ValueError("Name %s is already used." % name)
 
@@ -1459,70 +1468,70 @@
         nbits=8,
         quant_scale=None,
         quant_bias=None,
         quant_lut=None,
     ):
         """
         Add an inner product layer to the model.
-        Refer to the ``InnerProductLayerParams`` message in the specification 
+        Refer to the ``InnerProductLayerParams`` message in the specification
         (NeuralNetwork.proto) for more details.
 
         Parameters
         ----------
         name: str
             The name of this layer.
         W: numpy.array or bytes()
             Weight matrix of shape ``(output_channels, input_channels)``.
-            If ``W`` is of type ``bytes()`` (quantized), other quantization 
+            If ``W`` is of type ``bytes()`` (quantized), other quantization
             related arguments must be provided as well (see below).
         b: numpy.array
             Bias vector of shape: ``(output_channels, )``.
         input_channels: int
             Number of input channels.
         output_channels: int
             Number of output channels.
         has_bias: boolean
             Whether the bias vector of this layer is ignored in the spec.
 
             - If True, the bias vector of this layer is not ignored.
             - If False, the bias vector is ignored.
-        
+
         input_name: str
             The input blob name of this layer.
         output_name: str
             The output blob name of this layer.
 
         Quantization arguments, used when ``W`` is of type ``bytes()``:
             int_8_dynamic_quantize: boolean
                 Whether to quantize and dequantize before and after inner product, respectively.
-                Expects byte weights, representing int8 values, if True. 
+                Expects byte weights, representing int8 values, if True.
                 See NeuralNetwork.proto for other validation conditions.
 
             is_quantized_weight: bool, optional
-                Set it to true when ``W`` is of type ``bytes()``, representing 
+                Set it to true when ``W`` is of type ``bytes()``, representing
                 quantized weights, default: false.
 
             quantization_type: str
-                When weights are quantized (that is, ``W`` is of type ``bytes()``), 
+                When weights are quantized (that is, ``W`` is of type ``bytes()``),
                 this should be either ``"linear"`` or ``"lut"``.
 
             nbits: int
-                Should be between 1 and 8 (inclusive). Number of bits per weight 
+                Should be between 1 and 8 (inclusive). Number of bits per weight
                 value. Only applicable when weights are quantized.
 
             quant_scale: numpy.array(dtype=numpy.float32)
-                scale vector to be used with linear quantization. Must be of 
+                scale vector to be used with linear quantization. Must be of
                 length either 1 or output_channels.
 
             quant_bias: numpy.array(dtype=numpy.float32)
-                bias vector to be used with linear quantization. Must be of 
+                bias vector to be used with linear quantization. Must be of
                 length either 1 or output_channels.
 
             quant_lut: numpy.array(dtype=numpy.float32)
-                the LUT (look up table) to be used with LUT quantization. 
+                the LUT (look up table) to be used with LUT quantization.
                 Must be of length 2^n bits.
 
         See Also
         --------
         add_embedding, add_convolution, add_batched_mat_mul
         """
 
@@ -1583,24 +1592,24 @@
         nbits=8,
         quant_scale=None,
         quant_bias=None,
         quant_lut=None,
     ):
         """
         Add an embedding layer to the model.
-        Refer to the ``EmbeddingLayerParams`` message in the specification 
+        Refer to the ``EmbeddingLayerParams`` message in the specification
         (NeuralNetwork.proto) for more details.
 
         Parameters
         ----------
         name: str
             The name of this layer.
         W: float32 numpy.array or bytes()
             Weight matrix of shape ``(output_channels, input_dim)``.
-            If ``W`` is of type ``bytes()`` (quantized to 1-8 bits), other 
+            If ``W`` is of type ``bytes()`` (quantized to 1-8 bits), other
             quantization related arguments must be provided as well (see below).
         b: numpy.array
             Bias vector of shape ``(output_channels, )``.
         input_dim: int
             Size of the vocabulary (1 + maximum integer index of the words).
         output_channels: int
             Number of output channels.
@@ -1618,30 +1627,30 @@
 
         Quantization arguments expected, when ``W`` is of type ``bytes()``:
 
         is_quantized_weight: bool
             Set it to true when ``W`` is of type ``bytes()``, representing quantized weights.
 
         quantization_type: str
-            When weights are quantized (that is, ``W`` is of type ``bytes()``), 
+            When weights are quantized (that is, ``W`` is of type ``bytes()``),
             this should be either ``"linear"`` or ``"lut"``.
 
         nbits: int
             Should be between 1 and 8 (inclusive). Number of bits per weight value.
 
         quant_scale: numpy.array(dtype=numpy.float32)
-            Scale vector to be used with linear quantization. 
+            Scale vector to be used with linear quantization.
             Must be of length either 1 or output_channels.
 
         quant_bias: numpy.array(dtype=numpy.float32)
-            Bias vector to be used with linear quantization. 
+            Bias vector to be used with linear quantization.
             Must be of length either 1 or output_channels.
 
         quant_lut: numpy.array(dtype=numpy.float32)
-            The LUT (look up table) to be used with LUT quantization. 
+            The LUT (look up table) to be used with LUT quantization.
             Must be of length 2^n bits.
 
         See Also
         --------
         add_inner_product
         """
 
@@ -1683,15 +1692,15 @@
             bias.floatValue.extend(b.flatten())
 
         return spec_layer
 
     def add_softmax(self, name, input_name, output_name):
         """
         Add a softmax layer to the model.
-        Refer to the ``SoftmaxLayerParams`` message in the specification 
+        Refer to the ``SoftmaxLayerParams`` message in the specification
         (NeuralNetwork.proto) for more details.
 
         Parameters
         ----------
         name: str
             The name of this layer.
         input_name: str
@@ -1743,68 +1752,68 @@
                 - ``'SOFTPLUS'``: softplus function.
                 - ``'SOFTSIGN'``: softsign function.
                 - ``'SIGMOID_HARD'``: hard sigmoid function, defined as:
 
                   ``f(x) = min(max(alpha * x + beta, -1), 1)``
 
                   where ``alpha`` and ``beta`` are constant scalars.
-                  
+
                 - ``'LEAKYRELU'``: leaky relu function, defined as:
 
                   ``f(x) = (x >= 0) * x + (x < 0) * alpha * x``
 
                   where ``alpha`` is a constant scalar.
-                  
+
                 - ``'PRELU'``: Parametric ReLU function, defined as:
 
                   ``f(x) = (x >= 0) * x + (x < 0) * alpha * x``
 
                   where ``alpha`` is a multi-dimensional array of same size as ``x``.
-                  
+
                 - ``'ELU'``: Exponential linear unit function, defined as:
 
                   ``f(x) = (x >= 0) * x + (x < 0) * (alpha * exp(x) - 1)``
 
                   where ``alpha`` is a constant scalar.
 
                 - ``'PARAMETRICSOFTPLUS'``: Parametric softplus function, defined as:
 
                   ``f(x) = alpha * log(1 + exp(beta * x))``
 
-                  where ``alpha`` and ``beta`` are two multi-dimensional arrays 
+                  where ``alpha`` and ``beta`` are two multi-dimensional arrays
                   of same size as ``x``.
-                  
+
                 - ``'THRESHOLDEDRELU'``: Thresholded ReLU function, defined as:
 
                   ``f(x) = (x >= alpha) * x``
 
                   where ``alpha`` is a constant scalar.
-                  
+
                 - ``'LINEAR'``: linear function.
 
                    ``f(x) = alpha * x + beta``
 
         input_name: str
             The input blob name of this layer.
         output_name: str
             The output blob name of this layer.
         params: list of float or numpy.array
             Parameters for the activation, depending on non_linearity.
 
-                - When ``non_linearity`` is one of [``'RELU'``, ``'SIGMOID'``, ``'TANH'``, ``'SCALED_TANH'``, ``'SOFTPLUS'``, ``'SOFTSIGN'``], 
+                - When ``non_linearity`` is one of [``'RELU'``, ``'SIGMOID'``, ``'TANH'``, ``'SCALED_TANH'``, ``'SOFTPLUS'``, ``'SOFTSIGN'``],
                   params is ignored.
-                - When ``non_linearity`` is one of [``'SCALED_TANH'``, ``'SIGMOID_HARD'``, ``'LINEAR'``], 
+                - When ``non_linearity`` is one of [``'SCALED_TANH'``, ``'SIGMOID_HARD'``, ``'LINEAR'``],
                   param is a list of 2 floats ``[alpha, beta]``.
-                - When ``non_linearity`` is one of [``'LEAKYRELU'``, ``'ELU'``, ``'THRESHOLDEDRELU'``], 
+                - When ``non_linearity`` is one of [``'LEAKYRELU'``, ``'ELU'``, ``'THRESHOLDEDRELU'``],
                   param is a list of 1 float ``[alpha]``.
-                - When ``non_linearity`` is ``'PRELU'``, param is a list of 1 numpy array ``[alpha]``. 
+                - When ``non_linearity`` is ``'PRELU'``, param is a list of 1 numpy array ``[alpha]``.
                   The shape of ``alpha`` is ``(C,)``, where ``C`` is either the number of input channels or
                   1. When ``C = 1``, same ``alpha`` is applied to all channels.
-                - When ``non_linearity`` is ``'PARAMETRICSOFTPLUS'``, param is a 
-                  list of 2 numpy arrays ``[alpha, beta]``. The shape of ``alpha`` and 
+                - When ``non_linearity`` is ``'PARAMETRICSOFTPLUS'``, param is a
+                  list of 2 numpy arrays ``[alpha, beta]``. The shape of ``alpha`` and
                   `beta` is ``(C, )``, where ``C`` is either
                   the number of input channels or 1. When ``C = 1``, same ``alpha`` and
                   ``beta`` are applied to all channels.
 
         See Also
         --------
         add_convolution, add_softmax
@@ -1922,26 +1931,26 @@
         mode: str
             A string specifying the mode of the elementwise layer. It can be one of the following:
 
             - ``'CONCAT'``: Concatenate input blobs along the channel axis.
             - ``'SEQUENCE_CONCAT'``: Concatenate input blobs along the sequence axis.
             - ``'ADD'``: Perform an element-wise summation over the input blobs.
             - ``'MULTIPLY'``: Perform an element-wise multiplication over the input blobs.
-            - ``'DOT'``: Compute the dot product of the two input blobs. 
+            - ``'DOT'``: Compute the dot product of the two input blobs.
               In this mode, the length of ``input_names`` should be 2.
-            - ``'COS'``: Compute the cosine similarity of the two input blobs. 
+            - ``'COS'``: Compute the cosine similarity of the two input blobs.
               In this mode, the length of ``input_names`` should be 2.
             - ``'MAX'``: Compute the element-wise maximum over the input blobs.
             - ```'MIN'```: Compute the element-wise minimum over the input blobs.
             - ``'AVE'``: Compute the element-wise average over the input blobs.
 
         alpha: float
-            * if ``mode == 'ADD'`` and there is only one ``input_name``, 
+            * if ``mode == 'ADD'`` and there is only one ``input_name``,
               ``alpha`` is added to the input.
-            * if ``mode == 'MULTIPLY'`` and there is only one ``input_name``, 
+            * if ``mode == 'MULTIPLY'`` and there is only one ``input_name``,
               ``alpha`` is multiplied to the input.
 
         See Also
         --------
         add_upsample, add_sequence_repeat
 
         """
@@ -1984,53 +1993,53 @@
         input_name,
         output_name,
         mode="NN",
         linear_upsample_mode="DEFAULT",
     ):
         """
         Add an upsample layer to the model.
-        Refer to the ``UpsampleLayerParams`` message in the specification 
+        Refer to the ``UpsampleLayerParams`` message in the specification
         (NeuralNetwork.proto) for more details.
 
         Parameters
         ----------
         name: str
             The name of this layer.
         scaling_factor_h: int or float
-            Scaling factor on the vertical direction. Float values only 
+            Scaling factor on the vertical direction. Float values only
             supported with ``BILINEAR`` and ``ALIGN_CORNERS_*``.
         scaling_factor_w: int or float
-            Scaling factor on the horizontal direction. Float values only 
+            Scaling factor on the horizontal direction. Float values only
             supported with ``BILINEAR`` and ``ALIGN_CORNERS_*``.
         input_name: str
             The input blob name of this layer.
         output_name: str
             The output blob name of this layer.
         mode: str
             Overall interpolation mode. The following values are supported:
-            
+
             * ``'NN'``: nearest neighbour
             * ``'BILINEAR'``: bilinear interpolation
-            
+
         linear_upsample_mode: str
-            Specifies the behavior for linear upsampling. Only valid when 
+            Specifies the behavior for linear upsampling. Only valid when
             Interpolation Mode is ``BILINEAR``.
-            
-            If input grid is ``[0, Xin-1]`` (corresponding to an input size of 
+
+            If input grid is ``[0, Xin-1]`` (corresponding to an input size of
             ``Xin``), and if the output size is ``Xout``,
             then the grid points are sampled in the following manner:
-            
+
             'DEFAULT':
                 - ``spacing = (Xin-Xin/Xout) / (Xout-1)``
                 - ``grid_point[i] = min(Xin-1, max(0, i * spacing)), for i = 0,1,2,..,Xout-1``
-                
+
             'ALIGN_CORNERS_TRUE':
                 - ``spacing = (Xin-1) / (Xout-1)``
                 - ``grid_point[i] = min(Xin-1, max(0, i * spacing)), for i = 0,1,2,..,Xout-1``
-                
+
             'ALIGN_CORNERS_FALSE':
                 - ``spacing = Xin / Xout``
                 - ``grid_point[i] = min(Xin-1, max(0, i * spacing + 0.5 * spacing - 0.5)), for i = 0,1,2,..,Xout-1``
 
         See Also
         --------
         add_resize_bilinear
@@ -2039,21 +2048,17 @@
 
         mode = mode.upper() if isinstance(mode, str) else mode
         linear_upsample_mode = (
             linear_upsample_mode.upper()
             if isinstance(linear_upsample_mode, str)
             else linear_upsample_mode
         )
-        if not mode in ["NN", "BILINEAR"]:
+        if mode not in ["NN", "BILINEAR"]:
             raise ValueError("Unsupported upsampling mode %s" % mode)
-        if not linear_upsample_mode in [
-            "DEFAULT",
-            "ALIGN_CORNERS_TRUE",
-            "ALIGN_CORNERS_FALSE",
-        ]:
+        if linear_upsample_mode not in ["DEFAULT", "ALIGN_CORNERS_TRUE", "ALIGN_CORNERS_FALSE"]:
             raise ValueError(
                 "Unsupported linear upsampling mode %s" % linear_upsample_mode
             )
 
         # Default linear upsample mode is backwards compatible, else set spec to iOS14
         if (
             linear_upsample_mode != "DEFAULT"
@@ -2102,15 +2107,15 @@
         input_name,
         output_name,
         shape_scale=None,
         shape_bias=None,
     ):
         """
         Add a scale layer to the model.
-        Refer to the ``ScaleLayerParams`` message in the specification 
+        Refer to the ``ScaleLayerParams`` message in the specification
         (NeuralNetwork.proto) for more details.
 
         Parameters
         ----------
         name: str
             The name of this layer.
         W: int or numpy.array
@@ -2121,18 +2126,18 @@
             Whether the bias vector of this layer is ignored in the ``spec``.
         input_name: str
             The input blob name of this layer.
         output_name: str
             The output blob name of this layer.
 
         shape_scale: list of int or tuple of int
-            List of ints that specifies the shape of the scale parameter. 
+            List of ints that specifies the shape of the scale parameter.
             Can be ``[1]``, ``[C]``, ``[1,H,W]``, or ``[C,H,W]``.
         shape_bias: list of int
-            List of ints that specifies the shape of the bias parameter 
+            List of ints that specifies the shape of the bias parameter
             (if present). Can be ``[1]``, ``[C]``, ``[1,H,W]``, or ``[C,H,W]``.
 
         See Also
         --------
         add_bias
         """
 
@@ -2171,29 +2176,29 @@
                     "Dimensions of 'shape_bias' do not match the size of the provided 'b' parameter"
                 )
         return spec_layer
 
     def add_bias(self, name, b, input_name, output_name, shape_bias=None):
         """
         Add a bias layer to the model.
-        Refer to the ``BiasLayerParams`` message in the specification 
+        Refer to the ``BiasLayerParams`` message in the specification
         (NeuralNetwork.proto) for more details.
 
         Parameters
         ----------
         name: str
             The name of this layer.
         b: int or numpy.array
             Bias to add to the input.
         input_name: str
             The input blob name of this layer.
         output_name: str
             The output blob name of this layer.
         shape_bias: list of int
-            List of ints that specifies the shape of the bias parameter 
+            List of ints that specifies the shape of the bias parameter
             (if present). Can be ``[1]``, ``[C]``, ``[1,H,W]``, or ``[C,H,W]``.
 
         See Also
         --------
         add_scale
         """
 
@@ -2219,15 +2224,15 @@
                 "of the provided 'b' parameter"
             )
         return spec_layer
 
     def add_sequence_repeat(self, name, nrep, input_name, output_name):
         """
         Add a sequence repeat layer to the model.
-        Refer to the ``SequenceRepeatLayerParams`` message in the specification 
+        Refer to the ``SequenceRepeatLayerParams`` message in the specification
         (NeuralNetwork.proto) for more details.
 
         Parameters
         ----------
         name: str
             The name of this layer.
         nrep: int
@@ -2270,20 +2275,20 @@
         padding_left=0,
         padding_right=0,
         same_padding_asymmetry_mode="BOTTOM_RIGHT_HEAVY",
         **kwargs
     ):
         """
         Add a convolution layer to the network.
-        Refer to the ``ConvolutionLayerParams`` message in the specification 
+        Refer to the ``ConvolutionLayerParams`` message in the specification
         (NeuralNetwork.proto) for more details.
 
         Parameters
         ----------
-        
+
         name: str
             The name of this layer.
 
         kernel_channels: int
             Number of channels for the convolution kernels.
 
         output_channels: int
@@ -2299,57 +2304,57 @@
             Stride along the height direction.
 
         stride_width: int
             Stride along the height direction.
 
         border_mode: str
             Option for the padding type and output blob shape. Can be either 'valid' or 'same'.
- 
+
         groups: int
-            Number of kernel groups. Input is divided into groups along the channel axis. 
+            Number of kernel groups. Input is divided into groups along the channel axis.
             Each kernel group share the same weights.
- 
+
         W: numpy.array or bytes() or None
 
             Weight of the convolution kernels.
 
-            * If ``is_deconv`` is False, ``W`` should have 
+            * If ``is_deconv`` is False, ``W`` should have
               shape ``(height, width, kernel_channels, output_channels)``, where:
                  ``kernel_channel = input_channels / groups``
-            * If ``is_deconv`` is True, ``W`` should have 
+            * If ``is_deconv`` is True, ``W`` should have
               shape ``(height, width, kernel_channels, output_channels / groups)``, where:
                  ``kernel_channel = input_channels``
 
-            If ``W`` is of type ``bytes()`` (quantized), other quantization 
+            If ``W`` is of type ``bytes()`` (quantized), other quantization
             related arguments must be provided as well (see below).
 
             For Core ML specification version >=4, ``W`` can be ``None``. In this case,
-            the convolution layer takes 2 inputs, where the 1st input represents 
+            the convolution layer takes 2 inputs, where the 1st input represents
             the input feature map, and the 2nd input represents the weight blob.
 
         b: numpy.array
             Biases of the convolution kernels. ``b`` should have shape ``(outputChannels, )``.
 
         has_bias: boolean
             Whether bias is ignored.
 
             - If True, bias is not ignored.
             - If False, bias is ignored.
 
         is_deconv: boolean
-            Whether the convolution layer is performing a convolution or a 
+            Whether the convolution layer is performing a convolution or a
             transposed convolution (deconvolution).
 
             - If True, the convolution layer is performing transposed convolution.
             - If False, the convolution layer is performing regular convolution.
 
         output_shape: tuple or None
-            Either ``None`` or a 2-tuple, specifying the output 
-            shape ``(output_height, output_width)``. 
-            
+            Either ``None`` or a 2-tuple, specifying the output
+            shape ``(output_height, output_width)``.
+
             - Used only when ``is_deconv == True``.
             - When ``is_deconv == False``, this parameter is ignored.
             - If it is ``None``, the output shape is calculated automatically using the ``border_mode``.
 
         input_name: str or list of str
             The input blob name(s) of this layer.
 
@@ -2357,47 +2362,47 @@
             The output blob name of this layer.
 
         dilation_factors: list of int
             Dilation factors across height and width directions. Must be a list of two positive integers.
             Defaults to ``[1, 1]``.
 
         padding_top, padding_bottom, padding_left, padding_right: int
-            Values of height (top, bottom) and width (left, right) padding 
+            Values of height (top, bottom) and width (left, right) padding
             to be used if ``border_more`` is ``"valid"``.
 
         same_padding_asymmetry_mode: str
             Type of asymmetric padding to be used when  ``border_mode`` is ``'same'``.
             Can be either ``'BOTTOM_RIGHT_HEAVY'`` or  ``'TOP_LEFT_HEAVY'``.
 
-		Quantization
-			Quantization arguments expected in ``kwargs``, when ``W`` is of type ``bytes()``.
-        
-				quantization_type: str
-					When weights are quantized (that is, ``W`` is of type ``bytes()``), 
-					this should be either ``"linear"`` or ``"lut"``.
-
-				nbits: int
-					Should be between 1 and 8 (inclusive). Number of bits per weight 
-					value. Only applicable when weights are quantized.
-
-				quant_scale: numpy.array(dtype=numpy.float32)
-					scale vector to be used with linear quantization. Must be of 
-					length either 1 or ``output_channels``.
-
-				quant_bias: numpy.array(dtype=numpy.float32)
-					bias vector to be used with linear quantization. Must be of 
-					length either 1 or ``output_channels``.
+                Quantization
+                        Quantization arguments expected in ``kwargs``, when ``W`` is of type ``bytes()``.
+
+                                quantization_type: str
+                                        When weights are quantized (that is, ``W`` is of type ``bytes()``),
+                                        this should be either ``"linear"`` or ``"lut"``.
+
+                                nbits: int
+                                        Should be between 1 and 8 (inclusive). Number of bits per weight
+                                        value. Only applicable when weights are quantized.
+
+                                quant_scale: numpy.array(dtype=numpy.float32)
+                                        scale vector to be used with linear quantization. Must be of
+                                        length either 1 or ``output_channels``.
+
+                                quant_bias: numpy.array(dtype=numpy.float32)
+                                        bias vector to be used with linear quantization. Must be of
+                                        length either 1 or ``output_channels``.
 
-				quant_lut: numpy.array(dtype=numpy.float32)
-					the LUT (look up table) to be used with LUT quantization. 
+                                quant_lut: numpy.array(dtype=numpy.float32)
+                                        the LUT (look up table) to be used with LUT quantization.
                                         Must be of length 2^n bits.
 
         Depthwise convolution
-        	Depthwise convolution is a special case of convolution, in which:
-        
+                Depthwise convolution is a special case of convolution, in which:
+
                   * ``kernel_channels = 1 (== input_channels / groups)``
                   * ``output_channels = channel_multiplier * input_channels``
                   * ``groups = input_channels``
                   * ``W``: ``[Kernel_height, Kernel_width, 1, channel_multiplier * input_channels]``
 
         See Also
         --------
@@ -2555,15 +2560,15 @@
         padding_left=0,
         padding_right=0,
         input_name="data",
         output_name="out",
     ):
         """
         Add a 3 dimensional convolution layer to the network.
-        Refer to the ``Convolution3DLayerParams`` message in the specification 
+        Refer to the ``Convolution3DLayerParams`` message in the specification
         (NeuralNetwork.proto) for more details.
 
         Parameters
         ----------
 
         name: str
             The name of this layer.
@@ -2583,25 +2588,25 @@
         width: int
             Width of each kernel.
 
         W: numpy.array or bytes()
             Weight of the convolution kernels. ``W`` should have shape:
 
             - If ``deconv`` is False:
-            
+
                  ``(output_channels, kernel_channels, depth, height, width)``, where:
-                 
+
                  ``kernel_channels = input_channels / groups``
-              
-            - If ``deconv`` is True: 
-            
+
+            - If ``deconv`` is True:
+
                  ``(output_channels / groups, kernel_channels, depth, height, width)``, where:
-              
+
                  ``kernel_channels = input_channels``
-              
+
         b: numpy.array
             Biases of the convolution kernels. ``b`` should have shape ``(outputChannels, )``.
 
         has_bias: boolean
             Whether bias is ignored.
             - If True, bias is not ignored.
             - If False, bias is ignored.
@@ -2623,31 +2628,31 @@
 
         output_shape: None or Tuple of int
             Applicable only for Deconvolution layer.
             ``None`` if Convolution.
             Tuple of length 3 if Convolution Transpose.
 
         padding_mode: str
-            Option for the padding type and output blob shape. 
+            Option for the padding type and output blob shape.
             Can be ``'custom'``, ``'valid'``, or ``'same'``.
             Defaults to ``'valid'``. Case-insensitive.
 
         padding_front, padding_back, padding_top, padding_bottom, padding_left, padding_right: int
             Values of depth (front, back), height (top, bottom), and width (left, right) padding to
             be used. Must all be positive integers. All default to 0.
 
         input_name: str or list of str
             The input blob name(s) of this layer.
 
         output_name: str
             The output blob name of this layer.
 
         Depthwise convolution
-        	Depthwise convolution is a special case of convolution, in which:
-        
+                Depthwise convolution is a special case of convolution, in which:
+
             * ``kernel_channels = 1`` (``== input_channels / groups``)
             * ``output_channels = channel_multiplier * input_channels``
             * ``groups = input_channels``
             * ``W``: ``[Kernel_depth, Kernel_height, Kernel_width, 1, channel_multiplier * input_channels]``
 
         See Also
         --------
@@ -2752,15 +2757,15 @@
         padding_bottom=0,
         padding_left=0,
         padding_right=0,
         same_padding_asymmetry_mode="BOTTOM_RIGHT_HEAVY",
     ):
         """
         Add a pooling layer to the model that performs spatial pooling.
-        Refer to the ``PoolingLayerParams`` message in the specification 
+        Refer to the ``PoolingLayerParams`` message in the specification
         (NeuralNetwork.proto) for more details.
 
         Parameters
         ----------
 
         name: str
             The name of this layer.
@@ -2777,40 +2782,40 @@
         stride_width: int
             Stride along the width direction.
 
         layer_type: str
             Type of pooling performed. Can either be ``'MAX'``, ``'AVERAGE'``, or ``'L2'``.
 
         padding_type: str
-            Option for the type of padding and output blob shape. Can be either 
+            Option for the type of padding and output blob shape. Can be either
             ``'VALID'``, ``'SAME'``, or ``'INCLUDE_LAST_PIXEL'``.
 
         input_name: str
             The input blob name of this layer.
 
         output_name: str
             The output blob name of this layer.
 
         exclude_pad_area: boolean
             Whether to exclude padded area in the ``'AVERAGE'`` pooling operation,
             default: true. This flag is only used with average pooling.
-            
+
             - If True, the value of the padded area will be excluded.
             - If False, the padded area will be included.
 
         is_global: boolean
             Whether the pooling operation is global. Defaults to False.
-            
-            - If True, the pooling operation is global. The pooling region 
+
+            - If True, the pooling operation is global. The pooling region
               is of the same size of the input blob.
               Parameters ``height``, ``width``, ``stride_height``, and ``stride_width`` will be ignored.
             - If False, the pooling operation is not global.
 
         padding_top, padding_bottom, padding_left, padding_right: int
-            Values of height (top, bottom) and width (left, right) padding 
+            Values of height (top, bottom) and width (left, right) padding
             to be used if padding type is ``"VALID"`` or ``"INCLUDE_LAST_PIXEL"``.
 
         same_padding_asymmetry_mode: str.
             Type of asymmetric padding to be used when ``padding_type = 'SAME'``.
             Can be either ``'BOTTOM_RIGHT_HEAVY'`` or ``'TOP_LEFT_HEAVY'``.
 
         See Also
@@ -2894,15 +2899,15 @@
         custom_padding_bottom=0,
         custom_padding_left=0,
         custom_padding_right=0,
         average_pooling_count_excludes_padding=False,
     ):
         """
         Add a pooling layer to the model that performs spatial pooling across three dimensions.
-        Refer to the ``Pooling3DLayerParams`` message in the specification 
+        Refer to the ``Pooling3DLayerParams`` message in the specification
         (NeuralNetwork.proto) for more details.
 
         Parameters
         ----------
         name: str
             The name of this layer.
         input_name: str
@@ -2988,16 +2993,16 @@
         return spec_layer
 
     def add_global_pooling3d(self, name, input_name, output_name, pooling_type):
         """
         Add a layer to pool three spatial dimensions down to one value.
         This behaves like a special case of Pooling3DLayerParams in which
         the Kernel is the size of the input and there is no padding.
-        
-        Refer to the ``GlobalPooling3DLayerParams`` message in the specification 
+
+        Refer to the ``GlobalPooling3DLayerParams`` message in the specification
         (NeuralNetwork.proto) for more details.
 
         Parameters
         ----------
         name: str
             The name of this layer.
         input_name: str
@@ -3038,16 +3043,16 @@
         output_name="out",
         padding_type="constant",
     ):
         """
 
 
         Add a padding layer to the model that performs padding along spatial dimensions.
-        
-        Refer to the ``PaddingLayerParams`` message in the specification 
+
+        Refer to the ``PaddingLayerParams`` message in the specification
         (NeuralNetwork.proto) for more details.
 
         Parameters
         ----------
         name: str
             The name of this layer.
         left: int
@@ -3105,15 +3110,15 @@
         The cropping layer have two functional modes:
 
             - When it has 1 input blob, it crops the input blob based
               on the 4 parameters ``[left, right, top, bottom]``.
             - When it has 2 input blobs, it crops the first input blob based
               on the dimension of the second blob with an offset.
 
-        Refer to the ``CropLayerParams`` message in the specification 
+        Refer to the ``CropLayerParams`` message in the specification
         (NeuralNetwork.proto) for more details.
 
         Parameters
         ----------
         name: str
             The name of this layer.
         left: int
@@ -3167,29 +3172,29 @@
         input_names,
         output_names,
         output_all=False,
         reverse_input=False,
     ):
         """
         Add a simple recurrent layer to the model.
-        Refer to the ``SimpleRecurrentLayerParams`` message in the specification 
+        Refer to the ``SimpleRecurrentLayerParams`` message in the specification
         (NeuralNetwork.proto) for more details.
 
         Parameters
         ----------
         name: str
             The name of this layer.
         W_h: numpy.array
-            Weights of the recurrent layer's hidden state. 
+            Weights of the recurrent layer's hidden state.
             Must be of shape ``(hidden_size, hidden_size)``.
         W_x: numpy.array
-            Weights of the recurrent layer's input. 
+            Weights of the recurrent layer's input.
             Must be of shape ``(hidden_size, input_size)``.
         b: numpy.array or None
-            Bias of the recurrent layer's output. If ``None``, bias is ignored. 
+            Bias of the recurrent layer's output. If ``None``, bias is ignored.
             Otherwise it must be of shape ``(hidden_size, )``.
         hidden_size: int
             Number of hidden units. This is equal to the number of channels of output shape.
         input_size: int
             Number of the number of channels of input shape.
         activation: str
             Activation function name. Can be one of the following option:
@@ -3250,47 +3255,47 @@
         activation="TANH",
         inner_activation="SIGMOID_HARD",
         output_all=False,
         reverse_input=False,
     ):
         """
         Add a Gated-Recurrent Unit (GRU) layer to the model.
-        Refer to the ``GRULayerParams`` message in the specification 
+        Refer to the ``GRULayerParams`` message in the specification
         (NeuralNetwork.proto) for more details.
 
         Parameters
         ----------
         name: str
             The name of this layer.
         W_h: [numpy.array]
             List of recursion weight matrices. The ordering is ``[R_z, R_r, R_o]``,
-            where ``R_z``, ``R_r`` and ``R_o`` are weight matrices at update gate, 
+            where ``R_z``, ``R_r`` and ``R_o`` are weight matrices at update gate,
             reset gate and output gate.
             The shapes of these matrices are ``(hidden_size, hidden_size)``.
         W_x: [numpy.array]
             List of input weight matrices. The ordering is ``[W_z, W_r, W_o]``,
-            where ``W_z``, ``W_r``, and ``W_o`` are weight matrices at update gate, 
+            where ``W_z``, ``W_r``, and ``W_o`` are weight matrices at update gate,
             reset gate and output gate.
             The shapes of these matrices are ``(hidden_size, input_size)``.
         b: [numpy.array] or None
             List of biases of the GRU layer. The ordering is ``[b_z, b_r, b_o]``,
-            where ``b_z``, ``b_r``, and ``b_o`` are biases at update gate, 
+            where ``b_z``, ``b_r``, and ``b_o`` are biases at update gate,
             reset gate and output gate.
             If ``None``, biases are ignored. Otherwise the shapes of the biases are ``(hidden_size, )``.
         hidden_size: int
             Number of hidden units. This is equal to the number of channels of output shape.
         input_size: int
             Number of the number of channels of input shape.
         activation: str
             Activation function used at the output gate. Can be one of the following options:
             [``'RELU'``, ``'TANH'``, ``'SIGMOID'``, ``'SCALED_TANH'``, ``'SIGMOID_HARD'``, ``'LINEAR'``].
             Defaults to ``'TANH'``.
             See add_activation for more detailed description.
         inner_activation: str
-            Inner activation function used at update and reset gates. 
+            Inner activation function used at update and reset gates.
             Can be one of the following options:
             [``'RELU'``, ``'TANH'``, ``'SIGMOID'``, ``'SCALED_TANH'``, ``'SIGMOID_HARD'``, ``'LINEAR'``].
             Defaults to ``'SIGMOID_HARD'``.
             See add_activation for more detailed description.
         input_names: list of str
             The input blob names list of this layer, in the order of ``[x, h_input]``.
         output_names: list of str
@@ -3364,15 +3369,15 @@
         forget_bias=False,
         coupled_input_forget_gate=False,
         cell_clip_threshold=50000.0,
         reverse_input=False,
     ):
         """
         Add a Uni-directional LSTM layer to the model.
-        Refer to the ``UniDirectionalLSTMLayerParams`` message in the specification 
+        Refer to the ``UniDirectionalLSTMLayerParams`` message in the specification
         (NeuralNetwork.proto) for more details.
 
         Parameters
         ----------
         name: str
             The name of this layer.
         W_h: [numpy.array]
@@ -3516,83 +3521,83 @@
         Refer to the ``BiDirectionalLSTMLayerParams`` message in the specification (NeuralNetwork.proto) for more details.
 
         Parameters
         ----------
         name: str
             The name of this layer.
         W_h: [numpy.array]
-            List of recursion weight matrices for the forward layer. 
+            List of recursion weight matrices for the forward layer.
             The ordering is ``[R_i, R_f, R_o, R_z]``,
-            where ``R_i``, ``R_f``, ``R_o``, and ``R_z`` are weight matrices at 
+            where ``R_i``, ``R_f``, ``R_o``, and ``R_z`` are weight matrices at
             input gate, forget gate, output gate and cell gate.
             The shapes of these matrices are ``(hidden_size, hidden_size)``.
         W_x: [numpy.array]
-            List of input weight matrices for the forward layer. The ordering 
+            List of input weight matrices for the forward layer. The ordering
             is ``[W_i, W_f, W_o, W_z]``,
-            where ``W_i``, ``W_f``, ``W_o``, and ``W_z`` are weight matrices at 
+            where ``W_i``, ``W_f``, ``W_o``, and ``W_z`` are weight matrices at
             input gate, forget gate, output gate and cell gate.
             The shapes of these matrices are ``(hidden_size, input_size)``.
         b: [numpy.array]
-            List of biases for the forward layer. The ordering is 
+            List of biases for the forward layer. The ordering is
             ``[b_i, b_f, b_o, b_z]``,
-            where ``b_i``, ``b_f``, ``b_o``, and ``b_z`` are biases at input 
+            where ``b_i``, ``b_f``, ``b_o``, and ``b_z`` are biases at input
             gate, forget gate, output gate and cell gate.
-            If ``None``, biases are ignored. Otherwise the shapes of the biases 
+            If ``None``, biases are ignored. Otherwise the shapes of the biases
             are ``(hidden_size, )``.
         W_h_back: [numpy.array]
-            List of recursion weight matrices for the backward layer. The 
+            List of recursion weight matrices for the backward layer. The
             ordering is ``[R_i, R_f, R_o, R_z]``,
-            where ``R_i``, ``R_f``, ``R_o``, and ``R_z`` are weight matrices 
+            where ``R_i``, ``R_f``, ``R_o``, and ``R_z`` are weight matrices
             at input gate, forget gate, output gate and cell gate.
             The shapes of these matrices are ``(hidden_size, hidden_size)``.
         W_x_back: [numpy.array]
-            List of input weight matrices for the backward layer. The ordering 
+            List of input weight matrices for the backward layer. The ordering
             is `[W_i, W_f, W_o, W_z]``,
-            where ``W_i``, ``W_f``, ``W_o``, and ``W_z`` are weight matrices 
+            where ``W_i``, ``W_f``, ``W_o``, and ``W_z`` are weight matrices
             at input gate, forget gate, output gate and cell gate.
             The shapes of these matrices are ``(hidden_size, input_size)``.
         b_back: [numpy.array]
             List of biases for the backward layer. The ordering is ``[b_i, b_f, b_o, b_z]``,
-            where ``b_i``, ``b_f``, ``b_o``, and ``b_z`` are biases at input 
+            where ``b_i``, ``b_f``, ``b_o``, and ``b_z`` are biases at input
             gate, forget gate, output gate and cell gate.
             The shapes of the biases ``(hidden_size)``.
         hidden_size: int
             Number of hidden units. This is equal to the number of channels of output shape.
         input_size: int
             Number of the number of channels of input shape.
         input_names: list of str
-            The input blob names of this layer, in the order of 
+            The input blob names of this layer, in the order of
             ``[x, h_input, c_input, h_reverse_input, c_reverse_input]``.
         output_names: list of str
-            The output blob names of this layer, in the order of 
+            The output blob names of this layer, in the order of
             ``[y, h_output, c_output, h_reverse_output, c_reverse_output]``.
         inner_activation: str
-            Inner activation function used at input and forget gate. Can be one 
+            Inner activation function used at input and forget gate. Can be one
             of the following options:
             [``'RELU'``, ``'TANH'``, ``'SIGMOID'``, ``'SCALED_TANH'``, ``'SIGMOID_HARD'``, ``'LINEAR'``].
             Defaults to ``'SIGMOID'``.
         cell_state_update_activation: str
-            Cell state update activation function used at the cell state update gate. 
+            Cell state update activation function used at the cell state update gate.
             Can be one of the following options:
             [``'RELU'``, ``'TANH'``, ``'SIGMOID'``, ``'SCALED_TANH'``, ``'SIGMOID_HARD'``, ``'LINEAR'``].
             Defaults to ``'TANH'``.
         output_activation: str
             Activation function used at the output gate. Can be one of the following options:
             [``'RELU'``, ``'TANH'``, ``'SIGMOID'``, ``'SCALED_TANH'``, ``'SIGMOID_HARD'``, ``'LINEAR'``].
             Defaults to ``'TANH'``.
         peep: [numpy.array] or None
-            List of peephole vectors for the forward layer. The ordering 
+            List of peephole vectors for the forward layer. The ordering
             is ``[p_i, p_f, p_o]``,
-            where ``p_i``, ``p_f``, and ``p_o`` are peephole vectors at input 
+            where ``p_i``, ``p_f``, and ``p_o`` are peephole vectors at input
             gate, forget gate, and output gate.
             The shapes of the peephole vectors are ``(hidden_size,)``. Defaults to ``None``.
         peep_back: [numpy.array] or None
-            List of peephole vectors for the backward layer. The ordering 
+            List of peephole vectors for the backward layer. The ordering
             is ``[p_i, p_f, p_o]``,
-            where ``p_i``, ``p_f``, and ``p_o`` are peephole vectors at input 
+            where ``p_i``, ``p_f``, and ``p_o`` are peephole vectors at input
             gate, forget gate, and output gate.
             The shapes of the peephole vectors are ``(hidden_size,)``. Defaults to ``None``.
         output_all: boolean
             Whether the LSTM layer should output at every time step. Defaults to ``False``.
 
             - If ``False``, the output is the result after the final state update.
             - If ``True``, the output is a sequence, containing outputs at all time steps.
@@ -3697,17 +3702,17 @@
             weight_params_back.inputGatePeepholeVector.floatValue.extend(p_i.flatten())
             weight_params_back.forgetGatePeepholeVector.floatValue.extend(p_f.flatten())
             weight_params_back.outputGatePeepholeVector.floatValue.extend(p_o.flatten())
         return spec_layer
 
     def add_flatten(self, name, mode, input_name, output_name):
         """
-        Add a flatten layer. Only flattens the channel, height and width axis. 
+        Add a flatten layer. Only flattens the channel, height and width axis.
         Leaves the sequence axis as is.
-        Refer to the ``FlattenLayerParams`` message in the 
+        Refer to the ``FlattenLayerParams`` message in the
         specification (NeuralNetwork.proto) for more details.
 
         Parameters
         ----------
         name: str
             The name of this layer.
         mode: int
@@ -3931,15 +3936,15 @@
     ):
         """
         Add a batch normalization layer. Batch normalization operation is
         defined as:
 
         ``y = gamma * (x - mean) / sqrt(variance + epsilon) + beta``
 
-        Refer to the ``BatchnormLayerParams`` message in the specification 
+        Refer to the ``BatchnormLayerParams`` message in the specification
         (NeuralNetwork.proto) for more details.
 
         Parameters
         ----------
         name: str
             The name of this layer.
         channels: int
@@ -3956,15 +3961,15 @@
             The input blob name of this layer.
         output_name: str
             The output blob name of this layer.
         compute_mean_var: bool
             Set to ``True`` if mean and variance is to be computed from the input data.
         instance_normalization: bool
             Set compute_mean_var and this to ``True`` to perform
-            instance normalization. That is, mean and variance are computed 
+            instance normalization. That is, mean and variance are computed
             from the single input instance.
         epsilon: float
             Value of epsilon. Defaults to ``1e-5`` if not specified.
 
         See Also
         --------
         add_convolution, add_pooling, add_inner_product
@@ -4589,45 +4594,45 @@
                  This represents the bounding box coordinates for ``N`` patches/RoIs.
             * ``N``: number of patches/RoIs to be extracted.
             * If RoI shape = ``[N, 1, 4, 1, 1]``, the channel axis corresponds
               to the four coordinates specifying the bounding box.
               All the N~ RoIs are extracted from all the batches of the input.
             * If RoI shape = ``[N, 1, 5, 1, 1]``, the first element of the
               channel axis specifies the input batch id from which to extract the RoI and
-              must be in the interval ``[0, Batch - 1]``. That is, ``n`` -th RoI is 
+              must be in the interval ``[0, Batch - 1]``. That is, ``n`` -th RoI is
               extracted from the ``RoI[n,0,0,0]`` -th input batch id.
               The last four elements of the channel axis specify the
               bounding box coordinates.
 
         output_name: str
             The output blob name of this layer.
 
         target_height: int
             Output height dimension.
 
         target_width: int
             Output width dimension.
 
         mode: str
-            * The following values are supported: 
-              ``'STRICT_ALIGN_ENDPOINTS_MODE'``, ``'ALIGN_ENDPOINTS_MODE'``, 
+            * The following values are supported:
+              ``'STRICT_ALIGN_ENDPOINTS_MODE'``, ``'ALIGN_ENDPOINTS_MODE'``,
               ``'UPSAMPLE_MODE'``, ``'ROI_ALIGN_MODE'``.
             * This parameter determines the sampling grid used for bilinear interpolation.
 
         normalized_roi: bool
             * If true the bounding box coordinates must be in the interval ``[0, 1]``.
-              They are scaled by ``(input_height - 1)``, ``(input_width - 1)``; 
+              They are scaled by ``(input_height - 1)``, ``(input_width - 1)``;
               that is, based on the input spatial dimensions.
             * If false the bounding box coordinates must be in the interval
-              ``[0, input_height - 1]`` and ``[0, input_width - 1]``, 
+              ``[0, input_height - 1]`` and ``[0, input_width - 1]``,
               respectively for height and width dimensions.
 
         box_indices_mode: str
-            * The following values are supported: 
-              ``'CORNERS_HEIGHT_FIRST'``, ``'CORNERS_WIDTH_FIRST'``, 
+            * The following values are supported:
+              ``'CORNERS_HEIGHT_FIRST'``, ``'CORNERS_WIDTH_FIRST'``,
               ``'CENTER_SIZE_HEIGHT_FIRST'``, ``'CENTER_SIZE_WIDTH_FIRST'``.
             * Representation used to interpret the bounding box coordinates (RoI) input.
                 * ``'CORNERS_HEIGHT_FIRST'``: ``[h_start, w_start, h_end, w_end]``
                 * ``'CORNERS_WIDTH_FIRST'``: ``[w_start, h_start, w_end, h_end]``
                 * ``'CENTER_SIZE_HEIGHT_FIRST'``: ``[h_center, w_center, box_height, box_width]``
                 * ``'CENTER_SIZE_WIDTH_FIRST'``: ``[w_center, h_center, box_width, box_height]``
 
@@ -4769,15 +4774,15 @@
         if not isinstance(image_scale, dict):
             image_scale = dict.fromkeys(image_input_names, image_scale)
 
         # Raise error if any key in image preprocessing parameters
         # are not in image_input_names.
         def check_valid_preprocessing_keys(input, target, input_name):
             for key in input:
-                if not key in target:
+                if key not in target:
                     raise ValueError("Invalid key {} in {}.".format(key, input_name))
 
         target = image_input_names
         check_valid_preprocessing_keys(is_bgr, target, "is_bgr")
         check_valid_preprocessing_keys(red_bias, target, "red_bias")
         check_valid_preprocessing_keys(blue_bias, target, "blue_bias")
         check_valid_preprocessing_keys(green_bias, target, "green_bias")
@@ -7045,52 +7050,52 @@
         weight_matrix_rows: int, optional
             Must be equal to the last dimension of the input, default: 0.
 
         weight_matrix_columns: int, optional
             Must be equal to the last dimension of the output, default: 0.
 
         W: float32 numpy.array or bytes(), optional
-            Weight matrix of shape ``(weight_matrix_rows, weight_matrix_columns)``. 
+            Weight matrix of shape ``(weight_matrix_rows, weight_matrix_columns)``.
             If ``W`` is of type ``bytes()`` (quantized to 1-8 bits), other
             quantization-related arguments must be provided as well (see below).
 
         bias: float32 numpy.array, optional
             Bias vector of shape (weight_matrix_columns,).
 
         Quantization
-        	Quantization arguments, used when ``W`` is of type ``bytes()``:
+                Quantization arguments, used when ``W`` is of type ``bytes()``:
 
-				is_quantized_weight: bool, optional
-					Set it to true when ``W`` is of type ``bytes()``, representing
-					quantized weights, default: false.
-
-				quantization_type: str, optional
-					When weights are quantized (that is, ``W`` is of type ``bytes()``),
-					this should be either ``"linear"`` or ``"lut"``, default: ``"linear"``.
-
-				nbits: int, optional
-					Should be between 1 and 8 (inclusive). Number of bits per weight value, default: 8.
-
-				quant_scale: numpy.array(dtype=numpy.float32), optional
-					Scale vector to be used with linear quantization. 
-					Must be of length either 1 or ``weight_matrix_columns``, default: ``None``.
-
-				quant_bias: numpy.array(dtype=numpy.float32), optional
-					Bias vector to be used with linear quantization. 
-					Must be of length either 1 or ``weight_matrix_columns``, default: ``None``.
-
-				quant_lut: numpy.array(dtype=numpy.float32), optional
-					The LUT (look up table) to be used with LUT quantization. 
-					Must be of length 2^n bits, default: ``None``.
-
-				int_8_dynamic_quantize: bool
-					Whether to quantize and dequantize before and after 
-					batched matmul, respectively.
-					Expects byte weights, representing int8 values, if True. 
-					See NeuralNetwork.proto for other validation conditions.
+                                is_quantized_weight: bool, optional
+                                        Set it to true when ``W`` is of type ``bytes()``, representing
+                                        quantized weights, default: false.
+
+                                quantization_type: str, optional
+                                        When weights are quantized (that is, ``W`` is of type ``bytes()``),
+                                        this should be either ``"linear"`` or ``"lut"``, default: ``"linear"``.
+
+                                nbits: int, optional
+                                        Should be between 1 and 8 (inclusive). Number of bits per weight value, default: 8.
+
+                                quant_scale: numpy.array(dtype=numpy.float32), optional
+                                        Scale vector to be used with linear quantization.
+                                        Must be of length either 1 or ``weight_matrix_columns``, default: ``None``.
+
+                                quant_bias: numpy.array(dtype=numpy.float32), optional
+                                        Bias vector to be used with linear quantization.
+                                        Must be of length either 1 or ``weight_matrix_columns``, default: ``None``.
+
+                                quant_lut: numpy.array(dtype=numpy.float32), optional
+                                        The LUT (look up table) to be used with LUT quantization.
+                                        Must be of length 2^n bits, default: ``None``.
+
+                                int_8_dynamic_quantize: bool
+                                        Whether to quantize and dequantize before and after
+                                        batched matmul, respectively.
+                                        Expects byte weights, representing int8 values, if True.
+                                        See NeuralNetwork.proto for other validation conditions.
 
         See Also
         --------
         add_inner_product
         """
 
         spec_layer = self._add_generic_layer(name, input_names, [output_name])
```

### Comparing `coremltools-6.3.0/coremltools/models/neural_network/flexible_shape_utils.py` & `coremltools-7.0b1/coremltools/models/neural_network/flexible_shape_utils.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/models/neural_network/optimization_utils.py` & `coremltools-7.0b1/coremltools/models/neural_network/optimization_utils.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/models/neural_network/printer.py` & `coremltools-7.0b1/coremltools/models/neural_network/printer.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/models/neural_network/quantization_utils.py` & `coremltools-7.0b1/coremltools/models/neural_network/quantization_utils.py`

 * *Files 2% similar despite different names*

```diff
@@ -8,28 +8,37 @@
 Only available in coremltools 2.0b1 and onwards
 """
 from os import listdir as _listdir
 from sys import stdout as _stdout
 
 import numpy as _np
 
-from coremltools import ComputeUnit as _ComputeUnit
-from coremltools.models import (_QUANTIZATION_MODE_CUSTOM_LOOKUP_TABLE,
-                                _QUANTIZATION_MODE_DEQUANTIZE,
-                                _QUANTIZATION_MODE_LINEAR_QUANTIZATION,
-                                _QUANTIZATION_MODE_LINEAR_SYMMETRIC,
-                                _QUANTIZATION_MODE_LOOKUP_TABLE_KMEANS,
-                                _QUANTIZATION_MODE_LOOKUP_TABLE_LINEAR,
-                                _SUPPORTED_QUANTIZATION_MODES)
-from coremltools.models import MLModel as _MLModel
-
-from ... import (_MINIMUM_FP16_SPEC_VERSION,
-                 _MINIMUM_QUANTIZED_MODEL_SPEC_VERSION,
-                 _SPECIFICATION_VERSION_IOS_14)
-from ..._deps import _HAS_SKLEARN as _HAS_SKLEARN
+from coremltools import (
+    ComputeUnit as _ComputeUnit,
+    _logger
+)
+from coremltools._deps import (
+    _HAS_KMEANS1D,
+    _kmeans1d
+)
+from coremltools.models import (
+    _QUANTIZATION_MODE_CUSTOM_LOOKUP_TABLE,
+    _QUANTIZATION_MODE_DEQUANTIZE,
+    _QUANTIZATION_MODE_LINEAR_QUANTIZATION,
+    _QUANTIZATION_MODE_LINEAR_SYMMETRIC,
+    _QUANTIZATION_MODE_LOOKUP_TABLE_KMEANS,
+    _QUANTIZATION_MODE_LOOKUP_TABLE_LINEAR,
+    _SUPPORTED_QUANTIZATION_MODES,
+    MLModel as _MLModel
+)
+from ... import (
+    _MINIMUM_FP16_SPEC_VERSION,
+    _MINIMUM_QUANTIZED_MODEL_SPEC_VERSION,
+    _SPECIFICATION_VERSION_IOS_14
+)
 from ..utils import _get_model, _macos_version, _wp_to_fp16wp
 from .optimization_utils import _optimize_nn
 
 
 class QuantizedLayerSelector:
     """
     This is the base class to implement custom selectors to skip certain
@@ -153,25 +162,25 @@
                 if (
                     kc < self.minimum_conv_kernel_channels
                     or counts < self.minimum_conv_weight_count
                 ):
                     return False
 
             elif weight_param == "bias":
-                return not "bias" in self.skip_layer_types
+                return "bias" not in self.skip_layer_types
             else:
                 raise ValueError(
                     "Unrecognized quantization weight field {}".format(weight_param)
                 )
 
         elif layer_type == "innerProduct" or "batchedMatmul":
             if weight_param is None or weight_param == "weights":
                 return True
             if weight_param == "bias":
-                return not "bias" in self.skip_layer_types
+                return "bias" not in self.skip_layer_types
             else:
                 raise ValueError(
                     "Unrecognized quantization weight field {}".format(weight_param)
                 )
 
         return True
 
@@ -351,50 +360,70 @@
     w = wp.reshape(1, -1)
     qw, scales, biases = _quantize_channelwise_linear(w, nbits, axis=0)
     indices = _np.array(range(0, 2 ** nbits))
     lookup_table = indices * scales[0] + biases[0]
     return lookup_table, qw
 
 
-def _get_kmeans_lookup_table_and_weight(
-    nbits, w, init="k-means++", tol=1e-2, n_init=1, rand_seed=0
-):
+def _get_kmeans_lookup_table_and_weight(nbits, w, force_kmeans1d=False):
     """
-    Generate K-Means lookup table given a weight parameter field
+    Generate K-Means lookup table given weights
 
     nbits:
         Number of bits for quantization
 
     w:
-        Weight as numpy array
+        Weights as numpy array
+
+    force_kmeans1d:
+        Use kmeans1d regardless of number of weights
 
     Returns
     -------
     lut: numpy.array
-        Lookup table, numpy array of shape (1 << nbits, );
+        Lookup table, numpy array of shape (1 << nbits, )
     wq: numpy.array
         Quantized weight of type numpy.uint8
     """
-    if _HAS_SKLEARN:
-        from sklearn.cluster import KMeans
-    else:
-        raise ModuleNotFoundError(
-            "scikit-learn is required for k-means quantization."
-            " To install, run: \"pip install -U scikit-learn\"."
-        )
-    units = _np.prod(w.shape)
+    num_weights = _np.prod(w.shape)
     lut_len = 1 << nbits
-    n_clusters = units if (units < lut_len) else lut_len
     wf = w.reshape(-1, 1)
-    kmeans = KMeans(
-        n_clusters=n_clusters, init=init, tol=tol, n_init=n_init, random_state=rand_seed
-    ).fit(wf)
-    wq = kmeans.labels_[:units]
     lut = _np.zeros(lut_len)
-    lut[:n_clusters] = kmeans.cluster_centers_.flatten()
+
+    is_better_to_use_kmeans1d = (num_weights >= 10_000 and w.dtype == _np.float16)
+
+    if (is_better_to_use_kmeans1d and _HAS_KMEANS1D) or force_kmeans1d:
+        # Cluster with kmeans1d
+        assert(_HAS_KMEANS1D)
+        values, indices, counts = _np.unique(wf, return_inverse=True, return_counts=True)
+        n_clusters = min(len(values), lut_len)
+        kmeans_results = _kmeans1d.cluster(values, n_clusters, weights=counts)
+        lut[:n_clusters] = kmeans_results.centroids
+        wq = _np.array(kmeans_results.clusters)[indices]
+    else:
+        # Cluster with scikit-learn
+        try:
+            from sklearn.cluster import KMeans
+        except:
+            raise ModuleNotFoundError(
+                "scikit-learn is required for k-means quantization."
+                " To install, run: \"pip install scikit-learn\"."
+            )
+
+        if is_better_to_use_kmeans1d:
+            _logger.warning("It would be better to use kmeans1d but that is not available."
+                         " Using scikit-learn for K-means.")
+
+        n_clusters = min(num_weights, lut_len)
+        kmeans = KMeans(
+            n_clusters, init="k-means++", tol=1e-2, n_init=1, random_state=0
+        ).fit(wf)
+        wq = kmeans.labels_[:num_weights]
+        lut[:n_clusters] = kmeans.cluster_centers_.flatten()
+
     return lut, wq
 
 
 def _quantize_channelwise_linear(weight, nbits, axis=0, symmetric=False):
     """
     Linearly quantize weight blob.
```

### Comparing `coremltools-6.3.0/coremltools/models/neural_network/spec_inspection_utils.py` & `coremltools-7.0b1/coremltools/models/neural_network/spec_inspection_utils.py`

 * *Files 0% similar despite different names*

```diff
@@ -148,15 +148,15 @@
     elif mlmodel_spec.HasField("neuralNetworkClassifier"):
         nn = mlmodel_spec.neuralNetworkClassifier
     elif mlmodel_spec.HasField("neuralNetworkRegressor"):
         nn = mlmodel_spec.neuralNetworkRegressor
 
     layers = (
         [_summarize_network_layer_info(layer) for layer in nn.layers]
-        if nn != None
+        if nn is not None
         else None
     )
     return (inputs, outputs, layers)
 
 
 def _prRed(skk, end=None):
     print("\033[91m {}\033[00m".format(skk), end=end)
```

### Comparing `coremltools-6.3.0/coremltools/models/neural_network/update_optimizer_utils.py` & `coremltools-7.0b1/coremltools/models/neural_network/update_optimizer_utils.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/models/neural_network/utils.py` & `coremltools-7.0b1/coremltools/models/neural_network/utils.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/models/pipeline.py` & `coremltools-7.0b1/coremltools/models/pipeline.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/models/tree_ensemble.py` & `coremltools-7.0b1/coremltools/models/tree_ensemble.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/models/utils.py` & `coremltools-7.0b1/coremltools/models/utils.py`

 * *Files 1% similar despite different names*

```diff
@@ -1006,26 +1006,30 @@
 
 def make_pipeline(*models):
     """
     Makes a pipeline with the given models.
 
     Parameters
     ----------
-    *models - two or more instances of ct.models.MLModel
+    *models
+        Two or more instances of ct.models.MLModel.
 
     Returns
     -------
     ct.models.MLModel
 
     Examples
     --------
-    my_model1 = ct.models.MLModel('/tmp/m1.mlpackage')
-    my_model2 = ct.models.MLModel('/tmp/m2.mlmodel')
+    .. sourcecode:: python
+
+        my_model1 = ct.models.MLModel('/tmp/m1.mlpackage')
+        my_model2 = ct.models.MLModel('/tmp/m2.mlmodel')
+        
+        my_pipeline_model = ct.utils.make_pipeline(my_model1, my_model2)
 
-    my_pipeline_model = ct.utils.make_pipeline(my_model1, my_model2)
     """
 
     def updateBlobFileName(proto_message, new_path):
         if type(proto_message) == _mil_proto.Value:
             # Value protobuf message. This is what might need to be updated.
             if proto_message.WhichOneof('value') == 'blobFileValue':
                 assert proto_message.blobFileValue.fileName == "@model_path/weights/weight.bin"
```

### Comparing `coremltools-6.3.0/coremltools/proto/ArrayFeatureExtractor_pb2.py` & `coremltools-7.0b1/coremltools/proto/ArrayFeatureExtractor_pb2.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/proto/AudioFeaturePrint_pb2.py` & `coremltools-7.0b1/coremltools/proto/AudioFeaturePrint_pb2.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/proto/BayesianProbitRegressor_pb2.py` & `coremltools-7.0b1/coremltools/proto/BayesianProbitRegressor_pb2.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/proto/CategoricalMapping_pb2.py` & `coremltools-7.0b1/coremltools/proto/CategoricalMapping_pb2.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/proto/ClassConfidenceThresholding_pb2.py` & `coremltools-7.0b1/coremltools/proto/ClassConfidenceThresholding_pb2.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/proto/CustomModel_pb2.py` & `coremltools-7.0b1/coremltools/proto/CustomModel_pb2.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/proto/DataStructures_pb2.py` & `coremltools-7.0b1/coremltools/proto/DataStructures_pb2.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/proto/DictVectorizer_pb2.py` & `coremltools-7.0b1/coremltools/proto/DictVectorizer_pb2.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/proto/FeatureTypes_pb2.py` & `coremltools-7.0b1/coremltools/proto/FeatureTypes_pb2.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/proto/FeatureVectorizer_pb2.py` & `coremltools-7.0b1/coremltools/proto/FeatureVectorizer_pb2.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/proto/GLMClassifier_pb2.py` & `coremltools-7.0b1/coremltools/proto/GLMClassifier_pb2.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/proto/GLMRegressor_pb2.py` & `coremltools-7.0b1/coremltools/proto/GLMRegressor_pb2.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/proto/Gazetteer_pb2.py` & `coremltools-7.0b1/coremltools/proto/Gazetteer_pb2.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/proto/Identity_pb2.py` & `coremltools-7.0b1/coremltools/proto/Identity_pb2.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/proto/Imputer_pb2.py` & `coremltools-7.0b1/coremltools/proto/Imputer_pb2.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/proto/ItemSimilarityRecommender_pb2.py` & `coremltools-7.0b1/coremltools/proto/ItemSimilarityRecommender_pb2.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/proto/LinkedModel_pb2.py` & `coremltools-7.0b1/coremltools/proto/LinkedModel_pb2.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/proto/MIL_pb2.py` & `coremltools-7.0b1/coremltools/proto/MIL_pb2.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/proto/Model_pb2.py` & `coremltools-7.0b1/coremltools/proto/Model_pb2.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/proto/NamedParameters_pb2.py` & `coremltools-7.0b1/coremltools/proto/NamedParameters_pb2.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/proto/NearestNeighbors_pb2.py` & `coremltools-7.0b1/coremltools/proto/NearestNeighbors_pb2.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/proto/NeuralNetwork_pb2.py` & `coremltools-7.0b1/coremltools/proto/NeuralNetwork_pb2.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/proto/NonMaximumSuppression_pb2.py` & `coremltools-7.0b1/coremltools/proto/NonMaximumSuppression_pb2.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/proto/Normalizer_pb2.py` & `coremltools-7.0b1/coremltools/proto/Normalizer_pb2.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/proto/OneHotEncoder_pb2.py` & `coremltools-7.0b1/coremltools/proto/OneHotEncoder_pb2.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/proto/Parameters_pb2.py` & `coremltools-7.0b1/coremltools/proto/Parameters_pb2.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/proto/SVM_pb2.py` & `coremltools-7.0b1/coremltools/proto/SVM_pb2.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/proto/Scaler_pb2.py` & `coremltools-7.0b1/coremltools/proto/Scaler_pb2.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/proto/SoundAnalysisPreprocessing_pb2.py` & `coremltools-7.0b1/coremltools/proto/SoundAnalysisPreprocessing_pb2.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/proto/TextClassifier_pb2.py` & `coremltools-7.0b1/coremltools/proto/TextClassifier_pb2.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/proto/TreeEnsemble_pb2.py` & `coremltools-7.0b1/coremltools/proto/TreeEnsemble_pb2.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/proto/VisionFeaturePrint_pb2.py` & `coremltools-7.0b1/coremltools/proto/VisionFeaturePrint_pb2.py`

 * *Files 2% similar despite different names*

```diff
@@ -15,15 +15,15 @@
 
 
 
 DESCRIPTOR = _descriptor.FileDescriptor(
   name='VisionFeaturePrint.proto',
   package='CoreML.Specification.CoreMLModels',
   syntax='proto3',
-  serialized_pb=_b('\n\x18VisionFeaturePrint.proto\x12!CoreML.Specification.CoreMLModels\"\xe0\x04\n\x12VisionFeaturePrint\x12L\n\x05scene\x18\x14 \x01(\x0b\x32;.CoreML.Specification.CoreMLModels.VisionFeaturePrint.SceneH\x00\x12P\n\x07objects\x18\x15 \x01(\x0b\x32=.CoreML.Specification.CoreMLModels.VisionFeaturePrint.ObjectsH\x00\x1a\xb7\x01\n\x05Scene\x12Y\n\x07version\x18\x01 \x01(\x0e\x32H.CoreML.Specification.CoreMLModels.VisionFeaturePrint.Scene.SceneVersion\"S\n\x0cSceneVersion\x12\x19\n\x15SCENE_VERSION_INVALID\x10\x00\x12\x13\n\x0fSCENE_VERSION_1\x10\x01\x12\x13\n\x0fSCENE_VERSION_2\x10\x02\x1a\xd5\x01\n\x07Objects\x12]\n\x07version\x18\x01 \x01(\x0e\x32L.CoreML.Specification.CoreMLModels.VisionFeaturePrint.Objects.ObjectsVersion\x12\x0e\n\x06output\x18\x64 \x03(\t\"[\n\x0eObjectsVersion\x12\x1b\n\x17OBJECTS_VERSION_INVALID\x10\x00\x12\x15\n\x11OBJECTS_VERSION_1\x10\x01\x12\x15\n\x11OBJECTS_VERSION_2\x10\x02\x42\x18\n\x16VisionFeaturePrintTypeB\x02H\x03\x62\x06proto3')
+  serialized_pb=_b('\n\x18VisionFeaturePrint.proto\x12!CoreML.Specification.CoreMLModels\"\xc9\x04\n\x12VisionFeaturePrint\x12L\n\x05scene\x18\x14 \x01(\x0b\x32;.CoreML.Specification.CoreMLModels.VisionFeaturePrint.SceneH\x00\x12P\n\x07objects\x18\x15 \x01(\x0b\x32=.CoreML.Specification.CoreMLModels.VisionFeaturePrint.ObjectsH\x00\x1a\xb7\x01\n\x05Scene\x12Y\n\x07version\x18\x01 \x01(\x0e\x32H.CoreML.Specification.CoreMLModels.VisionFeaturePrint.Scene.SceneVersion\"S\n\x0cSceneVersion\x12\x19\n\x15SCENE_VERSION_INVALID\x10\x00\x12\x13\n\x0fSCENE_VERSION_1\x10\x01\x12\x13\n\x0fSCENE_VERSION_2\x10\x02\x1a\xbe\x01\n\x07Objects\x12]\n\x07version\x18\x01 \x01(\x0e\x32L.CoreML.Specification.CoreMLModels.VisionFeaturePrint.Objects.ObjectsVersion\x12\x0e\n\x06output\x18\x64 \x03(\t\"D\n\x0eObjectsVersion\x12\x1b\n\x17OBJECTS_VERSION_INVALID\x10\x00\x12\x15\n\x11OBJECTS_VERSION_1\x10\x01\x42\x18\n\x16VisionFeaturePrintTypeB\x02H\x03\x62\x06proto3')
 )
 
 
 
 _VISIONFEATUREPRINT_SCENE_SCENEVERSION = _descriptor.EnumDescriptor(
   name='SceneVersion',
   full_name='CoreML.Specification.CoreMLModels.VisionFeaturePrint.Scene.SceneVersion',
@@ -60,23 +60,19 @@
       name='OBJECTS_VERSION_INVALID', index=0, number=0,
       options=None,
       type=None),
     _descriptor.EnumValueDescriptor(
       name='OBJECTS_VERSION_1', index=1, number=1,
       options=None,
       type=None),
-    _descriptor.EnumValueDescriptor(
-      name='OBJECTS_VERSION_2', index=2, number=2,
-      options=None,
-      type=None),
   ],
   containing_type=None,
   options=None,
   serialized_start=555,
-  serialized_end=646,
+  serialized_end=623,
 )
 _sym_db.RegisterEnumDescriptor(_VISIONFEATUREPRINT_OBJECTS_OBJECTSVERSION)
 
 
 _VISIONFEATUREPRINT_SCENE = _descriptor.Descriptor(
   name='Scene',
   full_name='CoreML.Specification.CoreMLModels.VisionFeaturePrint.Scene',
@@ -139,15 +135,15 @@
   options=None,
   is_extendable=False,
   syntax='proto3',
   extension_ranges=[],
   oneofs=[
   ],
   serialized_start=433,
-  serialized_end=646,
+  serialized_end=623,
 )
 
 _VISIONFEATUREPRINT = _descriptor.Descriptor(
   name='VisionFeaturePrint',
   full_name='CoreML.Specification.CoreMLModels.VisionFeaturePrint',
   filename=None,
   file=DESCRIPTOR,
@@ -179,15 +175,15 @@
   extension_ranges=[],
   oneofs=[
     _descriptor.OneofDescriptor(
       name='VisionFeaturePrintType', full_name='CoreML.Specification.CoreMLModels.VisionFeaturePrint.VisionFeaturePrintType',
       index=0, containing_type=None, fields=[]),
   ],
   serialized_start=64,
-  serialized_end=672,
+  serialized_end=649,
 )
 
 _VISIONFEATUREPRINT_SCENE.fields_by_name['version'].enum_type = _VISIONFEATUREPRINT_SCENE_SCENEVERSION
 _VISIONFEATUREPRINT_SCENE.containing_type = _VISIONFEATUREPRINT
 _VISIONFEATUREPRINT_SCENE_SCENEVERSION.containing_type = _VISIONFEATUREPRINT_SCENE
 _VISIONFEATUREPRINT_OBJECTS.fields_by_name['version'].enum_type = _VISIONFEATUREPRINT_OBJECTS_OBJECTSVERSION
 _VISIONFEATUREPRINT_OBJECTS.containing_type = _VISIONFEATUREPRINT
```

### Comparing `coremltools-6.3.0/coremltools/proto/WordEmbedding_pb2.py` & `coremltools-7.0b1/coremltools/proto/WordEmbedding_pb2.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/proto/WordTagger_pb2.py` & `coremltools-7.0b1/coremltools/proto/WordTagger_pb2.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/test/api/test_api_examples.py` & `coremltools-7.0b1/coremltools/test/api/test_api_examples.py`

 * *Files 1% similar despite different names*

```diff
@@ -386,15 +386,15 @@
         )
 
     def test_empty_pipeline(self):
         model = self._get_test_model()
         example_input = torch.rand(1, 1, 28, 28)
         traced_model = torch.jit.trace(model, example_input)
 
-        pipeline = ct.PassPipeline.get_empty_pipeline()
+        pipeline = ct.PassPipeline.EMPTY
 
         model_converted = ct.convert(
             traced_model,
             inputs=[ct.TensorType(shape=example_input.shape)],
             convert_to="mlprogram",
             pass_pipeline=pipeline,
         )
@@ -462,15 +462,15 @@
         ).count("const") == get_op_types_in_program(
             model_converted_without_pipeline._get_mil_internal(), skip_const_ops=False
         ).count(
             "const"
         )
 
         pipeline.set_options(
-            "common::const_elimination", {"skip_const_by_size": "-1"}, override=True
+            "common::const_elimination", {"skip_const_by_size": "-1"}
         )
         model_converted = ct.convert(
             traced_model,
             inputs=[ct.TensorType(shape=example_input.shape)],
             convert_to="mlprogram",
             pass_pipeline=pipeline,
         )
```

### Comparing `coremltools-6.3.0/coremltools/test/api/test_api_visibilities.py` & `coremltools-7.0b1/coremltools/test/api/test_api_visibilities.py`

 * *Files 6% similar despite different names*

```diff
@@ -39,14 +39,15 @@
     "target",
     "utils",
     "version",
     "test",
     "transform",
     "libmodelpackage",
     "libmilstoragepython",
+    "optimize",
 ]
 
 
 class TestApiVisibilities:
     """Test public coremltools API visibilities."""
 
     def test_top_level(self):
@@ -156,14 +157,35 @@
             "libsvm",
             "mil",
             "sklearn",
             "xgboost",
         ]
         _check_visible_modules(_get_visible_items(ct.converters), expected)
 
+    def test_optimize(self):
+        expected = [
+            "coreml",
+            "torch",
+        ]
+        _check_visible_modules(_get_visible_items(ct.optimize), expected)
+
+    def test_optimize_coreml(self):
+        expected = [
+            "OpLinearQuantizerConfig",
+            "OpMagnitudePrunerConfig",
+            "OpPalettizerConfig",
+            "OptimizationConfig",
+            "OpThresholdPrunerConfig",
+            "linear_quantize_weights",
+            "palettize_weights",
+            "prune_weights",
+            "decompress_weights",
+        ]
+        _check_visible_modules(_get_visible_items(ct.optimize.coreml), expected)
+
     def test_converters_libsvm(self):
         _check_visible_modules(_get_visible_items(ct.converters.libsvm), ["convert"])
 
     def test_converters_sklearn(self):
         _check_visible_modules(_get_visible_items(ct.converters.sklearn), ["convert"])
 
     def test_converters_xgboost(self):
```

### Comparing `coremltools-6.3.0/coremltools/test/blob/test_weights.py` & `coremltools-7.0b1/coremltools/test/blob/test_weights.py`

 * *Files 27% similar despite different names*

```diff
@@ -25,44 +25,64 @@
     def test_weight_blob_int8(self):
         writer = BlobWriter(self.working_dir + "/net.wt")
         input_arr = np.array([-5, -2, 0, 2, 5], dtype=np.int8)
         offset = writer.write_int8_data(input_arr)
         writer = None
 
         reader = BlobReader(self.working_dir + "/net.wt")
-        output_arr = np.array(reader.read_int8_data(offset), np.int8)
+        output_arr = reader.read_int8_data(offset)
         np.testing.assert_equal(input_arr, output_arr)
 
     def test_weight_blob_uint8(self):
         writer = BlobWriter(self.working_dir + "/net.wt")
         input_arr = np.array([1, 2, 3, 4, 5], dtype=np.uint8)
         offset = writer.write_uint8_data(input_arr)
         writer = None
 
         reader = BlobReader(self.working_dir + "/net.wt")
-        output_arr = np.array(reader.read_uint8_data(offset), np.uint8)
+        output_arr = reader.read_uint8_data(offset)
+        np.testing.assert_almost_equal(input_arr, output_arr)
+
+    def test_weight_blob_int16(self):
+        writer = BlobWriter(self.working_dir + "/net.wt")
+        input_arr = np.array([-5, -2, 0, 2, 5], dtype=np.int16)
+        offset = writer.write_int16_data(input_arr)
+        writer = None
+
+        reader = BlobReader(self.working_dir + "/net.wt")
+        output_arr = reader.read_int16_data(offset)
+        np.testing.assert_equal(input_arr, output_arr)
+
+    def test_weight_blob_uint16(self):
+        writer = BlobWriter(self.working_dir + "/net.wt")
+        input_arr = np.array([1, 2, 3, 4, 5], dtype=np.uint16)
+        offset = writer.write_uint16_data(input_arr)
+        writer = None
+
+        reader = BlobReader(self.working_dir + "/net.wt")
+        output_arr = reader.read_uint16_data(offset)
         np.testing.assert_almost_equal(input_arr, output_arr)
 
     def test_weight_blob_fp16(self):
         writer = BlobWriter(self.working_dir + "/net.wt")
         input_arr = np.array([2.3, 4.6, 7.9], dtype=np.float16)
         input_arr_to_bytes_uint16 = np.frombuffer(input_arr.tobytes(), np.uint16)
         offset = writer.write_fp16_data(input_arr_to_bytes_uint16)
         writer = None
 
         reader = BlobReader(self.working_dir + "/net.wt")
-        output_arr_uint16 = np.array(reader.read_fp16_data(offset), np.uint16)
+        output_arr_uint16 = reader.read_fp16_data(offset)
         output_arr = np.frombuffer(output_arr_uint16.tobytes(), np.float16)
         np.testing.assert_almost_equal(input_arr, output_arr)
 
     def test_weight_blob_fp32(self):
         writer = BlobWriter(self.working_dir + "/net.wt")
         input_arr = np.array([1.0, 2.4, 3.9, -4.8, 5.2], dtype=np.float32)
         offset = writer.write_float_data(input_arr)
         writer = None
 
         reader = BlobReader(self.working_dir + "/net.wt")
-        output_arr = np.array(reader.read_float_data(offset), np.float32)
+        output_arr = reader.read_float_data(offset)
         np.testing.assert_almost_equal(input_arr, output_arr)
 
 if __name__ == "__main__":
     unittest.main()
```

### Comparing `coremltools-6.3.0/coremltools/test/modelpackage/test_mlmodel.py` & `coremltools-7.0b1/coremltools/test/modelpackage/test_mlmodel.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/test/modelpackage/test_modelpackage.py` & `coremltools-7.0b1/coremltools/test/modelpackage/test_modelpackage.py`

 * *Files 6% similar despite different names*

```diff
@@ -8,28 +8,32 @@
 import tempfile
 
 import numpy as np
 import pytest
 
 import coremltools
 from coremltools import ComputeUnit, utils
+from coremltools._deps import _HAS_TORCH
 from coremltools.converters.mil import Builder as mb
 from coremltools.libmodelpackage import ModelPackage
 from coremltools.models import MLModel
-from coremltools.models.utils import (_MLPACKAGE_AUTHOR_NAME,
-                                      _WEIGHTS_DIR_NAME)
+from coremltools.models.utils import _MLPACKAGE_AUTHOR_NAME, _WEIGHTS_DIR_NAME
 from coremltools.proto import Model_pb2
 
+if _HAS_TORCH:
+    import torch
+
 
 def _remove_path(path):
     if os.path.isdir(path):
         shutil.rmtree(path)
     else:
         os.remove(path)
 
+
 class TestMLModel:
 
     def setup_class(self):
 
         spec = Model_pb2.Model()
         spec.specificationVersion = coremltools.SPECIFICATION_VERSION
 
@@ -96,23 +100,52 @@
 
         package = tempfile.TemporaryDirectory(suffix=".mlpackage")
         package.cleanup()
 
         model.save(package.name)
         loaded_model = MLModel(package.name)
 
-        assert model.author == "Test author"
-        assert model.license == "Test license"
-        assert model.short_description == "Test model"
-        assert model.input_description["feature_1"] == "This is feature 1"
-        assert model.output_description["output"] == "This is output"
+        assert loaded_model.author == "Test author"
+        assert loaded_model.license == "Test license"
+        assert loaded_model.short_description == "Test model"
+        assert loaded_model.input_description["feature_1"] == "This is feature 1"
+        assert loaded_model.output_description["output"] == "This is output"
 
         # cleanup
         _remove_path(package.name)
 
+
+    @pytest.mark.skipif(not _HAS_TORCH, reason="requires torch")
+    def test_save_from_mlpackage(self):
+        class Model(torch.nn.Module):
+            def forward(self, x):
+                return x
+
+        example_input = torch.rand(1, 3, 50, 50)
+        traced_model = torch.jit.trace(Model().eval(), example_input)
+
+        model = coremltools.convert(
+            traced_model,
+            inputs=[coremltools.TensorType(shape=example_input.shape)],
+            convert_to="mlprogram",
+        )
+
+        author = "Bobby Joe!"
+        model.author = author
+
+        save_dir = tempfile.TemporaryDirectory(suffix=".mlpackage").name
+
+        model.save(save_dir)
+        loaded_model = MLModel(save_dir)
+
+        assert loaded_model.author == author
+
+        _remove_path(save_dir)
+
+
     def test_predict_api(self):
         model = MLModel(self.spec)
 
         package = tempfile.TemporaryDirectory(suffix=".mlpackage")
         package.cleanup()
 
         model.save(package.name)
@@ -123,23 +156,41 @@
                     and utils._macos_version() < (13, 0)):
                     continue
 
                 loaded_model = MLModel(package.name, compute_units=compute_units)
 
                 preds = loaded_model.predict({"feature_1": 1.0, "feature_2": 1.0})
                 assert preds is not None
+                assert len(preds.keys()) == 1
                 assert preds["output"] == 3.1
                 assert loaded_model.compute_unit == compute_units
         else:
             # just check if we can load it
             loaded_model = MLModel(package.name)
 
         # cleanup
         _remove_path(package.name)
 
+
+    @pytest.mark.skipif(utils._macos_version() < (12, 0),
+                        reason="prediction available only on macOS12+")
+    def test_batch_predict(self):
+        model = MLModel(self.spec)
+        x = [ {"feature_1": 1.0, "feature_2": 1.0},
+              {"feature_1": 2.0, "feature_2": 2.0} ]
+
+        y = model.predict(x)
+
+        assert len(y) == 2
+        assert y[0]["output"] == 3.1
+        assert len(y[0].keys()) == 1
+        assert y[1]["output"] == 6.1
+        assert len(y[1].keys()) == 1
+
+
     def test_rename_input(self):
         utils.rename_feature(self.spec, "feature_1", "renamed_feature", rename_inputs=True)
         model = MLModel(self.spec)
 
         package = tempfile.TemporaryDirectory(suffix=".mlpackage")
         package.cleanup()
 
@@ -210,23 +261,22 @@
             if utils._macos_version() >= (12, 0):
                 preds = loaded_model.predict({"feature_1": 1.0, "feature_2": 1.0})
                 assert preds is not None
                 assert preds["output"] == 3.1
 
         _remove_path(package.name)
 
+    @pytest.mark.skipif(not _HAS_TORCH, reason="requires torch")
     def test_mil_as_package(self):
-        import torch
-
         num_tokens = 3
         embedding_size = 5
 
         class TestModule(torch.nn.Module):
             def __init__(self):
-                super(TestModule, self).__init__()
+                super().__init__()
                 self.embedding = torch.nn.Embedding(num_tokens, embedding_size)
 
             def forward(self, x):
                 return self.embedding(x)
 
         model = TestModule()
         model.eval()
@@ -288,15 +338,15 @@
         import torch
 
         num_tokens = 3
         embedding_size = 5
 
         class TestModule(torch.nn.Module):
             def __init__(self):
-                super(TestModule, self).__init__()
+                super().__init__()
                 self.embedding = torch.nn.Embedding(num_tokens, embedding_size)
 
             def forward(self, x):
                 return self.embedding(x)
 
         model = TestModule()
         model.eval()
```

### Comparing `coremltools-6.3.0/coremltools/test/neural_network/test_custom_neural_nets.py` & `coremltools-7.0b1/coremltools/test/neural_network/test_custom_neural_nets.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/test/neural_network/test_model.py` & `coremltools-7.0b1/coremltools/test/neural_network/test_model.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/test/neural_network/test_neural_networks.py` & `coremltools-7.0b1/coremltools/test/neural_network/test_neural_networks.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/test/neural_network/test_nn_builder.py` & `coremltools-7.0b1/coremltools/test/neural_network/test_nn_builder.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/test/neural_network/test_numpy_nn_layers.py` & `coremltools-7.0b1/coremltools/test/neural_network/test_numpy_nn_layers.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/test/neural_network/test_quantization.py` & `coremltools-7.0b1/coremltools/test/neural_network/test_quantization.py`

 * *Files 2% similar despite different names*

```diff
@@ -3,14 +3,15 @@
 # Use of this source code is governed by a BSD-3-clause license that can be
 # found in the LICENSE.txt file or at https://opensource.org/licenses/BSD-3-Clause
 
 """
 Module containing unit tests for verifying various quantizations.
 """
 
+import itertools
 import unittest
 
 import numpy as np
 import pytest
 
 import coremltools
 import coremltools.models.datatypes as datatypes
@@ -556,7 +557,68 @@
         assert len(spec_uint5.neuralNetwork.layers[0].embeddingND.weights.rawValue) == 3750  # 3750 = 5*6000/8
 
     @unittest.skipIf(coremltools.utils._macos_version() < (13, 0),
                      'ComputeUnit.CPU_AND_NE is only available on macOS >= 13.0'
     )
     def test_embeddingND_quantize_CPU_and_NE(self):
         self.test_embeddingND_quantize(ComputeUnit.CPU_AND_NE)
+
+
+class TestKMeansLookup:
+    @pytest.mark.parametrize("weightShape, dtype",
+                             itertools.product(
+                                 [(20, 20), (120, 120)],
+                                 [np.float16, np.float32]
+                             ))
+    def test_kmeans_lookup(self, weightShape, dtype):
+        nbits = 4
+        w = np.random.rand(*weightShape).astype(dtype)
+
+        lookup_table, quantized_weights = quantization_utils._get_kmeans_lookup_table_and_weight(nbits, w)
+
+        assert(len(lookup_table) == 2 ** nbits)
+        assert(quantized_weights.shape == (np.prod(weightShape),))
+        assert(len(np.unique(quantized_weights)) <= len(lookup_table))
+
+        quantized_weight_values = lookup_table[quantized_weights]
+        max_deltas = np.abs(w.flatten() - quantized_weight_values.flatten()).max()
+        assert max_deltas < 0.1
+
+    def test_kmeans1d_exact_value(self):
+        w = np.array(
+            [
+                [12.0, 11.0, 12.0, 33.0, 32.0, 99.0, 0.0, 34.0, 40.0],
+                [41.0, 34.0, 98.0, 75.1, 89.0, 99.0, 0.0, 10.0, 41.0],
+            ]
+        )
+
+        lookup_table, quantized_weights = quantization_utils._get_kmeans_lookup_table_and_weight(
+            4, w, force_kmeans1d=True
+        )
+
+        assert all(
+            lookup_table
+            == np.array(
+                [
+                    0.0,
+                    10.0,
+                    11.0,
+                    12.0,
+                    32.0,
+                    33.0,
+                    34.0,
+                    40.0,
+                    41.0,
+                    75.1,
+                    89.0,
+                    98.0,
+                    99.0,
+                    0.0,
+                    0.0,
+                    0.0,
+                ]
+            )
+        )
+        assert all(
+            quantized_weights
+            == np.array([3, 2, 3, 5, 4, 12, 0, 6, 7, 8, 6, 11, 9, 10, 12, 0, 1, 8])
+        )
```

### Comparing `coremltools-6.3.0/coremltools/test/neural_network/test_simple_nn_inference.py` & `coremltools-7.0b1/coremltools/test/neural_network/test_simple_nn_inference.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/test/neural_network/test_tf_numeric.py` & `coremltools-7.0b1/coremltools/test/neural_network/test_tf_numeric.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/test/pipeline/test_model_updatable.py` & `coremltools-7.0b1/coremltools/test/pipeline/test_model_updatable.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/test/pipeline/test_pipeline.py` & `coremltools-7.0b1/coremltools/test/pipeline/test_pipeline.py`

 * *Files 3% similar despite different names*

```diff
@@ -11,14 +11,15 @@
 import pytest
 
 import coremltools as ct
 from coremltools._deps import _HAS_LIBSVM, _HAS_SKLEARN
 from coremltools.converters.mil.mil import Builder as mb
 from coremltools.converters.mil.mil import Function, Program
 from coremltools.models.pipeline import PipelineClassifier, PipelineRegressor
+from coremltools.models.utils import _is_macos
 
 if _HAS_SKLEARN:
     from sklearn.datasets import load_boston
     from sklearn.linear_model import LinearRegression
     from sklearn.pipeline import Pipeline
     from sklearn.preprocessing import OneHotEncoder
 
@@ -179,17 +180,25 @@
         self.scikit_data = scikit_data
         self.scikit_model = scikit_model
 
     def test_pipeline_regression_creation(self):
         input_names = self.scikit_data.feature_names
         output_name = "target"
 
-        p_regressor = converter.convert(
-            self.scikit_model, input_names, "target"
-        ).get_spec()
+        p_regressor_model = converter.convert(self.scikit_model, input_names, "target")
+
+        x = dict(zip(self.scikit_data["feature_names"], self.scikit_data["data"][0]))
+        y = p_regressor_model.predict(x)
+        self.assertIsNotNone(y)
+
+        with tempfile.TemporaryDirectory() as save_dir:
+            p_regressor_model.save(save_dir + "/test.mlmodel")
+
+        p_regressor = p_regressor_model.get_spec()
+
         self.assertIsNotNone(p_regressor)
         self.assertEqual(len(p_regressor.pipelineRegressor.pipeline.models), 2)
 
         # Test the model class of the linear regressor model
         spec = p_regressor.pipelineRegressor.pipeline.models[-1]
         self.assertIsNotNone(spec.description)
 
@@ -248,30 +257,34 @@
     def test_simple(model1_backend, model2_backend):
         # Create models
         m1 = TestMakePipeline._make_model("x", 20, "y1", 10, model1_backend)
         m2 = TestMakePipeline._make_model("y1", 10, "y2", 2, model2_backend)
 
         # Get non-pipeline result
         x = np.random.rand(20)
-        y1 = m1.predict({"x": x})["y1"]
-        y2 = m2.predict({"y1": y1})
+        if _is_macos():
+            y1 = m1.predict({"x": x})["y1"]
+            y2 = m2.predict({"y1": y1})
 
         pipeline_model = ct.utils.make_pipeline(m1, m2)
 
-        y_pipeline = pipeline_model.predict({"x": x})
-        np.testing.assert_allclose(y2["y2"], y_pipeline["y2"])
+        if _is_macos():
+            y_pipeline = pipeline_model.predict({"x": x})
+            np.testing.assert_allclose(y2["y2"], y_pipeline["y2"])
 
         # Check save/load
         with tempfile.TemporaryDirectory() as save_dir:
             # Save pipeline
             save_path = save_dir + "/test.mlpackage"
             pipeline_model.save(save_path)
 
             # Check loading from a mlpackage path
             p2 = ct.models.MLModel(save_path)
-            y_pipeline = p2.predict({"x": x})
-            np.testing.assert_allclose(y2["y2"], y_pipeline["y2"])
+            if _is_macos():
+                y_pipeline = p2.predict({"x": x})
+                np.testing.assert_allclose(y2["y2"], y_pipeline["y2"])
 
             # Check loading from spec and weight dir
             p3 = ct.models.MLModel(p2.get_spec(), weights_dir=p2.weights_dir)
-            y_pipeline = p3.predict({"x": x})
-            np.testing.assert_allclose(y2["y2"], y_pipeline["y2"])
+            if _is_macos():
+                y_pipeline = p3.predict({"x": x})
+                np.testing.assert_allclose(y2["y2"], y_pipeline["y2"])
```

### Comparing `coremltools-6.3.0/coremltools/test/sklearn_tests/test_NuSVC.py` & `coremltools-7.0b1/coremltools/test/sklearn_tests/test_NuSVC.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/test/sklearn_tests/test_NuSVR.py` & `coremltools-7.0b1/coremltools/test/sklearn_tests/test_NuSVR.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/test/sklearn_tests/test_SVC.py` & `coremltools-7.0b1/coremltools/test/sklearn_tests/test_SVC.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/test/sklearn_tests/test_SVR.py` & `coremltools-7.0b1/coremltools/test/sklearn_tests/test_SVR.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/test/sklearn_tests/test_categorical_imputer.py` & `coremltools-7.0b1/coremltools/test/sklearn_tests/test_categorical_imputer.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/test/sklearn_tests/test_composite_pipelines.py` & `coremltools-7.0b1/coremltools/test/sklearn_tests/test_composite_pipelines.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/test/sklearn_tests/test_dict_vectorizer.py` & `coremltools-7.0b1/coremltools/test/sklearn_tests/test_dict_vectorizer.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/test/sklearn_tests/test_feature_names.py` & `coremltools-7.0b1/coremltools/test/sklearn_tests/test_feature_names.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/test/sklearn_tests/test_glm_classifier.py` & `coremltools-7.0b1/coremltools/test/sklearn_tests/test_glm_classifier.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/test/sklearn_tests/test_imputer.py` & `coremltools-7.0b1/coremltools/test/sklearn_tests/test_imputer.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/test/sklearn_tests/test_io_types.py` & `coremltools-7.0b1/coremltools/test/sklearn_tests/test_io_types.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/test/sklearn_tests/test_k_neighbors_classifier.py` & `coremltools-7.0b1/coremltools/test/sklearn_tests/test_k_neighbors_classifier.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/test/sklearn_tests/test_linear_regression.py` & `coremltools-7.0b1/coremltools/test/sklearn_tests/test_linear_regression.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/test/sklearn_tests/test_nearest_neighbors_builder.py` & `coremltools-7.0b1/coremltools/test/sklearn_tests/test_nearest_neighbors_builder.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/test/sklearn_tests/test_normalizer.py` & `coremltools-7.0b1/coremltools/test/sklearn_tests/test_normalizer.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/test/sklearn_tests/test_one_hot_encoder.py` & `coremltools-7.0b1/coremltools/test/sklearn_tests/test_one_hot_encoder.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/test/sklearn_tests/test_random_forest_classifier.py` & `coremltools-7.0b1/coremltools/test/sklearn_tests/test_random_forest_classifier.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/test/sklearn_tests/test_random_forest_classifier_numeric.py` & `coremltools-7.0b1/coremltools/test/sklearn_tests/test_random_forest_classifier_numeric.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/test/sklearn_tests/test_random_forest_regression.py` & `coremltools-7.0b1/coremltools/test/sklearn_tests/test_random_forest_regression.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/test/sklearn_tests/test_random_forest_regression_numeric.py` & `coremltools-7.0b1/coremltools/test/sklearn_tests/test_random_forest_regression_numeric.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/test/sklearn_tests/test_ridge_regression.py` & `coremltools-7.0b1/coremltools/test/sklearn_tests/test_ridge_regression.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/test/sklearn_tests/test_standard_scalar.py` & `coremltools-7.0b1/coremltools/test/sklearn_tests/test_standard_scalar.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/test/sklearn_tests/test_utils.py` & `coremltools-7.0b1/coremltools/test/sklearn_tests/test_utils.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/test/xgboost_tests/test_boosted_trees_classifier.py` & `coremltools-7.0b1/coremltools/test/xgboost_tests/test_boosted_trees_classifier.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/test/xgboost_tests/test_boosted_trees_classifier_numeric.py` & `coremltools-7.0b1/coremltools/test/xgboost_tests/test_boosted_trees_classifier_numeric.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/test/xgboost_tests/test_boosted_trees_regression.py` & `coremltools-7.0b1/coremltools/test/xgboost_tests/test_boosted_trees_regression.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/test/xgboost_tests/test_boosted_trees_regression_numeric.py` & `coremltools-7.0b1/coremltools/test/xgboost_tests/test_boosted_trees_regression_numeric.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/test/xgboost_tests/test_decision_tree_classifier.py` & `coremltools-7.0b1/coremltools/test/xgboost_tests/test_decision_tree_classifier.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/test/xgboost_tests/test_decision_tree_classifier_numeric.py` & `coremltools-7.0b1/coremltools/test/xgboost_tests/test_decision_tree_classifier_numeric.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/test/xgboost_tests/test_decision_tree_regression.py` & `coremltools-7.0b1/coremltools/test/xgboost_tests/test_decision_tree_regression.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools/test/xgboost_tests/test_decision_tree_regression_numeric.py` & `coremltools-7.0b1/coremltools/test/xgboost_tests/test_decision_tree_regression_numeric.py`

 * *Files identical despite different names*

### Comparing `coremltools-6.3.0/coremltools.egg-info/PKG-INFO` & `coremltools-7.0b1/coremltools.egg-info/PKG-INFO`

 * *Files 3% similar despite different names*

```diff
@@ -1,26 +1,28 @@
 Metadata-Version: 2.1
 Name: coremltools
-Version: 6.3.0
+Version: 7.0b1
 Summary: Community Tools for Core ML
 Home-page: https://github.com/apple/coremltools
 Author: Apple Inc.
 Author-email: coremltools@apple.com
 License: BSD
 Classifier: Development Status :: 5 - Production/Stable
 Classifier: Intended Audience :: Developers
 Classifier: Operating System :: MacOS :: MacOS X
 Classifier: Operating System :: POSIX :: Linux
 Classifier: Programming Language :: Python :: 3.7
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
 Classifier: Programming Language :: Python :: 3.10
+Classifier: Programming Language :: Python :: 3.11
 Classifier: Topic :: Scientific/Engineering
 Classifier: Topic :: Software Development
 License-File: LICENSE.txt
+License-File: NOTICE.txt
 
 coremltools
 ===========
 
 `Core ML <http://developer.apple.com/documentation/coreml>`_
 is an Apple framework that allows developers to easily integrate
 machine learning (ML) models into apps. Core ML is available on iOS, iPadOS,
```

### Comparing `coremltools-6.3.0/coremltools.egg-info/SOURCES.txt` & `coremltools-7.0b1/coremltools.egg-info/SOURCES.txt`

 * *Files 24% similar despite different names*

```diff
@@ -1,9 +1,10 @@
 LICENSE.txt
 MANIFEST.in
+NOTICE.txt
 README.md
 setup.py
 coremltools/__init__.py
 coremltools/version.py
 coremltools.egg-info/PKG-INFO
 coremltools.egg-info/SOURCES.txt
 coremltools.egg-info/dependency_links.txt
@@ -125,27 +126,29 @@
 coremltools/converters/mil/frontend/tensorflow2/tf_graph_pass/rewrite_control_flow_functions.py
 coremltools/converters/mil/frontend/torch/__init__.py
 coremltools/converters/mil/frontend/torch/converter.py
 coremltools/converters/mil/frontend/torch/dialect_ops.py
 coremltools/converters/mil/frontend/torch/internal_graph.py
 coremltools/converters/mil/frontend/torch/load.py
 coremltools/converters/mil/frontend/torch/ops.py
+coremltools/converters/mil/frontend/torch/quantization_ops.py
 coremltools/converters/mil/frontend/torch/torch_op_registry.py
 coremltools/converters/mil/frontend/torch/torchir_passes.py
 coremltools/converters/mil/frontend/torch/ssa_passes/__init__.py
 coremltools/converters/mil/frontend/torch/ssa_passes/torch_tensor_assign_to_core.py
 coremltools/converters/mil/frontend/torch/ssa_passes/torch_upsample_to_core_upsample.py
 coremltools/converters/mil/frontend/torch/test/__init__.py
 coremltools/converters/mil/frontend/torch/test/test_api.py
 coremltools/converters/mil/frontend/torch/test/test_custom_ops.py
 coremltools/converters/mil/frontend/torch/test/test_examples.py
 coremltools/converters/mil/frontend/torch/test/test_internal_graph.py
 coremltools/converters/mil/frontend/torch/test/test_passes.py
 coremltools/converters/mil/frontend/torch/test/test_torch_conversion_api.py
 coremltools/converters/mil/frontend/torch/test/test_torch_ops.py
+coremltools/converters/mil/frontend/torch/test/test_torch_quantization_ops.py
 coremltools/converters/mil/frontend/torch/test/testing_utils.py
 coremltools/converters/mil/mil/__init__.py
 coremltools/converters/mil/mil/block.py
 coremltools/converters/mil/mil/builder.py
 coremltools/converters/mil/mil/input_type.py
 coremltools/converters/mil/mil/operation.py
 coremltools/converters/mil/mil/program.py
@@ -176,26 +179,36 @@
 coremltools/converters/mil/mil/ops/defs/iOS15/tensor_transformation.py
 coremltools/converters/mil/mil/ops/defs/iOS16/__init__.py
 coremltools/converters/mil/mil/ops/defs/iOS16/constexpr_ops.py
 coremltools/converters/mil/mil/ops/defs/iOS16/image_resizing.py
 coremltools/converters/mil/mil/ops/defs/iOS16/scatter_gather.py
 coremltools/converters/mil/mil/ops/defs/iOS16/tensor_operation.py
 coremltools/converters/mil/mil/ops/defs/iOS16/tensor_transformation.py
+coremltools/converters/mil/mil/ops/defs/iOS17/__init__.py
+coremltools/converters/mil/mil/ops/defs/iOS17/activation.py
+coremltools/converters/mil/mil/ops/defs/iOS17/elementwise_unary.py
+coremltools/converters/mil/mil/ops/defs/iOS17/image_resizing.py
+coremltools/converters/mil/mil/ops/defs/iOS17/quantization_ops.py
+coremltools/converters/mil/mil/ops/defs/iOS17/reduction.py
+coremltools/converters/mil/mil/ops/defs/iOS17/scatter_gather.py
+coremltools/converters/mil/mil/ops/defs/iOS17/tensor_operation.py
+coremltools/converters/mil/mil/ops/defs/iOS17/tensor_transformation.py
 coremltools/converters/mil/mil/ops/tests/__init__.py
 coremltools/converters/mil/mil/ops/tests/test_activation.py
 coremltools/converters/mil/mil/ops/tests/test_const.py
 coremltools/converters/mil/mil/ops/tests/test_constexpr_ops.py
 coremltools/converters/mil/mil/ops/tests/test_control_flow.py
 coremltools/converters/mil/mil/ops/tests/test_conv.py
 coremltools/converters/mil/mil/ops/tests/test_elementwise_binary.py
 coremltools/converters/mil/mil/ops/tests/test_elementwise_unary.py
 coremltools/converters/mil/mil/ops/tests/test_image_resizing.py
 coremltools/converters/mil/mil/ops/tests/test_linear.py
 coremltools/converters/mil/mil/ops/tests/test_normalization.py
 coremltools/converters/mil/mil/ops/tests/test_pool.py
+coremltools/converters/mil/mil/ops/tests/test_quantization.py
 coremltools/converters/mil/mil/ops/tests/test_random.py
 coremltools/converters/mil/mil/ops/tests/test_recurrent.py
 coremltools/converters/mil/mil/ops/tests/test_reduction.py
 coremltools/converters/mil/mil/ops/tests/test_scatter_gather.py
 coremltools/converters/mil/mil/ops/tests/test_slice.py
 coremltools/converters/mil/mil/ops/tests/test_tensor_operation.py
 coremltools/converters/mil/mil/ops/tests/test_tensor_transformation.py
@@ -209,32 +222,35 @@
 coremltools/converters/mil/mil/passes/defs/__init__.py
 coremltools/converters/mil/mil/passes/defs/lower_complex_dialect_ops.py
 coremltools/converters/mil/mil/passes/defs/optimize_activation.py
 coremltools/converters/mil/mil/passes/defs/optimize_conv.py
 coremltools/converters/mil/mil/passes/defs/optimize_elementwise_binary.py
 coremltools/converters/mil/mil/passes/defs/optimize_linear.py
 coremltools/converters/mil/mil/passes/defs/optimize_normalization.py
+coremltools/converters/mil/mil/passes/defs/optimize_quantization.py
 coremltools/converters/mil/mil/passes/defs/optimize_repeat_ops.py
 coremltools/converters/mil/mil/passes/defs/optimize_tensor_operation.py
 coremltools/converters/mil/mil/passes/defs/preprocess.py
 coremltools/converters/mil/mil/passes/defs/quantization.py
 coremltools/converters/mil/mil/passes/defs/cleanup/__init__.py
+coremltools/converters/mil/mil/passes/defs/cleanup/const_deduplication.py
 coremltools/converters/mil/mil/passes/defs/cleanup/const_elimination.py
 coremltools/converters/mil/mil/passes/defs/cleanup/dead_code_elimination.py
 coremltools/converters/mil/mil/passes/defs/cleanup/dedup_op_and_var_names.py
 coremltools/converters/mil/mil/passes/defs/cleanup/fuse_reduce_mean.py
 coremltools/converters/mil/mil/passes/defs/cleanup/loop_invariant_elimination.py
 coremltools/converters/mil/mil/passes/defs/cleanup/noop_elimination.py
 coremltools/converters/mil/mil/passes/defs/cleanup/remove_redundant_ops.py
 coremltools/converters/mil/mil/passes/defs/cleanup/remove_symbolic_reshape.py
 coremltools/converters/mil/mil/passes/defs/cleanup/topological_reorder.py
 coremltools/converters/mil/mil/passes/tests/__init__.py
 coremltools/converters/mil/mil/passes/tests/test_lower_complex_dialect_ops.py
 coremltools/converters/mil/mil/passes/tests/test_pass_pipeline.py
 coremltools/converters/mil/mil/passes/tests/test_passes.py
+coremltools/converters/mil/mil/passes/tests/test_quantization_passes.py
 coremltools/converters/mil/mil/passes/tests/test_reduce_transposes_pass.py
 coremltools/converters/mil/mil/tests/__init__.py
 coremltools/converters/mil/mil/tests/test_block.py
 coremltools/converters/mil/mil/tests/test_debug.py
 coremltools/converters/mil/mil/tests/test_programs.py
 coremltools/converters/mil/mil/tests/test_types.py
 coremltools/converters/mil/mil/types/__init__.py
@@ -308,14 +324,57 @@
 coremltools/models/neural_network/flexible_shape_utils.py
 coremltools/models/neural_network/optimization_utils.py
 coremltools/models/neural_network/printer.py
 coremltools/models/neural_network/quantization_utils.py
 coremltools/models/neural_network/spec_inspection_utils.py
 coremltools/models/neural_network/update_optimizer_utils.py
 coremltools/models/neural_network/utils.py
+coremltools/optimize/__init__.py
+coremltools/optimize/coreml/__init__.py
+coremltools/optimize/coreml/_config.py
+coremltools/optimize/coreml/_post_training_quantization.py
+coremltools/optimize/coreml/_quantization_passes.py
+coremltools/optimize/torch/__init__.py
+coremltools/optimize/torch/_logging.py
+coremltools/optimize/torch/_typing.py
+coremltools/optimize/torch/base_model_optimizer.py
+coremltools/optimize/torch/optimization_config.py
+coremltools/optimize/torch/_utils/__init__.py
+coremltools/optimize/torch/_utils/math_utils.py
+coremltools/optimize/torch/_utils/python_utils.py
+coremltools/optimize/torch/_utils/state_dict_utils.py
+coremltools/optimize/torch/_utils/torch_utils.py
+coremltools/optimize/torch/_utils/version_utils.py
+coremltools/optimize/torch/palettization/__init__.py
+coremltools/optimize/torch/palettization/_custom_conversion.py
+coremltools/optimize/torch/palettization/_efficient_kmeans.py
+coremltools/optimize/torch/palettization/_fake_palettizer_tensor_hook.py
+coremltools/optimize/torch/palettization/_partitioner.py
+coremltools/optimize/torch/palettization/_supported_modules.py
+coremltools/optimize/torch/palettization/fake_palettize.py
+coremltools/optimize/torch/palettization/palettization_config.py
+coremltools/optimize/torch/palettization/palettizer.py
+coremltools/optimize/torch/pruning/__init__.py
+coremltools/optimize/torch/pruning/_base_pruner.py
+coremltools/optimize/torch/pruning/_base_pruning_method.py
+coremltools/optimize/torch/pruning/_utils.py
+coremltools/optimize/torch/pruning/magnitude_pruner.py
+coremltools/optimize/torch/pruning/pruning_scheduler.py
+coremltools/optimize/torch/quantization/__init__.py
+coremltools/optimize/torch/quantization/_backend_config.py
+coremltools/optimize/torch/quantization/_backend_config_utils.py
+coremltools/optimize/torch/quantization/_configure.py
+coremltools/optimize/torch/quantization/_qconfig_mapping.py
+coremltools/optimize/torch/quantization/_utils.py
+coremltools/optimize/torch/quantization/quantization_config.py
+coremltools/optimize/torch/quantization/quantizer.py
+coremltools/optimize/torch/quantization/modules/__init__.py
+coremltools/optimize/torch/quantization/modules/fused_modules.py
+coremltools/optimize/torch/quantization/modules/qat_modules.py
+coremltools/optimize/torch/quantization/modules/quantized_modules.py
 coremltools/proto/ArrayFeatureExtractor_pb2.py
 coremltools/proto/AudioFeaturePrint_pb2.py
 coremltools/proto/BayesianProbitRegressor_pb2.py
 coremltools/proto/CategoricalMapping_pb2.py
 coremltools/proto/ClassConfidenceThresholding_pb2.py
 coremltools/proto/CustomModel_pb2.py
 coremltools/proto/DataStructures_pb2.py
@@ -363,14 +422,35 @@
 coremltools/test/neural_network/test_model.py
 coremltools/test/neural_network/test_neural_networks.py
 coremltools/test/neural_network/test_nn_builder.py
 coremltools/test/neural_network/test_numpy_nn_layers.py
 coremltools/test/neural_network/test_quantization.py
 coremltools/test/neural_network/test_simple_nn_inference.py
 coremltools/test/neural_network/test_tf_numeric.py
+coremltools/test/optimize/__init__.py
+coremltools/test/optimize/coreml/__init__.py
+coremltools/test/optimize/coreml/test_passes.py
+coremltools/test/optimize/coreml/test_post_training_quantization.py
+coremltools/test/optimize/torch/__init__.py
+coremltools/test/optimize/torch/conftest.py
+coremltools/test/optimize/torch/test_api_surface.py
+coremltools/test/optimize/torch/test_base_optimizer.py
+coremltools/test/optimize/torch/utils.py
+coremltools/test/optimize/torch/models/__init__.py
+coremltools/test/optimize/torch/models/mnist.py
+coremltools/test/optimize/torch/palettization/__init__.py
+coremltools/test/optimize/torch/palettization/palettization_utils.py
+coremltools/test/optimize/torch/palettization/test_palettization_api.py
+coremltools/test/optimize/torch/pruning/__init__.py
+coremltools/test/optimize/torch/pruning/pruning_utils.py
+coremltools/test/optimize/torch/pruning/test_magnitude_pruner.py
+coremltools/test/optimize/torch/pruning/test_pruning_scheduler.py
+coremltools/test/optimize/torch/quantization/__init__.py
+coremltools/test/optimize/torch/quantization/test_configure.py
+coremltools/test/optimize/torch/quantization/test_quantizer.py
 coremltools/test/pipeline/__init__.py
 coremltools/test/pipeline/test_model_updatable.py
 coremltools/test/pipeline/test_pipeline.py
 coremltools/test/sklearn_tests/__init__.py
 coremltools/test/sklearn_tests/test_NuSVC.py
 coremltools/test/sklearn_tests/test_NuSVR.py
 coremltools/test/sklearn_tests/test_SVC.py
```

### Comparing `coremltools-6.3.0/setup.py` & `coremltools-7.0b1/setup.py`

 * *Files 24% similar despite different names*

```diff
@@ -62,30 +62,41 @@
     description="Community Tools for Core ML",
     long_description=long_description,
     author="Apple Inc.",
     author_email="coremltools@apple.com",
     url="https://github.com/apple/coremltools",
     packages=find_packages(),
     package_data={
-        "": ["LICENSE.txt", "README.md", "libmilstoragepython.so", "libcoremlpython.so", "libmodelpackage.so"]
+        "": [
+            "_core.*.so",  # kmeans1d
+            "libcoremlpython.so",
+            "libmilstoragepython.so",
+            "libmodelpackage.so",
+            "LICENSE.txt",
+            "README.md",
+        ]
     },
     install_requires=[
         "numpy >= 1.14.5",
         "protobuf >= 3.1.0, <= 4.0.0",
         "sympy",
         "tqdm",
         "packaging",
+        "attrs",
+        "cattrs",
+        "pyaml",
     ],
     classifiers=[
         "Development Status :: 5 - Production/Stable",
         "Intended Audience :: Developers",
         "Operating System :: MacOS :: MacOS X",
         "Operating System :: POSIX :: Linux",
         "Programming Language :: Python :: 3.7",
         "Programming Language :: Python :: 3.8",
         "Programming Language :: Python :: 3.9",
         "Programming Language :: Python :: 3.10",
+        "Programming Language :: Python :: 3.11",
         "Topic :: Scientific/Engineering",
         "Topic :: Software Development",
     ],
     license="BSD",
 )
```

