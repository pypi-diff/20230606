# Comparing `tmp/checkthechain-0.3.0.tar.gz` & `tmp/checkthechain-0.3.4.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "checkthechain-0.3.0.tar", last modified: Mon Sep 26 01:29:09 2022, max compression
+gzip compressed data, was "checkthechain-0.3.4.tar", last modified: Tue Jun  6 00:31:23 2023, max compression
```

## Comparing `checkthechain-0.3.0.tar` & `checkthechain-0.3.4.tar`

### file list

```diff
@@ -1,656 +1,698 @@
--rw-r--r--   0        0        0      227 2022-08-15 22:23:13.533889 checkthechain-0.3.0/.gitignore
--rw-r--r--   0        0        0     7368 2022-09-25 06:02:46.722213 checkthechain-0.3.0/CHANGELOG.md
--rw-r--r--   0        0        0     3309 2022-07-24 17:33:32.632285 checkthechain-0.3.0/CONTRIBUTING.md
--rw-r--r--   0        0        0     1082 2022-09-25 05:12:28.321927 checkthechain-0.3.0/LICENSE
--rw-r--r--   0        0        0     7341 2022-09-25 23:23:49.104966 checkthechain-0.3.0/README.md
--rw-r--r--   0        0        0       52 2022-09-09 23:41:20.005598 checkthechain-0.3.0/docs/README.md
--rw-r--r--   0        0        0     4284 2022-09-25 23:11:23.671170 checkthechain-0.3.0/pyproject.toml
--rw-r--r--   0        0        0      566 2022-09-20 16:29:53.167710 checkthechain-0.3.0/src/ctc/__init__.py
--rw-r--r--   0        0        0       35 2022-07-24 17:33:32.632285 checkthechain-0.3.0/src/ctc/__main__.py
--rw-r--r--   0        0        0       59 2022-08-20 06:50:55.866922 checkthechain-0.3.0/src/ctc/cli/__init__.py
--rw-r--r--   0        0        0    13914 2022-09-25 04:30:17.092752 checkthechain-0.3.0/src/ctc/cli/cli_run.py
--rw-r--r--   0        0        0      129 2022-06-28 19:46:50.140649 checkthechain-0.3.0/src/ctc/cli/cli_utils/__init__.py
--rw-r--r--   0        0        0     9052 2022-09-14 07:25:04.063122 checkthechain-0.3.0/src/ctc/cli/cli_utils/cli_alias_utils.py
--rw-r--r--   0        0        0      612 2022-05-22 07:21:22.378479 checkthechain-0.3.0/src/ctc/cli/cli_utils/cli_execution_utils.py
--rw-r--r--   0        0        0     2777 2022-09-14 07:25:53.059008 checkthechain-0.3.0/src/ctc/cli/cli_utils/cli_output_utils.py
--rw-r--r--   0        0        0     4692 2022-09-17 06:06:21.132696 checkthechain-0.3.0/src/ctc/cli/cli_utils/cli_parse_utils.py
--rw-r--r--   0        0        0        0 2022-02-09 06:35:24.781264 checkthechain-0.3.0/src/ctc/cli/commands/__init__.py
--rw-r--r--   0        0        0        0 2022-02-14 18:41:05.225659 checkthechain-0.3.0/src/ctc/cli/commands/admin/__init__.py
--rw-r--r--   0        0        0     1952 2022-07-29 03:26:41.374084 checkthechain-0.3.0/src/ctc/cli/commands/admin/aliases_command.py
--rw-r--r--   0        0        0     2569 2022-09-14 07:23:18.283367 checkthechain-0.3.0/src/ctc/cli/commands/admin/chains_command.py
--rw-r--r--   0        0        0        0 2022-02-14 18:41:10.493383 checkthechain-0.3.0/src/ctc/cli/commands/admin/config/__init__.py
--rw-r--r--   0        0        0      756 2022-07-24 17:33:32.632285 checkthechain-0.3.0/src/ctc/cli/commands/admin/config/edit_command.py
--rw-r--r--   0        0        0      341 2022-07-24 17:33:32.632285 checkthechain-0.3.0/src/ctc/cli/commands/admin/config/path_command.py
--rw-r--r--   0        0        0     7960 2022-09-14 07:21:51.471565 checkthechain-0.3.0/src/ctc/cli/commands/admin/config_command.py
--rw-r--r--   0        0        0        0 2022-05-04 20:01:27.426937 checkthechain-0.3.0/src/ctc/cli/commands/admin/db/__init__.py
--rw-r--r--   0        0        0     1133 2022-07-28 03:54:57.943580 checkthechain-0.3.0/src/ctc/cli/commands/admin/db/create_tables_command.py
--rw-r--r--   0        0        0     1160 2022-06-29 08:24:44.983532 checkthechain-0.3.0/src/ctc/cli/commands/admin/db/drop_command.py
--rw-r--r--   0        0        0     4724 2022-09-14 07:23:08.907389 checkthechain-0.3.0/src/ctc/cli/commands/admin/db/status_command.py
--rw-r--r--   0        0        0      858 2022-08-11 22:48:13.234210 checkthechain-0.3.0/src/ctc/cli/commands/admin/log_command.py
--rw-r--r--   0        0        0     3324 2022-07-27 00:21:56.934023 checkthechain-0.3.0/src/ctc/cli/commands/admin/rechunk_command.py
--rw-r--r--   0        0        0     3184 2022-07-24 17:33:32.636285 checkthechain-0.3.0/src/ctc/cli/commands/admin/setup_command.py
--rw-r--r--   0        0        0        0 2022-02-14 18:40:55.690167 checkthechain-0.3.0/src/ctc/cli/commands/compute/__init__.py
--rw-r--r--   0        0        0      491 2022-09-17 21:36:13.545404 checkthechain-0.3.0/src/ctc/cli/commands/compute/ascii_command.py
--rw-r--r--   0        0        0      530 2022-08-29 17:14:59.012492 checkthechain-0.3.0/src/ctc/cli/commands/compute/checksum_command.py
--rw-r--r--   0        0        0     1202 2022-06-29 08:29:08.466843 checkthechain-0.3.0/src/ctc/cli/commands/compute/create_address_command.py
--rw-r--r--   0        0        0    13726 2022-09-25 16:13:54.201732 checkthechain-0.3.0/src/ctc/cli/commands/compute/decode_call_command.py
--rw-r--r--   0        0        0      980 2022-09-17 21:35:56.821422 checkthechain-0.3.0/src/ctc/cli/commands/compute/decode_command.py
--rw-r--r--   0        0        0     1504 2022-09-17 21:35:33.565446 checkthechain-0.3.0/src/ctc/cli/commands/compute/encode_command.py
--rw-r--r--   0        0        0      760 2022-09-17 21:35:11.649468 checkthechain-0.3.0/src/ctc/cli/commands/compute/hex_command.py
--rw-r--r--   0        0        0      509 2022-09-17 21:34:54.277484 checkthechain-0.3.0/src/ctc/cli/commands/compute/integer_command.py
--rw-r--r--   0        0        0     1618 2022-09-17 21:34:41.297496 checkthechain-0.3.0/src/ctc/cli/commands/compute/keccak_command.py
--rw-r--r--   0        0        0     4730 2022-09-14 07:23:31.183337 checkthechain-0.3.0/src/ctc/cli/commands/compute/limits_command.py
--rw-r--r--   0        0        0      436 2022-08-11 23:14:38.150356 checkthechain-0.3.0/src/ctc/cli/commands/compute/lower_command.py
--rw-r--r--   0        0        0      993 2022-09-17 21:34:22.753513 checkthechain-0.3.0/src/ctc/cli/commands/compute/rlp_encode.py
--rw-r--r--   0        0        0      720 2022-09-17 21:33:48.229542 checkthechain-0.3.0/src/ctc/cli/commands/compute/selector_command.py
--rw-r--r--   0        0        0        0 2022-02-14 18:40:26.151814 checkthechain-0.3.0/src/ctc/cli/commands/data/__init__.py
--rw-r--r--   0        0        0     6221 2022-09-23 04:31:29.161597 checkthechain-0.3.0/src/ctc/cli/commands/data/abi_command.py
--rw-r--r--   0        0        0     1506 2022-07-24 17:33:32.636285 checkthechain-0.3.0/src/ctc/cli/commands/data/abi_diff_command.py
--rw-r--r--   0        0        0     1364 2022-08-11 22:47:48.394262 checkthechain-0.3.0/src/ctc/cli/commands/data/address_command.py
--rw-r--r--   0        0        0     2532 2022-09-25 23:11:23.667170 checkthechain-0.3.0/src/ctc/cli/commands/data/address_txs_command.py
--rw-r--r--   0        0        0     2661 2022-08-15 22:38:28.092739 checkthechain-0.3.0/src/ctc/cli/commands/data/block_command.py
--rw-r--r--   0        0        0     5137 2022-09-14 07:15:55.416348 checkthechain-0.3.0/src/ctc/cli/commands/data/blocks_command.py
--rw-r--r--   0        0        0      634 2022-06-29 08:19:17.784318 checkthechain-0.3.0/src/ctc/cli/commands/data/bytecode_command.py
--rw-r--r--   0        0        0     4536 2022-09-14 07:20:46.267713 checkthechain-0.3.0/src/ctc/cli/commands/data/call_all_command.py
--rw-r--r--   0        0        0     3224 2022-09-14 20:30:43.272340 checkthechain-0.3.0/src/ctc/cli/commands/data/call_command.py
--rw-r--r--   0        0        0    22876 2022-09-19 05:27:29.903671 checkthechain-0.3.0/src/ctc/cli/commands/data/calls_command.py
--rw-r--r--   0        0        0     2938 2022-07-27 00:20:26.714286 checkthechain-0.3.0/src/ctc/cli/commands/data/chain_command.py
--rw-r--r--   0        0        0     4114 2022-09-14 07:22:39.535456 checkthechain-0.3.0/src/ctc/cli/commands/data/decompile_command.py
--rw-r--r--   0        0        0        0 2022-07-25 15:41:59.767248 checkthechain-0.3.0/src/ctc/cli/commands/data/dex/__init__.py
--rw-r--r--   0        0        0     6656 2022-09-14 06:42:43.892562 checkthechain-0.3.0/src/ctc/cli/commands/data/dex/chart_command.py
--rw-r--r--   0        0        0     4863 2022-09-14 05:36:55.256765 checkthechain-0.3.0/src/ctc/cli/commands/data/dex/pool_command.py
--rw-r--r--   0        0        0     8620 2022-09-14 07:22:03.407538 checkthechain-0.3.0/src/ctc/cli/commands/data/dex/pools_command.py
--rw-r--r--   0        0        0     4315 2022-09-14 05:42:49.659905 checkthechain-0.3.0/src/ctc/cli/commands/data/dex/trades_command.py
--rw-r--r--   0        0        0        0 2022-02-14 18:40:45.634715 checkthechain-0.3.0/src/ctc/cli/commands/data/erc20/__init__.py
--rw-r--r--   0        0        0     1603 2022-08-16 00:08:47.097882 checkthechain-0.3.0/src/ctc/cli/commands/data/erc20/balance_command.py
--rw-r--r--   0        0        0    10067 2022-09-14 07:21:03.035675 checkthechain-0.3.0/src/ctc/cli/commands/data/erc20/balances_command.py
--rw-r--r--   0        0        0     2056 2022-09-17 05:56:30.807230 checkthechain-0.3.0/src/ctc/cli/commands/data/erc20/transfers_command.py
--rw-r--r--   0        0        0      881 2022-08-12 20:04:47.646005 checkthechain-0.3.0/src/ctc/cli/commands/data/erc20_command.py
--rw-r--r--   0        0        0        0 2022-02-14 18:40:34.339347 checkthechain-0.3.0/src/ctc/cli/commands/data/eth/__init__.py
--rw-r--r--   0        0        0     1334 2022-06-27 07:54:18.752354 checkthechain-0.3.0/src/ctc/cli/commands/data/eth/balance_command.py
--rw-r--r--   0        0        0     7641 2022-09-14 07:21:17.391643 checkthechain-0.3.0/src/ctc/cli/commands/data/eth/balances_command.py
--rw-r--r--   0        0        0     3952 2022-09-17 05:59:48.230773 checkthechain-0.3.0/src/ctc/cli/commands/data/events_command.py
--rw-r--r--   0        0        0    11970 2022-09-14 07:22:56.095418 checkthechain-0.3.0/src/ctc/cli/commands/data/gas_command.py
--rw-r--r--   0        0        0     2520 2022-08-24 05:52:18.562984 checkthechain-0.3.0/src/ctc/cli/commands/data/proxy_command.py
--rw-r--r--   0        0        0     2549 2022-09-14 07:21:30.215614 checkthechain-0.3.0/src/ctc/cli/commands/data/proxy_register_command.py
--rw-r--r--   0        0        0     1493 2022-09-17 21:33:17.305566 checkthechain-0.3.0/src/ctc/cli/commands/data/storage_command.py
--rw-r--r--   0        0        0      850 2022-07-24 17:33:32.636285 checkthechain-0.3.0/src/ctc/cli/commands/data/symbol_command.py
--rw-r--r--   0        0        0     1450 2022-06-29 08:08:51.589918 checkthechain-0.3.0/src/ctc/cli/commands/data/timestamp_command.py
--rw-r--r--   0        0        0     1132 2022-09-02 20:49:59.079825 checkthechain-0.3.0/src/ctc/cli/commands/data/tx_command.py
--rw-r--r--   0        0        0     2813 2022-06-29 21:43:46.494392 checkthechain-0.3.0/src/ctc/cli/commands/root_command.py
--rw-r--r--   0        0        0        0 2022-05-16 06:22:55.818390 checkthechain-0.3.0/src/ctc/cli/plugins/__init__.py
--rw-r--r--   0        0        0     1453 2022-08-10 22:33:04.742753 checkthechain-0.3.0/src/ctc/cli/plugins/toolsql_plugin.py
--rw-r--r--   0        0        0      199 2022-07-24 17:33:32.636285 checkthechain-0.3.0/src/ctc/config/__init__.py
--rw-r--r--   0        0        0     3168 2022-08-14 01:56:37.921149 checkthechain-0.3.0/src/ctc/config/config_data_sources.py
--rw-r--r--   0        0        0     6622 2022-09-25 03:56:33.593615 checkthechain-0.3.0/src/ctc/config/config_defaults.py
--rw-r--r--   0        0        0     4032 2022-08-30 01:14:17.288570 checkthechain-0.3.0/src/ctc/config/config_read.py
--rw-r--r--   0        0        0      281 2022-06-18 22:33:00.239905 checkthechain-0.3.0/src/ctc/config/config_spec.py
--rw-r--r--   0        0        0     7262 2022-08-29 22:54:23.934360 checkthechain-0.3.0/src/ctc/config/config_validate.py
--rw-r--r--   0        0        0     6228 2022-09-17 15:45:09.194723 checkthechain-0.3.0/src/ctc/config/config_values.py
--rw-r--r--   0        0        0      607 2022-07-24 17:33:32.636285 checkthechain-0.3.0/src/ctc/config/config_write.py
--rw-r--r--   0        0        0       26 2022-07-24 17:33:32.640285 checkthechain-0.3.0/src/ctc/config/setup_utils/__init__.py
--rw-r--r--   0        0        0        0 2022-06-23 05:25:20.942685 checkthechain-0.3.0/src/ctc/config/setup_utils/default_data/__init__.py
--rw-r--r--   0        0        0   142600 2022-07-24 17:33:32.640285 checkthechain-0.3.0/src/ctc/config/setup_utils/default_data/default_erc20s.py
--rw-r--r--   0        0        0     3244 2022-08-14 01:54:24.329523 checkthechain-0.3.0/src/ctc/config/setup_utils/main_setup.py
--rw-r--r--   0        0        0     4161 2022-07-25 23:36:25.430760 checkthechain-0.3.0/src/ctc/config/setup_utils/setup_io.py
--rw-r--r--   0        0        0        0 2022-06-18 19:57:19.303046 checkthechain-0.3.0/src/ctc/config/setup_utils/stages/__init__.py
--rw-r--r--   0        0        0     1619 2022-07-29 03:34:09.440154 checkthechain-0.3.0/src/ctc/config/setup_utils/stages/alias_setup.py
--rw-r--r--   0        0        0     3190 2022-07-24 17:33:32.640285 checkthechain-0.3.0/src/ctc/config/setup_utils/stages/data_dir_setup.py
--rw-r--r--   0        0        0     4345 2022-09-23 04:10:07.333887 checkthechain-0.3.0/src/ctc/config/setup_utils/stages/db_setup.py
--rw-r--r--   0        0        0    16359 2022-09-25 03:49:22.463577 checkthechain-0.3.0/src/ctc/config/setup_utils/stages/network_setup.py
--rw-r--r--   0        0        0       30 2022-06-29 01:21:35.985634 checkthechain-0.3.0/src/ctc/config/upgrade_utils/__init__.py
--rw-r--r--   0        0        0     3775 2022-07-27 08:50:58.902459 checkthechain-0.3.0/src/ctc/config/upgrade_utils/config_upgrade.py
--rw-r--r--   0        0        0     5935 2022-07-24 17:33:32.640285 checkthechain-0.3.0/src/ctc/config/upgrade_utils/data_dir_versioning.py
--rw-r--r--   0        0        0     2798 2022-07-24 17:33:32.640285 checkthechain-0.3.0/src/ctc/config/upgrade_utils/legacy_types.py
--rw-r--r--   0        0        0      854 2022-08-15 22:56:40.661228 checkthechain-0.3.0/src/ctc/db/README.md
--rw-r--r--   0        0        0      162 2022-07-21 06:20:07.416808 checkthechain-0.3.0/src/ctc/db/__init__.py
--rw-r--r--   0        0        0     2041 2022-07-26 20:46:26.260142 checkthechain-0.3.0/src/ctc/db/connect_utils.py
--rw-r--r--   0        0        0     3226 2022-08-30 00:50:23.143833 checkthechain-0.3.0/src/ctc/db/intake_utils.py
--rw-r--r--   0        0        0      109 2022-07-24 17:33:32.640285 checkthechain-0.3.0/src/ctc/db/management/__init__.py
--rw-r--r--   0        0        0      975 2022-08-15 22:53:16.714003 checkthechain-0.3.0/src/ctc/db/management/active_utils.py
--rw-r--r--   0        0        0      268 2022-04-01 01:47:44.589560 checkthechain-0.3.0/src/ctc/db/management/compression/README.md
--rw-r--r--   0        0        0        0 2022-04-01 01:47:44.589560 checkthechain-0.3.0/src/ctc/db/management/compression/__init__.py
--rw-r--r--   0        0        0     2693 2022-06-29 02:06:26.114455 checkthechain-0.3.0/src/ctc/db/management/compression/block_timestamp_compression.py
--rw-r--r--   0        0        0     9134 2022-07-26 20:45:32.584331 checkthechain-0.3.0/src/ctc/db/management/dba_utils.py
--rw-r--r--   0        0        0      335 2022-07-24 17:33:32.640285 checkthechain-0.3.0/src/ctc/db/management/reorg_utils.py
--rw-r--r--   0        0        0     5167 2022-07-24 17:33:32.640285 checkthechain-0.3.0/src/ctc/db/management/version_utils.py
--rw-r--r--   0        0        0     1907 2022-07-24 17:33:32.640285 checkthechain-0.3.0/src/ctc/db/query_utils.py
--rw-r--r--   0        0        0     5031 2022-08-14 01:00:07.174699 checkthechain-0.3.0/src/ctc/db/schema_utils.py
--rw-r--r--   0        0        0      234 2022-08-14 00:51:22.531874 checkthechain-0.3.0/src/ctc/db/schemas/__init__.py
--rw-r--r--   0        0        0        0 2022-06-04 05:35:58.586166 checkthechain-0.3.0/src/ctc/db/schemas/__upcoming__/__init__.py
--rw-r--r--   0        0        0       43 2022-05-28 19:03:05.296646 checkthechain-0.3.0/src/ctc/db/schemas/__upcoming__/block_gas_stats/__init__.py
--rw-r--r--   0        0        0     1129 2022-07-24 17:33:32.640285 checkthechain-0.3.0/src/ctc/db/schemas/__upcoming__/block_gas_stats/block_gas_stats_schema_defs.py
--rw-r--r--   0        0        0       39 2022-05-28 19:01:51.952853 checkthechain-0.3.0/src/ctc/db/schemas/__upcoming__/erc20_state/__init__.py
--rw-r--r--   0        0        0     1250 2022-05-07 19:17:53.276707 checkthechain-0.3.0/src/ctc/db/schemas/__upcoming__/erc20_state/erc20_state_schema_defs.py
--rw-r--r--   0        0        0        0 2022-05-28 17:46:45.567982 checkthechain-0.3.0/src/ctc/db/schemas/__upcoming__/protocol_schemas/__init__.py
--rw-r--r--   0        0        0      783 2022-05-17 03:15:59.048614 checkthechain-0.3.0/src/ctc/db/schemas/__upcoming__/protocol_schemas/fourbyte_schema_defs.py
--rw-r--r--   0        0        0      625 2022-07-24 17:33:32.640285 checkthechain-0.3.0/src/ctc/db/schemas/__upcoming__/protocol_schemas/fuse_pools_schema_defs.py
--rw-r--r--   0        0        0      378 2022-07-24 17:33:32.640285 checkthechain-0.3.0/src/ctc/db/schemas/__upcoming__/protocol_schemas/uniswap_v2_pools_schema_defs.py
--rw-r--r--   0        0        0      427 2022-07-24 17:33:32.640285 checkthechain-0.3.0/src/ctc/db/schemas/__upcoming__/protocol_schemas/uniswap_v3_pools_schema_defs.py
--rw-r--r--   0        0        0      106 2022-08-14 21:18:48.111458 checkthechain-0.3.0/src/ctc/db/schemas/block_gas/__init__.py
--rw-r--r--   0        0        0      420 2022-08-14 01:31:18.181505 checkthechain-0.3.0/src/ctc/db/schemas/block_gas/block_gas_queries.py
--rw-r--r--   0        0        0      620 2022-08-14 22:50:11.725392 checkthechain-0.3.0/src/ctc/db/schemas/block_gas/block_gas_schema_defs.py
--rw-r--r--   0        0        0     2944 2022-08-15 21:39:46.882929 checkthechain-0.3.0/src/ctc/db/schemas/block_gas/block_gas_statements.py
--rw-r--r--   0        0        0      194 2022-06-04 05:37:55.197715 checkthechain-0.3.0/src/ctc/db/schemas/block_timestamps/__init__.py
--rw-r--r--   0        0        0      549 2022-07-24 17:33:32.640285 checkthechain-0.3.0/src/ctc/db/schemas/block_timestamps/block_timestamps_schema_defs.py
--rw-r--r--   0        0        0     6022 2022-06-29 05:43:49.783191 checkthechain-0.3.0/src/ctc/db/schemas/block_timestamps/block_timestamps_statements.py
--rw-r--r--   0        0        0     1596 2022-07-24 17:33:32.644285 checkthechain-0.3.0/src/ctc/db/schemas/block_timestamps/multischema_block_timestamps_queries.py
--rw-r--r--   0        0        0     4262 2022-07-24 17:33:32.644285 checkthechain-0.3.0/src/ctc/db/schemas/block_timestamps/multischema_block_timestamps_search.py
--rw-r--r--   0        0        0     3109 2022-06-27 19:20:37.522307 checkthechain-0.3.0/src/ctc/db/schemas/block_timestamps/multischema_block_timestamps_statements.py
--rw-r--r--   0        0        0      126 2022-06-04 05:39:12.501421 checkthechain-0.3.0/src/ctc/db/schemas/blocks/__init__.py
--rw-r--r--   0        0        0     7541 2022-09-06 17:15:30.823057 checkthechain-0.3.0/src/ctc/db/schemas/blocks/blocks_intake.py
--rw-r--r--   0        0        0      343 2022-07-24 17:33:32.644285 checkthechain-0.3.0/src/ctc/db/schemas/blocks/blocks_queries.py
--rw-r--r--   0        0        0     1416 2022-07-24 17:33:32.644285 checkthechain-0.3.0/src/ctc/db/schemas/blocks/blocks_schema_defs.py
--rw-r--r--   0        0        0     7592 2022-09-03 02:17:25.236119 checkthechain-0.3.0/src/ctc/db/schemas/blocks/blocks_statements.py
--rw-r--r--   0        0        0      154 2022-05-28 19:46:35.178080 checkthechain-0.3.0/src/ctc/db/schemas/contract_abis/__init__.py
--rw-r--r--   0        0        0     1196 2022-06-27 19:11:26.863797 checkthechain-0.3.0/src/ctc/db/schemas/contract_abis/contract_abis_intake.py
--rw-r--r--   0        0        0      406 2022-07-24 17:33:32.644285 checkthechain-0.3.0/src/ctc/db/schemas/contract_abis/contract_abis_queries.py
--rw-r--r--   0        0        0      383 2022-05-14 21:36:48.279041 checkthechain-0.3.0/src/ctc/db/schemas/contract_abis/contract_abis_schema_defs.py
--rw-r--r--   0        0        0     2463 2022-07-24 17:33:32.644285 checkthechain-0.3.0/src/ctc/db/schemas/contract_abis/contract_abis_statements.py
--rw-r--r--   0        0        0      198 2022-05-28 19:46:08.850146 checkthechain-0.3.0/src/ctc/db/schemas/contract_creation_blocks/__init__.py
--rw-r--r--   0        0        0     1019 2022-06-27 19:12:14.023667 checkthechain-0.3.0/src/ctc/db/schemas/contract_creation_blocks/contract_creation_blocks_intake.py
--rw-r--r--   0        0        0      505 2022-07-24 17:33:32.644285 checkthechain-0.3.0/src/ctc/db/schemas/contract_creation_blocks/contract_creation_blocks_queries.py
--rw-r--r--   0        0        0      525 2022-07-24 17:33:32.644285 checkthechain-0.3.0/src/ctc/db/schemas/contract_creation_blocks/contract_creation_blocks_schema_defs.py
--rw-r--r--   0        0        0     2167 2022-06-29 05:36:09.429062 checkthechain-0.3.0/src/ctc/db/schemas/contract_creation_blocks/contract_creation_blocks_statements.py
--rw-r--r--   0        0        0      138 2022-07-24 17:33:32.644285 checkthechain-0.3.0/src/ctc/db/schemas/dex_pools/__init__.py
--rw-r--r--   0        0        0     1584 2022-07-24 17:33:32.644285 checkthechain-0.3.0/src/ctc/db/schemas/dex_pools/dex_pools_intake.py
--rw-r--r--   0        0        0      578 2022-07-29 19:30:01.911425 checkthechain-0.3.0/src/ctc/db/schemas/dex_pools/dex_pools_queries.py
--rw-r--r--   0        0        0     1085 2022-07-24 17:33:32.644285 checkthechain-0.3.0/src/ctc/db/schemas/dex_pools/dex_pools_schema_defs.py
--rw-r--r--   0        0        0     6537 2022-08-24 19:29:45.779930 checkthechain-0.3.0/src/ctc/db/schemas/dex_pools/dex_pools_statements.py
--rw-r--r--   0        0        0      158 2022-06-09 17:47:39.371480 checkthechain-0.3.0/src/ctc/db/schemas/erc20_metadata/__init__.py
--rw-r--r--   0        0        0      765 2022-06-27 19:12:39.111598 checkthechain-0.3.0/src/ctc/db/schemas/erc20_metadata/erc20_metadata_intake.py
--rw-r--r--   0        0        0      473 2022-07-24 17:33:32.644285 checkthechain-0.3.0/src/ctc/db/schemas/erc20_metadata/erc20_metadata_queries.py
--rw-r--r--   0        0        0      756 2022-06-27 04:09:29.136106 checkthechain-0.3.0/src/ctc/db/schemas/erc20_metadata/erc20_metadata_schema_defs.py
--rw-r--r--   0        0        0     3879 2022-09-19 20:36:30.196797 checkthechain-0.3.0/src/ctc/db/schemas/erc20_metadata/erc20_metadata_statements.py
--rw-r--r--   0        0        0       43 2022-07-24 17:33:32.644285 checkthechain-0.3.0/src/ctc/db/schemas/schema_versions/__init__.py
--rw-r--r--   0        0        0      494 2022-06-06 06:36:51.690502 checkthechain-0.3.0/src/ctc/db/schemas/schema_versions/schema_versions_schema_defs.py
--rw-r--r--   0        0        0      250 2022-09-17 21:24:47.409498 checkthechain-0.3.0/src/ctc/evm/__init__.py
--rw-r--r--   0        0        0      131 2022-09-17 21:41:31.676990 checkthechain-0.3.0/src/ctc/evm/abi_utils/__init__.py
--rw-r--r--   0        0        0     1306 2022-09-20 16:28:58.071912 checkthechain-0.3.0/src/ctc/evm/abi_utils/abi_coding_utils.py
--rw-r--r--   0        0        0      189 2022-09-17 04:56:07.399066 checkthechain-0.3.0/src/ctc/evm/abi_utils/contract_abi_utils/__init__.py
--rw-r--r--   0        0        0     2698 2022-09-23 04:30:41.973601 checkthechain-0.3.0/src/ctc/evm/abi_utils/contract_abi_utils/contract_abi_comparison.py
--rw-r--r--   0        0        0     1258 2022-09-20 16:32:35.631113 checkthechain-0.3.0/src/ctc/evm/abi_utils/contract_abi_utils/contract_abi_decompilation.py
--rw-r--r--   0        0        0     2415 2022-09-20 16:34:13.578753 checkthechain-0.3.0/src/ctc/evm/abi_utils/contract_abi_utils/contract_abi_io.py
--rw-r--r--   0        0        0      660 2022-09-20 16:35:14.446530 checkthechain-0.3.0/src/ctc/evm/abi_utils/contract_abi_utils/contract_abi_modification.py
--rw-r--r--   0        0        0    10137 2022-09-23 04:32:00.889598 checkthechain-0.3.0/src/ctc/evm/abi_utils/contract_abi_utils/contract_abi_summary.py
--rw-r--r--   0        0        0       98 2022-09-15 06:20:46.435473 checkthechain-0.3.0/src/ctc/evm/abi_utils/event_abi_utils/__init__.py
--rw-r--r--   0        0        0     9085 2022-09-20 16:39:13.149653 checkthechain-0.3.0/src/ctc/evm/abi_utils/event_abi_utils/event_abi_coding.py
--rw-r--r--   0        0        0     1542 2022-09-20 16:39:44.981536 checkthechain-0.3.0/src/ctc/evm/abi_utils/event_abi_utils/event_abi_parsing.py
--rw-r--r--   0        0        0     3000 2022-09-20 16:41:02.877250 checkthechain-0.3.0/src/ctc/evm/abi_utils/event_abi_utils/event_abi_queries.py
--rw-r--r--   0        0        0      107 2022-09-15 06:27:29.946182 checkthechain-0.3.0/src/ctc/evm/abi_utils/function_abi_utils/__init__.py
--rw-r--r--   0        0        0     8236 2022-09-20 16:43:07.780791 checkthechain-0.3.0/src/ctc/evm/abi_utils/function_abi_utils/function_abi_coding.py
--rw-r--r--   0        0        0     7908 2022-09-20 16:48:02.447709 checkthechain-0.3.0/src/ctc/evm/abi_utils/function_abi_utils/function_abi_parsing.py
--rw-r--r--   0        0        0     4360 2022-09-20 16:48:43.391559 checkthechain-0.3.0/src/ctc/evm/abi_utils/function_abi_utils/function_abi_queries.py
--rw-r--r--   0        0        0      187 2022-05-26 03:40:33.956927 checkthechain-0.3.0/src/ctc/evm/address_utils/__init__.py
--rw-r--r--   0        0        0     2697 2022-09-20 16:50:30.359166 checkthechain-0.3.0/src/ctc/evm/address_utils/address_data.py
--rw-r--r--   0        0        0     1005 2022-09-20 16:51:06.319033 checkthechain-0.3.0/src/ctc/evm/address_utils/address_queries.py
--rw-r--r--   0        0        0     2920 2022-09-22 16:16:44.841879 checkthechain-0.3.0/src/ctc/evm/address_utils/address_resolution.py
--rw-r--r--   0        0        0     3006 2022-09-23 04:32:22.765601 checkthechain-0.3.0/src/ctc/evm/address_utils/address_summary.py
--rw-r--r--   0        0        0     5747 2022-09-20 16:55:04.722158 checkthechain-0.3.0/src/ctc/evm/address_utils/address_transactions.py
--rw-r--r--   0        0        0     9952 2022-09-20 17:24:32.487665 checkthechain-0.3.0/src/ctc/evm/address_utils/proxy_utils.py
--rw-r--r--   0        0        0      177 2022-09-17 21:42:07.400937 checkthechain-0.3.0/src/ctc/evm/binary_utils/__init__.py
--rw-r--r--   0        0        0     5340 2022-09-20 16:57:42.901577 checkthechain-0.3.0/src/ctc/evm/binary_utils/format_utils.py
--rw-r--r--   0        0        0     3184 2022-09-17 22:04:55.694489 checkthechain-0.3.0/src/ctc/evm/binary_utils/hash_utils.py
--rw-r--r--   0        0        0     9220 2022-09-20 16:59:18.169227 checkthechain-0.3.0/src/ctc/evm/binary_utils/rlp_utils.py
--rw-r--r--   0        0        0      146 2022-09-03 00:35:48.027387 checkthechain-0.3.0/src/ctc/evm/binary_utils/signature_utils/__init__.py
--rw-r--r--   0        0        0     7465 2022-09-20 17:18:00.037106 checkthechain-0.3.0/src/ctc/evm/binary_utils/signature_utils/eip712_utils.py
--rw-r--r--   0        0        0     1523 2022-09-20 17:19:50.332701 checkthechain-0.3.0/src/ctc/evm/binary_utils/signature_utils/key_utils.py
--rw-r--r--   0        0        0     4915 2022-08-28 04:07:48.991640 checkthechain-0.3.0/src/ctc/evm/binary_utils/signature_utils/secp256k1_utils.py
--rw-r--r--   0        0        0     2895 2022-09-20 17:20:59.964445 checkthechain-0.3.0/src/ctc/evm/binary_utils/signature_utils/signature_creation.py
--rw-r--r--   0        0        0     2872 2022-09-20 17:22:42.780068 checkthechain-0.3.0/src/ctc/evm/binary_utils/signature_utils/signature_recovery.py
--rw-r--r--   0        0        0     2008 2022-09-20 17:23:43.851843 checkthechain-0.3.0/src/ctc/evm/binary_utils/signature_utils/vrs_utils.py
--rw-r--r--   0        0        0      255 2022-09-14 07:53:19.962062 checkthechain-0.3.0/src/ctc/evm/block_utils/__init__.py
--rw-r--r--   0        0        0     1492 2022-09-20 17:07:36.491396 checkthechain-0.3.0/src/ctc/evm/block_utils/block_analysis.py
--rw-r--r--   0        0        0     2819 2022-09-20 17:08:19.179240 checkthechain-0.3.0/src/ctc/evm/block_utils/block_coding.py
--rw-r--r--   0        0        0     3953 2022-09-20 17:09:53.442893 checkthechain-0.3.0/src/ctc/evm/block_utils/block_creations.py
--rw-r--r--   0        0        0     6061 2022-09-20 17:10:32.314751 checkthechain-0.3.0/src/ctc/evm/block_utils/block_crud.py
--rw-r--r--   0        0        0     7808 2022-09-20 17:14:22.953903 checkthechain-0.3.0/src/ctc/evm/block_utils/block_gas.py
--rw-r--r--   0        0        0     1077 2022-09-20 17:15:36.665633 checkthechain-0.3.0/src/ctc/evm/block_utils/block_hashes.py
--rw-r--r--   0        0        0     1039 2022-09-20 17:15:57.409556 checkthechain-0.3.0/src/ctc/evm/block_utils/block_normalize.py
--rw-r--r--   0        0        0     2699 2022-09-20 17:16:07.981518 checkthechain-0.3.0/src/ctc/evm/block_utils/block_summary.py
--rw-r--r--   0        0        0      106 2022-07-24 17:33:32.644285 checkthechain-0.3.0/src/ctc/evm/block_utils/block_times/__init__.py
--rw-r--r--   0        0        0     6167 2022-09-20 17:05:19.035901 checkthechain-0.3.0/src/ctc/evm/block_utils/block_times/block_time_predictions.py
--rw-r--r--   0        0        0     2402 2022-09-20 17:05:49.123791 checkthechain-0.3.0/src/ctc/evm/block_utils/block_times/block_time_sampling.py
--rw-r--r--   0        0        0     2521 2022-09-20 17:06:21.111673 checkthechain-0.3.0/src/ctc/evm/block_utils/block_times/block_to_timestamp.py
--rw-r--r--   0        0        0      133 2022-07-31 19:13:27.465162 checkthechain-0.3.0/src/ctc/evm/block_utils/block_times/timestamp_to_block/__init__.py
--rw-r--r--   0        0        0     3625 2022-09-20 17:00:45.672905 checkthechain-0.3.0/src/ctc/evm/block_utils/block_times/timestamp_to_block/block_time_plural.py
--rw-r--r--   0        0        0     2445 2022-09-20 17:01:59.880633 checkthechain-0.3.0/src/ctc/evm/block_utils/block_times/timestamp_to_block/block_time_range.py
--rw-r--r--   0        0        0     5912 2022-09-17 16:17:22.580858 checkthechain-0.3.0/src/ctc/evm/block_utils/block_times/timestamp_to_block/block_time_search.py
--rw-r--r--   0        0        0     4184 2022-09-20 17:03:28.800306 checkthechain-0.3.0/src/ctc/evm/block_utils/block_times/timestamp_to_block/block_time_singular.py
--rw-r--r--   0        0        0      200 2022-07-24 17:33:32.648285 checkthechain-0.3.0/src/ctc/evm/erc20_utils/__init__.py
--rw-r--r--   0        0        0     4540 2022-09-21 02:39:19.256220 checkthechain-0.3.0/src/ctc/evm/erc20_utils/erc20_events.py
--rw-r--r--   0        0        0     1892 2022-09-17 16:06:06.626645 checkthechain-0.3.0/src/ctc/evm/erc20_utils/erc20_generic.py
--rw-r--r--   0        0        0    10980 2022-09-21 02:41:54.979698 checkthechain-0.3.0/src/ctc/evm/erc20_utils/erc20_metadata.py
--rw-r--r--   0        0        0     5775 2022-09-21 02:43:42.555459 checkthechain-0.3.0/src/ctc/evm/erc20_utils/erc20_normalize.py
--rw-r--r--   0        0        0     3433 2022-07-24 17:33:32.648285 checkthechain-0.3.0/src/ctc/evm/erc20_utils/erc20_spec.py
--rw-r--r--   0        0        0    11113 2022-09-21 02:47:45.946837 checkthechain-0.3.0/src/ctc/evm/erc20_utils/erc20_state.py
--rw-r--r--   0        0        0     1686 2022-09-21 02:48:01.350795 checkthechain-0.3.0/src/ctc/evm/erc20_utils/erc20_summary.py
--rw-r--r--   0        0        0       24 2022-02-08 17:43:17.144036 checkthechain-0.3.0/src/ctc/evm/eth_utils/__init__.py
--rw-r--r--   0        0        0     4220 2022-09-21 02:49:30.154546 checkthechain-0.3.0/src/ctc/evm/eth_utils/eth_crud.py
--rw-r--r--   0        0        0       56 2022-09-17 04:33:47.647579 checkthechain-0.3.0/src/ctc/evm/event_utils/__init__.py
--rw-r--r--   0        0        0       97 2022-02-08 17:43:17.144036 checkthechain-0.3.0/src/ctc/evm/event_utils/event_backends/__init__.py
--rw-r--r--   0        0        0    15269 2022-09-17 21:08:35.489318 checkthechain-0.3.0/src/ctc/evm/event_utils/event_backends/filesystem_events.py
--rw-r--r--   0        0        0     8595 2022-09-17 21:08:19.497367 checkthechain-0.3.0/src/ctc/evm/event_utils/event_backends/filesystem_rechunking.py
--rw-r--r--   0        0        0     7175 2022-09-17 16:07:10.158338 checkthechain-0.3.0/src/ctc/evm/event_utils/event_backends/node_events.py
--rw-r--r--   0        0        0     8301 2022-09-21 02:50:33.922362 checkthechain-0.3.0/src/ctc/evm/event_utils/event_crud.py
--rw-r--r--   0        0        0       33 2022-07-24 17:33:32.648285 checkthechain-0.3.0/src/ctc/evm/network_utils/__init__.py
--rw-r--r--   0        0        0     4125 2022-09-21 02:53:39.289807 checkthechain-0.3.0/src/ctc/evm/network_utils/network_directory.py
--rw-r--r--   0        0        0       33 2022-07-24 17:33:32.648285 checkthechain-0.3.0/src/ctc/evm/trace_utils/__init__.py
--rw-r--r--   0        0        0     3717 2022-09-17 21:05:41.793839 checkthechain-0.3.0/src/ctc/evm/trace_utils/trace_dataframes.py
--rw-r--r--   0        0        0      188 2022-09-02 18:23:06.306559 checkthechain-0.3.0/src/ctc/evm/transaction_utils/README.md
--rw-r--r--   0        0        0      209 2022-09-02 17:38:04.481480 checkthechain-0.3.0/src/ctc/evm/transaction_utils/__init__.py
--rw-r--r--   0        0        0      923 2022-09-21 02:55:18.649501 checkthechain-0.3.0/src/ctc/evm/transaction_utils/transaction_crud.py
--rw-r--r--   0        0        0      714 2022-09-21 02:55:43.237424 checkthechain-0.3.0/src/ctc/evm/transaction_utils/transaction_hashes.py
--rw-r--r--   0        0        0     1961 2022-09-21 02:56:03.877359 checkthechain-0.3.0/src/ctc/evm/transaction_utils/transaction_serialize.py
--rw-r--r--   0        0        0     3944 2022-09-21 02:58:00.808990 checkthechain-0.3.0/src/ctc/evm/transaction_utils/transaction_signatures.py
--rw-r--r--   0        0        0     7349 2022-09-21 02:58:38.652869 checkthechain-0.3.0/src/ctc/evm/transaction_utils/transaction_summary.py
--rw-r--r--   0        0        0     3002 2022-09-21 02:59:58.128614 checkthechain-0.3.0/src/ctc/evm/transaction_utils/transaction_types.py
--rw-r--r--   0        0        0        0 2022-02-08 17:43:17.144036 checkthechain-0.3.0/src/ctc/protocols/__init__.py
--rw-r--r--   0        0        0      210 2022-08-02 06:26:24.014907 checkthechain-0.3.0/src/ctc/protocols/aave_v2_utils/__init__.py
--rw-r--r--   0        0        0     7043 2022-08-15 19:03:19.803927 checkthechain-0.3.0/src/ctc/protocols/aave_v2_utils/aave_interest_rates.py
--rw-r--r--   0        0        0     2699 2022-09-21 16:13:06.352398 checkthechain-0.3.0/src/ctc/protocols/aave_v2_utils/aave_lending_pool.py
--rw-r--r--   0        0        0     3311 2022-08-15 19:19:28.557417 checkthechain-0.3.0/src/ctc/protocols/aave_v2_utils/aave_oracle.py
--rw-r--r--   0        0        0     1265 2022-09-14 07:58:08.877279 checkthechain-0.3.0/src/ctc/protocols/aave_v2_utils/aave_pool_tokens.py
--rw-r--r--   0        0        0     3169 2022-08-16 00:10:16.749516 checkthechain-0.3.0/src/ctc/protocols/aave_v2_utils/aave_rewards.py
--rw-r--r--   0        0        0      888 2022-08-02 20:10:14.723020 checkthechain-0.3.0/src/ctc/protocols/aave_v2_utils/aave_spec.py
--rw-r--r--   0        0        0    12806 2022-09-23 04:36:12.069678 checkthechain-0.3.0/src/ctc/protocols/aave_v2_utils/aave_summaries.py
--rw-r--r--   0        0        0        0 2022-08-02 06:26:45.272379 checkthechain-0.3.0/src/ctc/protocols/aave_v2_utils/cli/__init__.py
--rw-r--r--   0        0        0      870 2022-08-02 23:32:15.485361 checkthechain-0.3.0/src/ctc/protocols/aave_v2_utils/cli/aave_addresses_command.py
--rw-r--r--   0        0        0     3072 2022-09-23 04:42:07.585056 checkthechain-0.3.0/src/ctc/protocols/aave_v2_utils/cli/aave_command.py
--rw-r--r--   0        0        0      165 2022-09-11 23:06:46.089449 checkthechain-0.3.0/src/ctc/protocols/balancer_utils/__init__.py
--rw-r--r--   0        0        0     4038 2022-09-11 23:08:46.068668 checkthechain-0.3.0/src/ctc/protocols/balancer_utils/balancer_spec.py
--rw-r--r--   0        0        0     3379 2022-09-11 23:10:16.252133 checkthechain-0.3.0/src/ctc/protocols/balancer_utils/pool_metadata.py
--rw-r--r--   0        0        0     4334 2022-07-24 17:33:32.648285 checkthechain-0.3.0/src/ctc/protocols/balancer_utils/pool_plots.py
--rw-r--r--   0        0        0     5903 2022-08-08 06:36:31.134738 checkthechain-0.3.0/src/ctc/protocols/balancer_utils/pool_state.py
--rw-r--r--   0        0        0     5797 2022-09-23 04:40:02.665192 checkthechain-0.3.0/src/ctc/protocols/balancer_utils/pool_summary.py
--rw-r--r--   0        0        0     1007 2022-06-27 18:30:39.951328 checkthechain-0.3.0/src/ctc/protocols/balancer_utils/pool_trades.py
--rw-r--r--   0        0        0      237 2022-07-24 17:33:32.652285 checkthechain-0.3.0/src/ctc/protocols/chainlink_utils/__init__.py
--rw-r--r--   0        0        0     7669 2022-09-22 19:35:37.767873 checkthechain-0.3.0/src/ctc/protocols/chainlink_utils/chainlink_aggregators.py
--rw-r--r--   0        0        0      147 2022-03-16 07:23:42.504050 checkthechain-0.3.0/src/ctc/protocols/chainlink_utils/chainlink_data/__init__.py
--rw-r--r--   0        0        0     2008 2022-09-17 05:48:27.528376 checkthechain-0.3.0/src/ctc/protocols/chainlink_utils/chainlink_data/feed_composites.py
--rw-r--r--   0        0        0     4115 2022-09-17 05:48:24.652383 checkthechain-0.3.0/src/ctc/protocols/chainlink_utils/chainlink_data/feed_data.py
--rw-r--r--   0        0        0     3093 2022-07-24 17:33:32.652285 checkthechain-0.3.0/src/ctc/protocols/chainlink_utils/chainlink_data/feed_datum.py
--rw-r--r--   0        0        0     2194 2022-06-27 18:03:21.401662 checkthechain-0.3.0/src/ctc/protocols/chainlink_utils/chainlink_data/feed_datum_by_block.py
--rw-r--r--   0        0        0     6445 2022-09-22 18:46:35.857982 checkthechain-0.3.0/src/ctc/protocols/chainlink_utils/chainlink_data/feed_events.py
--rw-r--r--   0        0        0      138 2022-06-08 08:21:36.422366 checkthechain-0.3.0/src/ctc/protocols/chainlink_utils/chainlink_db/__init__.py
--rw-r--r--   0        0        0     9029 2022-09-25 04:07:38.759166 checkthechain-0.3.0/src/ctc/protocols/chainlink_utils/chainlink_db/chainlink_intake.py
--rw-r--r--   0        0        0      509 2022-09-22 16:17:13.801502 checkthechain-0.3.0/src/ctc/protocols/chainlink_utils/chainlink_db/chainlink_queries.py
--rw-r--r--   0        0        0     1449 2022-09-22 16:10:57.594833 checkthechain-0.3.0/src/ctc/protocols/chainlink_utils/chainlink_db/chainlink_schema_defs.py
--rw-r--r--   0        0        0     6137 2022-09-22 18:34:51.257254 checkthechain-0.3.0/src/ctc/protocols/chainlink_utils/chainlink_db/chainlink_statements.py
--rw-r--r--   0        0        0     4299 2022-07-24 17:33:32.652285 checkthechain-0.3.0/src/ctc/protocols/chainlink_utils/chainlink_feed_metadata.py
--rw-r--r--   0        0        0      844 2022-06-27 18:00:53.254019 checkthechain-0.3.0/src/ctc/protocols/chainlink_utils/chainlink_helpers.py
--rw-r--r--   0        0        0     4396 2022-06-29 03:51:06.096486 checkthechain-0.3.0/src/ctc/protocols/chainlink_utils/chainlink_registry.py
--rw-r--r--   0        0        0     2915 2022-09-18 19:19:11.757318 checkthechain-0.3.0/src/ctc/protocols/chainlink_utils/chainlink_spec.py
--rw-r--r--   0        0        0     6013 2022-09-25 04:33:24.976431 checkthechain-0.3.0/src/ctc/protocols/chainlink_utils/chainlink_summary.py
--rw-r--r--   0        0        0        0 2022-02-09 06:36:17.678064 checkthechain-0.3.0/src/ctc/protocols/chainlink_utils/cli/__init__.py
--rw-r--r--   0        0        0     5008 2022-09-23 04:41:41.169078 checkthechain-0.3.0/src/ctc/protocols/chainlink_utils/cli/chainlink_command.py
--rw-r--r--   0        0        0     2233 2022-09-25 04:37:13.043970 checkthechain-0.3.0/src/ctc/protocols/chainlink_utils/cli/chainlink_ls_command.py
--rw-r--r--   0        0        0       55 2022-07-26 08:09:27.881424 checkthechain-0.3.0/src/ctc/protocols/coingecko_utils/__init__.py
--rw-r--r--   0        0        0        0 2022-07-26 08:09:45.425352 checkthechain-0.3.0/src/ctc/protocols/coingecko_utils/cli/__init__.py
--rw-r--r--   0        0        0     3611 2022-09-23 04:41:24.397095 checkthechain-0.3.0/src/ctc/protocols/coingecko_utils/cli/cg_command.py
--rw-r--r--   0        0        0      138 2022-07-26 19:57:30.514246 checkthechain-0.3.0/src/ctc/protocols/coingecko_utils/coingecko_db/__init__.py
--rw-r--r--   0        0        0      937 2022-07-26 19:58:25.838079 checkthechain-0.3.0/src/ctc/protocols/coingecko_utils/coingecko_db/coingecko_intake.py
--rw-r--r--   0        0        0      385 2022-07-26 21:28:46.604693 checkthechain-0.3.0/src/ctc/protocols/coingecko_utils/coingecko_db/coingecko_queries.py
--rw-r--r--   0        0        0      763 2022-07-26 20:48:35.671703 checkthechain-0.3.0/src/ctc/protocols/coingecko_utils/coingecko_db/coingecko_schema_defs.py
--rw-r--r--   0        0        0     3128 2022-07-26 21:16:23.250895 checkthechain-0.3.0/src/ctc/protocols/coingecko_utils/coingecko_db/coingecko_statements.py
--rw-r--r--   0        0        0     5432 2022-08-14 00:16:24.032612 checkthechain-0.3.0/src/ctc/protocols/coingecko_utils/market_utils.py
--rw-r--r--   0        0        0    15807 2022-09-23 04:38:29.717346 checkthechain-0.3.0/src/ctc/protocols/coingecko_utils/token_utils.py
--rw-r--r--   0        0        0       29 2022-04-01 01:47:44.593560 checkthechain-0.3.0/src/ctc/protocols/compound_utils/__init__.py
--rw-r--r--   0        0        0     2133 2022-07-24 17:33:32.652285 checkthechain-0.3.0/src/ctc/protocols/compound_utils/compound_crud.py
--rw-r--r--   0        0        0      168 2022-09-12 02:39:55.844554 checkthechain-0.3.0/src/ctc/protocols/curve_utils/__init__.py
--rw-r--r--   0        0        0        0 2022-05-04 20:01:41.110897 checkthechain-0.3.0/src/ctc/protocols/curve_utils/cli/__init__.py
--rw-r--r--   0        0        0     1690 2022-08-09 06:43:56.091629 checkthechain-0.3.0/src/ctc/protocols/curve_utils/cli/curve_pools_command.py
--rw-r--r--   0        0        0     5120 2022-09-12 02:41:35.576803 checkthechain-0.3.0/src/ctc/protocols/curve_utils/curve_spec.py
--rw-r--r--   0        0        0     3663 2022-07-27 22:27:06.443073 checkthechain-0.3.0/src/ctc/protocols/curve_utils/metapool_utils.py
--rw-r--r--   0        0        0    14913 2022-09-17 05:48:43.484338 checkthechain-0.3.0/src/ctc/protocols/curve_utils/pool_lists.py
--rw-r--r--   0        0        0     5001 2022-07-31 06:50:04.533463 checkthechain-0.3.0/src/ctc/protocols/curve_utils/pool_metadata.py
--rw-r--r--   0        0        0     7302 2022-09-17 05:48:40.596345 checkthechain-0.3.0/src/ctc/protocols/curve_utils/pool_parameters.py
--rw-r--r--   0        0        0     4096 2022-09-11 19:24:18.955133 checkthechain-0.3.0/src/ctc/protocols/curve_utils/pool_state.py
--rw-r--r--   0        0        0       49 2022-07-24 17:33:32.652285 checkthechain-0.3.0/src/ctc/protocols/ens_utils/__init__.py
--rw-r--r--   0        0        0        0 2022-02-19 01:22:22.374519 checkthechain-0.3.0/src/ctc/protocols/ens_utils/cli/__init__.py
--rw-r--r--   0        0        0        0 2022-02-19 01:22:14.862271 checkthechain-0.3.0/src/ctc/protocols/ens_utils/cli/ens/__init__.py
--rw-r--r--   0        0        0      813 2022-09-14 07:59:32.317055 checkthechain-0.3.0/src/ctc/protocols/ens_utils/cli/ens/exists_command.py
--rw-r--r--   0        0        0      441 2022-07-24 17:33:32.652285 checkthechain-0.3.0/src/ctc/protocols/ens_utils/cli/ens/hash_command.py
--rw-r--r--   0        0        0      765 2022-09-14 07:59:19.269090 checkthechain-0.3.0/src/ctc/protocols/ens_utils/cli/ens/owner_command.py
--rw-r--r--   0        0        0      625 2022-09-07 06:29:57.598860 checkthechain-0.3.0/src/ctc/protocols/ens_utils/cli/ens/records_command.py
--rw-r--r--   0        0        0      862 2022-09-14 07:59:07.725121 checkthechain-0.3.0/src/ctc/protocols/ens_utils/cli/ens/resolve_command.py
--rw-r--r--   0        0        0      876 2022-09-14 07:58:53.073160 checkthechain-0.3.0/src/ctc/protocols/ens_utils/cli/ens/reverse_command.py
--rw-r--r--   0        0        0     4213 2022-09-14 07:58:37.677202 checkthechain-0.3.0/src/ctc/protocols/ens_utils/cli/ens_command.py
--rw-r--r--   0        0        0      482 2022-07-24 17:33:32.652285 checkthechain-0.3.0/src/ctc/protocols/ens_utils/ens_directory.py
--rw-r--r--   0        0        0     3693 2022-09-23 03:26:30.186102 checkthechain-0.3.0/src/ctc/protocols/ens_utils/registrar.py
--rw-r--r--   0        0        0     7161 2022-09-17 21:32:02.957613 checkthechain-0.3.0/src/ctc/protocols/ens_utils/resolver.py
--rw-r--r--   0        0        0      103 2022-06-24 19:00:13.495006 checkthechain-0.3.0/src/ctc/protocols/etherscan_utils/__init__.py
--rw-r--r--   0        0        0     3441 2022-08-30 01:10:24.641204 checkthechain-0.3.0/src/ctc/protocols/etherscan_utils/abi_crud.py
--rw-r--r--   0        0        0        0 2022-07-27 04:11:02.507697 checkthechain-0.3.0/src/ctc/protocols/etherscan_utils/cli/__init__.py
--rw-r--r--   0        0        0     4430 2022-09-06 18:26:54.658600 checkthechain-0.3.0/src/ctc/protocols/etherscan_utils/cli/etherscan_command.py
--rw-r--r--   0        0        0      325 2022-06-24 20:44:15.268130 checkthechain-0.3.0/src/ctc/protocols/etherscan_utils/etherscan_spec.py
--rw-r--r--   0        0        0      833 2022-06-10 21:20:58.454698 checkthechain-0.3.0/src/ctc/protocols/etherscan_utils/misc_crud.py
--rw-r--r--   0        0        0     4939 2022-07-31 02:38:29.584021 checkthechain-0.3.0/src/ctc/protocols/etherscan_utils/url_crud.py
--rw-r--r--   0        0        0      124 2022-04-26 18:07:27.125826 checkthechain-0.3.0/src/ctc/protocols/fei_utils/__init__.py
--rw-r--r--   0        0        0      144 2022-02-08 17:43:17.144036 checkthechain-0.3.0/src/ctc/protocols/fei_utils/analytics/__init__.py
--rw-r--r--   0        0        0     4355 2022-07-31 18:31:21.665928 checkthechain-0.3.0/src/ctc/protocols/fei_utils/analytics/analytics_spec.py
--rw-r--r--   0        0        0     2040 2022-07-31 18:30:12.530149 checkthechain-0.3.0/src/ctc/protocols/fei_utils/analytics/metric_crud.py
--rw-r--r--   0        0        0      119 2022-02-08 17:43:17.144036 checkthechain-0.3.0/src/ctc/protocols/fei_utils/analytics/metric_groups/__init__.py
--rw-r--r--   0        0        0     2634 2022-08-30 01:19:39.023521 checkthechain-0.3.0/src/ctc/protocols/fei_utils/analytics/metric_groups/buyback_metrics.py
--rw-r--r--   0        0        0     4254 2022-08-16 00:08:00.146079 checkthechain-0.3.0/src/ctc/protocols/fei_utils/analytics/metric_groups/fei_metrics.py
--rw-r--r--   0        0        0     5968 2022-09-12 05:51:26.494613 checkthechain-0.3.0/src/ctc/protocols/fei_utils/analytics/metric_groups/fei_volume_metrics.py
--rw-r--r--   0        0        0     3156 2022-07-31 18:34:04.313386 checkthechain-0.3.0/src/ctc/protocols/fei_utils/analytics/metric_groups/pcv_metrics.py
--rw-r--r--   0        0        0     2019 2022-07-24 17:33:32.652285 checkthechain-0.3.0/src/ctc/protocols/fei_utils/analytics/payload_crud.py
--rw-r--r--   0        0        0     4983 2022-09-23 04:28:06.489683 checkthechain-0.3.0/src/ctc/protocols/fei_utils/analytics/timestamp_crud.py
--rw-r--r--   0        0        0        0 2022-02-09 06:36:28.898251 checkthechain-0.3.0/src/ctc/protocols/fei_utils/cli/__init__.py
--rw-r--r--   0        0        0        0 2022-02-09 06:36:34.094340 checkthechain-0.3.0/src/ctc/protocols/fei_utils/cli/fei/__init__.py
--rw-r--r--   0        0        0     2031 2022-06-29 07:47:06.757970 checkthechain-0.3.0/src/ctc/protocols/fei_utils/cli/fei/analytics_command.py
--rw-r--r--   0        0        0     2164 2022-06-29 07:50:58.813251 checkthechain-0.3.0/src/ctc/protocols/fei_utils/cli/fei/depth_command.py
--rw-r--r--   0        0        0     2153 2022-08-04 23:59:31.200299 checkthechain-0.3.0/src/ctc/protocols/fei_utils/cli/fei/dex_command.py
--rw-r--r--   0        0        0      528 2022-06-29 07:52:34.376955 checkthechain-0.3.0/src/ctc/protocols/fei_utils/cli/fei/pcv_assets_command.py
--rw-r--r--   0        0        0     2286 2022-08-04 23:59:35.644281 checkthechain-0.3.0/src/ctc/protocols/fei_utils/cli/fei/pcv_command.py
--rw-r--r--   0        0        0      593 2022-06-29 07:53:47.844727 checkthechain-0.3.0/src/ctc/protocols/fei_utils/cli/fei/pcv_deposits_command.py
--rw-r--r--   0        0        0     3502 2022-07-27 00:18:07.226700 checkthechain-0.3.0/src/ctc/protocols/fei_utils/cli/fei/psms_command.py
--rw-r--r--   0        0        0      209 2022-02-08 17:43:17.144036 checkthechain-0.3.0/src/ctc/protocols/fei_utils/coracle/__init__.py
--rw-r--r--   0        0        0    10748 2022-09-23 03:35:28.543947 checkthechain-0.3.0/src/ctc/protocols/fei_utils/coracle/coracle_balances.py
--rw-r--r--   0        0        0     3050 2022-06-29 02:56:39.550308 checkthechain-0.3.0/src/ctc/protocols/fei_utils/coracle/coracle_deposits.py
--rw-r--r--   0        0        0     3865 2022-08-30 00:50:39.311797 checkthechain-0.3.0/src/ctc/protocols/fei_utils/coracle/coracle_fei.py
--rw-r--r--   0        0        0     6927 2022-06-29 02:58:50.189545 checkthechain-0.3.0/src/ctc/protocols/fei_utils/coracle/coracle_oracles.py
--rw-r--r--   0        0        0     8628 2022-07-24 17:33:32.652285 checkthechain-0.3.0/src/ctc/protocols/fei_utils/coracle/coracle_spec.py
--rw-r--r--   0        0        0     3253 2022-06-29 03:03:17.668284 checkthechain-0.3.0/src/ctc/protocols/fei_utils/coracle/coracle_stats.py
--rw-r--r--   0        0        0     1482 2022-09-14 07:57:38.261361 checkthechain-0.3.0/src/ctc/protocols/fei_utils/coracle/coracle_tokens.py
--rw-r--r--   0        0        0       33 2022-04-22 00:08:53.040426 checkthechain-0.3.0/src/ctc/protocols/fei_utils/depth/__init__.py
--rw-r--r--   0        0        0     2386 2022-07-24 17:33:32.652285 checkthechain-0.3.0/src/ctc/protocols/fei_utils/depth/fei_uniswap_depth.py
--rw-r--r--   0        0        0     6137 2022-08-30 05:02:15.776151 checkthechain-0.3.0/src/ctc/protocols/fei_utils/fei_dexes.py
--rw-r--r--   0        0        0     7355 2022-08-30 01:18:03.447815 checkthechain-0.3.0/src/ctc/protocols/fei_utils/fei_psms.py
--rw-r--r--   0        0        0     6996 2022-05-26 07:17:38.684527 checkthechain-0.3.0/src/ctc/protocols/fei_utils/fei_summaries.py
--rw-r--r--   0        0        0     6932 2022-06-27 17:40:06.576067 checkthechain-0.3.0/src/ctc/protocols/fei_utils/fei_voting.py
--rw-r--r--   0        0        0      119 2022-04-01 01:47:44.601560 checkthechain-0.3.0/src/ctc/protocols/fei_utils/yields/__init__.py
--rw-r--r--   0        0        0     1579 2022-07-24 17:33:32.652285 checkthechain-0.3.0/src/ctc/protocols/fei_utils/yields/yields_crud.py
--rw-r--r--   0        0        0     1548 2022-08-30 00:54:12.791329 checkthechain-0.3.0/src/ctc/protocols/fei_utils/yields/yields_source_utils.py
--rw-r--r--   0        0        0        0 2022-04-01 01:47:44.601560 checkthechain-0.3.0/src/ctc/protocols/fei_utils/yields/yields_sources/__init__.py
--rw-r--r--   0        0        0     1952 2022-07-24 17:33:32.652285 checkthechain-0.3.0/src/ctc/protocols/fei_utils/yields/yields_sources/aave_yields.py
--rw-r--r--   0        0        0     2382 2022-07-24 17:33:32.652285 checkthechain-0.3.0/src/ctc/protocols/fei_utils/yields/yields_sources/compound_yields.py
--rw-r--r--   0        0        0     3271 2022-06-27 17:39:08.588113 checkthechain-0.3.0/src/ctc/protocols/fei_utils/yields/yields_sources/curve_yields.py
--rw-r--r--   0        0        0     3136 2022-07-24 17:33:32.656285 checkthechain-0.3.0/src/ctc/protocols/fei_utils/yields/yields_sources/g_uni_yields.py
--rw-r--r--   0        0        0     2818 2022-07-24 17:33:32.656285 checkthechain-0.3.0/src/ctc/protocols/fei_utils/yields/yields_sources/rari_yields.py
--rw-r--r--   0        0        0     1432 2022-07-31 18:35:29.237100 checkthechain-0.3.0/src/ctc/protocols/fei_utils/yields/yields_spec.py
--rw-r--r--   0        0        0      119 2022-06-10 05:26:39.008295 checkthechain-0.3.0/src/ctc/protocols/fourbyte_utils/__init__.py
--rw-r--r--   0        0        0        0 2022-05-04 20:02:09.150816 checkthechain-0.3.0/src/ctc/protocols/fourbyte_utils/cli/__init__.py
--rw-r--r--   0        0        0     1407 2022-07-24 17:33:32.656285 checkthechain-0.3.0/src/ctc/protocols/fourbyte_utils/cli/fourbyte_build_command.py
--rw-r--r--   0        0        0     3849 2022-06-29 07:23:23.234612 checkthechain-0.3.0/src/ctc/protocols/fourbyte_utils/cli/fourbyte_command.py
--rw-r--r--   0        0        0      102 2022-06-10 05:26:02.808559 checkthechain-0.3.0/src/ctc/protocols/fourbyte_utils/fourbyte_db/__init__.py
--rw-r--r--   0        0        0     1841 2022-06-29 21:52:37.409062 checkthechain-0.3.0/src/ctc/protocols/fourbyte_utils/fourbyte_db/fourbyte_intake.py
--rw-r--r--   0        0        0     1843 2022-07-24 17:33:32.656285 checkthechain-0.3.0/src/ctc/protocols/fourbyte_utils/fourbyte_db/fourbyte_schema_defs.py
--rw-r--r--   0        0        0     3935 2022-06-29 03:50:33.236530 checkthechain-0.3.0/src/ctc/protocols/fourbyte_utils/fourbyte_db/fourbyte_statements.py
--rw-r--r--   0        0        0       90 2022-03-01 04:18:15.908005 checkthechain-0.3.0/src/ctc/protocols/fourbyte_utils/fourbyte_queries/__init__.py
--rw-r--r--   0        0        0     2728 2022-06-29 03:40:30.721244 checkthechain-0.3.0/src/ctc/protocols/fourbyte_utils/fourbyte_queries/general_queries.py
--rw-r--r--   0        0        0      447 2022-07-24 17:33:32.656285 checkthechain-0.3.0/src/ctc/protocols/fourbyte_utils/fourbyte_queries/local_queries.py
--rw-r--r--   0        0        0     4025 2022-09-23 04:25:08.357941 checkthechain-0.3.0/src/ctc/protocols/fourbyte_utils/fourbyte_queries/remote_queries.py
--rw-r--r--   0        0        0     3547 2022-09-22 19:40:12.861713 checkthechain-0.3.0/src/ctc/protocols/fourbyte_utils/fourbyte_scrape.py
--rw-r--r--   0        0        0     1330 2022-06-10 05:23:41.157966 checkthechain-0.3.0/src/ctc/protocols/fourbyte_utils/fourbyte_spec.py
--rw-r--r--   0        0        0       20 2022-04-01 01:47:44.601560 checkthechain-0.3.0/src/ctc/protocols/g_uni_utils/__init__.py
--rw-r--r--   0        0        0     3222 2022-07-27 04:04:42.820712 checkthechain-0.3.0/src/ctc/protocols/g_uni_utils/crud.py
--rw-r--r--   0        0        0      670 2022-09-02 00:55:06.773267 checkthechain-0.3.0/src/ctc/protocols/gnosis_utils/README.md
--rw-r--r--   0        0        0      149 2022-09-05 16:36:11.951237 checkthechain-0.3.0/src/ctc/protocols/gnosis_utils/__init__.py
--rw-r--r--   0        0        0        0 2022-06-18 00:15:53.781576 checkthechain-0.3.0/src/ctc/protocols/gnosis_utils/cli/__init__.py
--rw-r--r--   0        0        0     1036 2022-09-25 03:11:04.279306 checkthechain-0.3.0/src/ctc/protocols/gnosis_utils/cli/gnosis_command.py
--rw-r--r--   0        0        0     2559 2022-09-04 06:21:59.001794 checkthechain-0.3.0/src/ctc/protocols/gnosis_utils/safe_events.py
--rw-r--r--   0        0        0     3785 2022-09-05 17:40:35.017914 checkthechain-0.3.0/src/ctc/protocols/gnosis_utils/safe_factory_events.py
--rw-r--r--   0        0        0     1375 2022-09-04 06:32:37.671712 checkthechain-0.3.0/src/ctc/protocols/gnosis_utils/safe_metadata.py
--rw-r--r--   0        0        0     7324 2022-09-05 17:32:54.350620 checkthechain-0.3.0/src/ctc/protocols/gnosis_utils/safe_spec.py
--rw-r--r--   0        0        0     8055 2022-09-04 06:33:54.087688 checkthechain-0.3.0/src/ctc/protocols/gnosis_utils/safe_summary.py
--rw-r--r--   0        0        0     6743 2022-09-17 21:26:21.817597 checkthechain-0.3.0/src/ctc/protocols/gnosis_utils/safe_transactions.py
--rw-r--r--   0        0        0        0 2022-08-03 06:49:57.560085 checkthechain-0.3.0/src/ctc/protocols/llama_utils/__init__.py
--rw-r--r--   0        0        0        0 2022-08-03 07:06:47.158499 checkthechain-0.3.0/src/ctc/protocols/llama_utils/cli/__init__.py
--rw-r--r--   0        0        0      563 2022-09-23 04:43:11.717012 checkthechain-0.3.0/src/ctc/protocols/llama_utils/cli/llama_chain_command.py
--rw-r--r--   0        0        0      637 2022-09-23 04:43:02.737017 checkthechain-0.3.0/src/ctc/protocols/llama_utils/cli/llama_chains_command.py
--rw-r--r--   0        0        0      355 2022-09-23 04:42:51.621024 checkthechain-0.3.0/src/ctc/protocols/llama_utils/cli/llama_command.py
--rw-r--r--   0        0        0      627 2022-09-23 04:33:02.413611 checkthechain-0.3.0/src/ctc/protocols/llama_utils/cli/llama_pool_command.py
--rw-r--r--   0        0        0     3726 2022-09-23 04:32:44.965606 checkthechain-0.3.0/src/ctc/protocols/llama_utils/cli/llama_pools_command.py
--rw-r--r--   0        0        0      877 2022-09-23 04:42:41.141031 checkthechain-0.3.0/src/ctc/protocols/llama_utils/cli/llama_protocol_command.py
--rw-r--r--   0        0        0     1307 2022-09-23 04:42:28.045040 checkthechain-0.3.0/src/ctc/protocols/llama_utils/cli/llama_protocols_command.py
--rw-r--r--   0        0        0     4884 2022-09-09 22:43:21.799213 checkthechain-0.3.0/src/ctc/protocols/llama_utils/llama_requests.py
--rw-r--r--   0        0        0     5902 2022-09-23 04:39:50.117210 checkthechain-0.3.0/src/ctc/protocols/llama_utils/llama_tvls.py
--rw-r--r--   0        0        0    10033 2022-09-23 04:29:19.037631 checkthechain-0.3.0/src/ctc/protocols/llama_utils/llama_yields.py
--rw-r--r--   0        0        0       88 2022-04-01 01:47:44.601560 checkthechain-0.3.0/src/ctc/protocols/multicall_utils/__init__.py
--rw-r--r--   0        0        0     4542 2022-09-17 21:36:57.753355 checkthechain-0.3.0/src/ctc/protocols/multicall_utils/call_utils.py
--rw-r--r--   0        0        0     1507 2022-08-30 00:54:38.815272 checkthechain-0.3.0/src/ctc/protocols/multicall_utils/multicall_spec.py
--rw-r--r--   0        0        0     3767 2022-07-27 05:59:55.816250 checkthechain-0.3.0/src/ctc/protocols/multicall_utils/multicalls_utils.py
--rw-r--r--   0        0        0       57 2022-07-24 17:33:32.656285 checkthechain-0.3.0/src/ctc/protocols/rari_utils/__init__.py
--rw-r--r--   0        0        0        0 2022-02-09 06:36:44.542521 checkthechain-0.3.0/src/ctc/protocols/rari_utils/cli/__init__.py
--rw-r--r--   0        0        0        0 2022-02-09 06:36:49.222604 checkthechain-0.3.0/src/ctc/protocols/rari_utils/cli/rari/__init__.py
--rw-r--r--   0        0        0     2938 2022-09-23 04:38:03.689399 checkthechain-0.3.0/src/ctc/protocols/rari_utils/cli/rari/fuse_command.py
--rw-r--r--   0        0        0     1584 2022-06-29 07:37:22.191790 checkthechain-0.3.0/src/ctc/protocols/rari_utils/cli/rari/pools_command.py
--rw-r--r--   0        0        0     1367 2022-02-16 08:54:46.256071 checkthechain-0.3.0/src/ctc/protocols/rari_utils/fuse_lens/README.md
--rw-r--r--   0        0        0      108 2022-02-16 02:03:05.606360 checkthechain-0.3.0/src/ctc/protocols/rari_utils/fuse_lens/__init__.py
--rw-r--r--   0        0        0    21649 2022-09-14 20:35:16.135932 checkthechain-0.3.0/src/ctc/protocols/rari_utils/fuse_lens/lens_abis.py
--rw-r--r--   0        0        0     7781 2022-06-29 03:21:34.316935 checkthechain-0.3.0/src/ctc/protocols/rari_utils/fuse_lens/lens_spec.py
--rw-r--r--   0        0        0    15333 2022-06-29 02:21:25.898709 checkthechain-0.3.0/src/ctc/protocols/rari_utils/fuse_lens/primary_lens.py
--rw-r--r--   0        0        0      205 2022-04-20 18:45:18.839225 checkthechain-0.3.0/src/ctc/protocols/rari_utils/fuse_lens/secondary_lens.py
--rw-r--r--   0        0        0      231 2022-07-24 17:33:32.656285 checkthechain-0.3.0/src/ctc/protocols/rari_utils/fuse_queries/__init__.py
--rw-r--r--   0        0        0      807 2022-06-29 21:17:48.934750 checkthechain-0.3.0/src/ctc/protocols/rari_utils/fuse_queries/directory_metadata.py
--rw-r--r--   0        0        0      711 2022-07-24 17:33:32.656285 checkthechain-0.3.0/src/ctc/protocols/rari_utils/fuse_queries/irm_metadata.py
--rw-r--r--   0        0        0     2913 2022-06-29 03:24:38.841288 checkthechain-0.3.0/src/ctc/protocols/rari_utils/fuse_queries/pool_metadata.py
--rw-r--r--   0        0        0     2704 2022-06-27 17:32:24.000530 checkthechain-0.3.0/src/ctc/protocols/rari_utils/fuse_queries/pool_state.py
--rw-r--r--   0        0        0     3188 2022-07-24 17:33:32.656285 checkthechain-0.3.0/src/ctc/protocols/rari_utils/fuse_queries/pool_summary.py
--rw-r--r--   0        0        0     1311 2022-07-24 17:33:32.656285 checkthechain-0.3.0/src/ctc/protocols/rari_utils/fuse_queries/token_metadata.py
--rw-r--r--   0        0        0       84 2022-04-01 01:47:44.601560 checkthechain-0.3.0/src/ctc/protocols/rari_utils/fuse_queries/token_state/__init__.py
--rw-r--r--   0        0        0     3627 2022-09-23 03:33:32.724763 checkthechain-0.3.0/src/ctc/protocols/rari_utils/fuse_queries/token_state/token_interest.py
--rw-r--r--   0        0        0     2071 2022-06-29 03:13:56.566145 checkthechain-0.3.0/src/ctc/protocols/rari_utils/fuse_queries/token_state/token_price.py
--rw-r--r--   0        0        0     3658 2022-06-29 03:12:40.430363 checkthechain-0.3.0/src/ctc/protocols/rari_utils/fuse_queries/token_state/token_usage.py
--rw-r--r--   0        0        0     5765 2022-06-29 03:11:59.546483 checkthechain-0.3.0/src/ctc/protocols/rari_utils/fuse_queries/token_summary.py
--rw-r--r--   0        0        0    89362 2022-07-24 17:33:32.656285 checkthechain-0.3.0/src/ctc/protocols/rari_utils/rari_abis.py
--rw-r--r--   0        0        0    11977 2022-09-17 21:36:28.269388 checkthechain-0.3.0/src/ctc/protocols/rari_utils/summary_utils.py
--rw-r--r--   0        0        0       56 2022-08-08 05:14:58.827961 checkthechain-0.3.0/src/ctc/protocols/sushi_utils/__init__.py
--rw-r--r--   0        0        0      337 2022-08-08 04:51:45.678163 checkthechain-0.3.0/src/ctc/protocols/sushi_utils/sushi_spec.py
--rw-r--r--   0        0        0      859 2022-09-12 05:51:41.362855 checkthechain-0.3.0/src/ctc/protocols/sushi_utils/sushiswap_crud.py
--rw-r--r--   0        0        0      166 2022-08-08 01:07:02.283665 checkthechain-0.3.0/src/ctc/protocols/uniswap_v2_utils/__init__.py
--rw-r--r--   0        0        0        0 2022-05-04 20:01:57.438850 checkthechain-0.3.0/src/ctc/protocols/uniswap_v2_utils/cli/__init__.py
--rw-r--r--   0        0        0     1423 2022-09-17 06:04:11.661453 checkthechain-0.3.0/src/ctc/protocols/uniswap_v2_utils/cli/burns_command.py
--rw-r--r--   0        0        0     6280 2022-09-12 06:22:21.124207 checkthechain-0.3.0/src/ctc/protocols/uniswap_v2_utils/cli/chart_command.py
--rw-r--r--   0        0        0     1423 2022-09-17 06:03:05.561880 checkthechain-0.3.0/src/ctc/protocols/uniswap_v2_utils/cli/mints_command.py
--rw-r--r--   0        0        0     1860 2022-07-28 19:34:20.662460 checkthechain-0.3.0/src/ctc/protocols/uniswap_v2_utils/cli/pool_command.py
--rw-r--r--   0        0        0     1440 2022-09-17 06:03:15.917811 checkthechain-0.3.0/src/ctc/protocols/uniswap_v2_utils/cli/swaps_command.py
--rw-r--r--   0        0        0     6789 2022-09-17 05:48:36.148355 checkthechain-0.3.0/src/ctc/protocols/uniswap_v2_utils/uniswap_v2_deltas.py
--rw-r--r--   0        0        0     5607 2022-09-12 05:53:24.384624 checkthechain-0.3.0/src/ctc/protocols/uniswap_v2_utils/uniswap_v2_events.py
--rw-r--r--   0        0        0     2787 2022-09-11 18:34:39.765201 checkthechain-0.3.0/src/ctc/protocols/uniswap_v2_utils/uniswap_v2_metadata.py
--rw-r--r--   0        0        0     5002 2022-09-11 18:39:24.132402 checkthechain-0.3.0/src/ctc/protocols/uniswap_v2_utils/uniswap_v2_spec.py
--rw-r--r--   0        0        0     3841 2022-09-14 05:08:47.809043 checkthechain-0.3.0/src/ctc/protocols/uniswap_v2_utils/uniswap_v2_state.py
--rw-r--r--   0        0        0      119 2022-08-08 06:38:36.594350 checkthechain-0.3.0/src/ctc/protocols/uniswap_v3_utils/__init__.py
--rw-r--r--   0        0        0      138 2022-03-04 06:08:31.343495 checkthechain-0.3.0/src/ctc/protocols/uniswap_v3_utils/contracts/__init__.py
--rw-r--r--   0        0        0     1469 2022-07-24 17:33:32.656285 checkthechain-0.3.0/src/ctc/protocols/uniswap_v3_utils/contracts/pool_derived_state.py
--rw-r--r--   0        0        0     3317 2022-06-29 02:31:06.100818 checkthechain-0.3.0/src/ctc/protocols/uniswap_v3_utils/contracts/pool_immutables.py
--rw-r--r--   0        0        0     6592 2022-06-29 02:35:10.644358 checkthechain-0.3.0/src/ctc/protocols/uniswap_v3_utils/contracts/pool_state.py
--rw-r--r--   0        0        0     3057 2022-06-29 02:36:57.048190 checkthechain-0.3.0/src/ctc/protocols/uniswap_v3_utils/contracts/quoter.py
--rw-r--r--   0        0        0      794 2022-06-29 02:39:45.175953 checkthechain-0.3.0/src/ctc/protocols/uniswap_v3_utils/contracts/tick_lens.py
--rw-r--r--   0        0        0     3319 2022-07-31 19:59:41.035833 checkthechain-0.3.0/src/ctc/protocols/uniswap_v3_utils/uniswap_v3_crud.py
--rw-r--r--   0        0        0     3484 2022-06-29 07:48:52.737642 checkthechain-0.3.0/src/ctc/protocols/uniswap_v3_utils/uniswap_v3_depth.py
--rw-r--r--   0        0        0     3127 2022-09-11 18:43:55.847650 checkthechain-0.3.0/src/ctc/protocols/uniswap_v3_utils/uniswap_v3_spec.py
--rw-r--r--   0        0        0      140 2022-08-05 07:05:28.775565 checkthechain-0.3.0/src/ctc/protocols/yearn_utils/__init__.py
--rw-r--r--   0        0        0        0 2022-08-04 23:40:58.904096 checkthechain-0.3.0/src/ctc/protocols/yearn_utils/cli/__init__.py
--rw-r--r--   0        0        0     1056 2022-09-14 07:27:37.206764 checkthechain-0.3.0/src/ctc/protocols/yearn_utils/cli/yearn_addresses_command.py
--rw-r--r--   0        0        0     2551 2022-09-23 04:40:59.885120 checkthechain-0.3.0/src/ctc/protocols/yearn_utils/cli/yearn_command.py
--rw-r--r--   0        0        0     5690 2022-09-14 07:27:27.522787 checkthechain-0.3.0/src/ctc/protocols/yearn_utils/yearn_addresses.py
--rw-r--r--   0        0        0     1864 2022-08-05 19:44:13.328381 checkthechain-0.3.0/src/ctc/protocols/yearn_utils/yearn_spec.py
--rw-r--r--   0        0        0     2467 2022-08-05 22:18:28.389018 checkthechain-0.3.0/src/ctc/protocols/yearn_utils/yearn_strategies.py
--rw-r--r--   0        0        0     1069 2022-08-05 19:57:56.250370 checkthechain-0.3.0/src/ctc/protocols/yearn_utils/yearn_tvls.py
--rw-r--r--   0        0        0    11107 2022-09-23 04:34:53.477662 checkthechain-0.3.0/src/ctc/protocols/yearn_utils/yearn_vaults.py
--rw-r--r--   0        0        0     2327 2022-08-05 22:13:08.329953 checkthechain-0.3.0/src/ctc/protocols/yearn_utils/yearn_web_api.py
--rw-r--r--   0        0        0        0 2022-02-08 17:43:17.144036 checkthechain-0.3.0/src/ctc/py.typed
--rw-r--r--   0        0        0      307 2022-07-24 17:33:32.656285 checkthechain-0.3.0/src/ctc/rpc/__init__.py
--rw-r--r--   0        0        0      104 2022-02-08 17:43:17.148036 checkthechain-0.3.0/src/ctc/rpc/rpc_batch/__init__.py
--rw-r--r--   0        0        0    13260 2022-06-19 02:22:49.981935 checkthechain-0.3.0/src/ctc/rpc/rpc_batch/rpc_batch_constructors.py
--rw-r--r--   0        0        0    13079 2022-07-24 17:33:32.656285 checkthechain-0.3.0/src/ctc/rpc/rpc_batch/rpc_batch_executors.py
--rw-r--r--   0        0        0     3985 2022-08-29 22:29:06.562008 checkthechain-0.3.0/src/ctc/rpc/rpc_batch/rpc_batch_utils.py
--rw-r--r--   0        0        0      351 2022-02-08 17:43:17.148036 checkthechain-0.3.0/src/ctc/rpc/rpc_constructors/__init__.py
--rw-r--r--   0        0        0     2523 2022-09-17 21:31:06.629639 checkthechain-0.3.0/src/ctc/rpc/rpc_constructors/rpc_block_constructors.py
--rw-r--r--   0        0        0      569 2022-06-27 16:56:08.759799 checkthechain-0.3.0/src/ctc/rpc/rpc_constructors/rpc_dev_constructors.py
--rw-r--r--   0        0        0     2415 2022-09-17 21:30:43.401647 checkthechain-0.3.0/src/ctc/rpc/rpc_constructors/rpc_log_constructors.py
--rw-r--r--   0        0        0      902 2022-06-27 16:56:56.603874 checkthechain-0.3.0/src/ctc/rpc/rpc_constructors/rpc_mining_constructors.py
--rw-r--r--   0        0        0      939 2022-06-27 16:57:03.167885 checkthechain-0.3.0/src/ctc/rpc/rpc_constructors/rpc_node_constructors.py
--rw-r--r--   0        0        0     3438 2022-09-17 21:30:34.497650 checkthechain-0.3.0/src/ctc/rpc/rpc_constructors/rpc_state_constructors.py
--rw-r--r--   0        0        0     1861 2022-06-27 16:57:59.871974 checkthechain-0.3.0/src/ctc/rpc/rpc_constructors/rpc_submission_constructors.py
--rw-r--r--   0        0        0     2125 2022-09-17 21:30:20.101653 checkthechain-0.3.0/src/ctc/rpc/rpc_constructors/rpc_transaction_constructors.py
--rw-r--r--   0        0        0     1967 2022-06-27 16:58:23.256010 checkthechain-0.3.0/src/ctc/rpc/rpc_constructors/rpc_whisper_constructors.py
--rw-r--r--   0        0        0      324 2022-04-19 21:38:47.859704 checkthechain-0.3.0/src/ctc/rpc/rpc_digestors/__init__.py
--rw-r--r--   0        0        0     3589 2022-09-17 21:39:28.957164 checkthechain-0.3.0/src/ctc/rpc/rpc_digestors/rpc_block_digestors.py
--rw-r--r--   0        0        0      552 2022-06-27 16:53:05.795512 checkthechain-0.3.0/src/ctc/rpc/rpc_digestors/rpc_dev_digestors.py
--rw-r--r--   0        0        0     3831 2022-09-17 21:38:42.841225 checkthechain-0.3.0/src/ctc/rpc/rpc_digestors/rpc_log_digestors.py
--rw-r--r--   0        0        0      773 2022-06-27 16:53:42.247569 checkthechain-0.3.0/src/ctc/rpc/rpc_digestors/rpc_mining_digestors.py
--rw-r--r--   0        0        0     1465 2022-09-17 21:38:19.733255 checkthechain-0.3.0/src/ctc/rpc/rpc_digestors/rpc_node_digestors.py
--rw-r--r--   0        0        0     1738 2022-09-17 21:28:00.993650 checkthechain-0.3.0/src/ctc/rpc/rpc_digestors/rpc_state_digestors.py
--rw-r--r--   0        0        0     1197 2022-09-17 21:37:41.525303 checkthechain-0.3.0/src/ctc/rpc/rpc_digestors/rpc_submission_digestors.py
--rw-r--r--   0        0        0     2747 2022-09-17 21:28:18.565655 checkthechain-0.3.0/src/ctc/rpc/rpc_digestors/rpc_transaction_digestors.py
--rw-r--r--   0        0        0     1269 2022-06-27 16:55:25.095731 checkthechain-0.3.0/src/ctc/rpc/rpc_digestors/rpc_whisper_digestors.py
--rw-r--r--   0        0        0      291 2022-07-24 17:33:32.656285 checkthechain-0.3.0/src/ctc/rpc/rpc_executors/__init__.py
--rw-r--r--   0        0        0     4397 2022-08-15 22:46:28.703832 checkthechain-0.3.0/src/ctc/rpc/rpc_executors/rpc_block_executors.py
--rw-r--r--   0        0        0     1488 2022-07-24 17:33:32.656285 checkthechain-0.3.0/src/ctc/rpc/rpc_executors/rpc_dev_executors.py
--rw-r--r--   0        0        0     4544 2022-09-17 15:05:01.859233 checkthechain-0.3.0/src/ctc/rpc/rpc_executors/rpc_log_executors.py
--rw-r--r--   0        0        0     2267 2022-07-24 17:33:32.656285 checkthechain-0.3.0/src/ctc/rpc/rpc_executors/rpc_mining_executors.py
--rw-r--r--   0        0        0     2954 2022-07-24 17:33:32.656285 checkthechain-0.3.0/src/ctc/rpc/rpc_executors/rpc_node_executors.py
--rw-r--r--   0        0        0     6070 2022-07-24 17:33:32.656285 checkthechain-0.3.0/src/ctc/rpc/rpc_executors/rpc_state_executors.py
--rw-r--r--   0        0        0     3245 2022-07-24 17:33:32.656285 checkthechain-0.3.0/src/ctc/rpc/rpc_executors/rpc_submission_executors.py
--rw-r--r--   0        0        0      705 2022-07-24 17:33:32.656285 checkthechain-0.3.0/src/ctc/rpc/rpc_executors/rpc_trace_executors.py
--rw-r--r--   0        0        0     4680 2022-07-24 17:33:32.656285 checkthechain-0.3.0/src/ctc/rpc/rpc_executors/rpc_transaction_executors.py
--rw-r--r--   0        0        0     4099 2022-07-24 17:33:32.656285 checkthechain-0.3.0/src/ctc/rpc/rpc_executors/rpc_whisper_executors.py
--rw-r--r--   0        0        0     1068 2022-09-17 21:27:44.953645 checkthechain-0.3.0/src/ctc/rpc/rpc_format.py
--rw-r--r--   0        0        0     2063 2022-07-25 22:52:43.266169 checkthechain-0.3.0/src/ctc/rpc/rpc_lifecycle.py
--rw-r--r--   0        0        0       53 2022-07-24 17:33:32.656285 checkthechain-0.3.0/src/ctc/rpc/rpc_protocols/__init__.py
--rw-r--r--   0        0        0     2443 2022-07-24 17:33:32.656285 checkthechain-0.3.0/src/ctc/rpc/rpc_protocols/rpc_http_async.py
--rw-r--r--   0        0        0      457 2022-07-24 17:33:32.660285 checkthechain-0.3.0/src/ctc/rpc/rpc_protocols/rpc_websocket_async.py
--rw-r--r--   0        0        0     3786 2022-08-30 01:20:28.607373 checkthechain-0.3.0/src/ctc/rpc/rpc_provider.py
--rw-r--r--   0        0        0     1128 2022-07-24 17:33:32.660285 checkthechain-0.3.0/src/ctc/rpc/rpc_registry.py
--rw-r--r--   0        0        0     7391 2022-08-30 21:55:47.553330 checkthechain-0.3.0/src/ctc/rpc/rpc_request.py
--rw-r--r--   0        0        0     3595 2022-07-24 17:33:32.660285 checkthechain-0.3.0/src/ctc/rpc/rpc_spec.py
--rw-r--r--   0        0        0      200 2022-09-18 19:17:26.382062 checkthechain-0.3.0/src/ctc/spec/__init__.py
--rw-r--r--   0        0        0      126 2022-06-21 05:53:42.204949 checkthechain-0.3.0/src/ctc/spec/exceptions/__init__.py
--rw-r--r--   0        0        0       85 2022-07-24 17:33:32.660285 checkthechain-0.3.0/src/ctc/spec/exceptions/abi_exceptions.py
--rw-r--r--   0        0        0      127 2022-07-24 17:33:32.660285 checkthechain-0.3.0/src/ctc/spec/exceptions/config_exceptions.py
--rw-r--r--   0        0        0       87 2022-07-24 17:33:32.660285 checkthechain-0.3.0/src/ctc/spec/exceptions/oracle_exceptions.py
--rw-r--r--   0        0        0      131 2022-06-19 05:20:10.220561 checkthechain-0.3.0/src/ctc/spec/exceptions/rpc_exceptions.py
--rw-r--r--   0        0        0      487 2022-07-24 17:33:32.660285 checkthechain-0.3.0/src/ctc/spec/formatting.py
--rw-r--r--   0        0        0     2434 2022-09-03 02:13:06.137055 checkthechain-0.3.0/src/ctc/spec/typedata.py
--rw-r--r--   0        0        0      337 2022-09-12 00:23:42.287195 checkthechain-0.3.0/src/ctc/spec/typedefs/__init__.py
--rw-r--r--   0        0        0     1858 2022-09-07 20:30:24.632986 checkthechain-0.3.0/src/ctc/spec/typedefs/abi_types.py
--rw-r--r--   0        0        0     1005 2022-06-12 03:33:32.794237 checkthechain-0.3.0/src/ctc/spec/typedefs/address_types.py
--rw-r--r--   0        0        0      948 2022-09-17 15:05:37.879100 checkthechain-0.3.0/src/ctc/spec/typedefs/binary_types.py
--rw-r--r--   0        0        0     2806 2022-09-03 00:00:31.150388 checkthechain-0.3.0/src/ctc/spec/typedefs/block_types.py
--rw-r--r--   0        0        0     1647 2022-07-24 17:33:32.660285 checkthechain-0.3.0/src/ctc/spec/typedefs/config_types.py
--rw-r--r--   0        0        0      552 2022-09-12 02:59:01.485087 checkthechain-0.3.0/src/ctc/spec/typedefs/defi_types.py
--rw-r--r--   0        0        0      745 2022-07-24 17:33:32.660285 checkthechain-0.3.0/src/ctc/spec/typedefs/external_types.py
--rw-r--r--   0        0        0      300 2022-06-20 06:42:01.873864 checkthechain-0.3.0/src/ctc/spec/typedefs/network_types.py
--rw-r--r--   0        0        0      165 2022-07-24 17:33:32.660285 checkthechain-0.3.0/src/ctc/spec/typedefs/number_types.py
--rw-r--r--   0        0        0     2164 2022-08-30 00:57:12.942935 checkthechain-0.3.0/src/ctc/spec/typedefs/rpc_types.py
--rw-r--r--   0        0        0      671 2022-07-24 17:33:32.660285 checkthechain-0.3.0/src/ctc/spec/typedefs/storage_types.py
--rw-r--r--   0        0        0     2665 2022-09-03 00:09:56.467954 checkthechain-0.3.0/src/ctc/spec/typedefs/transaction_types.py
--rw-r--r--   0        0        0      100 2022-02-08 17:43:17.148036 checkthechain-0.3.0/src/ctc/spec/typeguards/__init__.py
--rw-r--r--   0        0        0     1637 2022-09-21 04:02:10.486479 checkthechain-0.3.0/src/ctc/spec/typeguards/binary_typeguards.py
--rw-r--r--   0        0        0     1708 2022-09-21 04:03:38.294229 checkthechain-0.3.0/src/ctc/spec/typeguards/block_typeguards.py
--rw-r--r--   0        0        0     1098 2022-09-21 04:04:34.430068 checkthechain-0.3.0/src/ctc/spec/typeguards/external_typeguards.py
--rw-r--r--   0        0        0        0 2022-02-08 17:43:17.148036 checkthechain-0.3.0/src/ctc/toolbox/__init__.py
--rw-r--r--   0        0        0     6064 2022-09-23 03:28:48.677576 checkthechain-0.3.0/src/ctc/toolbox/async_utils.py
--rw-r--r--   0        0        0       62 2022-07-24 17:33:32.660285 checkthechain-0.3.0/src/ctc/toolbox/backend_utils/__init__.py
--rw-r--r--   0        0        0     3816 2022-08-30 00:52:33.783546 checkthechain-0.3.0/src/ctc/toolbox/backend_utils/backend_crud.py
--rw-r--r--   0        0        0       77 2022-07-24 17:33:32.660285 checkthechain-0.3.0/src/ctc/toolbox/backend_utils/backend_exceptions.py
--rw-r--r--   0        0        0        1 2022-04-03 18:45:45.360047 checkthechain-0.3.0/src/ctc/toolbox/defi_utils/__init__.py
--rw-r--r--   0        0        0      622 2022-06-11 03:50:34.135722 checkthechain-0.3.0/src/ctc/toolbox/defi_utils/cex_utils.py
--rw-r--r--   0        0        0       21 2022-08-08 05:56:45.614646 checkthechain-0.3.0/src/ctc/toolbox/defi_utils/dex_utils/__init__.py
--rw-r--r--   0        0        0        0 2022-02-08 17:43:17.148036 checkthechain-0.3.0/src/ctc/toolbox/defi_utils/dex_utils/amm_utils/__init__.py
--rw-r--r--   0        0        0     1056 2022-07-24 17:33:32.660285 checkthechain-0.3.0/src/ctc/toolbox/defi_utils/dex_utils/amm_utils/amm_spec.py
--rw-r--r--   0        0        0       84 2022-02-08 17:43:17.148036 checkthechain-0.3.0/src/ctc/toolbox/defi_utils/dex_utils/amm_utils/cpmm/__init__.py
--rw-r--r--   0        0        0     2901 2022-06-27 08:24:44.891759 checkthechain-0.3.0/src/ctc/toolbox/defi_utils/dex_utils/amm_utils/cpmm/cpmm_liquidity.py
--rw-r--r--   0        0        0     1111 2022-07-24 17:33:32.660285 checkthechain-0.3.0/src/ctc/toolbox/defi_utils/dex_utils/amm_utils/cpmm/cpmm_spec.py
--rw-r--r--   0        0        0     9425 2022-09-14 05:05:29.881450 checkthechain-0.3.0/src/ctc/toolbox/defi_utils/dex_utils/amm_utils/cpmm/cpmm_summary.py
--rw-r--r--   0        0        0     7433 2022-07-24 17:33:32.660285 checkthechain-0.3.0/src/ctc/toolbox/defi_utils/dex_utils/amm_utils/cpmm/cpmm_trade.py
--rw-r--r--   0        0        0       37 2022-04-13 19:11:23.162835 checkthechain-0.3.0/src/ctc/toolbox/defi_utils/dex_utils/amm_utils/stableswap/__init__.py
--rw-r--r--   0        0        0      333 2022-07-24 17:33:32.660285 checkthechain-0.3.0/src/ctc/toolbox/defi_utils/dex_utils/amm_utils/stableswap/stableswap_operations.py
--rw-r--r--   0        0        0      151 2022-09-11 18:19:54.411697 checkthechain-0.3.0/src/ctc/toolbox/defi_utils/dex_utils/dexes/__init__.py
--rw-r--r--   0        0        0    23068 2022-09-17 05:48:17.592400 checkthechain-0.3.0/src/ctc/toolbox/defi_utils/dex_utils/dexes/dex_class.py
--rw-r--r--   0        0        0     3708 2022-09-21 04:08:05.997456 checkthechain-0.3.0/src/ctc/toolbox/defi_utils/dex_utils/dexes/dex_class_utils.py
--rw-r--r--   0        0        0     1358 2022-09-11 04:25:39.145003 checkthechain-0.3.0/src/ctc/toolbox/defi_utils/dex_utils/dexes/dex_directory.py
--rw-r--r--   0        0        0      145 2022-09-12 00:42:11.003666 checkthechain-0.3.0/src/ctc/toolbox/defi_utils/dex_utils/dexes/dex_functions/__init__.py
--rw-r--r--   0        0        0     3407 2022-09-11 05:35:58.718171 checkthechain-0.3.0/src/ctc/toolbox/defi_utils/dex_utils/dexes/dex_functions/dex_balance_functions.py
--rw-r--r--   0        0        0     1635 2022-09-21 04:09:45.805165 checkthechain-0.3.0/src/ctc/toolbox/defi_utils/dex_utils/dexes/dex_functions/dex_metadata_functions.py
--rw-r--r--   0        0        0     2261 2022-09-21 04:09:19.865241 checkthechain-0.3.0/src/ctc/toolbox/defi_utils/dex_utils/dexes/dex_functions/dex_pools_functions.py
--rw-r--r--   0        0        0     1624 2022-09-21 04:08:30.445385 checkthechain-0.3.0/src/ctc/toolbox/defi_utils/dex_utils/dexes/dex_functions/dex_trade_functions.py
--rw-r--r--   0        0        0      184 2022-09-11 18:19:33.119753 checkthechain-0.3.0/src/ctc/toolbox/defi_utils/dex_utils/dexes/dex_implementations/__init__.py
--rw-r--r--   0        0        0     6485 2022-09-21 04:06:10.913790 checkthechain-0.3.0/src/ctc/toolbox/defi_utils/dex_utils/dexes/dex_implementations/balancer_dex.py
--rw-r--r--   0        0        0     7777 2022-09-21 04:06:19.441765 checkthechain-0.3.0/src/ctc/toolbox/defi_utils/dex_utils/dexes/dex_implementations/curve_dex.py
--rw-r--r--   0        0        0      207 2022-09-21 04:06:46.173688 checkthechain-0.3.0/src/ctc/toolbox/defi_utils/dex_utils/dexes/dex_implementations/sushi_dex.py
--rw-r--r--   0        0        0     4645 2022-09-21 04:06:59.289650 checkthechain-0.3.0/src/ctc/toolbox/defi_utils/dex_utils/dexes/dex_implementations/uniswap_v2_dex.py
--rw-r--r--   0        0        0     4347 2022-09-21 04:07:06.997628 checkthechain-0.3.0/src/ctc/toolbox/defi_utils/dex_utils/dexes/dex_implementations/uniswap_v3_dex.py
--rw-r--r--   0        0        0       31 2022-02-18 07:13:08.729767 checkthechain-0.3.0/src/ctc/toolbox/defi_utils/lending_utils/__init__.py
--rw-r--r--   0        0        0     7727 2022-08-16 00:08:27.749962 checkthechain-0.3.0/src/ctc/toolbox/defi_utils/lending_utils/lending_summary.py
--rw-r--r--   0        0        0     1995 2022-09-12 06:03:47.553557 checkthechain-0.3.0/src/ctc/toolbox/defi_utils/ohlc_utils.py
--rw-r--r--   0        0        0      346 2022-03-14 23:48:10.133764 checkthechain-0.3.0/src/ctc/toolbox/defi_utils/twap_utils/README.md
--rw-r--r--   0        0        0      103 2022-07-24 17:33:32.660285 checkthechain-0.3.0/src/ctc/toolbox/defi_utils/twap_utils/__init__.py
--rw-r--r--   0        0        0     4133 2022-07-24 17:33:32.660285 checkthechain-0.3.0/src/ctc/toolbox/defi_utils/twap_utils/feed_utils.py
--rw-r--r--   0        0        0     2900 2022-06-29 02:40:30.131895 checkthechain-0.3.0/src/ctc/toolbox/defi_utils/twap_utils/twap_crud.py
--rw-r--r--   0        0        0      946 2022-06-27 08:21:49.472892 checkthechain-0.3.0/src/ctc/toolbox/defi_utils/twap_utils/twap_data.py
--rw-r--r--   0        0        0     2657 2022-07-24 17:33:32.660285 checkthechain-0.3.0/src/ctc/toolbox/defi_utils/twap_utils/twap_data_sources.py
--rw-r--r--   0        0        0     1267 2022-07-24 17:33:32.660285 checkthechain-0.3.0/src/ctc/toolbox/defi_utils/twap_utils/twap_filter.py
--rw-r--r--   0        0        0      384 2022-07-24 17:33:32.660285 checkthechain-0.3.0/src/ctc/toolbox/defi_utils/twap_utils/twap_spec.py
--rw-r--r--   0        0        0       34 2022-02-08 17:43:17.148036 checkthechain-0.3.0/src/ctc/toolbox/filesystem_utils/__init__.py
--rw-r--r--   0        0        0      531 2022-05-24 07:14:22.546241 checkthechain-0.3.0/src/ctc/toolbox/filesystem_utils/filesystem_dirsize.py
--rw-r--r--   0        0        0     1441 2022-08-30 00:51:06.295738 checkthechain-0.3.0/src/ctc/toolbox/nested_utils.py
--rw-r--r--   0        0        0       63 2022-04-21 23:26:19.680738 checkthechain-0.3.0/src/ctc/toolbox/optimize_utils/__init__.py
--rw-r--r--   0        0        0     3288 2022-07-24 17:33:32.660285 checkthechain-0.3.0/src/ctc/toolbox/optimize_utils/async_search.py
--rw-r--r--   0        0        0       80 2022-07-24 17:33:32.660285 checkthechain-0.3.0/src/ctc/toolbox/optimize_utils/optimize_exceptions.py
--rw-r--r--   0        0        0       73 2022-07-24 17:33:32.660285 checkthechain-0.3.0/src/ctc/toolbox/pd_utils/__init__.py
--rw-r--r--   0        0        0     3527 2022-07-24 17:33:32.664285 checkthechain-0.3.0/src/ctc/toolbox/pd_utils/pandas_interpolate_utils.py
--rw-r--r--   0        0        0     3740 2022-08-30 01:13:40.020705 checkthechain-0.3.0/src/ctc/toolbox/pd_utils/pandas_time_utils.py
--rw-r--r--   0        0        0       33 2022-07-24 17:33:32.664285 checkthechain-0.3.0/src/ctc/toolbox/plot_utils/__init__.py
--rw-r--r--   0        0        0     3538 2022-08-30 00:51:30.039686 checkthechain-0.3.0/src/ctc/toolbox/plot_utils/plot_format_utils.py
--rw-r--r--   0        0        0     9045 2022-08-30 00:51:42.975658 checkthechain-0.3.0/src/ctc/toolbox/search_utils.py
--rw-r--r--   0        0        0     1515 2022-08-30 00:52:21.383574 checkthechain-0.3.0/src/ctc/toolbox/validate_utils.py
--rw-r--r--   0        0        0      533 2022-07-24 17:33:32.664285 checkthechain-0.3.0/tests/conftest.py
--rw-r--r--   0        0        0    20988 2022-02-08 18:37:56.639193 checkthechain-0.3.0/tests/ctc/binary/.hypothesis/unicode_data/13.0.0/charmap.json.gz
--rw-r--r--   0        0        0      789 2022-09-17 21:50:46.452071 checkthechain-0.3.0/tests/ctc/binary/test_eip712.py
--rw-r--r--   0        0        0     1224 2022-09-17 21:51:28.907995 checkthechain-0.3.0/tests/ctc/binary/test_format_utils.py
--rw-r--r--   0        0        0      795 2022-09-17 21:51:41.699972 checkthechain-0.3.0/tests/ctc/binary/test_hash_utils.py
--rw-r--r--   0        0        0     4002 2022-09-17 21:52:09.155922 checkthechain-0.3.0/tests/ctc/binary/test_rlp_encoding.py
--rw-r--r--   0        0        0     4888 2022-09-17 21:52:40.115866 checkthechain-0.3.0/tests/ctc/binary/test_signatures.py
--rw-r--r--   0        0        0     1702 2022-09-14 07:07:37.445283 checkthechain-0.3.0/tests/ctc/cli/test_cli_args.py
--rw-r--r--   0        0        0     3589 2022-09-25 04:13:35.273965 checkthechain-0.3.0/tests/ctc/cli/test_cli_subcommands.py
--rw-r--r--   0        0        0      620 2022-06-23 05:14:34.944916 checkthechain-0.3.0/tests/ctc/config/test_config_defaults.py
--rw-r--r--   0        0        0     4399 2022-08-30 05:10:29.023862 checkthechain-0.3.0/tests/ctc/config/test_config_validators.py
--rw-r--r--   0        0        0     9609 2022-07-25 23:34:36.027069 checkthechain-0.3.0/tests/ctc/config/test_setup.py
--rw-r--r--   0        0        0     3937 2022-07-24 17:33:32.664285 checkthechain-0.3.0/tests/ctc/db/db_crud/test_db_block_timestamps.py
--rw-r--r--   0        0        0     5650 2022-07-24 17:33:32.664285 checkthechain-0.3.0/tests/ctc/db/db_crud/test_db_blocks.py
--rw-r--r--   0        0        0     2792 2022-07-24 17:33:32.664285 checkthechain-0.3.0/tests/ctc/db/db_crud/test_db_contract_abis.py
--rw-r--r--   0        0        0     2086 2022-07-24 17:33:32.664285 checkthechain-0.3.0/tests/ctc/db/db_crud/test_db_contract_creation.py
--rw-r--r--   0        0        0     3453 2022-06-11 00:33:18.084530 checkthechain-0.3.0/tests/ctc/db/db_crud/test_db_erc20_metadata.py
--rw-r--r--   0        0        0      446 2022-06-12 06:40:35.034871 checkthechain-0.3.0/tests/ctc/db/db_schemas.py
--rw-r--r--   0        0        0     1231 2022-06-12 06:35:24.672225 checkthechain-0.3.0/tests/ctc/db/dba_utils.py
--rw-r--r--   0        0        0    10495 2022-08-15 21:34:53.847842 checkthechain-0.3.0/tests/ctc/db/test_crud_problems.py
--rw-r--r--   0        0        0    20988 2022-02-08 18:22:56.572023 checkthechain-0.3.0/tests/ctc/directory/.hypothesis/unicode_data/13.0.0/charmap.json.gz
--rw-r--r--   0        0        0     1272 2022-08-30 05:11:18.749686 checkthechain-0.3.0/tests/ctc/directory/test_directory_networks.py
--rw-r--r--   0        0        0      588 2022-06-30 00:58:30.003217 checkthechain-0.3.0/tests/ctc/directory/test_directory_tokens.py
--rw-r--r--   0        0        0     1322 2022-09-17 22:17:50.133000 checkthechain-0.3.0/tests/ctc/docs/test_readme_examples.py
--rw-r--r--   0        0        0    20988 2022-02-08 18:38:56.641815 checkthechain-0.3.0/tests/ctc/evm/.hypothesis/unicode_data/13.0.0/charmap.json.gz
--rw-r--r--   0        0        0     3757 2022-09-17 04:40:22.909624 checkthechain-0.3.0/tests/ctc/evm/test_address_utils.py
--rw-r--r--   0        0        0     2964 2022-07-24 17:33:32.664285 checkthechain-0.3.0/tests/ctc/evm/test_block_utils.py
--rw-r--r--   0        0        0      600 2022-07-24 20:47:39.957669 checkthechain-0.3.0/tests/ctc/evm/test_erc20_utils/test_erc20_events.py
--rw-r--r--   0        0        0      588 2022-07-24 17:33:32.664285 checkthechain-0.3.0/tests/ctc/evm/test_erc20_utils/test_erc20_metadata.py
--rw-r--r--   0        0        0      650 2022-08-16 00:13:09.404842 checkthechain-0.3.0/tests/ctc/evm/test_erc20_utils/test_erc20_state.py
--rw-r--r--   0        0        0      500 2022-05-06 03:54:52.294289 checkthechain-0.3.0/tests/ctc/evm/test_eth_utils.py
--rw-r--r--   0        0        0      755 2022-07-24 20:47:39.957669 checkthechain-0.3.0/tests/ctc/evm/test_event_utils.py
--rw-r--r--   0        0        0    20988 2022-02-08 18:58:08.924030 checkthechain-0.3.0/tests/ctc/evm/test_rpc_utils/.hypothesis/unicode_data/13.0.0/charmap.json.gz
--rw-r--r--   0        0        0     1690 2022-07-24 17:33:32.664285 checkthechain-0.3.0/tests/ctc/evm/test_rpc_utils/test_rpc_blocks.py
--rw-r--r--   0        0        0     1981 2022-07-24 17:33:32.664285 checkthechain-0.3.0/tests/ctc/evm/test_rpc_utils/test_rpc_logs.py
--rw-r--r--   0        0        0     1065 2022-09-17 21:53:06.943817 checkthechain-0.3.0/tests/ctc/evm/test_rpc_utils/test_rpc_node.py
--rw-r--r--   0        0        0     5693 2022-07-24 17:33:32.664285 checkthechain-0.3.0/tests/ctc/evm/test_rpc_utils/test_rpc_state.py
--rw-r--r--   0        0        0      304 2022-07-24 17:33:32.664285 checkthechain-0.3.0/tests/ctc/evm/test_rpc_utils/test_rpc_submission.py
--rw-r--r--   0        0        0     2185 2022-07-24 17:33:32.664285 checkthechain-0.3.0/tests/ctc/evm/test_rpc_utils/test_rpc_transactions.py
--rw-r--r--   0        0        0     3666 2022-09-14 08:02:52.656520 checkthechain-0.3.0/tests/ctc/evm/test_transaction_utils/test_transaction_utils.py
--rw-r--r--   0        0        0      915 2022-07-24 17:33:32.664285 checkthechain-0.3.0/tests/ctc/protocols/balancer_utils/test_balancer_utils.py
--rw-r--r--   0        0        0     3378 2022-07-24 17:33:32.664285 checkthechain-0.3.0/tests/ctc/protocols/chainlink_utils/test_chainlink_db.py
--rw-r--r--   0        0        0     1471 2022-07-24 17:33:32.664285 checkthechain-0.3.0/tests/ctc/protocols/fei_utils/test_fei_collateralization_oracle.py
--rw-r--r--   0        0        0     3276 2022-06-13 01:05:33.900359 checkthechain-0.3.0/tests/ctc/protocols/fourbyte_utils/test_fourbyte_db.py
--rw-r--r--   0        0        0      668 2022-07-24 17:33:32.664285 checkthechain-0.3.0/tests/ctc/protocols/uniswap_v2_utils/test_uniswap_queries.py
--rw-r--r--   0        0        0      456 2022-08-29 23:39:13.124979 checkthechain-0.3.0/tests/ctc/spec/test_typedata.py
--rw-r--r--   0        0        0      564 2022-08-30 05:12:12.701375 checkthechain-0.3.0/tests/ctc/spec/test_typedefs.py
--rw-r--r--   0        0        0    10342 2022-09-21 04:33:52.784000 checkthechain-0.3.0/tests/ctc/test_code.py
--rw-r--r--   0        0        0     2018 2022-07-24 17:33:32.664285 checkthechain-0.3.0/tests/ctc/test_config.py
--rw-r--r--   0        0        0      702 2022-08-09 07:49:34.360758 checkthechain-0.3.0/tests/ctc/toolbox/defi_utils/defi_directory.py
--rw-r--r--   0        0        0     4182 2022-09-11 02:57:50.415065 checkthechain-0.3.0/tests/ctc/toolbox/defi_utils/dex_utils.py
--rw-r--r--   0        0        0     5143 2022-07-28 23:36:47.548741 checkthechain-0.3.0/tests/ctc/toolbox/test_amm_utils.py
--rw-r--r--   0        0        0      651 2022-07-24 17:33:32.664285 checkthechain-0.3.0/tests/ctc/toolbox/test_feed_utils.py
--rwxr-xr-x   0        0        0      231 2022-04-20 02:51:57.693040 checkthechain-0.3.0/tests/run_type_checks.sh
--rw-r--r--   0        0        0     9683 1970-01-01 00:00:00.000000 checkthechain-0.3.0/PKG-INFO
+-rw-r--r--   0        0        0      217 2023-02-26 18:21:06.927738 checkthechain-0.3.4/.gitignore
+-rw-r--r--   0        0        0     8294 2023-02-26 18:21:06.927914 checkthechain-0.3.4/CHANGELOG.md
+-rw-r--r--   0        0        0     3117 2023-04-11 03:46:56.460577 checkthechain-0.3.4/CONTRIBUTING.md
+-rw-r--r--   0        0        0    11357 2023-02-26 18:21:06.928214 checkthechain-0.3.4/LICENSE-APACHE
+-rw-r--r--   0        0        0     1093 2023-02-26 18:21:06.928570 checkthechain-0.3.4/LICENSE-MIT
+-rw-r--r--   0        0        0     7487 2023-02-26 18:21:06.928884 checkthechain-0.3.4/README.md
+-rw-r--r--   0        0        0       52 2022-11-23 19:36:31.097613 checkthechain-0.3.4/docs/README.md
+-rw-r--r--   0        0        0     1167 2023-02-26 18:21:06.929180 checkthechain-0.3.4/docs/contributing_guides/adding_config_keys.md
+-rw-r--r--   0        0        0      797 2023-02-26 18:21:06.929401 checkthechain-0.3.4/docs/contributing_guides/adding_db_caches.md
+-rw-r--r--   0        0        0      243 2023-02-26 18:21:06.929558 checkthechain-0.3.4/docs/contributing_guides/upgrade_to_new_ctc_version.md
+-rw-r--r--   0        0        0     4438 2023-06-06 00:15:39.725055 checkthechain-0.3.4/pyproject.toml
+-rw-r--r--   0        0        0      566 2023-04-29 01:37:54.115295 checkthechain-0.3.4/src/ctc/__init__.py
+-rw-r--r--   0        0        0       35 2022-11-23 19:36:31.097865 checkthechain-0.3.4/src/ctc/__main__.py
+-rw-r--r--   0        0        0       97 2023-02-26 18:21:06.930730 checkthechain-0.3.4/src/ctc/cli/__init__.py
+-rw-r--r--   0        0        0    12631 2023-04-11 16:22:47.887085 checkthechain-0.3.4/src/ctc/cli/cli_run.py
+-rw-r--r--   0        0        0      193 2023-02-26 18:21:06.931328 checkthechain-0.3.4/src/ctc/cli/cli_utils/__init__.py
+-rw-r--r--   0        0        0     9052 2022-11-23 19:36:31.098221 checkthechain-0.3.4/src/ctc/cli/cli_utils/cli_alias_utils.py
+-rw-r--r--   0        0        0     8508 2023-02-26 18:21:06.931449 checkthechain-0.3.4/src/ctc/cli/cli_utils/cli_charset_utils.py
+-rw-r--r--   0        0        0     8581 2023-04-17 00:55:51.315895 checkthechain-0.3.4/src/ctc/cli/cli_utils/cli_color_utils.py
+-rw-r--r--   0        0        0      612 2022-11-23 19:36:31.098462 checkthechain-0.3.4/src/ctc/cli/cli_utils/cli_execution_utils.py
+-rw-r--r--   0        0        0     2308 2023-04-11 03:44:53.034908 checkthechain-0.3.4/src/ctc/cli/cli_utils/cli_output_utils.py
+-rw-r--r--   0        0        0     9184 2023-05-09 04:20:26.327124 checkthechain-0.3.4/src/ctc/cli/cli_utils/cli_parse_utils.py
+-rw-r--r--   0        0        0        0 2022-11-23 19:36:31.098735 checkthechain-0.3.4/src/ctc/cli/commands/__init__.py
+-rw-r--r--   0        0        0        0 2022-11-23 19:36:31.098821 checkthechain-0.3.4/src/ctc/cli/commands/admin/__init__.py
+-rw-r--r--   0        0        0     1952 2022-11-23 19:36:31.098935 checkthechain-0.3.4/src/ctc/cli/commands/admin/aliases_command.py
+-rw-r--r--   0        0        0     2569 2022-11-23 19:36:31.099038 checkthechain-0.3.4/src/ctc/cli/commands/admin/chains_command.py
+-rw-r--r--   0        0        0      939 2023-02-26 18:21:06.932612 checkthechain-0.3.4/src/ctc/cli/commands/admin/charset_command.py
+-rw-r--r--   0        0        0     2796 2023-02-26 18:21:06.932700 checkthechain-0.3.4/src/ctc/cli/commands/admin/color_command.py
+-rw-r--r--   0        0        0        0 2022-11-23 19:36:31.099306 checkthechain-0.3.4/src/ctc/cli/commands/admin/config/__init__.py
+-rw-r--r--   0        0        0     1231 2023-02-26 18:21:06.932846 checkthechain-0.3.4/src/ctc/cli/commands/admin/config/edit_command.py
+-rw-r--r--   0        0        0      341 2022-11-23 19:36:31.099535 checkthechain-0.3.4/src/ctc/cli/commands/admin/config/path_command.py
+-rw-r--r--   0        0        0    11615 2023-05-09 03:03:31.696453 checkthechain-0.3.4/src/ctc/cli/commands/admin/config_command.py
+-rw-r--r--   0        0        0        0 2022-11-23 19:36:31.099729 checkthechain-0.3.4/src/ctc/cli/commands/admin/db/__init__.py
+-rw-r--r--   0        0        0     1310 2023-02-26 21:00:17.933995 checkthechain-0.3.4/src/ctc/cli/commands/admin/db/create_tables_command.py
+-rw-r--r--   0        0        0     1410 2023-02-26 20:15:07.407580 checkthechain-0.3.4/src/ctc/cli/commands/admin/db/drop_command.py
+-rw-r--r--   0        0        0      370 2023-04-12 04:04:05.737647 checkthechain-0.3.4/src/ctc/cli/commands/admin/db/login_command.py
+-rw-r--r--   0        0        0     4772 2023-04-26 23:18:25.231255 checkthechain-0.3.4/src/ctc/cli/commands/admin/db/status_command.py
+-rw-r--r--   0        0        0      858 2022-11-23 19:36:31.100027 checkthechain-0.3.4/src/ctc/cli/commands/admin/log_command.py
+-rw-r--r--   0        0        0     3184 2022-11-23 19:36:31.100197 checkthechain-0.3.4/src/ctc/cli/commands/admin/setup_command.py
+-rw-r--r--   0        0        0        0 2022-11-23 19:36:31.100283 checkthechain-0.3.4/src/ctc/cli/commands/compute/__init__.py
+-rw-r--r--   0        0        0      491 2022-11-23 19:36:31.100403 checkthechain-0.3.4/src/ctc/cli/commands/compute/ascii_command.py
+-rw-r--r--   0        0        0      530 2022-11-23 19:36:31.100502 checkthechain-0.3.4/src/ctc/cli/commands/compute/checksum_command.py
+-rw-r--r--   0        0        0     1202 2022-11-23 19:36:31.100601 checkthechain-0.3.4/src/ctc/cli/commands/compute/create_address_command.py
+-rw-r--r--   0        0        0    13751 2023-04-11 16:58:47.041829 checkthechain-0.3.4/src/ctc/cli/commands/compute/decode_call_command.py
+-rw-r--r--   0        0        0      965 2023-04-11 16:55:27.846437 checkthechain-0.3.4/src/ctc/cli/commands/compute/decode_command.py
+-rw-r--r--   0        0        0     1482 2023-04-11 16:55:12.443123 checkthechain-0.3.4/src/ctc/cli/commands/compute/encode_command.py
+-rw-r--r--   0        0        0      760 2022-11-23 19:36:31.100956 checkthechain-0.3.4/src/ctc/cli/commands/compute/hex_command.py
+-rw-r--r--   0        0        0      509 2022-11-23 19:36:31.101019 checkthechain-0.3.4/src/ctc/cli/commands/compute/integer_command.py
+-rw-r--r--   0        0        0     1618 2022-11-23 19:36:31.101088 checkthechain-0.3.4/src/ctc/cli/commands/compute/keccak_command.py
+-rw-r--r--   0        0        0     4730 2022-11-23 19:36:31.101172 checkthechain-0.3.4/src/ctc/cli/commands/compute/limits_command.py
+-rw-r--r--   0        0        0      436 2022-11-23 19:36:31.101239 checkthechain-0.3.4/src/ctc/cli/commands/compute/lower_command.py
+-rw-r--r--   0        0        0      993 2022-11-23 19:36:31.101312 checkthechain-0.3.4/src/ctc/cli/commands/compute/rlp_encode.py
+-rw-r--r--   0        0        0      720 2022-11-23 19:36:31.101376 checkthechain-0.3.4/src/ctc/cli/commands/compute/selector_command.py
+-rw-r--r--   0        0        0        0 2022-11-23 19:36:31.101442 checkthechain-0.3.4/src/ctc/cli/commands/data/__init__.py
+-rw-r--r--   0        0        0     6408 2023-02-26 18:21:06.935201 checkthechain-0.3.4/src/ctc/cli/commands/data/abi_command.py
+-rw-r--r--   0        0        0     1506 2022-11-23 19:36:31.101616 checkthechain-0.3.4/src/ctc/cli/commands/data/abi_diff_command.py
+-rw-r--r--   0        0        0     1454 2023-02-26 18:21:06.935512 checkthechain-0.3.4/src/ctc/cli/commands/data/address_command.py
+-rw-r--r--   0        0        0     2532 2023-01-07 08:13:49.926885 checkthechain-0.3.4/src/ctc/cli/commands/data/address_txs_command.py
+-rw-r--r--   0        0        0     2593 2023-02-26 18:21:06.935644 checkthechain-0.3.4/src/ctc/cli/commands/data/block_command.py
+-rw-r--r--   0        0        0     5173 2023-04-11 03:48:25.322507 checkthechain-0.3.4/src/ctc/cli/commands/data/blocks_command.py
+-rw-r--r--   0        0        0      634 2022-11-23 19:36:31.101982 checkthechain-0.3.4/src/ctc/cli/commands/data/bytecode_command.py
+-rw-r--r--   0        0        0     4642 2023-03-18 06:34:21.816682 checkthechain-0.3.4/src/ctc/cli/commands/data/call_all_command.py
+-rw-r--r--   0        0        0     3224 2022-11-23 19:36:31.102138 checkthechain-0.3.4/src/ctc/cli/commands/data/call_command.py
+-rw-r--r--   0        0        0    23122 2023-04-12 16:08:53.179783 checkthechain-0.3.4/src/ctc/cli/commands/data/calls_command.py
+-rw-r--r--   0        0        0     2927 2023-02-26 18:21:06.936911 checkthechain-0.3.4/src/ctc/cli/commands/data/chain_command.py
+-rw-r--r--   0        0        0     4207 2023-02-26 18:21:06.937286 checkthechain-0.3.4/src/ctc/cli/commands/data/decompile_command.py
+-rw-r--r--   0        0        0        0 2022-11-23 19:36:31.102575 checkthechain-0.3.4/src/ctc/cli/commands/data/dex/__init__.py
+-rw-r--r--   0        0        0     6890 2023-04-15 16:03:33.976343 checkthechain-0.3.4/src/ctc/cli/commands/data/dex/chart_command.py
+-rw-r--r--   0        0        0     4813 2023-04-15 16:00:40.959584 checkthechain-0.3.4/src/ctc/cli/commands/data/dex/pool_command.py
+-rw-r--r--   0        0        0     8639 2023-04-15 16:00:02.454511 checkthechain-0.3.4/src/ctc/cli/commands/data/dex/pools_command.py
+-rw-r--r--   0        0        0     4354 2023-04-15 15:43:58.809999 checkthechain-0.3.4/src/ctc/cli/commands/data/dex/trades_command.py
+-rw-r--r--   0        0        0        0 2022-11-23 19:36:31.103150 checkthechain-0.3.4/src/ctc/cli/commands/data/erc20/__init__.py
+-rw-r--r--   0        0        0     1603 2022-11-23 19:36:31.103246 checkthechain-0.3.4/src/ctc/cli/commands/data/erc20/balance_command.py
+-rw-r--r--   0        0        0     9969 2023-04-11 03:56:24.764985 checkthechain-0.3.4/src/ctc/cli/commands/data/erc20/balances_command.py
+-rw-r--r--   0        0        0     1947 2023-04-10 04:18:22.101055 checkthechain-0.3.4/src/ctc/cli/commands/data/erc20/transfers_command.py
+-rw-r--r--   0        0        0      881 2022-11-23 19:36:31.103509 checkthechain-0.3.4/src/ctc/cli/commands/data/erc20_command.py
+-rw-r--r--   0        0        0        0 2022-11-23 19:36:31.103574 checkthechain-0.3.4/src/ctc/cli/commands/data/eth/__init__.py
+-rw-r--r--   0        0        0     1334 2022-11-23 19:36:31.103652 checkthechain-0.3.4/src/ctc/cli/commands/data/eth/balance_command.py
+-rw-r--r--   0        0        0     7719 2023-04-12 23:11:07.611640 checkthechain-0.3.4/src/ctc/cli/commands/data/eth/balances_command.py
+-rw-r--r--   0        0        0     3653 2023-04-11 05:49:15.694208 checkthechain-0.3.4/src/ctc/cli/commands/data/events_command.py
+-rw-r--r--   0        0        0    11909 2023-04-14 03:52:55.753011 checkthechain-0.3.4/src/ctc/cli/commands/data/gas_command.py
+-rw-r--r--   0        0        0     2520 2022-11-23 19:36:31.104030 checkthechain-0.3.4/src/ctc/cli/commands/data/proxy_command.py
+-rw-r--r--   0        0        0     2597 2023-02-26 18:21:06.939031 checkthechain-0.3.4/src/ctc/cli/commands/data/proxy_register_command.py
+-rw-r--r--   0        0        0     1478 2023-04-11 17:03:09.850892 checkthechain-0.3.4/src/ctc/cli/commands/data/storage_command.py
+-rw-r--r--   0        0        0      850 2022-11-23 19:36:31.104247 checkthechain-0.3.4/src/ctc/cli/commands/data/symbol_command.py
+-rw-r--r--   0        0        0     1450 2022-11-23 19:36:31.104314 checkthechain-0.3.4/src/ctc/cli/commands/data/timestamp_command.py
+-rw-r--r--   0        0        0     2050 2023-02-26 18:21:06.939163 checkthechain-0.3.4/src/ctc/cli/commands/data/tx_command.py
+-rw-r--r--   0        0        0     2813 2022-11-23 19:36:31.104457 checkthechain-0.3.4/src/ctc/cli/commands/root_command.py
+-rw-r--r--   0        0        0      226 2023-02-26 18:21:06.939627 checkthechain-0.3.4/src/ctc/config/__init__.py
+-rw-r--r--   0        0        0     6947 2023-04-26 23:49:08.151324 checkthechain-0.3.4/src/ctc/config/config_defaults.py
+-rw-r--r--   0        0        0     3987 2023-02-26 18:21:06.940408 checkthechain-0.3.4/src/ctc/config/config_env_vars.py
+-rw-r--r--   0        0        0      687 2023-02-26 18:21:06.940691 checkthechain-0.3.4/src/ctc/config/config_overrides.py
+-rw-r--r--   0        0        0     4267 2023-04-17 00:26:09.800618 checkthechain-0.3.4/src/ctc/config/config_read.py
+-rw-r--r--   0        0        0      375 2023-02-26 18:21:06.941204 checkthechain-0.3.4/src/ctc/config/config_spec.py
+-rw-r--r--   0        0        0    11474 2023-04-27 04:45:26.239328 checkthechain-0.3.4/src/ctc/config/config_validate.py
+-rw-r--r--   0        0        0     4912 2023-04-17 01:15:59.426408 checkthechain-0.3.4/src/ctc/config/config_values.py
+-rw-r--r--   0        0        0     1236 2023-04-17 00:11:55.733936 checkthechain-0.3.4/src/ctc/config/config_write.py
+-rw-r--r--   0        0        0      121 2023-02-26 18:21:06.942475 checkthechain-0.3.4/src/ctc/config/context_utils/__init__.py
+-rw-r--r--   0        0        0     7359 2023-04-11 22:37:33.866053 checkthechain-0.3.4/src/ctc/config/context_utils/context_caches.py
+-rw-r--r--   0        0        0     1944 2023-02-26 18:21:06.943080 checkthechain-0.3.4/src/ctc/config/context_utils/context_crud.py
+-rw-r--r--   0        0        0     3118 2023-04-10 23:34:05.929913 checkthechain-0.3.4/src/ctc/config/context_utils/context_sources.py
+-rw-r--r--   0        0        0      506 2023-02-26 18:21:06.943482 checkthechain-0.3.4/src/ctc/config/context_utils/context_validate.py
+-rw-r--r--   0        0        0       26 2022-11-23 19:36:31.105507 checkthechain-0.3.4/src/ctc/config/setup_utils/__init__.py
+-rw-r--r--   0        0        0        0 2022-11-23 19:36:31.105567 checkthechain-0.3.4/src/ctc/config/setup_utils/default_data/__init__.py
+-rw-r--r--   0        0        0   142771 2023-04-12 02:21:19.579767 checkthechain-0.3.4/src/ctc/config/setup_utils/default_data/default_erc20s.py
+-rw-r--r--   0        0        0     3629 2023-04-27 01:46:49.405189 checkthechain-0.3.4/src/ctc/config/setup_utils/main_setup.py
+-rw-r--r--   0        0        0     7383 2023-04-17 00:15:05.747317 checkthechain-0.3.4/src/ctc/config/setup_utils/setup_io.py
+-rw-r--r--   0        0        0        0 2022-11-23 19:36:31.106519 checkthechain-0.3.4/src/ctc/config/setup_utils/stages/__init__.py
+-rw-r--r--   0        0        0     1622 2023-02-26 18:21:06.945600 checkthechain-0.3.4/src/ctc/config/setup_utils/stages/alias_setup.py
+-rw-r--r--   0        0        0     4171 2023-02-26 18:21:06.945828 checkthechain-0.3.4/src/ctc/config/setup_utils/stages/cli_setup.py
+-rw-r--r--   0        0        0     3309 2023-02-26 18:21:06.945947 checkthechain-0.3.4/src/ctc/config/setup_utils/stages/data_dir_setup.py
+-rw-r--r--   0        0        0     8319 2023-04-27 04:36:30.568338 checkthechain-0.3.4/src/ctc/config/setup_utils/stages/db_setup.py
+-rw-r--r--   0        0        0    16993 2023-04-12 02:20:49.003316 checkthechain-0.3.4/src/ctc/config/setup_utils/stages/network_setup.py
+-rw-r--r--   0        0        0       59 2023-02-26 18:21:06.946626 checkthechain-0.3.4/src/ctc/config/upgrade_utils/__init__.py
+-rw-r--r--   0        0        0     7078 2023-04-17 00:18:44.690569 checkthechain-0.3.4/src/ctc/config/upgrade_utils/config_upgrade.py
+-rw-r--r--   0        0        0     7171 2023-04-17 01:16:23.566187 checkthechain-0.3.4/src/ctc/config/upgrade_utils/data_dir_versioning.py
+-rw-r--r--   0        0        0     3026 2023-04-17 01:29:37.379812 checkthechain-0.3.4/src/ctc/config/upgrade_utils/legacy_types.py
+-rw-r--r--   0        0        0      623 2023-02-26 18:21:06.947460 checkthechain-0.3.4/src/ctc/config/upgrade_utils/version_utils.py
+-rw-r--r--   0        0        0        0 2023-03-04 19:50:23.525211 checkthechain-0.3.4/src/ctc/datasets/__init__.py
+-rw-r--r--   0        0        0     6803 2023-06-03 00:20:08.970969 checkthechain-0.3.4/src/ctc/datasets/extract_blocks_and_transactions.py
+-rw-r--r--   0        0        0     2348 2023-05-30 06:43:40.603733 checkthechain-0.3.4/src/ctc/datasets/extract_erc20_transfers.py
+-rw-r--r--   0        0        0      162 2022-11-23 19:36:31.107400 checkthechain-0.3.4/src/ctc/db/__init__.py
+-rw-r--r--   0        0        0     3217 2023-04-15 07:07:44.333514 checkthechain-0.3.4/src/ctc/db/connect_utils.py
+-rw-r--r--   0        0        0     2890 2023-02-26 20:15:07.410640 checkthechain-0.3.4/src/ctc/db/intake_utils.py
+-rw-r--r--   0        0        0      109 2023-02-26 20:15:07.410802 checkthechain-0.3.4/src/ctc/db/management/__init__.py
+-rw-r--r--   0        0        0      997 2023-02-26 18:21:06.948577 checkthechain-0.3.4/src/ctc/db/management/active_utils.py
+-rw-r--r--   0        0        0     8200 2023-03-24 17:28:52.210535 checkthechain-0.3.4/src/ctc/db/management/dba_utils.py
+-rw-r--r--   0        0        0      634 2023-02-26 20:15:07.411288 checkthechain-0.3.4/src/ctc/db/management/reorg_utils.py
+-rw-r--r--   0        0        0     3594 2023-02-27 18:50:47.123257 checkthechain-0.3.4/src/ctc/db/management/version_utils.py
+-rw-r--r--   0        0        0     1879 2023-04-14 22:55:23.964370 checkthechain-0.3.4/src/ctc/db/query_utils.py
+-rw-r--r--   0        0        0     4735 2023-04-27 20:25:01.753860 checkthechain-0.3.4/src/ctc/db/schema_utils.py
+-rw-r--r--   0        0        0      285 2023-02-26 18:21:06.950384 checkthechain-0.3.4/src/ctc/db/schemas/__init__.py
+-rw-r--r--   0        0        0        0 2022-11-23 19:36:31.108677 checkthechain-0.3.4/src/ctc/db/schemas/__upcoming__/__init__.py
+-rw-r--r--   0        0        0       43 2022-11-23 19:36:31.108781 checkthechain-0.3.4/src/ctc/db/schemas/__upcoming__/block_gas_stats/__init__.py
+-rw-r--r--   0        0        0     1138 2023-02-26 20:15:07.412506 checkthechain-0.3.4/src/ctc/db/schemas/__upcoming__/block_gas_stats/block_gas_stats_schema_defs.py
+-rw-r--r--   0        0        0       39 2022-11-23 19:36:31.108986 checkthechain-0.3.4/src/ctc/db/schemas/__upcoming__/erc20_state/__init__.py
+-rw-r--r--   0        0        0     1259 2023-02-26 20:15:07.412713 checkthechain-0.3.4/src/ctc/db/schemas/__upcoming__/erc20_state/erc20_state_schema_defs.py
+-rw-r--r--   0        0        0        0 2022-11-23 19:36:31.109185 checkthechain-0.3.4/src/ctc/db/schemas/__upcoming__/protocol_schemas/__init__.py
+-rw-r--r--   0        0        0      792 2023-02-26 20:15:07.412923 checkthechain-0.3.4/src/ctc/db/schemas/__upcoming__/protocol_schemas/fourbyte_schema_defs.py
+-rw-r--r--   0        0        0      634 2023-02-26 20:15:07.413166 checkthechain-0.3.4/src/ctc/db/schemas/__upcoming__/protocol_schemas/fuse_pools_schema_defs.py
+-rw-r--r--   0        0        0      387 2023-02-26 20:15:07.413408 checkthechain-0.3.4/src/ctc/db/schemas/__upcoming__/protocol_schemas/uniswap_v2_pools_schema_defs.py
+-rw-r--r--   0        0        0      436 2023-02-26 20:15:07.413623 checkthechain-0.3.4/src/ctc/db/schemas/__upcoming__/protocol_schemas/uniswap_v3_pools_schema_defs.py
+-rw-r--r--   0        0        0      106 2022-11-23 19:36:31.109629 checkthechain-0.3.4/src/ctc/db/schemas/block_gas/__init__.py
+-rw-r--r--   0        0        0      420 2022-11-23 19:36:31.109689 checkthechain-0.3.4/src/ctc/db/schemas/block_gas/block_gas_queries.py
+-rw-r--r--   0        0        0      629 2023-02-26 20:15:07.414036 checkthechain-0.3.4/src/ctc/db/schemas/block_gas/block_gas_schema_defs.py
+-rw-r--r--   0        0        0     3001 2023-04-15 23:24:04.689689 checkthechain-0.3.4/src/ctc/db/schemas/block_gas/block_gas_statements.py
+-rw-r--r--   0        0        0      194 2022-11-23 19:36:31.109953 checkthechain-0.3.4/src/ctc/db/schemas/block_timestamps/__init__.py
+-rw-r--r--   0        0        0      562 2023-02-26 20:15:07.414563 checkthechain-0.3.4/src/ctc/db/schemas/block_timestamps/block_timestamps_schema_defs.py
+-rw-r--r--   0        0        0     6162 2023-04-15 23:08:40.662417 checkthechain-0.3.4/src/ctc/db/schemas/block_timestamps/block_timestamps_statements.py
+-rw-r--r--   0        0        0     1596 2022-11-23 19:36:31.110176 checkthechain-0.3.4/src/ctc/db/schemas/block_timestamps/multischema_block_timestamps_queries.py
+-rw-r--r--   0        0        0     4431 2023-04-17 01:12:40.874133 checkthechain-0.3.4/src/ctc/db/schemas/block_timestamps/multischema_block_timestamps_search.py
+-rw-r--r--   0        0        0     3058 2023-02-26 20:15:07.415190 checkthechain-0.3.4/src/ctc/db/schemas/block_timestamps/multischema_block_timestamps_statements.py
+-rw-r--r--   0        0        0      126 2022-11-23 19:36:31.110528 checkthechain-0.3.4/src/ctc/db/schemas/blocks/__init__.py
+-rw-r--r--   0        0        0    10484 2023-02-26 21:02:01.364459 checkthechain-0.3.4/src/ctc/db/schemas/blocks/blocks_intake.py
+-rw-r--r--   0        0        0      343 2022-11-23 19:36:31.110828 checkthechain-0.3.4/src/ctc/db/schemas/blocks/blocks_queries.py
+-rw-r--r--   0        0        0      725 2023-02-26 20:15:07.415649 checkthechain-0.3.4/src/ctc/db/schemas/blocks/blocks_schema_defs.py
+-rw-r--r--   0        0        0     7041 2023-02-27 06:50:44.454081 checkthechain-0.3.4/src/ctc/db/schemas/blocks/blocks_statements.py
+-rw-r--r--   0        0        0      154 2022-11-23 19:36:31.111040 checkthechain-0.3.4/src/ctc/db/schemas/contract_abis/__init__.py
+-rw-r--r--   0        0        0     1155 2023-02-26 20:15:07.416090 checkthechain-0.3.4/src/ctc/db/schemas/contract_abis/contract_abis_intake.py
+-rw-r--r--   0        0        0      406 2022-11-23 19:36:31.111159 checkthechain-0.3.4/src/ctc/db/schemas/contract_abis/contract_abis_queries.py
+-rw-r--r--   0        0        0      392 2023-02-26 20:15:07.416278 checkthechain-0.3.4/src/ctc/db/schemas/contract_abis/contract_abis_schema_defs.py
+-rw-r--r--   0        0        0     2403 2023-03-04 08:00:44.984031 checkthechain-0.3.4/src/ctc/db/schemas/contract_abis/contract_abis_statements.py
+-rw-r--r--   0        0        0      198 2022-11-23 19:36:31.111410 checkthechain-0.3.4/src/ctc/db/schemas/contract_creation_blocks/__init__.py
+-rw-r--r--   0        0        0     1031 2023-02-26 20:15:07.416737 checkthechain-0.3.4/src/ctc/db/schemas/contract_creation_blocks/contract_creation_blocks_intake.py
+-rw-r--r--   0        0        0      505 2022-11-23 19:36:31.111535 checkthechain-0.3.4/src/ctc/db/schemas/contract_creation_blocks/contract_creation_blocks_queries.py
+-rw-r--r--   0        0        0      534 2023-02-26 20:15:07.416982 checkthechain-0.3.4/src/ctc/db/schemas/contract_creation_blocks/contract_creation_blocks_schema_defs.py
+-rw-r--r--   0        0        0     2081 2023-03-06 04:31:37.480699 checkthechain-0.3.4/src/ctc/db/schemas/contract_creation_blocks/contract_creation_blocks_statements.py
+-rw-r--r--   0        0        0      138 2022-11-23 19:36:31.111785 checkthechain-0.3.4/src/ctc/db/schemas/dex_pools/__init__.py
+-rw-r--r--   0        0        0     1576 2023-02-26 20:15:07.417521 checkthechain-0.3.4/src/ctc/db/schemas/dex_pools/dex_pools_intake.py
+-rw-r--r--   0        0        0      578 2022-11-23 19:36:31.111973 checkthechain-0.3.4/src/ctc/db/schemas/dex_pools/dex_pools_queries.py
+-rw-r--r--   0        0        0     1094 2023-02-26 20:15:07.417730 checkthechain-0.3.4/src/ctc/db/schemas/dex_pools/dex_pools_schema_defs.py
+-rw-r--r--   0        0        0     6060 2023-04-12 21:15:00.071455 checkthechain-0.3.4/src/ctc/db/schemas/dex_pools/dex_pools_statements.py
+-rw-r--r--   0        0        0      158 2022-11-23 19:36:31.112442 checkthechain-0.3.4/src/ctc/db/schemas/erc20_metadata/__init__.py
+-rw-r--r--   0        0        0      761 2023-02-26 20:15:07.418167 checkthechain-0.3.4/src/ctc/db/schemas/erc20_metadata/erc20_metadata_intake.py
+-rw-r--r--   0        0        0      419 2023-02-26 18:21:06.953935 checkthechain-0.3.4/src/ctc/db/schemas/erc20_metadata/erc20_metadata_queries.py
+-rw-r--r--   0        0        0      765 2023-02-26 20:15:07.418402 checkthechain-0.3.4/src/ctc/db/schemas/erc20_metadata/erc20_metadata_schema_defs.py
+-rw-r--r--   0        0        0     3673 2023-04-11 21:30:22.630170 checkthechain-0.3.4/src/ctc/db/schemas/erc20_metadata/erc20_metadata_statements.py
+-rw-r--r--   0        0        0      126 2023-02-26 18:21:06.954232 checkthechain-0.3.4/src/ctc/db/schemas/events/__init__.py
+-rw-r--r--   0        0        0     2217 2023-04-10 04:00:25.884785 checkthechain-0.3.4/src/ctc/db/schemas/events/events_intake.py
+-rw-r--r--   0        0        0      359 2023-04-10 23:47:03.987654 checkthechain-0.3.4/src/ctc/db/schemas/events/events_queries.py
+-rw-r--r--   0        0        0     2896 2023-04-27 21:04:55.972761 checkthechain-0.3.4/src/ctc/db/schemas/events/events_schema_defs.py
+-rw-r--r--   0        0        0    12138 2023-04-12 19:57:20.128959 checkthechain-0.3.4/src/ctc/db/schemas/events/events_statements.py
+-rw-r--r--   0        0        0       43 2022-11-23 19:36:31.112900 checkthechain-0.3.4/src/ctc/db/schemas/schema_versions/__init__.py
+-rw-r--r--   0        0        0      503 2023-02-26 20:15:07.419573 checkthechain-0.3.4/src/ctc/db/schemas/schema_versions/schema_versions_schema_defs.py
+-rw-r--r--   0        0        0      151 2023-02-26 18:21:06.955047 checkthechain-0.3.4/src/ctc/db/schemas/transactions/__init__.py
+-rw-r--r--   0        0        0     3065 2023-02-26 20:15:07.419798 checkthechain-0.3.4/src/ctc/db/schemas/transactions/transactions_intake.py
+-rw-r--r--   0        0        0     1084 2023-02-26 18:21:06.955542 checkthechain-0.3.4/src/ctc/db/schemas/transactions/transactions_queries.py
+-rw-r--r--   0        0        0     1505 2023-02-26 20:15:07.419998 checkthechain-0.3.4/src/ctc/db/schemas/transactions/transactions_schema_defs.py
+-rw-r--r--   0        0        0      125 2023-02-26 18:21:06.956032 checkthechain-0.3.4/src/ctc/db/schemas/transactions/transactions_statements/__init__.py
+-rw-r--r--   0        0        0     2343 2023-04-27 06:04:57.381242 checkthechain-0.3.4/src/ctc/db/schemas/transactions/transactions_statements/composite_block_transactions.py
+-rw-r--r--   0        0        0     3690 2023-02-27 06:48:19.824368 checkthechain-0.3.4/src/ctc/db/schemas/transactions/transactions_statements/table_block_transaction_queries.py
+-rw-r--r--   0        0        0     3251 2023-03-10 20:38:54.085113 checkthechain-0.3.4/src/ctc/db/schemas/transactions/transactions_statements/table_transactions.py
+-rw-r--r--   0        0        0        1 2022-11-23 19:36:31.148839 checkthechain-0.3.4/src/ctc/defi/__init__.py
+-rw-r--r--   0        0        0    39847 2023-04-11 15:01:03.698383 checkthechain-0.3.4/src/ctc/defi/cex_utils.py
+-rw-r--r--   0        0        0       21 2022-11-23 19:36:31.149006 checkthechain-0.3.4/src/ctc/defi/dex_utils/__init__.py
+-rw-r--r--   0        0        0        0 2022-11-23 19:36:31.149080 checkthechain-0.3.4/src/ctc/defi/dex_utils/amm_utils/__init__.py
+-rw-r--r--   0        0        0     1056 2022-11-23 19:36:31.149155 checkthechain-0.3.4/src/ctc/defi/dex_utils/amm_utils/amm_spec.py
+-rw-r--r--   0        0        0       84 2022-11-23 19:36:31.149422 checkthechain-0.3.4/src/ctc/defi/dex_utils/amm_utils/cpmm/__init__.py
+-rw-r--r--   0        0        0     3241 2023-04-10 01:05:06.123710 checkthechain-0.3.4/src/ctc/defi/dex_utils/amm_utils/cpmm/cpmm_liquidity.py
+-rw-r--r--   0        0        0     1292 2023-04-17 01:28:17.884516 checkthechain-0.3.4/src/ctc/defi/dex_utils/amm_utils/cpmm/cpmm_spec.py
+-rw-r--r--   0        0        0     9425 2022-11-23 19:36:31.149776 checkthechain-0.3.4/src/ctc/defi/dex_utils/amm_utils/cpmm/cpmm_summary.py
+-rw-r--r--   0        0        0     7780 2023-04-12 21:01:00.654910 checkthechain-0.3.4/src/ctc/defi/dex_utils/amm_utils/cpmm/cpmm_trade.py
+-rw-r--r--   0        0        0       37 2022-11-23 19:36:31.149993 checkthechain-0.3.4/src/ctc/defi/dex_utils/amm_utils/stableswap/__init__.py
+-rw-r--r--   0        0        0      333 2022-11-23 19:36:31.150062 checkthechain-0.3.4/src/ctc/defi/dex_utils/amm_utils/stableswap/stableswap_operations.py
+-rw-r--r--   0        0        0      151 2022-11-23 19:36:31.150205 checkthechain-0.3.4/src/ctc/defi/dex_utils/dexes/__init__.py
+-rw-r--r--   0        0        0    22413 2023-05-03 23:49:39.987609 checkthechain-0.3.4/src/ctc/defi/dex_utils/dexes/dex_class.py
+-rw-r--r--   0        0        0     3458 2023-02-26 18:21:07.009571 checkthechain-0.3.4/src/ctc/defi/dex_utils/dexes/dex_class_utils.py
+-rw-r--r--   0        0        0     1523 2023-04-12 02:18:53.791732 checkthechain-0.3.4/src/ctc/defi/dex_utils/dexes/dex_directory.py
+-rw-r--r--   0        0        0      145 2022-11-23 19:36:31.150615 checkthechain-0.3.4/src/ctc/defi/dex_utils/dexes/dex_functions/__init__.py
+-rw-r--r--   0        0        0     2749 2023-02-26 18:21:07.009954 checkthechain-0.3.4/src/ctc/defi/dex_utils/dexes/dex_functions/dex_balance_functions.py
+-rw-r--r--   0        0        0     1603 2023-02-26 18:21:07.010224 checkthechain-0.3.4/src/ctc/defi/dex_utils/dexes/dex_functions/dex_metadata_functions.py
+-rw-r--r--   0        0        0     2038 2023-02-26 18:21:07.010390 checkthechain-0.3.4/src/ctc/defi/dex_utils/dexes/dex_functions/dex_pools_functions.py
+-rw-r--r--   0        0        0     1510 2023-04-17 01:11:51.919003 checkthechain-0.3.4/src/ctc/defi/dex_utils/dexes/dex_functions/dex_trade_functions.py
+-rw-r--r--   0        0        0      184 2022-11-23 19:36:31.151177 checkthechain-0.3.4/src/ctc/defi/dex_utils/dexes/dex_implementations/__init__.py
+-rw-r--r--   0        0        0     5880 2023-04-11 02:43:28.475321 checkthechain-0.3.4/src/ctc/defi/dex_utils/dexes/dex_implementations/balancer_dex.py
+-rw-r--r--   0        0        0     7488 2023-04-11 02:44:21.401565 checkthechain-0.3.4/src/ctc/defi/dex_utils/dexes/dex_implementations/curve_dex.py
+-rw-r--r--   0        0        0      207 2022-11-23 19:36:31.151507 checkthechain-0.3.4/src/ctc/defi/dex_utils/dexes/dex_implementations/sushi_dex.py
+-rw-r--r--   0        0        0     4350 2023-04-12 22:58:36.356923 checkthechain-0.3.4/src/ctc/defi/dex_utils/dexes/dex_implementations/uniswap_v2_dex.py
+-rw-r--r--   0        0        0     3932 2023-04-11 00:19:46.796938 checkthechain-0.3.4/src/ctc/defi/dex_utils/dexes/dex_implementations/uniswap_v3_dex.py
+-rw-r--r--   0        0        0       31 2022-11-23 19:36:31.151852 checkthechain-0.3.4/src/ctc/defi/lending_utils/__init__.py
+-rw-r--r--   0        0        0     7740 2023-04-11 05:05:46.922489 checkthechain-0.3.4/src/ctc/defi/lending_utils/lending_summary.py
+-rw-r--r--   0        0        0        1 2023-04-15 16:02:19.893267 checkthechain-0.3.4/src/ctc/defi/metric_utils/__init__.py
+-rw-r--r--   0        0        0     1965 2023-04-11 21:23:13.516151 checkthechain-0.3.4/src/ctc/defi/metric_utils/ohlc_utils.py
+-rw-r--r--   0        0        0      346 2022-11-23 19:36:31.152114 checkthechain-0.3.4/src/ctc/defi/metric_utils/twap_utils/README.md
+-rw-r--r--   0        0        0      103 2022-11-23 19:36:31.152177 checkthechain-0.3.4/src/ctc/defi/metric_utils/twap_utils/__init__.py
+-rw-r--r--   0        0        0     4043 2023-02-26 18:21:07.012053 checkthechain-0.3.4/src/ctc/defi/metric_utils/twap_utils/feed_utils.py
+-rw-r--r--   0        0        0     2824 2023-04-11 05:41:47.387268 checkthechain-0.3.4/src/ctc/defi/metric_utils/twap_utils/twap_crud.py
+-rw-r--r--   0        0        0      936 2023-04-11 05:24:45.040006 checkthechain-0.3.4/src/ctc/defi/metric_utils/twap_utils/twap_data.py
+-rw-r--r--   0        0        0     2630 2023-04-11 05:25:54.330704 checkthechain-0.3.4/src/ctc/defi/metric_utils/twap_utils/twap_data_sources.py
+-rw-r--r--   0        0        0     1292 2023-04-11 04:55:26.105147 checkthechain-0.3.4/src/ctc/defi/metric_utils/twap_utils/twap_filter.py
+-rw-r--r--   0        0        0      442 2023-04-17 01:29:49.343807 checkthechain-0.3.4/src/ctc/defi/metric_utils/twap_utils/twap_spec.py
+-rw-r--r--   0        0        0      365 2023-02-26 18:21:06.956840 checkthechain-0.3.4/src/ctc/evm/__init__.py
+-rw-r--r--   0        0        0      131 2022-11-23 19:36:31.113210 checkthechain-0.3.4/src/ctc/evm/abi_utils/__init__.py
+-rw-r--r--   0        0        0     2256 2023-05-04 21:17:33.110466 checkthechain-0.3.4/src/ctc/evm/abi_utils/abi_coding_utils.py
+-rw-r--r--   0        0        0      189 2022-11-23 19:36:31.113375 checkthechain-0.3.4/src/ctc/evm/abi_utils/contract_abi_utils/__init__.py
+-rw-r--r--   0        0        0     2698 2022-11-23 19:36:31.113461 checkthechain-0.3.4/src/ctc/evm/abi_utils/contract_abi_utils/contract_abi_comparison.py
+-rw-r--r--   0        0        0     1361 2023-02-26 18:21:06.957338 checkthechain-0.3.4/src/ctc/evm/abi_utils/contract_abi_utils/contract_abi_decompilation.py
+-rw-r--r--   0        0        0     2142 2023-02-26 18:21:06.957664 checkthechain-0.3.4/src/ctc/evm/abi_utils/contract_abi_utils/contract_abi_io.py
+-rw-r--r--   0        0        0      660 2022-11-23 19:36:31.113721 checkthechain-0.3.4/src/ctc/evm/abi_utils/contract_abi_utils/contract_abi_modification.py
+-rw-r--r--   0        0        0     9934 2023-04-11 03:28:48.635201 checkthechain-0.3.4/src/ctc/evm/abi_utils/contract_abi_utils/contract_abi_summary.py
+-rw-r--r--   0        0        0      137 2023-03-04 05:46:27.752144 checkthechain-0.3.4/src/ctc/evm/abi_utils/event_abi_utils/__init__.py
+-rw-r--r--   0        0        0     6278 2023-04-11 17:04:41.509191 checkthechain-0.3.4/src/ctc/evm/abi_utils/event_abi_utils/event_abi_coding.py
+-rw-r--r--   0        0        0    14548 2023-06-03 00:20:08.972191 checkthechain-0.3.4/src/ctc/evm/abi_utils/event_abi_utils/event_abi_coding_polars.py
+-rw-r--r--   0        0        0     2650 2023-04-11 17:23:39.585194 checkthechain-0.3.4/src/ctc/evm/abi_utils/event_abi_utils/event_abi_parsing.py
+-rw-r--r--   0        0        0     3660 2023-03-04 07:55:53.565102 checkthechain-0.3.4/src/ctc/evm/abi_utils/event_abi_utils/event_abi_queries.py
+-rw-r--r--   0        0        0      107 2022-11-23 19:36:31.114446 checkthechain-0.3.4/src/ctc/evm/abi_utils/function_abi_utils/__init__.py
+-rw-r--r--   0        0        0     8050 2023-04-11 16:54:40.278301 checkthechain-0.3.4/src/ctc/evm/abi_utils/function_abi_utils/function_abi_coding.py
+-rw-r--r--   0        0        0     8453 2023-02-26 18:21:06.958642 checkthechain-0.3.4/src/ctc/evm/abi_utils/function_abi_utils/function_abi_parsing.py
+-rw-r--r--   0        0        0     5155 2023-05-03 21:01:44.378805 checkthechain-0.3.4/src/ctc/evm/abi_utils/function_abi_utils/function_abi_queries.py
+-rw-r--r--   0        0        0      129 2023-02-26 18:21:06.959059 checkthechain-0.3.4/src/ctc/evm/address_utils/__init__.py
+-rw-r--r--   0        0        0     1555 2023-04-11 17:07:31.645090 checkthechain-0.3.4/src/ctc/evm/address_utils/address_data.py
+-rw-r--r--   0        0        0     2881 2023-02-26 18:21:06.959458 checkthechain-0.3.4/src/ctc/evm/address_utils/address_resolution.py
+-rw-r--r--   0        0        0     3628 2023-02-26 18:21:06.959812 checkthechain-0.3.4/src/ctc/evm/address_utils/address_summary.py
+-rw-r--r--   0        0        0     6147 2023-04-11 03:41:52.412674 checkthechain-0.3.4/src/ctc/evm/address_utils/address_transactions.py
+-rw-r--r--   0        0        0      177 2022-11-23 19:36:31.115455 checkthechain-0.3.4/src/ctc/evm/binary_utils/__init__.py
+-rw-r--r--   0        0        0     7187 2023-04-11 17:24:12.284270 checkthechain-0.3.4/src/ctc/evm/binary_utils/format_utils.py
+-rw-r--r--   0        0        0     3169 2023-04-17 01:02:40.149889 checkthechain-0.3.4/src/ctc/evm/binary_utils/hash_utils.py
+-rw-r--r--   0        0        0     8948 2023-04-11 17:11:36.961031 checkthechain-0.3.4/src/ctc/evm/binary_utils/rlp_utils.py
+-rw-r--r--   0        0        0      146 2022-11-23 19:36:31.115957 checkthechain-0.3.4/src/ctc/evm/binary_utils/signature_utils/__init__.py
+-rw-r--r--   0        0        0     7465 2022-11-23 19:36:31.116055 checkthechain-0.3.4/src/ctc/evm/binary_utils/signature_utils/eip712_utils.py
+-rw-r--r--   0        0        0     1407 2023-04-11 17:13:01.266528 checkthechain-0.3.4/src/ctc/evm/binary_utils/signature_utils/key_utils.py
+-rw-r--r--   0        0        0     4915 2022-11-23 19:36:31.116213 checkthechain-0.3.4/src/ctc/evm/binary_utils/signature_utils/secp256k1_utils.py
+-rw-r--r--   0        0        0     2850 2023-04-11 17:12:22.146113 checkthechain-0.3.4/src/ctc/evm/binary_utils/signature_utils/signature_creation.py
+-rw-r--r--   0        0        0     2835 2023-04-11 17:11:56.281971 checkthechain-0.3.4/src/ctc/evm/binary_utils/signature_utils/signature_recovery.py
+-rw-r--r--   0        0        0     1926 2023-04-11 17:16:27.004803 checkthechain-0.3.4/src/ctc/evm/binary_utils/signature_utils/vrs_utils.py
+-rw-r--r--   0        0        0      280 2023-05-30 06:46:30.790511 checkthechain-0.3.4/src/ctc/evm/block_utils/__init__.py
+-rw-r--r--   0        0        0     2750 2023-04-11 17:18:20.638063 checkthechain-0.3.4/src/ctc/evm/block_utils/block_coding.py
+-rw-r--r--   0        0        0      608 2023-02-26 18:21:06.960791 checkthechain-0.3.4/src/ctc/evm/block_utils/block_convert.py
+-rw-r--r--   0        0        0     6865 2023-05-09 04:17:37.723832 checkthechain-0.3.4/src/ctc/evm/block_utils/block_crud.py
+-rw-r--r--   0        0        0     8315 2023-06-03 00:20:08.973363 checkthechain-0.3.4/src/ctc/evm/block_utils/block_gas.py
+-rw-r--r--   0        0        0     1083 2023-02-26 18:21:06.961562 checkthechain-0.3.4/src/ctc/evm/block_utils/block_hashes.py
+-rw-r--r--   0        0        0     1990 2023-02-26 18:21:06.961734 checkthechain-0.3.4/src/ctc/evm/block_utils/block_normalize.py
+-rw-r--r--   0        0        0      662 2023-05-30 06:46:30.790714 checkthechain-0.3.4/src/ctc/evm/block_utils/block_prices.py
+-rw-r--r--   0        0        0     5580 2023-05-27 19:14:13.240378 checkthechain-0.3.4/src/ctc/evm/block_utils/block_samples.py
+-rw-r--r--   0        0        0     2759 2023-05-27 15:37:02.677178 checkthechain-0.3.4/src/ctc/evm/block_utils/block_summary.py
+-rw-r--r--   0        0        0      137 2023-05-27 19:01:35.203629 checkthechain-0.3.4/src/ctc/evm/block_utils/block_times/__init__.py
+-rw-r--r--   0        0        0     3690 2023-05-30 06:46:30.791681 checkthechain-0.3.4/src/ctc/evm/block_utils/block_times/block_time_bins.py
+-rw-r--r--   0        0        0     6100 2023-02-26 18:21:06.962078 checkthechain-0.3.4/src/ctc/evm/block_utils/block_times/block_time_predictions.py
+-rw-r--r--   0        0        0     2437 2023-02-26 18:21:06.962477 checkthechain-0.3.4/src/ctc/evm/block_utils/block_times/block_to_timestamp.py
+-rw-r--r--   0        0        0      133 2022-11-23 19:36:31.118022 checkthechain-0.3.4/src/ctc/evm/block_utils/block_times/timestamp_to_block/__init__.py
+-rw-r--r--   0        0        0     3620 2023-02-26 18:21:06.962780 checkthechain-0.3.4/src/ctc/evm/block_utils/block_times/timestamp_to_block/block_time_plural.py
+-rw-r--r--   0        0        0     4479 2023-02-26 18:21:06.962964 checkthechain-0.3.4/src/ctc/evm/block_utils/block_times/timestamp_to_block/block_time_range.py
+-rw-r--r--   0        0        0     6005 2023-05-27 19:13:07.231807 checkthechain-0.3.4/src/ctc/evm/block_utils/block_times/timestamp_to_block/block_time_search.py
+-rw-r--r--   0        0        0     4136 2023-05-27 19:13:12.416617 checkthechain-0.3.4/src/ctc/evm/block_utils/block_times/timestamp_to_block/block_time_singular.py
+-rw-r--r--   0        0        0       64 2023-02-26 18:21:06.963936 checkthechain-0.3.4/src/ctc/evm/consensus_utils/__init__.py
+-rw-r--r--   0        0        0     4002 2023-02-26 18:21:06.964193 checkthechain-0.3.4/src/ctc/evm/consensus_utils/consensus_queries.py
+-rw-r--r--   0        0        0     1665 2023-04-28 23:57:21.283647 checkthechain-0.3.4/src/ctc/evm/consensus_utils/consensus_requests.py
+-rw-r--r--   0        0        0     2118 2023-02-26 18:21:06.964748 checkthechain-0.3.4/src/ctc/evm/consensus_utils/consensus_spec.py
+-rw-r--r--   0        0        0       96 2023-02-26 18:21:06.965010 checkthechain-0.3.4/src/ctc/evm/contract_utils/__init__.py
+-rw-r--r--   0        0        0     6575 2023-04-11 17:04:21.999102 checkthechain-0.3.4/src/ctc/evm/contract_utils/contract_creations.py
+-rw-r--r--   0        0        0     9875 2023-02-26 18:21:06.965502 checkthechain-0.3.4/src/ctc/evm/contract_utils/contract_proxies.py
+-rw-r--r--   0        0        0      979 2023-02-26 18:21:06.965736 checkthechain-0.3.4/src/ctc/evm/contract_utils/contract_tests.py
+-rw-r--r--   0        0        0      200 2022-11-23 19:36:31.118451 checkthechain-0.3.4/src/ctc/evm/erc20_utils/__init__.py
+-rw-r--r--   0        0        0     5922 2023-04-11 15:05:42.419653 checkthechain-0.3.4/src/ctc/evm/erc20_utils/erc20_events.py
+-rw-r--r--   0        0        0     2179 2023-04-12 16:02:37.446080 checkthechain-0.3.4/src/ctc/evm/erc20_utils/erc20_generic.py
+-rw-r--r--   0        0        0    13187 2023-06-03 00:20:08.974291 checkthechain-0.3.4/src/ctc/evm/erc20_utils/erc20_metadata.py
+-rw-r--r--   0        0        0     6574 2023-04-12 16:01:20.761726 checkthechain-0.3.4/src/ctc/evm/erc20_utils/erc20_normalize.py
+-rw-r--r--   0        0        0     3433 2022-11-23 19:36:31.118864 checkthechain-0.3.4/src/ctc/evm/erc20_utils/erc20_spec.py
+-rw-r--r--   0        0        0    12612 2023-05-03 23:48:57.178118 checkthechain-0.3.4/src/ctc/evm/erc20_utils/erc20_state.py
+-rw-r--r--   0        0        0     1871 2023-02-26 18:21:06.967336 checkthechain-0.3.4/src/ctc/evm/erc20_utils/erc20_summary.py
+-rw-r--r--   0        0        0      188 2023-02-26 18:21:06.967455 checkthechain-0.3.4/src/ctc/evm/erc4626_utils/__init__.py
+-rw-r--r--   0        0        0     4233 2023-04-12 06:22:58.195596 checkthechain-0.3.4/src/ctc/evm/erc4626_utils/erc4626_events.py
+-rw-r--r--   0        0        0     1097 2023-02-26 18:21:06.967850 checkthechain-0.3.4/src/ctc/evm/erc4626_utils/erc4626_metadata.py
+-rw-r--r--   0        0        0     5796 2023-04-10 06:23:55.747564 checkthechain-0.3.4/src/ctc/evm/erc4626_utils/erc4626_normalize.py
+-rw-r--r--   0        0        0    10976 2023-02-26 18:21:06.968082 checkthechain-0.3.4/src/ctc/evm/erc4626_utils/erc4626_spec.py
+-rw-r--r--   0        0        0    23565 2023-02-26 18:21:06.968309 checkthechain-0.3.4/src/ctc/evm/erc4626_utils/erc4626_state.py
+-rw-r--r--   0        0        0      147 2023-02-26 18:21:06.968426 checkthechain-0.3.4/src/ctc/evm/erc721_utils/__init__.py
+-rw-r--r--   0        0        0     1740 2023-04-11 15:04:56.245383 checkthechain-0.3.4/src/ctc/evm/erc721_utils/erc721_events.py
+-rw-r--r--   0        0        0     1930 2023-02-26 18:21:06.968922 checkthechain-0.3.4/src/ctc/evm/erc721_utils/erc721_metadata.py
+-rw-r--r--   0        0        0     2967 2023-04-11 15:04:52.910074 checkthechain-0.3.4/src/ctc/evm/erc721_utils/erc721_ownership.py
+-rw-r--r--   0        0        0     5323 2023-02-26 18:21:06.969310 checkthechain-0.3.4/src/ctc/evm/erc721_utils/erc721_spec.py
+-rw-r--r--   0        0        0     3108 2023-02-26 18:21:06.969455 checkthechain-0.3.4/src/ctc/evm/erc721_utils/erc721_state.py
+-rw-r--r--   0        0        0       24 2022-11-23 19:36:31.120339 checkthechain-0.3.4/src/ctc/evm/eth_utils/__init__.py
+-rw-r--r--   0        0        0     4151 2023-02-26 18:21:06.969708 checkthechain-0.3.4/src/ctc/evm/eth_utils/eth_crud.py
+-rw-r--r--   0        0        0       96 2023-02-26 18:21:06.969843 checkthechain-0.3.4/src/ctc/evm/event_utils/__init__.py
+-rw-r--r--   0        0        0    15537 2023-04-13 02:52:22.209972 checkthechain-0.3.4/src/ctc/evm/event_utils/event_crud.py
+-rw-r--r--   0        0        0     6151 2023-05-02 21:14:45.321958 checkthechain-0.3.4/src/ctc/evm/event_utils/event_hybrid_queries.py
+-rw-r--r--   0        0        0     1909 2023-04-11 15:05:32.152407 checkthechain-0.3.4/src/ctc/evm/event_utils/event_metadata.py
+-rw-r--r--   0        0        0     7662 2023-04-11 17:14:11.631727 checkthechain-0.3.4/src/ctc/evm/event_utils/event_node_utils.py
+-rw-r--r--   0        0        0    10602 2023-05-02 21:14:20.680012 checkthechain-0.3.4/src/ctc/evm/event_utils/event_query_utils.py
+-rw-r--r--   0        0        0       33 2022-11-23 19:36:31.121258 checkthechain-0.3.4/src/ctc/evm/network_utils/__init__.py
+-rw-r--r--   0        0        0     2501 2023-02-26 18:21:06.972751 checkthechain-0.3.4/src/ctc/evm/network_utils/network_directory.py
+-rw-r--r--   0        0        0       89 2023-03-11 04:51:22.361782 checkthechain-0.3.4/src/ctc/evm/trace_utils/__init__.py
+-rw-r--r--   0        0        0     4160 2023-05-05 05:28:17.202870 checkthechain-0.3.4/src/ctc/evm/trace_utils/specific_traces.py
+-rw-r--r--   0        0        0     2259 2023-03-06 03:07:15.579397 checkthechain-0.3.4/src/ctc/evm/trace_utils/trace_crud.py
+-rw-r--r--   0        0        0     4712 2023-02-26 20:15:07.421666 checkthechain-0.3.4/src/ctc/evm/trace_utils/trace_state_diff.py
+-rw-r--r--   0        0        0      244 2023-02-26 18:21:06.973711 checkthechain-0.3.4/src/ctc/evm/transaction_utils/__init__.py
+-rw-r--r--   0        0        0     3687 2023-04-27 06:18:19.829021 checkthechain-0.3.4/src/ctc/evm/transaction_utils/transaction_convert.py
+-rw-r--r--   0        0        0     6691 2023-02-26 20:15:07.422149 checkthechain-0.3.4/src/ctc/evm/transaction_utils/transaction_crud.py
+-rw-r--r--   0        0        0      722 2023-02-26 18:21:06.974413 checkthechain-0.3.4/src/ctc/evm/transaction_utils/transaction_hashes.py
+-rw-r--r--   0        0        0     3119 2023-04-12 19:53:53.308960 checkthechain-0.3.4/src/ctc/evm/transaction_utils/transaction_serialize.py
+-rw-r--r--   0        0        0     4298 2023-04-12 19:55:41.976804 checkthechain-0.3.4/src/ctc/evm/transaction_utils/transaction_signatures.py
+-rw-r--r--   0        0        0     7878 2023-04-11 17:08:12.970832 checkthechain-0.3.4/src/ctc/evm/transaction_utils/transaction_summary.py
+-rw-r--r--   0        0        0     2911 2023-04-12 16:41:24.818020 checkthechain-0.3.4/src/ctc/evm/transaction_utils/transaction_types.py
+-rw-r--r--   0        0        0        0 2022-11-23 19:36:31.122150 checkthechain-0.3.4/src/ctc/protocols/__init__.py
+-rw-r--r--   0        0        0      210 2022-11-23 19:36:31.122290 checkthechain-0.3.4/src/ctc/protocols/aave_v2_utils/__init__.py
+-rw-r--r--   0        0        0     7437 2023-04-17 01:33:49.120175 checkthechain-0.3.4/src/ctc/protocols/aave_v2_utils/aave_interest_rates.py
+-rw-r--r--   0        0        0     2271 2023-04-10 04:41:13.923918 checkthechain-0.3.4/src/ctc/protocols/aave_v2_utils/aave_lending_pool.py
+-rw-r--r--   0        0        0     3034 2023-02-26 18:21:06.976319 checkthechain-0.3.4/src/ctc/protocols/aave_v2_utils/aave_oracle.py
+-rw-r--r--   0        0        0     1198 2023-02-26 18:21:06.976540 checkthechain-0.3.4/src/ctc/protocols/aave_v2_utils/aave_pool_tokens.py
+-rw-r--r--   0        0        0     3099 2023-02-26 18:21:06.976782 checkthechain-0.3.4/src/ctc/protocols/aave_v2_utils/aave_rewards.py
+-rw-r--r--   0        0        0      953 2023-04-12 02:17:55.732920 checkthechain-0.3.4/src/ctc/protocols/aave_v2_utils/aave_spec.py
+-rw-r--r--   0        0        0    14153 2023-04-12 02:17:27.412342 checkthechain-0.3.4/src/ctc/protocols/aave_v2_utils/aave_summaries.py
+-rw-r--r--   0        0        0        0 2022-11-23 19:36:31.122992 checkthechain-0.3.4/src/ctc/protocols/aave_v2_utils/cli/__init__.py
+-rw-r--r--   0        0        0      870 2023-01-02 06:57:18.122699 checkthechain-0.3.4/src/ctc/protocols/aave_v2_utils/cli/aave_addresses_command.py
+-rw-r--r--   0        0        0     3072 2022-11-23 19:36:31.123144 checkthechain-0.3.4/src/ctc/protocols/aave_v2_utils/cli/aave_command.py
+-rw-r--r--   0        0        0      165 2022-11-23 19:36:31.123232 checkthechain-0.3.4/src/ctc/protocols/balancer_utils/__init__.py
+-rw-r--r--   0        0        0     4074 2023-02-26 18:21:06.977445 checkthechain-0.3.4/src/ctc/protocols/balancer_utils/balancer_spec.py
+-rw-r--r--   0        0        0     3341 2023-04-11 02:48:49.301350 checkthechain-0.3.4/src/ctc/protocols/balancer_utils/pool_metadata.py
+-rw-r--r--   0        0        0     4646 2023-04-11 05:41:02.218451 checkthechain-0.3.4/src/ctc/protocols/balancer_utils/pool_plots.py
+-rw-r--r--   0        0        0     6265 2023-02-26 18:21:06.978055 checkthechain-0.3.4/src/ctc/protocols/balancer_utils/pool_state.py
+-rw-r--r--   0        0        0     6171 2023-04-17 01:25:48.874215 checkthechain-0.3.4/src/ctc/protocols/balancer_utils/pool_summary.py
+-rw-r--r--   0        0        0     1007 2022-11-23 19:36:31.123708 checkthechain-0.3.4/src/ctc/protocols/balancer_utils/pool_trades.py
+-rw-r--r--   0        0        0      237 2022-11-23 19:36:31.123840 checkthechain-0.3.4/src/ctc/protocols/chainlink_utils/__init__.py
+-rw-r--r--   0        0        0     6981 2023-02-26 18:21:06.978589 checkthechain-0.3.4/src/ctc/protocols/chainlink_utils/chainlink_aggregators.py
+-rw-r--r--   0        0        0      147 2022-11-23 19:36:31.124095 checkthechain-0.3.4/src/ctc/protocols/chainlink_utils/chainlink_data/__init__.py
+-rw-r--r--   0        0        0     2083 2023-04-11 05:31:39.920503 checkthechain-0.3.4/src/ctc/protocols/chainlink_utils/chainlink_data/feed_composites.py
+-rw-r--r--   0        0        0     3101 2023-04-11 05:27:03.456016 checkthechain-0.3.4/src/ctc/protocols/chainlink_utils/chainlink_data/feed_data.py
+-rw-r--r--   0        0        0     3181 2023-02-26 18:21:06.979122 checkthechain-0.3.4/src/ctc/protocols/chainlink_utils/chainlink_data/feed_datum.py
+-rw-r--r--   0        0        0     2291 2023-04-11 14:58:42.923101 checkthechain-0.3.4/src/ctc/protocols/chainlink_utils/chainlink_data/feed_datum_by_block.py
+-rw-r--r--   0        0        0     7300 2023-05-30 06:46:30.792533 checkthechain-0.3.4/src/ctc/protocols/chainlink_utils/chainlink_data/feed_events.py
+-rw-r--r--   0        0        0      138 2022-11-23 19:36:31.124610 checkthechain-0.3.4/src/ctc/protocols/chainlink_utils/chainlink_db/__init__.py
+-rw-r--r--   0        0        0     9709 2023-04-12 02:16:57.774414 checkthechain-0.3.4/src/ctc/protocols/chainlink_utils/chainlink_db/chainlink_intake.py
+-rw-r--r--   0        0        0      509 2022-11-23 19:36:31.124755 checkthechain-0.3.4/src/ctc/protocols/chainlink_utils/chainlink_db/chainlink_queries.py
+-rw-r--r--   0        0        0     1458 2023-02-26 20:15:07.422868 checkthechain-0.3.4/src/ctc/protocols/chainlink_utils/chainlink_db/chainlink_schema_defs.py
+-rw-r--r--   0        0        0     6188 2023-02-27 06:48:28.002164 checkthechain-0.3.4/src/ctc/protocols/chainlink_utils/chainlink_db/chainlink_statements.py
+-rw-r--r--   0        0        0     3742 2023-02-26 18:21:06.980172 checkthechain-0.3.4/src/ctc/protocols/chainlink_utils/chainlink_feed_metadata.py
+-rw-r--r--   0        0        0      818 2023-02-26 18:21:06.980357 checkthechain-0.3.4/src/ctc/protocols/chainlink_utils/chainlink_helpers.py
+-rw-r--r--   0        0        0     4401 2023-04-12 02:16:48.985174 checkthechain-0.3.4/src/ctc/protocols/chainlink_utils/chainlink_registry.py
+-rw-r--r--   0        0        0     2921 2023-04-17 01:06:07.155895 checkthechain-0.3.4/src/ctc/protocols/chainlink_utils/chainlink_spec.py
+-rw-r--r--   0        0        0     6328 2023-04-10 03:26:37.038448 checkthechain-0.3.4/src/ctc/protocols/chainlink_utils/chainlink_summary.py
+-rw-r--r--   0        0        0        0 2022-11-23 19:36:31.125353 checkthechain-0.3.4/src/ctc/protocols/chainlink_utils/cli/__init__.py
+-rw-r--r--   0        0        0     4564 2023-04-10 03:42:49.095411 checkthechain-0.3.4/src/ctc/protocols/chainlink_utils/cli/chainlink_command.py
+-rw-r--r--   0        0        0     2038 2023-02-26 18:21:06.981259 checkthechain-0.3.4/src/ctc/protocols/chainlink_utils/cli/chainlink_ls_command.py
+-rw-r--r--   0        0        0       55 2022-11-23 19:36:31.125633 checkthechain-0.3.4/src/ctc/protocols/coingecko_utils/__init__.py
+-rw-r--r--   0        0        0        0 2022-11-23 19:36:31.125714 checkthechain-0.3.4/src/ctc/protocols/coingecko_utils/cli/__init__.py
+-rw-r--r--   0        0        0     3751 2023-04-14 06:36:37.709398 checkthechain-0.3.4/src/ctc/protocols/coingecko_utils/cli/cg_command.py
+-rw-r--r--   0        0        0      138 2022-11-23 19:36:31.125960 checkthechain-0.3.4/src/ctc/protocols/coingecko_utils/coingecko_db/__init__.py
+-rw-r--r--   0        0        0      957 2023-02-26 20:15:07.423297 checkthechain-0.3.4/src/ctc/protocols/coingecko_utils/coingecko_db/coingecko_intake.py
+-rw-r--r--   0        0        0      331 2023-02-26 18:21:06.981971 checkthechain-0.3.4/src/ctc/protocols/coingecko_utils/coingecko_db/coingecko_queries.py
+-rw-r--r--   0        0        0      773 2023-04-17 01:08:19.565253 checkthechain-0.3.4/src/ctc/protocols/coingecko_utils/coingecko_db/coingecko_schema_defs.py
+-rw-r--r--   0        0        0     3074 2023-04-12 23:19:05.754820 checkthechain-0.3.4/src/ctc/protocols/coingecko_utils/coingecko_db/coingecko_statements.py
+-rw-r--r--   0        0        0     5795 2023-02-26 18:21:06.982284 checkthechain-0.3.4/src/ctc/protocols/coingecko_utils/market_utils.py
+-rw-r--r--   0        0        0    16600 2023-02-27 08:16:17.715834 checkthechain-0.3.4/src/ctc/protocols/coingecko_utils/token_utils.py
+-rw-r--r--   0        0        0       29 2022-11-23 19:36:31.126557 checkthechain-0.3.4/src/ctc/protocols/compound_utils/__init__.py
+-rw-r--r--   0        0        0     2397 2023-02-26 18:21:06.982879 checkthechain-0.3.4/src/ctc/protocols/compound_utils/compound_crud.py
+-rw-r--r--   0        0        0      168 2022-11-23 19:36:31.126693 checkthechain-0.3.4/src/ctc/protocols/curve_utils/__init__.py
+-rw-r--r--   0        0        0        0 2022-11-23 19:36:31.126751 checkthechain-0.3.4/src/ctc/protocols/curve_utils/cli/__init__.py
+-rw-r--r--   0        0        0     1690 2022-11-23 19:36:31.126829 checkthechain-0.3.4/src/ctc/protocols/curve_utils/cli/curve_pools_command.py
+-rw-r--r--   0        0        0     5258 2023-04-17 01:26:07.392801 checkthechain-0.3.4/src/ctc/protocols/curve_utils/curve_spec.py
+-rw-r--r--   0        0        0     3714 2023-02-26 18:21:06.983220 checkthechain-0.3.4/src/ctc/protocols/curve_utils/metapool_utils.py
+-rw-r--r--   0        0        0    15567 2023-04-17 01:36:34.284052 checkthechain-0.3.4/src/ctc/protocols/curve_utils/pool_lists.py
+-rw-r--r--   0        0        0     4951 2023-02-26 18:21:06.983838 checkthechain-0.3.4/src/ctc/protocols/curve_utils/pool_metadata.py
+-rw-r--r--   0        0        0     7351 2023-04-11 02:49:36.985754 checkthechain-0.3.4/src/ctc/protocols/curve_utils/pool_parameters.py
+-rw-r--r--   0        0        0     4085 2023-02-26 18:21:06.984206 checkthechain-0.3.4/src/ctc/protocols/curve_utils/pool_state.py
+-rw-r--r--   0        0        0       49 2022-11-23 19:36:31.127594 checkthechain-0.3.4/src/ctc/protocols/ens_utils/__init__.py
+-rw-r--r--   0        0        0        0 2022-11-23 19:36:31.127647 checkthechain-0.3.4/src/ctc/protocols/ens_utils/cli/__init__.py
+-rw-r--r--   0        0        0        0 2022-11-23 19:36:31.127712 checkthechain-0.3.4/src/ctc/protocols/ens_utils/cli/ens/__init__.py
+-rw-r--r--   0        0        0      813 2022-11-23 19:36:31.127791 checkthechain-0.3.4/src/ctc/protocols/ens_utils/cli/ens/exists_command.py
+-rw-r--r--   0        0        0      441 2022-11-23 19:36:31.127871 checkthechain-0.3.4/src/ctc/protocols/ens_utils/cli/ens/hash_command.py
+-rw-r--r--   0        0        0      765 2022-11-23 19:36:31.127934 checkthechain-0.3.4/src/ctc/protocols/ens_utils/cli/ens/owner_command.py
+-rw-r--r--   0        0        0      625 2022-11-23 19:36:31.127994 checkthechain-0.3.4/src/ctc/protocols/ens_utils/cli/ens/records_command.py
+-rw-r--r--   0        0        0      862 2022-11-23 19:36:31.128056 checkthechain-0.3.4/src/ctc/protocols/ens_utils/cli/ens/resolve_command.py
+-rw-r--r--   0        0        0      876 2022-11-23 19:36:31.128123 checkthechain-0.3.4/src/ctc/protocols/ens_utils/cli/ens/reverse_command.py
+-rw-r--r--   0        0        0     4278 2023-04-17 01:27:38.950415 checkthechain-0.3.4/src/ctc/protocols/ens_utils/cli/ens_command.py
+-rw-r--r--   0        0        0      482 2022-11-23 19:36:31.128261 checkthechain-0.3.4/src/ctc/protocols/ens_utils/ens_directory.py
+-rw-r--r--   0        0        0     3782 2023-04-11 04:50:29.681889 checkthechain-0.3.4/src/ctc/protocols/ens_utils/registrar.py
+-rw-r--r--   0        0        0     7572 2023-04-13 02:54:35.167992 checkthechain-0.3.4/src/ctc/protocols/ens_utils/resolver.py
+-rw-r--r--   0        0        0      132 2023-02-26 18:21:06.984864 checkthechain-0.3.4/src/ctc/protocols/etherscan_utils/__init__.py
+-rw-r--r--   0        0        0     3353 2023-04-17 01:27:53.003738 checkthechain-0.3.4/src/ctc/protocols/etherscan_utils/abi_crud.py
+-rw-r--r--   0        0        0     2596 2023-04-12 02:18:49.893638 checkthechain-0.3.4/src/ctc/protocols/etherscan_utils/browser_utils.py
+-rw-r--r--   0        0        0        0 2022-11-23 19:36:31.128654 checkthechain-0.3.4/src/ctc/protocols/etherscan_utils/cli/__init__.py
+-rw-r--r--   0        0        0     2635 2023-02-26 18:21:06.985639 checkthechain-0.3.4/src/ctc/protocols/etherscan_utils/cli/etherscan_command.py
+-rw-r--r--   0        0        0      326 2023-04-12 02:18:22.167751 checkthechain-0.3.4/src/ctc/protocols/etherscan_utils/etherscan_spec.py
+-rw-r--r--   0        0        0      703 2023-04-12 02:18:27.736358 checkthechain-0.3.4/src/ctc/protocols/etherscan_utils/misc_crud.py
+-rw-r--r--   0        0        0     4951 2023-04-12 02:18:47.139319 checkthechain-0.3.4/src/ctc/protocols/etherscan_utils/url_crud.py
+-rw-r--r--   0        0        0      119 2022-11-23 19:36:31.133315 checkthechain-0.3.4/src/ctc/protocols/fourbyte_utils/__init__.py
+-rw-r--r--   0        0        0        0 2022-11-23 19:36:31.133373 checkthechain-0.3.4/src/ctc/protocols/fourbyte_utils/cli/__init__.py
+-rw-r--r--   0        0        0     1407 2022-11-23 19:36:31.133450 checkthechain-0.3.4/src/ctc/protocols/fourbyte_utils/cli/fourbyte_build_command.py
+-rw-r--r--   0        0        0     3849 2022-11-23 19:36:31.133514 checkthechain-0.3.4/src/ctc/protocols/fourbyte_utils/cli/fourbyte_command.py
+-rw-r--r--   0        0        0      102 2022-11-23 19:36:31.133597 checkthechain-0.3.4/src/ctc/protocols/fourbyte_utils/fourbyte_db/__init__.py
+-rw-r--r--   0        0        0     1846 2023-02-26 20:15:07.423891 checkthechain-0.3.4/src/ctc/protocols/fourbyte_utils/fourbyte_db/fourbyte_intake.py
+-rw-r--r--   0        0        0     1856 2023-04-27 20:09:32.665313 checkthechain-0.3.4/src/ctc/protocols/fourbyte_utils/fourbyte_db/fourbyte_schema_defs.py
+-rw-r--r--   0        0        0     5593 2023-04-27 20:23:37.596062 checkthechain-0.3.4/src/ctc/protocols/fourbyte_utils/fourbyte_db/fourbyte_statements.py
+-rw-r--r--   0        0        0       90 2022-11-23 19:36:31.133972 checkthechain-0.3.4/src/ctc/protocols/fourbyte_utils/fourbyte_queries/__init__.py
+-rw-r--r--   0        0        0     2746 2023-04-27 20:24:38.665613 checkthechain-0.3.4/src/ctc/protocols/fourbyte_utils/fourbyte_queries/general_queries.py
+-rw-r--r--   0        0        0      393 2023-02-26 18:21:06.990217 checkthechain-0.3.4/src/ctc/protocols/fourbyte_utils/fourbyte_queries/local_queries.py
+-rw-r--r--   0        0        0     4042 2023-04-17 01:28:43.369803 checkthechain-0.3.4/src/ctc/protocols/fourbyte_utils/fourbyte_queries/remote_queries.py
+-rw-r--r--   0        0        0     3580 2023-02-26 18:21:06.990325 checkthechain-0.3.4/src/ctc/protocols/fourbyte_utils/fourbyte_scrape.py
+-rw-r--r--   0        0        0     1420 2023-04-17 01:28:32.903495 checkthechain-0.3.4/src/ctc/protocols/fourbyte_utils/fourbyte_spec.py
+-rw-r--r--   0        0        0       20 2022-11-23 19:36:31.134412 checkthechain-0.3.4/src/ctc/protocols/g_uni_utils/__init__.py
+-rw-r--r--   0        0        0     3624 2023-02-26 18:21:06.990518 checkthechain-0.3.4/src/ctc/protocols/g_uni_utils/crud.py
+-rw-r--r--   0        0        0      670 2022-11-23 19:36:31.134602 checkthechain-0.3.4/src/ctc/protocols/gnosis_utils/README.md
+-rw-r--r--   0        0        0      149 2022-11-23 19:36:31.134662 checkthechain-0.3.4/src/ctc/protocols/gnosis_utils/__init__.py
+-rw-r--r--   0        0        0        0 2022-11-23 19:36:31.134718 checkthechain-0.3.4/src/ctc/protocols/gnosis_utils/cli/__init__.py
+-rw-r--r--   0        0        0     1036 2022-11-23 19:36:31.134790 checkthechain-0.3.4/src/ctc/protocols/gnosis_utils/cli/gnosis_command.py
+-rw-r--r--   0        0        0     2976 2023-04-11 05:28:54.333360 checkthechain-0.3.4/src/ctc/protocols/gnosis_utils/safe_events.py
+-rw-r--r--   0        0        0     3793 2023-04-11 14:59:17.679623 checkthechain-0.3.4/src/ctc/protocols/gnosis_utils/safe_factory_events.py
+-rw-r--r--   0        0        0     1552 2023-02-26 18:21:06.991058 checkthechain-0.3.4/src/ctc/protocols/gnosis_utils/safe_metadata.py
+-rw-r--r--   0        0        0     7390 2023-04-17 01:07:53.696824 checkthechain-0.3.4/src/ctc/protocols/gnosis_utils/safe_spec.py
+-rw-r--r--   0        0        0     8950 2023-04-13 22:50:55.610898 checkthechain-0.3.4/src/ctc/protocols/gnosis_utils/safe_summary.py
+-rw-r--r--   0        0        0     6520 2023-04-11 16:33:17.017825 checkthechain-0.3.4/src/ctc/protocols/gnosis_utils/safe_transactions.py
+-rw-r--r--   0        0        0        0 2022-11-23 19:36:31.135334 checkthechain-0.3.4/src/ctc/protocols/llama_utils/__init__.py
+-rw-r--r--   0        0        0        0 2022-11-23 19:36:31.135412 checkthechain-0.3.4/src/ctc/protocols/llama_utils/cli/__init__.py
+-rw-r--r--   0        0        0      563 2022-11-23 19:36:31.135510 checkthechain-0.3.4/src/ctc/protocols/llama_utils/cli/llama_chain_command.py
+-rw-r--r--   0        0        0      637 2022-11-23 19:36:31.135597 checkthechain-0.3.4/src/ctc/protocols/llama_utils/cli/llama_chains_command.py
+-rw-r--r--   0        0        0      355 2022-11-23 19:36:31.135677 checkthechain-0.3.4/src/ctc/protocols/llama_utils/cli/llama_command.py
+-rw-r--r--   0        0        0      627 2022-11-23 19:36:31.135766 checkthechain-0.3.4/src/ctc/protocols/llama_utils/cli/llama_pool_command.py
+-rw-r--r--   0        0        0     3756 2023-04-17 01:08:32.684084 checkthechain-0.3.4/src/ctc/protocols/llama_utils/cli/llama_pools_command.py
+-rw-r--r--   0        0        0      877 2022-11-23 19:36:31.135929 checkthechain-0.3.4/src/ctc/protocols/llama_utils/cli/llama_protocol_command.py
+-rw-r--r--   0        0        0     1307 2022-11-23 19:36:31.135982 checkthechain-0.3.4/src/ctc/protocols/llama_utils/cli/llama_protocols_command.py
+-rw-r--r--   0        0        0     4886 2023-04-17 01:06:44.638753 checkthechain-0.3.4/src/ctc/protocols/llama_utils/llama_requests.py
+-rw-r--r--   0        0        0     6140 2023-02-26 18:21:06.991562 checkthechain-0.3.4/src/ctc/protocols/llama_utils/llama_tvls.py
+-rw-r--r--   0        0        0    10185 2023-04-17 01:08:15.444434 checkthechain-0.3.4/src/ctc/protocols/llama_utils/llama_yields.py
+-rw-r--r--   0        0        0       88 2022-11-23 19:36:31.136328 checkthechain-0.3.4/src/ctc/protocols/multicall_utils/__init__.py
+-rw-r--r--   0        0        0     4439 2023-04-11 16:49:40.251517 checkthechain-0.3.4/src/ctc/protocols/multicall_utils/call_utils.py
+-rw-r--r--   0        0        0     1511 2023-04-17 01:06:25.624061 checkthechain-0.3.4/src/ctc/protocols/multicall_utils/multicall_spec.py
+-rw-r--r--   0        0        0     3738 2023-04-12 02:17:20.118623 checkthechain-0.3.4/src/ctc/protocols/multicall_utils/multicalls_utils.py
+-rw-r--r--   0        0        0       57 2022-11-23 19:36:31.136829 checkthechain-0.3.4/src/ctc/protocols/rari_utils/__init__.py
+-rw-r--r--   0        0        0        0 2022-11-23 19:36:31.136919 checkthechain-0.3.4/src/ctc/protocols/rari_utils/cli/__init__.py
+-rw-r--r--   0        0        0        0 2022-11-23 19:36:31.137039 checkthechain-0.3.4/src/ctc/protocols/rari_utils/cli/rari/__init__.py
+-rw-r--r--   0        0        0     2938 2022-11-23 19:36:31.137166 checkthechain-0.3.4/src/ctc/protocols/rari_utils/cli/rari/fuse_command.py
+-rw-r--r--   0        0        0     1584 2022-11-23 19:36:31.137258 checkthechain-0.3.4/src/ctc/protocols/rari_utils/cli/rari/pools_command.py
+-rw-r--r--   0        0        0     1367 2022-11-23 19:36:31.137399 checkthechain-0.3.4/src/ctc/protocols/rari_utils/fuse_lens/README.md
+-rw-r--r--   0        0        0      108 2022-11-23 19:36:31.137466 checkthechain-0.3.4/src/ctc/protocols/rari_utils/fuse_lens/__init__.py
+-rw-r--r--   0        0        0    21649 2022-11-23 19:36:31.137582 checkthechain-0.3.4/src/ctc/protocols/rari_utils/fuse_lens/lens_abis.py
+-rw-r--r--   0        0        0     8029 2023-04-17 01:30:37.145025 checkthechain-0.3.4/src/ctc/protocols/rari_utils/fuse_lens/lens_spec.py
+-rw-r--r--   0        0        0    15145 2023-04-17 01:30:56.860930 checkthechain-0.3.4/src/ctc/protocols/rari_utils/fuse_lens/primary_lens.py
+-rw-r--r--   0        0        0      205 2022-11-23 19:36:31.137849 checkthechain-0.3.4/src/ctc/protocols/rari_utils/fuse_lens/secondary_lens.py
+-rw-r--r--   0        0        0      231 2022-11-23 19:36:31.137957 checkthechain-0.3.4/src/ctc/protocols/rari_utils/fuse_queries/__init__.py
+-rw-r--r--   0        0        0      794 2023-02-26 18:21:06.993247 checkthechain-0.3.4/src/ctc/protocols/rari_utils/fuse_queries/directory_metadata.py
+-rw-r--r--   0        0        0      711 2022-11-23 19:36:31.138102 checkthechain-0.3.4/src/ctc/protocols/rari_utils/fuse_queries/irm_metadata.py
+-rw-r--r--   0        0        0     2913 2022-11-23 19:36:31.138171 checkthechain-0.3.4/src/ctc/protocols/rari_utils/fuse_queries/pool_metadata.py
+-rw-r--r--   0        0        0     2704 2022-11-23 19:36:31.138236 checkthechain-0.3.4/src/ctc/protocols/rari_utils/fuse_queries/pool_state.py
+-rw-r--r--   0        0        0     3188 2022-11-23 19:36:31.138313 checkthechain-0.3.4/src/ctc/protocols/rari_utils/fuse_queries/pool_summary.py
+-rw-r--r--   0        0        0     1311 2022-11-23 19:36:31.138413 checkthechain-0.3.4/src/ctc/protocols/rari_utils/fuse_queries/token_metadata.py
+-rw-r--r--   0        0        0       84 2022-11-23 19:36:31.138564 checkthechain-0.3.4/src/ctc/protocols/rari_utils/fuse_queries/token_state/__init__.py
+-rw-r--r--   0        0        0     3627 2022-11-23 19:36:31.138668 checkthechain-0.3.4/src/ctc/protocols/rari_utils/fuse_queries/token_state/token_interest.py
+-rw-r--r--   0        0        0     2071 2022-11-23 19:36:31.138773 checkthechain-0.3.4/src/ctc/protocols/rari_utils/fuse_queries/token_state/token_price.py
+-rw-r--r--   0        0        0     3658 2022-11-23 19:36:31.138888 checkthechain-0.3.4/src/ctc/protocols/rari_utils/fuse_queries/token_state/token_usage.py
+-rw-r--r--   0        0        0     5852 2023-04-17 01:28:05.297767 checkthechain-0.3.4/src/ctc/protocols/rari_utils/fuse_queries/token_summary.py
+-rw-r--r--   0        0        0    89362 2022-11-23 19:36:31.139251 checkthechain-0.3.4/src/ctc/protocols/rari_utils/rari_abis.py
+-rw-r--r--   0        0        0    11979 2023-02-26 18:21:06.993503 checkthechain-0.3.4/src/ctc/protocols/rari_utils/summary_utils.py
+-rw-r--r--   0        0        0       56 2022-11-23 19:36:31.139484 checkthechain-0.3.4/src/ctc/protocols/sushi_utils/__init__.py
+-rw-r--r--   0        0        0      337 2022-11-23 19:36:31.139559 checkthechain-0.3.4/src/ctc/protocols/sushi_utils/sushi_spec.py
+-rw-r--r--   0        0        0      918 2023-02-26 18:21:06.993785 checkthechain-0.3.4/src/ctc/protocols/sushi_utils/sushiswap_crud.py
+-rw-r--r--   0        0        0      166 2022-11-23 19:36:31.139748 checkthechain-0.3.4/src/ctc/protocols/uniswap_v2_utils/__init__.py
+-rw-r--r--   0        0        0        0 2022-11-23 19:36:31.139808 checkthechain-0.3.4/src/ctc/protocols/uniswap_v2_utils/cli/__init__.py
+-rw-r--r--   0        0        0     1423 2022-11-23 19:36:31.139896 checkthechain-0.3.4/src/ctc/protocols/uniswap_v2_utils/cli/burns_command.py
+-rw-r--r--   0        0        0     6445 2023-04-15 16:03:17.419508 checkthechain-0.3.4/src/ctc/protocols/uniswap_v2_utils/cli/chart_command.py
+-rw-r--r--   0        0        0     1423 2022-11-23 19:36:31.140033 checkthechain-0.3.4/src/ctc/protocols/uniswap_v2_utils/cli/mints_command.py
+-rw-r--r--   0        0        0     1846 2023-04-15 15:59:51.449246 checkthechain-0.3.4/src/ctc/protocols/uniswap_v2_utils/cli/pool_command.py
+-rw-r--r--   0        0        0     1440 2022-11-23 19:36:31.140220 checkthechain-0.3.4/src/ctc/protocols/uniswap_v2_utils/cli/swaps_command.py
+-rw-r--r--   0        0        0     8203 2023-04-11 04:48:00.558717 checkthechain-0.3.4/src/ctc/protocols/uniswap_v2_utils/uniswap_v2_deltas.py
+-rw-r--r--   0        0        0     5717 2023-04-15 15:59:32.040213 checkthechain-0.3.4/src/ctc/protocols/uniswap_v2_utils/uniswap_v2_events.py
+-rw-r--r--   0        0        0     2776 2023-04-12 16:09:31.994054 checkthechain-0.3.4/src/ctc/protocols/uniswap_v2_utils/uniswap_v2_metadata.py
+-rw-r--r--   0        0        0     5089 2023-04-17 01:27:08.232982 checkthechain-0.3.4/src/ctc/protocols/uniswap_v2_utils/uniswap_v2_spec.py
+-rw-r--r--   0        0        0     3887 2023-05-03 23:41:11.177114 checkthechain-0.3.4/src/ctc/protocols/uniswap_v2_utils/uniswap_v2_state.py
+-rw-r--r--   0        0        0      151 2023-06-03 00:20:08.975286 checkthechain-0.3.4/src/ctc/protocols/uniswap_v3_utils/__init__.py
+-rw-r--r--   0        0        0      138 2022-11-23 19:36:31.141120 checkthechain-0.3.4/src/ctc/protocols/uniswap_v3_utils/contracts/__init__.py
+-rw-r--r--   0        0        0     1443 2023-02-26 18:21:06.994940 checkthechain-0.3.4/src/ctc/protocols/uniswap_v3_utils/contracts/pool_derived_state.py
+-rw-r--r--   0        0        0     3240 2023-02-26 18:21:06.995117 checkthechain-0.3.4/src/ctc/protocols/uniswap_v3_utils/contracts/pool_immutables.py
+-rw-r--r--   0        0        0     6560 2023-04-17 01:31:30.100039 checkthechain-0.3.4/src/ctc/protocols/uniswap_v3_utils/contracts/pool_state.py
+-rw-r--r--   0        0        0     3006 2023-02-26 18:21:06.995466 checkthechain-0.3.4/src/ctc/protocols/uniswap_v3_utils/contracts/quoter.py
+-rw-r--r--   0        0        0      860 2023-02-26 18:21:06.995686 checkthechain-0.3.4/src/ctc/protocols/uniswap_v3_utils/contracts/tick_lens.py
+-rw-r--r--   0        0        0     3562 2023-04-17 01:31:50.529264 checkthechain-0.3.4/src/ctc/protocols/uniswap_v3_utils/uniswap_v3_crud.py
+-rw-r--r--   0        0        0     3751 2023-02-26 18:21:06.996225 checkthechain-0.3.4/src/ctc/protocols/uniswap_v3_utils/uniswap_v3_depth.py
+-rw-r--r--   0        0        0     3163 2023-02-26 18:21:06.996363 checkthechain-0.3.4/src/ctc/protocols/uniswap_v3_utils/uniswap_v3_spec.py
+-rw-r--r--   0        0        0     6720 2023-06-03 00:20:08.975536 checkthechain-0.3.4/src/ctc/protocols/uniswap_v3_utils/uniswap_v3_swaps.py
+-rw-r--r--   0        0        0      140 2022-11-23 19:36:31.141857 checkthechain-0.3.4/src/ctc/protocols/yearn_utils/__init__.py
+-rw-r--r--   0        0        0        0 2022-11-23 19:36:31.141930 checkthechain-0.3.4/src/ctc/protocols/yearn_utils/cli/__init__.py
+-rw-r--r--   0        0        0     1073 2023-04-12 02:18:13.432357 checkthechain-0.3.4/src/ctc/protocols/yearn_utils/cli/yearn_addresses_command.py
+-rw-r--r--   0        0        0     2553 2023-04-12 02:18:04.750648 checkthechain-0.3.4/src/ctc/protocols/yearn_utils/cli/yearn_command.py
+-rw-r--r--   0        0        0     5692 2023-04-12 02:17:48.585548 checkthechain-0.3.4/src/ctc/protocols/yearn_utils/yearn_addresses.py
+-rw-r--r--   0        0        0     1864 2022-11-23 19:36:31.142281 checkthechain-0.3.4/src/ctc/protocols/yearn_utils/yearn_spec.py
+-rw-r--r--   0        0        0     2885 2023-04-11 05:22:09.399822 checkthechain-0.3.4/src/ctc/protocols/yearn_utils/yearn_strategies.py
+-rw-r--r--   0        0        0     1200 2023-02-26 18:21:06.996752 checkthechain-0.3.4/src/ctc/protocols/yearn_utils/yearn_tvls.py
+-rw-r--r--   0        0        0    11227 2023-04-11 03:24:04.115576 checkthechain-0.3.4/src/ctc/protocols/yearn_utils/yearn_vaults.py
+-rw-r--r--   0        0        0     2327 2022-11-23 19:36:31.142631 checkthechain-0.3.4/src/ctc/protocols/yearn_utils/yearn_web_api.py
+-rw-r--r--   0        0        0        0 2022-11-23 19:36:31.142664 checkthechain-0.3.4/src/ctc/py.typed
+-rw-r--r--   0        0        0      370 2023-04-29 02:18:16.632039 checkthechain-0.3.4/src/ctc/rpc/__init__.py
+-rw-r--r--   0        0        0      104 2022-11-23 19:36:31.142859 checkthechain-0.3.4/src/ctc/rpc/rpc_batch/__init__.py
+-rw-r--r--   0        0        0    16275 2023-03-04 19:50:23.519624 checkthechain-0.3.4/src/ctc/rpc/rpc_batch/rpc_batch_constructors.py
+-rw-r--r--   0        0        0    13042 2023-03-04 19:50:23.520213 checkthechain-0.3.4/src/ctc/rpc/rpc_batch/rpc_batch_executors.py
+-rw-r--r--   0        0        0     4185 2023-04-13 02:20:26.971506 checkthechain-0.3.4/src/ctc/rpc/rpc_batch/rpc_batch_utils.py
+-rw-r--r--   0        0        0      389 2023-02-26 18:21:06.998278 checkthechain-0.3.4/src/ctc/rpc/rpc_constructors/__init__.py
+-rw-r--r--   0        0        0     2442 2023-04-11 16:31:38.655891 checkthechain-0.3.4/src/ctc/rpc/rpc_constructors/rpc_block_constructors.py
+-rw-r--r--   0        0        0      602 2023-02-26 18:21:06.998793 checkthechain-0.3.4/src/ctc/rpc/rpc_constructors/rpc_dev_constructors.py
+-rw-r--r--   0        0        0     2486 2023-02-26 18:21:06.998980 checkthechain-0.3.4/src/ctc/rpc/rpc_constructors/rpc_log_constructors.py
+-rw-r--r--   0        0        0      951 2023-02-26 18:21:06.999159 checkthechain-0.3.4/src/ctc/rpc/rpc_constructors/rpc_mining_constructors.py
+-rw-r--r--   0        0        0     1004 2023-02-26 18:21:06.999424 checkthechain-0.3.4/src/ctc/rpc/rpc_constructors/rpc_node_constructors.py
+-rw-r--r--   0        0        0     3443 2023-04-11 16:30:45.199617 checkthechain-0.3.4/src/ctc/rpc/rpc_constructors/rpc_state_constructors.py
+-rw-r--r--   0        0        0     1916 2023-02-26 18:21:06.999889 checkthechain-0.3.4/src/ctc/rpc/rpc_constructors/rpc_submission_constructors.py
+-rw-r--r--   0        0        0     7325 2023-06-03 00:20:08.976370 checkthechain-0.3.4/src/ctc/rpc/rpc_constructors/rpc_trace_constructors.py
+-rw-r--r--   0        0        0     2138 2023-04-11 16:31:54.035220 checkthechain-0.3.4/src/ctc/rpc/rpc_constructors/rpc_transaction_constructors.py
+-rw-r--r--   0        0        0     2069 2023-02-26 18:21:07.000693 checkthechain-0.3.4/src/ctc/rpc/rpc_constructors/rpc_whisper_constructors.py
+-rw-r--r--   0        0        0        0 2023-03-11 18:04:07.082068 checkthechain-0.3.4/src/ctc/rpc/rpc_decoders/__init__.py
+-rw-r--r--   0        0        0     4653 2023-05-03 06:18:05.706354 checkthechain-0.3.4/src/ctc/rpc/rpc_decoders/call_trace_decoder.py
+-rw-r--r--   0        0        0     2258 2023-04-21 15:41:10.224968 checkthechain-0.3.4/src/ctc/rpc/rpc_decoders/create_trace_decoder.py
+-rw-r--r--   0        0        0      998 2023-03-26 06:20:45.338428 checkthechain-0.3.4/src/ctc/rpc/rpc_decoders/log_decoder.py
+-rw-r--r--   0        0        0     4653 2023-05-02 22:58:53.788729 checkthechain-0.3.4/src/ctc/rpc/rpc_decoders/native_transfer_decoder.py
+-rw-r--r--   0        0        0     6779 2023-05-03 16:33:35.235586 checkthechain-0.3.4/src/ctc/rpc/rpc_decoders/slot_diff_decoder.py
+-rw-r--r--   0        0        0      359 2023-02-26 18:21:07.000942 checkthechain-0.3.4/src/ctc/rpc/rpc_digestors/__init__.py
+-rw-r--r--   0        0        0     3589 2022-11-23 19:36:31.144157 checkthechain-0.3.4/src/ctc/rpc/rpc_digestors/rpc_block_digestors.py
+-rw-r--r--   0        0        0      552 2022-11-23 19:36:31.144227 checkthechain-0.3.4/src/ctc/rpc/rpc_digestors/rpc_dev_digestors.py
+-rw-r--r--   0        0        0     3831 2022-11-23 19:36:31.144290 checkthechain-0.3.4/src/ctc/rpc/rpc_digestors/rpc_log_digestors.py
+-rw-r--r--   0        0        0      773 2022-11-23 19:36:31.144353 checkthechain-0.3.4/src/ctc/rpc/rpc_digestors/rpc_mining_digestors.py
+-rw-r--r--   0        0        0     1465 2022-11-23 19:36:31.144412 checkthechain-0.3.4/src/ctc/rpc/rpc_digestors/rpc_node_digestors.py
+-rw-r--r--   0        0        0     1738 2022-11-23 19:36:31.144465 checkthechain-0.3.4/src/ctc/rpc/rpc_digestors/rpc_state_digestors.py
+-rw-r--r--   0        0        0     1197 2022-11-23 19:36:31.144518 checkthechain-0.3.4/src/ctc/rpc/rpc_digestors/rpc_submission_digestors.py
+-rw-r--r--   0        0        0     7929 2023-03-04 19:50:23.521981 checkthechain-0.3.4/src/ctc/rpc/rpc_digestors/rpc_trace_digestors.py
+-rw-r--r--   0        0        0     2747 2022-11-23 19:36:31.144581 checkthechain-0.3.4/src/ctc/rpc/rpc_digestors/rpc_transaction_digestors.py
+-rw-r--r--   0        0        0     1269 2022-11-23 19:36:31.144661 checkthechain-0.3.4/src/ctc/rpc/rpc_digestors/rpc_whisper_digestors.py
+-rw-r--r--   0        0        0      380 2023-04-29 02:55:17.696175 checkthechain-0.3.4/src/ctc/rpc/rpc_executors_async/__init__.py
+-rw-r--r--   0        0        0     4628 2023-05-04 00:21:12.284488 checkthechain-0.3.4/src/ctc/rpc/rpc_executors_async/rpc_block_executors_async.py
+-rw-r--r--   0        0        0     1437 2023-03-27 22:28:00.721319 checkthechain-0.3.4/src/ctc/rpc/rpc_executors_async/rpc_dev_executors_async.py
+-rw-r--r--   0        0        0     5279 2023-03-26 06:20:39.297576 checkthechain-0.3.4/src/ctc/rpc/rpc_executors_async/rpc_log_executors_async.py
+-rw-r--r--   0        0        0     2190 2023-02-26 18:21:07.002129 checkthechain-0.3.4/src/ctc/rpc/rpc_executors_async/rpc_mining_executors_async.py
+-rw-r--r--   0        0        0     2851 2023-02-26 18:21:07.002296 checkthechain-0.3.4/src/ctc/rpc/rpc_executors_async/rpc_node_executors_async.py
+-rw-r--r--   0        0        0     6117 2023-04-13 02:15:46.804141 checkthechain-0.3.4/src/ctc/rpc/rpc_executors_async/rpc_state_executors_async.py
+-rw-r--r--   0        0        0     3168 2023-02-26 18:21:07.002644 checkthechain-0.3.4/src/ctc/rpc/rpc_executors_async/rpc_submission_executors_async.py
+-rw-r--r--   0        0        0    10219 2023-03-04 19:50:23.522274 checkthechain-0.3.4/src/ctc/rpc/rpc_executors_async/rpc_trace_executors_async.py
+-rw-r--r--   0        0        0     4590 2023-02-26 18:21:07.003081 checkthechain-0.3.4/src/ctc/rpc/rpc_executors_async/rpc_transaction_executors_async.py
+-rw-r--r--   0        0        0     3970 2023-02-26 18:21:07.003260 checkthechain-0.3.4/src/ctc/rpc/rpc_executors_async/rpc_whisper_executors_async.py
+-rw-r--r--   0        0        0      372 2023-04-29 02:20:39.544187 checkthechain-0.3.4/src/ctc/rpc/rpc_executors_sync/__init__.py
+-rw-r--r--   0        0        0     4530 2023-04-29 02:40:39.931253 checkthechain-0.3.4/src/ctc/rpc/rpc_executors_sync/rpc_block_executors_sync.py
+-rw-r--r--   0        0        0     1381 2023-04-29 02:41:16.847417 checkthechain-0.3.4/src/ctc/rpc/rpc_executors_sync/rpc_dev_executors_sync.py
+-rw-r--r--   0        0        0     5174 2023-04-29 02:42:15.741339 checkthechain-0.3.4/src/ctc/rpc/rpc_executors_sync/rpc_log_executors_sync.py
+-rw-r--r--   0        0        0     2106 2023-04-29 02:43:32.387691 checkthechain-0.3.4/src/ctc/rpc/rpc_executors_sync/rpc_mining_executors_sync.py
+-rw-r--r--   0        0        0     2739 2023-04-29 02:44:35.472432 checkthechain-0.3.4/src/ctc/rpc/rpc_executors_sync/rpc_node_executors_sync.py
+-rw-r--r--   0        0        0     6033 2023-04-29 02:48:08.574123 checkthechain-0.3.4/src/ctc/rpc/rpc_executors_sync/rpc_state_executors_sync.py
+-rw-r--r--   0        0        0     3084 2023-04-29 02:49:21.046565 checkthechain-0.3.4/src/ctc/rpc/rpc_executors_sync/rpc_submission_executors_sync.py
+-rw-r--r--   0        0        0    10030 2023-04-29 02:50:56.085928 checkthechain-0.3.4/src/ctc/rpc/rpc_executors_sync/rpc_trace_executors_sync.py
+-rw-r--r--   0        0        0     4492 2023-04-29 02:51:37.478912 checkthechain-0.3.4/src/ctc/rpc/rpc_executors_sync/rpc_transaction_executors_sync.py
+-rw-r--r--   0        0        0     3830 2023-04-29 02:53:28.556506 checkthechain-0.3.4/src/ctc/rpc/rpc_executors_sync/rpc_whisper_executors_sync.py
+-rw-r--r--   0        0        0     1068 2022-12-25 15:14:22.765380 checkthechain-0.3.4/src/ctc/rpc/rpc_format.py
+-rw-r--r--   0        0        0     2051 2023-02-26 18:21:07.003537 checkthechain-0.3.4/src/ctc/rpc/rpc_lifecycle.py
+-rw-r--r--   0        0        0     1999 2023-02-26 18:21:07.003667 checkthechain-0.3.4/src/ctc/rpc/rpc_logging.py
+-rw-r--r--   0        0        0       47 2023-04-29 00:10:42.447596 checkthechain-0.3.4/src/ctc/rpc/rpc_protocols/__init__.py
+-rw-r--r--   0        0        0     4255 2023-04-29 03:32:17.512979 checkthechain-0.3.4/src/ctc/rpc/rpc_protocols/rpc_http.py
+-rw-r--r--   0        0        0      321 2023-04-29 00:13:48.363233 checkthechain-0.3.4/src/ctc/rpc/rpc_protocols/rpc_websocket.py
+-rw-r--r--   0        0        0     9770 2023-04-17 01:11:21.303538 checkthechain-0.3.4/src/ctc/rpc/rpc_provider.py
+-rw-r--r--   0        0        0     1128 2022-11-23 19:36:31.146057 checkthechain-0.3.4/src/ctc/rpc/rpc_registry.py
+-rw-r--r--   0        0        0       86 2023-04-29 02:54:07.448132 checkthechain-0.3.4/src/ctc/rpc/rpc_request/__init__.py
+-rw-r--r--   0        0        0     4730 2023-04-29 00:11:33.888738 checkthechain-0.3.4/src/ctc/rpc/rpc_request/request_async.py
+-rw-r--r--   0        0        0     4620 2023-04-29 02:58:16.903919 checkthechain-0.3.4/src/ctc/rpc/rpc_request/request_sync.py
+-rw-r--r--   0        0        0     4602 2023-06-02 23:42:32.086805 checkthechain-0.3.4/src/ctc/rpc/rpc_request/request_utils.py
+-rw-r--r--   0        0        0     3688 2023-03-04 19:50:23.524532 checkthechain-0.3.4/src/ctc/rpc/rpc_spec.py
+-rw-r--r--   0        0        0      102 2023-02-26 18:21:07.005328 checkthechain-0.3.4/src/ctc/spec/__init__.py
+-rw-r--r--   0        0        0      126 2022-11-23 19:36:31.146419 checkthechain-0.3.4/src/ctc/spec/exceptions/__init__.py
+-rw-r--r--   0        0        0       85 2022-11-23 19:36:31.146519 checkthechain-0.3.4/src/ctc/spec/exceptions/abi_exceptions.py
+-rw-r--r--   0        0        0      230 2023-04-17 00:04:51.283975 checkthechain-0.3.4/src/ctc/spec/exceptions/config_exceptions.py
+-rw-r--r--   0        0        0       87 2022-11-23 19:36:31.146696 checkthechain-0.3.4/src/ctc/spec/exceptions/oracle_exceptions.py
+-rw-r--r--   0        0        0      131 2022-11-23 19:36:31.146783 checkthechain-0.3.4/src/ctc/spec/exceptions/rpc_exceptions.py
+-rw-r--r--   0        0        0      487 2022-11-23 19:36:31.146870 checkthechain-0.3.4/src/ctc/spec/formatting.py
+-rw-r--r--   0        0        0     4620 2023-04-12 16:44:13.479488 checkthechain-0.3.4/src/ctc/spec/typedata.py
+-rw-r--r--   0        0        0      704 2023-02-26 18:21:07.005950 checkthechain-0.3.4/src/ctc/spec/typedefs/__init__.py
+-rw-r--r--   0        0        0     2116 2023-04-17 01:15:16.387519 checkthechain-0.3.4/src/ctc/spec/typedefs/abi_types.py
+-rw-r--r--   0        0        0     1012 2023-04-15 07:13:56.749794 checkthechain-0.3.4/src/ctc/spec/typedefs/address_types.py
+-rw-r--r--   0        0        0      948 2022-11-23 19:36:31.147255 checkthechain-0.3.4/src/ctc/spec/typedefs/binary_types.py
+-rw-r--r--   0        0        0     2239 2023-02-26 18:21:07.006211 checkthechain-0.3.4/src/ctc/spec/typedefs/block_types.py
+-rw-r--r--   0        0        0     2019 2023-04-17 01:15:50.282375 checkthechain-0.3.4/src/ctc/spec/typedefs/config_types.py
+-rw-r--r--   0        0        0      154 2023-02-26 18:21:07.006635 checkthechain-0.3.4/src/ctc/spec/typedefs/consensus_types.py
+-rw-r--r--   0        0        0     1571 2023-04-12 00:25:44.366208 checkthechain-0.3.4/src/ctc/spec/typedefs/context_types.py
+-rw-r--r--   0        0        0     1150 2023-04-17 01:34:02.808903 checkthechain-0.3.4/src/ctc/spec/typedefs/data_source_types.py
+-rw-r--r--   0        0        0      752 2023-02-26 18:21:07.007297 checkthechain-0.3.4/src/ctc/spec/typedefs/db_types.py
+-rw-r--r--   0        0        0      539 2023-04-10 06:29:29.191082 checkthechain-0.3.4/src/ctc/spec/typedefs/defi_types.py
+-rw-r--r--   0        0        0     1178 2023-04-17 01:14:53.735415 checkthechain-0.3.4/src/ctc/spec/typedefs/event_types.py
+-rw-r--r--   0        0        0      971 2023-04-13 02:34:03.315850 checkthechain-0.3.4/src/ctc/spec/typedefs/external_types.py
+-rw-r--r--   0        0        0      728 2023-02-26 18:21:07.007839 checkthechain-0.3.4/src/ctc/spec/typedefs/log_types.py
+-rw-r--r--   0        0        0      300 2023-04-17 01:28:53.685750 checkthechain-0.3.4/src/ctc/spec/typedefs/network_types.py
+-rw-r--r--   0        0        0      165 2022-11-23 19:36:31.147653 checkthechain-0.3.4/src/ctc/spec/typedefs/number_types.py
+-rw-r--r--   0        0        0     2178 2023-03-24 20:18:53.548764 checkthechain-0.3.4/src/ctc/spec/typedefs/rpc_types.py
+-rw-r--r--   0        0        0      671 2022-11-23 19:36:31.147834 checkthechain-0.3.4/src/ctc/spec/typedefs/storage_types.py
+-rw-r--r--   0        0        0     4523 2023-03-04 19:50:23.525113 checkthechain-0.3.4/src/ctc/spec/typedefs/trace_types.py
+-rw-r--r--   0        0        0     4519 2023-04-17 01:29:16.409479 checkthechain-0.3.4/src/ctc/spec/typedefs/transaction_types.py
+-rw-r--r--   0        0        0      129 2023-04-17 00:26:49.657179 checkthechain-0.3.4/src/ctc/spec/typeguards/__init__.py
+-rw-r--r--   0        0        0     1637 2022-11-23 19:36:31.148153 checkthechain-0.3.4/src/ctc/spec/typeguards/binary_typeguards.py
+-rw-r--r--   0        0        0     1708 2022-11-23 19:36:31.148252 checkthechain-0.3.4/src/ctc/spec/typeguards/block_typeguards.py
+-rw-r--r--   0        0        0      289 2023-02-26 20:15:07.427239 checkthechain-0.3.4/src/ctc/spec/typeguards/db_typeguards.py
+-rw-r--r--   0        0        0     1422 2023-04-11 15:03:04.546469 checkthechain-0.3.4/src/ctc/spec/typeguards/external_typeguards.py
+-rw-r--r--   0        0        0        0 2022-11-23 19:36:31.148387 checkthechain-0.3.4/src/ctc/toolbox/__init__.py
+-rw-r--r--   0        0        0     1441 2022-11-23 19:36:31.152899 checkthechain-0.3.4/src/ctc/toolbox/nested_utils.py
+-rw-r--r--   0        0        0     3258 2023-04-15 07:19:21.326943 checkthechain-0.3.4/src/ctc/toolbox/optimize_utils.py
+-rw-r--r--   0        0        0      175 2023-04-24 06:28:07.927137 checkthechain-0.3.4/src/ctc/toolbox/pl_utils/__init__.py
+-rw-r--r--   0        0        0     2464 2023-04-11 15:01:28.142423 checkthechain-0.3.4/src/ctc/toolbox/pl_utils/binary_utils.py
+-rw-r--r--   0        0        0     1002 2023-04-11 15:00:27.569336 checkthechain-0.3.4/src/ctc/toolbox/pl_utils/concat_utils.py
+-rw-r--r--   0        0        0     2638 2023-04-24 06:28:56.069741 checkthechain-0.3.4/src/ctc/toolbox/pl_utils/file_utils.py
+-rw-r--r--   0        0        0     3562 2023-05-30 06:46:30.793034 checkthechain-0.3.4/src/ctc/toolbox/pl_utils/interpolate_utils.py
+-rw-r--r--   0        0        0    13676 2023-04-24 18:32:50.650896 checkthechain-0.3.4/src/ctc/toolbox/pl_utils/partition_utils.py
+-rw-r--r--   0        0        0     7632 2023-05-03 17:48:02.702127 checkthechain-0.3.4/src/ctc/toolbox/pl_utils/summary_utils.py
+-rw-r--r--   0        0        0     3512 2023-02-26 18:21:07.014557 checkthechain-0.3.4/src/ctc/toolbox/plot_utils.py
+-rw-r--r--   0        0        0     8876 2023-03-04 19:50:23.527332 checkthechain-0.3.4/src/ctc/toolbox/range_utils.py
+-rw-r--r--   0        0        0     9045 2022-11-23 19:36:31.153915 checkthechain-0.3.4/src/ctc/toolbox/search_utils.py
+-rw-r--r--   0        0        0      719 2023-02-27 08:14:19.899656 checkthechain-0.3.4/tests/conftest.py
+-rw-r--r--   0        0        0    20988 2022-11-23 19:36:31.154352 checkthechain-0.3.4/tests/ctc/binary/.hypothesis/unicode_data/13.0.0/charmap.json.gz
+-rw-r--r--   0        0        0      789 2022-11-23 19:36:31.154466 checkthechain-0.3.4/tests/ctc/binary/test_eip712.py
+-rw-r--r--   0        0        0     1224 2022-11-23 19:36:31.154549 checkthechain-0.3.4/tests/ctc/binary/test_format_utils.py
+-rw-r--r--   0        0        0      795 2022-11-23 19:36:31.154622 checkthechain-0.3.4/tests/ctc/binary/test_hash_utils.py
+-rw-r--r--   0        0        0     3946 2023-04-11 17:17:48.856155 checkthechain-0.3.4/tests/ctc/binary/test_rlp_encoding.py
+-rw-r--r--   0        0        0     4888 2022-11-23 19:36:31.154783 checkthechain-0.3.4/tests/ctc/binary/test_signatures.py
+-rw-r--r--   0        0        0     1702 2022-11-23 19:36:31.154907 checkthechain-0.3.4/tests/ctc/cli/test_cli_args.py
+-rw-r--r--   0        0        0     3589 2022-11-23 19:36:31.155012 checkthechain-0.3.4/tests/ctc/cli/test_cli_subcommands.py
+-rw-r--r--   0        0        0    16961 2023-02-26 18:21:07.015169 checkthechain-0.3.4/tests/ctc/config/contexts/test_cache_contexts.py
+-rw-r--r--   0        0        0     5248 2023-04-12 02:20:12.521865 checkthechain-0.3.4/tests/ctc/config/contexts/test_network_contexts.py
+-rw-r--r--   0        0        0      620 2022-11-23 19:36:31.155162 checkthechain-0.3.4/tests/ctc/config/test_config_defaults.py
+-rw-r--r--   0        0        0     4545 2023-04-26 23:49:26.324218 checkthechain-0.3.4/tests/ctc/config/test_config_validators.py
+-rw-r--r--   0        0        0     9776 2023-04-11 22:11:40.166308 checkthechain-0.3.4/tests/ctc/config/test_setup.py
+-rw-r--r--   0        0        0     3387 2023-04-12 02:19:52.771416 checkthechain-0.3.4/tests/ctc/db/db_crud/test_db_block_timestamps.py
+-rw-r--r--   0        0        0     5624 2023-04-12 02:23:22.803870 checkthechain-0.3.4/tests/ctc/db/db_crud/test_db_blocks.py
+-rw-r--r--   0        0        0     2624 2023-04-12 02:19:46.343714 checkthechain-0.3.4/tests/ctc/db/db_crud/test_db_contract_abis.py
+-rw-r--r--   0        0        0     1906 2023-04-12 02:23:17.026530 checkthechain-0.3.4/tests/ctc/db/db_crud/test_db_contract_creation.py
+-rw-r--r--   0        0        0     3295 2023-04-12 02:19:42.769384 checkthechain-0.3.4/tests/ctc/db/db_crud/test_db_erc20_metadata.py
+-rw-r--r--   0        0        0      446 2022-11-23 19:36:31.155877 checkthechain-0.3.4/tests/ctc/db/db_schemas.py
+-rw-r--r--   0        0        0     1081 2023-02-27 08:07:49.692060 checkthechain-0.3.4/tests/ctc/db/dba_utils.py
+-rw-r--r--   0        0        0    11873 2023-04-14 23:05:20.037248 checkthechain-0.3.4/tests/ctc/db/test_crud_problems.py
+-rw-r--r--   0        0        0    20988 2022-11-23 19:36:31.156314 checkthechain-0.3.4/tests/ctc/directory/.hypothesis/unicode_data/13.0.0/charmap.json.gz
+-rw-r--r--   0        0        0     1104 2023-04-17 00:07:23.260049 checkthechain-0.3.4/tests/ctc/directory/test_directory_networks.py
+-rw-r--r--   0        0        0      588 2022-11-23 19:36:31.156484 checkthechain-0.3.4/tests/ctc/directory/test_directory_tokens.py
+-rw-r--r--   0        0        0     1322 2022-11-23 19:36:31.156621 checkthechain-0.3.4/tests/ctc/docs/test_readme_examples.py
+-rw-r--r--   0        0        0    20988 2022-11-23 19:36:31.156862 checkthechain-0.3.4/tests/ctc/evm/.hypothesis/unicode_data/13.0.0/charmap.json.gz
+-rw-r--r--   0        0        0     3757 2022-11-23 19:36:31.156975 checkthechain-0.3.4/tests/ctc/evm/test_address_utils.py
+-rw-r--r--   0        0        0     2687 2023-02-26 18:21:07.018040 checkthechain-0.3.4/tests/ctc/evm/test_block_utils.py
+-rw-r--r--   0        0        0      514 2023-04-12 04:51:28.445072 checkthechain-0.3.4/tests/ctc/evm/test_erc20_utils/test_erc20_events.py
+-rw-r--r--   0        0        0      588 2022-11-23 19:36:31.157327 checkthechain-0.3.4/tests/ctc/evm/test_erc20_utils/test_erc20_metadata.py
+-rw-r--r--   0        0        0      650 2022-11-23 19:36:31.157422 checkthechain-0.3.4/tests/ctc/evm/test_erc20_utils/test_erc20_state.py
+-rw-r--r--   0        0        0        0 2023-02-26 18:21:07.018238 checkthechain-0.3.4/tests/ctc/evm/test_erc4626_utils/__init__.py
+-rw-r--r--   0        0        0      981 2023-02-26 18:21:07.018338 checkthechain-0.3.4/tests/ctc/evm/test_erc4626_utils/test_erc4626_events.py
+-rw-r--r--   0        0        0     1085 2023-02-26 18:21:07.018415 checkthechain-0.3.4/tests/ctc/evm/test_erc4626_utils/test_erc4626_metadata.py
+-rw-r--r--   0        0        0     2429 2023-02-26 18:21:07.018492 checkthechain-0.3.4/tests/ctc/evm/test_erc4626_utils/test_erc4626_normalize.py
+-rw-r--r--   0        0        0    10489 2023-02-26 18:21:07.018576 checkthechain-0.3.4/tests/ctc/evm/test_erc4626_utils/test_erc4626_state.py
+-rw-r--r--   0        0        0      300 2023-02-26 18:21:07.018842 checkthechain-0.3.4/tests/ctc/evm/test_eth_utils.py
+-rw-r--r--   0        0        0      714 2023-04-12 04:52:01.852764 checkthechain-0.3.4/tests/ctc/evm/test_event_utils.py
+-rw-r--r--   0        0        0     6573 2023-04-12 04:44:35.718866 checkthechain-0.3.4/tests/ctc/evm/test_event_utils_new.py
+-rw-r--r--   0        0        0    20988 2022-11-23 19:36:31.158160 checkthechain-0.3.4/tests/ctc/evm/test_rpc_utils/.hypothesis/unicode_data/13.0.0/charmap.json.gz
+-rw-r--r--   0        0        0     1690 2022-11-23 19:36:31.158245 checkthechain-0.3.4/tests/ctc/evm/test_rpc_utils/test_rpc_blocks.py
+-rw-r--r--   0        0        0     2025 2023-04-12 18:13:33.792410 checkthechain-0.3.4/tests/ctc/evm/test_rpc_utils/test_rpc_logs.py
+-rw-r--r--   0        0        0     1065 2022-11-23 19:36:31.158425 checkthechain-0.3.4/tests/ctc/evm/test_rpc_utils/test_rpc_node.py
+-rw-r--r--   0        0        0     5693 2022-11-23 19:36:31.158531 checkthechain-0.3.4/tests/ctc/evm/test_rpc_utils/test_rpc_state.py
+-rw-r--r--   0        0        0      325 2023-02-26 18:21:07.019547 checkthechain-0.3.4/tests/ctc/evm/test_rpc_utils/test_rpc_submission.py
+-rw-r--r--   0        0        0     2185 2022-11-23 19:36:31.158726 checkthechain-0.3.4/tests/ctc/evm/test_rpc_utils/test_rpc_transactions.py
+-rw-r--r--   0        0        0     3751 2023-04-12 18:09:08.234614 checkthechain-0.3.4/tests/ctc/evm/test_transaction_utils/test_transaction_utils.py
+-rw-r--r--   0        0        0      915 2022-11-23 19:36:31.159046 checkthechain-0.3.4/tests/ctc/protocols/balancer_utils/test_balancer_utils.py
+-rw-r--r--   0        0        0     3367 2023-04-12 02:19:29.511661 checkthechain-0.3.4/tests/ctc/protocols/chainlink_utils/test_chainlink_db.py
+-rw-r--r--   0        0        0     2855 2023-04-27 22:25:08.354233 checkthechain-0.3.4/tests/ctc/protocols/fourbyte_utils/test_fourbyte_db.py
+-rw-r--r--   0        0        0      668 2022-11-23 19:36:31.159439 checkthechain-0.3.4/tests/ctc/protocols/uniswap_v2_utils/test_uniswap_queries.py
+-rw-r--r--   0        0        0     1483 2023-02-26 18:21:07.020336 checkthechain-0.3.4/tests/ctc/spec/test_typedata.py
+-rw-r--r--   0        0        0      867 2023-02-26 18:21:07.020613 checkthechain-0.3.4/tests/ctc/spec/test_typedefs.py
+-rw-r--r--   0        0        0    15225 2023-04-12 19:52:25.910305 checkthechain-0.3.4/tests/ctc/test_code.py
+-rw-r--r--   0        0        0     2008 2023-04-15 22:53:54.067041 checkthechain-0.3.4/tests/ctc/test_config.py
+-rw-r--r--   0        0        0      688 2023-04-15 22:49:32.487864 checkthechain-0.3.4/tests/ctc/toolbox/defi_utils/defi_directory.py
+-rw-r--r--   0        0        0     4168 2023-04-15 22:49:37.457470 checkthechain-0.3.4/tests/ctc/toolbox/defi_utils/dex_utils.py
+-rw-r--r--   0        0        0     5333 2023-04-15 22:49:24.672815 checkthechain-0.3.4/tests/ctc/toolbox/test_amm_utils.py
+-rw-r--r--   0        0        0     6329 2023-02-26 18:21:07.020999 checkthechain-0.3.4/tests/ctc/toolbox/test_chunk_utils.py
+-rw-r--r--   0        0        0      651 2022-11-23 19:36:31.160315 checkthechain-0.3.4/tests/ctc/toolbox/test_feed_utils.py
+-rw-r--r--   0        0        0     4425 2023-03-04 18:28:55.366320 checkthechain-0.3.4/tests/ctc/toolbox/test_range_utils.py
+-rwxr-xr-x   0        0        0      231 2022-11-23 19:36:31.160379 checkthechain-0.3.4/tests/run_type_checks.sh
+-rw-r--r--   0        0        0     9798 1970-01-01 00:00:00.000000 checkthechain-0.3.4/PKG-INFO
```

### Comparing `checkthechain-0.3.0/CHANGELOG.md` & `checkthechain-0.3.4/CHANGELOG.md`

 * *Files 10% similar despite different names*

```diff
@@ -1,12 +1,37 @@
 
 # Changelog
 
 *until version `1.0.0` is reached, will use `0.X.Y` versioning where `X` is for breaking changes / major feature upgrades, and `Y` is for bug fixes / minor feature upgrades*
 
+## 0.3.1
+
+**[WIP] Not Released Yet**
+
+## New Features
+- added erc721_utils for collecting NFT data
+- added erc4626_utils for collecting tokenized vault data
+- upgrade to mypy 0.982 for type annotations
+- add `--receipt` flag to `tx` command
+- add `pd_utils.bin_data()` for performing various bin operations
+- refactor internal versioning system for more robustness
+- add `cli_color_theme` and `cli_chart_charset` options to config for customizing cli colors and charts
+- [WIP]
+
+## Bugfixes
+- adjust request chunk size to prevent server timeouts
+- fix pluralized version of dex pool tvl getters for custom pools
+- support numpy int types in block timestamp search
+- handle null values in yearn api
+- various bugfixes for use of multiple providers on a single network
+- fix hashing of event and function signatures with deep nested structs
+- [WIP]
+
+Update also includes many micro-features and micro-fixes not worth mentioning
+
 ## 0.3.0
 
 **September 25, 2022**
 
 This is a significant release that includes features such as: sql database integration, refactored documentation, streamlined syntax, performance optimizations, and many new types of data queries. This release also includes lots of small bug fixes and quality-of-life improvements not listed below.
 
 #### DB
```

### Comparing `checkthechain-0.3.0/CONTRIBUTING.md` & `checkthechain-0.3.4/CONTRIBUTING.md`

 * *Files 8% similar despite different names*

```diff
@@ -33,18 +33,14 @@
 - use mypy
 - use strict mode
 - avoid using `typing.Any` or `typing.cast()` whenever possible
 - when using general functions that return `Any`, like `json.load()` or `rpc.async_batch_execute()`:
     - validate simple datatypes
     - avoid validating `TypedDict` entries for now
         - wait until a good solution is created either in the python standard library or a 3rd party library
-- until mypy has a mature implementation of variadic generics, use:
-    - `spec.NumpyArray` for numpy arrays
-    - `spec.Series` for pandas Series
-    - `spec.DataFrame` for pandas DataFrames
 
 
 ## API guide
 - naming conventions
     - use consistent variable names across related functions
     - only use by_block, dont use by_blocks or per_block
 - argument design
```

### Comparing `checkthechain-0.3.0/LICENSE` & `checkthechain-0.3.4/LICENSE-MIT`

 * *Files 16% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 The MIT License (MIT)
 
-Copyright © 2022 Fei Labs
+Copyright (c) 2022 checkthechain contributors
 
-Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
+Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
 
 The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
 
-THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
```

#### encoding

```diff
@@ -1 +1 @@
-utf-8
+us-ascii
```

### Comparing `checkthechain-0.3.0/README.md` & `checkthechain-0.3.4/README.md`

 * *Files 3% similar despite different names*

```diff
@@ -29,15 +29,15 @@
 3. [**FAQ**](#faq)
 4. [**Similar Projects**](#similar-projects)
 
 <table>
   <tbody>
     <tr>
       <td>
-        <b>📜 Legal Disclaimer 📜</b> As stated in the MIT license, <code>ctc</code> comes with no warranty of any kind. The authors of <code>ctc</code> accept no responsibility for any damages or negative outcomes that result from using <code>ctc</code> or <code>ctc</code>-derived data. <code>ctc</code> is not audited and using it as a basis for making financial decisions is not recommended.
+        <b>📜 Legal Disclaimer 📜</b> <code>ctc</code> is available under either the MIT license or the Apache license at your option. As stated in both licenses, <code>ctc</code> comes with no warranty of any kind. The authors of <code>ctc</code> accept no responsibility for any damages or negative outcomes that result from using <code>ctc</code> or <code>ctc</code>-derived data. <code>ctc</code> is not audited and using it as a basis for making financial decisions is not recommended.
       </td>
     </tr>
   </tbody>
 </table>
 
 ## Example Usage
 
@@ -150,15 +150,15 @@
 1. `pip install checkthechain`
 2. run `ctc setup` in terminal to specify data provider and data storage path
 
 If your shell's `PATH` does not include python scripts you may need to do something like `python3 -m pip ...` and `python3 -m ctc ...`
 
 Detailed instructions can be found in the [installation documentation](https://ctc.readthedocs.io/en/latest/overview/installation.html).
 
-`ctc` requires python >= 3.7. 
+`ctc` requires python >= 3.7 (supports `3.7`, `3.8`, `3.9`, `3.10`, and `3.11`). 
 
 ## FAQ
 - What are the goals of `ctc`?
     1. **Treat historical data as a first-class feature**: This means having historical data functionality well-integrated into each part of the of the API. It also means optimizing the codebase with historical data workloads in mind.
     2. **Protocol-specific functionality**: This means having built-in support for popular on-chain protocols.
     3. **Terminal-based block explorer**: This means supporting as many block explorer tasks as possible from the terminal. And doing so in a way that is faster than can be done with a web browser.
     4. **Clean API emphasizing UX**: With `ctc` most data queries can be obtained with a single function call. No need to instantiate objects. RPC inputs/outputs are automatically encoded/decoded by default.
```

### Comparing `checkthechain-0.3.0/pyproject.toml` & `checkthechain-0.3.4/pyproject.toml`

 * *Files 13% similar despite different names*

```diff
@@ -1,7 +1,8 @@
+# SPDX-License-Identifier: MIT OR Apache-2.0
 
 #
 # # resources
 #
 
 # https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html
 # https://github.com/flying-sheep/awesome-python-packaging
@@ -16,78 +17,74 @@
 build-backend = "flit_core.buildapi"
 
 [project]
 name = "checkthechain"
 readme = "README.md"
 requires-python = ">=3.7"
 dynamic = ["version", "description"]
-license = {file = "LICENSE"}
+license = {text = "MIT OR Apache-2.0"}
 classifiers = [
     "Development Status :: 4 - Beta",
     "Intended Audience :: Developers",
     "Intended Audience :: Financial and Insurance Industry",
     "Intended Audience :: Science/Research",
+    "License :: OSI Approved :: Apache Software License",
     "License :: OSI Approved :: MIT License",
     "Natural Language :: English",
     "Operating System :: MacOS",
     "Operating System :: Microsoft :: Windows",
     "Operating System :: POSIX :: Linux",
     "Programming Language :: Python :: 3.7",
     "Programming Language :: Python :: 3.8",
     "Programming Language :: Python :: 3.9",
     "Programming Language :: Python :: 3.10",
+    "Programming Language :: Python :: 3.11",
     "Typing :: Typed",
 ]
 dependencies = [
     'typing-extensions >=4.2.0, <5',
     #
     # data science
     'numpy >=1.19.0, <1.24',
-    'pandas >=1.2.0, <1.5',
+    'polars >=0.17.3, <0.18',
+    'pyarrow >=12.0.0, <13',
     #
     # io dependencies
     'aiohttp >=3.7.4, <4',
+    'connectorx==0.3.2a5',
     'loguru >=0.5.3, <0.7',
+    'msgspec >=0.14.1, <0.15',
+    'orjson >=3.7.9, <4',
+    'requests >=2.20.0, <3',
     'toml >=0.10.2, <0.11',
     #
     # tool suite
-    'toolcli >=0.6.8, <0.7',
+    'toolcli >=0.6.13, <0.7',
     'toolconf >=0.1.2, <0.2',
-    'toolsql >=0.3.11, <0.4',
-    'toolstr >=0.8.2, <0.9',
-    'tooltime >=0.2.7, <0.3',
+    'toolsql >=0.6.0, <0.7',
+    'toolstr >=0.9.3, <0.10',
+    'tooltime >=0.2.10, <0.3',
     #
     # EVM dependencies
     'pycryptodome >=3.9.1, <4',  # for keccak()
-    'eth_abi_lite >=3.0.3, <4',  # for abi encoding
-    'idna >=3.3, <4',  # ENS resolution
+    'eth_abi_lite >=3.2.0, <4',  # for abi encoding
+    'idna >=2.10, <4',  # ENS resolution
 ]
 
 [project.optional-dependencies]
 test = [
-    'mypy ==0.960',
-    'mypy_extensions >= 0.4.3, <0.5.0',
-    'pandas-stubs >=1.2.0.1',
+    'mypy ==1.2.0',
+    'mypy_extensions >= 1.0.0, <1.1.0',
     'pytest-asyncio ==0.18.0',
+    'pytest-xdist ==3.1.0',
     'pytest >=6',
     'tox-asdf ==0.1.0',
     'tox ==3.8.0',
     'virtualenv >=20.6.0',
-]
-performance = [
-    'pysha3 ==1.0.2',  # for keccak()
-    'scikit-image >=0.19.2',  # for console unicode drawing with toolstr
-    'orjson >=3.6.8',  # for json loading
-]
-plots = [
-    'matplotlib >=3.1.3',
-    'toolplot >=0.1.0',
-]
-full = [
-    'rlp >=3.0.0',  # for create2 address computation
+    'types-requests >= 2.28.11.17',
 ]
 
 
 [project.urls]
 Documentation = "https://ctc.readthedocs.io/en/latest/"
 Source = "https://github.com/fei-protocol/checkthechain"
 
@@ -167,15 +164,15 @@
 # https://tox.wiki/en/latest/example/basic.html#pyproject-toml-tox-legacy-ini
 
 # run using `tox` in repo root directory
 
 [tool.tox]
 legacy_tox_ini = """
 [tox]
-envlist = py37,py38,py39,py310,py37-legacy
+envlist = py37,py38,py39,py310,py311,py37-legacy
 isolated_build = True
 
 [testenv]
 deps =
     pytest >= 6
     pytest-asyncio
     matplotlib
@@ -187,28 +184,33 @@
     pytest >= 6
     pytest-asyncio
     matplotlib
     typing-extensions==4.2.0
     ;
     ; data science
     numpy==1.19.0
-    pandas==1.2.0
+    polars==0.17.3
+    pyarrow==12.0.0
     ;
     ; data dependencies
     aiohttp==3.7.4
+    connectorx==0.3.2a3
     loguru==0.5.3
+    msgspec==0.14.1
+    orjson==3.7.9
+    requests==2.20.0
     toml==0.10.2
     ;
     ; tool suite
-    toolcli==0.6.8
+    toolcli==0.6.12
     toolconf==0.1.2
-    toolsql==0.3.11
-    toolstr==0.8.2
-    tooltime==0.2.7
+    toolsql==0.5.2
+    toolstr==0.9.2
+    tooltime==0.2.10
     ;
     ; EVM dependencies
     pycryptodome==3.9.1
-    eth_abi_lite==3.0.3
-    idna==3.3
+    eth_abi_lite==3.2.0
+    idna==2.10
 
 commands = pytest --disable-warnings
 """
```

### Comparing `checkthechain-0.3.0/src/ctc/__init__.py` & `checkthechain-0.3.4/src/ctc/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 """ctc is a tool for collecting and processing historical EVM data"""
 
 from .evm import *
 
 
-__version__ = '0.3.0'
+__version__ = '0.3.4'
 
 
 def _clean_package_imports() -> None:
     """remove deep nested modules from ctc namespace"""
 
     import sys
```

### Comparing `checkthechain-0.3.0/src/ctc/cli/cli_run.py` & `checkthechain-0.3.4/src/ctc/cli/cli_run.py`

 * *Files 22% similar despite different names*

```diff
@@ -7,35 +7,37 @@
     import toolsql
 
     import mypy_extensions
 
 import toolcli
 
 import ctc
-from .plugins import toolsql_plugin
+import ctc.config
 from . import cli_utils
 
 
 command_index_by_category: dict[str, toolcli.CommandIndex] = {
     'admin': {
         (): 'ctc.cli.commands.root_command',
         ('aliases',): 'ctc.cli.commands.admin.aliases_command',
+        ('charset',): 'ctc.cli.commands.admin.charset_command',
+        ('color',): 'ctc.cli.commands.admin.color_command',
         ('config',): 'ctc.cli.commands.admin.config_command',
         ('config', 'edit'): 'ctc.cli.commands.admin.config.edit_command',
         ('config', 'path'): 'ctc.cli.commands.admin.config.path_command',
         ('db',): 'ctc.cli.commands.admin.db.status_command',
         (
             'db',
             'create',
             'tables',
         ): 'ctc.cli.commands.admin.db.create_tables_command',
         ('db', 'drop'): 'ctc.cli.commands.admin.db.drop_command',
+        ('db', 'login'): 'ctc.cli.commands.admin.db.login_command',
         ('log',): 'ctc.cli.commands.admin.log_command',
         ('setup',): 'ctc.cli.commands.admin.setup_command',
-        ('rechunk-events',): 'ctc.cli.commands.admin.rechunk_command',
         ('chains',): 'ctc.cli.commands.admin.chains_command',
     },
     'compute': {
         ('ascii',): 'ctc.cli.commands.compute.ascii_command',
         (
             'create',
             'address',
@@ -101,32 +103,14 @@
         ('ens', 'exists'): 'ctc.protocols.ens_utils.cli.ens.exists_command',
         ('ens', 'hash'): 'ctc.protocols.ens_utils.cli.ens.hash_command',
         ('ens', 'owner'): 'ctc.protocols.ens_utils.cli.ens.owner_command',
         ('ens', 'records'): 'ctc.protocols.ens_utils.cli.ens.records_command',
         ('ens', 'resolve'): 'ctc.protocols.ens_utils.cli.ens.resolve_command',
         ('ens', 'reverse'): 'ctc.protocols.ens_utils.cli.ens.reverse_command',
         ('etherscan',): 'ctc.protocols.etherscan_utils.cli.etherscan_command',
-        (
-            'fei',
-            'analytics',
-        ): 'ctc.protocols.fei_utils.cli.fei.analytics_command',
-        ('fei', 'depth'): 'ctc.protocols.fei_utils.cli.fei.depth_command',
-        ('fei', 'dex'): 'ctc.protocols.fei_utils.cli.fei.dex_command',
-        ('fei', 'pcv'): 'ctc.protocols.fei_utils.cli.fei.pcv_command',
-        (
-            'fei',
-            'pcv',
-            'assets',
-        ): 'ctc.protocols.fei_utils.cli.fei.pcv_assets_command',
-        (
-            'fei',
-            'pcv',
-            'deposits',
-        ): 'ctc.protocols.fei_utils.cli.fei.pcv_deposits_command',
-        ('fei', 'psms'): 'ctc.protocols.fei_utils.cli.fei.psms_command',
         ('gnosis',): 'ctc.protocols.gnosis_utils.cli.gnosis_command',
         ('llama',): 'ctc.protocols.llama_utils.cli.llama_command',
         ('llama', 'chain'): 'ctc.protocols.llama_utils.cli.llama_chain_command',
         (
             'llama',
             'chains',
         ): 'ctc.protocols.llama_utils.cli.llama_chains_command',
@@ -168,15 +152,17 @@
         (
             '4byte',
             'build',
         ): 'ctc.protocols.fourbyte_utils.cli.fourbyte_build_command',
     },
 }
 
-command_index: typing.MutableMapping[toolcli.CommandSequence, toolcli.CommandSpecReference] = {}
+command_index: typing.MutableMapping[
+    toolcli.CommandSequence, toolcli.CommandSpecReference
+] = {}
 help_subcommand_categories = {}
 for category, category_command_index in command_index_by_category.items():
     command_index.update(category_command_index)
     for subcommand in category_command_index.keys():
         help_subcommand_categories[subcommand] = category
 
 
@@ -253,15 +239,21 @@
             + '.html'
         )
 
 
 def _db_config_getter() -> toolsql.DBConfig | None:
     import ctc.config
 
-    return ctc.config.get_db_config()
+    import warnings
+
+    warnings.warn('full context not given for db_config')
+
+    return ctc.config.get_context_db_config(
+        context={}, schema_name='schema_versions'
+    )
 
 
 # def _is_root_help(raw_command):
 #     import sys
 
 #     for command in [raw_command, sys.argv]:
 #         if command is None:
@@ -290,40 +282,14 @@
 
 #     command_index_str = str(sorted(command_index.items()))
 #     name_hash = hashlib.md5(command_index_str.encode()).hexdigest()
 #     help_cache_path = os.path.join(help_cache_dir, name_hash)
 #     return help_cache_path
 
 
-def get_cli_styles() -> toolcli.StyleTheme:
-    try:
-        # if in notebook, do not use styles
-
-        get_ipython  # type: ignore
-
-        return {
-            'title': '',
-            'metavar': '',
-            'description': '',
-            'content': '',
-            'option': '',
-            'comment': '',
-        }
-
-    except NameError:
-        return {
-            'title': 'bold #ce93f9',
-            'metavar': '#8be9fd',
-            'description': '#b9f29f',
-            'content': '#f1fa8c',
-            'option': '#64aaaa',
-            'comment': '#6272a4',
-        }
-
-
 def run_cli(
     raw_command: str | None = None,
     **toolcli_kwargs: typing.Any,
 ) -> None:
 
     import tempfile
 
@@ -338,46 +304,37 @@
     #                 command_index, help_cache_dir
     #             )
     #             if printed:
     #                 return
     #         except Exception:
     #             pass
 
-    styles = get_cli_styles()
+    styles = cli_utils.get_cli_styles()
 
     config: toolcli.CLIConfig = {
         #
         # metadata
         'base_command': 'ctc',
         'description': description,
         'version': ctc.__version__,
         'cd_dir_help': cd_dir_help,
         'cd_dir_getter': cd_dir_getter,
         'help_url_getter': help_url_getter,  # type: ignore
         'help_cache_dir': help_cache_dir,
         'help_subcommand_categories': help_subcommand_categories,
         'async_context_manager': cli_utils.AsyncContextManager,
-        #
+        'extra_data': {'styles': styles},
         'style_theme': styles,
         #
         # standard subcommands and standard args
         'include_standard_subcommands': True,
         'include_debug_arg': True,
-        #
-        # plugins
-        'plugins': [toolsql_plugin.plugin],
-        'extra_data': {
-            'styles': styles,
-        },
-        'extra_data_getters': {
-            'db_config': _db_config_getter,
-            'db_schema': ('ctc.db', 'get_complete_prepared_schema'),  # type: ignore
-        },
     }
 
     toolcli_kwargs = dict({'config': config}, **toolcli_kwargs)
 
     toolcli.run_cli(
         raw_command=raw_command,
         command_index=command_index,
         **toolcli_kwargs,
     )
+
```

### Comparing `checkthechain-0.3.0/src/ctc/cli/cli_utils/cli_alias_utils.py` & `checkthechain-0.3.4/src/ctc/cli/cli_utils/cli_alias_utils.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/cli/cli_utils/cli_execution_utils.py` & `checkthechain-0.3.4/src/ctc/cli/cli_utils/cli_execution_utils.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/cli/cli_utils/cli_output_utils.py` & `checkthechain-0.3.4/src/ctc/toolbox/pl_utils/file_utils.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,109 +1,90 @@
 from __future__ import annotations
 
 import os
 import typing
-from ctc import cli
 
-if typing.TYPE_CHECKING:
-    from ctc import spec
+import polars as pl
 
 
-def print_bullet(
-    value: typing.Any,
-    *,
-    key: typing.Any | None = None,
-    number: int | None = None,
-    colon_str: str | None = None,
-    indent: int | str | None = None,
-) -> None:
+def create_multipath_glob(paths: typing.Sequence[str]) -> str:
+    """create a glob that points to a specific set of files
+
+    works by creating a temporary directory filled with symlinks, so epheremeral
+    """
+    import tempfile
 
-    import toolstr
+    temp_dir = tempfile.mkdtemp()
+    for path in paths:
+        os.symlink(path, os.path.join(os.path.basename(path)))
+    return os.path.join(temp_dir, '*')
 
-    styles = cli.get_cli_styles()
 
-    toolstr.print_bullet(
-        key=key,
-        value=value,
-        number=number,
-        colon_str=colon_str,
-        indent=indent,
-        bullet_style=styles['title'],
-        colon_style=styles['comment'],
-        key_style=styles['option'],
-        value_style=styles['description'],
-    )
-
-
-def output_data(
-    data: spec.DataFrame | spec.Series,
-    output: str,
+def write_df(
+    df: pl.DataFrame | pl.LazyFrame,
+    path: str,
     *,
-    overwrite: bool,
-    top: int | None = None,
-    indent: str | int | None = None,
-    raw: bool = False,
+    n_row_groups: int | None = None,
+    row_group_size: int | None = None,
+    statistics: bool = True,
+    create_dir: bool = False,
+    overwrite: bool = False,
+    **write_kwargs: typing.Any,
 ) -> None:
+    import shutil
 
-    import pandas as pd
-
-    if output == 'stdout':
-        import toolstr
-
-        rows = []
-        if isinstance(data, pd.DataFrame):
-            iterator = data.iterrows()
-        elif isinstance(data, pd.Series):
-            iterator = data.iteritems()
+    if create_dir:
+        dirpath = os.path.dirname(path)
+        if len(dirpath) > 0:
+            os.makedirs(dirpath, exist_ok=True)
+
+    if os.path.exists(path) and not overwrite:
+        raise Exception('file already exists, use overwrite=True: ' + str(path))
+
+    if n_row_groups is not None:
+        if isinstance(df, pl.LazyFrame):
+            raise Exception('cannot specify n_row_groups with LazyFrame\'s')
+        write_kwargs['row_group_size'] = int(len(df) / n_row_groups)
+        if write_kwargs['row_group_size'] == 0:
+            write_kwargs['row_group_size'] = 1
+    elif row_group_size is not None:
+        write_kwargs['row_group_size'] = row_group_size
+
+    temp_path = path + '_temp'
+    if path.endswith('.parquet'):
+        if isinstance(df, pl.LazyFrame):
+            df.sink_parquet(temp_path, statistics=statistics, **write_kwargs)
+        elif isinstance(df, pl.DataFrame):
+            df.write_parquet(temp_path, statistics=statistics, **write_kwargs)
         else:
-            raise Exception('unknown data format')
-
-        for index, values in iterator:
-            row = []
-            row.append(index)
-            if hasattr(values, 'values'):
-                # dataframe
-                for value in values.values:
-                    if value and not isinstance(value, str):
-                        value = toolstr.format(value)
-                    row.append(value)
-            else:
-                # series
-                if raw:
-                    row.append(values)
-                else:
-                    row.append(toolstr.format(values, order_of_magnitude=True))
-            rows.append(row)
-
-        if top is not None:
-            if len(rows) > top:
-                rows = rows[:top]
-
-        if isinstance(data, pd.DataFrame):
-            columns = [data.index.name] + list(data.columns)
-        elif isinstance(data, pd.Series):
-            columns = [data.index.name, data.name]
+            raise Exception('unknown dataframe type')
+    elif path.endswith('.csv'):
+        if isinstance(df, pl.LazyFrame):
+            df.collect(streaming=True).write_csv(temp_path, **write_kwargs)
+        elif isinstance(df, pl.DataFrame):
+            df.write_csv(temp_path, **write_kwargs)
         else:
-            raise Exception('unknown data format')
-        toolstr.print_table(rows=rows, labels=columns, indent=indent)
-
+            raise Exception('unknown dataframe type')
     else:
+        raise Exception('unknown file format: ' + str(path))
 
-        import toolcli
+    shutil.move(temp_path, path)
 
-        # check whether file exists
-        if os.path.isfile(output):
-            if overwrite:
-                pass
-            elif toolcli.input_yes_or_no('File already exists. Overwrite? '):
-                pass
-            else:
-                raise Exception('aborting')
 
-        if output.endswith('.csv'):
-            data.to_csv(output)
+# def add_stats_to_parquet_file(
+#     path: str,
+#     *,
+#     new_path: str | None = None,
+#     replace: bool = False,
+# ):
+#     if new_path is None:
+#         if replace:
+#             new_path = path + '_tmp'
+#         else:
+#             pass
 
-        elif output.endswith('.json'):
-            data.to_json(output)
+#     df = pl.read_parquet(path)
+#     df.write_parquet(new_path, statistics=True)
+
+#     if replace:
+#         shutil.move(new_path, path)
 
-        else:
-            raise Exception('unknown output format: ' + str(output))
```

### Comparing `checkthechain-0.3.0/src/ctc/cli/commands/admin/aliases_command.py` & `checkthechain-0.3.4/src/ctc/cli/commands/admin/aliases_command.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/cli/commands/admin/chains_command.py` & `checkthechain-0.3.4/src/ctc/cli/commands/admin/chains_command.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/cli/commands/admin/db/status_command.py` & `checkthechain-0.3.4/src/ctc/cli/commands/admin/db/status_command.py`

 * *Files 6% similar despite different names*

```diff
@@ -28,31 +28,27 @@
 
 
 def status_command(verbose: bool) -> None:
     styles = cli.get_cli_styles()
 
     toolstr.print_text_box('Database Status', style=styles['title'])
     print()
-    db_config = config.get_db_config()
+    context: spec.Context = {}
+    db_config = config.get_context_db_config(
+        context=context, schema_name='schema_versions'
+    )
     if db_config is None:
         print('[no db configured]')
         return
 
     toolstr.print_header('Database Config', style=styles['title'])
-    toolstr.print(
-        toolstr.add_style('- dbms:', styles['option']),
-        toolstr.add_style(db_config['dbms'], styles['description']),
-    )
-    if db_config['dbms'] == 'sqlite':
-        toolstr.print(
-            toolstr.add_style('- path:', styles['option']),
-            toolstr.add_style(db_config['path'], styles['metavar'] + ' bold'),
-        )
-    else:
-        raise NotImplementedError()
+    for key, value in db_config.items():
+        if key == 'password':
+            value = '********'
+        cli.print_bullet(key=key, value=value)
 
     # print data being stored
     active_schemas = db.get_active_schemas()
     print()
     toolstr.print_header('Data to Store', style=styles['title'])
     networks = config.get_networks_that_have_providers()
     admin_schemas = db.get_admin_schema_names()
@@ -73,70 +69,67 @@
                 '    -', datatype, '(inactive)', style=styles['description']
             )
     toolstr.print('- networks', style=styles['option'])
     for network in networks:
         toolstr.print('    -', network, style=styles['description'])
 
     print()
-    db_exists = toolsql.does_db_exist(db_config=db_config)
+    db_exists = toolsql.does_db_exist(db_config)
     if db_exists:
 
-        db_schema = db.get_complete_prepared_schema()
-        if verbose:
-            toolsql.print_schema(
-                db_config=db_config,
-                db_schema=db_schema,
-                styles=styles,
-            )
-
-            print()
-            toolstr.print_header('Schema Versions', style=styles['title'])
-            rows = []
-            for schema_name in active_schemas:
-                if schema_name in network_schemas:
-                    schema_networks: typing.Sequence[
-                        spec.NetworkReference
-                    ] | typing.Sequence[
-                        None
-                    ] = config.get_networks_that_have_providers()
-                else:
-                    schema_networks = [None]
-
-                for schema_network in schema_networks:
-                    version = db.get_schema_version(
-                        schema_name, network=schema_network
-                    )
-                    if version is None:
-                        version = '[DNE]'
+        with toolsql.connect(db_config) as conn:
+            db_schema = toolsql.get_db_schema(conn)
 
-                    if schema_network is None:
-                        network_str = ''
+        with toolsql.connect(db_config) as conn:
+            if verbose:
+                # toolsql.print_db_schema(db_schema=db_schema, styles=styles)
+
+                print()
+                toolstr.print_header('Schema Versions', style=styles['title'])
+                rows = []
+                for schema_name in active_schemas:
+                    if schema_name in network_schemas:
+                        schema_networks: typing.Sequence[
+                            spec.NetworkReference
+                        ] | typing.Sequence[
+                            None
+                        ] = config.get_networks_that_have_providers()
                     else:
-                        network_str = str(schema_network)
-                    row = [schema_name, network_str, version]
-                    rows.append(row)
-                rows = sorted(rows, key=lambda row: tuple(row))
-            toolstr.print_table(
-                rows,
-                labels=['schema', 'network', 'version'],
-                indent=4,
-                border=styles['comment'],
-                label_style=styles['title'],
-                column_styles={
-                    'schema': styles['description'],
-                    'network': 'bold',
-                    'version': 'bold',
-                },
-            )
-
-            print()
-            print()
-            toolsql.print_db_usage(
-                db_config=db_config,
-                db_schema=db_schema,
-                full=False,
-                styles=styles,
-            )
+                        schema_networks = [None]
+                    for schema_network in schema_networks:
+                        version = db.get_schema_version(
+                            schema_name,
+                            context=dict(network=schema_network),
+                            conn=conn,
+                        )
+                        if version is None:
+                            version = '[DNE]'
+
+                        if schema_network is None:
+                            network_str = ''
+                        else:
+                            network_str = str(schema_network)
+                        row = [schema_name, network_str, version]
+                        rows.append(row)
+                    rows = sorted(rows, key=lambda row: tuple(row))
+                toolstr.print_table(
+                    rows,
+                    labels=['schema', 'network', 'version'],
+                    indent=4,
+                    border=styles['comment'],
+                    label_style=styles['title'],
+                    column_styles={
+                        'schema': styles['description'],
+                        'network': 'bold',
+                        'version': 'bold',
+                    },
+                )
+
+                print()
+                print()
+                toolstr.print_header('Table Usage', style=styles['title'])
+                toolsql.print_db_usage(conn, styles=styles)
 
     else:
         toolstr.print_text_box('Schema Summary', style=styles['title'])
         print('- db does not exist')
+
```

### Comparing `checkthechain-0.3.0/src/ctc/cli/commands/admin/log_command.py` & `checkthechain-0.3.4/src/ctc/cli/commands/admin/log_command.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/cli/commands/admin/rechunk_command.py` & `checkthechain-0.3.4/src/ctc/cli/commands/data/events_command.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,120 +1,127 @@
 from __future__ import annotations
 
+import typing
+
 import toolcli
 
 from ctc import evm
-from ctc.evm.event_utils import event_backends
 from ctc import spec
+from ctc.cli import cli_utils
 
 
 def get_command_spec() -> toolcli.CommandSpec:
     return {
-        'f': async_rechunk,
-        'help': 'rechunk events by specific chunk size',
+        'f': async_events_command,
+        'help': 'get contract events',
         'args': [
             {
                 'name': 'contract',
-                'nargs': '?',
-                'help': 'address of contract emitting the event',
+                'help': 'contract address of event',
             },
             {
                 'name': 'event',
-                'nargs': '?',
-                'default': None,
-                'help': 'event hash',
+                'help': 'event name or event hash',
             },
             {
-                'name': '--network',
-                'metavar': 'NAME_OR_ID',
-                'help': 'network to rechunk events of',
+                'name': '--blocks',
+                'help': 'block range',
             },
             {
-                'name': '--all',
+                'name': '--include-timestamps',
+                'default': False,
                 'action': 'store_true',
-                'dest': 'all_events',
-                'help': 'whether to rechunk all events (can take a long time)',
-            },
-            {
-                'name': '--start-block',
-                'type': int,
-                'help': 'start of block range to rechunk',
-            },
-            {
-                'name': '--end-block',
-                'type': int,
-                'help': 'end of block range to rechunk',
+                'help': 'include timestamps',
             },
             {
-                'name': '--chunk-bytes',
-                'type': int,
-                'required': True,
-                'help': 'target number of bytes per chunk',
+                'name': '--export',
+                'default': 'stdout',
+                'help': 'file path for output (.json or .csv)',
             },
             {
-                'name': '--dry',
+                'name': '--overwrite',
                 'action': 'store_true',
-                'help': 'perform a dry run where no changes are made',
+                'help': 'specify that output path can be overwritten',
             },
             {
                 'name': ['--verbose', '-v'],
+                'help': 'display more event data',
                 'action': 'store_true',
-                'help': 'increase verbosity',
             },
         ],
-        'examples': [
-            '0x956f47f50a910163d8bf957cf5846d573e7f87ca 0xddf252ad1be2c89b69c2b068fc378daa952ba7f163c4a11628f55a4df523b3ef',
-            '--all',
-        ],
-        'hidden': True,
+        'examples': {
+            '0x956f47f50a910163d8bf957cf5846d573e7f87ca Transfer': {
+                'long': True
+            },
+            '0x956f47f50a910163d8bf957cf5846d573e7f87ca Transfer --blocks 14000000:14010000': {},
+            '0x956f47f50a910163d8bf957cf5846d573e7f87ca Transfer --blocks 14000000:14010000 --include-timestamps': {},
+        },
     }
 
 
-async def async_rechunk(
+async def async_events_command(
     *,
-    contract: spec.Address,
+    contract: str,
     event: str,
-    all_events: bool,
-    start_block: int,
-    end_block: int,
-    chunk_bytes: int,
-    dry: bool,
+    blocks: str,
+    include_timestamps: bool,
+    export: str,
+    overwrite: bool,
     verbose: bool,
-    network: spec.NetworkReference,
 ) -> None:
 
-    if all_events:
+    import polars as pl
+
+    contract = await evm.async_resolve_address(contract)
+
+    if blocks is not None:
+        all_blocks = await cli_utils.async_parse_block_range(blocks)
+        start_block = all_blocks[0]
+        end_block = all_blocks[-1]
+    else:
+        start_block = None
+        end_block = None
 
-        await event_backends.async_rechunk_all_events(
-            network=network,
+    if event.startswith('0x'):
+        events: spec.DataFrame = await evm.async_get_events(
+            contract_address=contract,
             start_block=start_block,
             end_block=end_block,
-            chunk_target_bytes=chunk_bytes,
-            dry=dry,
-            verbose=verbose,
+            include_timestamps=include_timestamps,
+            verbose=False,
+            event_hash=event,
         )
-
-    elif contract is not None and event is not None:
-
-        if evm.is_event_hash(event):
-            event_name = event
-            event_hash = None
-        else:
-            event_name = None
-            event_hash = event
-
-        await event_backends.async_rechunk_events(
+    else:
+        events = await evm.async_get_events(
             contract_address=contract,
-            network=network,
-            event_name=event_name,
-            event_hash=event_hash,
             start_block=start_block,
             end_block=end_block,
-            chunk_target_bytes=chunk_bytes,
-            dry=dry,
-            verbose=verbose,
+            include_timestamps=include_timestamps,
+            verbose=False,
+            event_name=event,
         )
 
+    if len(events) == 0:
+        print('[no events found]')
+
     else:
-        raise Exception(
-            'usage either `ctc rechunk --all` or `ctc rechunk contract_address event_hash`'
-        )
+
+        # output
+        if not verbose:
+            columns = [
+                column
+                for column in events.columns
+                if column.startswith('arg__')
+            ]
+            if include_timestamps:
+                columns.insert(0, 'timestamp')
+
+            events = events[columns]
+            new_column_names = {
+                old_column: old_column[5:]
+                for old_column in events.columns
+                if old_column.startswith('arg__')
+            }
+            events = events.rename(new_column_names)
+        if export == 'stdout' and include_timestamps:
+            events = events.with_columns(pl.col('timestamp').cast(pl.Utf8))
+        cli_utils.output_data(events, output=export, overwrite=overwrite)
```

### Comparing `checkthechain-0.3.0/src/ctc/cli/commands/admin/setup_command.py` & `checkthechain-0.3.4/src/ctc/cli/commands/admin/setup_command.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/cli/commands/compute/checksum_command.py` & `checkthechain-0.3.4/src/ctc/cli/commands/compute/checksum_command.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/cli/commands/compute/create_address_command.py` & `checkthechain-0.3.4/src/ctc/cli/commands/compute/create_address_command.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/cli/commands/compute/decode_call_command.py` & `checkthechain-0.3.4/src/ctc/cli/commands/compute/decode_call_command.py`

 * *Files 5% similar despite different names*

```diff
@@ -47,14 +47,15 @@
     args: typing.Sequence[str],
     nested: bool = False,
     title: str | None = None,
     indent: str | None = None,
     mention_nested: bool = True,
     send_value: int | None = None,
     explicit_signature: str | None = None,
+    context: spec.Context = None,
 ) -> None:
 
     tx = len(args) == 1 and (
         (args[0].startswith('0x') and len(args[0]) == 66)
         or (len(args[0]) == 64)
     )
 
@@ -65,25 +66,25 @@
     if title is None:
         title = 'Decoding Call Data'
     toolstr.print_text_box(title, style=styles['title'])
 
     if tx:
         if len(args) != 1:
             raise Exception('syntax is `ctc decode call TX_HASH --tx`')
-        transaction = await evm.async_get_transaction(args[0])
+        transaction = await evm.async_get_transaction(args[0], context=context)
         call_data = transaction['input']
-        contract_address = transaction['to']
+        contract_address = transaction['to_address']
         contract_known = True
     elif len(args) == 1:
         from ctc.protocols import fourbyte_utils
 
         contract_known = False
         call_data = args[0]
         signature = call_data[:10]
-        result = await fourbyte_utils.async_query_function_signatures(signature)
+        result = await fourbyte_utils.async_query_function_signatures(signature, context=context)
 
         for subresult in result:
             try:
                 function_abi: spec.FunctionABI | None = (
                     evm.function_signature_to_abi(subresult['text_signature'])
                 )
                 decoded = evm.decode_call_data(
@@ -104,24 +105,25 @@
         contract_known = True
     else:
         raise Exception('wrong syntax, see `ctc decode -h`')
 
     if contract_known:
         try:
             contract_abi = await evm.async_get_contract_abi(
-                contract_address=contract_address
+                contract_address=contract_address,
+                context=context,
             )
             if explicit_signature is not None:
                 function_selector = evm.get_function_selector(
                     function_signature=explicit_signature
                 )
                 call_data = (
                     '0x'
                     + function_selector
-                    + evm.binary_convert(call_data, 'raw_hex')
+                    + evm.to_hex(call_data, prefix=False)
                 )
 
             decoded = evm.decode_call_data(
                 contract_abi=contract_abi, call_data=call_data
             )
             function_abi = decoded['function_abi']
         except Exception:
@@ -144,15 +146,15 @@
             ) + toolstr.add_style(': ', styles['comment'])
         as_str += toolstr.add_style(str(value), styles['description'] + ' bold')
         toolstr.print(as_str)
 
     if contract_known:
         print_bullet('to', contract_address, indent)
     print_bullet(
-        'n_bytes', len(evm.binary_convert(call_data, 'binary')), indent
+        'n_bytes', len(evm.to_binary(call_data)), indent
     )
     if send_value is not None:
         print_bullet('value', send_value, indent)
 
     if function_abi is None:
         if explicit_signature is not None:
             print_bullet('signature', explicit_signature)
@@ -315,28 +317,26 @@
                 print_bullet(
                     str(input_name),
                     indent=indent,
                     bullet=str(p + 1) + '.',
                 )
                 for subparameter in parameter:
                     if isinstance(subparameter, bytes):
-                        subparameter = evm.binary_convert(
-                            subparameter, 'prefix_hex'
-                        )
+                        subparameter = evm.to_hex(subparameter)
                     toolstr.print(
                         indent + '    ' + stringify(subparameter),
                         style=styles['description'],
                     )
                 if len(parameter) == 0:
                     toolstr.print(
                         indent + '    \[none]', style=styles['comment']
                     )
             else:
                 if isinstance(parameter, bytes):
-                    parameter = evm.binary_convert(parameter, 'prefix_hex')
+                    parameter = evm.to_hex(parameter)
                 print_bullet(
                     input_name,
                     parameter,
                     indent=indent,
                     bullet=str(p + 1) + '.',
                 )
 
@@ -355,14 +355,15 @@
                 args=[nested_call['address'], nested_call['call_data']],
                 nested=False,
                 title=title,
                 indent='',
                 mention_nested=False,
                 send_value=nested_call['value'],
                 explicit_signature=nested_call['signature'],
+                context=context,
             )
             if nc + 1 != len(nested_calls):
                 print()
 
     if mention_nested and not nested:
         toolstr.print(
             'use --nested to decode nested calls',
```

### Comparing `checkthechain-0.3.0/src/ctc/cli/commands/compute/decode_command.py` & `checkthechain-0.3.4/src/ctc/cli/commands/compute/decode_command.py`

 * *Files 13% similar despite different names*

```diff
@@ -21,9 +21,9 @@
             'address 0x0000000000000000000000006b175474e89094c44da98b954eedeac495271d0f',
             '"(int64,int64,int64)" 0x000000000000000000000000000000000000000000000000000000000000000100000000000000000000000000000000000000000000000000000000000000020000000000000000000000000000000000000000000000000000000000000003',
         ],
     }
 
 
 def decode_command(type: str, data: str) -> None:
-    decoded = evm.abi_decode(evm.binary_convert(data, 'binary'), type)
+    decoded = evm.abi_decode(evm.to_binary(data), type)
     print(decoded)
```

### Comparing `checkthechain-0.3.0/src/ctc/cli/commands/compute/encode_command.py` & `checkthechain-0.3.4/src/ctc/cli/commands/compute/encode_command.py`

 * *Files 7% similar despite different names*

```diff
@@ -49,9 +49,9 @@
             literal_data = ast.literal_eval('"' + data + '"')
 
     if packed:
         encoded = evm.abi_encode_packed(literal_data, type)
     else:
         encoded = evm.abi_encode(literal_data, type)
 
-    as_hex = evm.binary_convert(encoded, 'prefix_hex')
+    as_hex = evm.to_hex(encoded)
     print(as_hex)
```

### Comparing `checkthechain-0.3.0/src/ctc/cli/commands/compute/hex_command.py` & `checkthechain-0.3.4/src/ctc/cli/commands/compute/hex_command.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/cli/commands/compute/keccak_command.py` & `checkthechain-0.3.4/src/ctc/cli/commands/compute/keccak_command.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/cli/commands/compute/limits_command.py` & `checkthechain-0.3.4/src/ctc/cli/commands/compute/limits_command.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/cli/commands/compute/rlp_encode.py` & `checkthechain-0.3.4/src/ctc/cli/commands/compute/rlp_encode.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/cli/commands/compute/selector_command.py` & `checkthechain-0.3.4/src/ctc/cli/commands/compute/selector_command.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/cli/commands/data/abi_command.py` & `checkthechain-0.3.4/src/ctc/cli/commands/data/abi_command.py`

 * *Files 9% similar despite different names*

```diff
@@ -74,14 +74,18 @@
                 'action': 'store_true',
             },
             {
                 'name': '--update',
                 'help': 're-import ABI from etherscan (e.g. if proxy has changed)',
                 'action': 'store_true',
             },
+            {
+                'name': '--network',
+                'help': 'network of context',
+            },
         ],
         'examples': [
             '0x956f47f50a910163d8bf957cf5846d573e7f87ca',
             '0x2b79b3c3c7b35463a28a76e0d332aab3e20aa337 Mint Burn Swap Sync',
             '0x2b79b3c3c7b35463a28a76e0d332aab3e20aa337 -f',
             '0x2b79b3c3c7b35463a28a76e0d332aab3e20aa337 -e',
             '0x956f47f50a910163d8bf957cf5846d573e7f87ca --json',
@@ -101,25 +105,27 @@
     events: bool,
     search: str,
     verbose: bool,
     map_names: bool,
     map_selectors: bool,
     python: bool,
     update: bool,
+    network: spec.NetworkReference,
 ) -> None:
 
     if map_names and map_selectors:
         raise Exception('can only specify one of --map-names or --map-keys')
     if map_names or map_selectors:
         if not json_raw:
             json_pretty = True
 
     address = await evm.async_resolve_address(address)
     contract_abi = await evm.async_get_contract_abi(
-        contract_address=address, db_query=(not update),
+        contract_address=address,
+        context={'network': network, 'cache': (not update)},
     )
 
     # filter by name
     if len(names) > 0:
         contract_abi = [
             item
             for item in contract_abi
@@ -203,7 +209,8 @@
         else:
             evm.print_contract_abi(
                 contract_abi,
                 max_width=columns,
                 verbose=verbose,
                 read_write=True,
             )
+
```

### Comparing `checkthechain-0.3.0/src/ctc/cli/commands/data/abi_diff_command.py` & `checkthechain-0.3.4/src/ctc/cli/commands/data/abi_diff_command.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/cli/commands/data/address_command.py` & `checkthechain-0.3.4/src/ctc/cli/commands/data/erc20/balance_command.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,53 +1,53 @@
 from __future__ import annotations
 
 import toolcli
+import toolstr
 
 from ctc import evm
 from ctc import spec
 
 
 def get_command_spec() -> toolcli.CommandSpec:
     return {
-        'f': async_address_command,
-        'help': """summarize address
-
-for contracts, will display ABI""",
+        'f': async_balance_command,
+        'help': 'output an ERC20 balance',
         'args': [
-            {'name': 'address', 'help': 'address to get summary of'},
-            {
-                'name': ['-v', '--verbose'],
-                'action': 'store_true',
-                'help': 'emit extra output',
-            },
+            {'name': 'erc20_address', 'help': 'address of ERC20 token'},
+            {'name': 'wallet_address', 'help': 'address of wallet'},
+            {'name': '--block', 'help': 'block number'},
             {
                 'name': '--raw',
                 'action': 'store_true',
-                'help': 'emit abi in raw json',
-            },
-            {
-                'name': '--network',
-                'metavar': 'NAME_OR_ID',
-                'help': 'network name or id to scan address of',
+                'help': 'whether to normalize balance by ERC20 decimals',
             },
         ],
-        'examples': ['0x956f47f50a910163d8bf957cf5846d573e7f87ca'],
+        'examples': [
+            '0x956f47f50a910163d8bf957cf5846d573e7f87ca 0x9928e4046d7c6513326ccea028cd3e7a91c7590a',
+            '0x956f47f50a910163d8bf957cf5846d573e7f87ca 0x9928e4046d7c6513326ccea028cd3e7a91c7590a --raw',
+            '0x956f47f50a910163d8bf957cf5846d573e7f87ca 0x9928e4046d7c6513326ccea028cd3e7a91c7590a --block 14000000',
+        ],
     }
 
 
-async def async_address_command(
-    *, address: spec.Address, verbose: bool | int, network: str, raw: bool
+async def async_balance_command(
+    *,
+    erc20_address: spec.Address,
+    wallet_address: spec.Address,
+    block: str,
+    raw: bool,
 ) -> None:
-
-    max_width = toolcli.get_n_terminal_cols()
-
-    address = await evm.async_resolve_address(address)
-
-    if verbose:
-        verbose = 2
-    await evm.async_print_address_summary(
-        address=address,
-        verbose=verbose,
-        max_width=max_width,
-        raw=raw,
-        provider={'network': network},
+    erc20_address = await evm.async_resolve_address(erc20_address, block=block)
+    wallet_address = await evm.async_resolve_address(
+        wallet_address,
+        block=block,
+    )
+    balance = await evm.async_get_erc20_balance(
+        wallet=wallet_address,
+        token=erc20_address,
+        block=block,
+        normalize=(not raw),
     )
+    if raw:
+        print(balance)
+    else:
+        print(toolstr.format(balance))
```

### Comparing `checkthechain-0.3.0/src/ctc/cli/commands/data/address_txs_command.py` & `checkthechain-0.3.4/src/ctc/cli/commands/data/address_txs_command.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/cli/commands/data/block_command.py` & `checkthechain-0.3.4/src/ctc/cli/commands/data/block_command.py`

 * *Files 8% similar despite different names*

```diff
@@ -84,14 +84,11 @@
     else:
         block_number = await evm.async_block_number_to_int(block)
 
     if as_json:
         import rich
         import json
 
-        block_data = await evm.async_get_block(
-            block_number,
-            include_full_transactions=False,
-        )
+        block_data = await evm.async_get_block(block_number)
         rich.print_json(json.dumps(block_data))
     else:
         await evm.async_print_block_summary(block=block_number)
```

### Comparing `checkthechain-0.3.0/src/ctc/cli/commands/data/blocks_command.py` & `checkthechain-0.3.4/src/ctc/cli/commands/data/blocks_command.py`

 * *Files 7% similar despite different names*

```diff
@@ -56,26 +56,26 @@
     blocks: typing.Sequence[str],
     n: int | None,
     attributes: typing.Optional[typing.Sequence[str]],
     export: str,
     overwrite: bool,
     provider: typing.Optional[str],
 ) -> None:
-    import pandas as pd
+    import polars as pl
 
     if attributes is None:
         # gas stats as well
         attributes = [
             'number',
             'timestamp',
             'age',
             'median_gas',
         ]
     elif attributes == ['all']:
-        attributes = list(spec.block_keys)
+        attributes = list(spec.db_block_keys)
     else:
         attributes = [
             attribute for token in attributes for attribute in token.split(',')
         ]
 
     # determine blocks
     # export_blocks = await cli_utils.async_resolve_block_range(blocks)
@@ -87,15 +87,15 @@
     cli.print_bullet(key='n_blocks', value=len(export_blocks))
     cli.print_bullet(key='min block', value=min(export_blocks))
     cli.print_bullet(key='max block', value=max(export_blocks))
 
     blocks_data = await rpc.async_batch_eth_get_block_by_number(
         block_numbers=export_blocks,
         include_full_transactions=True,
-        provider=provider,
+        context=dict(provider=provider),
     )
 
     if export == 'stdout':
         cli.print_bullet(key='attributes', value='')
         for attribute in attributes:
             cli.print_bullet(value=attribute, indent=4)
         print()
@@ -115,16 +115,16 @@
                 elif attribute == 'age':
                     age = tooltime.get_age(
                         block['timestamp'], 'TimelengthPhrase'
                     )
                     age = ', '.join(age.split(', ')[:2])
                     row.append(age)
                 elif attribute == 'median_gas':
-                    median_gas = evm.compute_median_block_gas_fee(
-                        block, normalize=True
+                    median_gas = evm.compute_transactions_gas_stats(
+                        block['transactions'], normalize=True
                     )
                     row.append(median_gas)
                 else:
                     row.append(block[attribute])
             rows.append(row)
         labels = [aliases.get(attribute, attribute) for attribute in attributes]
         print()
@@ -141,21 +141,22 @@
                 'median gas': {'postfix': ' gwei', 'trailing_zeros': True},
             },
             compact=4,
         )
     else:
 
         # format as dataframe
-        df = pd.DataFrame(blocks_data)
+        df = pl.DataFrame(blocks_data)
 
         # # special attribute: time
         # if 'time' in attributes:
         #     df['time'] = df['timestamp'].map(tooltime.timestamp_to_iso)
 
         # # trim attributes
         # if len(attributes) > 0:
         #     df = df[attributes]
 
         # # output data
         # if 'number' in df:
         #     df = df.set_index('number')
         cli_utils.output_data(df, output=export, overwrite=overwrite)
+
```

### Comparing `checkthechain-0.3.0/src/ctc/cli/commands/data/bytecode_command.py` & `checkthechain-0.3.4/src/ctc/cli/commands/data/bytecode_command.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/cli/commands/data/call_all_command.py` & `checkthechain-0.3.4/src/ctc/cli/commands/data/call_all_command.py`

 * *Files 7% similar despite different names*

```diff
@@ -65,15 +65,15 @@
             if evm.is_function_read_only(function_abi):
                 inputs = function_abi.get('inputs')
                 if inputs is not None and len(inputs) == 0:
                     function_abis.append(function_abi)
                     coroutine = rpc.async_eth_call(
                         to_address=contract_address,
                         function_abi=function_abi,
-                        provider={'convert_reverts_to_none': True},
+                        context=dict(provider={'convert_reverts_to_none': True}),
                         block_number=block_number,
                     )
                     coroutines.append(coroutine)
 
     results = await asyncio.gather(*coroutines)
 
     styles = cli.get_cli_styles()
@@ -98,15 +98,18 @@
             footnote = 'length = ' + str(len(result))
             if len(result) > max_results:
                 footnote += ', clipped to ' + str(max_results)
                 result = result[:max_results]
                 clipped = True
             else:
                 clipped = False
-            str_result = json.dumps(result, sort_keys=True, indent=2)
+            try:
+                str_result = json.dumps(result, sort_keys=True, indent=2)
+            except TypeError:
+                str_result = str(result)
             if clipped:
                 str_result = str_result[: str_result.rindex('\n')]
                 str_result = str_result + ',\n...'
 
             footnote = toolstr.add_style(
                 '(' + footnote + ')', styles['comment']
             )
```

### Comparing `checkthechain-0.3.0/src/ctc/cli/commands/data/call_command.py` & `checkthechain-0.3.4/src/ctc/cli/commands/data/call_command.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/cli/commands/data/calls_command.py` & `checkthechain-0.3.4/src/ctc/cli/commands/data/calls_command.py`

 * *Files 2% similar despite different names*

```diff
@@ -10,14 +10,15 @@
 
 import asyncio
 import typing
 
 import toolcli
 import toolstr
 
+import ctc.config
 from ctc import cli
 from ctc import evm
 from ctc import rpc
 from ctc import spec
 from ctc.cli import cli_utils
 
 
@@ -111,15 +112,14 @@
     )
     stylized = stylized.replace('[comment]', '[' + styles['comment'] + ']')
     stylized = stylized.replace('[/comment]', '[/' + styles['comment'] + ']')
     return stylized
 
 
 def get_timestamp_format_table() -> str:
-
     rows = [
         [
             'number + letter\n[comment](one of {yMdhms})[/comment]',
             'timelength',
             '100d\n24h',
         ],
         ['YYYY', 'start of year', '2018\n2022'],
@@ -163,25 +163,23 @@
     if not isinstance(as_str, str):
         raise Exception('did not return str')
 
     return as_str
 
 
 def stylize_markdown(text: str, styles: toolcli.StyleTheme) -> str:
-
     import re
 
     lines = text.split('\n')
 
     code_regex = re.compile('`.*?`')
     bold_regex = re.compile('\*\*.*?\*\*')
 
     styled_lines = []
     for i, line in enumerate(lines):
-
         # stylize titles
         if line.startswith('#'):
             line = toolstr.add_style(line, styles['title'])
 
         if line.startswith('    - '):
             line = toolstr.add_style(line[:6], styles['title']) + line[6:]
 
@@ -316,15 +314,14 @@
     overwrite: bool,
     no_table: bool,
     no_chart: bool,
     from_address: spec.Address | None,
     normalize: typing.Sequence[str],
     blocks_gte_times: bool,
 ) -> None:
-
     # check whether using multi-contract query or multi-block query
     multi_contract_query = addresses is not None
     multi_block_query = blocks is not None or times is not None
     if multi_contract_query and multi_block_query:
         raise Exception('cannot specify --addresses and --blocks or --times')
 
     # resolve from address
@@ -375,15 +372,14 @@
     addresses: typing.Sequence[spec.Address] | None,
     block: str,
     unique_abis: bool,
     from_address: spec.Address | None,
     normalize: typing.Sequence[str],
     export: str,
 ) -> spec.DataFrame | None:
-
     if addresses is not None:
         addresses = await evm.async_resolve_addresses(addresses, block=block)
     if addresses is None:
         raise Exception('could not detect addresses')
 
     # multi-contract queries
     if block is None:
@@ -417,17 +413,17 @@
                 function_abi=function_abi,
                 function_parameters=function_parameters,
                 block_number=block,
                 from_address=from_address,
             )
             for address in addresses
         ]
-        results = await asyncio.gather(*coroutines)
+        raw_results = await asyncio.gather(*coroutines)
     else:
-        results = await rpc.async_batch_eth_call(
+        raw_results = await rpc.async_batch_eth_call(
             to_addresses=addresses,
             function_abi=function_abi,
             function_parameters=function_parameters,
             block_number=block,
             from_address=from_address,
         )
 
@@ -439,25 +435,29 @@
     if normalize is not None:
         if len(normalize) == 0:
             if len(output_names) != 1:
                 raise Exception(
                     'can only normalize functions that have a single output'
                 )
             try:
-                results = await evm.async_normalize_erc20s_quantities(
-                    quantities=results,
+                results: typing.Sequence[
+                    typing.Any
+                ] = await evm.async_normalize_erc20s_quantities(
+                    quantities=raw_results,
                     tokens=addresses,
                 )
             except Exception:
-                results = [result / 1e18 for result in results]
+                results = [result / 1e18 for result in raw_results]
         elif len(normalize) == 1:
             factor = float(normalize[0])
-            results = [subresult / factor for subresult in results]
+            results = [subresult / factor for subresult in raw_results]
         else:
             raise Exception('--normalize should have at most 1 argument')
+    else:
+        results = raw_results
 
     styles = cli.get_cli_styles()
     toolstr.print_text_box('Multi-contract calls', style=styles['title'])
     if block is None:
         block = 'latest'
     cli.print_bullet(key='block', value=block)
     cli.print_bullet(key='function', value=function_abi.get('name', '\[none]'))
@@ -492,19 +492,19 @@
             column_formats={
                 'balanceOf': {'trailing_zeros': True, 'decimals': 2},
             },
         )
         return None
 
     else:
-        import pandas as pd
+        import polars as pl
 
-        df = pd.DataFrame(results, index=addresses)
-        df.index.name = 'to_address'
-        df.columns = output_names
+        names = [name if name is not None else '' for name in output_names]
+        df = pl.DataFrame(results, names)
+        df.with_columns(pl.Series('to_address', addresses))
 
         return df
 
 
 async def async_perform_multi_block_call(
     *,
     address_and_or_function: typing.Sequence[str],
@@ -516,15 +516,14 @@
     export: str,
     no_table: bool,
     no_chart: bool,
     from_address: spec.Address | None,
     normalize: typing.Sequence[str],
     blocks_gte_times: bool,
 ) -> spec.DataFrame | None:
-
     # historical queries
     if block is not None:
         raise Exception(
             'cannot specify both --block alongside --blocks or --times'
         )
     if addresses is not None:
         raise Exception('cannot specify --addresses in multi block call')
@@ -539,20 +538,18 @@
     function_abi = await evm.async_parse_function_str_abi(
         function,
         contract_address=to_address,
     )
 
     # parse blocks or times
     if blocks is not None:
-
         # parse blocks
         block_numbers = await cli_utils.async_parse_block_slice(blocks, n=n)
 
     elif times is not None:
-
         # parse timestamps
         import tooltime
 
         if len(times) != 1:
             raise Exception('--times specified improperly')
 
         raw_timestamps = tooltime.parse_timeslice(times[0], n=n)
@@ -616,19 +613,17 @@
     cli.print_bullet(key='function_args', value='')
     for fp, function_parameter in enumerate(function_parameters):
         cli.print_bullet(value=function_parameter, number=fp + 1, indent=4)
     cli.print_bullet(key='# blocks', value=str(len(block_numbers)))
     print()
 
     if export == 'stdout':
-
         import tooltime
 
         if not no_table:
-
             block_timestamps = await block_timestamps_task
 
             rows = []
             for r, result in enumerate(results):
                 row = []
                 row.append(block_numbers[r])
                 age = tooltime.get_age(block_timestamps[r], 'TimelengthPhrase')
@@ -665,39 +660,39 @@
                 label_style=styles['title'],
                 column_styles=column_styles,
                 column_formats=column_formats,
                 indent=4,
             )
 
         if not no_chart:
-
             xvals = block_numbers
             yvals = results
             plot = toolstr.render_line_plot(
                 xvals=xvals,
                 yvals=yvals,
-                n_rows=40,
-                n_columns=120,
+                n_rows=10,
+                n_columns=60,
                 line_style=styles['description'],
                 chrome_style=styles['comment'],
                 tick_label_style=styles['metavar'],
                 xaxis_kwargs={'tick_label_format': None, 'n_ticks': 2},
+                char_dict=ctc.config.get_cli_chart_charset(),
             )
             print()
             print()
             toolstr.print(
                 toolstr.hjustify(output_names[0], 'center', 70),
                 indent=4,
                 style=styles['title'],
             )
             toolstr.print(plot, indent=4)
 
         return None
 
     else:
-        import pandas as pd
+        import polars as pl
 
         # format into dataframe
-        df = pd.DataFrame(results, index=block_numbers)
-        df.index.name = 'block'
-        df.columns = output_names
+        df = pl.DataFrame(results, output_names)
+        df = df.insert_at_idx(0, pl.Series('block', block_numbers))
         return df
+
```

### Comparing `checkthechain-0.3.0/src/ctc/cli/commands/data/chain_command.py` & `checkthechain-0.3.4/src/ctc/cli/commands/data/chain_command.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,12 +1,13 @@
 from __future__ import annotations
 
 import toolcli
 import toolstr
 
+import ctc.config
 from ctc import evm
 from ctc import rpc
 from ctc import spec
 
 
 def get_command_spec() -> toolcli.CommandSpec:
     return {
@@ -41,35 +42,35 @@
     *,
     provider: str,
     config: bool,
     verbose: bool,
     no_check: bool,
 ) -> None:
 
+    context = ctc.config.create_user_input_context(provider=provider)
+
     # gather configured chain_id
-    provider_network = None
     config_chain_id = None
     if verbose or config or not no_check:
         try:
-            provider_network = rpc.get_provider_network(provider)
-            config_chain_id = evm.get_network_chain_id(provider_network)
+            config_chain_id = ctc.config.get_context_chain_id(context)
         except spec.CouldNotDetermineNetwork:
             pass
 
     # gather reported chain_id
     reported_chain_id = None
     if verbose or not config or not no_check:
-        reported_chain_id = await rpc.async_eth_chain_id(provider=provider)
+        reported_chain_id = await rpc.async_eth_chain_id(context=context)
 
     # print output
     if verbose:
         toolstr.print_text_box('Provider chain information')
         print()
 
-        reported_chain_id = await rpc.async_eth_chain_id(provider=provider)
+        reported_chain_id = await rpc.async_eth_chain_id(context=context)
         toolstr.print_header('Info reported by node')
         print('- chain_id:', reported_chain_id)
         print('- name:', evm.get_network_name(reported_chain_id))
         print()
         toolstr.print_header('Info in config')
         if config_chain_id is None:
             print('[provider not in config]')
```

### Comparing `checkthechain-0.3.0/src/ctc/cli/commands/data/decompile_command.py` & `checkthechain-0.3.4/src/ctc/cli/commands/data/decompile_command.py`

 * *Files 4% similar despite different names*

```diff
@@ -14,14 +14,15 @@
 
 import toolcli
 import toolstr
 
 from ctc import cli
 from ctc import evm
 from ctc import rpc
+from ctc import spec
 
 
 def get_command_spec() -> toolcli.CommandSpec:
     return {
         'f': async_decompile_command,
         'help': 'decompile contract abi',
         'args': [
@@ -38,15 +39,18 @@
         'examples': [
             '0x956f47f50a910163d8bf957cf5846d573e7f87ca',
         ],
     }
 
 
 async def async_decompile_command(
-    address_or_bytecode: str, verbose: bool
+    address_or_bytecode: str,
+    verbose: bool,
+    *,
+    context: spec.Context = None,
 ) -> None:
 
     address_or_bytecode = await evm.async_resolve_address(address_or_bytecode)
 
     if len(address_or_bytecode) == 42:
         bytecode = await rpc.async_eth_get_code(address_or_bytecode)
     else:
@@ -59,14 +63,15 @@
         for index, function_selector in enumerate(sorted(function_selectors))
     }
 
     # match against 4bytes
     decompiled_function_abis = await evm.async_decompile_function_abis(
         bytecode,
         sort='hex_signature',
+        context=context,
     )
 
     styles = cli.get_cli_styles()
     toolstr.print(
         'Found '
         + toolstr.add_style(
             str(len(function_selectors)),
@@ -140,7 +145,8 @@
         toolstr.print_header('Unknown selectors', style=styles['title'])
         for unknown_selector in unknown_selectors:
             print(unknown_selector)
 
     if len(decompiled_function_abis) == 0:
         print()
         print('could not detect any function signatures')
+
```

### Comparing `checkthechain-0.3.0/src/ctc/cli/commands/data/dex/chart_command.py` & `checkthechain-0.3.4/src/ctc/protocols/uniswap_v2_utils/cli/chart_command.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,29 +1,28 @@
 from __future__ import annotations
 
-import asyncio
 import functools
 import math
 
 import rich.console
 import toolcli
 import toolstr
 import tooltime
 
 from ctc import cli
 from ctc import evm
 from ctc import spec
-from ctc.toolbox.defi_utils import dex_utils
-from ctc.toolbox.defi_utils import ohlc_utils
+from ctc.defi.metric_utils import ohlc_utils
+from ctc.protocols import uniswap_v2_utils
 
 
 def get_command_spec() -> toolcli.CommandSpec:
     return {
-        'f': async_dex_chart_command,
-        'help': 'display candlestick chart of DEX pool trades',
+        'f': async_chart_command,
+        'help': 'chart price action of uniswap pools',
         'args': [
             {
                 'name': 'pool',
                 'help': 'Uniswap pool address',
             },
             {
                 'name': '--timescale',
@@ -36,32 +35,29 @@
             },
             {
                 'name': '--no-volume',
                 'action': 'store_true',
                 'help': 'hide volume data',
             },
         ],
-        'examples': [
-            '0xf4ad61db72f114be877e87d62dc5e7bd52df4d9b',
-            '0xf4ad61db72f114be877e87d62dc5e7bd52df4d9b --invert',
-        ],
+        'examples': ['0x9928e4046d7c6513326ccea028cd3e7a91c7590a'],
     }
 
 
-async def async_dex_chart_command(
+async def async_chart_command(
     *,
     pool: spec.Address,
     invert: bool,
     timescale: str,
     no_volume: bool,
 ) -> None:
+    import asyncio
 
-    dex = await dex_utils.async_get_dex_class(pool=pool)
-    asset_symbols_task = asyncio.create_task(
-        dex.async_get_pool_asset_symbols(pool=pool)
+    metadata_task = asyncio.create_task(
+        uniswap_v2_utils.async_get_pool_tokens_metadata(pool)
     )
 
     columns = toolcli.get_n_terminal_cols()
     n_candles = math.floor((columns - 10) / 2)
     if timescale is None:
         candle_timescale = '1d'
     else:
@@ -74,143 +70,138 @@
         math.floor((window_end - window_seconds) / candle_seconds)
         * candle_seconds
     )
     start_block = await evm.async_get_block_of_timestamp(window_start) - 1
     end_block = await evm.async_get_latest_block_number()
 
     # get data
-    swaps = await dex_utils.async_get_pool_trades(
+    swaps = await uniswap_v2_utils.async_get_pool_swaps(
         pool,
         start_block=start_block,
         end_block=end_block,
         normalize=True,
         include_volumes=True,
         include_prices=True,
     )
 
     # compute candlesticks
-    prices = swaps['price__0__per__1'].values
-    x_volumes = swaps['volume__0'].values
+    prices = swaps['price__0__per__1'].to_numpy()
+    x_volumes = swaps['volume__0'].to_numpy()
     if invert:
         prices = 1 / prices
-    block_numbers = list(swaps.index.get_level_values('block_number'))
     block_timestamps = await evm.async_get_block_timestamps(
-        block_numbers,
-        provider={'chunk_size': 1},
+        swaps['block_number'].to_list()
     )
     ohlc = ohlc_utils.compute_ohlc(
-        values=prices,  # type: ignore
+        values=list(prices),
         indices=block_timestamps,
         bin_size=candle_seconds,
-        volumes=x_volumes,  # type: ignore
+        volumes=list(x_volumes),
     )
-    ohlc = ohlc.iloc[-n_candles:]
+    ohlc = ohlc[-n_candles:]
 
     min_price = min(prices)
     max_price = max(prices)
-    min_time = ohlc.index[0]
-    max_time = ohlc.index[-1] + candle_seconds
+    min_time = ohlc['bin'][0]
+    max_time = ohlc['bin'][-1] + candle_seconds
     render_grid = toolstr.create_grid(
         n_rows=20,
         n_columns=n_candles * 2,
         xmin=min_time - 0.05 * (max_time - min_time),
         xmax=max_time + 0.05 * (max_time - min_time),
         ymin=min_price - 0.05 * (max_price - min_price),
         ymax=max_price + 0.05 * (max_price - min_price),
     )
     sample_grid = toolstr.create_grid(sample_mode='quadrants', **render_grid)
-    result = toolstr.raster_candlesticks(ohlc.values, sample_grid, render_grid)
+    result = toolstr.raster_candlesticks(ohlc.rows(), sample_grid, render_grid)
     raster = result['raster']
     color_grid = result['color_grid']
 
     as_str = toolstr.render_supergrid(
         raster,
         char_dict='quadrants',
         color_grid=color_grid,
         color_map=toolstr.candlestick_color_map,
     )
 
     console = rich.console.Console(theme=rich.theme.Theme(inherit=False))
 
     styles = cli.get_cli_styles()
-    plot_styles = {
-        'tick_label_style': 'bold',
-        'chrome_style': '#888888',
-    }
+    tick_label_style = 'bold'
+    chrome_style = '#888888'
 
     y_axis = toolstr.render_y_axis(
         grid=render_grid,
-        **plot_styles,  # type: ignore
+        tick_label_style=tick_label_style,
+        chrome_style=chrome_style,
     )
     y_axis_width = rich.text.Text.from_markup(y_axis.split('\n')[0]).cell_len
     graph = toolstr.concatenate_blocks([y_axis, as_str])
 
     formatter = functools.partial(
         toolstr.format_timestamp,
         representation='TimestampDate',
     )
     x_axis = toolstr.render_x_axis(
         grid=render_grid,
         formatter=formatter,
-        **plot_styles,  # type: ignore
+        tick_label_style=tick_label_style,
+        chrome_style=chrome_style,
     )
     x_axis = toolstr.indent_block(x_axis, indent=y_axis_width)
 
     # compute volume
     if not no_volume:
-        ymax = ohlc['volume'].max() * 1.1
+        max_volume = ohlc['volume'].max()
+        if max_volume is None:
+            max_volume = 100.0
+        ymax = float(max_volume) * 1.1  # type: ignore
         volume_render_grid = toolstr.create_grid(
             n_rows=5,
             n_columns=n_candles * 2,
             xmin=render_grid['xmin'],
             xmax=render_grid['xmax'],
             ymin=0 - ymax / 9,
             ymax=ymax,
         )
         volume_sample_grid = toolstr.create_grid(
             sample_mode='quadrants',
             **volume_render_grid,
         )
         volume_raster = toolstr.raster_bar_chart(
-            values=ohlc['volume'],  # type: ignore
+            values=ohlc['volume'].to_list(),
             grid=volume_sample_grid,
             bar_width=1,
             bar_gap=3,
             start_gap=1,
         )
         volume_y_axis = toolstr.render_y_axis(
             grid=volume_render_grid,
             n_ticks=1,
-            **plot_styles,  # type: ignore
+            tick_label_style=tick_label_style,
+            chrome_style=chrome_style,
         )
 
     # wait for metadata
-    asset_symbols = await asset_symbols_task
-
-    if len(asset_symbols) != 2:
-        raise Exception('can only display candlesticks for pools with 2 assets')
+    metadata = await metadata_task
 
     # print output
-    token0 = asset_symbols[0]
-    token1 = asset_symbols[1]
+    token0 = metadata['x_symbol']
+    token1 = metadata['y_symbol']
     toolstr.print_text_box(
-        token0 + '-' + token1 + ' ' + dex.get_dex_name() + ' Pool',
+        metadata['x_symbol'] + '-' + metadata['y_symbol'] + ' Uniswap V2 Pool',
         style=styles['title'],
     )
     cli.print_bullet(key='pool address', value=pool)
     cli.print_bullet(key='each candle', value=candle_timescale)
     cli.print_bullet(key='n_candles', value=n_candles)
     if invert:
-        cli.print_bullet(
-            key='price units', value=str(token1) + ' per ' + str(token0)
-        )
+        cli.print_bullet(key='price units', value=str(token1) + ' per ' + str(token0))
     else:
-        cli.print_bullet(
-            key='price units', value=str(token0) + ' per ' + str(token1)
-        )
+        cli.print_bullet(key='price units', value=str(token0) + ' per ' + str(token1))
     if not no_volume:
         cli.print_bullet(key='volume units', value=token0)
     print()
     console.print(graph)
 
     if not no_volume:
         volume_bars_str = toolstr.render_supergrid(
```

### Comparing `checkthechain-0.3.0/src/ctc/cli/commands/data/dex/pool_command.py` & `checkthechain-0.3.4/src/ctc/cli/commands/data/dex/pool_command.py`

 * *Files 18% similar despite different names*

```diff
@@ -8,15 +8,15 @@
 import tooltime
 
 from ctc import cli
 from ctc.cli import cli_utils
 from ctc import evm
 from ctc import config
 from ctc import spec
-from ctc.toolbox.defi_utils import dex_utils
+from ctc.defi import dex_utils
 
 
 help_message = """show information about a pool"""
 
 
 def get_command_spec() -> toolcli.CommandSpec:
     return {
@@ -42,62 +42,58 @@
         ],
     }
 
 
 async def async_dex_pool_command(
     *,
     pool: spec.Address,
-    network: str | int | None,
     block: str | None,
+    network: str,
+    context: spec.Context = None,
 ) -> None:
     from ctc import db
 
-    if network is not None:
-        network = cli_utils.parse_network(typing.cast(str, network))
-    if network is None:
-        network = config.get_default_network()
-
     if block is not None:
-        block_number = await cli_utils.async_parse_block(block)
+        block_number = await cli_utils.async_parse_block(block, context=context)
     else:
         block_number = None
 
-    dex_pool = await db.async_query_dex_pool(address=pool, network=network)
+    dex_pool = await db.async_query_dex_pool(address=pool, context=context)
     if dex_pool is None:
         print('pool not found, updating dex database')
         await dex_utils.async_update_all_dexes()
-        dex_pool = await db.async_query_dex_pool(address=pool, network=network)
+        dex_pool = await db.async_query_dex_pool(address=pool, context=context)
         if dex_pool is None:
             raise Exception('could not find pool data')
 
     dex = await dex_utils.async_get_dex_class(
-        pool=dex_pool['address'],
+        pool=dex_pool['address'], context=context,
     )
 
     # queue creation timestamp task
     creation_timestamp_coroutine = evm.async_get_block_timestamp(
-        dex_pool['creation_block'],
+        dex_pool['creation_block'], context=context
     )
     creation_timestamp_task = asyncio.create_task(creation_timestamp_coroutine)
 
     # queue asset symbols task
     assets: typing.Sequence[str] = [
         typing.cast(str, dex_pool.get(key))
         for key in ['asset0', 'asset1', 'asset2', 'asset3']
         if dex_pool.get(key) is not None
     ]
     asset_symbols_task = asyncio.create_task(
-        evm.async_get_erc20s_symbols(assets)
+        evm.async_get_erc20s_symbols(assets, context=context)
     )
 
     # queue balances task
     balances_coroutine = dex.async_get_pool_balances(
         pool,
-        network=network,
         block=block_number,
+        context=context,
     )
     balances_task = asyncio.create_task(balances_coroutine)
 
     # await all tasks
     creation_timestamp = await creation_timestamp_task
     asset_symbols = await asset_symbols_task
     balances = await balances_task
@@ -146,25 +142,27 @@
         column_formats={
             'balance': {'trailing_zeros': True},
         },
     )
 
     if dex_name == 'UniswapV2':
         from ctc.protocols import uniswap_v2_utils
-        from ctc.toolbox.defi_utils.dex_utils.amm_utils import cpmm
+        from ctc.defi.dex_utils.amm_utils import cpmm
 
         print()
         toolstr.print_header('Pool State', style=styles['title'])
         tokens_metadata = await uniswap_v2_utils.async_get_pool_tokens_metadata(
-            pool
+            pool,
+            context=context,
         )
         x_symbol = tokens_metadata['x_symbol']
         y_symbol = tokens_metadata['y_symbol']
         pool_state = await uniswap_v2_utils.async_get_pool_state(
             pool,
             block=block_number,
+            context=context,
         )
         cpmm.print_pool_summary(
             x_name=x_symbol,
             y_name=y_symbol,
             **pool_state,
         )
```

### Comparing `checkthechain-0.3.0/src/ctc/cli/commands/data/dex/pools_command.py` & `checkthechain-0.3.4/src/ctc/cli/commands/data/dex/pools_command.py`

 * *Files 8% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 import toolcli
 import toolstr
 
 from ctc import cli
 from ctc.cli import cli_utils
 from ctc import evm
 from ctc import spec
-from ctc.toolbox.defi_utils import dex_utils
+from ctc.defi import dex_utils
 
 
 def get_command_spec() -> toolcli.CommandSpec:
     return {
         'f': async_dex_pools_command,
         'help': 'list dex pools',
         'args': [
@@ -107,21 +107,23 @@
     json_output: bool,
     csv_output: bool,
     export: str | None,
     overwrite: bool,
     sort: typing.Sequence[str] | None,
 ) -> None:
 
-    factory_dexes = dex_utils.get_dex_names_of_factories(network='mainnet')
+    factory_dexes = dex_utils.get_dex_names_of_factories(network='ethereum')
 
     coroutines = [evm.async_get_erc20_address(token) for token in tokens]
     assets = await asyncio.gather(*coroutines)
 
     if created is not None:
-        start_block, end_block = await cli_utils.async_parse_block_range(created)
+        start_block, end_block = await cli_utils.async_parse_block_range(
+            created
+        )
     else:
         start_block = None
         end_block = None
     dex_pools = await dex_utils.async_get_pools(
         assets=assets,
         factory=factory,
         dex=dex,
@@ -134,24 +136,24 @@
     if json_output and export is None:
         import json
 
         as_str = json.dumps(dex_pools)
         print(as_str)
         return
     if csv_output and export is None:
-        import pandas as pd
+        import polars as pl
 
-        df = pd.DataFrame(dex_pools)
-        csv_str = df.to_csv()
+        df = pl.DataFrame(dex_pools)
+        csv_str = df.write_csv(None)
         print(csv_str)
         return
     if export:
-        import pandas as pd
+        import polars as pl
 
-        df = pd.DataFrame(dex_pools)
+        df = pl.DataFrame(dex_pools)
         cli_utils.output_data(df, output=export, overwrite=overwrite)
         print('saved output to', export)
         return
 
     styles = cli.get_cli_styles()
 
     toolstr.print(
@@ -182,15 +184,17 @@
         if asset3 is not None:
             all_assets.add(dex_pool['asset3'])
             n_assets = 4
 
     ordered_assets = [asset for asset in all_assets if asset is not None]
     symbols = await evm.async_get_erc20s_symbols(
         ordered_assets,
-        provider={'chunk_size': 10, 'convert_reverts_to_none': True},
+        context=dict(
+            provider={'chunk_size': 10, 'convert_reverts_to_none': True}
+        ),
     )
 
     symbols = [symbol.replace('\x00', '') for symbol in symbols]
 
     for i in range(len(ordered_assets)):
         if ordered_assets[i] == '0xeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee':
             symbols[i] = 'ETH'
@@ -243,18 +247,15 @@
     if n_assets >= 4:
         labels.append('asset3')
     if verbose:
         labels.append('creation\nblock')
         labels.append('age')
 
     if sort is not None:
-        sort_indices = [
-            labels.index(column)
-            for column in sort
-        ]
+        sort_indices = [labels.index(column) for column in sort]
     else:
         sort_indices = [
             labels.index('dex'),
             labels.index('asset0'),
             labels.index('asset1'),
         ]
     rows = sorted(
@@ -299,7 +300,8 @@
             'pools, use',
             toolstr.add_style('--all', styles['option']),
             'to display all',
             clipped + max_pools,
             'pools',
             style=styles['comment'],
         )
+
```

### Comparing `checkthechain-0.3.0/src/ctc/cli/commands/data/dex/trades_command.py` & `checkthechain-0.3.4/src/ctc/cli/commands/data/dex/trades_command.py`

 * *Files 8% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 import toolstr
 import tooltime
 
 from ctc import cli
 from ctc import evm
 from ctc import spec
 from ctc.cli import cli_utils
-from ctc.toolbox.defi_utils import dex_utils
+from ctc.defi import dex_utils
 
 
 def get_command_spec() -> toolcli.CommandSpec:
     return {
         'f': async_trades_command,
         'help': 'get DEX swaps',
         'args': [
@@ -54,14 +54,16 @@
     blocks: str,
     no_normalize: bool,
     export: str,
     overwrite: bool,
     verbose: bool,
 ) -> None:
 
+    import polars as pl
+
     if blocks is not None:
         start_block, end_block = await cli_utils.async_parse_block_range(blocks)
     else:
         start_block = None
         end_block = None
 
     trades = await dex_utils.async_get_pool_trades(
@@ -74,42 +76,42 @@
         include_volumes=True,
     )
 
     if export is not None:
         if not overwrite and os.path.isfile(export):
             raise Exception('file already exists, use --overwrite')
         if export.endswith('.csv'):
-            trades.to_csv(export)
+            trades.write_csv(export)
         elif export.endswith('.json'):
-            trades.to_json(export, orient='records')
+            trades.write_json(export, row_oriented=True)
         else:
             raise Exception('unknown export format')
     else:
 
-        trades = trades.iloc[-100:]
-        trades = trades.reset_index()
+        trades = trades[-100:]
 
         block_timestamps = await evm.async_get_block_timestamps(
             trades['block_number']
         )
-        trades['timestamp'] = [
+        timestamp_list = [
             tooltime.timestamp_to_iso_pretty(timestamp)
             for timestamp in block_timestamps
         ]
+        trades = trades.with_columns(pl.Series('timestamp', timestamp_list))
 
         rename_columns = {
             key: key.replace('__', '\n') for key in list(trades.columns)
         }
         rename_columns['block_number'] = 'block'
         rename_columns['sold_id'] = 'sold'
         rename_columns['bought_id'] = 'bought'
         for key, value in rename_columns.items():
             if value.startswith('price\n'):
                 rename_columns[key] = value[6:]
-        trades = trades.rename(columns=rename_columns)
+        trades = trades.rename(rename_columns)
 
         columns = list(trades.columns)
         if not verbose:
             columns = [
                 column
                 for column in columns
                 if column
```

### Comparing `checkthechain-0.3.0/src/ctc/cli/commands/data/erc20/balance_command.py` & `checkthechain-0.3.4/src/ctc/cli/commands/data/eth/balance_command.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,53 +1,53 @@
 from __future__ import annotations
 
+import typing
+
 import toolcli
 import toolstr
 
 from ctc import evm
 from ctc import spec
 
 
 def get_command_spec() -> toolcli.CommandSpec:
     return {
         'f': async_balance_command,
-        'help': 'output an ERC20 balance',
+        'help': 'output ETH balance of address',
         'args': [
-            {'name': 'erc20_address', 'help': 'address of ERC20 token'},
-            {'name': 'wallet_address', 'help': 'address of wallet'},
+            {'name': 'address', 'help': 'address of wallet'},
             {'name': '--block', 'help': 'block number'},
             {
                 'name': '--raw',
                 'action': 'store_true',
-                'help': 'whether to normalize balance by ERC20 decimals',
+                'help': 'skip normalizing balance by 1e18 decimals',
             },
         ],
         'examples': [
-            '0x956f47f50a910163d8bf957cf5846d573e7f87ca 0x9928e4046d7c6513326ccea028cd3e7a91c7590a',
-            '0x956f47f50a910163d8bf957cf5846d573e7f87ca 0x9928e4046d7c6513326ccea028cd3e7a91c7590a --raw',
-            '0x956f47f50a910163d8bf957cf5846d573e7f87ca 0x9928e4046d7c6513326ccea028cd3e7a91c7590a --block 14000000',
+            '0xd8da6bf26964af9d7eed9e03e53415d37aa96045',
+            '0xd8da6bf26964af9d7eed9e03e53415d37aa96045 --raw',
+            '0xd8da6bf26964af9d7eed9e03e53415d37aa96045 --block 14000000',
         ],
     }
 
 
 async def async_balance_command(
     *,
-    erc20_address: spec.Address,
-    wallet_address: spec.Address,
-    block: str,
+    address: str,
+    block: typing.Optional[spec.BlockNumberReference],
     raw: bool,
 ) -> None:
-    erc20_address = await evm.async_resolve_address(erc20_address, block=block)
-    wallet_address = await evm.async_resolve_address(
-        wallet_address,
-        block=block,
-    )
-    balance = await evm.async_get_erc20_balance(
-        wallet=wallet_address,
-        token=erc20_address,
+
+    address = await evm.async_resolve_address(address, block=block)
+
+    if block is not None:
+        block = await evm.async_block_number_to_int(block)
+
+    balance = await evm.async_get_eth_balance(
+        address=address,
         block=block,
         normalize=(not raw),
     )
     if raw:
         print(balance)
     else:
         print(toolstr.format(balance))
```

### Comparing `checkthechain-0.3.0/src/ctc/cli/commands/data/erc20/balances_command.py` & `checkthechain-0.3.4/src/ctc/cli/commands/data/erc20/balances_command.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,14 +1,15 @@
 from __future__ import annotations
 
 import typing
 
 import toolcli
 import toolstr
 
+import ctc.config
 from ctc import cli
 from ctc import evm
 from ctc import spec
 from ctc.cli import cli_utils
 
 
 command_help = """output ERC20 balances of blocks / addresses / tokens"""
@@ -80,15 +81,15 @@
     erc20s: typing.Optional[typing.Sequence[str]],
     raw: bool,
     export: str,
     overwrite: bool,
     n: int | None,
 ) -> None:
 
-    import pandas as pd
+    import polars as pl
 
     if wallets is not None:
         wallets = await evm.async_resolve_addresses(wallets, block=block)
     if erc20s is not None:
         erc20s = await evm.async_resolve_addresses(erc20s, block=block)
 
     indent = None
@@ -110,16 +111,15 @@
             wallet=wallet,
             tokens=erc20s,
             block=block,
             normalize=(not raw),
         )
         symbols = await symbols_coroutine
         data = {'balance': balances, 'symbol': symbols, 'erc20_address': erc20s}
-        df = pd.DataFrame(data)
-        df = df.set_index('erc20_address')
+        df = pl.DataFrame(data)
         output_data: typing.Union[spec.DataFrame, spec.Series] = df
 
         toolstr.print_text_box('ERC20 balances in wallet')
         print('- wallet:', wallet)
         print('- block:', block)
         print('- n_tokens:', len(erc20s))
         print()
@@ -145,18 +145,16 @@
                 wallets=wallets,
                 token=erc20,
                 block=block,
                 normalize=(not raw),
             )
             symbol = await symbol_coroutine
 
-            series = pd.Series(balances, index=wallets)
-            series.name = 'balance'
-            series.index.name = 'address'
-            output_data = series
+            df = pl.DataFrame({'balance': balances, 'address': wallets})
+            output_data = df
 
             print()
             toolstr.print_text_box(symbol + ' Balances')
             print('- token:', erc20)
             print('- symbol:', symbol)
             print('- block:', block)
             print()
@@ -177,15 +175,15 @@
             transfers = await evm.async_get_erc20_transfers(
                 erc20,
                 start_block=None,
                 end_block=block,
                 normalize=False,
             )
             df = await evm.async_get_erc20_balances_from_transfers(
-                transfers=transfers, dtype=None, normalize=(not raw)
+                transfers=transfers, normalize=(not raw)
             )
             output_data = df
 
             if n is None:
                 n = 20
 
             print()
@@ -271,36 +269,35 @@
                 return toolstr.format(round(xval))
 
             xvals = resolved_blocks
             yvals = balances
             plot = toolstr.render_line_plot(
                 xvals=xvals,
                 yvals=yvals,
-                n_rows=40,
-                n_columns=120,
+                n_rows=10,
+                n_columns=60,
                 line_style=styles['description'],
                 chrome_style=styles['comment'],
                 tick_label_style=styles['metavar'],
                 xaxis_kwargs={'formatter': formatter},
+                char_dict=ctc.config.get_cli_chart_charset(),
             )
             print()
             print()
             toolstr.print(
                 toolstr.hjustify('ETH balance over time', 'center', 70),
                 indent=4,
                 style=styles['title'],
             )
             toolstr.print(plot, indent=4)
 
             return
 
         else:
-            df = pd.dataframe(balances, index=resolved_blocks)
-            df.index.name = 'block'
-            df.columns = ['balance']
+            df = pl.DataFrame({'balance': balances, 'block': resolved_blocks})
             output_data = df
 
     else:
         raise Exception('invalid inputs')
 
     cli_utils.output_data(
         output_data,
```

### Comparing `checkthechain-0.3.0/src/ctc/cli/commands/data/erc20/transfers_command.py` & `checkthechain-0.3.4/src/ctc/cli/commands/data/erc20/transfers_command.py`

 * *Files 5% similar despite different names*

```diff
@@ -63,10 +63,8 @@
     transfers = await evm.async_get_erc20_transfers(
         erc20,
         start_block=start_block,
         end_block=end_block,
         include_timestamps=include_timestamps,
     )
 
-    if export == 'stdout' and include_timestamps:
-        transfers = transfers.astype({'timestamp': 'str'})
     cli_utils.output_data(transfers, output=export, overwrite=overwrite)
```

### Comparing `checkthechain-0.3.0/src/ctc/cli/commands/data/erc20_command.py` & `checkthechain-0.3.4/src/ctc/cli/commands/data/erc20_command.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/cli/commands/data/eth/balance_command.py` & `checkthechain-0.3.4/src/ctc/protocols/uniswap_v2_utils/cli/mints_command.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,53 +1,53 @@
 from __future__ import annotations
 
-import typing
-
 import toolcli
-import toolstr
 
-from ctc import evm
+from ctc.protocols import uniswap_v2_utils
+from ctc.cli import cli_utils
 from ctc import spec
 
 
 def get_command_spec() -> toolcli.CommandSpec:
     return {
-        'f': async_balance_command,
-        'help': 'output ETH balance of address',
+        'f': async_burns_command,
+        'help': 'output information about pool mints',
         'args': [
-            {'name': 'address', 'help': 'address of wallet'},
-            {'name': '--block', 'help': 'block number'},
+            {'name': 'pool', 'help': 'pool address'},
+            {'name': '--blocks', 'help': 'block number range'},
+            {
+                'name': '--export',
+                'default': 'stdout',
+                'help': 'file path for output (.json or .csv)',
+            },
             {
-                'name': '--raw',
+                'name': '--overwrite',
                 'action': 'store_true',
-                'help': 'skip normalizing balance by 1e18 decimals',
+                'help': 'specify that output path can be overwritten',
             },
         ],
         'examples': [
-            '0xd8da6bf26964af9d7eed9e03e53415d37aa96045',
-            '0xd8da6bf26964af9d7eed9e03e53415d37aa96045 --raw',
-            '0xd8da6bf26964af9d7eed9e03e53415d37aa96045 --block 14000000',
+            '0xae461ca67b15dc8dc81ce7615e0320da1a9ab8d5 --blocks 14000000:14001000',
         ],
     }
 
 
-async def async_balance_command(
+async def async_burns_command(
     *,
-    address: str,
-    block: typing.Optional[spec.BlockNumberReference],
-    raw: bool,
+    pool: spec.Address,
+    blocks: str | None,
+    export: str,
+    overwrite: bool,
 ) -> None:
 
-    address = await evm.async_resolve_address(address, block=block)
-
-    if block is not None:
-        block = await evm.async_block_number_to_int(block)
+    if blocks is not None:
+        start_block, end_block = await cli_utils.async_parse_block_range(blocks)
+    else:
+        start_block = None
+        end_block = None
 
-    balance = await evm.async_get_eth_balance(
-        address=address,
-        block=block,
-        normalize=(not raw),
+    burns = await uniswap_v2_utils.async_get_pool_burns(
+        pool,
+        start_block=start_block,
+        end_block=end_block,
     )
-    if raw:
-        print(balance)
-    else:
-        print(toolstr.format(balance))
+    cli_utils.output_data(burns, export, overwrite=overwrite)
```

### Comparing `checkthechain-0.3.0/src/ctc/cli/commands/data/eth/balances_command.py` & `checkthechain-0.3.4/src/ctc/cli/commands/data/eth/balances_command.py`

 * *Files 5% similar despite different names*

```diff
@@ -9,14 +9,15 @@
 from __future__ import annotations
 
 import typing
 
 import toolcli
 import toolstr
 
+import ctc.config
 from ctc import cli
 from ctc import evm
 from ctc import spec
 from ctc.cli import cli_utils
 
 
 def get_command_spec() -> toolcli.CommandSpec:
@@ -73,15 +74,15 @@
     raw: bool,
     export: str,
     overwrite: bool,
     verbose: bool,
 ) -> None:
 
     # REMOVE this
-    import pandas as pd
+    import polars as pl
 
     indent = None
     wallets = [wallet.lower() for wallet in wallets]
 
     if blocks is not None:
         # single wallet, multiple blocks
         if len(wallets) > 1:
@@ -112,18 +113,18 @@
 
         toolstr.print_text_box(
             'ETH Balances for ' + wallet, style=styles['title']
         )
         print()
 
         if verbose:
-            eth_usd = (await eth_usd_task).values
+            eth_usd = (await eth_usd_task).to_numpy()
             usd_balances = [
                 balance * eth_price
-                for balance, eth_price in zip(balances, eth_usd)
+                for balance, eth_price in zip(balances, eth_usd[:, 0])
             ]
         rows = []
         for b in range(len(resolved_blocks)):
             row = [
                 resolved_blocks[b],
                 balances[b],
             ]
@@ -163,20 +164,21 @@
             return toolstr.format(round(xval))
 
         xvals = resolved_blocks
         yvals = balances
         plot = toolstr.render_line_plot(
             xvals=xvals,
             yvals=yvals,
-            n_rows=40,
-            n_columns=120,
+            n_rows=10,
+            n_columns=60,
             line_style=styles['description'],
             chrome_style=styles['comment'],
             tick_label_style=styles['metavar'],
             xaxis_kwargs={'formatter': formatter},
+            char_dict=ctc.config.get_cli_chart_charset(),
         )
         print()
         print()
         toolstr.print(
             toolstr.hjustify('ETH balance over time', 'center', 70),
             indent=4,
             style=styles['title'],
@@ -185,35 +187,35 @@
 
         if verbose:
             xvals = resolved_blocks
             yvals = usd_balances
             plot = toolstr.render_line_plot(
                 xvals=xvals,
                 yvals=yvals,
-                n_rows=40,
-                n_columns=120,
+                n_rows=10,
+                n_columns=60,
                 line_style=styles['description'],
                 chrome_style=styles['comment'],
                 tick_label_style=styles['metavar'],
                 xaxis_kwargs={'formatter': formatter},
                 yaxis_kwargs={'tick_label_format': {'prefix': '$'}},
+                char_dict=ctc.config.get_cli_chart_charset(),
             )
             print()
             print()
             toolstr.print(
                 toolstr.hjustify('ETH balance over time (USD)', 'center', 70),
                 indent=4,
                 style=styles['title'],
             )
             toolstr.print(plot, indent=4)
 
         if export != 'stdout':
-            df = pd.DataFrame(balances, index=resolved_blocks)
-            df.index.name = 'block'
-            df.columns = ['balance']
+            df = pl.DataFrame(balances, ['balance'])
+            df = df.with_columns(pl.Series('block', resolved_blocks))
             output_data: typing.Union[spec.DataFrame, spec.Series] = df
             cli_utils.output_data(
                 output_data, export, overwrite=overwrite, indent=indent, raw=raw
             )
     else:
         # multiple wallets, single block
         if blocks is not None:
@@ -229,15 +231,14 @@
             wallets = await evm.async_resolve_addresses(wallets, block=block)
             balances = await evm.async_get_eth_balance_of_addresses(
                 addresses=wallets,
                 block=block,
                 normalize=(not raw),
             )
 
-            series = pd.Series(balances, index=wallets)
-            series.name = 'balance'
-            series.index.name = 'address'
-            output_data = series
+            output_data = pl.DataFrame(
+                {'balance': balances, 'address': wallets}
+            )
 
         cli_utils.output_data(
             output_data, export, overwrite=overwrite, indent=indent, raw=raw
         )
```

### Comparing `checkthechain-0.3.0/src/ctc/cli/commands/data/gas_command.py` & `checkthechain-0.3.4/src/ctc/cli/commands/data/gas_command.py`

 * *Files 3% similar despite different names*

```diff
@@ -19,14 +19,15 @@
 import time
 import typing
 
 import toolcli
 import toolstr
 import tooltime
 
+import ctc.config
 from ctc import cli
 from ctc import evm
 from ctc import rpc
 from ctc.cli import cli_utils
 
 
 def get_command_spec() -> toolcli.CommandSpec:
@@ -64,15 +65,15 @@
                 'name': ['-v', '--verbose'],
                 'action': 'store_true',
                 'help': 'output additional information',
             },
         ],
         'examples': [
             '',
-            '--last 300',
+            '--last 30',
         ],
     }
 
 
 async def async_gas_command(
     *,
     block: int | None,
@@ -250,21 +251,17 @@
             row.append(np.nanmax(interval_median_gas_fees))
         else:
             row.extend([None] * 4)
 
         rows.append(row)
 
     if export != 'stdout':
-        import pandas as pd
-
-        final_df = pd.DataFrame(rows)
-        final_df.columns = labels
-        final_df = final_df.sort_values(by='time')
-        final_df = final_df.set_index('blocks')
+        import polars as pl
 
+        final_df = pl.DataFrame(rows, labels, orient='row').sort('time')
         cli_utils.output_data(final_df, export, overwrite=overwrite)
     else:
         toolstr.print_table(
             rows=rows,
             labels=labels,
             border=styles['comment'],
             label_style=styles['title'],
@@ -292,24 +289,24 @@
             n_ticks = 3
         else:
             xtick_format = 'iso'
             n_ticks = 2
         plot = toolstr.render_line_plot(
             xvals=xvals,
             yvals=yvals,  # type: ignore
-            n_rows=40,
-            n_columns=120,
+            n_rows=10,
+            n_columns=60,
             line_style=styles['description'],
             chrome_style=styles['comment'],
             tick_label_style=styles['metavar'],
             xaxis_kwargs={
                 'tick_label_format': xtick_format,
                 'n_ticks': n_ticks,
             },
-            # char_dict='sextants',
+            char_dict=ctc.config.get_cli_chart_charset(),
         )
         print()
         print()
         toolstr.print(
             toolstr.hjustify('median fee', 'center', 70),
             indent=4,
             style=styles['title'],
```

### Comparing `checkthechain-0.3.0/src/ctc/cli/commands/data/proxy_command.py` & `checkthechain-0.3.4/src/ctc/cli/commands/data/proxy_command.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/cli/commands/data/proxy_register_command.py` & `checkthechain-0.3.4/src/ctc/cli/commands/data/proxy_register_command.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 from __future__ import annotations
 
 import toolcli
 import toolstr
 
 from ctc import cli
+from ctc import config
 from ctc import evm
 from ctc import spec
-from ctc import rpc
 
 
 help_message = """register custom proxy implementation of a contract
 
 Implementation ABI will be downloaded for original contract
 
 Manual registration using this command is normally unnecessary
@@ -48,16 +48,16 @@
     implementation_contract: spec.Address,
     *,
     confirm: bool,
 ) -> None:
 
     styles = cli.get_cli_styles()
 
-    provider = rpc.get_provider()
-    network = evm.get_network_name(provider['network'])
+    context: spec.Context = {}
+    network = config.get_context_chain_id(context)
 
     if not confirm:
         toolstr.print(
             'Registering ABI implementation for use with proxy contract...',
             style=styles['description'],
         )
         toolstr.print(
@@ -78,15 +78,15 @@
         print()
         answer = toolcli.input_yes_or_no(
             'Proceed? (y/n) ', style=styles['metavar']
         )
         if not answer:
             return
 
+    context = config.create_user_input_context(network=network, cache=False)
     abi = await evm.async_get_contract_abi(
         contract_address=proxy_contract,
-        network=network,
         proxy_implementation=implementation_contract,
-        db_query=False,
+        context=context,
     )
 
     print('resulting abi contains', len(abi), 'items')
```

### Comparing `checkthechain-0.3.0/src/ctc/cli/commands/data/storage_command.py` & `checkthechain-0.3.4/src/ctc/cli/commands/data/storage_command.py`

 * *Files 3% similar despite different names*

```diff
@@ -46,10 +46,10 @@
         contract_address,
         position=slot,
         block_number=block,
     )
     if datatype is None:
         print(result)
     else:
-        as_bytes = evm.binary_convert(result, 'binary')
+        as_bytes = evm.to_binary(result)
         decoded = evm.abi_decode(as_bytes, datatype)
         print(decoded)
```

### Comparing `checkthechain-0.3.0/src/ctc/cli/commands/data/symbol_command.py` & `checkthechain-0.3.4/src/ctc/cli/commands/data/symbol_command.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/cli/commands/data/timestamp_command.py` & `checkthechain-0.3.4/src/ctc/cli/commands/data/timestamp_command.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/cli/commands/root_command.py` & `checkthechain-0.3.4/src/ctc/cli/commands/root_command.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/config/config_defaults.py` & `checkthechain-0.3.4/src/ctc/config/config_defaults.py`

 * *Files 5% similar despite different names*

```diff
@@ -5,43 +5,57 @@
 
 from __future__ import annotations
 
 import os
 import typing
 
 import ctc
-from ctc import evm
 from ctc import spec
 
 if typing.TYPE_CHECKING:
+    import toolcli
     import toolsql
+    import toolstr
 
 
 def get_default_config(use_env_variables: bool = True) -> spec.Config:
 
     data_dir = get_default_data_dir()
 
     default_config: spec.Config = {
         'config_spec_version': ctc.__version__,
         'data_dir': data_dir,
         #
         # networks
-        'default_network': None,
+        'default_network': 1,
         'networks': get_default_networks_metadata(),
         #
         # providers
         'providers': {},
         'default_providers': {},
         #
         # db
         'db_configs': get_default_db_configs(data_dir=data_dir),
         #
+        # cache
+        'context_cache_rules': [
+            {
+                'backend': 'main',
+                'read': True,
+                'write': True,
+            },
+        ],
+        #
         # logging
         'log_rpc_calls': get_default_log_rpc_calls(),
         'log_sql_queries': get_default_log_sql_queries(),
+        #
+        # cli
+        'cli_color_theme': get_default_cli_color_theme(),
+        'cli_chart_charset': get_default_cli_chart_charset(),
     }
     # add in ETH_RPC_URL provider for no config mode
     if use_env_variables:
         add_env_var_rpc_provider(default_config)
 
     return default_config
 
@@ -57,15 +71,17 @@
         if chain_id not in [None, '']:
             try:
                 chain_id = int(chain_id)  # type: ignore
             except Exception:
                 pass
         if chain_id is None:
             try:
-                chain_id = _sync_get_chain_id(eth_rpc_url)
+                from ctc.rpc import rpc_provider
+
+                chain_id = rpc_provider._sync_get_chain_id(eth_rpc_url)
             except Exception:
                 print(
                     '[WARNING] not using value in ETH_RPC_URL because could not determine its chain_id (value = '
                     + str(eth_rpc_url)
                     + ')'
                 )
                 return
@@ -82,47 +98,32 @@
         default_config['providers'][provider_name] = {  # type: ignore
             'name': provider_name,
             'network': chain_id,
             'protocol': 'http',
             'url': eth_rpc_url,
             'session_kwargs': {},
             'chunk_size': None,
+            'convert_reverts_to_none': False,
+            'disable_batch_requests': False,
         }
         default_config['default_providers'][chain_id] = provider_name  # type: ignore
 
 
-def _sync_get_chain_id(provider_url: str) -> int:
-    import json
-    import urllib.request
-
-    data = {'jsonrpc': '2.0', 'method': 'eth_chainId', 'params': [], 'id': 1}
-    encoded_data = json.dumps(data).encode()
-    request = urllib.request.Request(
-        provider_url,
-        data=encoded_data,
-        headers={'User-Agent': 'python3'},
-    )
-    response = urllib.request.urlopen(request)
-    response_data = json.loads(response.read().decode())
-    raw_chain_id = response_data['result']
-    return evm.binary_convert(raw_chain_id, 'integer')
-
-
 def get_default_data_dir() -> str:
     return os.path.abspath(os.path.join(os.path.expanduser('~'), 'ctc_data'))
 
 
 #
 # # networks
 #
 
 
 def get_default_network_names_by_chain_id() -> typing.Mapping[int, str]:
     return {
-        1: 'mainnet',
+        1: 'ethereum',
         3: 'ropsten',
         4: 'rinkeby',
         5: 'goerli',
         10: 'optimism',
         42: 'kovan',
         56: 'bnb',
         69: 'optimism_kovan',
@@ -152,15 +153,15 @@
         name: chain_id
         for chain_id, name in get_default_network_names_by_chain_id().items()
     }
 
 
 def get_default_block_explorers() -> typing.Mapping[str, str]:
     return {
-        'mainnet': 'etherscan.io',
+        'ethereum': 'etherscan.io',
         'ropsten': 'ropsten.etherscan.io',
         'rinkeby': 'rinkeby.etherscan.io',
         'goerli': 'goerli.etherscan.io',
         'optimism': 'optimistic.etherscan.io',
         'kovan': 'kovan.etherscan.io',
         'bnb': 'bscscan.com',
         'optimism_kovan': 'kovan-optimistic.etherscan.io',
@@ -201,22 +202,23 @@
 
 
 #
 # # db
 #
 
 
-def get_default_db_config(data_dir: str) -> toolsql.DBConfig:
+def get_default_db_config(*, data_dir: str) -> toolsql.DBConfig:
     return {
         'dbms': 'sqlite',
         'path': os.path.join(data_dir, 'dbs/ctc.db'),
     }
 
 
 def get_default_db_configs(
+    *,
     data_dir: str,
 ) -> typing.Mapping[str, toolsql.DBConfig]:
     return {'main': get_default_db_config(data_dir=data_dir)}
 
 
 #
 # # logging
@@ -225,7 +227,28 @@
 
 def get_default_log_rpc_calls() -> bool:
     return False
 
 
 def get_default_log_sql_queries() -> bool:
     return False
+
+
+#
+# # cli
+#
+
+
+def get_default_cli_color_theme() -> toolcli.StyleTheme:
+    return {
+        'title': 'bold #ce93f9',
+        'metavar': '#8be9fd',
+        'description': '#b9f29f',
+        'content': '#f1fa8c',
+        'option': '#64aaaa',
+        'comment': '#6272a4',
+    }
+
+
+def get_default_cli_chart_charset() -> toolstr.SampleMode:
+    return 'braille'
+
```

### Comparing `checkthechain-0.3.0/src/ctc/config/config_read.py` & `checkthechain-0.3.4/src/ctc/config/config_read.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,126 +1,113 @@
 """utilitize for config file IO"""
 
 from __future__ import annotations
 
+import os
 import functools
 import sys
 import typing
-from typing_extensions import TypedDict
-
-if typing.TYPE_CHECKING:
-    import toolconfig
 
 import ctc
 from ctc import spec
+from . import config_env_vars
+from . import config_overrides
 from . import config_spec
 from . import config_validate
-
-
-class _ToolconfigKwargs(TypedDict):
-    config_path_env_var: str
-    default_config_path: str
-
-
-_kwargs: _ToolconfigKwargs = {
-    'config_path_env_var': config_spec.config_path_env_var,
-    'default_config_path': config_spec.default_config_path,
-}
+from . import upgrade_utils
 
 
 def get_config_path(*, raise_if_dne: bool = True) -> str:
-    import toolconfig
-
-    return toolconfig.get_config_path(raise_if_dne=raise_if_dne, **_kwargs)
-
-
-def config_path_exists() -> bool:
-    import toolconfig
 
-    return toolconfig.config_path_exists(**_kwargs)
+    config_path_env_var = config_spec.config_path_env_var
+    default_config_path = config_spec.default_config_path
 
+    # get config_path from environmental variable
+    if config_path_env_var is not None:
+        config_path = os.environ.get(config_path_env_var)
+        if config_path == '':
+            config_path = None
+
+    # use default config path if not specified
+    if config_path is None and default_config_path is not None:
+        config_path = default_config_path
+
+    # validate config_path
+    if config_path is None:
+        raise spec.ConfigPathNotSet('config path is not set')
+    else:
+        if raise_if_dne and not os.path.isfile(config_path):
+            raise spec.ConfigDoesNotExist(
+                'config at path does not exist: ' + str(config_path)
+            )
 
-@typing.overload
-def get_config(
-    validate: typing.Literal['raise'] = 'raise',
-    warn_if_dne: bool = True,
-) -> spec.Config:
-    ...
-
-
-@typing.overload
-def get_config(
-    validate: typing.Literal['warn', False],
-    warn_if_dne: bool = True,
-) -> typing.MutableMapping[str, typing.Any]:
-    ...
+    return config_path
 
 
 @functools.lru_cache()
 def get_config(
-    validate: toolconfig.ValidationOption = False,
     warn_if_dne: bool = True,
-) -> typing.Union[spec.Config, typing.MutableMapping[str, typing.Any]]:
-    import toolconfig
+    warn_if_outdated: bool = True,
+) -> spec.Config:
 
     # load from file
     try:
-        config_from_file = toolconfig.get_config(
-            config_spec=None, validate=validate, **_kwargs
-        )
-    except toolconfig.ConfigDoesNotExist:
+        config_path = get_config_path()
+        with open(config_path, 'r') as f:
+            import json
+
+            raw_config = json.load(f)
+    except spec.ConfigDoesNotExist:
         from . import config_defaults
 
         if warn_if_dne:
             print(
                 '[WARNING]'
                 ' ctc config file does not exist;'
                 ' use `ctc setup` on command line to generate a config file',
                 file=sys.stderr,
             )
-        config_from_file = config_defaults.get_default_config(
-            use_env_variables=True,
-        )  # type: ignore
-
-    if config_from_file.get('config_spec_version') != ctc.__version__:
-        print(
-            '[WARNING] using outdated config -- run `ctc setup` on command line'
-        )
-        from . import upgrade_utils
+        raw_config = config_defaults.get_default_config(use_env_variables=True)
 
-        config_from_file = upgrade_utils.upgrade_config(config_from_file)
+    # auto-upgrade config if need be
+    config_version = raw_config.get('config_spec_version')
+    if config_version is not None:
+        config_stable_version = upgrade_utils.get_stable_version(config_version)
+    else:
+        config_stable_version = None
+    ctc_stable_version = upgrade_utils.get_stable_version(ctc.__version__)
+    if config_stable_version != ctc_stable_version:
+        if warn_if_outdated:
+            print(
+                '[WARNING] using outdated config -- run `ctc setup` on command line to update',
+                file=sys.stderr,
+            )
+        raw_config = upgrade_utils.upgrade_config(raw_config)
 
     # convert int keys from str to int
-    if config_from_file.get('networks') is not None:
-        config_from_file['networks'] = {
-            int(chain_id): network_metadata
-            for chain_id, network_metadata in config_from_file[
-                'networks'
-            ].items()
-        }
-    if config_from_file.get('default_providers') is not None:
-        config_from_file['default_providers'] = {
-            int(chain_id): provider
-            for chain_id, provider in config_from_file[
-                'default_providers'
-            ].items()
-        }
-
-    config = config_from_file
+    for key in spec.typedata.config_int_subkeys:
+        if raw_config.get(key) is not None:
+            raw_config[key] = {
+                int(chain_id): network_metadata
+                for chain_id, network_metadata in raw_config[key].items()
+            }
+
+    # load settings from env vars
+    raw_config = config_env_vars._add_config_env_vars(raw_config)
+
+    # add config overrides
+    raw_config = raw_config
+    overrides = config_overrides.get_config_overrides()
+    if len(overrides) > 0:
+        raw_config = dict(raw_config)
+        raw_config.update(overrides)
 
     # validate
-    config_validate.validate_config(config)
-
-    if validate == 'raise':
-        if typing.TYPE_CHECKING:
-            return typing.cast(spec.Config, config)
-        else:
-            return config
-    else:
-        return config
+    config_validate.validate_config(raw_config)
+    return raw_config  # type: ignore
 
 
 def get_config_version_tuple(
     config: typing.Mapping[str, typing.Any],
 ) -> typing.Tuple[int, int, int]:
 
     if 'config_spec_version' in config:
@@ -140,7 +127,12 @@
             and isinstance(config_version[0], int)
             and isinstance(config_version[1], int)
             and isinstance(config_version[2], int)
         ):
             return (config_version[0], config_version[1], config_version[2])
 
     raise Exception('could not detect config version')
+
+
+def reset_config_cache() -> None:
+    get_config.cache_clear()
+
```

### Comparing `checkthechain-0.3.0/src/ctc/config/config_validate.py` & `checkthechain-0.3.4/src/ctc/config/setup_utils/setup_io.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,215 +1,212 @@
 from __future__ import annotations
 
+import json
 import os
 import typing
 
-from ctc import spec
+import toolcli
+import toolstr
 
+import ctc
+import ctc.config
+from ctc import spec
+from ctc.cli import cli_utils
+from .. import config_spec
+from .. import config_read
+from .. import upgrade_utils
+
+
+def load_old_config(
+    convert_to_latest: bool,
+) -> typing.Mapping[typing.Any, typing.Any]:
+
+    # get old config path
+    config_path: str | None = os.environ.get(config_spec.config_path_env_var)
+    if config_path in ['', None]:
+        config_path = config_spec.default_config_path
+
+    # load old config file
+    if isinstance(config_path, str) and os.path.isfile(config_path):
+        with open(config_path) as f:
+            old_config: typing.Mapping[typing.Any, typing.Any] = json.load(f)
+    else:
+        old_config = {}
+
+    old_providers = old_config.get('providers')
+    if old_providers is not None:
+        for provider_name, provider in list(old_providers.items()):
+            for provider_key in spec.provider_keys:
+                if provider_key not in provider:
+                    if provider_key in spec.default_provider_settings:
+                        provider.setdefault(
+                            provider_key,
+                            spec.default_provider_settings[provider_key],
+                        )
+                    else:
+                        print('skipping provider, missing essential keys')
+                        del old_providers[provider_name]
+
+    # upgrade config file if need be
+    config_version = old_config.get('config_spec_version')
+    if config_version is not None:
+        config_stable_version = upgrade_utils.get_stable_version(config_version)
+    else:
+        config_stable_version = None
+    ctc_stable_version = upgrade_utils.get_stable_version(ctc.__version__)
+    if convert_to_latest and config_stable_version != ctc_stable_version:
+        try:
+            old_config = upgrade_utils.upgrade_config(old_config)
+        except spec.ConfigUpgradeError:
+            print()
+            print('old config could not be processed, skipping it')
+            old_config = {}
+
+    return old_config
+
+
+def setup_config_path() -> None:
+
+    # create parent dir
+    config_path = config_read.get_config_path(raise_if_dne=False)
+    parent_dir = os.path.dirname(config_path)
+    os.makedirs(parent_dir, exist_ok=True)
+
+
+def write_new_config(
+    *,
+    network_data: spec.PartialConfig,
+    db_data: spec.PartialConfig,
+    data_dir_data: spec.PartialConfig,
+    cli_data: spec.PartialConfig,
+    styles: toolcli.StyleTheme,
+    overwrite: bool = False,
+    headless: bool = False,
+) -> None:
 
-def get_config_validators() -> typing.Mapping[
-    str, None | typing.Callable[..., None]
-]:
-    return {
-        'config_spec_version': validate_config_spec_version,
-        'data_dir': validate_data_dir,
-        'networks': validate_networks,
-        'providers': validate_providers,
-        'default_network': validate_default_network,
-        'default_providers': validate_default_providers,
-        'db_configs': validate_db_configs,
-        'log_rpc_calls': None,
-        'log_sql_queries': None,
-    }
+    import json
 
+    config_path = config_read.get_config_path(raise_if_dne=False)
 
-def get_config_base_types() -> typing.Mapping[
-    str, typing.Type[typing.Any] | tuple[typing.Type[typing.Any], ...]
-]:
-    return {
-        'config_spec_version': str,
-        'data_dir': str,
-        'networks': dict,
-        'providers': dict,
-        'default_network': (int, type(None)),
-        'default_providers': dict,
-        'db_configs': dict,
-        'log_rpc_calls': bool,
-        'log_sql_queries': bool,
+    networks = {
+        str(key): value for key, value in network_data['networks'].items()
+    }
+    default_providers = {
+        str(key): value
+        for key, value in network_data['default_providers'].items()
     }
 
-
-def validate_config(config: typing.Mapping[typing.Any, typing.Any]) -> None:
-    """raise spec.ConfigInvalid if config is not valid"""
-
-    config_validators = get_config_validators()
-    config_base_types = get_config_base_types()
-
-    # check that all required keys are present
-    for key in spec.config_keys:
-        if key not in config:
-            raise spec.ConfigInvalid('config does not specify key: ' + str(key))
-
-    # check that each entry is valid
-    for key, value in config.items():
-
-        # check that key is allowed
-        if key not in spec.config_keys:
-            raise spec.ConfigInvalid('key not allowed in config:')
-
-        # check value type
-        if not isinstance(value, config_base_types[key]):
-            message = 'invalid type for ' + str(key) + ': ' + str(value)
-            raise spec.ConfigInvalid(message)
-
-    # check additional key validations
-    for key, value in config.items():
-        key_validator = config_validators.get(key)
-        if key_validator is not None:
-            key_validator(value=value, config=config)
-
-
-def is_valid_config(config: typing.Mapping[typing.Any, typing.Any]) -> bool:
-    try:
-        validate_config(config)
-        return True
-    except spec.ConfigInvalid:
-        return False
-
-
-#
-# # individual validators
-#
-
-
-def validate_config_spec_version(
-    value: typing.Any, config: typing.Mapping[typing.Any, typing.Any]
-) -> None:
-    pieces = value.split('.')
-    if len(pieces) != 3:
-        raise spec.ConfigInvalid('invalid config_spec_version: ' + str(value))
-    if not all(piece.isnumeric() for piece in pieces):
-        raise spec.ConfigInvalid('invalid config_spec_version: ' + str(value))
-
-    if pieces[0] != '0' or pieces[1] != '3':
-        raise spec.ConfigInvalid('config must use a version 0.3.x')
-
-
-def validate_data_dir(
-    value: typing.Any, config: typing.Mapping[typing.Any, typing.Any]
-) -> None:
-    abspath = os.path.abspath(os.path.expanduser(value))
-    if value != abspath:
-        raise spec.ConfigInvalid(
-            'data_dir path should be absolute: ' + str(value)
+    config: spec.JsonConfig = {
+        'config_spec_version': ctc.__version__,
+        'data_dir': data_dir_data['data_dir'],
+        'networks': networks,
+        'providers': network_data['providers'],
+        'default_network': network_data['default_network'],
+        'default_providers': default_providers,
+        'db_configs': db_data['db_configs'],
+        'log_rpc_calls': data_dir_data['log_rpc_calls'],
+        'log_sql_queries': data_dir_data['log_sql_queries'],
+        'cli_color_theme': cli_data['cli_color_theme'],
+        'cli_chart_charset': cli_data['cli_chart_charset'],
+        'context_cache_rules': [
+            {
+                'backend': 'main',
+                'read': True,
+                'write': True,
+            }
+        ],
+    }
+    print()
+    print()
+    toolstr.print('## Creating Configuration File', style=styles['title'])
+    if os.path.isfile(config_path):
+        with open(config_path, 'r') as f:
+            old_config_raw = json.load(f)
+        write_new = json.dumps(config, sort_keys=True) != json.dumps(
+            old_config_raw, sort_keys=True
         )
 
+        # print updated keys
+        if write_new:
 
-def validate_networks(
-    value: typing.Any, config: typing.Mapping[typing.Any, typing.Any]
-) -> None:
-    config_keys = {'name', 'chain_id', 'block_explorer'}
-    for chain_id, network_metadata in value.items():
-        if not isinstance(chain_id, int):
-            raise spec.ConfigInvalid(
-                'networks should be identified by int chain_id'
-            )
-        if set(network_metadata.keys()) != config_keys:
-            raise spec.ConfigInvalid(
-                'network_metadata should specify name, chain_id, and block_explorer, instead got: '
-                + str(list(network_metadata.keys()))
-            )
-
-        name = network_metadata['name']
-        block_explorer = network_metadata['block_explorer']
-        if name is not None and not isinstance(name, str):
-            raise spec.ConfigInvalid('network name is not a str')
-        if network_metadata['chain_id'] != chain_id:
-            raise spec.ConfigInvalid('chain_id does not match')
-        if block_explorer is not None and not isinstance(block_explorer, str):
-            raise spec.ConfigInvalid('block_explorer is not a str')
-
-
-def validate_providers(
-    value: typing.Any, config: typing.Mapping[typing.Any, typing.Any]
-) -> None:
-
-    provider_keys = set(spec.provider_keys)
-    for provider_name, provider in value.items():
-        if not isinstance(provider_name, str):
-            raise spec.ConfigInvalid('provider name should be a str')
-
-        if set(provider.keys()) != provider_keys:
-            raise spec.ConfigInvalid(
-                'provider should have keys: ' + str(provider_keys)
-            )
-
-        url = provider['url']
-        name = provider['name']
-        network = provider['network']
-        protocol = provider['protocol']
-        session_kwargs = provider['session_kwargs']
-        chunk_size = provider['chunk_size']
-
-        if not isinstance(url, str):
-            raise spec.ConfigInvalid('provider url must be a str')
-        if name != provider_name:
-            raise spec.ConfigInvalid('provider name does not match')
-        if not isinstance(network, int):
-            raise spec.ConfigInvalid(
-                'provider networks should be an int chain_id'
-            )
-        if network not in config['networks']:
-            raise spec.ConfigInvalid('provider network not in network entries')
-        if protocol != 'http':
-            raise spec.ConfigInvalid('only http supported')
-        if not isinstance(session_kwargs, dict):
-            raise spec.ConfigInvalid('session_kwargs must be a dict')
-        if chunk_size is not None and not isinstance(chunk_size, int):
-            raise spec.ConfigInvalid('chunk_size is not int')
-
-        if not url.startswith('http'):
-            raise spec.ConfigInvalid(
-                'http provider url must start with "http://" or "https://"'
-            )
-
-
-def validate_default_network(
-    value: typing.Any, config: typing.Mapping[typing.Any, typing.Any]
-) -> None:
-
-    if value is None:
-        return
-
-    # check that value is present in networks
-    networks = config['networks']
-    if value not in networks:
-        raise spec.ConfigInvalid('default_network not in networks entries')
-
-
-def validate_default_providers(
-    value: typing.Any, config: typing.Mapping[typing.Any, typing.Any]
-) -> None:
-
-    networks = config['networks']
-    providers = config['providers']
-    for chain_id, provider_name in value.items():
-        if chain_id not in networks:
-            raise spec.ConfigInvalid(
-                'chain_id in default_providers not present in network entries'
-            )
-        if provider_name not in providers:
-            raise spec.ConfigInvalid(
-                'provider in default_providers not present in provider entries'
-            )
-
-
-def validate_db_configs(
-    value: typing.Any, config: typing.Mapping[typing.Any, typing.Any]
-) -> None:
-
-    if set(value.keys()) != {'main'}:
-        raise spec.ConfigInvalid(
-            'db_configs should only have main entry for now'
+            # detect updated keys
+            changed_keys: set[str] = set()
+            for key, value in config.items():
+                if json.dumps(value, sort_keys=True) != json.dumps(
+                    old_config_raw.get(key), sort_keys=True
+                ):
+                    changed_keys.add(key)
+            for key in old_config_raw.keys():
+                if key not in config:
+                    changed_keys.add(key)
+
+            print()
+            if changed_keys == set(config.keys()):
+                print('All keys updated')
+            else:
+                print('Updated keys:')
+                for key in sorted(changed_keys):
+                    cli_utils.print_bullet(
+                        value=key, key_style=styles['description']
+                    )
+                    old_value = old_config_raw.get(key)
+                    new_value = config.get(key)
+                    if isinstance(old_value, dict) and isinstance(
+                        new_value, dict
+                    ):
+                        changed_values = {}
+                        for k, v in new_value.items():
+                            if v != old_value.get(k):
+                                changed_values[k] = (old_value.get(k), v)
+                        if len(changed_values) > 0:
+                            for k, (old_v, new_v) in changed_values.items():
+                                cli_utils.print_bullet(
+                                    key='subkey', value=k, indent=4
+                                )
+                                cli_utils.print_bullet(
+                                    key='old', value=old_v, indent=8
+                                )
+                                cli_utils.print_bullet(
+                                    key='new', value=new_v, indent=8
+                                )
+
+                        # print deleted keys
+                        deleted_keys = [
+                            k for k in old_value if k not in new_value
+                        ]
+                        if len(deleted_keys) > 0:
+                            print('    - deleted subkeys:', deleted_keys)
+
+                    else:
+                        cli_utils.print_bullet(
+                            key='old value',
+                            value=old_config_raw.get(key),
+                            indent=4,
+                        )
+                        cli_utils.print_bullet(
+                            key='new value', value=config.get(key), indent=4
+                        )
+
+        # make sure file overwrite is confirmed
+        if write_new and not overwrite:
+            print()
+            if not toolcli.input_yes_or_no(
+                'Overwrite old config file? ',
+                default='yes',
+                style=styles['metavar'],
+                headless=headless,
+            ):
+                raise Exception('cannot continue without replacing config file')
+    else:
+        write_new = True
+
+    print()
+    if write_new:
+        with open(config_path, 'w') as f:
+            json.dump(config, f)
+        toolstr.print(
+            'Config file created at',
+            toolstr.add_style(config_path, styles['description']),
         )
-    if set(value['main'].keys()) != {'dbms', 'path'}:
-        raise spec.ConfigInvalid('db config should have keys dbms and path')
+    else:
+        print('Config unchanged')
+
```

### Comparing `checkthechain-0.3.0/src/ctc/config/config_values.py` & `checkthechain-0.3.4/src/ctc/config/config_values.py`

 * *Files 22% similar despite different names*

```diff
@@ -7,19 +7,20 @@
     - str values might be invalid
 - return a default when appropriate if no config value is specified
 """
 
 from __future__ import annotations
 
 import typing
-from typing_extensions import Literal
 import os
 
 if typing.TYPE_CHECKING:
+    import toolcli
     import toolsql
+    import toolstr
 
 from ctc import spec
 from . import config_defaults
 from . import config_read
 
 
 def get_config_spec_version() -> str | None:
@@ -36,16 +37,16 @@
 
 
 #
 # # networks
 #
 
 
-def get_default_network() -> spec.ChainId | None:
-    return config_read.get_config().get('default_network')
+def get_default_network() -> spec.ChainId:
+    return config_read.get_config()['default_network']
 
 
 def get_config_networks() -> typing.Mapping[spec.ChainId, spec.NetworkMetadata]:
     config = config_read.get_config()
     networks = config.get('networks')
     if networks is not None:
         return networks
@@ -84,70 +85,19 @@
 #
 
 
 def get_providers() -> typing.Mapping[spec.NetworkName, spec.Provider]:
     return config_read.get_config()['providers']
 
 
-def has_provider(
-    *,
-    name: str | None = None,
-    network: str | None = None,
-    url: str | None = None,
-) -> bool:
-    try:
-        get_provider(name=name, network=network, url=url)
-        return True
-    except LookupError:
-        return False
-
-
-def get_provider(
-    *,
-    name: str | None = None,
-    network: str | int | None = None,
-    protocol: str | None = None,
-    url: str | None = None,
-) -> spec.Provider:
-
-    from ctc.toolbox import search_utils
-
-    providers = list(get_providers().values())
-
-    # build query
-    query: typing.MutableMapping[str, str | int] = {}
-    if name is None and network is None and url is None:
-        raise Exception('specify network name or network or url')
-    if name is not None:
-        query['name'] = name
-    if network is not None:
-        if isinstance(network, str):
-            from ctc import evm
-
-            network = evm.get_network_chain_id(network)
-        query['network'] = network
-    if protocol is not None:
-        query['protocol'] = protocol
-    if url is not None:
-        query['url'] = url
-
-    return search_utils.get_matching_entry(sequence=providers, query=query)
-
-
-def get_default_provider(
-    network: spec.NetworkName | spec.ChainId | None = None,
-) -> spec.Provider:
+def get_network_default_provider(
+    network: spec.NetworkName | spec.ChainId,
+) -> spec.Provider | None:
     """get default provider for network"""
 
-    # if network not specified use default
-    if network is None:
-        network = get_default_network()
-    if network is None:
-        raise Exception('no default network specified')
-
     if not isinstance(network, int):
         if isinstance(network, str):
             for chain_id, network_metadata in get_config_networks().items():
                 if network == network_metadata['name']:
                     network = chain_id
                     break
             else:
@@ -155,67 +105,54 @@
         else:
             raise Exception('unknown network type: ' + str(type(network)))
 
     # get provider of network
     config = config_read.get_config()
     default_providers = config.get('default_providers', {})
     if network in default_providers:
-        return get_provider(name=default_providers[network])
+        provider_name = default_providers[network]
+        return config['providers'][provider_name]
     else:
         message = 'no default provider specified for network ' + str(network)
         raise Exception(message)
 
 
 #
-# # db
+# # caches
 #
 
+def get_context_cache_rules() -> typing.Sequence[spec.ContextCacheRule]:
+    config = config_read.get_config()
+    return config['context_cache_rules']
 
-@typing.overload
-def get_db_config(
-    *,
-    schema_name: str | None = None,
-    network: spec.NetworkReference | None = None,
-    require: Literal[True],
-) -> 'toolsql.DBConfig':
-    ...
-
-
-@typing.overload
-def get_db_config(
-    *,
-    schema_name: str | None = None,
-    network: spec.NetworkReference | None = None,
-    require: bool = False,
-) -> 'toolsql.DBConfig' | None:
-    ...
-
-
-def get_db_config(
-    *,
-    schema_name: str | None = None,
-    network: spec.NetworkReference | None = None,
-    require: bool = False,
-) -> 'toolsql.DBConfig' | None:
-
-    # for now, use same database for all schema_names and networks
-    config = config_read.get_config()
-    db_config = config.get('db_configs', {}).get('main')
-    if require and db_config is None:
-        raise Exception('db not configured')
+
+#
+# # db
+#
+
+def get_db_config(backend_name: str) -> toolsql.DBConfig:
+    config = config_read.get_config()
+    db_config = config['db_configs'].get(backend_name)
+    if db_config is None:
+        raise Exception('no valid db_config for ' + str(backend_name))
     return db_config
 
 
+def get_cache_backends() -> typing.Sequence[str]:
+    config = config_read.get_config()
+    return list(config['db_configs'].keys())
+
+
 #
 # # logging
 #
 
 
 def get_log_rpc_calls() -> bool:
-    config = config_read.get_config(warn_if_dne=False)
+    config = config_read.get_config()
     return config.get('log_rpc_calls', False)
 
 
 def get_log_sql_queries() -> bool:
     config = config_read.get_config()
     return config.get('log_sql_queries', False)
 
@@ -230,7 +167,23 @@
     return os.path.join(log_dir, 'rpc_requests.log')
 
 
 def get_sql_queries_log_path() -> str:
     log_dir = get_log_dir()
     os.makedirs(log_dir, exist_ok=True)
     return os.path.join(log_dir, 'sql_queries.log')
+
+
+#
+# # cli
+#
+
+
+def get_cli_color_theme() -> toolcli.StyleTheme:
+    config = config_read.get_config()
+    return config['cli_color_theme']
+
+
+def get_cli_chart_charset() -> toolstr.SampleMode:
+    config = config_read.get_config()
+    return config['cli_chart_charset']
+
```

### Comparing `checkthechain-0.3.0/src/ctc/config/setup_utils/default_data/default_erc20s.py` & `checkthechain-0.3.4/src/ctc/config/setup_utils/default_data/default_erc20s.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,60 +1,64 @@
 from __future__ import annotations
 
 import typing
 
-if typing.TYPE_CHECKING:
-    import toolsql
+import toolsql
 
-from ctc import spec
+from ctc import config
 from ctc import db
+from ctc import spec
 
 
 async def async_intake_default_erc20s(
-    network: spec.NetworkReference = 'mainnet',
+    context: spec.Context = None,
     verbose: bool = True,
-    *,
-    engine: toolsql.SAEngine | None = None,
 ) -> None:
 
-    if network not in ['mainnet', 1]:
+    network = config.get_context_chain_id(context)
+    if network not in ['ethereum', 1]:
         print('No default tokens for network: ' + str(network))
         return
 
     # load data
-    data = load_default_erc20s(network=network)
-
-    # create engine
-    if engine is None:
-        engine = db.create_engine(
-            schema_name='erc20_metadata',
-            network=network,
-        )
-    if engine is None:
-        return
+    data = load_default_erc20s(context=context)
 
     # write to db
-    with engine.begin() as conn:
+    db_config = config.get_context_db_config(
+        schema_name='erc20_metadata',
+        context=context,
+    )
+    async with toolsql.async_connect(db_config) as conn:
         await db.async_upsert_erc20s_metadata(
             erc20s_metadata=data,
             conn=conn,
-            network=network,
+            context=context,
         )
 
     # print summary
     if verbose:
-        print('Added metadata of', len(data), 'default ERC20 tokens to db')
+        import toolstr
+        from ctc import cli
+
+        styles = cli.get_cli_styles()
+        toolstr.print(
+            'Added metadata of',
+            toolstr.add_style(str(len(data)), styles['description'] + ' bold'),
+            'default ERC20 tokens to db',
+        )
 
 
 def load_default_erc20s(
-    network: spec.NetworkReference = 'mainnet',
+    context: spec.Context = None,
 ) -> typing.Sequence[spec.ERC20Metadata]:
 
-    if network == 'mainnet':
-        raw_csv_data = mainnet_erc20s_csv
+    network = config.get_context_chain_id(context)
+
+    if network in ('ethereum', 1):
+        raw_csv_data = etheruem_erc20s_csv
     else:
         raise NotImplementedError(
             'no erc20 defaults provided for network ' + str(network)
         )
 
     erc20_metadatas = []
     lines = raw_csv_data.split('\n')
@@ -69,15 +73,15 @@
         }
         erc20_metadatas.append(erc20_metadata)
 
     return erc20_metadatas
 
 
 # from 1inch default token list
-mainnet_erc20s_csv = """address,decimals,name,symbol
+etheruem_erc20s_csv = """address,decimals,name,symbol
 0x006bea43baa3f7a6f765f14f10a1a1b08334ef45,18,Stox,STX
 0x0327112423f3a68efdf1fcf402f6c5cb9f7c33fd,18,PieDAOBTC++,BTC
 0x0417912b3a7af768051765040a55bb0925d4ddcf,18,LiquidityDividendsProtocol,LID
 0x04fa0d235c4abf4bcf4787af4cf447de572ef828,18,UMAVotingTokenv1,UMA
 0x07597255910a51509ca469568b048f2597e72504,18,Uptrennd,1UP
 0x08d967bb0134f2d07f7cfb6e246680c53927dd30,18,MATHToken,MATH
 0x0a913bead80f321e7ac35285ee10d9d922659cb7,18,DOSNetworkToken,DOS
@@ -1184,15 +1188,15 @@
 0x8037b1b69d6fa63a9cc053c25f7e168e6e6d857a,18,PartsofFourCoin,P4C
 0xcfeaead4947f0705a14ec42ac3d44129e1ef3ed5,8,Notional,NOTE
 0x41a3dba3d677e573636ba691a70ff2d606c29666,18,GoBlankToken,BLANK
 0xc48b4814faed1ccc885dd6fde62a6474aecbb19a,9,CoinMerge,CMERGE
 0x8254e26e453eb5abd29b3c37ac9e8da32e5d3299,18,RBX,RBX"""
 
 
-mainnet_erc20s = """address,decimals,name,symbol
+ethereum_erc20s = """address,decimals,name,symbol
 0x006bea43baa3f7a6f765f14f10a1a1b08334ef45,18,Stox,STX
 0x0327112423f3a68efdf1fcf402f6c5cb9f7c33fd,18,PieDAOBTC++,BTC
 0x0417912b3a7af768051765040a55bb0925d4ddcf,18,LiquidityDividendsProtocol,LID
 0x04fa0d235c4abf4bcf4787af4cf447de572ef828,18,UMAVotingTokenv1,UMA
 0x07597255910a51509ca469568b048f2597e72504,18,Uptrennd,1UP
 0x08d967bb0134f2d07f7cfb6e246680c53927dd30,18,MATHToken,MATH
 0x0a913bead80f321e7ac35285ee10d9d922659cb7,18,DOSNetworkToken,DOS
```

### Comparing `checkthechain-0.3.0/src/ctc/config/setup_utils/main_setup.py` & `checkthechain-0.3.4/src/ctc/config/setup_utils/main_setup.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,27 +1,29 @@
 from __future__ import annotations
 
 import typing
 
 import toolstr
+import toolcli
 
 import ctc
 from . import setup_io
 from .stages import alias_setup
 from .stages import data_dir_setup
 from .stages import db_setup
 from .stages import network_setup
+from .stages import cli_setup
 
 
-styles = {
-    'header': '#ce93f9 bold',
-    'path': '#b9f29f bold',
-    'question': '#8be9fd',
-    'quote': '#f1fa8c',
-    'command': '#64aaaa',
+styles: toolcli.StyleTheme = {
+    'title': '#ce93f9 bold',
+    'description': '#b9f29f bold',
+    'metavar': '#8be9fd',
+    'content': '#f1fa8c',
+    'option': '#64aaaa',
     'comment': '#6272a4',
 }
 
 
 async def async_setup_ctc(
     *,
     headless: bool = False,
@@ -33,21 +35,22 @@
     disable_logs: bool = False,
     skip_db: bool = False,
     overwrite: bool = True,
     skip_aliases: bool = False,
 ) -> None:
 
     # print intro
-    toolstr.print('# Setting up ctc...', style=styles['header'])
-    # toolstr.print_text_box('Setting up ctc', style=styles['header'])
+    toolstr.print('# Setting up ctc...', style=styles['title'])
     print()
     toolstr.print(
         'Running setup process for ctc '
-        + toolstr.add_style(ctc.__version__, styles['path'] + ' bold')
+        + toolstr.add_style(ctc.__version__, styles['description'] + ' bold')
     )
+    if not ctc.__version__.split('.')[-1].isnumeric():
+        print('(this is not a stable release, use pypi for stable releases)')
     print()
     print('Each step is optional')
     print('- by default, setup process will leave existing settings unchanged')
     print('- setup can be rerun multiple times idempotently')
     print()
     toolstr.print(
         'Can skip options by pressing enter at each prompt', style='bold'
@@ -72,34 +75,42 @@
     data_dir_data = data_dir_setup.setup_data_dir(
         old_config=old_config,
         styles=styles,
         headless=headless,
         default_data_dir=data_dir,
         disable_logs=disable_logs,
     )
+    cli_data = cli_setup.setup_cli(
+        old_config=old_config,
+        styles=styles,
+        headless=headless,
+    )
     if not skip_db:
         db_data = db_setup.setup_dbs(
             data_dir=data_dir_data['data_dir'],
             network_data=network_data,
             styles=styles,
+            headless=headless,
+            old_db_configs=old_config.get('db_configs'),
         )
     else:
         from ctc.config import config_defaults
 
         db_data = {
             'db_configs': config_defaults.get_default_db_configs(
-                data_dir_data['data_dir']
+                data_dir=data_dir_data['data_dir']
             ),
         }
 
     # create new config file if need be
     setup_io.write_new_config(
         network_data=network_data,
         db_data=db_data,
         data_dir_data=data_dir_data,
+        cli_data=cli_data,
         styles=styles,
         headless=headless,
         overwrite=overwrite,
     )
 
     # populate db
     if not skip_db:
@@ -114,10 +125,10 @@
         headless=headless,
         skip_aliases=skip_aliases,
     )
 
     # finalize
     print()
     print()
-    toolstr.print('## Final Steps', style=styles['header'])
+    toolstr.print('## Final Steps', style=styles['title'])
     print()
     print('ctc setup complete')
```

### Comparing `checkthechain-0.3.0/src/ctc/config/setup_utils/stages/alias_setup.py` & `checkthechain-0.3.4/src/ctc/config/setup_utils/stages/alias_setup.py`

 * *Files 3% similar despite different names*

```diff
@@ -5,20 +5,23 @@
 import toolcli
 import toolstr
 
 from ctc.cli.cli_utils import cli_alias_utils
 
 
 def add_cli_aliases(
-    *, styles: typing.Mapping[str, str], headless: bool, skip_aliases: bool
+    *,
+    styles: toolcli.StyleTheme,
+    headless: bool,
+    skip_aliases: bool,
 ) -> None:
 
     print()
     print()
-    toolstr.print('## Installing CLI Aliases', style=styles['header'])
+    toolstr.print('## Installing CLI Aliases', style=styles['title'])
 
     alias_status = cli_alias_utils.get_paths_alias_status()
     current = all(status == 'current' for status in alias_status.values())
 
     if current:
         print()
         cli_alias_utils.print_alias_status(include_title=False)
@@ -28,31 +31,31 @@
         print()
         print(
             'ctc can install cli aliases to make many commands quicker to type'
         )
         print()
         toolstr.print(
             'For example, you can type '
-            + toolstr.add_style('4byte 0xa9059cbb', styles['command'])
+            + toolstr.add_style('4byte 0xa9059cbb', styles['option'])
             + ' instead of '
-            + toolstr.add_style('ctc 4byte 0xa9059cbb', styles['command'])
+            + toolstr.add_style('ctc 4byte 0xa9059cbb', styles['option'])
         )
         print()
         print('ctc has aliases prepared for the following commands:')
         print()
         cli_alias_utils.print_aliases()
         print()
 
         if skip_aliases:
             default = 'no'
         else:
             default = 'yes'
 
         if toolcli.input_yes_or_no(
             'Do you want to install these aliases? ',
-            style=styles['question'],
+            style=styles['metavar'],
             default=default,
             headless=headless,
         ):
             cli_alias_utils.install_aliases(confirm=True, headless=headless)
             print()
             print('Aliases installed')
```

### Comparing `checkthechain-0.3.0/src/ctc/config/setup_utils/stages/data_dir_setup.py` & `checkthechain-0.3.4/src/ctc/config/setup_utils/stages/data_dir_setup.py`

 * *Files 10% similar despite different names*

```diff
@@ -3,55 +3,57 @@
 import os
 import shutil
 import typing
 
 import toolcli
 import toolstr
 
+import ctc
 from ctc import spec
+from ... import upgrade_utils
 from ...upgrade_utils import data_dir_versioning
 from ... import config_defaults
 
 
 def setup_data_dir(
     *,
-    styles: dict[str, str],
+    styles: toolcli.StyleTheme,
     old_config: typing.Mapping[typing.Any, typing.Any],
     headless: bool,
     default_data_dir: str | None,
     disable_logs: bool,
 ) -> spec.PartialConfig:
 
     print()
     print()
-    toolstr.print('## Data Root Directory', style=styles['header'])
+    toolstr.print('## Data Root Directory', style=styles['title'])
     print()
 
     new_data_root = None
 
     # decide whether to use old data root
     old_data_root: str | None = old_config.get('data_dir')
     if old_data_root is not None and not isinstance(old_data_root, str):
         old_data_root = None
     if isinstance(old_data_root, str):
         old_data_root = os.path.abspath(os.path.expanduser(old_data_root))
         if os.path.isdir(old_data_root):
             prompt = (
                 'Continue using data directory ['
-                + styles['path']
+                + styles['description']
                 + ']'
                 + str(old_data_root)
                 + '[/'
-                + styles['path']
+                + styles['description']
                 + ']? '
             )
             if toolcli.input_yes_or_no(
                 prompt,
                 default='yes',
-                style=styles['question'],
+                style=styles['metavar'],
                 headless=headless,
             ):
                 new_data_root = old_data_root
             else:
                 print(
                     'OK. You can specify whether to keep this old data'
                     ' after a new directory is chosen'
@@ -63,44 +65,47 @@
             default_data_dir = config_defaults.get_default_data_dir()
         new_data_root = toolcli.input_directory_path(
             prompt='Where should ctc store data? (specify a directory path) ',
             default=default_data_dir,
             require_absolute=True,
             must_already_exist=False,
             create_directory=False,
-            style=styles['question'],
+            style=styles['metavar'],
             headless=headless,
         )
 
         # move old data
         if isinstance(old_data_root, str) and os.path.isdir(old_data_root):
             prompt = 'Move old ctc data to this new location? '
             answer = toolcli.input_yes_or_no(
                 prompt,
                 default='yes',
                 headless=headless,
-                style=styles['question'],
+                style=styles['metavar'],
             )
             if answer:
                 if not os.path.isdir(new_data_root):
                     shutil.move(old_data_root, new_data_root)
 
     # create files and subdirectories and upgrade if need be
-    data_dir_versioning.initialize_data_subdirs(new_data_root, version='0.3.0')
+    data_dir_versioning.initialize_data_subdirs(
+        new_data_root,
+        version=upgrade_utils.get_stable_version(ctc.__version__),
+    )
 
     print()
     prompt = 'Do you want to disable ctc logging? '
     if disable_logs:
         default = 'yes'
     else:
         default = 'no'
     disable_logs = toolcli.input_yes_or_no(
         prompt,
         default=default,
-        style=styles['question'],
+        style=styles['metavar'],
         headless=headless,
     )
 
     return {
         'data_dir': new_data_root,
         'log_rpc_calls': not disable_logs,
         'log_sql_queries': not disable_logs,
```

### Comparing `checkthechain-0.3.0/src/ctc/config/setup_utils/stages/db_setup.py` & `checkthechain-0.3.4/src/ctc/protocols/ens_utils/cli/ens_command.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,150 +1,152 @@
 from __future__ import annotations
 
-import os
+import asyncio
 import typing
 
-import aiohttp
+import toolcli
 import toolstr
-import toolsql
+import tooltime
 
-from ctc import db
+from ctc import cli
+from ctc import evm
 from ctc import spec
-from ... import config_defaults
 
+from ctc.protocols import ens_utils
 
-def setup_dbs(
-    *,
-    styles: typing.Mapping[str, str],
-    data_dir: str,
-    network_data: spec.PartialConfig,
-    db_config: toolsql.DBConfig | None = None,
-) -> spec.PartialConfig:
-
-    print()
-    print()
-    toolstr.print('## Database Setup', style=styles['header'])
-    print()
-    print('ctc stores its collected chain data in an sql database')
-
-    db_configs = config_defaults.get_default_db_configs(data_dir)
-
-    # create db
-    print()
-    for db_config in db_configs.values():
-        if 'path' in db_config:
-            db_path = db_config['path']
-            db_dirpath = os.path.dirname(db_path)
-            os.makedirs(db_dirpath, exist_ok=True)
-
-        if not os.path.isfile(db_path):
-            toolstr.print(
-                'Creating database at path ['
-                + styles['path']
-                + ']'
-                + db_path
-                + '[/'
-                + styles['path']
-                + ']'
-            )
-        else:
-            toolstr.print(
-                'Existing database detected at path ['
-                + styles['path']
-                + ']'
-                + db_path
-                + '[/'
-                + styles['path']
-                + ']'
-            )
-
-    print()
-    _delete_incomplete_chainlink_schemas()
+if typing.TYPE_CHECKING:
+    from typing_extensions import TypedDict
 
-    # create tables
-    used_networks: set[spec.NetworkReference] = set()
-    default_network = network_data.get('default_network')
-    if default_network is not None:
-        used_networks.add(default_network)
-    for provider in network_data['providers'].values():
-        network = provider.get('network')
-        if network is not None:
-            used_networks.add(network)
-    used_networks = {
-        network for network in used_networks if network is not None
+    class ENSResult(TypedDict):
+        address: spec.Address | None
+        name: str | None
+        owner: str | None
+        expiration: int | None
+        resolver: str | None
+
+
+def get_command_spec() -> toolcli.CommandSpec:
+    return {
+        'f': async_ens_command,
+        'help': 'summarize ENS entry',
+        'args': [
+            {
+                'name': 'name_or_address',
+                'nargs': '+',
+                'help': 'ENS name(s) or address(es)',
+            },
+            {'name': '--block', 'help': 'block number'},
+            {
+                'name': ['--verbose', '-v'],
+                'help': 'display additional information',
+                'action': 'store_true',
+            },
+        ],
+        'examples': [
+            '0xd8da6bf26964af9d7eed9e03e53415d37aa96045',
+            'vitalik.eth',
+            'vitalik.eth --verbose',
+        ],
     }
-    print()
-    db.create_missing_tables(
-        networks=list(used_networks),
-        db_config=db_configs['main'],
-        confirm=True,
-    )
-
-    return {'db_configs': db_configs}
 
 
-async def async_populate_db_tables(
-    db_config: toolsql.SAEngine,
-    styles: typing.Mapping[str, str],
+async def async_ens_command(
+    *,
+    name_or_address: str,
+    block: spec.BlockNumberReference,
+    verbose: bool,
 ) -> None:
-    from ctc.protocols.chainlink_utils import chainlink_db
-    from ..default_data import default_erc20s
+    if block is not None:
+        block = evm.standardize_block_number(block)
 
-    engine = toolsql.create_engine(db_config=db_config)
+    coroutines = [
+        async_process_ens_arg(arg=arg, block=block) for arg in name_or_address
+    ]
+    results = await asyncio.gather(*coroutines)
+
+    for r, result in enumerate(results):
+        if r > 0:
+            print()
+
+        if result['name'] is None:
+            toolstr.print_text_box(result['address'])
+            print('[no ENS records]')
+            continue
+        elif result['address'] is None and result['owner'] is None:
+            toolstr.print_text_box(result['name'])
+            print('[no ENS records]')
+            raise Exception()
+            continue
+
+        styles = cli.get_cli_styles()
+        toolstr.print_text_box(result['name'], style=styles['title'])
+        cli.print_bullet(key='address', value=result['address'])
+        cli.print_bullet(key='owner', value=result['owner'])
+        cli.print_bullet(key='resolver', value=result['resolver'])
+        cli.print_bullet(
+            key='namehash', value=ens_utils.hash_name(result['name'])
+        )
+        # print('- registered:', )
+        cli.print_bullet(
+            key='expiration',
+            value=tooltime.timestamp_to_iso(result['expiration']).replace(
+                'T', ' '
+            ),
+        )
 
-    print()
-    print()
-    toolstr.print('## Populating Database', style=styles['header'])
-
-    # populate data: erc20s
-    print()
-    print('Populating database with metadata of common ERC20 tokens...')
-    print()
-    await default_erc20s.async_intake_default_erc20s(
-        network='mainnet',
-        engine=engine,
+        if verbose:
+            text_records = await ens_utils.async_get_text_records(
+                name=result['name']
+            )
+            if len(text_records) > 0:
+                print()
+                print()
+                toolstr.print_header('Text Records', style=styles['title'])
+                for key, value in sorted(text_records.items()):
+                    cli.print_bullet(key=key, value=value)
+            else:
+                cli.print_bullet(value='no text records')
+
+
+async def async_process_ens_arg(
+    arg: str, block: spec.BlockNumberReference
+) -> ENSResult:
+    if '.' in arg:
+        name = arg
+        address = None
+        address_coroutine = ens_utils.async_resolve_name(name, block=block)
+    elif evm.is_address_str(arg):
+        address = arg
+        name = await ens_utils.async_reverse_lookup(address, block=block)
+    else:
+        raise Exception('could not parse inputs')
+
+    if name == '':
+        return {
+            'address': address,
+            'name': None,
+            'owner': None,
+            'expiration': None,
+            'resolver': None,
+        }
+
+    owner_coroutine = ens_utils.async_get_owner(name=name)
+    expiration_coroutine = ens_utils.async_get_expiration(name=name)
+    resolver_coroutine = ens_utils.async_get_resolver(name=name)
+
+    owner, expiration, resolver = await asyncio.gather(
+        owner_coroutine,
+        expiration_coroutine,
+        resolver_coroutine,
     )
 
-    # populate data: chainlink
-    print()
-    print('Populating database with latest Chainlink oracle feeds...')
-    print()
-    try:
-        await chainlink_db.async_import_networks_to_db()
-    except aiohttp.client_exceptions.ClientConnectorError:
-        print('Could not connect to Chainlink server, skipping')
-    except Exception:
-        print('Could not add feeds to db, skipping')
-
-
-def _delete_incomplete_chainlink_schemas() -> None:
-    """detect any tables missing in chainlink schema
-
-    this is a stopgap until a more comprehensive migration system is in place
-    """
-
-    from ctc import config
-    from ctc import db
-    from ctc import evm
-
-    # looking for schemas that have already been created, but are missing tables
-    metadata = toolsql.create_metadata_object_from_db(
-        db_config=config.get_db_config()
-    )
-    if 'schema_versions' not in metadata.tables.keys():
-        return
-    for network in evm.get_networks():
-        schema_version = db.get_schema_version(
-            schema_name='chainlink', network=network
-        )
-        if schema_version is not None:
-            schema = db.get_prepared_schema(
-                schema_name='chainlink', network=network
-            )
-            for table_name in schema['tables'].keys():
-                if table_name not in metadata.tables.keys():
-                    print(
-                        'missing chainlink_aggregator_updates table, rebuilding schema'
-                    )
-                    db.drop_schema(
-                        schema_name='chainlink', network=network, confirm=True
-                    )
+    if address is None:
+        address = await address_coroutine
+
+    return {
+        'address': address,
+        'name': name,
+        'owner': owner,
+        'expiration': expiration,
+        'resolver': resolver,
+    }
+
```

### Comparing `checkthechain-0.3.0/src/ctc/config/setup_utils/stages/network_setup.py` & `checkthechain-0.3.4/src/ctc/config/setup_utils/stages/network_setup.py`

 * *Files 6% similar despite different names*

```diff
@@ -15,42 +15,49 @@
 async def async_setup_networks(
     *,
     old_config: typing.Mapping[typing.Any, typing.Any],
     headless: bool,
     rpc_url: str | None,
     rpc_chain_id: int | None,
     skip_networking: bool = False,
-    styles: typing.Mapping[str, str],
+    styles: toolcli.StyleTheme,
 ) -> spec.PartialConfig:
 
     if skip_networking:
         providers = old_config.get('providers')
         if providers is None:
             providers = {}
 
         networks = old_config.get('networks')
         if networks is None:
             networks = config_defaults.get_default_networks_metadata()
 
         default_network = old_config.get('default_network')
+        if not isinstance(default_network, int):
+            default_network = None
 
         default_providers = old_config.get('default_providers')
         if default_providers is None:
             default_providers = {}
 
+        if default_network is None:
+            if len(default_providers) > 0:
+                default_network = min(default_providers.keys())
+            else:
+                default_network = 1
         return {
             'providers': providers,
             'networks': networks,
             'default_network': default_network,
             'default_providers': default_providers,
         }
 
     print()
     print()
-    toolstr.print('## Network Setup', style=styles['header'])
+    toolstr.print('## Network Setup', style=styles['title'])
     print()
 
     # get providers
     providers, networks = await async_specify_providers(
         old_config=old_config,
         styles=styles,
         headless=headless,
@@ -76,14 +83,15 @@
 
     # get default providers
     default_providers = specify_default_providers(
         providers=providers,
         networks=networks,
         styles=styles,
         headless=headless,
+        old_config=old_config,
     )
 
     print()
     print('Network setup complete')
 
     # return results
     data: spec.PartialConfig = {
@@ -97,15 +105,15 @@
 
 async def async_specify_providers(
     *,
     old_config: typing.Mapping[str, typing.Any],
     headless: bool,
     rpc_url: str | None,
     rpc_chain_id: int | None,
-    styles: typing.Mapping[str, str],
+    styles: toolcli.StyleTheme,
 ) -> tuple[
     typing.Mapping[str, spec.Provider],
     typing.MutableMapping[spec.ChainId, spec.NetworkMetadata],
 ]:
 
     providers: typing.MutableMapping[str, spec.Provider] = {}
     networks: typing.MutableMapping[spec.ChainId, spec.NetworkMetadata] = dict(
@@ -117,25 +125,25 @@
     if len(old_providers) > 0:
         print('Currently using these providers:')
         for provider_name, provider_metadata in old_providers.items():
             toolstr.print(
                 '-',
                 provider_name,
                 '['
-                + styles['path']
+                + styles['description']
                 + ']'
                 + provider_metadata['url']
                 + '[/'
-                + styles['path']
+                + styles['description']
                 + ']',
             )
         print()
         answer = toolcli.input_yes_or_no(
             'Would you like to continue using these providers? ',
-            style=styles['question'],
+            style=styles['metavar'],
             default='yes',
             headless=headless,
         )
         if answer:
             # TODO: validate old_providers
             providers.update(old_providers)
 
@@ -151,15 +159,15 @@
     elif len(providers) == 0:
         print()
         print('Most ctc operations require an RPC provider')
         print()
         prompt = 'Would you like to specify an RPC provider? '
         if toolcli.input_yes_or_no(
             prompt=prompt,
-            style=styles['question'],
+            style=styles['metavar'],
             default='yes',
             headless=headless,
         ):
             await async_collect_provider_metadata(
                 providers=providers,
                 networks=networks,
                 styles=styles,
@@ -168,15 +176,15 @@
                 chain_id=None,
             )
 
     # collect additional providers
     if len(providers) > 0:
         answer = toolcli.input_yes_or_no(
             prompt='Would you like to specify additional RPC providers? ',
-            style=styles['question'],
+            style=styles['metavar'],
             default='no',
             headless=headless,
         )
         while answer:
 
             # collect provider
             await async_collect_provider_metadata(
@@ -187,27 +195,27 @@
                 url=None,
                 chain_id=None,
             )
 
             # prompt for additional providers
             answer = toolcli.input_yes_or_no(
                 prompt='Would you like to specify additional RPC providers? ',
-                style=styles['question'],
+                style=styles['metavar'],
                 default='no',
                 headless=False,
             )
 
     return providers, networks
 
 
 async def async_collect_provider_metadata(
     *,
     providers: typing.MutableMapping[str, spec.Provider],
     networks: typing.MutableMapping[spec.ChainId, spec.NetworkMetadata],
-    styles: typing.Mapping[str, str],
+    styles: toolcli.StyleTheme,
     headless: bool,
     url: str | None,
     chain_id: int | None,
 ) -> None:
     """collect metadata for a provider"""
 
     print()
@@ -221,29 +229,31 @@
         if headless and default_url is None:
             raise Exception(
                 'if using headless mode, must either specify --rpc-url or set the ETH_RPC_URL env var'
             )
 
         url = toolcli.input_prompt(
             'What is the RPC provider URL? ',
-            style=styles['question'],
+            style=styles['metavar'],
             allow_blank=False,
             default=default_url,
             headless=headless,
         )
     else:
         print('Adding RPC provider: ' + str(url))
 
     if url.startswith('ws://'):
         # TODO: take new input instead of raising exception
         raise NotImplementedError('websockets not supported')
-    elif not url.startswith('https://') and not url.startswith('http://'):
-        print()
-        print('No prefix for url. Adding `https://`')
-        url = 'https://' + url
+    if not (url.startswith('http://') or url.startswith('https://')):
+        check_provider = rpc.resolve_provider(url)
+        if check_provider['url'] != url:
+            print()
+            print('added prefix to url: ' + str(check_provider['url']))
+            url = check_provider['url']
 
     if (
         chain_id is None
         and url == os.environ.get('ETH_RPC_URL')
         and os.environ.get('ETH_RPC_CHAIN_ID') not in [None, '']
     ):
         try:
@@ -252,45 +262,34 @@
                 'could not use value of ETH_RPC_CHAIN_ID, not a valid integer'
             )
         except Exception:
             pass
 
     if chain_id is None:
         try:
-            temporary_provider: spec.Provider = {
-                'name': None,
-                'network': -2,
-                'protocol': 'http',
-                'session_kwargs': {},
-                'chunk_size': None,
-                'url': url,
-                'convert_reverts_to_none': False,
-            }
             try:
-                chain_id = await rpc.async_eth_chain_id(
-                    provider=temporary_provider
-                )
+                chain_id = rpc.rpc_provider._sync_get_chain_id(url)
             except Exception:
                 chain_id = toolcli.input_int(
                     'Could not connect to RPC provider. What is this provider\'s chain_id? ',
-                    style=styles['question'],
+                    style=styles['metavar'],
                     headless=False,
                 )
             description = 'chain_id = ' + str(chain_id)
             if chain_id in networks:
                 name = networks[chain_id]['name']
                 if name is not None:
                     description = description + ', network = ' + name
             print('Provider using: ' + description)
         except Exception as e:
             raise e
             print('Could not query node for chain_id metadata')
             chain_id = toolcli.input_int(
                 'What is the chain_id used by this node? ',
-                style=styles['question'],
+                style=styles['metavar'],
                 headless=False,
             )
 
     # determine whether chain_id is of known network
     known_network = any(
         chain_id == network.get('chain_id') for network in networks.values()
     )
@@ -306,34 +305,38 @@
             networks=networks,
             styles=styles,
         )
 
     name = toolcli.input_prompt(
         prompt='What should this node be called? ',
         default=create_default_provider_name(url=url, network=chain_id),
-        style=styles['question'],
+        style=styles['metavar'],
         headless=headless,
     )
     if url.startswith('http'):
         protocol: typing.Literal['http'] = 'http'
     else:
         raise Exception('unknown protocol, missing http(s) in url?')
     provider: spec.Provider = {
         'name': name,
         'url': url,
         'network': chain_id,
         'protocol': protocol,
         'session_kwargs': {},
         'chunk_size': None,
         'convert_reverts_to_none': False,
+        'disable_batch_requests': False,
     }
     providers[name] = provider
 
 
 def create_default_provider_name(url: str, network: int) -> str:
+    if all(c.isnumeric() or c in ['.', ':'] for c in url.split('://')[1]):
+        return url.split('://')[1].split('/')[0] + '__' + str(network)
+
     hostname = urllib.parse.urlparse(url).hostname
     if hostname is not None:
         hostname_pieces = hostname.split('.')
         if len(hostname_pieces) == 1:
             hostname_piece = hostname_pieces[0]
         else:
             hostname_piece = hostname_pieces[-2]
@@ -341,49 +344,49 @@
         hostname_piece = url
 
     return hostname_piece + '__' + str(network)
 
 
 def collect_network_metadata(
     *,
-    styles: typing.Mapping[str, str],
+    styles: toolcli.StyleTheme,
     networks: typing.MutableMapping[spec.ChainId, spec.NetworkMetadata],
     name: str | None = None,
     chain_id: int | None = None,
 ) -> None:
     """collect metadata for a network"""
 
     if chain_id is None:
         chain_id = toolcli.input_int(
             'What is the network\'s chain_id? (enter a blank line to go back)\n',
-            style=styles['question'],
+            style=styles['metavar'],
         )
         # CHECK that chain_id is not already taken
     if name is None:
         name = toolcli.input_prompt(
             'What is the network\'s name? (enter a blank line to go back)\n',
-            style=styles['question'],
+            style=styles['metavar'],
         )
         # CHECK that name is not already taken
 
     block_explorer = toolcli.input_prompt(
-        'Network block explorer? ', style=styles['question']
+        'Network block explorer? ', style=styles['metavar']
     )
     network_metadata: spec.NetworkMetadata = {
         'name': name,
         'chain_id': chain_id,
         'block_explorer': block_explorer,
     }
     networks[chain_id] = network_metadata
 
 
 def specify_networks(
     *,
     networks: typing.MutableMapping[spec.ChainId, spec.NetworkMetadata],
-    styles: typing.Mapping[str, str],
+    styles: toolcli.StyleTheme,
     headless: bool,
 ) -> typing.MutableMapping[spec.ChainId, spec.NetworkMetadata]:
 
     # print current networks
     print()
     print('Have metadata for the following networks:')
     print()
@@ -391,26 +394,26 @@
         [networks[chain_id]['name'], chain_id]
         for chain_id in sorted(networks.keys())
     ]
     toolstr.print_table(
         rows,
         labels=['name', 'chain_id'],
         border=styles['comment'],
-        label_style=styles['header'],
+        label_style=styles['title'],
         column_styles={
-            'name': styles['question'],
-            'chain_id': styles['path'],
+            'name': styles['metavar'],
+            'chain_id': styles['description'],
         },
         add_row_index=True,
     )
 
     # add new networks
     while toolcli.input_yes_or_no(
         '\nWould you like to add metadata for additional networks? ',
-        style=styles['question'],
+        style=styles['metavar'],
         default='no',
         headless=headless,
     ):
         collect_network_metadata(
             styles=styles,
             networks=networks,
         )
@@ -421,15 +424,15 @@
     return networks
 
 
 def specify_default_network(
     *,
     networks: typing.Mapping[spec.ChainId, spec.NetworkMetadata],
     providers: typing.Mapping[str, spec.Provider],
-    styles: typing.Mapping[str, str],
+    styles: toolcli.StyleTheme,
     headless: bool,
     rpc_url: str | None,
 ) -> spec.ChainId:
 
     # set default network
     choices_set = [
         str(network['name']) + ' (chain_id = ' + str(network['chain_id']) + ')'
@@ -442,15 +445,15 @@
         providers = {
             provider_name: provider
             for provider_name, provider in providers.items()
             if provider['url'] == rpc_url
         }
 
     # determine default choice
-    default: str | None = None
+    default = 'ethereum (chain_id = 1)'
     if len(providers) == 1:
         provider = list(providers.values())[0]
         network = provider.get('network')
         for network_metadata in networks.values():
             if (
                 isinstance(network, int)
                 and network == network_metadata['chain_id']
@@ -462,37 +465,38 @@
                     + ' (chain_id = '
                     + str(network_metadata['chain_id'])
                     + ')'
                 )
                 break
     elif len(providers) > 1:
         for provider in providers.values():
-            if provider.get('network') in [1, 'mainnet']:
-                default = 'mainnet (chain_id = 1)'
+            if provider.get('network') in [1, 'ethereum']:
+                default = 'ethereum (chain_id = 1)'
 
     print()
     default_network_index = toolcli.input_number_choice(
         prompt='Which network to use as default?',
         choices=choices,
         default=default,
-        style=styles['question'],
+        style=styles['metavar'],
         headless=headless,
     )
 
     # clean this horrorshow up
     return int(choices[default_network_index].split(' ')[-1].strip(')'))
 
 
 def specify_default_providers(
     *,
     networks: typing.Mapping[spec.ChainId, spec.NetworkMetadata],
     providers: typing.Mapping[str, spec.Provider],
-    styles: typing.Mapping[str, str],
+    styles: toolcli.StyleTheme,
     headless: bool,
-) -> typing.Mapping[spec.ChainId, spec.ProviderName]:
+    old_config: typing.Mapping[typing.Any, typing.Any],
+) -> typing.Mapping[spec.ChainId, str]:
 
     # compile providers for each network
     providers_per_network: dict[int, list[str]] = {}
     for provider_name, provider_metadata in providers.items():
         network = provider_metadata['network']
         if network is None:
             raise Exception(
@@ -516,20 +520,32 @@
         n_providers = len(providers_per_network[network])
         if n_providers == 1:
             default_providers[network] = providers_per_network[network][0]
         elif n_providers > 1:
             prompt = (
                 'Which provider to use as default for '
                 + str(networks[network]['name'])
-                + ' (chain_id = '
+                + ', chain_id = '
                 + str(network)
-                + ')?'
+                + '?'
             )
+
+            default_choice = old_config.get('default_providers', {}).get(
+                str(network)
+            )
+            if (
+                default_choice is None
+                or default_choice not in providers_per_network[network]
+            ):
+                default_choice = providers_per_network[network][0]
+
             answer = toolcli.input_number_choice(
                 prompt=prompt,
                 choices=providers_per_network[network],
-                style=styles['question'],
+                style=styles['metavar'],
                 headless=headless,
+                default=default_choice,
             )
             default_providers[network] = providers_per_network[network][answer]
 
     return default_providers
+
```

### Comparing `checkthechain-0.3.0/src/ctc/config/upgrade_utils/data_dir_versioning.py` & `checkthechain-0.3.4/src/ctc/config/upgrade_utils/data_dir_versioning.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,186 +1,216 @@
 from __future__ import annotations
 
 import os
-import shutil
 import typing
-from typing_extensions import TypedDict, Literal
 
-import toolcli
-
-from ctc import config
+if typing.TYPE_CHECKING:
 
+    from typing_extensions import TypedDict
 
-if typing.TYPE_CHECKING:
+    DirectoryTree = typing.Mapping[str, typing.Mapping[str, typing.Any]]
 
     class DataDirSpec(TypedDict, total=False):
-        # for now, only specifieds entries in root data dir
-        files: list[str]  # list of expected file paths
-        directories: list[str]  # list of expected directory paths
-        directory_subdirs: typing.Mapping[
-            str, typing.Sequence[str]
-        ]  # list of items in each directory
-        move_items: typing.Mapping[str, str]
+        files: typing.Sequence[str]
+        directory_tree: DirectoryTree
 
-    DataSpecVersion = Literal['0.2.0', '0.3.0']
+        # # for now, only specifies entries in root data dir
+        # files: list[str]  # list of expected file paths
+        # directories: list[str]  # list of expected directory paths
+        # directory_subdirs: typing.Mapping[
+        #     str, typing.Sequence[str]
+        # ]  # list of items in each directory
+        # move_items: typing.Mapping[str, str]
 
+    DataSpecVersion = str
 
-data_spec_order: list[DataSpecVersion] = [
+
+data_spec_order = [
     '0.2.0',
     '0.3.0',
+    '0.3.1',
+    '0.3.2',
+    '0.3.3',
+    '0.3.4',
 ]
 
+_0_3_0_spec: DataDirSpec = {
+    'directory_tree': {
+        'dbs': {},
+        'logs': {'rpc': {}, 'db': {}},
+        'evm': {},
+    },
+    'files': [
+        './directory_version',
+    ],
+}
+
 data_dir_specs: typing.Mapping[DataSpecVersion, DataDirSpec] = {
     '0.2.0': {
         'files': [],
-        'directories': [],
-    },
-    '0.3.0': {
-        'files': [
-            'directory_version',
-        ],
-        'directories': [
-            'dbs',
-            'logs',
-            'evm',
-        ],
-        'directory_subdirs': {
-            'logs': ['rpc', 'db'],
-        },
-        'move_items': {
-            'mainnet/events': 'evm/networks/mainnet/events',
-        },
+        'directory_tree': {},
     },
+    '0.3.0': _0_3_0_spec,
+    '0.3.1': _0_3_0_spec,
+    '0.3.2': _0_3_0_spec,
+    '0.3.3': _0_3_0_spec,
+    '0.3.4': _0_3_0_spec,
 }
 
 
-def initialize_data_subdirs(data_dir: str, *, version: DataSpecVersion) -> None:
-    data_dir_spec = data_dir_specs[version]
-
-    for dirname in data_dir_spec.get('directories', []):
-        path = os.path.join(data_dir, dirname)
-        if not os.path.isdir(path):
-            print('creating directory:', path)
-            os.makedirs(path, exist_ok=True)
-
-    for dirname in data_dir_spec.get('directory_subdirs', []):
-        for subdirname in data_dir_spec['directory_subdirs'][dirname]:
-            path = os.path.join(data_dir, dirname, subdirname)
-            if not os.path.isdir(path):
-                print('creating directory:', path)
-                os.makedirs(path, exist_ok=True)
-
-
-def get_data_dir_version(data_dir: str | None = None) -> DataSpecVersion:
-    if data_dir is None:
-        data_dir = config.get_data_dir()
-
-    version_file = os.path.join(data_dir, 'directory_version')
-
-    if not os.path.isfile(version_file):
-        return '0.2.0'
+def initialize_data_subdirs(data_dir: str, *, version: str) -> None:
+    if version in data_spec_order:
+        data_dir_spec = data_dir_specs[version]
     else:
-        with open(version_file, 'r') as f:
-            version = f.read()
-        if version in data_spec_order:
-            return typing.cast(DataSpecVersion, version)
-        else:
-            raise Exception('unknown data_spec_version: ' + str(version))
-
-
-def fully_migrate_data_dir(data_dir: str | None = None) -> None:
-
-    if data_dir is None:
-        data_dir = config.get_data_dir()
-
-    # detect current version
-    current_version = get_data_dir_version()
-    latest_version = data_spec_order[-1]
-    if current_version == latest_version:
-        print('data_dir already fully migrated')
-        return
-
-    # gather all migrate functions
-    migrate_functions = {
-        '0.3.0': migrate_data_dir__0_2_0__to__0_3_0,
-    }
-
-    # perform each upgrade function sequentially
-    index = data_spec_order.index(current_version)
-    steps = data_spec_order[index + 1 :]
-    for step in steps:
-        migrate_functions[step](data_dir=data_dir)
-
-
-def migrate_data_dir__0_2_0__to__0_3_0(
-    data_dir: str,
-    *,
-    delete_old_data: bool = True,
-    confirm_delete: bool = False,
-) -> None:
-
-    data_dir_spec = data_dir_specs['0.3.0']
-
-    # create version file
-    version_file = os.path.join(data_dir, 'directory_version')
-    print('creating new version indicator file:', version_file)
-    with open(version_file, 'w') as f:
-        f.write('0.3.0')
-
-    # create new directories
-    for relpath in data_dir_spec['directories']:
-        dirpath = os.path.join(data_dir, relpath)
-        print('creating directory:', dirpath)
-        os.makedirs(dirpath, exist_ok=True)
-
-    # migrate data (the only old data that is migrated is events)
-    print()
-    for old_item, new_item in data_dir_spec['move_items'].items():
-        old_path = os.path.join(data_dir, old_item)
-        new_path = os.path.join(data_dir, new_item)
-        if os.path.exists(old_path):
-            print('moving', old_item, 'to', new_item)
-            new_parent = os.path.dirname(new_path)
-            os.makedirs(new_parent, exist_ok=True)
-            shutil.move(old_path, new_path)
-
-    # delete old files
-    if delete_old_data:
-        to_delete = []
-        for item in os.listdir(data_dir):
-            if (
-                item not in data_dir_spec['directories']
-                and item not in data_dir_spec['files']
-            ):
-                to_delete.append(item)
-            elif (
-                item in data_dir_spec['directories']
-                and item in data_dir_spec['directory_subdirs']
-            ):
-                directory_subdirs = data_dir_spec['directory_subdirs'][item]
-                for subitem in os.listdir(os.path.join(data_dir, item)):
-                    if subitem not in directory_subdirs:
-                        to_delete.append(os.path.join(item, subitem))
-        if len(to_delete) > 0:
-            if not confirm_delete:
-                print()
-                print(
-                    'the following files and directories are not used in ctc 0.3.0:'
-                )
-                for item in sorted(to_delete):
-                    print('-', item)
-                print()
-                if not toolcli.input_yes_or_no('delete these items? '):
-                    raise Exception(
-                        'migration unfinished, must delete old files'
-                    )
-
-            for path in to_delete:
-                path = os.path.join(data_dir, path)
-                if os.path.isfile(path) or os.path.islink(path):
-                    os.remove(path)
-                elif os.path.isdir(path):
-                    shutil.rmtree(path)
-                else:
-                    raise Exception('cannot process path: ' + str(path))
+        raise Exception('invalid version: ' + str(version))
+
+    directory_tree = data_dir_spec['directory_tree']
+    tree_paths = _flatten_tree(directory_tree)
+    for tree_path in tree_paths:
+        os.makedirs(os.path.join(data_dir, tree_path), exist_ok=True)
+
+
+def _flatten_tree(directory_tree: DirectoryTree) -> typing.Sequence[str]:
+    """return depth-first flattening of nested dict filesystem tree"""
+    flat = []
+    for dirname, subdirs in directory_tree.items():
+        flat.append(dirname)
+        if len(subdirs) > 0:
+            for subdir in _flatten_tree(subdirs):
+                flat.append(os.path.join(dirname, subdir))
+    return flat
+
+
+# def initialize_data_subdirs(data_dir: str, *, version: DataSpecVersion) -> None:
+#     data_dir_spec = data_dir_specs[version]
+
+#     for dirname in data_dir_spec.get('directories', []):
+#         path = os.path.join(data_dir, dirname)
+#         if not os.path.isdir(path):
+#             print('creating directory:', path)
+#             os.makedirs(path, exist_ok=True)
+
+#     for dirname in data_dir_spec.get('directory_subdirs', []):
+#         for subdirname in data_dir_spec['directory_subdirs'][dirname]:
+#             path = os.path.join(data_dir, dirname, subdirname)
+#             if not os.path.isdir(path):
+#                 print('creating directory:', path)
+#                 os.makedirs(path, exist_ok=True)
+
+
+# def get_data_dir_version(data_dir: str | None = None) -> DataSpecVersion:
+#     if data_dir is None:
+#         data_dir = config.get_data_dir()
+
+#     version_file = os.path.join(data_dir, 'directory_version')
+
+#     if not os.path.isfile(version_file):
+#         return '0.2.0'
+#     else:
+#         with open(version_file, 'r') as f:
+#             version = f.read()
+#         if version in data_spec_order:
+#             return typing.cast(DataSpecVersion, version)
+#         else:
+#             raise Exception('unknown data_spec_version: ' + str(version))
+
+
+# def fully_migrate_data_dir(data_dir: str | None = None) -> None:
+
+#     if data_dir is None:
+#         data_dir = config.get_data_dir()
+
+#     # detect current version
+#     current_version = get_data_dir_version()
+#     latest_version = data_spec_order[-1]
+#     if current_version == latest_version:
+#         print('data_dir already fully migrated')
+#         return
+
+#     # gather all migrate functions, use None if no migration necessary
+#     migrate_functions = {
+#         '0.3.0': migrate_data_dir__0_2_0__to__0_3_0,
+#         '0.3.1': None,
+#     }
+
+#     # perform each upgrade function sequentially
+#     index = data_spec_order.index(current_version)
+#     steps = data_spec_order[index + 1:]
+#     for step in steps:
+#         f = migrate_functions[step]
+#         if f is not None:
+#             f(data_dir=data_dir)
+
+
+# def migrate_data_dir__0_2_0__to__0_3_0(
+#     data_dir: str,
+#     *,
+#     delete_old_data: bool = True,
+#     confirm_delete: bool = False,
+# ) -> None:
+
+#     data_dir_spec = data_dir_specs['0.3.0']
+
+#     # create version file
+#     version_file = os.path.join(data_dir, 'directory_version')
+#     print('creating new version indicator file:', version_file)
+#     with open(version_file, 'w') as f:
+#         f.write('0.3.0')
+
+#     # create new directories
+#     for relpath in data_dir_spec['directories']:
+#         dirpath = os.path.join(data_dir, relpath)
+#         print('creating directory:', dirpath)
+#         os.makedirs(dirpath, exist_ok=True)
+
+#     # migrate data (the only old data that is migrated is events)
+#     print()
+#     for old_item, new_item in data_dir_spec['move_items'].items():
+#         old_path = os.path.join(data_dir, old_item)
+#         new_path = os.path.join(data_dir, new_item)
+#         if os.path.exists(old_path):
+#             print('moving', old_item, 'to', new_item)
+#             new_parent = os.path.dirname(new_path)
+#             os.makedirs(new_parent, exist_ok=True)
+#             shutil.move(old_path, new_path)
+
+#     # delete old files
+#     if delete_old_data:
+#         to_delete = []
+#         for item in os.listdir(data_dir):
+#             if (
+#                 item not in data_dir_spec['directories']
+#                 and item not in data_dir_spec['files']
+#             ):
+#                 to_delete.append(item)
+#             elif (
+#                 item in data_dir_spec['directories']
+#                 and item in data_dir_spec['directory_subdirs']
+#             ):
+#                 directory_subdirs = data_dir_spec['directory_subdirs'][item]
+#                 for subitem in os.listdir(os.path.join(data_dir, item)):
+#                     if subitem not in directory_subdirs:
+#                         to_delete.append(os.path.join(item, subitem))
+#         if len(to_delete) > 0:
+#             if not confirm_delete:
+#                 print()
+#                 print(
+#                     'the following files and directories are not used in ctc 0.3.0:'
+#                 )
+#                 for item in sorted(to_delete):
+#                     print('-', item)
+#                 print()
+#                 if not toolcli.input_yes_or_no('delete these items? '):
+#                     raise Exception(
+#                         'migration unfinished, must delete old files'
+#                     )
+
+#             for path in to_delete:
+#                 path = os.path.join(data_dir, path)
+#                 if os.path.isfile(path) or os.path.islink(path):
+#                     os.remove(path)
+#                 elif os.path.isdir(path):
+#                     shutil.rmtree(path)
+#                 else:
+#                     raise Exception('cannot process path: ' + str(path))
 
-    print('data migration complete, now using the 0.3.0 data schema')
+#     print('data migration complete, now using the 0.3.0 data schema')
```

### Comparing `checkthechain-0.3.0/src/ctc/config/upgrade_utils/legacy_types.py` & `checkthechain-0.3.4/src/ctc/config/upgrade_utils/legacy_types.py`

 * *Files 17% similar despite different names*

```diff
@@ -8,104 +8,94 @@
     - toolsql.DBConfig
 """
 
 from __future__ import annotations
 
 import typing
 
-from typing_extensions import Literal
-from typing_extensions import TypedDict
-
 from ctc import spec
 
+if typing.TYPE_CHECKING:
+    from typing_extensions import Literal
+    from typing_extensions import TypedDict
+
+    class LegacyConfig__3_0_0(TypedDict):
+        config_spec_version: str
+        data_dir: str
+        providers: typing.Mapping[str, LegacyProvider__0_3_0]
+        networks: typing.Mapping[spec.ChainId, LegacyNetworkMetadata__0_3_0]
+        default_network: spec.ChainId | None
+        default_providers: typing.Mapping[spec.ChainId, str]
+        db_configs: typing.Mapping[str, ToolsqlDBConfig]
+        log_rpc_calls: bool
+        log_sql_queries: bool
+
+    class LegacyConfig__0_2_3(TypedDict):
+        config_spec_version: str
+        data_dir: str
+        providers: typing.Mapping[str, LegacyProvider__0_2_1]
+        networks: typing.Mapping[spec.NetworkName, LegacyNetworkMetadata__0_2_1]
+        network_defaults: LegacyConfigNetworkDefaults
+
+    class LegacyConfig__0_2_1(TypedDict):
+        version: str
+        data_dir: str
+        providers: typing.Mapping[str, LegacyProvider__0_2_1]
+        networks: typing.Mapping[spec.NetworkName, LegacyNetworkMetadata__0_2_1]
+        network_defaults: LegacyConfigNetworkDefaults
+
+    class LegacyConfigNetworkDefaults(TypedDict):
+        default_network: spec.NetworkName
+        default_providers: typing.Mapping[spec.NetworkName, str]
+
+    #
+    # # network metadata
+    #
+
+    class LegacyNetworkMetadata__0_3_0(TypedDict):
+        name: str | None
+        chain_id: int
+        block_explorer: str | None
+
+    class LegacyNetworkMetadata__0_2_1(TypedDict):
+        name: str
+        chain_id: int
+        block_explorer: str
+
+    #
+    # # provider
+    #
+
+    class LegacyProvider__0_3_0(TypedDict, total=True):
+        url: str
+        name: typing.Optional[str]
+        network: typing.Optional[str | int]
+        protocol: Literal['http', 'wss', 'ipc']
+        session_kwargs: typing.Optional[typing.Mapping[typing.Any, typing.Any]]
+        chunk_size: typing.Optional[int]
+
+    class LegacyProvider__0_2_1(TypedDict, total=True):
+        url: str
+        name: typing.Optional[str]
+        network: typing.Optional[str]
+        protocol: Literal['http', 'wss', 'ipc']
+        session_kwargs: typing.Optional[typing.Mapping[typing.Any, typing.Any]]
+        chunk_size: typing.Optional[int]
+
+    #
+    # # toolsql
+    #
+
+    class ToolsqlDBConfig(TypedDict, total=False):
+        dbms: Literal['sqlite', 'postgresql']
+        path: str
+        engine: str
+        hostname: str
+        port: int
+        database: str
+        username: str
+        password: str
+        socket: str
+        socket_dir: str
+        timeout: typing.Union[int, float]
+        pool_timeout: typing.Union[int, float]
 
-class LegacyConfig__3_0_0(TypedDict):
-    config_spec_version: str
-    data_dir: str
-    providers: typing.Mapping[spec.ProviderName, LegacyProvider__0_3_0]
-    networks: typing.Mapping[spec.ChainId, LegacyNetworkMetadata__0_3_0]
-    default_network: spec.ChainId | None
-    default_providers: typing.Mapping[spec.ChainId, spec.ProviderName]
-    db_configs: typing.Mapping[str, ToolsqlDBConfig]
-    log_rpc_calls: bool
-    log_sql_queries: bool
-
-
-class LegacyConfig__0_2_3(TypedDict):
-    config_spec_version: str
-    data_dir: str
-    providers: typing.Mapping[spec.ProviderName, LegacyProvider__0_2_1]
-    networks: typing.Mapping[spec.NetworkName, LegacyNetworkMetadata__0_2_1]
-    network_defaults: LegacyConfigNetworkDefaults
-
-
-class LegacyConfig__0_2_1(TypedDict):
-    version: str
-    data_dir: str
-    providers: typing.Mapping[spec.ProviderName, LegacyProvider__0_2_1]
-    networks: typing.Mapping[spec.NetworkName, LegacyNetworkMetadata__0_2_1]
-    network_defaults: LegacyConfigNetworkDefaults
-
-
-class LegacyConfigNetworkDefaults(TypedDict):
-    default_network: spec.NetworkName
-    default_providers: typing.Mapping[spec.NetworkName, spec.ProviderName]
-
-
-#
-# # network metadata
-#
-
-
-class LegacyNetworkMetadata__0_3_0(TypedDict):
-    name: str | None
-    chain_id: int
-    block_explorer: str | None
-
-
-class LegacyNetworkMetadata__0_2_1(TypedDict):
-    name: str
-    chain_id: int
-    block_explorer: str
-
-
-#
-# # provider
-#
-
-
-class LegacyProvider__0_3_0(TypedDict, total=True):
-    url: str
-    name: typing.Optional[str]
-    network: typing.Optional[str | int]
-    protocol: Literal['http', 'wss', 'ipc']
-    session_kwargs: typing.Optional[typing.Mapping[typing.Any, typing.Any]]
-    chunk_size: typing.Optional[int]
-
-
-class LegacyProvider__0_2_1(TypedDict, total=True):
-    url: str
-    name: typing.Optional[str]
-    network: typing.Optional[str]
-    protocol: Literal['http', 'wss', 'ipc']
-    session_kwargs: typing.Optional[typing.Mapping[typing.Any, typing.Any]]
-    chunk_size: typing.Optional[int]
-
-
-#
-# # toolsql
-#
-
-
-class ToolsqlDBConfig(TypedDict, total=False):
-    dbms: Literal['sqlite', 'postgresql']
-    path: str
-    engine: str
-    hostname: str
-    port: int
-    database: str
-    username: str
-    password: str
-    socket: str
-    socket_dir: str
-    timeout: typing.Union[int, float]
-    pool_timeout: typing.Union[int, float]
```

### Comparing `checkthechain-0.3.0/src/ctc/db/management/active_utils.py` & `checkthechain-0.3.4/src/ctc/db/management/active_utils.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,38 +1,38 @@
 from __future__ import annotations
 
 import typing
 
 if typing.TYPE_CHECKING:
     from .. import schema_utils
 
+from ctc import spec
 
-def get_active_schemas() -> typing.Mapping[
-    schema_utils.SchemaName,
-    bool,
-]:
+
+def get_active_schemas() -> typing.Mapping[spec.SchemaName, bool]:
     """return specification of which subset of incoming data to store in db"""
     return {
         # 'block_gas_stats': False,
         'block_timestamps': True,
         'block_gas': True,
         'blocks': True,
         'contract_abis': True,
         'contract_creation_blocks': True,
         'dex_pools': True,
         'erc20_metadata': True,
+        'events': True,
+        'transactions': True,
         # 'erc20_state': False,
-        # 'events': False,
         '4byte': True,
         'chainlink': True,
         'schema_versions': True,
     }
 
 
-def get_active_timestamp_schema() -> schema_utils.NetworkSchemaName | None:
+def get_active_timestamp_schema() -> spec.NetworkSchemaName | None:
     active_schemas = get_active_schemas()
     if active_schemas['block_timestamps']:
         return 'block_timestamps'
     elif active_schemas['blocks']:
         return 'blocks'
     else:
         return None
```

### Comparing `checkthechain-0.3.0/src/ctc/db/management/compression/block_timestamp_compression.py` & `checkthechain-0.3.4/src/ctc/evm/block_utils/block_times/timestamp_to_block/block_time_plural.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,102 +1,107 @@
 from __future__ import annotations
 
-import os
 import typing
 
 from ctc import spec
+from . import block_time_search
+from . import block_time_singular
 
+if typing.TYPE_CHECKING:
+    from typing_extensions import Literal
 
-block_timestamps_template = (
-    'block_timestamps__{start_block}_to_{end_block}__{t_index}_{t_start}.npz'
-)
 
-
-def save_compressed_block_timestamps(
-    block_timestamps: typing.Mapping[int, int],
+async def async_get_blocks_of_timestamps(
+    timestamps: typing.Sequence[int],
     *,
-    dirname: str | None = None,
-    path: str | None = None,
-    clip_t0: bool | None = None,
-) -> str:
-    import numpy as np
-
-    start_block = min(block_timestamps.keys())
-    end_block = max(block_timestamps.keys())
-
-    timestamps = []
-    for i in range(start_block, end_block + 1):
-        timestamps.append(block_timestamps[i])
-
-    # clip t0 if need be
-    if clip_t0 is None:
-        clip_t0 = block_timestamps[start_block] == 0
-    if clip_t0:
-        timestamps = timestamps[1:]
-        t_index = 't1'
-    else:
-        t_index = 't0'
-    t_start = timestamps[0]
-
-    # compute diffs
-    timestamps_array: spec.NumpyArray = np.array(timestamps)
-    timestamp_diffs = timestamps_array[1:] - timestamps_array[:-1]
-
-    # convert to efficient dtype
-    dtype: type = np.int16
-    if (timestamp_diffs > np.iinfo(dtype).max).sum() > 0:
-        dtype = np.int32
-    timestamp_diffs = timestamp_diffs.astype(dtype)
-
-    if path is None:
-        filename = block_timestamps_template.format(
-            start_block=start_block,
-            end_block=end_block,
-            t_index=t_index,
-            t_start=t_start,
-        )
-        if dirname is not None:
-            path = os.path.join(dirname, filename)
-        else:
-            path = filename
+    block_timestamps: typing.Mapping[int, int] | None = None,
+    block_number_array: spec.NumpyArray | None = None,
+    block_timestamp_array: spec.NumpyArray | None = None,
+    nary: int | None = None,
+    cache: block_time_search.BlockTimestampSearchCache | None = None,
+    mode: Literal['<=', '>=', '=='] = '>=',
+    context: spec.Context = None,
+) -> list[int]:
+    """search for blocks corresponding to list of timestamps"""
+
+    from ctc import config
+
+    read_cache, write_cache = config.get_context_cache_read_write(
+        schema_name='block_timestamps', context=context
+    )
+
+    if block_timestamps is not None or (
+        block_number_array is not None and block_timestamp_array is not None
+    ):
+        import numpy as np
+
+        if mode != '>=':
+            raise NotImplementedError()
+
+        if block_timestamp_array is None:
+            if block_timestamps is None:
+                raise Exception('must specify more arguments')
+            block_timestamp_array = np.array(list(block_timestamps.values()))
+        if block_number_array is None:
+            if block_timestamps is None:
+                raise Exception('must specify more arguments')
+            block_number_array = np.array(list(block_timestamps.keys()))
+
+        blocks = []
+        for timestamp in timestamps:
+            block = block_time_singular._get_block_of_timestamp_from_arrays(
+                timestamp=timestamp,
+                block_timestamp_array=block_timestamp_array,
+                block_number_array=block_number_array,
+                verbose=False,
+            )
+            blocks.append(block)
 
-    np.savez_compressed(path, timestamp_diffs=timestamp_diffs)
+        return blocks
 
-    return path
+    else:
 
+        # get timestamps form db
+        if read_cache:
+            from ctc import db
+
+            db_blocks = await db.async_query_timestamps_blocks(
+                context=context,
+                timestamps=timestamps,
+                mode=mode,
+            )
+            if db_blocks is None:
+                db_blocks = [None for timestamp in timestamps]
+
+            # package non-null results
+            results: dict[int, int] = {}
+            remaining_timestamps: list[int] = []
+            for possible_block, timestamp in zip(db_blocks, timestamps):
+                if possible_block is None:
+                    remaining_timestamps.append(timestamp)
+                else:
+                    results[timestamp] = possible_block
+        else:
+            remaining_timestamps = list(timestamps)
+            results = {}
 
-def load_compressed_block_times(
-    path: str,
-    *,
-    start_block: int | None = None,
-    end_block: int | None = None,
-    t0: int | None = None,
-    t1: int | None = None,
-) -> typing.Mapping[int, int]:
-
-    import numpy as np
-
-    if start_block is None or end_block is None or (t0 is None and t1 is None):
-        filename = os.path.basename(path)
-        name = os.path.splitext(filename)[0]
-        _, block_range, t_info = name.split('__')
-
-        start_block_str, end_block_str = block_range.split('_to_')
-        start_block = int(start_block_str)
-        end_block = int(end_block_str)
-
-        t_index, t_str = t_info.split('_')
-        t_start = int(t_str)
-
-    timestamp_diffs = np.load(path)['timestamp_diffs']
-
-    if t_index == 't0':
-        head = [t_start]
-    elif t_index == 't1':
-        head = [0, t_start]
-    else:
-        raise Exception()
-    tail = [int(item) for item in (t_start + np.cumsum(timestamp_diffs))]
-    timestamps = head + tail
+        # get timestamps from rpc node
+        if len(remaining_timestamps) > 0:
+            coroutines = []
+            for timestamp in remaining_timestamps:
+                coroutine = block_time_singular.async_get_block_of_timestamp(
+                    timestamp=timestamp,
+                    verbose=False,
+                    cache=cache,
+                    nary=nary,
+                    context=config.update_context(context=context, cache=False),
+                    mode=mode,
+                )
+                coroutines.append(coroutine)
+            import asyncio
+
+            node_blocks = await asyncio.gather(*coroutines)
+            node_results = dict(zip(remaining_timestamps, node_blocks))
+            results.update(node_results)
 
-    blocks = range(start_block, end_block + 1)
-    return dict(zip(blocks, timestamps))
+        # combine
+        return [results[timestamp] for timestamp in timestamps]
```

### Comparing `checkthechain-0.3.0/src/ctc/db/management/dba_utils.py` & `checkthechain-0.3.4/src/ctc/db/management/dba_utils.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,103 +1,98 @@
 from __future__ import annotations
 
 import typing
 
-import sqlalchemy  # type: ignore
 import toolcli
 import toolsql
 
 from ctc import config
 from ctc import spec
-from .. import connect_utils
+from ctc.spec.typedefs import db_types
 from .. import schema_utils
 from . import version_utils
 
 
 def create_missing_tables(
     networks: typing.Sequence[spec.NetworkReference] | None = None,
-    schema_names: typing.Sequence[schema_utils.SchemaName] | None = None,
+    schema_names: typing.Sequence[str] | None = None,
     *,
-    db_config: toolsql.DBConfig | None = None,
+    conn: toolsql.Connection,
     verbose: bool = True,
     confirm: bool = False,
 ) -> None:
-    network_schema_names = schema_utils.get_network_schema_names()
-    generic_schema_names = schema_utils.get_generic_schema_names()
 
     # get netowrks and schemas
+    network_schema_names = schema_utils.get_network_schema_names()
+    generic_schema_names = schema_utils.get_generic_schema_names()
     if networks is None:
         networks = config.get_networks_that_have_providers()
     if schema_names is None:
         schema_names = network_schema_names + generic_schema_names
 
     # get preamble
     if verbose or not confirm:
-        print(
-            'Actively using',
-            len(schema_names),
-            'schema(s) across',
-            len(networks),
-            'network(s)',
-        )
+        n_schemas = len(schema_names)
+        n_networks = len(networks)
+        print('Using', n_schemas, 'schema(s) over', n_networks, 'network(s)')
         if len(schema_names) > 1:
             print('    - schemas:')
             for schema_name in schema_names:
                 print('        -', schema_name)
+        elif len(schema_names) == 1:
+            print('    - schema:', schema_names[0])
         else:
-            print('    - schema:', schema_name)
+            print('    - schema: [none specified]')
         if len(networks) > 1:
             print('    - networks:')
             for network in networks:
                 print('        -', network)
         elif len(networks) == 1:
             print('    - network:', networks[0])
         else:
             print()
             print('No networks specified, creating no tables')
 
-    # using single db config for all schemas
-    if db_config is None:
-        db_config = config.get_db_config(
-            schema_name='schema_versions',
-            network=None,
-            require=True,
-        )
-
     # get missing tables
     schemas_to_create: list[
-        tuple[spec.NetworkReference | None, schema_utils.SchemaName]
+        tuple[spec.NetworkReference | None, spec.SchemaName]
     ] = []
-    for schema_name in schema_names:
+    for schema_name_raw in schema_names:
+
+        if schema_name_raw in schema_utils.get_all_schema_names():
+            schema_name = typing.cast(db_types.SchemaName, schema_name_raw)
+        else:
+            raise Exception('unknown schema name: ' + str(schema_name_raw))
 
         # determine schema networks
         if schema_name in network_schema_names:
             schema_networks: typing.Sequence[
                 spec.NetworkReference | None
             ] = networks
         else:
             schema_networks = [None]
 
         for schema_network in schema_networks:
 
             if schema_network is not None:
                 schema = schema_utils.get_prepared_schema(
-                    schema_name=typing.cast(
-                        schema_utils.NetworkSchemaName, schema_name
-                    ),
-                    network=schema_network,
+                    schema_name=schema_name,
+                    context=dict(network=schema_network),
                 )
             else:
                 schema = schema_utils.get_raw_schema(schema_name=schema_name)
 
-            missing_tables = toolsql.get_missing_tables(
-                db_schema=schema,
-                db_config=db_config,
-            )
-            if len(missing_tables['missing_from_db']) > 0:
+            # if any tables missing, mark schema for creation
+            tables_in_db = toolsql.get_table_names(conn=conn)
+            missing_tables = [
+                table
+                for table in schema['tables'].keys()
+                if table not in tables_in_db
+            ]
+            if len(missing_tables) > 0:
                 schemas_to_create.append((schema_network, schema_name))
 
     # print missing tables
     if len(schemas_to_create) == 0:
         print()
         print('All tables already exist')
         return
@@ -111,181 +106,154 @@
     if not confirm:
         print()
         if not toolcli.input_yes_or_no('continue? '):
             raise Exception('Skipping creation of tables')
 
     # create tables
     # (for now, use same database for all tables)
-    engine = toolsql.create_engine(db_config=db_config)
-    if engine is None:
-        raise Exception('Could not create engine for database')
 
     # initialize schema versions schema if need be
-    with engine.begin() as conn:
-        if not version_utils.is_schema_versions_initialized(engine=engine):
-            initialize_schema_versions(conn=conn)
-
-    with engine.begin() as conn:
+    if not version_utils.is_schema_versions_initialized(conn=conn):
+        initialize_schema_versions(conn=conn)
 
-        # create each schema for each used network
-        for schema_network, schema_name in schemas_to_create:
-            initialize_schema(
-                schema_name=schema_name,
-                network=schema_network,
-                conn=conn,
-            )
+    # create each schema for each used network
+    for schema_network, schema_name in schemas_to_create:
+        initialize_schema(
+            schema_name=schema_name,
+            context=dict(network=schema_network),
+            conn=conn,
+        )
 
     print()
     print('All tables created')
 
 
-def initialize_schema_versions(conn: toolsql.SAConnection) -> None:
+def initialize_schema_versions(conn: toolsql.Connection) -> None:
     """initialize the schema_versions schema which manages versions of schemas"""
-    initialize_schema(
-        'schema_versions',
-        network=None,
-        conn=conn,
-    )
+
+    initialize_schema('schema_versions', context=dict(network=None), conn=conn)
 
 
 def initialize_schema(
-    schema_name: schema_utils.SchemaName,
+    schema_name: spec.SchemaName,
     *,
-    network: spec.NetworkReference | None,
-    conn: toolsql.SAConnection,
+    context: spec.Context,
+    conn: toolsql.Connection,
 ) -> None:
     """initialize schema by creating its table and other objects"""
 
     network_schema_names = schema_utils.get_network_schema_names()
     prepared_schema = schema_name in network_schema_names
 
     # check that schema versions are being tracked
-    if not version_utils.is_schema_versions_initialized(engine=conn.engine):
+    if not version_utils.is_schema_versions_initialized(conn=conn):
         if schema_name != 'schema_versions':
             initialize_schema_versions(conn=conn)
     else:
         # check that schema not already initialized
         schema_version = version_utils.get_schema_version(
             schema_name=schema_name,
-            network=network,
+            context=context,
             conn=conn,
         )
         if schema_version is not None:
             raise Exception('schema already initialized')
 
     # load schema data
     if prepared_schema:
         schema = schema_utils.get_prepared_schema(
-            schema_name=typing.cast(
-                schema_utils.NetworkSchemaName, schema_name
-            ),
-            network=network,
+            schema_name=schema_name,
+            context=context,
         )
     else:
         schema = schema_utils.get_raw_schema(schema_name=schema_name)
 
     # create tables
     for table_name, table_schema in schema['tables'].items():
         toolsql.create_table(
-            table_name,
-            table_schema=table_schema,
+            table_schema,
             conn=conn,
+            if_not_exists=True,
+            confirm=True,
         )
 
-    # set version in schema version table
     version_utils.set_schema_version(
         schema_name=schema_name,
-        network=network,
+        context=context,
         conn=conn,
     )
 
-    toolsql.clear_table_caches(conn=conn)
-
 
 def drop_schema(
-    schema_name: schema_utils.SchemaName,
-    network: spec.NetworkReference | None = None,
+    schema_name: str,
     *,
+    context: spec.Context = None,
+    conn: toolsql.Connection,
     confirm: bool = False,
 ) -> None:
 
+    if schema_name not in schema_utils.get_all_schema_names():
+        raise Exception('unknown schema name: ' + str(schema_name))
+    schema = typing.cast(db_types.SchemaName, schema_name)
+
+    network: int | str | None = config.get_context_chain_id(context)
     if not confirm:
         if network is not None:
             answer = toolcli.input_yes_or_no(
                 'Delete version row for schema '
-                + schema_name
+                + schema
                 + ' for network '
                 + str(network)
                 + '? '
             )
             if not answer:
                 raise Exception('aborting')
         else:
             answer = toolcli.input_yes_or_no(
-                'Delete ALL version rows for schema ' + schema_name + '? '
+                'Delete ALL version rows for schema ' + schema + '? '
             )
             if not answer:
                 raise Exception('aborting')
 
     if network is None:
-        if schema_name in schema_utils.get_network_schema_names():
+        if schema in schema_utils.get_network_schema_names():
             networks: typing.Sequence[
                 spec.NetworkReference | None
             ] = config.get_networks_that_have_providers()
         else:
             networks = [None]
     else:
         networks = [network]
 
     for network in networks:
 
         # determine tables in db
-        engine = connect_utils.create_engine(
-            schema_name=schema_name,
-            network=network,
-            create_missing_schema=False,
-        )
-        if engine is None:
-            continue
-        db_table_names = sqlalchemy.inspect(engine).get_table_names()
+        db_table_names = toolsql.get_table_names(conn=conn)
 
         # determine tables in schema
         if network is not None:
             schema_data = schema_utils.get_prepared_schema(
-                schema_name=typing.cast(
-                    schema_utils.NetworkSchemaName, schema_name
-                ),
-                network=network,
+                schema_name=schema,
+                context=context,
             )
         else:
-            schema_data = schema_utils.get_raw_schema(schema_name=schema_name)
+            schema_data = schema_utils.get_raw_schema(schema_name=schema)
         schema_table_names = schema_data['tables']
 
         # determine which tables to drop
         drop_table_names = set(db_table_names) & set(schema_table_names)
 
         # drop schema tables
-        with engine.begin() as conn:
-            for table_name in drop_table_names:
-                print('Dropping table', table_name)
-                table_object = toolsql.create_table_object_from_db(
-                    engine=engine,
-                    table_name=table_name,
-                )
-                table_object.drop(bind=engine)
+        for table_name in drop_table_names:
+            print('Dropping table', table_name)
+            toolsql.drop_table(table=table_name, conn=conn, confirm=True)
 
     # delete rows from schema_versions table
-    schema_version_engine = connect_utils.create_engine(
-        schema_name='schema_versions',
-        network=None,
-        create_missing_schema=False,
-    )
-    if schema_version_engine is not None:
-        with schema_version_engine.begin() as conn:
-            for network in networks:
-                version_utils.delete_schema_version(
-                    schema_name=schema_name,
-                    network=network,
-                    conn=conn,
-                    confirm_delete_row=True,
-                    confirm_delete_schema=True,
-                )
+    for network in networks:
+        version_utils.delete_schema_version(
+            schema_name=schema,
+            network=network,
+            conn=conn,
+            confirm_delete_row=True,
+            confirm_delete_schema=True,
+        )
+
```

### Comparing `checkthechain-0.3.0/src/ctc/db/query_utils.py` & `checkthechain-0.3.4/src/ctc/db/query_utils.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,69 +1,67 @@
 from __future__ import annotations
 
 import functools
 from typing import Callable, Coroutine, Any, TypeVar
 
-import sqlalchemy  # type: ignore
 import toolsql
 
 from ctc import spec
 from . import connect_utils
-from . import schema_utils
 
 
 R = TypeVar('R')
 
 
 def wrap_selector_with_connection(
     async_f: Callable[..., Coroutine[Any, Any, R | None]],
-    schema_name: schema_utils.SchemaName
-    | Callable[..., schema_utils.SchemaName | None],
-    *,
-    require_network: bool = True,
+    schema_name: spec.SchemaName | Callable[..., spec.SchemaName | None],
 ) -> Callable[..., Coroutine[Any, Any, R | None]]:
 
     # define new function
     @functools.wraps(async_f)
     async def async_connected_f(
         *args: Any,
-        network: spec.NetworkReference | None = None,
-        engine: toolsql.SAEngine | None = None,
+        context: spec.Context,
+        db_config: toolsql.DBConfig | None = None,
+        raise_if_cannot_connect: bool = False,
+        raise_if_table_dne: bool = False,
         **kwargs: Any,
     ) -> R | None:
-        # TODO: allow this function to accept a conn that already exists
-
-        if network is None and require_network:
-            raise Exception('must specify network')
 
+        # determine schema_name
         if not isinstance(schema_name, str) and hasattr(
             schema_name, '__call__'
         ):
             name = schema_name()
             if name is None:
                 return None
         elif isinstance(schema_name, str):
             name = schema_name
         else:
             raise Exception('unknown schema_name format')
 
-        # create engine
-        if engine is None:
-            engine = connect_utils.create_engine(
-                schema_name=name,
-                network=network,
-            )
-
-        # if cannot create engine, return None
-        if engine is None:
-            return None
-
-        # connect and execute
-        if require_network:
-            kwargs['network'] = network
+        # try to query data
         try:
-            with engine.connect() as conn:
-                return await async_f(*args, conn=conn, **kwargs)
-        except sqlalchemy.exc.OperationalError:
-            return None
+            async with connect_utils.async_connect(
+                context=context,
+                db_config=db_config,
+                schema=name,
+                read_only=True,
+            ) as conn:
+                return await async_f(*args, conn=conn, context=context, **kwargs)
+
+        # handle errors, either by returning None or raising exceptions
+        except toolsql.CannotConnect as e:
+            if raise_if_cannot_connect:
+                raise e
+            else:
+                return None
+        except toolsql.TableDoesNotExist as e:
+            if raise_if_table_dne:
+                raise e
+            else:
+                return None
 
+    # return decorated function
     return async_connected_f
+
```

### Comparing `checkthechain-0.3.0/src/ctc/db/schema_utils.py` & `checkthechain-0.3.4/src/ctc/db/schema_utils.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,168 +1,159 @@
 from __future__ import annotations
 
 import copy
 import typing
-from typing_extensions import Literal
 
 import toolsql
 
 from ctc import config
-from ctc import evm
 from ctc import spec
+from ctc.spec.typedefs import db_types
 
 from . import schemas
 
-# admin schemas = those related to managing ctc
-AdminSchemaName = Literal['schema_versions']
+#
+# # schema lists
+#
+
+
+def get_admin_schema_names() -> tuple[db_types.AdminSchemaName]:
+    return db_types.AdminSchemaName.__args__  # type: ignore
 
-# generic schemas = those agnostic to network
-GenericSchemaName = Literal[
-    '4byte',
-    'coingecko',
-]
-
-# network schemas = those that have unique data on each network
-NetworkSchemaName = Literal[
-    # 'block_gas_stats',
-    'block_timestamps',
-    'block_gas',
-    'blocks',
-    'contract_abis',
-    'contract_creation_blocks',
-    'erc20_metadata',
-    'dex_pools',
-    # 'erc20_state',
-    # 'events',
-    #
-    # protocols
-    'chainlink',
-]
 
-SchemaName = typing.Union[NetworkSchemaName, GenericSchemaName, AdminSchemaName]
+def get_generic_schema_names() -> tuple[db_types.GenericSchemaName]:
+    return db_types.GenericSchemaName.__args__  # type: ignore
 
 
-def get_admin_schema_names() -> tuple[AdminSchemaName]:
-    return AdminSchemaName.__args__  # type: ignore
+def get_network_schema_names() -> tuple[db_types.NetworkSchemaName]:
+    return db_types.NetworkSchemaName.__args__  # type: ignore
 
 
-def get_generic_schema_names() -> tuple[GenericSchemaName]:
-    return GenericSchemaName.__args__  # type: ignore
+def get_all_schema_names() -> typing.Sequence[db_types.SchemaName]:
+    schema_names = (
+        get_admin_schema_names()
+        + get_generic_schema_names()
+        + get_network_schema_names()
+    )
+    return typing.cast(typing.Sequence[db_types.SchemaName], schema_names)
 
 
-def get_network_schema_names() -> tuple[NetworkSchemaName]:
-    return NetworkSchemaName.__args__  # type: ignore
+#
+# # raw schemas
+#
 
 
-def get_raw_schema(schema_name: SchemaName) -> toolsql.DBSchema:
+def get_raw_schema(schema_name: str) -> toolsql.DBSchema:
+    """get raw schema, a set of tables not customized for any network"""
+    schema: toolsql.DBSchemaShorthand
     if schema_name == 'block_timestamps':
-        return schemas.block_timestamps_schema
+        schema = schemas.block_timestamps_schema
     elif schema_name == 'block_gas':
-        return schemas.block_gas_schema
+        schema = schemas.block_gas_schema
     elif schema_name == 'blocks':
-        return schemas.blocks_schema
+        schema = schemas.blocks_schema
     elif schema_name == 'contract_abis':
-        return schemas.contract_abis_schema
+        schema = schemas.contract_abis_schema
     elif schema_name == 'contract_creation_blocks':
-        return schemas.contract_creation_blocks_schema
-    elif schema_name == 'erc20_metadata':
-        return schemas.erc20_metadata_schema
+        schema = schemas.contract_creation_blocks_schema
     elif schema_name == 'dex_pools':
-        return schemas.dex_pools_schema
+        schema = schemas.dex_pools_schema
+    elif schema_name == 'erc20_metadata':
+        schema = schemas.erc20_metadata_schema
+    elif schema_name == 'events':
+        schema = schemas.events_schema
     # elif schema_name == 'erc20_state':
-    #     return schemas.erc20_state_schema
+    #     schema = schemas.erc20_state_schema
     elif schema_name == 'schema_versions':
-        return schemas.schema_versions_schema
+        schema = schemas.schema_versions_schema
+    elif schema_name == 'transactions':
+        schema = schemas.transactions_schema
     #
     # # protocols
     #
     elif schema_name == '4byte':
         from ctc.protocols import fourbyte_utils
 
-        return fourbyte_utils.fourbyte_schema
+        schema = fourbyte_utils.fourbyte_schema
     elif schema_name == 'chainlink':
         from ctc.protocols.chainlink_utils import chainlink_db
 
-        return chainlink_db.chainlink_schema
+        schema = chainlink_db.chainlink_schema
     elif schema_name == 'coingecko':
         from ctc.protocols.coingecko_utils import coingecko_db
 
-        return coingecko_db.coingecko_schema
+        schema = coingecko_db.coingecko_schema
     else:
         raise Exception('unknown schema: ' + str(schema_name))
 
+    return toolsql.normalize_shorthand_db_schema(schema)
+
+
+#
+# # prepared schemas
+#
+
 
 def get_prepared_schema(
-    schema_name: NetworkSchemaName,
-    network: spec.NetworkReference | None = None,
+    schema_name: str,
+    context: spec.Context = None,
 ) -> toolsql.DBSchema:
+    """get prepared schema, a set of tables customized for a specific network"""
 
     # get schema
     schema = get_raw_schema(schema_name)
     schema = copy.deepcopy(schema)
 
-    if network is None:
-        network = config.get_default_network()
-
     # add network to table name
     for table_name, table in list(schema['tables'].items()):
-        full_name = get_table_name(network=network, table_name=table_name)
+        full_name = get_prepared_table_name(
+            context=context, table_name=table_name
+        )
         if table.get('name') is not None:
             table['name'] = full_name
         schema['tables'][full_name] = schema['tables'].pop(table_name)  # type: ignore
 
     return schema
 
 
-def get_table_name(
+def get_table_schema(
     table_name: str,
-    network: spec.NetworkReference | None = None,
+    context: spec.Context = None,
+) -> toolsql.TableSchema:
+    schema_name = _get_schema_of_raw_table(table_name)
+    if schema_name in get_generic_schema_names():
+        schema = get_raw_schema(schema_name=schema_name)
+        return schema['tables'][table_name]
+    else:
+        schema = get_prepared_schema(schema_name=schema_name, context=context)
+        prepared_name = get_prepared_table_name(
+            context=context, table_name=table_name
+        )
+        return schema['tables'][prepared_name]
+
+
+def get_prepared_table_name(
+    table_name: str,
+    context: spec.Context = None,
 ) -> str:
     """get full table name, incorporating chain information"""
-    if network is None:
-        network = config.get_default_network()
-        if network is None:
-            raise Exception('must specify network or configure default network')
-    chain_id = evm.get_network_chain_id(network)
+    chain_id = config.get_context_chain_id(context)
     return 'network_' + str(chain_id) + '__' + table_name
 
 
-def get_complete_prepared_schema(
-    networks: typing.Sequence[spec.NetworkReference] | None = None,
-) -> toolsql.DBSchema:
-
-    # include network schemas
-    if networks is None:
-        networks = config.get_networks_that_have_providers()
-    schema_name: SchemaName
-    all_schemas = []
-    for network in networks:
-        for schema_name in get_network_schema_names():
-            schema = get_prepared_schema(
-                network=network, schema_name=schema_name
-            )
-            all_schemas.append(schema)
-
-    # include generic schemas
-    for schema_name in get_generic_schema_names():
-        schema = get_raw_schema(schema_name)
-        all_schemas.append(schema)
-
-    # include admin schemas
-    for schema_name in get_admin_schema_names():
-        schema = get_raw_schema(schema_name)
-        all_schemas.append(schema)
-
-    return _combine_db_schemas(all_schemas)
-
+def _get_schema_of_raw_table(table: str) -> spec.SchemaName:
+    candidates = []
+    for schema_name in get_all_schema_names():
+        raw_schema = get_raw_schema(schema_name)
+        for schema_table in raw_schema['tables'].keys():
+            if table == schema_table:
+                candidates.append(schema_name)
+
+    if len(candidates) == 1:
+        return candidates[0]
+    elif len(candidates) == 0:
+        raise Exception(
+            'could not find any schema containing table ' + str(table)
+        )
+    else:
+        raise Exception('found multiple schemas containing table ' + str(table))
 
-def _combine_db_schemas(
-    db_schemas: typing.Sequence[toolsql.DBSchema],
-) -> toolsql.DBSchema:
-    tables: typing.MutableMapping[str, toolsql.TableSpec] = {}
-    for db_schema in db_schemas:
-        for table_name, table_spec in db_schema.get('tables', {}).items():
-            if table_name in tables:
-                raise Exception('table name collision')
-            tables[table_name] = table_spec
-    combined_schema: toolsql.DBSchema = {'tables': tables}
-    return combined_schema
```

### Comparing `checkthechain-0.3.0/src/ctc/db/schemas/__upcoming__/block_gas_stats/block_gas_stats_schema_defs.py` & `checkthechain-0.3.4/src/ctc/db/schemas/__upcoming__/block_gas_stats/block_gas_stats_schema_defs.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 from __future__ import annotations
 
 import toolsql
 
-block_gas_stats_schema: toolsql.DBSchema = {
+block_gas_stats_schema: toolsql.DBSchemaShorthand = {
     'tables': {
         'block_gas_stats': {
             'columns': [
                 {'name': 'block_number', 'type': 'Integer', 'primary': True},
                 {'name': 'base', 'type': 'Integer'},
                 {'name': 'mean', 'type': 'Integer'},
                 {'name': 'median', 'type': 'Integer'},
```

### Comparing `checkthechain-0.3.0/src/ctc/db/schemas/__upcoming__/erc20_state/erc20_state_schema_defs.py` & `checkthechain-0.3.4/src/ctc/db/schemas/__upcoming__/erc20_state/erc20_state_schema_defs.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 from __future__ import annotations
 
 import toolsql
 
 
-erc20_state_schema: toolsql.DBSchema = {
+erc20_state_schema: toolsql.DBSchemaShorthand = {
     'tables': {
         'erc20_balances': {
             'columns': [
                 {
                     'name': 'erc20',
                     'type': 'Text',
                     'primary': True,
```

### Comparing `checkthechain-0.3.0/src/ctc/db/schemas/__upcoming__/protocol_schemas/fourbyte_schema_defs.py` & `checkthechain-0.3.4/src/ctc/db/schemas/__upcoming__/protocol_schemas/fourbyte_schema_defs.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 from __future__ import annotations
 
 import toolsql
 
 
-fourbyte_schema: toolsql.DBSchema = {
+fourbyte_schema: toolsql.DBSchemaShorthand = {
     'tables': {
         'function_signatures': {
             'columns': [
                 {'name': 'id', 'primary': True},
                 {'name': 'created_at'},
                 {'name': 'text_signature', 'index': True},
                 {'name': 'hex_signature', 'index': True},
```

### Comparing `checkthechain-0.3.0/src/ctc/db/schemas/__upcoming__/protocol_schemas/fuse_pools_schema_defs.py` & `checkthechain-0.3.4/src/ctc/db/schemas/__upcoming__/protocol_schemas/fuse_pools_schema_defs.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 from __future__ import annotations
 
 import toolsql
 
-fuse_pools_schema: toolsql.DBSchema = {
+fuse_pools_schema: toolsql.DBSchemaShorthand = {
     'tables': {
         'fuse_pools': {
             'columns': [
                 {'name': 'index', 'type': 'Integer', 'primary': True},
                 {'name': 'comptroller', 'type': 'Text', 'index': True},
             ],
         },
```

### Comparing `checkthechain-0.3.0/src/ctc/db/schemas/block_gas/block_gas_schema_defs.py` & `checkthechain-0.3.4/src/ctc/db/schemas/block_timestamps/block_timestamps_schema_defs.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,27 +1,24 @@
 from __future__ import annotations
 
 import toolsql
 
 
-block_gas_schema: toolsql.DBSchema = {
+block_timestamps_schema: toolsql.DBSchemaShorthand = {
     'tables': {
-        'block_gas': {
+        'block_timestamps': {
             'columns': [
                 {
                     'name': 'block_number',
                     'type': 'Integer',
                     'primary': True,
                 },
                 {
                     'name': 'timestamp',
                     'type': 'Integer',
                     'index': True,
-                },
-                {
-                    'name': 'median_gas_fee',
-                    'type': 'Float',
+                    'nullable': False,
                 },
             ],
         },
     },
 }
```

### Comparing `checkthechain-0.3.0/src/ctc/db/schemas/block_timestamps/block_timestamps_schema_defs.py` & `checkthechain-0.3.4/src/ctc/db/schemas/contract_creation_blocks/contract_creation_blocks_schema_defs.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,24 +1,23 @@
 from __future__ import annotations
 
 import toolsql
 
 
-block_timestamps_schema: toolsql.DBSchema = {
+contract_creation_blocks_schema: toolsql.DBSchemaShorthand = {
     'tables': {
-        'block_timestamps': {
+        'contract_creation_blocks': {
             'columns': [
                 {
-                    'name': 'block_number',
-                    'type': 'Integer',
+                    'name': 'address',
+                    'type': 'Text',
                     'primary': True,
                 },
                 {
-                    'name': 'timestamp',
+                    'name': 'block_number',
                     'type': 'Integer',
                     'index': True,
-                    'null': False,
                 },
             ],
         },
     },
 }
```

### Comparing `checkthechain-0.3.0/src/ctc/db/schemas/block_timestamps/block_timestamps_statements.py` & `checkthechain-0.3.4/src/ctc/db/schemas/block_timestamps/block_timestamps_statements.py`

 * *Files 23% similar despite different names*

```diff
@@ -6,133 +6,130 @@
 
 from ctc import spec
 from ... import schema_utils
 
 
 async def async_upsert_block_timestamp(
     *,
-    conn: toolsql.SAConnection,
+    conn: toolsql.AsyncConnection,
     block_number: int,
     timestamp: int,
-    network: spec.NetworkReference | None = None,
+    context: spec.Context = None,
 ) -> None:
 
-    table = schema_utils.get_table_name('block_timestamps', network=network)
-    toolsql.insert(
+    table = schema_utils.get_table_schema('block_timestamps', context=context)
+    await toolsql.async_insert(
         conn=conn,
         table=table,
         row={'block_number': block_number, 'timestamp': timestamp},
-        upsert='do_update',
+        upsert=True,
     )
 
 
 async def async_upsert_block_timestamps(
     *,
-    conn: toolsql.SAConnection,
+    conn: toolsql.AsyncConnection,
     block_timestamps: typing.Mapping[int, int] | None = None,
-    blocks: typing.Sequence[spec.Block] | None = None,
-    network: spec.NetworkReference | None = None,
+    blocks: typing.Sequence[spec.DBBlock] | None = None,
+    context: spec.Context = None,
 ) -> None:
 
     if block_timestamps is None:
         if blocks is None:
             raise Exception('must specify block_timestamps or blocks')
         block_timestamps = {
             block['number']: block['timestamp'] for block in blocks
         }
 
     rows = [
         {'block_number': block_number, 'timestamp': timestamp}
         for block_number, timestamp in block_timestamps.items()
     ]
-    table = schema_utils.get_table_name('block_timestamps', network=network)
-    toolsql.insert(
+    table = schema_utils.get_table_schema('block_timestamps', context=context)
+    await toolsql.async_insert(
         conn=conn,
         table=table,
         rows=rows,
-        upsert='do_update',
+        upsert=True,
     )
 
 
 async def async_delete_block_timestamp(
     *,
-    conn: toolsql.SAConnection,
+    conn: toolsql.AsyncConnection,
     block_number: typing.Sequence[int],
-    network: spec.NetworkReference | None = None,
+    context: spec.Context = None,
 ) -> None:
 
-    table = schema_utils.get_table_name('block_timestamps', network=network)
+    table = schema_utils.get_table_schema('block_timestamps', context=context)
 
-    toolsql.delete(
+    await toolsql.async_delete(
         conn=conn,
         table=table,
         where_equals={'block_number': block_number},
     )
 
 
 async def async_delete_block_timestamps(
     *,
-    conn: toolsql.SAConnection,
+    conn: toolsql.AsyncConnection,
     block_numbers: typing.Sequence[int],
-    network: spec.NetworkReference | None = None,
+    context: spec.Context = None,
 ) -> None:
 
-    table = schema_utils.get_table_name('block_timestamps', network=network)
+    table = schema_utils.get_table_schema('block_timestamps', context=context)
 
-    toolsql.delete(
+    await toolsql.async_delete(
         conn=conn,
         table=table,
         where_in={'block_number': block_numbers},
     )
 
 
 #
 # # do not export
 #
 
 
 async def async_select_block_timestamp(
     block_number: int,
     *,
-    conn: toolsql.SAConnection,
-    network: spec.NetworkReference | None = None,
+    conn: toolsql.AsyncConnection,
+    context: spec.Context = None,
 ) -> int | None:
 
-    table = schema_utils.get_table_name('block_timestamps', network=network)
+    table = schema_utils.get_table_schema('block_timestamps', context=context)
 
-    result = toolsql.select(
+    result = await toolsql.async_select(
         conn=conn,
         table=table,
         where_equals={'block_number': block_number},
-        row_format='only_column',
-        only_columns=['timestamp'],
-        return_count='one',
-        raise_if_table_dne=False,
+        columns=['timestamp'],
+        output_format='cell_or_none',
     )
     if result is not None and not isinstance(result, int):
         raise Exception('invalid db result')
     return result
 
 
 async def async_select_block_timestamps(
     block_numbers: typing.Sequence[typing.SupportsInt],
     *,
-    conn: toolsql.SAConnection,
-    network: spec.NetworkReference | None = None,
+    conn: toolsql.AsyncConnection,
+    context: spec.Context = None,
 ) -> list[int | None] | None:
 
-    table = schema_utils.get_table_name('block_timestamps', network=network)
+    table = schema_utils.get_table_schema('block_timestamps', context=context)
 
     block_numbers_int = [int(item) for item in block_numbers]
 
-    results = toolsql.select(
+    results = await toolsql.async_select(
         conn=conn,
         table=table,
         where_in={'block_number': block_numbers_int},
-        raise_if_table_dne=False,
     )
 
     if results is None:
         return results
 
     block_timestamps = {
         row['block_number']: row['timestamp'] for row in results
@@ -141,96 +138,104 @@
     return [
         block_timestamps.get(block_number) for block_number in block_numbers
     ]
 
 
 async def async_select_max_block_number(
     *,
-    conn: toolsql.SAConnection,
-    network: spec.NetworkReference | None = None,
+    conn: toolsql.AsyncConnection,
+    context: spec.Context = None,
 ) -> int | None:
 
-    table = schema_utils.get_table_name('block_timestamps', network=network)
-    result = toolsql.select(
-        conn=conn,
-        table=table,
-        sql_functions=[
-            ['max', 'block_number'],
-        ],
-        return_count='one',
-        raise_if_table_dne=False,
-    )
+    table = schema_utils.get_table_schema('block_timestamps', context=context)
+
+    # try-catch because connectorx panics on empty rows
+    try:
+        result = await toolsql.async_select(
+            conn=conn,
+            table=table,
+            columns=['MAX(block_number)'],
+            output_format='cell_or_none',
+        )
+    except RuntimeError as e:
+        if e.args == ('Cannot infer type from null for SQLite',):
+            return None
+        else:
+            raise e
+
     if result is None:
         return None
-    subresult = result['max__block_number']
-    if subresult is not None and not isinstance(subresult, int):
+    elif isinstance(result, int):
+        return result
+    else:
         raise Exception('invalid db result')
-    return subresult
 
 
 async def async_select_max_block_timestamp(
     *,
-    conn: toolsql.SAConnection,
-    network: spec.NetworkReference | None = None,
+    conn: toolsql.AsyncConnection,
+    context: spec.Context = None,
 ) -> int | None:
 
-    table = schema_utils.get_table_name('block_timestamps', network=network)
-    result = toolsql.select(
-        conn=conn,
-        table=table,
-        sql_functions=[
-            ['max', 'timestamp'],
-        ],
-        return_count='one',
-        raise_if_table_dne=False,
-    )
+    table = schema_utils.get_table_schema('block_timestamps', context=context)
+
+    # try-catch because connectorx panics on empty rows
+    try:
+        result = await toolsql.async_select(
+            conn=conn,
+            table=table,
+            columns=['MAX(timestamp)'],
+            output_format='cell_or_none',
+        )
+    except RuntimeError as e:
+        if e.args == ('Cannot infer type from null for SQLite',):
+            return None
+        else:
+            raise e
+
     if result is None:
         return None
-
-    subresult = result['max__timestamp']
-    if subresult is not None and not isinstance(subresult, int):
+    elif isinstance(result, int):
+        return result
+    else:
         raise Exception('invalid db result')
-    return subresult
 
 
 async def async_select_timestamp_block_range(
     timestamp: int,
     *,
-    conn: toolsql.SAConnection,
-    network: spec.NetworkReference | None = None,
+    conn: toolsql.AsyncConnection,
+    context: spec.Context = None,
 ) -> tuple[int | None, int | None]:
     """return block range that must contain timestamp
 
     this function is used to confine a block-of-timestamp search
     """
 
-    table = schema_utils.get_table_name('block_timestamps', network=network)
+    # convert numpy types to native python type
+    if type(timestamp).__name__.startswith('int'):
+        timestamp = int(timestamp)
 
-    lower_bound = toolsql.select(
+    table = schema_utils.get_table_schema('block_timestamps', context=context)
+    lower_bound = await toolsql.async_select(
         conn=conn,
         table=table,
         where_lte={'timestamp': timestamp},
-        sql_functions=[
-            ['max', 'block_number'],
-        ],
-        return_count='one',
-        raise_if_table_dne=False,
+        columns=['MAX(block_number)'],
+        output_format='cell_or_none',
     )
-    upper_bound = toolsql.select(
+    upper_bound = await toolsql.async_select(
         conn=conn,
         table=table,
         where_gte={'timestamp': timestamp},
-        sql_functions=[
-            ['min', 'block_number'],
-        ],
-        return_count='one',
-        raise_if_table_dne=False,
+        columns=['MIN(block_number)'],
+        output_format='cell_or_none',
     )
 
-    return lower_bound['max__block_number'], upper_bound['min__block_number']
+    return lower_bound, upper_bound
 
 
 __all__ = (
     'async_upsert_block_timestamp',
     'async_upsert_block_timestamps',
     'async_delete_block_timestamp',
     'async_delete_block_timestamps',
```

### Comparing `checkthechain-0.3.0/src/ctc/db/schemas/block_timestamps/multischema_block_timestamps_queries.py` & `checkthechain-0.3.4/src/ctc/db/schemas/block_timestamps/multischema_block_timestamps_queries.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/db/schemas/block_timestamps/multischema_block_timestamps_search.py` & `checkthechain-0.3.4/src/ctc/db/schemas/block_timestamps/multischema_block_timestamps_search.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,30 +1,32 @@
 from __future__ import annotations
 
 import asyncio
 import typing
-from typing_extensions import Literal
 
 import toolsql
 
 from ctc import spec
 from ... import management
 from ... import schema_utils
 from . import block_timestamps_statements
 
 from .multischema_block_timestamps_statements import (
     async_select_block_timestamp,
 )
 
+if typing.TYPE_CHECKING:
+    from typing_extensions import Literal
+
 
 async def async_select_timestamp_block(
     timestamp: int,
     *,
-    conn: toolsql.SAConnection,
-    network: spec.NetworkReference | None = None,
+    conn: toolsql.AsyncConnection,
+    context: spec.Context = None,
     mode: Literal['<=', '>=', '=='] = '>=',
 ) -> int | None:
     """
 
     possible approaches to ensure db has enough data to give answer:
     - possibilities
         - run two queries, like (gte + lt) or (lte + gt)
@@ -48,23 +50,28 @@
         query = {'where_equals': {'timestamp': timestamp}}
     else:
         raise Exception('unknown mode: ' + str(mode))
 
     timestamp_schema = management.get_active_timestamp_schema()
 
     if timestamp_schema == 'block_timestamps':
-        table = schema_utils.get_table_name('block_timestamps', network=network)
-        block_number: int = toolsql.select(
+        table = schema_utils.get_table_schema(
+            'block_timestamps', context=context
+        )
+        block_numbers: typing.Sequence[int] = await toolsql.async_select(
             conn=conn,
             table=table,
-            return_count='one',
-            only_columns=['block_number'],
-            row_format='only_column',
+            columns=['block_number'],
+            output_format='single_column',
             **query,
         )
+        if block_numbers is not None and len(block_numbers) > 0:
+            block_number = block_numbers[0]
+        else:
+            block_number = None
     elif timestamp_schema == 'blocks':
         raise NotImplementedError()
     else:
         raise Exception('unknown schema: ' + str(timestamp_schema))
 
     if block_number is not None:
         if mode == '==':
@@ -90,27 +97,27 @@
 
     return block_number
 
 
 async def async_select_timestamps_blocks(
     timestamps: typing.Sequence[int],
     *,
-    conn: toolsql.SAConnection,
-    network: spec.NetworkReference | None = None,
+    conn: toolsql.AsyncConnection,
+    context: spec.Context = None,
     mode: Literal['<=', '>=', '=='] = '>=',
 ) -> list[int | None]:
 
     timestamp_schema = management.get_active_timestamp_schema()
 
     if timestamp_schema == 'block_timestamps':
         coroutines = [
             async_select_timestamp_block(
                 conn=conn,
                 timestamp=timestamp,
-                network=network,
+                context=context,
                 mode=mode,
             )
             for timestamp in timestamps
         ]
         return await asyncio.gather(*coroutines)
 
     elif timestamp_schema == 'blocks':
@@ -119,23 +126,24 @@
     else:
         raise Exception('unknown schema: ' + str(timestamp_schema))
 
 
 async def async_select_timestamp_block_range(
     timestamp: int,
     *,
-    conn: toolsql.SAConnection,
-    network: spec.NetworkReference | None = None,
+    conn: toolsql.AsyncConnection,
+    context: spec.Context = None,
 ) -> tuple[int | None, int | None]:
 
     timestamp_schema = management.get_active_timestamp_schema()
 
     if timestamp_schema == 'block_timestamps':
         return await block_timestamps_statements.async_select_timestamp_block_range(
             timestamp=timestamp,
             conn=conn,
-            network=network,
+            context=context,
         )
     elif timestamp_schema == 'blocks':
         raise NotImplementedError()
     else:
         raise Exception('unknown schema: ' + str(timestamp_schema))
+
```

### Comparing `checkthechain-0.3.0/src/ctc/db/schemas/block_timestamps/multischema_block_timestamps_statements.py` & `checkthechain-0.3.4/src/ctc/db/schemas/block_timestamps/multischema_block_timestamps_statements.py`

 * *Files 14% similar despite different names*

```diff
@@ -9,105 +9,106 @@
 from . import block_timestamps_statements
 from ..blocks import blocks_statements
 
 
 async def async_select_block_timestamp(
     block_number: int,
     *,
-    conn: toolsql.SAConnection,
-    network: spec.NetworkReference | None = None,
+    conn: toolsql.AsyncConnection,
+    context: spec.Context = None,
 ) -> int | None:
 
     timestamp_schema = management.get_active_timestamp_schema()
 
     if timestamp_schema == 'block_timestamps':
         return await block_timestamps_statements.async_select_block_timestamp(
             conn=conn,
             block_number=block_number,
-            network=network,
+            context=context,
         )
 
     elif timestamp_schema == 'blocks':
         return await blocks_statements.async_select_block_timestamp(
             conn=conn,
             block_number=block_number,
-            network=network,
+            context=context,
         )
 
     else:
         raise Exception('unknown schema: ' + str(timestamp_schema))
 
 
 async def async_select_block_timestamps(
     block_numbers: typing.Sequence[typing.SupportsInt],
     *,
-    conn: toolsql.SAConnection,
-    network: spec.NetworkReference | None = None,
+    conn: toolsql.AsyncConnection,
+    context: spec.Context = None,
 ) -> list[int | None] | None:
 
     timestamp_schema = management.get_active_timestamp_schema()
 
     if timestamp_schema == 'block_timestamps':
         return await block_timestamps_statements.async_select_block_timestamps(
             conn=conn,
             block_numbers=block_numbers,
-            network=network,
+            context=context,
         )
 
     elif timestamp_schema == 'blocks':
         return await blocks_statements.async_select_block_timestamps(
             conn=conn,
             block_numbers=block_numbers,
-            network=network,
+            context=context,
         )
 
     else:
         raise Exception('unknown schema: ' + str(timestamp_schema))
 
 
 async def async_select_max_block_number(
     *,
-    conn: toolsql.SAConnection,
-    network: spec.NetworkReference | None = None,
+    conn: toolsql.AsyncConnection,
+    context: spec.Context = None,
 ) -> int | None:
 
     timestamp_schema = management.get_active_timestamp_schema()
 
     if timestamp_schema == 'block_timestamps':
         return await block_timestamps_statements.async_select_max_block_number(
             conn=conn,
-            network=network,
+            context=context,
         )
 
     elif timestamp_schema == 'blocks':
         return await blocks_statements.async_select_max_block_number(
             conn=conn,
-            network=network,
+            context=context,
         )
 
     else:
         raise Exception('unknown schema: ' + str(timestamp_schema))
 
 
 async def async_select_max_block_timestamp(
     *,
-    conn: toolsql.SAConnection,
-    network: spec.NetworkReference | None = None,
+    conn: toolsql.AsyncConnection,
+    context: spec.Context = None,
 ) -> int | None:
     timestamp_schema = management.get_active_timestamp_schema()
 
     if timestamp_schema == 'block_timestamps':
         return (
             await block_timestamps_statements.async_select_max_block_timestamp(
                 conn=conn,
-                network=network,
+                context=context,
             )
         )
 
     elif timestamp_schema == 'blocks':
         return await blocks_statements.async_select_max_block_timestamp(
             conn=conn,
-            network=network,
+            context=context,
         )
 
     else:
         raise Exception('unknown schema: ' + str(timestamp_schema))
+
```

### Comparing `checkthechain-0.3.0/src/ctc/db/schemas/blocks/blocks_intake.py` & `checkthechain-0.3.4/src/ctc/db/schemas/blocks/blocks_intake.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,219 +1,154 @@
 from __future__ import annotations
 
 import typing
 
+from ctc import config
 from ctc import evm
 from ctc import spec
 
 from ... import management
-from ... import connect_utils
 from ... import intake_utils
-from . import blocks_statements
 from ..block_timestamps import block_timestamps_statements
-from ..block_gas import block_gas_statements
-from .. import block_gas
+from ..transactions import transactions_intake
+from . import blocks_statements
 
 if typing.TYPE_CHECKING:
     import toolsql
 
 
-#
-# # singular
-#
-
-
 async def async_intake_block(
-    block: spec.Block,
-    network: spec.NetworkReference,
-) -> None:
-    """intake block and extract relevant information to db tables
-
-    under normal operation should store raw block or block timestamp, noth both
-    """
-
-    # check whether to intake
-    active_schemas = management.get_active_schemas()
-    intake_block_object = active_schemas.get('blocks')
-    intake_block_timestamp = active_schemas.get('block_timestamps')
-    intake_block_gas = active_schemas.get('block_gas')
-
-    # check that block is confirmed
-    if intake_block_object or intake_block_timestamp:
-        if not await intake_utils.async_is_block_fully_confirmed(
-            block=block, network=network
-        ):
-            intake_block_object = False
-            intake_block_timestamp = False
-
-    # insert into databases
-    if intake_block_object or intake_block_timestamp or intake_block_gas:
-        engine = connect_utils.create_engine(
-            schema_name='block_timestamps',
-            network=network,
-        )
-        if engine is None:
-            return
-
-        with engine.begin() as conn:
-            # do not perform these concurrently to prevent deadlocks
-            await _async_intake_block_object(
-                block=block,
-                conn=conn,
-                network=network,
-            )
-            await _async_intake_block_timestamp(
-                block=block,
-                conn=conn,
-                network=network,
-            )
-            await _async_intake_block_gas(
-                block=block,
-                conn=conn,
-                network=network,
-            )
-
-
-async def _async_intake_block_object(
-    block: spec.Block,
     *,
-    network: spec.NetworkReference,
-    conn: toolsql.SAConnection,
+    db_block: spec.DBBlock | None = None,
+    rpc_block: spec.RPCBlock | None = None,
+    context: spec.Context,
 ) -> None:
 
-    await blocks_statements.async_upsert_block(
-        block=block,
-        conn=conn,
-        network=network,
-    )
-
-
-async def _async_intake_block_timestamp(
-    block: spec.Block | None,
-    *,
-    network: spec.NetworkReference,
-    conn: toolsql.SAConnection,
-    block_number: int | None = None,
-    timestamp: int | None = None,
-) -> None:
-
-    # get block_number and timestamp
-    if block_number is None or timestamp is None:
-        if block is None:
-            raise Exception('must specify block or block_number and timestamp')
-        block_number = block['number']
-        timestamp = block['timestamp']
-
-    # store in db
-    await block_timestamps_statements.async_upsert_block_timestamp(
-        conn=conn,
-        block_number=block_number,
-        timestamp=timestamp,
-        network=network,
-    )
-
-
-async def _async_intake_block_gas(
-    block: spec.Block,
-    *,
-    conn: toolsql.SAConnection,
-    network: spec.NetworkReference,
-) -> None:
-
-    if len(block['transactions']) == 0 or isinstance(
-        block['transactions'][0], dict
-    ):
-        await block_gas_statements.async_upsert_median_block_gas_fee(
-            block_number=block['number'],
-            median_gas_fee=evm.compute_median_block_gas_fee(
-                block,
-                normalize=False,
-            ),
-            timestamp=block['timestamp'],
-            conn=conn,
-            network=network,
-        )
-
-
-#
-# # plural
-#
+    if rpc_block is not None and db_block is not None:
+        raise Exception('cannot specify rpc_block and db_block')
+    elif rpc_block is not None:
+        await async_intake_blocks(rpc_blocks=[rpc_block], context=context)
+    elif db_block is not None:
+        await async_intake_blocks(db_blocks=[db_block], context=context)
+    else:
+        raise Exception('must specify rpc_block or db_block')
 
 
 async def async_intake_blocks(
-    blocks: typing.Sequence[spec.Block],
-    network: spec.NetworkReference,
     *,
+    db_blocks: typing.Sequence[spec.DBBlock] | None = None,
+    rpc_blocks: typing.Sequence[spec.RPCBlock] | None = None,
     latest_block_number: int | None = None,
+    blocks_db_transactions: typing.Sequence[spec.DBTransaction] | None = None,
+    context: spec.Context,
 ) -> None:
+    """intake block and extract relevant information to db tables
 
-    if len(blocks) == 0:
-        return
+    under normal operation should store raw block or block timestamp, noth both
+    """
+
+    import toolsql
 
-    # check whether schemas are active
+    # check whether to intake
     active_schemas = management.get_active_schemas()
-    intake_block_objects = active_schemas.get('blocks')
+    intake_blocks = active_schemas.get('blocks')
+    intake_transactions = active_schemas.get('transactions')
     intake_block_timestamps = active_schemas.get('block_timestamps')
-    intake_block_gases = active_schemas.get('block_gas')
 
-    # check which blocks are confirmed
-    confirmed_blocks = await intake_utils.async_filter_fully_confirmed_blocks(
-        blocks=blocks,
-        network=network,
-        latest_block_number=latest_block_number,
-    )
+    # get db blocks
+    if rpc_blocks is not None and db_blocks is not None:
+        raise Exception('should specify only rpc_blocks or db_blocks')
+    if db_blocks is None:
+        if rpc_blocks is None:
+            raise Exception('must specify rpc_blocks or db_blocks')
+        db_blocks = [
+            evm.convert_rpc_block_to_db_block(rpc_block)
+            for rpc_block in rpc_blocks
+        ]
 
-    if intake_block_objects or intake_block_timestamps or intake_block_gases:
-        engine = connect_utils.create_engine(
-            schema_name='block_timestamps',
-            network=network,
-        )
-        if engine is None:
-            return
+    if len(db_blocks) == 0:
+        return
 
-        with engine.begin() as conn:
-            # do not perform these concurrently to prevent deadlocks
-            await _async_intake_block_objects(
-                confirmed_blocks=confirmed_blocks,
-                network=network,
-                conn=conn,
-            )
-            await _async_intake_block_timestamps(
-                confirmed_blocks=confirmed_blocks,
-                network=network,
-                conn=conn,
-            )
-            await _async_intake_blocks_gas(
-                blocks=blocks,
+    # filter unconfirmed blocks
+    db_config = config.get_context_db_config(
+        schema_name='blocks',
+        context=context,
+    )
+    async with toolsql.async_connect(db_config) as conn:
+        filtered_db_blocks = (
+            await intake_utils.async_filter_fully_confirmed_blocks(
+                db_blocks,
+                context=context,
+                latest_block_number=latest_block_number,
                 conn=conn,
-                network=network,
             )
+        )
+    if len(filtered_db_blocks) == 0:
+        return
+    db_blocks = filtered_db_blocks
+    block_numbers = [block['number'] for block in db_blocks]
 
+    # get db_block_transactions
+    if (
+        intake_transactions
+        and blocks_db_transactions is None
+        and rpc_blocks is not None
+    ):
+        import asyncio
 
-async def _async_intake_block_objects(
-    confirmed_blocks: typing.Sequence[spec.Block],
-    *,
-    network: spec.NetworkReference,
-    conn: toolsql.SAConnection,
-) -> None:
-
-    if len(confirmed_blocks) > 0:
-        await blocks_statements.async_upsert_blocks(
-            conn=conn,
-            blocks=confirmed_blocks,
-            network=network,
+        blocks_rpc_transactions: typing.Sequence[spec.RPCTransaction] = [
+            tx  # type: ignore
+            for rpc_block in rpc_blocks
+            for tx in rpc_block['transactions']
+            if rpc_block['number'] in block_numbers
+            and len(rpc_block['transactions']) > 0
+            and isinstance(rpc_block['transactions'][0], dict)
+        ]
+        coroutines = [
+            evm.async_convert_rpc_transaction_to_db_transaction(
+                transaction=tx, context=context
+            )
+            for tx in blocks_rpc_transactions
+        ]
+        blocks_db_transactions = await asyncio.gather(*coroutines)
+
+    # insert into database
+    if intake_blocks or intake_transactions:
+        # do not perform these inserts concurrently to prevent deadlocks
+        db_config = config.get_context_db_config(
+            schema_name='blocks',
+            context=context,
         )
+        async with toolsql.async_connect(db_config) as conn:
+            if intake_blocks:
+                await blocks_statements.async_upsert_blocks(
+                    blocks=db_blocks,
+                    conn=conn,
+                    context=context,
+                )
+            if intake_block_timestamps:
+                await _async_intake_blocks_timestamps(
+                    confirmed_blocks=db_blocks,
+                    context=context,
+                    conn=conn,
+                )
+        if blocks_db_transactions is not None and intake_transactions:
+            await transactions_intake.async_intake_blocks_transactions(
+                block_numbers=block_numbers,
+                transactions=blocks_db_transactions,
+                context=context,
+            )
 
 
-async def _async_intake_block_timestamps(
-    confirmed_blocks: typing.Sequence[spec.Block] | None = None,
+async def _async_intake_blocks_timestamps(
+    confirmed_blocks: typing.Sequence[spec.DBBlock] | None = None,
     *,
     confirmed_block_timestamps: typing.Mapping[int, int] | None = None,
-    network: spec.NetworkReference,
-    conn: toolsql.SAConnection,
+    context: spec.Context,
+    conn: toolsql.AsyncConnection,
 ) -> None:
 
     if confirmed_blocks is not None and confirmed_block_timestamps is not None:
         raise Exception('cannot specify both blocks and block_timestamps')
 
     # determine timestamps
     if confirmed_blocks is not None:
@@ -224,41 +159,166 @@
         raise Exception('specify either blocks or block_timestamps')
 
     # store in database
     if len(confirmed_block_timestamps) > 0:
         await block_timestamps_statements.async_upsert_block_timestamps(
             conn=conn,
             block_timestamps=confirmed_block_timestamps,
+            context=context,
         )
 
 
-async def _async_intake_blocks_gas(
-    blocks: typing.Sequence[spec.Block],
-    *,
-    conn: toolsql.SAConnection,
-    network: spec.NetworkReference,
-) -> None:
+#
+# # singular
+#
+
+
+# async def async_intake_block(
+#     *,
+#     db_block: spec.DBBlock | None = None,
+#     rpc_block: spec.RPCBlock | None = None,
+#     context: spec.Context,
+# ) -> None:
+#     """intake block and extract relevant information to db tables
+
+#     under normal operation should store raw block or block timestamp, noth both
+#     """
+
+#     if rpc_block is not None and db_block is not None:
+#         raise Exception('should specify only rpc_block or db_block')
+#     if db_block is None:
+#         if rpc_block is None:
+#             raise Exception('must specify rpc_block or db_block')
+#         else:
+#             db_block = evm.block_utils.block_crud._rpc_block_to_db_block(
+#                 rpc_block
+#             )
+#             transactions = rpc_block['transactions']
+#     else:
+#         transactions = None
+
+#     # check whether to intake
+#     active_schemas = management.get_active_schemas()
+#     intake_block_object = active_schemas.get('blocks')
+#     intake_transactions = active_schemas.get('transactions')
+
+#     # check that block is confirmed
+#     if not await intake_utils.async_is_block_fully_confirmed(
+#         block=db_block['number'], context=context
+#     ):
+#         return
+
+#     # insert into databases
+#     if intake_block_object or intake_transactions:
+#         engine = connect_utils.create_engine(
+#             schema_name='block_timestamps',
+#             context=context,
+#         )
+#         if engine is None:
+#             return
+
+#         with engine.begin() as conn:
+#             # do not perform these concurrently to prevent deadlocks
+#             await blocks_statements.async_upsert_block(
+#                 block=db_block,
+#                 conn=conn,
+#                 context=context,
+#             )
+#             if transactions is not None and active_schemas.get('transactions'):
+#                 transactions = [
+#                     tx for tx in transactions if isinstance(tx, dict)
+#                 ]
+#                 if len(transactions) > 0:
+#                     await _async_intake_block_transactions(
+#                         transactions=transactions,
+#                         block_number=db_block['number'],
+#                         conn=conn,
+#                         context=context,
+#                     )
+
+
+# async def _async_intake_block_timestamp(
+#     block: spec.DBBlock | None,
+#     *,
+#     context: spec.Context,
+#     conn: toolsql.SAConnection,
+#     block_number: int | None = None,
+#     timestamp: int | None = None,
+# ) -> None:
+
+#     # get block_number and timestamp
+#     if block_number is None or timestamp is None:
+#         if block is None:
+#             raise Exception('must specify block or block_number and timestamp')
+#         block_number = block['number']
+#         timestamp = block['timestamp']
+
+#     # store in db
+#     await block_timestamps_statements.async_upsert_block_timestamp(
+#         conn=conn,
+#         block_number=block_number,
+#         timestamp=timestamp,
+#         context=context,
+#     )
+
+#
+# # plural
+#
+
+
+# async def async_intake_blocks(
+#     blocks: typing.Sequence[spec.DBBlock | spec.RPCBlock],
+#     *,
+#     context: spec.Context,
+#     latest_block_number: int | None = None,
+# ) -> None:
+
+#     if len(blocks) == 0:
+#         return
+
+#     # check whether schemas are active
+#     active_schemas = management.get_active_schemas()
+#     intake_block_objects = active_schemas.get('blocks')
+#     intake_block_timestamps = active_schemas.get('block_timestamps')
+#     intake_block_gases = active_schemas.get('block_gas')
+
+#     # check which blocks are confirmed
+#     confirmed_blocks = await intake_utils.async_filter_fully_confirmed_blocks(
+#         blocks=blocks,
+#         context=context,
+#         latest_block_number=latest_block_number,
+#     )
+
+#     if len(confirmed_blocks) == 0:
+#         return
+
+#     # convert to db blocks
+#     db_blocks = [
+#         evm.block_utils.block_crud._rpc_block_to_db_block(block)
+#         for block in confirmed_blocks
+#     ]
+
+#     if intake_block_objects or intake_block_timestamps or intake_block_gases:
+#         engine = connect_utils.create_engine(
+#             schema_name='block_timestamps',
+#             context=context,
+#         )
+#         if engine is None:
+#             return
+
+#         with engine.begin() as conn:
+#             # do not perform these concurrently to prevent deadlocks
+#             await blocks_statements.async_upsert_blocks(
+#                 conn=conn,
+#                 blocks=db_blocks,
+#                 context=context,
+#             )
+#             await _async_intake_block_timestamps(
+#                 confirmed_blocks=db_blocks,
+#                 context=context,
+#                 conn=conn,
+#             )
+#         await async_intake_blocks_transactions(
+#             blocks=db_blocks,
+#             context=context,
+#         )
 
-    # only perform on blocks that have full transactions included
-    blocks_gas_data: typing.MutableSequence[block_gas.BlockGasRow] = []
-    for block in blocks:
-        if len(block['transactions']) == 0 or isinstance(
-            block['transactions'][0], dict
-        ):
-            fee = evm.compute_median_block_gas_fee(
-                block,
-                normalize=False,
-            )
-            block_gas_data: block_gas.BlockGasRow = {
-                'block_number': block['number'],
-                'timestamp': block['timestamp'],
-                'median_gas_fee': fee,
-            }
-            blocks_gas_data.append(block_gas_data)
-
-    # insert into db
-    if len(blocks_gas_data) > 0:
-        await block_gas_statements.async_upsert_median_blocks_gas_fees(
-            block_gas_data=blocks_gas_data,
-            conn=conn,
-            network=network,
-        )
```

### Comparing `checkthechain-0.3.0/src/ctc/db/schemas/blocks/blocks_schema_defs.py` & `checkthechain-0.3.4/src/ctc/db/schemas/dex_pools/dex_pools_schema_defs.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,34 +1,28 @@
 from __future__ import annotations
 
 import toolsql
 
-
-blocks_schema: toolsql.DBSchema = {
+dex_pools_schema: toolsql.DBSchemaShorthand = {
     'tables': {
-        'blocks': {
+        'dex_pools': {
+            'columns': [
+                {'name': 'address', 'type': 'Text', 'primary': True},
+                {'name': 'factory', 'type': 'Text', 'index': True},
+                {'name': 'asset0', 'type': 'Text', 'index': True},
+                {'name': 'asset1', 'type': 'Text', 'index': True},
+                {'name': 'asset2', 'type': 'Text', 'index': True},
+                {'name': 'asset3', 'type': 'Text', 'index': True},
+                {'name': 'creation_block', 'type': 'Integer', 'index': True},
+                {'name': 'fee', 'type': 'Integer'},
+                {'name': 'additional_data', 'type': 'JSON'},
+                {'name': 'priority', 'type': 'Integer', 'index': True},
+            ],
+        },
+        'dex_pool_factory_queries': {
             'columns': [
-                {'name': 'base_fee_per_gas', 'type': 'Text'},
-                {'name': 'difficulty', 'type': 'Integer'},
-                {'name': 'extra_data', 'type': 'Text'},
-                {'name': 'gas_limit', 'type': 'Integer'},
-                {'name': 'gas_used', 'type': 'Integer'},
-                {'name': 'hash', 'type': 'Text', 'index': True},
-                {'name': 'logs_bloom', 'type': 'Text'},
-                {'name': 'miner', 'type': 'Text'},
-                {'name': 'mix_hash', 'type': 'Text'},
-                {'name': 'nonce', 'type': 'Text'},
-                {'name': 'number', 'type': 'Integer', 'primary': True},
-                {'name': 'parent_hash', 'type': 'Text'},
-                {'name': 'receipts_root', 'type': 'Text'},
-                {'name': 'sha3_uncles', 'type': 'Text'},
-                {'name': 'size', 'type': 'Integer'},
-                {'name': 'state_root', 'type': 'Text'},
-                {'name': 'timestamp', 'type': 'Integer', 'index': True},
-                {'name': 'total_difficulty', 'type': 'Text'},
-                {'name': 'transactions', 'type': 'JSON'},
-                {'name': 'transactions_root', 'type': 'Text'},
-                {'name': 'uncles', 'type': 'JSON'},
+                {'name': 'factory', 'type': 'Text', 'primary': True},
+                {'name': 'last_scanned_block', 'type': 'Integer'},
             ],
         },
     },
 }
```

### Comparing `checkthechain-0.3.0/src/ctc/db/schemas/blocks/blocks_statements.py` & `checkthechain-0.3.4/src/ctc/db/schemas/blocks/blocks_statements.py`

 * *Files 20% similar despite different names*

```diff
@@ -4,172 +4,162 @@
 
 import toolsql
 
 from ctc import spec
 from ... import schema_utils
 
 
-def _remove_block_transactions(block: spec.Block) -> spec.Block:
-    txs = block['transactions']
-    if len(txs) > 0 and isinstance(txs[0], dict):
-        if typing.TYPE_CHECKING:
-            full_txs = typing.cast(list[spec.Transaction], txs)
-        else:
-            full_txs = txs
-        tx_hashes = [tx['hash'] for tx in full_txs]
-        return dict(block, transactions=tx_hashes)  # type: ignore
-    else:
-        return block
+def _prepare_block_for_db(
+    block: spec.DBBlock,
+) -> typing.Mapping[str, typing.Any]:
+
+    # remove extra keys
+    extra_keys = ['send_root', 'l1_block_number', 'send_count', 'transactions']
+    if any(key in block for key in extra_keys):
+        block = block.copy()
+        for key in extra_keys:
+            if key in block:
+                del block[key]  # type: ignore
+    return block
 
 
 async def async_upsert_block(
     *,
-    block: spec.Block,
-    conn: toolsql.SAConnection,
-    network: spec.NetworkReference,
+    block: spec.DBBlock,
+    conn: toolsql.AsyncConnection,
+    context: spec.Context,
 ) -> None:
 
-    table = schema_utils.get_table_name('blocks', network=network)
-    block = _remove_block_transactions(block)
-    toolsql.insert(
+    table = schema_utils.get_table_schema('blocks', context=context)
+    ready_block = _prepare_block_for_db(block)
+    await toolsql.async_insert(
         conn=conn,
         table=table,
-        row=block,
-        upsert='do_update',
+        row=ready_block,
+        upsert=True,
     )
 
 
 async def async_upsert_blocks(
     *,
-    blocks: typing.Sequence[spec.Block],
-    conn: toolsql.SAConnection,
-    network: spec.NetworkReference,
+    blocks: typing.Sequence[spec.DBBlock],
+    conn: toolsql.AsyncConnection,
+    context: spec.Context,
 ) -> None:
 
-    table = schema_utils.get_table_name('blocks', network=network)
-    blocks = [_remove_block_transactions(block) for block in blocks]
-    toolsql.insert(
+    table = schema_utils.get_table_schema('blocks', context=context)
+    ready_blocks = [_prepare_block_for_db(block) for block in blocks]
+    await toolsql.async_insert(
         conn=conn,
         table=table,
-        rows=blocks,
-        upsert='do_update',
+        rows=ready_blocks,
+        upsert=True,
     )
 
 
 async def async_select_block(
     block_number: int | str,
     *,
-    conn: toolsql.SAConnection,
-    network: spec.NetworkReference,
-) -> spec.Block | None:
+    conn: toolsql.AsyncConnection,
+    context: spec.Context,
+) -> spec.DBBlock | None:
 
-    table = schema_utils.get_table_name('blocks', network=network)
+    table = schema_utils.get_table_schema('blocks', context=context)
 
-    block: spec.Block | None = toolsql.select(
+    block: spec.DBBlock | None = await toolsql.async_select(  # type: ignore
         conn=conn,
         table=table,
         where_equals={'number': block_number},
-        return_count='one',
-        raise_if_table_dne=False,
+        output_format='single_dict_or_none',
     )
 
-    if block is not None and block['base_fee_per_gas'] is None:
-        del block['base_fee_per_gas']
-    else:
-        if block is not None and block['base_fee_per_gas'] is not None:
-            block['base_fee_per_gas'] = int(block['base_fee_per_gas'])
-
     return block
 
 
 async def async_select_blocks(
     block_numbers: typing.Sequence[int | str] | None = None,
     *,
     start_block: int | None = None,
     end_block: int | None = None,
-    conn: toolsql.SAConnection,
-    network: spec.NetworkReference,
-) -> typing.Sequence[spec.Block | None] | None:
+    conn: toolsql.AsyncConnection,
+    context: spec.Context,
+) -> typing.Sequence[spec.DBBlock | None] | None:
 
-    table = schema_utils.get_table_name('blocks', network=network)
+    table = schema_utils.get_table_schema('blocks', context=context)
 
     if block_numbers is not None:
-        blocks = toolsql.select(
+        blocks = await toolsql.async_select(
             conn=conn,
             table=table,
             where_in={'number': block_numbers},
-            raise_if_table_dne=False,
         )
 
     elif start_block is not None and end_block is not None:
-        blocks = toolsql.select(
+        blocks = await toolsql.async_select(
             conn=conn,
             table=table,
             where_gte={'number': start_block},
             where_lte={'number': end_block},
-            raise_if_table_dne=False,
         )
         block_numbers = range(start_block, end_block + 1)
 
     else:
         raise Exception(
             'must specify block_numbers or start_block and end_block'
         )
 
     if blocks is None:
         return None
 
     for block in blocks:
-        if block is not None and block['base_fee_per_gas'] is None:
-            del block['base_fee_per_gas']
-        else:
+        if block is not None and block['base_fee_per_gas'] is not None:
             block['base_fee_per_gas'] = int(block['base_fee_per_gas'])
 
     blocks_by_number = {
         block['number']: block for block in blocks if block is not None
     }
 
-    return [blocks_by_number.get(number) for number in block_numbers]
+    return [blocks_by_number.get(number) for number in block_numbers]  # type: ignore
 
 
 async def async_delete_block(
     block_number: int | str,
     *,
-    conn: toolsql.SAConnection,
-    network: spec.NetworkReference,
+    conn: toolsql.AsyncConnection,
+    context: spec.Context,
 ) -> None:
 
-    table = schema_utils.get_table_name('blocks', network=network)
+    table = schema_utils.get_table_schema('blocks', context=context)
 
-    toolsql.delete(
+    await toolsql.async_delete(
         conn=conn,
         table=table,
         where_equals={'number': block_number},
     )
 
 
 async def async_delete_blocks(
     block_numbers: typing.Sequence[int | str] | None = None,
     *,
     start_block: int | None = None,
     end_block: int | None = None,
-    conn: toolsql.SAConnection,
-    network: spec.NetworkReference,
+    conn: toolsql.AsyncConnection,
+    context: spec.Context,
 ) -> None:
 
-    table = schema_utils.get_table_name('blocks', network=network)
+    table = schema_utils.get_table_schema('blocks', context=context)
 
     if block_numbers is not None:
-        toolsql.delete(
+        await toolsql.async_delete(
             conn=conn,
             table=table,
             where_in={'number': block_numbers},
         )
     elif start_block is not None and end_block is not None:
-        toolsql.delete(
+        await toolsql.async_delete(
             conn=conn,
             table=table,
             where_gte={'number': start_block},
             where_lte={'number': end_block},
         )
     else:
         raise Exception(
@@ -181,50 +171,47 @@
 # # do not export these functions
 #
 
 
 async def async_select_block_timestamp(
     block_number: int,
     *,
-    conn: toolsql.SAConnection,
-    network: spec.NetworkReference | None = None,
+    conn: toolsql.AsyncConnection,
+    context: spec.Context = None,
 ) -> int | None:
 
-    table = schema_utils.get_table_name('blocks', network=network)
+    table = schema_utils.get_table_schema('blocks', context=context)
 
-    result = toolsql.select(
+    result = await toolsql.async_select(
         conn=conn,
         table=table,
         where_equals={'number': block_number},
-        row_format='only_column',
-        only_columns=['timestamp'],
-        return_count='one',
-        raise_if_table_dne=False,
+        columns=['timestamp'],
+        output_format='cell_or_none',
     )
     if result is not None and not isinstance(result, int):
         raise Exception('invalid db result')
     return result
 
 
 async def async_select_block_timestamps(
     block_numbers: typing.Sequence[typing.SupportsInt],
     *,
-    conn: toolsql.SAConnection,
-    network: spec.NetworkReference | None = None,
+    conn: toolsql.AsyncConnection,
+    context: spec.Context = None,
 ) -> list[int | None] | None:
 
-    table = schema_utils.get_table_name('blocks', network=network)
+    table = schema_utils.get_table_schema('blocks', context=context)
 
     block_numbers_int = [int(item) for item in block_numbers]
 
-    results = toolsql.select(
+    results = await toolsql.async_select(
         conn=conn,
         table=table,
         where_in={'number': block_numbers_int},
-        raise_if_table_dne=False,
     )
 
     if results is None:
         return None
 
     block_timestamps = {
         row['number']: row['timestamp'] for row in results if row is not None
@@ -233,52 +220,46 @@
     return [
         block_timestamps.get(block_number) for block_number in block_numbers
     ]
 
 
 async def async_select_max_block_number(
     *,
-    conn: toolsql.SAConnection,
-    network: spec.NetworkReference | None = None,
+    conn: toolsql.AsyncConnection,
+    context: spec.Context = None,
 ) -> int | None:
 
-    table = schema_utils.get_table_name('blocks', network=network)
-    result = toolsql.select(
+    table = schema_utils.get_table_schema('blocks', context=context)
+    result = await toolsql.async_select(
         conn=conn,
         table=table,
-        sql_functions=[
-            ['max', 'number'],
-        ],
-        return_count='one',
-        raise_if_table_dne=False,
+        columns=['max(number)'],
+        output_format='cell',
     )
     if result is not None:
         output = result['max__block_number']
         if output is not None and not isinstance(output, int):
             raise Exception('invalid db result')
         return output
     else:
         return None
 
 
 async def async_select_max_block_timestamp(
     *,
-    conn: toolsql.SAConnection,
-    network: spec.NetworkReference | None = None,
+    conn: toolsql.AsyncConnection,
+    context: spec.Context = None,
 ) -> int | None:
 
-    table = schema_utils.get_table_name('blocks', network=network)
-    result = toolsql.select(
+    table = schema_utils.get_table_schema('blocks', context=context)
+    result = await toolsql.async_select(
         conn=conn,
         table=table,
-        sql_functions=[
-            ['max', 'timestamp'],
-        ],
-        return_count='one',
-        raise_if_table_dne=False,
+        columns=['max(number)'],
+        output_format='cell',
     )
     if result is None:
         return None
     else:
         max_timestamp = result['max__timestamp']
         if max_timestamp is not None and not isinstance(max_timestamp, int):
             raise Exception('invalid db output')
@@ -289,7 +270,8 @@
     'async_upsert_block',
     'async_upsert_blocks',
     'async_select_block',
     'async_select_blocks',
     'async_delete_block',
     'async_delete_blocks',
 )
+
```

### Comparing `checkthechain-0.3.0/src/ctc/db/schemas/contract_abis/contract_abis_intake.py` & `checkthechain-0.3.4/src/ctc/db/schemas/contract_abis/contract_abis_intake.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,41 +1,42 @@
 from __future__ import annotations
 
+import toolsql
+
+from ctc import config
 from ctc import spec
-from ... import connect_utils
 from ... import management
 
 from . import contract_abis_statements
 
 
 async def async_intake_contract_abi(
     abi: spec.ContractABI,
     contract_address: spec.Address,
     *,
-    network: spec.NetworkReference,
-    # block: int,
+    context: spec.Context = None,
     includes_proxy: bool,
 ) -> None:
     """block age not checked because abis are not usually acquired from reorg-ably young blocks"""
 
     # validate input format
     if not isinstance(abi, list):
         raise Exception('bad format for contract abi')
     if any(not isinstance(item, dict) for item in abi):
         raise Exception('bad format for contract abi')
 
     if not management.get_active_schemas().get('contract_abis'):
         return
 
-    engine = connect_utils.create_engine(
+    db_config = config.get_context_db_config(
         schema_name='contract_abis',
-        network=network,
+        context=context,
     )
-    if engine is not None:
-        with engine.begin() as conn:
-            await contract_abis_statements.async_upsert_contract_abi(
-                address=contract_address,
-                abi=abi,
-                includes_proxy=includes_proxy,
-                conn=conn,
-                network=network,
-            )
+    async with toolsql.async_connect(db_config) as conn:
+        await contract_abis_statements.async_upsert_contract_abi(
+            address=contract_address,
+            abi=abi,
+            includes_proxy=includes_proxy,
+            conn=conn,
+            context=context,
+        )
+
```

### Comparing `checkthechain-0.3.0/src/ctc/db/schemas/contract_abis/contract_abis_statements.py` & `checkthechain-0.3.4/src/ctc/evm/abi_utils/contract_abi_utils/contract_abi_io.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,108 +1,79 @@
 from __future__ import annotations
 
-import json
-import typing
-
-import toolsql
-
 from ctc import spec
-from ... import schema_utils
-
 
-async def async_upsert_contract_abi(
-    *,
-    address: spec.Address,
-    abi: spec.ContractABI,
-    includes_proxy: bool,
-    conn: toolsql.SAConnection,
-    network: spec.NetworkReference | None = None,
-) -> None:
-
-    abi_text = json.dumps(abi)
-
-    table = schema_utils.get_table_name('contract_abis', network=network)
-    toolsql.insert(
-        conn=conn,
-        table=table,
-        row={
-            'address': address.lower(),
-            'abi_text': abi_text,
-            'includes_proxy': includes_proxy,
-        },
-        upsert='do_update',
-    )
-
-
-async def async_select_contract_abi(
-    address: spec.Address,
-    *,
-    network: spec.NetworkReference | None = None,
-    conn: toolsql.SAConnection,
-) -> spec.ContractABI | None:
-
-    table = schema_utils.get_table_name(
-        'contract_abis',
-        network=network,
-    )
-    abi_text = toolsql.select(
-        conn=conn,
-        table=table,
-        row_id=address.lower(),
-        return_count='one',
-        only_columns=['abi_text'],
-        row_format='only_column',
-        raise_if_table_dne=False,
-    )
-    if abi_text is not None:
-        contract_abi: spec.ContractABI = json.loads(abi_text)
-        return contract_abi
-    else:
-        return None
+from ... import contract_utils
+from . import contract_abi_modification
 
 
-async def async_select_contract_abis(
-    addresses: typing.Sequence[spec.Address] | None = None,
+async def async_get_contract_abi(
+    contract_address: spec.Address,
     *,
-    network: spec.NetworkReference | None = None,
-    conn: toolsql.SAConnection,
-) -> typing.Mapping[spec.Address, spec.ContractABI] | None:
-
-    table = schema_utils.get_table_name(
-        'contract_abis',
-        network=network,
-    )
-
-    if addresses is not None:
-        where_in = {'address': addresses}
-    else:
-        where_in = None
-    results = toolsql.select(
-        conn=conn,
-        table=table,
-        where_in=where_in,
-        raise_if_table_dne=False,
-    )
-
-    if results is None:
-        return None
+    block: spec.BlockNumberReference | None = None,
+    proxy_implementation: spec.Address | None = None,
+    verbose: bool = True,
+    context: spec.Context = None,
+) -> spec.ContractABI:
+    """retrieve abi of contract either from local database or block explorer
+
+    for addresses that change ABI's over time, use db_query=False to skip cache
+    """
+    from ctc import config
+
+    # load from db
+    read_cache, write_cache = config.get_context_cache_read_write(
+        context=context, schema_name='contract_abis'
+    )
+    if read_cache:
+        from ctc import db
+
+        abi = await db.async_query_contract_abi(
+            address=contract_address,
+            context=context,
+        )
+        if abi is not None:
+            return abi
+
+    from ctc.protocols import etherscan_utils
+
+    # load from block explorer
+    abi = await etherscan_utils.async_get_contract_abi(
+        contract_address,
+        context=context,
+        verbose=verbose,
+    )
+
+    # get proxy implementation
+    if proxy_implementation is None:
+        proxy_implementation = (
+            await contract_utils.async_get_proxy_implementation(
+                contract_address=contract_address,
+                context=context,
+                block=block,
+            )
+        )
+
+    # get proxy abi
+    includes_proxy = False
+    if proxy_implementation is not None:
+        proxy_abi = await etherscan_utils.async_get_contract_abi(
+            contract_address=proxy_implementation,
+            context=context,
+            verbose=verbose,
+        )
+        abi = contract_abi_modification.combine_contract_abis([abi, proxy_abi])
+        includes_proxy = True
+
+    # save to db
+    if write_cache:
+        from ctc import db
+
+        await db.async_intake_contract_abi(
+            contract_address=contract_address,
+            context=context,
+            abi=abi,
+            includes_proxy=includes_proxy,
+        )
 
-    return {
-        result['address']: json.loads(result['abi_text']) for result in results
-    }
+    return abi
 
-
-async def async_delete_contract_abi(
-    address: spec.Address,
-    *,
-    conn: toolsql.SAConnection,
-    network: spec.NetworkReference | None = None,
-) -> None:
-    table = schema_utils.get_table_name(
-        'contract_abis',
-        network=network,
-    )
-    toolsql.delete(
-        conn=conn,
-        table=table,
-        row_id=address.lower(),
-    )
```

### Comparing `checkthechain-0.3.0/src/ctc/db/schemas/contract_creation_blocks/contract_creation_blocks_statements.py` & `checkthechain-0.3.4/src/ctc/db/schemas/contract_creation_blocks/contract_creation_blocks_statements.py`

 * *Files 12% similar despite different names*

```diff
@@ -8,86 +8,81 @@
 from ... import schema_utils
 
 
 async def async_upsert_contract_creation_block(
     *,
     address: spec.Address,
     block_number: int,
-    network: spec.NetworkReference | None = None,
-    conn: toolsql.SAConnection,
+    context: spec.Context = None,
+    conn: toolsql.AsyncConnection,
 ) -> None:
 
-    table = schema_utils.get_table_name(
-        'contract_creation_blocks', network=network
+    table = schema_utils.get_table_schema(
+        'contract_creation_blocks', context=context
     )
-    toolsql.insert(
+    await toolsql.async_insert(
         conn=conn,
         table=table,
         row={
             'address': address.lower(),
             'block_number': block_number,
         },
-        upsert='do_update',
+        upsert=True,
     )
 
 
 async def async_select_contract_creation_block(
     address: spec.Address,
     *,
-    network: spec.NetworkReference | None = None,
-    conn: toolsql.SAConnection,
+    context: spec.Context = None,
+    conn: toolsql.AsyncConnection,
 ) -> int | None:
 
-    table = schema_utils.get_table_name(
+    table = schema_utils.get_table_schema(
         'contract_creation_blocks',
-        network=network,
+        context=context,
     )
-    result = toolsql.select(
+    result = await toolsql.async_select(
         conn=conn,
         table=table,
-        row_id=address.lower(),
-        return_count='one',
-        only_columns=['block_number'],
-        row_format='only_column',
-        raise_if_table_dne=False,
+        where_equals={'address': address.lower()},
+        columns=['block_number'],
+        output_format='cell_or_none',
     )
 
     if result is not None and not isinstance(result, int):
         raise Exception('invalid db result')
 
     return result
 
 
 async def async_select_contract_creation_blocks(
     *,
-    network: spec.NetworkReference | None = None,
-    conn: toolsql.SAConnection,
+    context: spec.Context = None,
+    conn: toolsql.AsyncConnection,
 ) -> typing.Sequence[typing.Mapping[str, typing.Any]] | None:
-    table = schema_utils.get_table_name(
+    table = schema_utils.get_table_schema(
         'contract_creation_blocks',
-        network=network,
-    )
-    result: typing.Sequence[
-        typing.Mapping[str, typing.Any]
-    ] | None = toolsql.select(
-        conn=conn,
-        table=table,
-        raise_if_table_dne=False,
+        context=context,
     )
+    result: typing.Sequence[typing.Mapping[str, typing.Any]] | None
+    result = await toolsql.async_select(conn=conn, table=table)
+
     return result
 
 
 async def async_delete_contract_creation_block(
     address: spec.Address,
     *,
-    network: spec.NetworkReference | None = None,
-    conn: toolsql.SAConnection,
+    context: spec.Context = None,
+    conn: toolsql.AsyncConnection,
 ) -> None:
-    table = schema_utils.get_table_name(
+    table = schema_utils.get_table_schema(
         'contract_creation_blocks',
-        network=network,
+        context=context,
     )
-    toolsql.delete(
+    await toolsql.async_delete(
         conn=conn,
         table=table,
-        row_id=address.lower(),
+        where_equals={'address': address.lower()},
     )
+
```

### Comparing `checkthechain-0.3.0/src/ctc/db/schemas/dex_pools/dex_pools_intake.py` & `checkthechain-0.3.4/src/ctc/db/schemas/dex_pools/dex_pools_intake.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,22 +1,24 @@
 from __future__ import annotations
 
 import typing
 
+import toolsql
+
+from ctc import config
 from ctc import spec
-from ... import connect_utils
 from . import dex_pools_statements
 
 
 async def async_intake_dex_pools(
     *,
     factory: spec.Address,
     dex_pools: typing.Sequence[spec.DexPool],
-    network: spec.NetworkReference,
     last_scanned_block: int | None = None,
+    context: spec.Context = None,
 ) -> None:
     """intake dex pools into database
 
     - this function should always be provided with the complete set of dex pools
         that have been created since the previous last_scanned_block
     - all dex pools should have the same factory
     """
@@ -30,25 +32,23 @@
     if last_scanned_block is None:
         if len(dex_pools) == 0:
             return
         last_scanned_block = max(
             dex_pool['creation_block'] for dex_pool in dex_pools
         )
 
-    engine = connect_utils.create_engine(
+    db_config = config.get_context_db_config(
         schema_name='dex_pools',
-        network=network,
+        context=context,
     )
-    if engine is None:
-        return None
-    with engine.begin() as conn:
+    async with toolsql.async_connect(db_config) as conn:
         await dex_pools_statements.async_upsert_dex_pools(
             dex_pools=dex_pools,
             conn=conn,
-            network=network,
+            context=context,
         )
         await dex_pools_statements.async_upsert_dex_pool_factory_query(
             factory=factory,
             last_scanned_block=last_scanned_block,
             conn=conn,
-            network=network,
+            context=context,
         )
```

### Comparing `checkthechain-0.3.0/src/ctc/db/schemas/dex_pools/dex_pools_queries.py` & `checkthechain-0.3.4/src/ctc/db/schemas/dex_pools/dex_pools_queries.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/db/schemas/dex_pools/dex_pools_statements.py` & `checkthechain-0.3.4/src/ctc/db/schemas/dex_pools/dex_pools_statements.py`

 * *Files 22% similar despite different names*

```diff
@@ -13,155 +13,153 @@
     formatted = copy.copy(dex_pool)
     return formatted
 
 
 async def async_upsert_dex_pool(
     *,
     dex_pool: spec.DexPool,
-    conn: toolsql.SAConnection,
-    network: spec.NetworkReference,
+    conn: toolsql.AsyncConnection,
+    context: spec.Context,
 ) -> None:
-    table = schema_utils.get_table_name('dex_pools', network=network)
+    table = schema_utils.get_table_schema('dex_pools', context=context)
     dex_pool = _format_dex_pool(dex_pool)
-    toolsql.insert(
+    await toolsql.async_insert(
         conn=conn,
         table=table,
         row=dex_pool,
-        upsert='do_update',
+        upsert=True,
     )
 
 
 async def async_upsert_dex_pools(
     *,
     dex_pools: typing.Sequence[spec.DexPool],
-    conn: toolsql.SAConnection,
-    network: spec.NetworkReference,
+    conn: toolsql.AsyncConnection,
+    context: spec.Context,
 ) -> None:
     if len(dex_pools) == 0:
         return
-    table = schema_utils.get_table_name('dex_pools', network=network)
+    table = schema_utils.get_table_schema('dex_pools', context=context)
     dex_pools = [_format_dex_pool(dex_pool) for dex_pool in dex_pools]
-    toolsql.insert(
+    await toolsql.async_insert(
         conn=conn,
         table=table,
         rows=dex_pools,
-        upsert='do_update',
+        upsert=True,
     )
 
 
 async def async_upsert_dex_pool_factory_query(
     *,
     factory: spec.Address,
     last_scanned_block: int,
-    conn: toolsql.SAConnection,
-    network: spec.NetworkReference,
+    conn: toolsql.AsyncConnection,
+    context: spec.Context,
 ) -> None:
-    table = schema_utils.get_table_name(
+    table = schema_utils.get_table_schema(
         'dex_pool_factory_queries',
-        network=network,
+        context=context,
     )
-    toolsql.insert(
+    await toolsql.async_insert(
         conn=conn,
         table=table,
         row={
             'factory': factory.lower(),
             'last_scanned_block': last_scanned_block,
         },
-        upsert='do_update',
+        upsert=True,
     )
 
 
 async def async_delete_dex_pool(
     *,
-    conn: toolsql.SAConnection,
+    conn: toolsql.AsyncConnection,
     dex_pool: spec.Address,
-    network: spec.NetworkReference | None = None,
+    context: spec.Context = None,
 ) -> None:
 
-    table = schema_utils.get_table_name('dex_pools', network=network)
+    table = schema_utils.get_table_schema('dex_pools', context=context)
 
-    toolsql.delete(
+    await toolsql.async_delete(
         conn=conn,
         table=table,
         where_equals={'address': dex_pool.lower()},
     )
 
 
 async def async_delete_dex_pools(
     *,
-    conn: toolsql.SAConnection,
+    conn: toolsql.AsyncConnection,
     dex_pools: typing.Sequence[spec.Address],
-    network: spec.NetworkReference | None = None,
+    context: spec.Context = None,
 ) -> None:
 
-    table = schema_utils.get_table_name('dex_pools', network=network)
+    table = schema_utils.get_table_schema('dex_pools', context=context)
 
-    toolsql.delete(
+    await toolsql.async_delete(
         conn=conn,
         table=table,
         where_in={'address': [dex_pool.lower() for dex_pool in dex_pools]},
     )
 
 
 async def async_delete_dex_pool_factory_query(
     *,
-    conn: toolsql.SAConnection,
+    conn: toolsql.AsyncConnection,
     factory: spec.Address,
-    network: spec.NetworkReference | None = None,
+    context: spec.Context = None,
 ) -> None:
 
-    table = schema_utils.get_table_name(
-        'dex_pool_factory_queries', network=network
+    table = schema_utils.get_table_schema(
+        'dex_pool_factory_queries', context=context
     )
 
-    toolsql.delete(
+    await toolsql.async_delete(
         conn=conn,
         table=table,
         where_equals={'factory': factory.lower()},
     )
 
 
 async def async_select_dex_pool(
     address: spec.Address,
     *,
-    conn: toolsql.SAConnection,
-    network: spec.NetworkReference | None = None,
+    conn: toolsql.AsyncConnection,
+    context: spec.Context = None,
 ) -> spec.DexPool | None:
 
-    table = schema_utils.get_table_name('dex_pools', network=network)
+    table = schema_utils.get_table_schema('dex_pools', context=context)
 
     where_equals = {'address': address.lower()}
 
-    result = toolsql.select(
+    result = await toolsql.async_select(
         conn=conn,
         table=table,
         where_equals=where_equals,
-        return_count='one',
-        raise_if_table_dne=False,
+        output_format='single_dict_or_none',
     )
     return result  # type: ignore
 
 
 async def async_select_dex_pools_by_id(
     addresses: typing.Sequence[spec.Address],
     *,
-    conn: toolsql.SAConnection,
-    network: spec.NetworkReference | None = None,
+    conn: toolsql.AsyncConnection,
+    context: spec.Context = None,
 ) -> typing.Mapping[spec.Address, spec.DexPool | None] | None:
     raise NotImplementedError()
 
     if len(addresses) == 0:
         return {}
 
-    table = schema_utils.get_table_name('dex_pools', network=network)
+    table = schema_utils.get_table_schema('dex_pools', context=context)
 
-    results = await toolsql.select(
+    results = await toolsql.async_select(
         conn=conn,
         table=table,
-        raise_if_table_dne=False,
         where_in={'address': addresses},
     )
 
     results_by_address = {
         row['address']: row for row in results if row is not None
     }
 
@@ -169,81 +167,69 @@
 
 
 async def async_select_dex_pools(
     *,
     factory: spec.Address | None = None,
     factories: typing.Sequence[spec.Address] | None = None,
     assets: typing.Sequence[spec.Address] | None = None,
-    conn: toolsql.SAConnection,
-    network: spec.NetworkReference | None = None,
+    conn: toolsql.AsyncConnection,
+    context: spec.Context = None,
     start_block: int | None = None,
     end_block: int | None = None,
 ) -> typing.Sequence[spec.DexPool] | None:
 
-    table = schema_utils.get_table_name('dex_pools', network=network)
+    table = schema_utils.get_table_schema('dex_pools', context=context)
 
     query: typing.MutableMapping[str, typing.Any] = {}
     if factory is not None:
         query.setdefault('where_equals', {})
         query['where_equals']['factory'] = factory
     if factories is not None:
         query.setdefault('where_in', {})
         query['where_in']['factory'] = factories
     if assets is not None:
-        import sqlalchemy  # type: ignore
-
-        # get table object
-        try:
-            sqla_table = toolsql.create_table_object_from_db(
-                table_name=table,
-                conn=conn,
-            )
-        except toolsql.TableNotFound:
-            return None
-
-        query.setdefault('filters', [])
         for asset in assets:
             asset = asset.lower()
-            asset_filter = sqlalchemy.or_(
-                sqla_table.c['asset0'] == asset,
-                sqla_table.c['asset1'] == asset,
-                sqla_table.c['asset2'] == asset,
-                sqla_table.c['asset3'] == asset,
-            )
-            query['filters'].append(asset_filter)
+            query['where_or'] = [
+                {'where_equals': {'asset0': asset}},
+                {'where_equals': {'asset1': asset}},
+                {'where_equals': {'asset2': asset}},
+                {'where_equals': {'asset3': asset}},
+            ]
     if start_block is not None:
         query.setdefault('where_gte', {})
         query['where_gte']['creation_block'] = start_block
     if end_block is not None:
         query.setdefault('where_lte', {})
         query['where_lte']['creation_block'] = end_block
 
-    return toolsql.select(  # type: ignore
-        conn=conn, table=table, raise_if_table_dne=False, **query
+    return await toolsql.async_select(  # type: ignore
+        conn=conn,
+        table=table,
+        **query,
     )
 
 
 async def async_select_dex_pool_factory_last_scanned_block(
     factory: spec.Address,
     *,
-    conn: toolsql.SAConnection,
-    network: spec.NetworkReference,
+    conn: toolsql.AsyncConnection,
+    context: spec.Context,
 ) -> int | None:
 
-    table = schema_utils.get_table_name(
-        'dex_pool_factory_queries', network=network
+    table = schema_utils.get_table_schema(
+        'dex_pool_factory_queries', context=context
     )
 
-    result = toolsql.select(
+    result = await toolsql.async_select(
         conn=conn,
         table=table,
-        raise_if_table_dne=False,
-        row_format='only_column',
-        only_columns=['last_scanned_block'],
-        return_count='one',
+        columns=['last_scanned_block'],
+        output_format='cell_or_none',
         where_equals={'factory': factory.lower()},
     )
 
     if result is None or isinstance(result, int):
         return result
     else:
         raise Exception('bad data format received from db')
+
```

### Comparing `checkthechain-0.3.0/src/ctc/db/schemas/erc20_metadata/erc20_metadata_schema_defs.py` & `checkthechain-0.3.4/src/ctc/db/schemas/erc20_metadata/erc20_metadata_schema_defs.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 from __future__ import annotations
 
 import toolsql
 
 
-erc20_metadata_schema: toolsql.DBSchema = {
+erc20_metadata_schema: toolsql.DBSchemaShorthand = {
     'tables': {
         'erc20_metadata': {
             'columns': [
                 {
                     'name': 'address',
                     'type': 'Text',
                     'primary': True,
```

### Comparing `checkthechain-0.3.0/src/ctc/db/schemas/erc20_metadata/erc20_metadata_statements.py` & `checkthechain-0.3.4/src/ctc/db/schemas/erc20_metadata/erc20_metadata_statements.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,149 +1,141 @@
 from __future__ import annotations
 
 import asyncio
 import typing
 
 import toolsql
 
-from ctc import config
 from ctc import spec
 from ... import schema_utils
 
 
 async def async_upsert_erc20_metadata(
     *,
+    context: spec.Context,
     address: spec.Address,
-    network: spec.NetworkReference,
     symbol: str | None = None,
     decimals: int | None = None,
     name: str | None = None,
     upsert: bool = True,
-    conn: toolsql.SAConnection,
+    conn: toolsql.AsyncConnection,
 ) -> None:
 
     # construct row
     row = {
         'address': address.lower(),
         'symbol': symbol,
         'decimals': decimals,
         'name': name,
     }
     row = {k: v for k, v in row.items() if v is not None}
 
-    # get upsert option
-    if upsert:
-        upsert_option: toolsql.ConflictOption | None = 'do_update'
-    else:
-        upsert_option = None
-
     # get table name
-    table = schema_utils.get_table_name('erc20_metadata', network=network)
+    table = schema_utils.get_table_schema('erc20_metadata', context=context)
 
     # insert data
-    toolsql.insert(
+    await toolsql.async_insert(
         conn=conn,
         table=table,
         row=row,
-        upsert=upsert_option,
+        upsert=upsert,
     )
 
 
 async def async_upsert_erc20s_metadata(
     *,
     erc20s_metadata: typing.Sequence[spec.ERC20Metadata],
-    network: spec.NetworkReference,
-    conn: toolsql.SAConnection,
+    context: spec.Context,
+    conn: toolsql.AsyncConnection,
 ) -> None:
     coroutines = [
-        async_upsert_erc20_metadata(conn=conn, network=network, **metadata)
+        async_upsert_erc20_metadata(conn=conn, context=context, **metadata)
         for metadata in erc20s_metadata
     ]
     await asyncio.gather(*coroutines)
 
 
 async def async_select_erc20_metadata(
     address: spec.Address | None = None,
     *,
     symbol: str | None = None,
     case_insensitive_symbol: bool = False,
-    network: spec.NetworkReference | None = None,
-    conn: toolsql.SAConnection,
+    context: spec.Context | None = None,
+    conn: toolsql.AsyncConnection,
 ) -> spec.ERC20Metadata | None:
 
-    if network is None:
-        network = config.get_default_network()
-
-    table = schema_utils.get_table_name('erc20_metadata', network=network)
+    table = schema_utils.get_table_schema('erc20_metadata', context=context)
 
     if address is not None:
-        query: typing.Mapping[str, typing.Any] = {'row_id': address.lower()}
+        query: typing.Mapping[str, typing.Any] = {
+            'where_equals': {'address': address.lower()}
+        }
     elif symbol is not None:
         if case_insensitive_symbol:
             query = {'where_ilike': {'symbol': symbol}}
         else:
             query = {'where_equals': {'symbol': symbol}}
     else:
         raise Exception('must specify address or symbol')
 
-    erc20_metadata: spec.ERC20Metadata = toolsql.select(
+    erc20_metadata: spec.ERC20Metadata = await toolsql.async_select(  # type: ignore
         conn=conn,
         table=table,
-        row_count='at_most_one',
-        row_format='dict',
-        return_count='one',
-        raise_if_table_dne=False,
+        output_format='single_dict_or_none',
         **query,
     )
 
     return erc20_metadata
 
 
 async def async_select_erc20s_metadata(
     addresses: typing.Sequence[spec.Address],
     *,
-    network: spec.NetworkReference | None = None,
-    conn: toolsql.SAConnection,
+    context: spec.Context | None = None,
+    conn: toolsql.AsyncConnection,
 ) -> typing.Sequence[spec.ERC20Metadata | None] | None:
 
-    if network is None:
-        network = config.get_default_network()
-
-    table = schema_utils.get_table_name('erc20_metadata', network=network)
-    results = toolsql.select(
+    table = schema_utils.get_table_schema('erc20_metadata', context=context)
+    results: typing.Sequence[spec.ERC20Metadata] = await toolsql.async_select(  # type: ignore
         conn=conn,
         table=table,
-        row_ids=[address.lower() for address in addresses],
-        raise_if_table_dne=False,
+        where_in={'address': [address.lower() for address in addresses]},
     )
 
     if results is None:
         return None
 
     # package into output
     results_by_address = {result['address']: result for result in results}
 
     return [results_by_address.get(address) for address in addresses]
 
 
 async def async_delete_erc20_metadata(
     address: spec.Address,
     *,
-    network: spec.NetworkReference,
-    conn: toolsql.SAConnection,
+    context: spec.Context,
+    conn: toolsql.AsyncConnection,
 ) -> None:
-    table = schema_utils.get_table_name('erc20_metadata', network=network)
-    toolsql.delete(table=table, conn=conn, row_id=address.lower())
+
+    table = schema_utils.get_table_schema('erc20_metadata', context=context)
+    await toolsql.async_delete(
+        table=table,
+        conn=conn,
+        where_equals={'address': address.lower()},
+    )
 
 
 async def async_delete_erc20s_metadata(
     addresses: typing.Sequence[spec.Address],
     *,
-    network: spec.NetworkReference,
-    conn: toolsql.SAConnection,
+    context: spec.Context,
+    conn: toolsql.AsyncConnection,
 ) -> None:
-    table = schema_utils.get_table_name('erc20_metadata', network=network)
-    toolsql.delete(
+
+    table = schema_utils.get_table_schema('erc20_metadata', context=context)
+    await toolsql.async_delete(
         table=table,
         conn=conn,
-        row_ids=[address.lower() for address in addresses],
+        where_in={'address': [address.lower() for address in addresses]},
     )
+
```

### Comparing `checkthechain-0.3.0/src/ctc/evm/abi_utils/contract_abi_utils/contract_abi_comparison.py` & `checkthechain-0.3.4/src/ctc/evm/abi_utils/contract_abi_utils/contract_abi_comparison.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/evm/abi_utils/contract_abi_utils/contract_abi_decompilation.py` & `checkthechain-0.3.4/src/ctc/evm/abi_utils/contract_abi_utils/contract_abi_decompilation.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,11 +1,13 @@
 from __future__ import annotations
 
 import typing
 
+from ctc import spec
+
 
 def extract_bytecode_function_selectors(bytecode: str) -> typing.Sequence[str]:
     """extract solidity-style function selectors from contract bytecode"""
     import re
 
     # solidity style signatures
     results = re.findall('8063([a-f0-9]{8})146', bytecode)
@@ -15,31 +17,36 @@
         results = re.findall('5[b,2]63([0-9a-f]{8})600051141561', bytecode)
 
     return ['0x' + result for result in results]
 
 
 async def async_decompile_function_abis(
     bytecode: str,
+    *,
     sort: str | None = None,
+    context: spec.Context = None,
 ) -> typing.Sequence[typing.Mapping[str, typing.Any]]:
     """decompile solidity-style function ABI's from contract bytecode"""
 
     from ctc.protocols import fourbyte_utils
 
     function_selectors = extract_bytecode_function_selectors(bytecode)
 
     coroutines = [
-        fourbyte_utils.async_query_function_signatures(selector)
+        fourbyte_utils.async_query_function_signatures(
+            selector, context=context
+        )
         for selector in function_selectors
     ]
 
     import asyncio
 
     abi_lists = await asyncio.gather(*coroutines)
     abis: list[fourbyte_utils.Entry] = [
         abi for abi_list in abi_lists for abi in abi_list
     ]
 
     if sort is not None:
         abis = sorted(abis, key=lambda item: item[sort])  # type: ignore
 
     return abis
+
```

### Comparing `checkthechain-0.3.0/src/ctc/evm/abi_utils/contract_abi_utils/contract_abi_modification.py` & `checkthechain-0.3.4/src/ctc/evm/abi_utils/contract_abi_utils/contract_abi_modification.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/evm/abi_utils/contract_abi_utils/contract_abi_summary.py` & `checkthechain-0.3.4/src/ctc/evm/abi_utils/contract_abi_utils/contract_abi_summary.py`

 * *Files 2% similar despite different names*

```diff
@@ -284,17 +284,18 @@
     )
 
 
 def contract_abi_to_dataframe(
     contract_abi: spec.ContractABI,
     human_readable: bool,
 ) -> spec.DataFrame:
-    """create pandas DataFrame representation of contract ABI"""
+    """create DataFrame representation of contract ABI"""
 
     import copy
+    import polars as pl
 
     contract_abi = copy.deepcopy(contract_abi)
     for entry in typing.cast(
         typing.List[typing.Dict[str, typing.Any]], contract_abi
     ):
 
         if human_readable:
@@ -330,22 +331,11 @@
 
             if 'anonymous' not in entry:
                 entry['anonymous'] = ''
 
             if 'stateMutability' not in entry:
                 entry['stateMutability'] = ''
 
-    import pandas as pd
-
-    df = pd.DataFrame(contract_abi)
-    df = df.reindex(
-        columns=[
-            'type',
-            'name',
-            'inputs',
-            'outputs',
-            'stateMutability',
-            'anonymous',
-        ]
-    )
+    df = pl.DataFrame(contract_abi)
 
     return df
+
```

### Comparing `checkthechain-0.3.0/src/ctc/evm/abi_utils/event_abi_utils/event_abi_queries.py` & `checkthechain-0.3.4/src/ctc/evm/abi_utils/event_abi_utils/event_abi_queries.py`

 * *Files 12% similar despite different names*

```diff
@@ -26,15 +26,15 @@
     candidates = []
     for item in contract_abi:
         if item['type'] != 'event':
             continue
         if event_name is not None and item.get('name') != event_name:
             continue
         if event_hash is not None:
-            item_hash = event_abi_parsing.get_event_hash(event_abi=item)
+            item_hash = event_abi_parsing.get_event_hash(item)
             if item_hash != event_hash:
                 continue
 
         candidates.append(item)
 
     if len(candidates) == 0:
         raise LookupError('could not find event abi')
@@ -44,46 +44,65 @@
         raise Exception('found too many candidates for event abi')
 
 
 async def async_get_event_abi(
     *,
     contract_abi: typing.Optional[spec.ContractABI] = None,
     contract_address: typing.Optional[spec.Address] = None,
+    contract_addresses: typing.Sequence[spec.Address] | None = None,
     event_name: typing.Optional[str] = None,
     event_hash: typing.Optional[str] = None,
     event_abi: typing.Optional[spec.EventABI] = None,
-    network: typing.Optional[spec.NetworkReference] = None,
+    context: spec.Context = None,
 ) -> spec.EventABI:
     """get event ABI from local database or block explorer"""
 
+    if contract_addresses is not None:
+        for contract_address in contract_addresses:
+            try:
+                return await async_get_event_abi(
+                    contract_abi=contract_abi,
+                    contract_address=contract_address,
+                    event_name=event_name,
+                    event_hash=event_hash,
+                    event_abi=event_abi,
+                    context=context,
+                )
+            except Exception:
+                pass
+        else:
+            raise Exception('could not find event abi')
+
     # get contract abi
     if contract_abi is None:
         if contract_address is None:
             raise Exception('must specify contract_abi or contract_address')
         contract_abi = await contract_abi_utils.async_get_contract_abi(
             contract_address=contract_address,
-            network=network,
+            context=context,
         )
 
+    # get event abi
     try:
         return evm.get_event_abi(
             contract_abi=contract_abi,
             event_name=event_name,
             event_hash=event_hash,
             event_abi=event_abi,
         )
 
     except LookupError as e:
 
+        from ctc import config
+
         # query contract_abi again if contract abi might have changed since db
         if contract_address is not None:
             contract_abi = await contract_abi_utils.async_get_contract_abi(
                 contract_address=contract_address,
-                network=network,
-                db_query=False,
+                context=config.update_context(context=context, cache=False)
             )
 
             return evm.get_event_abi(
                 contract_abi=contract_abi,
                 event_name=event_name,
                 event_hash=event_hash,
                 event_abi=event_abi,
```

### Comparing `checkthechain-0.3.0/src/ctc/evm/abi_utils/function_abi_utils/function_abi_coding.py` & `checkthechain-0.3.4/src/ctc/evm/abi_utils/function_abi_utils/function_abi_coding.py`

 * *Files 3% similar despite different names*

```diff
@@ -32,46 +32,40 @@
     """encode function call data using solidity-style ABI encoding"""
 
     # encode function selector
     if function_selector is None:
         function_selector = function_abi_parsing.get_function_selector(
             function_abi
         )
-    function_selector = binary_utils.binary_convert(
-        function_selector, 'prefix_hex'
-    )
+    function_selector = binary_utils.to_hex(function_selector)
 
     # encode parameters
     if encoded_parameters is None:
         encoded_parameters = encode_function_parameters(
             parameters=parameters,
             parameter_types=parameter_types,
             function_abi=function_abi,
         )
-    encoded_parameters = binary_utils.binary_convert(
-        encoded_parameters, 'raw_hex'
-    )
+    encoded_parameters = binary_utils.to_hex(encoded_parameters, prefix=False)
 
     # join function selector with parameters
     return function_selector + encoded_parameters
 
 
 def decode_call_data(
     call_data: spec.BinaryData,
     function_abi: typing.Optional[spec.FunctionABI] = None,
     *,
     contract_abi: typing.Optional[spec.ContractABI] = None,
 ) -> spec.DecodedCallData:
     """decode function call data using solidity-style ABI decoding"""
 
     # get function selector
-    call_data_bytes = binary_utils.binary_convert(call_data, 'binary')
-    function_selector = binary_utils.binary_convert(
-        call_data_bytes[:4], 'prefix_hex'
-    )
+    call_data_bytes = binary_utils.to_binary(call_data)
+    function_selector = binary_utils.to_hex(call_data_bytes[:4])
 
     # get function abi
     if function_abi is None:
         if contract_abi is None:
             raise Exception('must specify function_abi or contract_abi')
         function_abi = function_abi_queries.get_function_abi(
             contract_abi=contract_abi,
@@ -146,15 +140,15 @@
     # inefficient: convert prefix_hex binary to bytes
     new_parameters = []
     for parameter_type, parameter in zip(parameter_types, parameters):
         if (
             parameter_type == 'bytes32'
             and binary_utils.get_binary_format(parameter) != 'binary'
         ):
-            parameter = binary_utils.binary_convert(parameter, 'binary')
+            parameter = binary_utils.to_binary(parameter)
         new_parameters.append(parameter)
     parameters = new_parameters
 
     # encode
     if len(parameters) != len(parameter_types):
         raise Exception(
             'improper number of arguments for function, cannot encode'
@@ -170,17 +164,15 @@
 def decode_function_parameters(
     encoded_parameters: spec.BinaryData,
     parameter_types: list[spec.ABIDatumType],
 ) -> list[typing.Any]:
     """decode function parameters using solidity-style ABI decoding"""
 
     parameter_types_str = '(' + ','.join(parameter_types) + ')'
-    encoded_parameters = binary_utils.binary_convert(
-        encoded_parameters, 'binary'
-    )
+    encoded_parameters = binary_utils.to_binary(encoded_parameters)
     parameters = abi_coding_utils.abi_decode(
         encoded_parameters, parameter_types_str
     )
 
     return list(parameters)
 
 
@@ -232,27 +224,27 @@
             raise Exception('must specify function_abi')
         output_types = function_abi_parsing.get_function_output_types(
             function_abi
         )
     output_types_str = '(' + ','.join(output_types) + ')'
 
     # decode
-    encoded_output = binary_utils.binary_convert(encoded_output, 'binary')
+    encoded_output = binary_utils.to_binary(encoded_output)
     decoded_output = abi_coding_utils.abi_decode(
         encoded_output, output_types_str
     )
 
     # decode strings
     new_decoded_output = []
     for output_type, item in zip(output_types, decoded_output):
         if output_type == 'string':
             # item = item.decode()
             item = item
         elif output_type == 'bytes32':
-            item = binary_utils.binary_convert(item, 'prefix_hex')
+            item = binary_utils.to_hex(item)
         new_decoded_output.append(item)
     decoded_output = new_decoded_output
 
     # delist
     if delist_single_outputs and len(output_types) == 1:
         decoded_output = decoded_output[0]
 
@@ -261,7 +253,8 @@
         if function_abi is None:
             raise Exception('must specify function_abi')
         names = function_abi_parsing.get_function_output_names(function_abi)
         if all(name is not None for name in names):
             decoded_output = dict(zip(names, decoded_output))
 
     return decoded_output
+
```

### Comparing `checkthechain-0.3.0/src/ctc/evm/abi_utils/function_abi_utils/function_abi_parsing.py` & `checkthechain-0.3.4/src/ctc/evm/abi_utils/function_abi_utils/function_abi_parsing.py`

 * *Files 3% similar despite different names*

```diff
@@ -25,14 +25,16 @@
         'outputs': [],
     }
 
 
 async def async_parse_function_str_abi(
     function: str,
     contract_address: spec.Address | None = None,
+    *,
+    context: spec.Context = None,
 ) -> spec.FunctionABI:
     """parse a function str into a function ABI
 
     function str can be a function name, 4byte selector, or ABI
 
     used for cli commands
     """
@@ -59,14 +61,15 @@
             function_abi = None
 
     if function_abi is None:
         function_abi = await function_abi_queries.async_get_function_abi(
             contract_address=contract_address,
             function_name=function_name,
             function_selector=function_selector,
+            context=context,
         )
 
     return function_abi
 
 
 def get_function_parameter_types(
     function_abi: spec.FunctionABI | None = None,
@@ -181,18 +184,32 @@
     elif datatype == 'fixed':
         return 'fixed128x18'
     else:
         return datatype
 
 
 def get_function_selector(
+    function: spec.FunctionABI | spec.FunctionSignature | None = None,
+    *,
     function_abi: typing.Optional[spec.FunctionABI] = None,
     function_signature: typing.Optional[spec.FunctionSignature] = None,
 ) -> str:
-    """get function 4 byte selector"""
+    """get function 4 byte selector
+
+    TODO: deprecate function_abi and function_signature inputs
+    """
+
+    if isinstance(function, dict):
+        function_abi = function
+    elif isinstance(function, str):
+        function_signature = function
+    elif function is None:
+        assert function_abi is not None or function_signature is not None
+    else:
+        raise Exception('unknown funciton format: ' + str(type(function)))
 
     if function_signature is None:
         if function_abi is None:
             raise Exception('must specify function_abi or function_signature')
         function_signature = get_function_signature(function_abi)
 
     full_hash = binary_utils.keccak(
```

### Comparing `checkthechain-0.3.0/src/ctc/evm/abi_utils/function_abi_utils/function_abi_queries.py` & `checkthechain-0.3.4/src/ctc/evm/abi_utils/function_abi_utils/function_abi_queries.py`

 * *Files 13% similar despite different names*

```diff
@@ -15,17 +15,15 @@
     n_parameters: typing.Optional[int] = None,
     parameter_types: typing.Optional[list[spec.ABIDatumType]] = None,
     function_selector: typing.Optional[spec.FunctionSelector] = None,
 ) -> spec.FunctionABI:
     """get function ABI from contract ABI"""
 
     if function_selector is not None:
-        function_selector = binary_utils.binary_convert(
-            function_selector, 'prefix_hex'
-        )
+        function_selector = binary_utils.to_hex(function_selector)
 
     candidates = []
     for item in contract_abi:
         if item.get('type') != 'function':
             continue
         else:
 
@@ -50,15 +48,15 @@
             )
             if tuple(parameter_types) != tuple(types):
                 continue
         if function_selector is not None:
             item_selector = function_abi_parsing.get_function_selector(
                 function_abi
             )
-            item_selector = binary_utils.binary_convert(item_selector, 'prefix_hex')
+            item_selector = binary_utils.to_hex(item_selector)
             if item_selector != function_selector:
                 continue
         candidates.append(function_abi)
 
     if len(candidates) == 1:
         return candidates[0]
     elif len(candidates) == 0:
@@ -71,32 +69,51 @@
             return candidates[0]
 
         raise LookupError('too many candidates found for function abi')
     else:
         raise Exception('internal error')
 
 
+def sync_get_function_abi(
+    *,
+    function_name: typing.Optional[str] = None,
+    contract_abi: typing.Optional[spec.ContractABI] = None,
+    contract_address: typing.Optional[spec.Address] = None,
+    n_parameters: typing.Optional[int] = None,
+    parameter_types: typing.Optional[list[spec.ABIDatumType]] = None,
+    function_selector: typing.Optional[spec.FunctionSelector] = None,
+    context: spec.Context = None,
+) -> spec.FunctionABI:
+    """get function abi from ABI source"""
+    raise NotImplementedError('sync version of get_function_abi')
+    # necessary functions to replace:
+    # - contract_utils.async_get_proxy_implementation
+    # - etherscan_utils.async_get_contract_abi
+    # - db.async_query_contract_ab
+    # - db.async_intake_contract_abi
+
+
 async def async_get_function_abi(
     *,
     function_name: typing.Optional[str] = None,
     contract_abi: typing.Optional[spec.ContractABI] = None,
     contract_address: typing.Optional[spec.Address] = None,
     n_parameters: typing.Optional[int] = None,
     parameter_types: typing.Optional[list[spec.ABIDatumType]] = None,
     function_selector: typing.Optional[spec.FunctionSelector] = None,
-    network: typing.Optional[spec.NetworkReference] = None,
+    context: spec.Context = None,
 ) -> spec.FunctionABI:
     """get function ABI from local database or block explorer"""
 
     if contract_abi is None:
         if contract_address is None:
             raise Exception('must specify contract_abi or contract_address')
         contract_abi = await contract_abi_utils.async_get_contract_abi(
             contract_address=contract_address,
-            network=network,
+            context=context,
         )
 
     try:
         return get_function_abi(
             function_name=function_name,
             contract_abi=contract_abi,
             n_parameters=n_parameters,
@@ -104,18 +121,22 @@
             function_selector=function_selector,
         )
 
     except LookupError as e:
 
         # query contract_abi again if contract abi might have changed since db
         if contract_address is not None:
+            from ctc import config
+
+            context = config.update_context(
+                context=context, cache={'read': False}
+            )
             contract_abi = await contract_abi_utils.async_get_contract_abi(
                 contract_address=contract_address,
-                network=network,
-                db_query=False,
+                context=context,
             )
 
             return get_function_abi(
                 function_name=function_name,
                 contract_abi=contract_abi,
                 n_parameters=n_parameters,
                 parameter_types=parameter_types,
@@ -127,7 +148,8 @@
 
 
 def get_function_abis(
     contract_abi: spec.ContractABI,
 ) -> typing.Sequence[spec.FunctionABI]:
     """get list of function ABI's in contract ABI"""
     return [item for item in contract_abi if item['type'] == 'function']
+
```

### Comparing `checkthechain-0.3.0/src/ctc/evm/address_utils/address_queries.py` & `checkthechain-0.3.4/src/ctc/evm/contract_utils/contract_tests.py`

 * *Files 18% similar despite different names*

```diff
@@ -5,37 +5,37 @@
 from ctc import spec
 
 
 async def async_is_contract_address(
     address: spec.Address,
     *,
     block: spec.BlockNumberReference = 'latest',
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
 ) -> bool:
     """return whether address has bytecode on chain"""
 
     from ctc import rpc
 
     code = await rpc.async_eth_get_code(
         address=address,
         block_number=block,
-        provider=provider,
+        context=context,
     )
     return len(code) >= 3
 
 
 async def async_are_contract_addresses(
     addresses: typing.Sequence[spec.Address],
     *,
     block: spec.BlockNumberReference = 'latest',
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
 ) -> dict[spec.Address, bool]:
     """return whether addresses have bytecode on chain"""
 
     from ctc import rpc
 
     codes = await rpc.async_batch_eth_get_code(
         addresses=addresses,
         block_number=block,
-        provider=provider,
+        context=context,
     )
     return {address: len(code) > 3 for address, code in zip(addresses, codes)}
```

### Comparing `checkthechain-0.3.0/src/ctc/evm/address_utils/address_resolution.py` & `checkthechain-0.3.4/src/ctc/evm/address_utils/address_resolution.py`

 * *Files 10% similar despite different names*

```diff
@@ -16,44 +16,44 @@
 #         and name.endswith('.eth')
 #     )
 
 
 async def async_resolve_address(
     name_or_address: str,
     *,
-    provider: spec.ProviderReference = None,
     block: spec.BlockNumberReference | None = None,
+    context: spec.Context = None,
 ) -> str:
     """resolve alternate address formats (i.e. ENS) to standard address str"""
 
     if not (
         isinstance(name_or_address, str)
         and len(name_or_address) > 4
         and name_or_address.endswith('.eth')
     ):
         return name_or_address
 
     from ctc.protocols import ens_utils
 
     result = await ens_utils.async_resolve_name(
         name=name_or_address,
-        provider=provider,
+        context=context,
         block=block,
     )
     if result is not None:
         return result
     else:
         return name_or_address
 
 
 async def async_resolve_addresses(
     names_or_addresses: typing.Sequence[str],
     *,
-    provider: spec.ProviderReference = None,
     block: spec.BlockNumberReference | None = None,
+    context: spec.Context = None,
 ) -> typing.Sequence[str]:
     """resolve alternate address formats (i.e. ENS) to standard address strs"""
 
     to_resolve: list[str] = []
     for item in names_or_addresses:
         if isinstance(item, str) and len(item) > 4 and item.endswith('.eth'):
             to_resolve.append(item)
@@ -63,16 +63,16 @@
 
     else:
 
         from ctc.protocols import ens_utils
 
         results = await ens_utils.async_resolve_names(
             names=to_resolve,
-            provider=provider,
             block=block,
+            context=context,
         )
         resolved: typing.Mapping[str, str | None] = dict(
             zip(to_resolve, results)
         )
 
         output: list[str] = []
         for name_or_address in names_or_addresses:
@@ -85,25 +85,25 @@
         return output
 
 
 async def async_resolve_address_by_block(
     name_or_address: str,
     *,
     blocks: typing.Sequence[spec.BlockNumberReference],
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
 ) -> typing.Sequence[str]:
     """return resolution history of address over multiple blocks"""
 
     import asyncio
 
     coroutines = [
         async_resolve_address(
             name_or_address=name_or_address,
-            provider=provider,
             block=block,
+            context=context,
         )
         for block in blocks
     ]
 
     results = await asyncio.gather(*coroutines)
 
     return [
```

### Comparing `checkthechain-0.3.0/src/ctc/evm/address_utils/address_transactions.py` & `checkthechain-0.3.4/src/ctc/evm/address_utils/address_transactions.py`

 * *Files 14% similar despite different names*

```diff
@@ -14,117 +14,138 @@
         cummulative: list[int]
 
 
 @typing.overload
 async def async_get_transactions_from_address(
     address: spec.Address,
     output_format: typing.Literal['dataframe'],
+    *,
+    context: spec.Context = None,
 ) -> spec.DataFrame:
     ...
 
 
 @typing.overload
 async def async_get_transactions_from_address(
     address: spec.Address,
     output_format: typing.Literal['hashes'],
+    *,
+    context: spec.Context = None,
 ) -> typing.Sequence[str]:
     ...
 
 
 @typing.overload
 async def async_get_transactions_from_address(
     address: spec.Address,
     output_format: typing.Literal['full'] = 'full',
-) -> typing.Sequence[spec.Transaction]:
+    *,
+    context: spec.Context = None,
+) -> typing.Sequence[spec.DBTransaction]:
     ...
 
 
 @typing.overload
 async def async_get_transactions_from_address(
     address: spec.Address,
     output_format: typing.Literal['full', 'dataframe', 'hashes'],
-) -> typing.Sequence[spec.Transaction] | spec.DataFrame | typing.Sequence[str]:
+    *,
+    context: spec.Context = None,
+) -> typing.Sequence[spec.DBTransaction] | spec.DataFrame | typing.Sequence[
+    str
+]:
     ...
 
 
 async def async_get_transactions_from_address(
     address: spec.Address,
     output_format: typing.Literal['full', 'dataframe', 'hashes'] = 'full',
-) -> typing.Sequence[spec.Transaction] | spec.DataFrame | typing.Sequence[str]:
+    *,
+    context: spec.Context = None,
+) -> typing.Sequence[spec.DBTransaction] | spec.DataFrame | typing.Sequence[
+    str
+]:
     """get all transactions from an address"""
 
     address = address.lower()
 
-    count_data = await async_get_address_transaction_counts_by_block(address)
-    blocks = await evm.async_get_blocks(
-        blocks=count_data['blocks'],
-        include_full_transactions=True,
-        provider={'chunk_size': 1},
+    count_data = await async_get_address_transaction_counts_by_block(
+        address, context=context
     )
 
+    # note: this can be made much more efficient with proper queries
     transactions = []
-    for block, block_count in zip(blocks, count_data['diffs']):
+    for block_number, block_count in zip(
+        count_data['blocks'],
+        count_data['diffs'],
+    ):
+        block_transactions = await evm.async_get_block_transactions(
+            block=block_number,
+            context=context,
+        )
         n_block_transactions = 0
-        for transaction_data in block['transactions']:
-            if typing.TYPE_CHECKING:
-                transaction = typing.cast(spec.Transaction, transaction_data)
-            else:
-                transaction = transaction_data
-            if transaction['from'] == address:
+        for transaction in block_transactions:
+            if transaction['from_address'] == address:
                 transactions.append(transaction)
                 n_block_transactions += 1
                 if n_block_transactions == block_count:
                     break
     if output_format == 'full':
         return transactions
     elif output_format == 'dataframe':
-        import pandas as pd
+        import polars as pl
 
-        return pd.DataFrame(transactions)
+        return pl.DataFrame(transactions)
     elif output_format == 'hashes':
         return [transaction['hash'] for transaction in transactions]
     else:
         raise Exception('unknown output format: ' + str(output_format))
 
 
 async def async_get_address_transaction_counts_by_block(
-    address: spec.Address, nary: int = 3
+    address: spec.Address,
+    nary: int = 3,
+    *,
+    context: spec.Context = None,
 ) -> AddressTransactionCounts:
     """return historical transaction count of address by block"""
 
     import asyncio
     from ctc import rpc
 
     address = address.lower()
 
     # get initial data
     min_block = 0
     min_count_coroutine = rpc.async_eth_get_transaction_count(
         from_address=address,
         block_number=0,
+        context=context,
     )
     min_count_task = asyncio.create_task(min_count_coroutine)
-    max_block = await rpc.async_eth_block_number()
+    max_block = await rpc.async_eth_block_number(context=context)
     max_count = await rpc.async_eth_get_transaction_count(
         from_address=address,
         block_number=max_block,
+        context=context,
     )
     min_count = await min_count_task
 
     block_counts = {
         min_block: min_count,
         max_block: max_count,
     }
 
     await _async_get_block_range_transaction_counts(
         address=address,
         min_block=min_block,
         max_block=max_block,
         block_counts=block_counts,
         nary=nary,
+        context=context,
     )
 
     # parse blocks that contain transactions
     blocks = []
     diffs = []
     cummulative = []
     as_tuples = sorted(block_counts.items())
@@ -144,14 +165,15 @@
 async def _async_get_block_range_transaction_counts(
     *,
     address: spec.Address,
     min_block: int,
     max_block: int,
     block_counts: dict[int, int],
     nary: int,
+    context: spec.Context = None,
 ) -> None:
 
     import asyncio
     import numpy as np
     from ctc import rpc
 
     n_unknown_blocks = max_block - min_block - 1
@@ -164,14 +186,15 @@
         min(nary + 1, n_unknown_blocks + 2),
     )[1:-1].astype(int)
 
     coroutines = [
         rpc.async_eth_get_transaction_count(
             from_address=address,
             block_number=block,
+            context=context,
         )
         for block in blocks
     ]
     counts = await asyncio.gather(*coroutines)
     for block, count in zip(blocks, counts):
         block_counts[block] = count
 
@@ -194,10 +217,12 @@
         else:
             coroutine = _async_get_block_range_transaction_counts(
                 address=address,
                 min_block=range_min_block,
                 max_block=range_max_block,
                 block_counts=block_counts,
                 nary=nary,
+                context=context,
             )
             recursive_coroutines.append(coroutine)
     await asyncio.gather(*recursive_coroutines)
+
```

### Comparing `checkthechain-0.3.0/src/ctc/evm/address_utils/proxy_utils.py` & `checkthechain-0.3.4/src/ctc/evm/contract_utils/contract_proxies.py`

 * *Files 11% similar despite different names*

```diff
@@ -21,89 +21,89 @@
             'gnosis_safe',
         ] | None
 
 
 async def async_get_proxy_implementation(
     contract_address: spec.Address,
     *,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     block: spec.BlockNumberReference | None = None,
 ) -> spec.Address | None:
     """return implementation address of proxy contract"""
 
     proxy_metadata = await async_get_proxy_metadata(
-        contract_address=contract_address, provider=provider, block=block
+        contract_address=contract_address, context=context, block=block
     )
 
     return proxy_metadata['implementation']
 
 
 async def async_get_proxy_metadata(
     contract_address: spec.Address,
     *,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     block: spec.BlockNumberReference | None = None,
 ) -> ProxyAddressMetadata:
     """return metadata of proxy address"""
 
     # try eip897
     try:
         eip897_address = await _async_get_eip897_implementation(
             contract_address=contract_address,
-            provider=provider,
+            context=context,
             block=block,
         )
         if eip897_address is not None:
             return {
                 'implementation': eip897_address,
                 'proxy_type': 'eip897',
             }
     except (spec.exceptions.rpc_exceptions.RpcException, Exception):
         pass
 
     # try eip1967 logic
     eip1967_logic_address = await _async_get_eip1967_proxy_logic_address(
         contract_address=contract_address,
-        provider=provider,
+        context=context,
         block=block,
     )
     if eip1967_logic_address != '0x0000000000000000000000000000000000000000':
         return {
             'implementation': eip1967_logic_address,
             'proxy_type': 'eip1967-logic',
         }
 
     # try eip1967 beacon
     eip1967_beacon_address = await _async_get_eip1967_proxy_beacon_address(
         contract_address=contract_address,
-        provider=provider,
+        context=context,
         block=block,
     )
     if eip1967_beacon_address is not None:
         return {
             'implementation': eip1967_beacon_address,
             'proxy_type': 'eip1967-beacon',
         }
 
     # try openzeppelin
     openzeppelin_address = await _async_get_oz_proxy_address(
         contract_address=contract_address,
-        provider=provider,
+        context=context,
         block=block,
     )
     if openzeppelin_address is not None:
         return {
             'implementation': openzeppelin_address,
             'proxy_type': 'openzeppelin',
         }
 
     # try gnosis proxy
     gnosis_proxy_address = await _async_get_gnosis_safe_proxy_address(
         contract_address,
-        provider=provider,
+        context=context,
         block=block,
     )
     if gnosis_proxy_address is not None:
         return {
             'implementation': gnosis_proxy_address,
             'proxy_type': 'gnosis_safe',
         }
@@ -118,15 +118,15 @@
 # # eip897
 #
 
 
 async def _async_get_eip897_proxy_type(
     contract_address: spec.Address,
     *,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     block: spec.BlockNumberReference | None = None,
 ) -> int | None:
 
     from ctc import rpc
 
     function_abi: spec.FunctionABI = {
         'name': 'proxyType',
@@ -136,26 +136,26 @@
             {'name': 'proxyTypeId', 'type': 'uint256'},
         ],
     }
 
     result = await rpc.async_eth_call(
         to_address=contract_address,
         function_abi=function_abi,
-        provider=provider,
+        context=context,
         block_number=block,
     )
     if result is not None and not isinstance(result, int):
         raise Exception('invalid rpc result')
     return result
 
 
 async def _async_get_eip897_implementation(
     contract_address: spec.Address,
     *,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     block: spec.BlockNumberReference | None = None,
 ) -> spec.Address:
 
     from ctc import rpc
 
     function_abi: spec.FunctionABI = {
         'name': 'implementation',
@@ -165,15 +165,15 @@
             {'name': 'codeAddr', 'type': 'address'},
         ],
     }
 
     result = await rpc.async_eth_call(
         to_address=contract_address,
         function_abi=function_abi,
-        provider=provider,
+        context=context,
         block_number=block,
     )
     if not isinstance(result, str):
         raise Exception('invalid rpc result')
     return result
 
 
@@ -182,15 +182,15 @@
 #
 
 
 async def _async_get_eip1967_proxy_logic_address(
     contract_address: spec.Address,
     *,
     block: typing.Optional[spec.BlockNumberReference] = None,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
 ) -> spec.Address:
     """get a contract's logic address
 
     storage position obtained as:
         bytes32(uint256(keccak256('eip1967.proxy.implementation')) - 1)
 
     see https://eips.ethereum.org/EIPS/eip-1967
@@ -202,27 +202,27 @@
         '0x360894a13ba1a3210667c828492db98dca3e2076cc3735a920a3ca505d382bbc'
     )
 
     result = await rpc.async_eth_get_storage_at(
         address=contract_address,
         position=position,
         block_number=block,
-        provider=provider,
+        context=context,
     )
     if not isinstance(result, str):
         raise Exception('invalid rpc result')
 
     return '0x' + result[-40:]
 
 
 async def _async_get_eip1967_proxy_beacon_address(
     contract_address: spec.Address,
     *,
     block: typing.Optional[spec.BlockNumberReference] = None,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
 ) -> spec.Address | None:
     """get a contract's logic address
 
     storage position obtained as:
         bytes32(uint256(keccak256('eip1967.proxy.beacon')) - 1)
 
     see https://eips.ethereum.org/EIPS/eip-1967
@@ -234,15 +234,15 @@
         '0xa3f0ad74e5423aebfd80d3ef4346578335a9a72aeaee59ff6cb3582b35133d50'
     )
 
     result = await rpc.async_eth_get_storage_at(
         address=contract_address,
         position=position,
         block_number=block,
-        provider=provider,
+        context=context,
     )
     if not isinstance(result, str):
         raise Exception('invalid rpc result')
 
     beacon = '0x' + result[-40:]
     if beacon == '0x0000000000000000000000000000000000000000':
         return None
@@ -254,29 +254,29 @@
         'outputs': [{'type': 'address'}],
     }
 
     try:
         proxy_in_beacon = await rpc.async_eth_call(
             to_address=beacon,
             function_abi=implementation_abi,
-            provider=provider,
+            context=context,
         )
     except Exception:
         proxy_in_beacon = None
 
-    if not isinstance(proxy_in_beacon, str):
+    if not isinstance(proxy_in_beacon, str) and proxy_in_beacon is not None:
         raise Exception('bad rpc data')
     return proxy_in_beacon
 
 
 async def _async_get_eip1967_proxy_admin_address(
     contract_address: spec.Address,
     *,
     block: typing.Optional[spec.BlockNumberReference] = None,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
 ) -> spec.Address:
     """get a contract's logic address
 
     storage position obtained as:
         bytes32(uint256(keccak256('eip1967.proxy.admin')) - 1)
 
     see https://eips.ethereum.org/EIPS/eip-1967
@@ -288,15 +288,15 @@
         '0xa3f0ad74e5423aebfd80d3ef4346578335a9a72aeaee59ff6cb3582b35133d50'
     )
 
     result = await rpc.async_eth_get_storage_at(
         address=contract_address,
         position=position,
         block_number=block,
-        provider=provider,
+        context=context,
     )
     if not isinstance(result, str):
         raise Exception('invalid rpc result')
 
     return '0x' + result[-40:]
 
 
@@ -311,28 +311,28 @@
 #
 
 
 async def _async_get_oz_proxy_address(
     contract_address: spec.Address,
     *,
     block: typing.Optional[spec.BlockNumberReference] = None,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
 ) -> spec.Address | None:
 
     from ctc import rpc
 
     position = (
         '0x7050c9e0f4ca769c69bd3a8ef740bc37934f8e2c036e5a723fd8ee048ed3f8c3'
     )
 
     result = await rpc.async_eth_get_storage_at(
         address=contract_address,
         position=position,
         block_number=block,
-        provider=provider,
+        context=context,
     )
     if not isinstance(result, str):
         raise Exception('invalid rpc result')
 
     address = '0x' + result[-40:]
 
     if address == '0x0000000000000000000000000000000000000000':
@@ -347,30 +347,31 @@
 
 
 async def _async_get_gnosis_safe_proxy_address(
     contract_address: spec.Address,
     *,
     block: spec.BlockNumberReference | None = None,
     confirm_bytecode: bool = True,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
 ) -> spec.Address | None:
 
     from ctc import rpc
 
     if confirm_bytecode:
         gnosis_proxy_code = '0x608060405273ffffffffffffffffffffffffffffffffffffffff600054167fa619486e0000000000000000000000000000000000000000000000000000000060003514156050578060005260206000f35b3660008037600080366000845af43d6000803e60008114156070573d6000fd5b3d6000f3fea2646970667358221220d1429297349653a4918076d650332de1a1068c5f3e07c5c82360c277770b955264736f6c63430007060033'
         bytecode = await rpc.async_eth_get_code(
-            contract_address, block_number=block
+            contract_address, block_number=block, context=context
         )
         if bytecode != gnosis_proxy_code:
             return None
 
     result = await rpc.async_eth_get_storage_at(
         address=contract_address,
         position='0x0',
-        provider=provider,
+        context=context,
         block_number=block,
     )
     if not isinstance(result, str):
         raise Exception('invalid rpc result')
 
     return '0x' + result[-40:]
+
```

### Comparing `checkthechain-0.3.0/src/ctc/evm/binary_utils/format_utils.py` & `checkthechain-0.3.4/src/ctc/evm/binary_utils/format_utils.py`

 * *Files 19% similar despite different names*

```diff
@@ -43,14 +43,49 @@
 
 
 #
 # # binary data manipulation
 #
 
 
+def to_hex(
+    data: spec.GenericBinaryData,
+    *,
+    prefix: bool = True,
+    n_bytes: int | None = None,
+    keep_leading_0: bool | None = None,
+) -> str:
+    """convert hex, binary, or integer data to hex"""
+    if prefix:
+        output_format: typing.Literal['prefix_hex', 'raw_hex'] = 'prefix_hex'
+    else:
+        output_format = 'raw_hex'
+    return binary_convert(
+        data=data,
+        output_format=output_format,
+        n_bytes=n_bytes,
+        keep_leading_0=keep_leading_0,
+    )
+
+
+def to_binary(
+    data: spec.GenericBinaryData,
+    *,
+    n_bytes: int | None = None,
+    keep_leading_0: bool | None = None,
+) -> bytes:
+    """convert hex, binary, or integer data to binary"""
+    return binary_convert(
+        data=data,
+        output_format='binary',
+        n_bytes=n_bytes,
+        keep_leading_0=keep_leading_0,
+    )
+
+
 def text_to_binary(
     text: str,
     output_format: typing.Optional[spec.BinaryFormat] = None,
 ) -> spec.GenericBinaryData:
     """convert text to binary data"""
     return binary_convert(text.encode(), output_format)
 
@@ -119,15 +154,18 @@
     if isinstance(data, str):
         if data.startswith('0x'):
             raw_data = data[2:]
         else:
             raw_data = data
 
         if n_bytes is not None and len(raw_data) / 2 != n_bytes:
-            raise Exception('data does not have target length')
+            if len(raw_data) % 2 != 0:
+                raise Exception('incomplete byte representation')
+            input_bytes = int(len(raw_data) / 2)
+            raw_data = '00' * (n_bytes - input_bytes) + raw_data
 
         if output_format == 'prefix_hex':
             return '0x' + raw_data
         elif output_format == 'raw_hex':
             return raw_data
         elif output_format == 'binary':
             if len(raw_data) % 2 == 1:
@@ -137,15 +175,15 @@
             return int(data, 16)
         else:
             raise Exception('invalid output_format: ' + str(output_format))
 
     elif isinstance(data, bytes):
 
         if n_bytes is not None and len(data) != n_bytes:
-            raise Exception('data does not have target length')
+            data = b'0' * (n_bytes - len(data)) + data
 
         if output_format == 'binary':
             return data
         elif output_format == 'prefix_hex':
             return '0x' + data.hex()
         elif output_format == 'raw_hex':
             return data.hex()
@@ -185,7 +223,35 @@
                     return as_hex
             else:
                 raise Exception('invalid output_format: ' + str(output_format))
 
     else:
 
         raise Exception('unknown input data format: ' + str(type(data)))
+
+
+def binarize_fields(
+    mapping: typing.Mapping[str, typing.Any],
+    fields: typing.Sequence[str] | None = None,
+    *,
+    binary_format: spec.BinaryFormat = 'binary',
+    allow_none: bool = True,
+) -> typing.Mapping[str, typing.Any]:
+    """convert fields of dict to specific binary format"""
+
+    if fields is None:
+        fields = list(mapping.keys())
+
+    binarized: typing.MutableMapping[str, typing.Any] = {}
+    for key, value in mapping.items():
+        if key in fields:
+            if value is not None:
+                binarized[key] = binary_convert(value, binary_format)
+            else:
+                if allow_none:
+                    binarized[key] = value
+                else:
+                    raise Exception('field has value None: ' + str(key))
+        else:
+            binarized[key] = value
+
+    return binarized
```

### Comparing `checkthechain-0.3.0/src/ctc/evm/binary_utils/hash_utils.py` & `checkthechain-0.3.4/src/ctc/evm/binary_utils/hash_utils.py`

 * *Files 2% similar despite different names*

```diff
@@ -63,15 +63,15 @@
 
             library = 'pysha3'
 
         except ImportError:
             library = 'pycryptodome'
 
     # convert data to binary
-    data = format_utils.binary_convert(data, 'binary')
+    data = format_utils.to_binary(data)
 
     if library == 'pysha3':
         import sha3
 
         binary = sha3.keccak_256(data).digest()
     elif library == 'pycryptodome':
         from Crypto.Hash import keccak as f_keccak
```

### Comparing `checkthechain-0.3.0/src/ctc/evm/binary_utils/rlp_utils.py` & `checkthechain-0.3.4/src/ctc/evm/binary_utils/rlp_utils.py`

 * *Files 6% similar despite different names*

```diff
@@ -66,99 +66,86 @@
     str_mode specifies how str values should be interpreted
     """
 
     if isinstance(item, int):
         if item == 0:
             item = bytes()
         else:
-            item = format_utils.binary_convert(item, 'binary')
+            item = format_utils.to_binary(item)
 
     if isinstance(item, (tuple, list)):
         output = _rlp_encode_list(item, str_mode=str_mode)
     elif isinstance(item, bytes):
         output = _rlp_encode_bytes(item)
     elif isinstance(item, str):
         output = _rlp_encode_str(item, str_mode=str_mode)
     else:
         raise Exception('cannot rlp encode items of type ' + str(type(item)))
 
     return format_utils.binary_convert(output, output_format)
 
 
 def _rlp_encode_bytes(data: bytes) -> bytes:
-
-    data = format_utils.binary_convert(data, 'binary')
+    data = format_utils.to_binary(data)
 
     length = len(data)
     if length == 0:
         return bytes.fromhex('80')
     elif length == 1 and data <= bytes.fromhex('7f'):
         return data
     elif length <= 55:
         prefix = 128 + length
-        return format_utils.binary_convert(prefix, 'binary') + data
+        return format_utils.to_binary(prefix) + data
     else:
-        length_as_bytes = format_utils.binary_convert(length, 'binary')
+        length_as_bytes = format_utils.to_binary(length)
         prefix = 183 + len(length_as_bytes)
-        return (
-            format_utils.binary_convert(prefix, 'binary')
-            + length_as_bytes
-            + data
-        )
+        return format_utils.to_binary(prefix) + length_as_bytes + data
 
 
 def _rlp_encode_list(
     items: typing.Sequence[typing.Any],
     str_mode: Literal['auto', 'text', 'hex'] | None = None,
 ) -> bytes:
-
     encoded_items = [
         rlp_encode(item, str_mode=str_mode, output_format='binary')
         for item in items
     ]
     item_lengths = [len(encoded_item) for encoded_item in encoded_items]
     total_payload_length = sum(item_lengths)
 
     if total_payload_length <= 55:
-        prefix = format_utils.binary_convert(
-            192 + total_payload_length, 'binary'
-        )
+        prefix = format_utils.to_binary(192 + total_payload_length)
         output = prefix
         for item in encoded_items:
             output = output + item
         return output
 
     else:
-        bytes_of_length = format_utils.binary_convert(
-            total_payload_length, 'binary'
-        )
+        bytes_of_length = format_utils.to_binary(total_payload_length)
         prefix_int = 247 + len(bytes_of_length)
-        output = (
-            format_utils.binary_convert(prefix_int, 'binary') + bytes_of_length
-        )
+        output = format_utils.to_binary(prefix_int) + bytes_of_length
         for item in encoded_items:
             output = output + item
         return output
 
 
 def _rlp_encode_str(
     item: str,
     str_mode: Literal['auto', 'text', 'hex'] | None,
 ) -> bytes:
-
     if str_mode == 'auto':
         if item.startswith('0x'):
             str_mode = 'hex'
         else:
             str_mode = 'text'
 
     if str_mode == 'text':
         as_bytes = item.encode()
     elif str_mode == 'hex':
-        as_bytes = format_utils.binary_convert(item, 'binary')
+        as_bytes = format_utils.to_binary(item)
     else:
         raise Exception('unknown str mode: ' + str(str_mode))
 
     return _rlp_encode_bytes(as_bytes)
 
 
 #
@@ -178,25 +165,24 @@
         2. list/tuple of binary format names, corresponding to items in rlp list
     """
 
     # convert any abi types to RLP types
     if types is not None:
         types = _process_rlp_types(types)
 
-    data = format_utils.binary_convert(data, 'binary')
+    data = format_utils.to_binary(data)
     decoded, remaining = _rlp_decode_chunk(data=data, types=types)
     if len(remaining) > 0:
         raise Exception('data contains extra bytes')
     return decoded
 
 
 def _process_rlp_types(
     types: str | typing.Sequence[str],
 ) -> str | typing.Sequence[str]:
-
     allowed_types = [
         'prefix_hex',
         'raw_hex',
         'binary',
         'integer',
         'ascii',
         'bool',
@@ -232,15 +218,14 @@
         return result
 
 
 def _rlp_decode_primitive_chunk(
     data: bytes,
     types: RLPDecodeTypes,
 ) -> tuple[typing.Any, bytes]:
-
     first_byte = data[0]
 
     if first_byte <= 0x7F:
         # data that is single byte less than or equal to 127
 
         decoded: typing.Any = first_byte.to_bytes(1, 'big')
         remaining = data[1:]
@@ -289,15 +274,14 @@
     return decoded, remaining
 
 
 def _rlp_decode_list_chunk(
     data: bytes,
     types: RLPDecodeTypes,
 ) -> tuple[list[typing.Any], bytes]:
-
     first_byte = data[0]
 
     if first_byte <= 0xBF:
         raise Exception('next item in data is not a list chunk')
 
     elif first_byte <= 0xF7:
         # list with total payload length between 0 and 55 bytes
@@ -337,15 +321,14 @@
         remaining = data[end:]
 
     # decode each item of list payload
     output = []
     remaining_payload = list_payload
     index = 0
     while len(remaining_payload) > 0:
-
         # get type of item
         if isinstance(types, (list, tuple)):
             if index >= len(types):
                 raise Exception(
                     'number of types does not match number of list items'
                 )
             item_types = types[index]
@@ -359,7 +342,8 @@
             remaining_payload,
             types=item_types,
         )
         output.append(item)
         index += 1
 
     return output, remaining
+
```

### Comparing `checkthechain-0.3.0/src/ctc/evm/binary_utils/signature_utils/eip712_utils.py` & `checkthechain-0.3.4/src/ctc/evm/binary_utils/signature_utils/eip712_utils.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/evm/binary_utils/signature_utils/key_utils.py` & `checkthechain-0.3.4/src/ctc/evm/binary_utils/signature_utils/key_utils.py`

 * *Files 10% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 from .. import hash_utils
 from . import secp256k1_utils
 
 
 def private_key_to_public_key(private_key: spec.Data) -> str:
     """convert private key to public key"""
 
-    binary_private_key = format_utils.binary_convert(private_key, 'binary')
+    binary_private_key = format_utils.to_binary(private_key)
     as_tuple = secp256k1_utils.privtopub(binary_private_key)
     return public_key_tuple_to_hex(as_tuple)
 
 
 def private_key_to_address(private_key: spec.Data) -> spec.Address:
     """convert private key to address"""
     public_key = private_key_to_public_key(private_key)
@@ -25,25 +25,24 @@
     public_key: tuple[int, int] | spec.Data
 ) -> spec.Address:
     """convert public key to address"""
 
     as_hex = public_key_tuple_to_hex(public_key)
     hash = hash_utils.keccak(as_hex, 'binary')
     address = hash[-20:]
-    return format_utils.binary_convert(address, 'prefix_hex')
+    return format_utils.to_hex(address)
 
 
 def public_key_tuple_to_hex(public_key: tuple[int, int] | spec.Data) -> str:
     """convert public key tuple to key"""
 
     if isinstance(public_key, tuple):
         if len(public_key) == 2:
             x, y = public_key
             as_bytes = x.to_bytes(32, 'big') + y.to_bytes(32, 'big')
-            return format_utils.binary_convert(as_bytes, 'prefix_hex')
+            return format_utils.to_hex(as_bytes)
         else:
             raise Exception('unknown pubilc key format')
 
     else:
-        return format_utils.binary_convert(
-            public_key, output_format='prefix_hex', n_bytes=64
-        )
+        return format_utils.to_hex(public_key, n_bytes=64)
+
```

### Comparing `checkthechain-0.3.0/src/ctc/evm/binary_utils/signature_utils/secp256k1_utils.py` & `checkthechain-0.3.4/src/ctc/evm/binary_utils/signature_utils/secp256k1_utils.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/evm/binary_utils/signature_utils/signature_creation.py` & `checkthechain-0.3.4/src/ctc/evm/binary_utils/signature_utils/signature_creation.py`

 * *Files 10% similar despite different names*

```diff
@@ -57,18 +57,18 @@
     message_hash: spec.Data,
     *,
     private_key: spec.Data,
     chain_id: int | None = None,
 ) -> tuple[int, int, int]:
     """sign message hash using private key"""
 
-    message_hash = format_utils.binary_convert(message_hash, 'binary')
+    message_hash = format_utils.to_binary(message_hash)
 
     # compute signature
-    private_binary = format_utils.binary_convert(private_key, 'binary')
+    private_binary = format_utils.to_binary(private_key)
     v, r, s = secp256k1_utils.ecdsa_raw_sign(
         message_hash,
         priv=private_binary,
     )
 
     # alter v with chain_id
     if chain_id is not None:
@@ -101,15 +101,15 @@
 
 
 def _hash_data_message(
     message: spec.Data,
     mode: Literal['eth_sign', 'personal_sign'],
 ) -> bytes:
 
-    message = format_utils.binary_convert(message, 'binary')
+    message = format_utils.to_binary(message)
 
     # add prefix
     if mode == 'eth_sign':
         full_message = message
     elif mode == 'personal_sign':
         prefix = '\x19Ethereum Signed Message:\n' + str(len(message))
         full_message = prefix.encode() + message
```

### Comparing `checkthechain-0.3.0/src/ctc/evm/binary_utils/signature_utils/signature_recovery.py` & `checkthechain-0.3.4/src/ctc/evm/binary_utils/signature_utils/signature_recovery.py`

 * *Files 2% similar despite different names*

```diff
@@ -71,19 +71,19 @@
     if v >= 37:
         network_id = get_signature_network_id(signature)
         if network_id is None:
             raise Exception('could not parse valid network_id')
         v = v - network_id * 2 - 8
 
     # get signer
-    message_hash = format_utils.binary_convert(message_hash, 'binary')
+    message_hash = format_utils.to_binary(message_hash)
     x, y = secp256k1_utils.ecdsa_raw_recover(message_hash, (v, r, s))
     signer = x.to_bytes(32, byteorder='big') + y.to_bytes(32, byteorder='big')
 
-    return format_utils.binary_convert(signer, 'prefix_hex')
+    return format_utils.to_hex(signer)
 
 
 def recover_signer_address(
     *,
     message_hash: spec.Data,
     signature: spec.Signature,
 ) -> spec.Address:
```

### Comparing `checkthechain-0.3.0/src/ctc/evm/block_utils/block_coding.py` & `checkthechain-0.3.4/src/ctc/evm/block_utils/block_coding.py`

 * *Files 5% similar despite different names*

```diff
@@ -10,19 +10,15 @@
     """encode block number as hex str"""
 
     standard_block = standardize_block_number(block)
 
     if isinstance(standard_block, str):
         return standard_block
     elif isinstance(standard_block, int):
-        return binary_utils.binary_convert(
-            standard_block,
-            'prefix_hex',
-            keep_leading_0=False,
-        )
+        return binary_utils.to_hex(standard_block, keep_leading_0=False)
     else:
         raise Exception('could not encode block number')
 
 
 #
 # # singular block standardization
 #
```

### Comparing `checkthechain-0.3.0/src/ctc/evm/block_utils/block_crud.py` & `checkthechain-0.3.4/src/ctc/evm/block_utils/block_crud.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,174 +1,206 @@
 from __future__ import annotations
 
 import time
 import typing
 
 from ctc import evm
 from ctc import spec
+from . import block_convert
 
 if typing.TYPE_CHECKING:
     import asyncio
     from typing_extensions import TypedDict
 
     class LatestBlockCacheEntry(TypedDict, total=False):
         request_time: float
         response_time: float
         block_number: int
 
 
 async def async_get_block(
     block: spec.BlockReference,
     *,
-    include_full_transactions: bool = False,
-    provider: spec.ProviderReference = None,
-    use_db: bool = True,
-) -> spec.Block:
+    context: spec.Context = None,
+) -> spec.DBBlock:
     """get block from local database or from RPC node"""
 
-    from ctc import rpc
-
     if spec.is_block_number_reference(block):
+        return await _async_get_block_by_number(block=block, context=context)
+    elif spec.is_block_hash(block):
+        from ctc import rpc
 
-        from ctc import db
+        rpc_block_data = await rpc.async_eth_get_block_by_hash(
+            block_hash=block,
+            context=context,
+            include_full_transactions=False,
+        )
+        return block_convert.convert_rpc_block_to_db_block(rpc_block_data)
+    else:
+        raise Exception('unknown block specifier: ' + str(block))
 
-        network = rpc.get_provider_network(provider)
 
-        if use_db and not include_full_transactions:
-            db_block_data = await db.async_query_block(
-                block_number=block,
-                network=network,
-            )
-            if db_block_data is not None:
-                return db_block_data
-
-        block_data: spec.Block = await rpc.async_eth_get_block_by_number(
-            block_number=evm.standardize_block_number(block),
-            provider=provider,
-            include_full_transactions=include_full_transactions,
-        )
-        block_data.setdefault('base_fee_per_gas', None)
+async def _async_get_block_by_number(
+    block: spec.BlockNumberReference,
+    *,
+    context: spec.Context = None,
+) -> spec.DBBlock:
+
+    from ctc import config
+    from ctc import db
+    from ctc import rpc
+
+    read_cache, write_cache = config.get_context_cache_read_write(
+        schema_name='blocks', context=context
+    )
+
+    if read_cache and isinstance(block, int):
+        db_block_data = await db.async_query_block(
+            block_number=block,
+            context=context,
+        )
+        if db_block_data is not None:
+            return db_block_data
+
+    rpc_block_data: spec.RPCBlock = await rpc.async_eth_get_block_by_number(
+        block_number=evm.standardize_block_number(block),
+        context=context,
+        include_full_transactions=False,
+    )
+    db_block = block_convert.convert_rpc_block_to_db_block(rpc_block_data)
 
+    if write_cache:
         await db.async_intake_block(
-            block=block_data,
-            network=network,
+            db_block=db_block,
+            context=context,
         )
 
-        return block_data
+    return db_block
 
-    elif spec.is_block_hash(block):
 
-        block_data = await rpc.async_eth_get_block_by_hash(
-            block_hash=block,
-            provider=provider,
-            include_full_transactions=include_full_transactions,
-        )
-        return block_data
-
-    else:
-        raise Exception('unknown block specifier: ' + str(block))
+#
+# # plural
+#
 
 
 async def async_get_blocks(
     blocks: typing.Sequence[spec.BlockReference],
     *,
-    include_full_transactions: bool = False,
-    chunk_size: int = 500,
-    provider: spec.ProviderReference = None,
-    use_db: bool = True,
     latest_block_number: int | None = None,
-) -> list[spec.Block]:
+    context: spec.Context = None,
+) -> typing.Sequence[spec.DBBlock]:
     """get blocks from local database or from RPC node"""
 
     from ctc import rpc
 
-    if isinstance(provider, dict) and provider.get('chunk_size') is None:
-        provider = rpc.add_provider_parameters(
-            provider, {'chunk_size': chunk_size}
+    if all(spec.is_block_number_reference(block) for block in blocks):
+        return await _async_get_blocks_by_numbers(
+            blocks=blocks,
+            latest_block_number=latest_block_number,
+            context=context,
+        )
+    elif all(spec.is_block_hash(block) for block in blocks):
+        return await rpc.async_batch_eth_get_block_by_hash(
+            block_hashes=blocks,
+            include_full_transactions=False,
+            context=context,
+        )
+    else:
+        raise Exception(
+            'blocks should be all block number references or all block hashes'
         )
 
-    if all(spec.is_block_number_reference(block) for block in blocks):
 
-        standardized = [evm.standardize_block_number(block) for block in blocks]
-        pending = standardized
+async def _async_get_blocks_by_numbers(
+    blocks: typing.Sequence[spec.BlockReference],
+    *,
+    latest_block_number: int | None = None,
+    context: spec.Context = None,
+) -> typing.Sequence[spec.DBBlock]:
 
-        if use_db and not include_full_transactions:
-            from ctc import db
+    from ctc import config
+    from ctc import rpc
 
-            network = rpc.get_provider_network(provider)
-            db_block_datas = await db.async_query_blocks(
-                block_numbers=pending, network=network
-            )
-            if db_block_datas is None:
-                block_data_map = {}
-            else:
-                block_data_map = dict(zip(pending, db_block_datas))
-                pending = [
-                    block
-                    for block, db_block_data in block_data_map.items()
-                    if db_block_data is None
-                ]
-        else:
-            block_data_map = {}
+    standardized = [evm.standardize_block_number(block) for block in blocks]
+    pending = standardized
+
+    read_cache, write_cache = config.get_context_cache_read_write(
+        schema_name='blocks', context=context
+    )
 
-        blocks_data = await rpc.async_batch_eth_get_block_by_number(
-            block_numbers=pending,
-            include_full_transactions=include_full_transactions,
-            provider=provider,
+    if read_cache:
+        from ctc import db
+
+        db_block_datas = await db.async_query_blocks(
+            block_numbers=pending, context=context
         )
-        for block_data in blocks_data:
-            block_data.setdefault('base_fee_per_gas', None)
+        if db_block_datas is None:
+            block_data_map = {}
+        else:
+            block_data_map = dict(zip(pending, db_block_datas))
+            pending = [
+                block
+                for block, db_block_data in block_data_map.items()
+                if db_block_data is None
+            ]
+    else:
+        block_data_map = {}
+
+    rpc_blocks = await rpc.async_batch_eth_get_block_by_number(
+        block_numbers=pending,
+        include_full_transactions=False,
+        context=context,
+    )
+    db_blocks = [
+        block_convert.convert_rpc_block_to_db_block(block)
+        for block in rpc_blocks
+    ]
 
+    # intake rpc data to db
+    if write_cache:
         from ctc import db
 
-        # intake rpc data to db
         await db.async_intake_blocks(
-            blocks=blocks_data,
-            network=rpc.get_provider_network(provider),
+            db_blocks=db_blocks,
             latest_block_number=latest_block_number,
+            context=context,
         )
 
-        if use_db:
-            block_data_map.update(dict(zip(pending, blocks_data)))
-            blocks_data = [block_data_map[block] for block in standardized]
-
-        return blocks_data
-
-    elif all(spec.is_block_hash(block) for block in blocks):
+    block_data_map.update(dict(zip(pending, db_blocks)))
+    blocks_data = [block_data_map[block] for block in standardized]
 
-        return await rpc.async_batch_eth_get_block_by_hash(
-            block_hashes=blocks,
-            include_full_transactions=include_full_transactions,
-            provider=provider,
-        )
+    return blocks_data  # type: ignore
 
-    else:
-        raise Exception(
-            'blocks should be all block number references or all block hashes'
-        )
 
+#
+# # latest block number
+#
 
 _latest_block_cache: typing.MutableMapping[int, LatestBlockCacheEntry] = {}
 _latest_block_lock: typing.MutableMapping[str, asyncio.Lock | None] = {
     'lock': None
 }
 
 
 async def async_get_latest_block_number(
-    provider: spec.ProviderReference = None,
     *,
+    context: spec.Context = None,
     use_cache: bool = True,
     cache_time: int | float = 1,
 ) -> int:
-    """get latest block number"""
+    """get latest block number
+
+    uses a per-network in-memory cache with a ttl of cache_time
+    """
 
+    from ctc import config
     from ctc import rpc
 
     if not use_cache:
-        result = await rpc.async_eth_block_number(provider=provider)
+        result = await rpc.async_eth_block_number(context=context)
         if not isinstance(result, int):
             raise Exception('invalid rpc result')
         return result
 
     else:
 
         # must initialize asyncio.Lock within a running event loop
@@ -178,28 +210,44 @@
             import asyncio
 
             lock = asyncio.Lock()
             _latest_block_lock['lock'] = lock
 
         async with lock:
 
-            network = rpc.get_provider_network(provider)
+            network = config.get_context_chain_id(context)
             request_time = time.time()
             network_cache = _latest_block_cache.get(network)
             if (
                 network_cache is not None
                 and request_time - network_cache['request_time'] < cache_time
             ):
                 return network_cache['block_number']
 
-            result = await rpc.async_eth_block_number(provider=provider)
+            result = await rpc.async_eth_block_number(context=context)
             if not isinstance(result, int):
                 raise Exception('invalid rpc result')
 
             response_time = time.time()
             _latest_block_cache[network] = {
                 'request_time': request_time,
                 'response_time': response_time,
                 'block_number': result,
             }
 
             return result
+
+
+def sync_get_latest_block_number(
+    *,
+    context: spec.Context = None,
+    use_cache: bool = True,
+    cache_time: int | float = 1,
+) -> int:
+    """get latest block number"""
+    from ctc import rpc
+
+    result = rpc.sync_eth_block_number(context=context)
+    if not isinstance(result, int):
+        raise Exception('invalid rpc result')
+    return result
+
```

### Comparing `checkthechain-0.3.0/src/ctc/evm/block_utils/block_gas.py` & `checkthechain-0.3.4/src/ctc/evm/block_utils/block_gas.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,151 +1,116 @@
 from __future__ import annotations
 
 import os
 import typing
 
-from . import block_crud
+from .. import transaction_utils
+from . import block_times
+from . import block_normalize
 from ctc import evm
 from ctc import spec
 
 if typing.TYPE_CHECKING or os.environ.get('BUILDING_SPHINX') == '1':
 
     from typing_extensions import TypedDict
     from ctc import db
 
     class BlockGasStats(TypedDict):
-        base_fee: int | float | None
         min_gas_price: int | float | None
         median_gas_price: int | float | None
         mean_gas_price: float | None
         max_gas_price: int | float | None
-        gas_used: int
-        gas_limit: int
         n_transactions: int
+        # base_fee: int | float | None
+        # gas_used: int
+        # gas_limit: int
 
 
-def compute_median_block_gas_fee(
-    block: spec.Block,
-    *,
-    normalize: bool,
-) -> int | float | None:
-    """compute median gas fee of transactions in block"""
-
-    import numpy as np
-
-    # get transactions
-    transactions = block['transactions']
-    if len(transactions) == 0:
-        return None
-
-    # gather gas fees
-    gas_fees = []
-    for transaction in transactions:
-        if isinstance(transaction, str):
-            raise Exception(
-                'must use a block with include_full_transactions=True'
-            )
-        gas_fees.append(transaction['gas_price'])
-
-    # compute median
-    median = float(np.median(gas_fees))
-
-    # normalize
-    if normalize:
-        median = median / 1e9
-
-    return median
-
-
-def compute_median_blocks_gas_fees(
-    blocks: typing.Sequence[spec.Block],
-    *,
-    normalize: bool = True,
-) -> typing.Sequence[int | float | None]:
-    """compute median gas fees of transactionss in multiple blocks"""
-
-    return [
-        compute_median_block_gas_fee(block, normalize=normalize)
-        for block in blocks
-    ]
+#
+# # query median gas fees
+#
 
 
 async def async_get_median_block_gas_fee(
     block: spec.BlockNumberReference,
     *,
     normalize: bool = True,
-    use_db: bool = True,
-    network: spec.NetworkReference | None = None,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
 ) -> db.BlockGasRow:
     """get median gas fee for a given block"""
 
+    from ctc import config
     from ctc import rpc
 
-    network, provider = evm.get_network_and_provider(network, provider)
-    block = await evm.async_block_number_to_int(block, provider=provider)
+    block = await evm.async_block_number_to_int(block, context=context)
 
-    if use_db:
+    read_cache, write_cache = config.get_context_cache_read_write(
+        schema_name='block_gas', context=context
+    )
+    if read_cache:
         from ctc import db
 
         try:
             result = await db.async_query_median_block_gas_fee(
-                block, network=network
+                block, context=context
             )
 
             if result is not None:
                 if normalize and result['median_gas_fee'] is not None:
                     result['median_gas_fee'] /= 1e9
 
                 return result
 
         except Exception:
             pass
 
-    block_data = await rpc.async_eth_get_block_by_number(
-        block,
-        provider=provider,
-        include_full_transactions=True,
+    block_timestamp = await block_times.async_get_block_timestamp(
+        block=block, context=context
+    )
+    txs = await transaction_utils.async_get_block_transactions(
+        block, context=context
     )
     return {
         'block_number': block,
-        'timestamp': block_data['timestamp'],
-        'median_gas_fee': compute_median_block_gas_fee(
-            block_data,
+        'timestamp': block_timestamp,
+        'median_gas_fee': compute_transactions_median_gas_fee(
+            txs,
             normalize=normalize,
         ),
     }
 
 
 async def async_get_median_blocks_gas_fees(
     blocks: typing.Sequence[spec.BlockNumberReference],
     *,
-    use_db: bool = True,
     normalize: bool = True,
-    network: spec.NetworkReference | None = None,
-    provider: spec.ProviderReference = None,
     verbose: bool = True,
     latest_block_number: int | None = None,
+    context: spec.Context = None,
 ) -> typing.Sequence[db.BlockGasRow]:
     """get median gas fees for multiple blocks"""
 
-    network, provider = evm.get_network_and_provider(network, provider)
+    from ctc import config
+
     blocks = await evm.async_block_numbers_to_int(blocks)
 
     # get data from db
-    if use_db:
+    read_cache, write_cache = config.get_context_cache_read_write(
+        schema_name='block_gas', context=context
+    )
+    if read_cache:
         from ctc import db
 
         result = await db.async_query_median_blocks_gas_fees(
-            blocks, network=network
+            blocks, context=context
         )
 
         if result is None:
             fee_map: typing.MutableMapping[int, db.BlockGasRow] = {}
-            missing = blocks
+            missing: typing.Sequence[int] = blocks
         else:
             fee_map = dict(result)
             missing = []
             for block in blocks:
                 if block not in fee_map:
                     missing.append(block)
     else:
@@ -162,119 +127,182 @@
                 'fetching tx gas data for '
                 + toolstr.add_style(
                     str(len(missing)), styles['description'] + ' bold'
                 )
                 + ' blocks',
             )
             print()
-        blocks_data = await evm.async_get_blocks(
-            blocks=missing,
-            include_full_transactions=True,
-            provider={'chunk_size': 1},
-            latest_block_number=latest_block_number,
+
+        from ctc import config
+
+        context = config.update_context(
+            context, merge_provider={'chunk_size': 1}
         )
 
-        missing_fees = compute_median_blocks_gas_fees(
-            blocks_data,
-            normalize=False,
+        # get txs by block
+        txs = await transaction_utils.async_get_blocks_transactions(
+            blocks=missing,
+            context=context,
+        )
+        blocks_timestamps = await block_times.async_get_block_timestamps(
+            blocks=blocks, context=context
         )
-        for block, block_data, fee in zip(missing, blocks_data, missing_fees):
+        txs_by_block: dict[int, list[spec.DBTransaction]] = {}
+        for tx in txs:
+            block = tx['block_number']
+            txs_by_block.setdefault(block, [])
+            txs_by_block[block].append(tx)
+
+        for block, timestamp in zip(missing, blocks_timestamps):
+            fee = compute_transactions_median_gas_fee(
+                txs_by_block[block], normalize=normalize
+            )
             fee_map[block] = {
                 'block_number': block,
                 'median_gas_fee': fee,
-                'timestamp': block_data['timestamp'],
+                'timestamp': timestamp,
             }
 
     if normalize:
         for block, fee_data in fee_map.items():
             if fee_data is not None and fee_data['median_gas_fee'] is not None:
                 fee_data['median_gas_fee'] /= 1e9
 
     return [fee_map[block] for block in blocks]
 
 
+#
+# # query gas stats
+#
+
+
 async def async_get_block_gas_stats(
-    block: spec.BlockNumberReference | spec.Block,
+    block: spec.BlockNumberReference,
     *,
     normalize: bool = True,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
 ) -> BlockGasStats:
     """get gas usage statistics for a given block"""
-    if isinstance(block, dict):
-        block_data = block
-    else:
-        block_data = await block_crud.async_get_block(
-            block, include_full_transactions=True, provider=provider
-        )
 
-    return compute_block_gas_stats(block_data, normalize=normalize)
+    block_number = await block_normalize.async_block_reference_to_int(
+        block=block, context=context
+    )
+    txs = await transaction_utils.async_get_block_transactions(
+        block=block_number, context=context
+    )
+    return compute_transactions_gas_stats(txs, normalize=normalize)
 
 
 async def async_get_gas_stats_by_block(
-    blocks: typing.Sequence[spec.BlockNumberReference | spec.Block],
+    blocks: typing.Sequence[spec.BlockNumberReference],
     *,
     normalize: bool = True,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
 ) -> list[BlockGasStats]:
     """get block gas usage statistics of multiple blocks"""
 
-    import asyncio
+    # get txs of blocks
+    int_blocks = await block_normalize.async_block_numbers_to_int(
+        blocks=blocks, context=context
+    )
+    txs = await transaction_utils.async_get_blocks_transactions(
+        blocks=int_blocks, context=context
+    )
 
-    coroutines = [
-        async_get_block_gas_stats(
-            block=block,
-            normalize=normalize,
-            provider=provider,
+    # sort txs by block
+    txs_by_block: dict[int, list[spec.DBTransaction]] = {}
+    for tx in txs:
+        block = tx['block_number']
+        txs_by_block.setdefault(block, [])
+        txs_by_block[block].append(tx)
+
+    # compute stats per block
+    return [
+        compute_transactions_gas_stats(
+            txs_by_block[int_block], normalize=normalize
         )
-        for block in blocks
+        for int_block in int_blocks
     ]
 
-    return await asyncio.gather(*coroutines)
 
+#
+# # compute gas stats
+#
+
+
+def compute_transactions_median_gas_fee(
+    transactions: typing.Sequence[spec.DBTransaction],
+    *,
+    normalize: bool,
+) -> int | float | None:
+    """compute median gas fee of transactions in block"""
+
+    import numpy as np
+
+    # gather gas fees
+    gas_fees = []
+    for transaction in transactions:
+        if isinstance(transaction, str):
+            raise Exception(
+                'must use a block with include_full_transactions=True'
+            )
+        gas_fees.append(transaction['gas_price'])
+
+    # compute median
+    median = float(np.median(gas_fees))
+
+    # # normalize
+    # if normalize:
+    #     median = median / 1e9
 
-def compute_block_gas_stats(
-    block: spec.Block,
+    return median
+
+
+def compute_transactions_gas_stats(
+    transactions: typing.Sequence[spec.DBTransaction],
     *,
     normalize: bool = True,
 ) -> BlockGasStats:
     """compute gas usage statistics for given block"""
-    import numpy as np
 
-    base_fee: int | float | None = block.get('base_fee_per_gas')
+    import numpy as np
 
-    if len(block['transactions']) > 0:
-        if isinstance(block['transactions'][0], str):
-            raise Exception(
-                'transaction data not in block, use include_full_transactions=True when retrieving block'
-            )
+    if len(transactions) > 0:
 
         gas_prices: list[int | float] = [
-            transaction['gas_price']  # type: ignore
-            for transaction in block['transactions']
+            transaction['gas_price'] for transaction in transactions
         ]
 
         if normalize:
             gas_prices = [gas_price / 1e9 for gas_price in gas_prices]
-            if base_fee is not None:
-                base_fee = base_fee / 1e9
 
         min_gas_price = min(gas_prices)
         median_gas_price = float(np.median(gas_prices))
         mean_gas_price = sum(gas_prices) / len(gas_prices)
         max_gas_price = max(gas_prices)
 
     else:
         min_gas_price = None
         median_gas_price = None
         mean_gas_price = None
         max_gas_price = None
 
     return {
-        'base_fee': base_fee,
         'min_gas_price': min_gas_price,
         'median_gas_price': median_gas_price,
         'mean_gas_price': mean_gas_price,
         'max_gas_price': max_gas_price,
-        'gas_used': block['gas_used'],
-        'gas_limit': block['gas_limit'],
-        'n_transactions': len(block['transactions']),
+        'n_transactions': len(transactions),
     }
+
+
+# def compute_block_gas_stats(block: spec.DBBlock, normalize: bool = False):
+#     base_fee: int | float | None = block.get('base_fee_per_gas')
+#     if normalize:
+#         if base_fee is not None:
+#             base_fee = base_fee / 1e9
+#     return {
+#         'base_fee': base_fee,
+#         'gas_used': block['gas_used'],
+#         'gas_limit': block['gas_limit'],
+#     }
+
```

### Comparing `checkthechain-0.3.0/src/ctc/evm/block_utils/block_hashes.py` & `checkthechain-0.3.4/src/ctc/evm/block_utils/block_hashes.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 from __future__ import annotations
 
 from .. import binary_utils
 from ctc import spec
 
 
-def serialize_block(block: spec.Block) -> spec.PrefixHexData:
+def serialize_block(block: spec.RPCBlock) -> spec.PrefixHexData:
     """serialize block in preparation for hashing"""
 
     if block.get('base_fee_per_gas') is not None:
         block_type = 'eip1559'
     else:
         block_type = 'legacy'
 
@@ -32,12 +32,12 @@
 
     if block_type == 'eip1559':
         as_list.append(block['base_fee_per_gas'])
 
     return binary_utils.rlp_encode(as_list)
 
 
-def hash_block(block: spec.Block) -> spec.PrefixHexData:
+def hash_block(block: spec.RPCBlock) -> spec.PrefixHexData:
     """compute hash of block"""
 
     serialized = serialize_block(block)
     return binary_utils.keccak(serialized)
```

### Comparing `checkthechain-0.3.0/src/ctc/evm/block_utils/block_summary.py` & `checkthechain-0.3.4/src/ctc/evm/block_utils/block_summary.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,54 +1,59 @@
 from __future__ import annotations
 
 import typing
 import time
 
 from ctc import spec
 from .. import binary_utils
+from .. import transaction_utils
 from . import block_crud
 
 
 async def async_print_block_summary(
-    block: spec.Block | spec.BlockNumberReference,
-    provider: spec.ProviderReference = None,
+    block: spec.DBBlock | spec.BlockNumberReference,
+    *,
+    context: spec.Context = None,
 ) -> None:
     """print summary of block"""
 
     import toolstr
     import tooltime
 
     from ctc import cli
 
     if not isinstance(block, dict):
-        block = await block_crud.async_get_block(block=block, provider=provider)
+        block = await block_crud.async_get_block(
+            block=block, context=context
+        )
 
-    full_transactions = len(block['transactions']) > 0 and isinstance(
-        block['transactions'][0], dict
+    block_transactions = await transaction_utils.async_get_block_transactions(
+        block['number'], context=context
     )
     percentiles = [
         0,
         5,
         50,
         95,
         100,
     ]
 
-    if full_transactions:
-        gas_prices = []
-        for transaction in block['transactions']:
-            if typing.TYPE_CHECKING:
-                transaction = typing.cast(spec.Transaction, transaction)
-            gas_prices.append(transaction['gas_price'] / 1e9)
-        import numpy as np
+    gas_prices = []
+    for transaction in block_transactions:
+        gas_prices.append(transaction['gas_price'] / 1e9)
+    import numpy as np
 
+    gas_percentiles: typing.Sequence[typing.Any] | spec.NumpyArray
+    if len(gas_prices) > 0:
         gas_percentiles = np.percentile(
             gas_prices,
             percentiles,
         )
+    else:
+        gas_percentiles = [None] * len(percentiles)
 
     title = 'Block ' + str(block['number'])
     styles = cli.get_cli_styles()
     toolstr.print_text_box(title, style=styles['title'])
     cli.print_bullet(key='timestamp', value=block['timestamp'])
     cli.print_bullet(
         key='time', value=tooltime.timestamp_to_iso(block['timestamp'])
@@ -56,24 +61,25 @@
     cli.print_bullet(
         key='age',
         value=tooltime.timelength_to_phrase(
             round(time.time()) - block['timestamp']
         ),
     )
     cli.print_bullet(key='block_hash', value=block['hash'])
-    cli.print_bullet(key='n_transactions', value=len(block['transactions']))
+    cli.print_bullet(key='n_transactions', value=len(block_transactions))
     cli.print_bullet(
         key='gas used',
         value=(
             toolstr.format(block['gas_used'])
             + ' / '
             + toolstr.format(block['gas_limit'])
         ),
     )
-    if full_transactions:
+
+    if block_transactions is not None:
         percentile_label = (
             '('
             + ', '.join([str(percentile) + '%' for percentile in percentiles])
             + ')'
         )
         gas_percentiles_str = (
             '('
@@ -85,14 +91,15 @@
         cli.print_bullet(
             key='gas prices:',
             value=percentile_label + '=' + gas_percentiles_str,
         )
 
     message = block['extra_data']
     try:
-        message = binary_utils.binary_convert(message, 'binary').decode()
+        message = binary_utils.to_binary(message).decode()
     except Exception:
         if len(message) > 80:
             message = message[:77] + '...'
         else:
             message = message
     cli.print_bullet(key='message', value=message)
+
```

### Comparing `checkthechain-0.3.0/src/ctc/evm/block_utils/block_times/block_time_predictions.py` & `checkthechain-0.3.4/src/ctc/evm/block_utils/block_times/block_time_predictions.py`

 * *Files 8% similar despite different names*

```diff
@@ -8,70 +8,70 @@
 from ctc import evm
 from ctc import spec
 
 
 async def async_predict_block_timestamp(
     block: typing.SupportsInt,
     *,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     window_size: int = 88295,
 ) -> int:
     """predict timestamp of future block number"""
 
     block = int(block)
 
-    latest_block = await evm.async_get_block('latest', provider=provider)
+    latest_block = await evm.async_get_block('latest', context=context)
     latest_number = latest_block['number']
     if block == latest_number:
         return latest_block['timestamp']
     elif block < latest_number:
-        return await evm.async_get_block_timestamp(block, provider=provider)
+        return await evm.async_get_block_timestamp(block, context=context)
     else:
         old_block = await evm.async_get_block(
-            latest_number - window_size, provider=provider
+            latest_number - window_size, context=context
         )
         mean_block_time = (
             latest_block['timestamp'] - old_block['timestamp']
         ) / (latest_number - old_block['number'])
         return round(
             latest_block['timestamp']
             + (block - latest_number) * mean_block_time
         )
 
 
 async def async_predict_block_timestamps(
     blocks: typing.Sequence[typing.SupportsInt],
     *,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     window_size: int = 100000,
 ) -> typing.Sequence[int]:
     """predict timestamps of future block numbers"""
 
     import asyncio
 
     int_blocks = [int(block) for block in blocks]
 
     predictions = {}
     old_block_tasks = {}
     window_task = None
     new_blocks = []
 
-    latest_block = await evm.async_get_block('latest', provider=provider)
+    latest_block = await evm.async_get_block('latest', context=context)
     latest_number = latest_block['number']
 
     for block in int_blocks:
         if block == latest_number:
             predictions[block] = latest_block['timestamp']
         elif block < latest_number:
-            coroutine = evm.async_get_block_timestamp(block, provider=provider)
+            coroutine = evm.async_get_block_timestamp(block, context=context)
             old_block_tasks[block] = asyncio.create_task(coroutine)
         else:
             if window_task is None:
                 window_task = evm.async_get_block(
-                    latest_number - window_size, provider=provider
+                    latest_number - window_size, context=context
                 )
             new_blocks.append(block)
 
     # process new blocks
     if window_task is not None:
         old_block = await window_task
         mean_block_time = (
@@ -94,81 +94,81 @@
 
     return [predictions[block] for block in int_blocks]
 
 
 async def async_predict_timestamp_block(
     timestamp: tooltime.Timestamp,
     *,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     window_size: int = 86400 * 16,
 ) -> int:
     """predict block number of future timestamp"""
 
     import tooltime
 
     timestamp = tooltime.timestamp_to_seconds(timestamp)
 
-    latest_block = await evm.async_get_block('latest', provider=provider)
+    latest_block = await evm.async_get_block('latest', context=context)
     latest_timestamp = latest_block['timestamp']
 
     if timestamp == latest_timestamp:
         return latest_block['number']
     elif timestamp < latest_timestamp:
         return await evm.async_get_block_of_timestamp(
-            timestamp, provider=provider
+            timestamp, context=context
         )
     else:
         old_timestamp = latest_timestamp - window_size
         old_block = await evm.async_get_block_of_timestamp(
-            old_timestamp, provider=provider
+            old_timestamp, context=context
         )
         mean_blocks_per_time = (latest_block['number'] - old_block) / (
             latest_block['timestamp'] - old_timestamp
         )
         return round(
             latest_block['number']
             + (timestamp - latest_timestamp) * mean_blocks_per_time
         )
 
 
 async def async_predict_timestamp_blocks(
     timestamps: typing.Sequence[tooltime.Timestamp],
     *,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     window_size: int = 86400 * 16,
 ) -> typing.Sequence[int]:
     """predict timestamps of future block numbers"""
 
     import asyncio
     import tooltime
 
     int_timestamps = [
         tooltime.timestamp_to_seconds(timestamp) for timestamp in timestamps
     ]
 
-    latest_block = await evm.async_get_block('latest', provider=provider)
+    latest_block = await evm.async_get_block('latest', context=context)
     latest_timestamp = latest_block['timestamp']
     old_timestamp_tasks = {}
     new_timestamps = []
     window_task = None
 
     predictions: dict[int, int | float] = {}
     for timestamp in int_timestamps:
         if timestamp == latest_timestamp:
             predictions[timestamp] = latest_block['number']
         elif timestamp < latest_timestamp:
             coroutine = evm.async_get_block_of_timestamp(
-                timestamp, provider=provider
+                timestamp, context=context
             )
             old_timestamp_tasks[timestamp] = asyncio.create_task(coroutine)
         else:
             if window_task is None:
                 window_timestamp = latest_timestamp - window_size
                 window_coroutine = evm.async_get_block_of_timestamp(
-                    window_timestamp, provider=provider
+                    window_timestamp, context=context
                 )
                 window_task = asyncio.create_task(window_coroutine)
             new_timestamps.append(timestamp)
 
     if window_task is not None:
         window_block = await window_task
         mean_blocks_per_time = (latest_block['number'] - window_block) / (
@@ -181,7 +181,8 @@
 
     if len(old_timestamp_tasks) > 0:
         results = await asyncio.gather(*old_timestamp_tasks.values())
         for timestamp, result in zip(old_timestamp_tasks.keys(), results):
             predictions[timestamp] = result
 
     return [round(predictions[timestamp]) for timestamp in int_timestamps]
+
```

### Comparing `checkthechain-0.3.0/src/ctc/evm/block_utils/block_times/block_time_sampling.py` & `checkthechain-0.3.4/src/ctc/evm/block_utils/block_times/block_to_timestamp.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,75 +1,89 @@
 from __future__ import annotations
 
 import typing
 
 from ctc import spec
-from .. import block_crud
-from . import block_to_timestamp
-from . import timestamp_to_block
 
-if typing.TYPE_CHECKING:
-    import tooltime
+from .. import block_crud
+from .. import block_normalize
 
 
-async def async_sample_blocks(
+async def async_get_block_timestamp(
+    block: spec.BlockReference,
     *,
-    start_block: spec.BlockNumberReference | None = None,
-    end_block: spec.BlockNumberReference | None = None,
-    include_latest_if_trimmed: bool = True,
-    start_time: tooltime.Timestamp | None = None,
-    end_time: tooltime.Timestamp | None = None,
-    n_samples: int | None = None,
-    sample_interval: tooltime.Timelength | None = None,
-    window_size: tooltime.Timelength | None = None,
-    align_to: typing.Literal['start', 'end'] = 'start',
-    include_misaligned_bound: bool = False,
-    include_misaligned_overflow: bool = False,
-) -> typing.Sequence[int]:
-    """create sample of blocks matching input sampling parameters"""
-
-    import tooltime
-
-    if start_block is not None:
-        start_time = await block_to_timestamp.async_get_block_timestamp(
-            start_block
+    context: spec.Context = None,
+) -> int:
+    """get timestamp of block"""
+
+    from ctc import config
+
+    read_cache, write_cache = config.get_context_cache_read_write(
+        schema_name='block_timestamps', context=context
+    )
+    if isinstance(block, int) and read_cache:
+        from ctc import db
+
+        timestamp = await db.async_query_block_timestamp(
+            block_number=block,
+            context=context,
         )
-    if end_block is not None:
-        end_time = await block_to_timestamp.async_get_block_timestamp(end_block)
+        if timestamp is not None:
+            return timestamp
 
-    float_timestamps = tooltime.sample_timestamps(
-        start_time=start_time,
-        end_time=end_time,
-        n_samples=n_samples,
-        sample_interval=sample_interval,
-        window_size=window_size,
-        align_to=align_to,
-        include_misaligned_bound=include_misaligned_bound,
-        include_misaligned_overflow=include_misaligned_overflow,
+    block_data = await block_crud.async_get_block(block, context=context)
+    return block_data['timestamp']
+
+
+async def async_get_block_timestamps(
+    blocks: typing.Sequence[spec.BlockReference],
+    *,
+    context: spec.Context = None,
+) -> list[int]:
+    """get timestamps of blocks"""
+
+    from ctc import config
+
+    blocks = await block_normalize.async_block_numbers_to_int(
+        blocks=blocks,
+        context=context,
     )
-    timestamps: typing.Sequence[int] = [
-        round(timestamp) for timestamp in float_timestamps
-    ]
-
-    # time to latest block timestamp
-    latest_block = await block_crud.async_get_block('latest')
-    latest_block_timestamp = latest_block['timestamp']
-    n_original_timestamps = len(timestamps)
-    timestamps = [
-        timestamp
-        for timestamp in timestamps
-        if timestamp <= latest_block_timestamp
-    ]
-    trimmed = len(timestamps) != n_original_timestamps
-
-    # get blocks of timestamps
-    blocks = await timestamp_to_block.async_get_blocks_of_timestamps(
-        timestamps=timestamps,
+
+    # get timestamps from db
+    read_cache, write_cache = config.get_context_cache_read_write(
+        schema_name='block_timestamps', context=context
     )
+    if read_cache:
+        from ctc import db
 
-    # include latest if trimmed
-    if trimmed and include_latest_if_trimmed:
-        latest_block_number = latest_block['number']
-        if blocks[-1] != latest_block_number:
-            blocks.append(latest_block_number)
+        db_timestamps = await db.async_query_block_timestamps(
+            block_numbers=blocks,
+            context=context,
+        )
+        if db_timestamps is None:
+            db_timestamps = [None for block in blocks]
+        results: dict[int, int | None] = dict(zip(blocks, db_timestamps))
+        remaining_blocks: typing.Sequence[int] = [
+            block
+            for block, timestamp in zip(blocks, db_timestamps)
+            if timestamp is None
+        ]
+    else:
+        results = {}
+        remaining_blocks = blocks
+
+    # get timestamps from rpc
+    if len(remaining_blocks) > 0:
+        node_blocks = await block_crud.async_get_blocks(
+            blocks=remaining_blocks,
+            context=context,
+        )
+        for block_data in node_blocks:
+            results[block_data['number']] = block_data['timestamp']
 
-    return blocks
+    output: list[int] = []
+    for block in blocks:
+        result = results[block]
+        if result is None:
+            raise Exception('failed to get timestamp for block: ' + str(block))
+        output.append(result)
+    return output
```

### Comparing `checkthechain-0.3.0/src/ctc/evm/block_utils/block_times/timestamp_to_block/block_time_plural.py` & `checkthechain-0.3.4/src/ctc/evm/block_utils/block_times/timestamp_to_block/block_time_singular.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,105 +1,130 @@
 from __future__ import annotations
 
 import typing
 
+if typing.TYPE_CHECKING:
+    import tooltime
+
 from ctc import spec
+from ... import block_crud
 from . import block_time_search
-from . import block_time_singular
-
-if typing.TYPE_CHECKING:
-    from typing_extensions import Literal
 
 
-async def async_get_blocks_of_timestamps(
-    timestamps: typing.Sequence[int],
+async def async_get_block_of_timestamp(
+    timestamp: tooltime.Timestamp,
     *,
-    block_timestamps: typing.Optional[typing.Mapping[int, int]] = None,
-    block_number_array: typing.Optional[spec.NumpyArray] = None,
-    block_timestamp_array: typing.Optional[spec.NumpyArray] = None,
     nary: typing.Optional[int] = None,
     cache: typing.Optional[block_time_search.BlockTimestampSearchCache] = None,
-    provider: spec.ProviderReference = None,
-    use_db: bool = True,
-    mode: Literal['<=', '>=', '=='] = '>=',
-) -> list[int]:
-    """search for blocks corresponding to list of timestamps"""
+    block_timestamps: typing.Optional[typing.Mapping[int, int]] = None,
+    block_timestamp_array: typing.Optional[spec.NumpyArray] = None,
+    block_number_array: typing.Optional[spec.NumpyArray] = None,
+    verbose: bool = False,
+    context: spec.Context = None,
+    mode: typing.Literal['<=', '>=', '=='] = '>=',
+) -> int:
+    """search for the block that corresponds to a given timestamp"""
+
+    if not isinstance(timestamp, int):
+        import tooltime
+
+        timestamp = tooltime.timestamp_to_seconds(timestamp)
 
     if block_timestamps is not None or (
-        block_number_array is not None and block_timestamp_array is not None
+        block_timestamp_array is not None and block_number_array is not None
     ):
-        import numpy as np
+        return _get_block_of_timestamp_from_arrays(
+            timestamp=timestamp,
+            block_timestamp_array=block_timestamp_array,
+            block_number_array=block_number_array,
+            block_timestamps=block_timestamps,
+            verbose=verbose,
+        )
+    else:
+
+        from ctc import config
 
-        if mode != '>=':
-            raise NotImplementedError()
+        # db
+        read_cache, write_cache = config.get_context_cache_read_write(
+            schema_name='block_timestamps', context=context
+        )
+        if read_cache:
+            from ctc import db
 
-        if block_timestamp_array is None:
-            if block_timestamps is None:
-                raise Exception('must specify more arguments')
-            block_timestamp_array = np.array(list(block_timestamps.values()))
-        if block_number_array is None:
-            if block_timestamps is None:
-                raise Exception('must specify more arguments')
-            block_number_array = np.array(list(block_timestamps.keys()))
-
-        blocks = []
-        for timestamp in timestamps:
-            block = block_time_singular._get_block_of_timestamp_from_arrays(
+            block = await db.async_query_timestamp_block(
                 timestamp=timestamp,
-                block_timestamp_array=block_timestamp_array,
-                block_number_array=block_number_array,
-                verbose=False,
+                mode=mode,
+                context=context,
             )
-            blocks.append(block)
+            if block is not None:
+                return block
 
-        return blocks
+        # rpc node
+        return await block_time_search._async_get_block_of_timestamp_from_node(
+            timestamp=timestamp,
+            nary=nary,
+            cache=cache,
+            verbose=verbose,
+            context=context,
+            mode=mode,
+        )
 
-    else:
 
-        # get timestamps form db
-        if use_db:
-            from ctc import db
-            from ctc import rpc
+def _get_block_of_timestamp_from_arrays(
+    timestamp: tooltime.Timestamp,
+    *,
+    block_timestamp_array: spec.NumpyArray | None = None,
+    block_number_array: spec.NumpyArray | None = None,
+    block_timestamps: typing.Mapping[int, int] | None = None,
+    verbose: bool = False,
+) -> int:
+    import numpy as np
+
+    if block_timestamp_array is None:
+        if block_timestamps is None:
+            raise Exception('must specify more arguments')
+        block_timestamp_array = np.array(list(block_timestamps.values()))
+    if block_number_array is None:
+        if block_timestamps is None:
+            raise Exception('must specify more arguments')
+        block_number_array = np.array(list(block_timestamps.keys()))
+
+    if not isinstance(timestamp, int):
+        import tooltime
+
+        timestamp = tooltime.timestamp_to_seconds(timestamp)
+
+    index = np.searchsorted(block_timestamp_array, timestamp)
+    result = block_number_array[index]
+    if not isinstance(result, int):
+        raise Exception('invalid rpc result')
+    return result
 
-            network = rpc.get_provider_network(provider)
-            db_blocks = await db.async_query_timestamps_blocks(
-                network=network,
-                timestamps=timestamps,
-                mode=mode,
-            )
-            if db_blocks is None:
-                db_blocks = [None for timestamp in timestamps]
 
-            # package non-null results
-            results: dict[int, int] = {}
-            remaining_timestamps: list[int] = []
-            for possible_block, timestamp in zip(db_blocks, timestamps):
-                if possible_block is None:
-                    remaining_timestamps.append(timestamp)
-                else:
-                    results[timestamp] = possible_block
-        else:
-            remaining_timestamps = list(timestamps)
-            results = {}
-
-        # get timestamps from rpc node
-        if len(remaining_timestamps) > 0:
-            coroutines = []
-            for timestamp in remaining_timestamps:
-                coroutine = block_time_singular.async_get_block_of_timestamp(
-                    timestamp=timestamp,
-                    verbose=False,
-                    cache=cache,
-                    nary=nary,
-                    provider=provider,
-                    use_db=False,
-                    mode=mode,
-                )
-                coroutines.append(coroutine)
-            import asyncio
-
-            node_blocks = await asyncio.gather(*coroutines)
-            node_results = dict(zip(remaining_timestamps, node_blocks))
-            results.update(node_results)
+async def async_get_block_number_and_time(
+    *,
+    block_number: typing.Optional[spec.BlockNumberReference] = None,
+    block_timestamp: typing.Optional[tooltime.Timestamp] = None,
+    context: spec.Context = None,
+) -> tuple[int, int]:
+    """get block number and timestamp corresponding to given input"""
+
+    if block_timestamp is not None and block_number is not None:
+        raise Exception('must specify start_time or block_number')
+
+    if block_number is not None:
+        block = await block_crud.async_get_block(
+            block_number, context=context
+        )
+        return block['number'], block['timestamp']
+
+    elif block_timestamp is not None:
+        block_number = await async_get_block_of_timestamp(
+            block_timestamp, context=context
+        )
+        block = await block_crud.async_get_block(
+            block_number, context=context
+        )
+        return block['number'], block['timestamp']
 
-        # combine
-        return [results[timestamp] for timestamp in timestamps]
+    else:
+        raise Exception('must specify start_time or block_number')
```

### Comparing `checkthechain-0.3.0/src/ctc/evm/block_utils/block_times/timestamp_to_block/block_time_range.py` & `checkthechain-0.3.4/src/ctc/protocols/aave_v2_utils/aave_lending_pool.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,81 +1,89 @@
 from __future__ import annotations
 
 import typing
 
 from ctc import evm
 from ctc import spec
 
+from . import aave_spec
+
 if typing.TYPE_CHECKING:
     import tooltime
 
 
-@typing.overload
-async def async_resolve_block_range(
+async def async_get_deposits(
     *,
     start_block: spec.BlockNumberReference | None = None,
     end_block: spec.BlockNumberReference | None = None,
     start_time: tooltime.Timestamp | None = None,
     end_time: tooltime.Timestamp | None = None,
-    allow_none: typing.Literal[False],
-    provider: spec.ProviderReference = None,
-) -> tuple[spec.BlockNumberReference, spec.BlockNumberReference]:
-    ...
-
+    include_timestamps: bool = False,
+    context: spec.Context = None,
+) -> spec.DataFrame:
+
+    start_block, end_block = await evm.async_resolve_block_range(
+        start_block=start_block,
+        end_block=end_block,
+        start_time=start_time,
+        end_time=end_time,
+        allow_none=True,
+        context=context,
+    )
+
+    if end_block is None:
+        end_block = 'latest'
+
+    aave_lending_pool = aave_spec.get_aave_address(
+        name='LendingPool',
+        context=context,
+    )
+    events = await evm.async_get_events(
+        contract_address=aave_lending_pool,
+        event_name='Deposit',
+        start_block=start_block,
+        end_block=end_block,
+        include_timestamps=include_timestamps,
+        verbose=False,
+        context=context,
+    )
 
-@typing.overload
-async def async_resolve_block_range(
-    *,
-    start_block: spec.BlockNumberReference | None = None,
-    end_block: spec.BlockNumberReference | None = None,
-    start_time: tooltime.Timestamp | None = None,
-    end_time: tooltime.Timestamp | None = None,
-    allow_none: bool,
-    provider: spec.ProviderReference = None,
-) -> tuple[spec.BlockNumberReference | None, spec.BlockNumberReference | None]:
-    ...
+    return events
 
 
-async def async_resolve_block_range(
+async def async_get_withdrawals(
     *,
     start_block: spec.BlockNumberReference | None = None,
     end_block: spec.BlockNumberReference | None = None,
     start_time: tooltime.Timestamp | None = None,
     end_time: tooltime.Timestamp | None = None,
-    allow_none: bool,
-    provider: spec.ProviderReference = None,
-) -> tuple[spec.BlockNumberReference | None, spec.BlockNumberReference | None]:
-    """resolve block or timestamp range to a block range"""
-
-    import asyncio
-
-    tasks = {}
-    if start_block is not None:
-        start_block = start_block
-    elif start_time is not None:
-        tasks['start_block'] = asyncio.create_task(
-            evm.async_get_block_of_timestamp(start_time, provider=provider)
-        )
-    else:
-        if allow_none:
-            start_block = None
-        else:
-            raise Exception('must specify start_block or start_time')
-
-    if end_block is not None:
-        end_block = end_block
-    elif end_time is not None:
-        tasks['end_block'] = asyncio.create_task(
-            evm.async_get_block_of_timestamp(end_time, provider=provider)
-        )
-    else:
-        if allow_none:
-            end_block = None
-        else:
-            raise Exception('must specify end_block or end_time')
-
-    if 'start_block' in tasks:
-        start_block = await tasks['start_block']
-    if 'end_block' in tasks:
-        end_block = await tasks['end_block']
+    include_timestamps: bool = False,
+    context: spec.Context = None,
+) -> spec.DataFrame:
+
+    start_block, end_block = await evm.async_resolve_block_range(
+        start_block=start_block,
+        end_block=end_block,
+        start_time=start_time,
+        end_time=end_time,
+        allow_none=True,
+        context=context,
+    )
+
+    if end_block is None:
+        end_block = 'latest'
+
+    aave_lending_pool = aave_spec.get_aave_address(
+        name='LendingPool',
+        context=context,
+    )
+    events = await evm.async_get_events(
+        contract_address=aave_lending_pool,
+        event_name='Withdraw',
+        start_block=start_block,
+        include_timestamps=include_timestamps,
+        end_block=end_block,
+        verbose=False,
+        context=context,
+    )
 
-    return start_block, end_block
+    return events
```

### Comparing `checkthechain-0.3.0/src/ctc/evm/block_utils/block_times/timestamp_to_block/block_time_search.py` & `checkthechain-0.3.4/src/ctc/evm/block_utils/block_times/timestamp_to_block/block_time_search.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,78 +1,82 @@
 # TODO: rename this file to block_time_rpc
 from __future__ import annotations
 
 import functools
 import typing
 
 from ctc import spec
-from .. import block_crud
+from ... import block_crud
 
 if typing.TYPE_CHECKING:
     from typing_extensions import TypedDict, Literal
 
     class BlockTimestampSearchCache(TypedDict):
         initializing: dict[int, bool]
         timestamps: dict[int, int]
 
 
 async def _async_get_block_of_timestamp_from_node(
     timestamp: int,
     *,
     nary: typing.Optional[int] = None,
     cache: typing.Optional[BlockTimestampSearchCache] = None,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     mode: Literal['<=', '>=', '=='] = '>=',
     verbose: bool = True,
-    use_db_assist: bool = True,
 ) -> int:
     """
 
     - could make this efficiently parallelizable to multiple timestamps by sharing cache
         - would need to remove the initializing key from the shared cache
     """
 
+    from ctc import config
     from ctc.toolbox import search_utils
 
     if nary is None:
         nary = 6
 
     if cache is None:
         cache = {'initializing': {timestamp: True}, 'timestamps': {}}
 
     async_is_match = functools.partial(
-        _async_is_match_block_of_timestamp, timestamp=timestamp, cache=cache
+        _async_is_match_block_of_timestamp,
+        timestamp=timestamp,
+        cache=cache,
+        context=context,
     )
     get_next_probes = functools.partial(
         _get_next_probes_block_of_timestamp,
         timestamp=timestamp,
         cache=cache,
         debug=verbose,
     )
 
     # determine search range
     start_index: int | None = None
     end_index: int | None = None
-    if use_db_assist:
+    read_cache, write_cache = config.get_context_cache_read_write(
+        schema_name='block_timestamps', context=context
+    )
+    if read_cache:
         from ctc import db
-        from ctc import rpc
 
-        network = rpc.get_provider_network(provider)
         result = await db.async_query_timestamp_block_range(
-            timestamp, network=network
+            timestamp, context=context
         )
         if result is not None:
             start_index, end_index = result
             if start_index == end_index and start_index is not None:
                 return start_index
     if start_index is None:
         start_index = 1
     if end_index is None:
         end_index = await block_crud.async_get_latest_block_number(
-            provider=provider
+            context=context,
         )
 
     try:
         block = await search_utils.async_nary_search(
             nary=nary,
             start_index=start_index,
             end_index=end_index,
@@ -85,48 +89,48 @@
         else:
             raise Exception('no block after timestamp: ' + str(timestamp))
 
     if block is None:
         raise Exception('could not find block for timestamp')
 
     if mode == '==':
-        block_data = await block_crud.async_get_block(block)
+        block_data = await block_crud.async_get_block(block, context=context)
         if block_data['timestamp'] == timestamp:
             return block
         else:
             raise Exception(
                 'there is no block with timestamp ' + str(timestamp)
             )
     elif mode == '<=':
         if block == 0:
             raise Exception('no block exists <= timestamp')
-        block_data = await block_crud.async_get_block(block)
+        block_data = await block_crud.async_get_block(block, context=context)
         if block_data['timestamp'] == timestamp:
             return block
         else:
             return block - 1
     else:
         return block
 
 
 async def _async_is_match_block_of_timestamp(
     block_numbers: list[int],
     timestamp: int,
     *,
     cache: BlockTimestampSearchCache,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
 ) -> list[bool]:
 
     # retrieve values not in cache
     not_in_cache = [
         block_number
         for block_number in block_numbers
         if block_number not in cache['timestamps']
     ]
-    gotten = await block_crud.async_get_blocks(not_in_cache, provider=provider)
+    gotten = await block_crud.async_get_blocks(not_in_cache, context=context)
     for block_number, block in zip(not_in_cache, gotten):
         cache['timestamps'][block_number] = block['timestamp']
 
     # compute results
     return [
         cache['timestamps'][block_number] >= timestamp
         for block_number in block_numbers
@@ -190,7 +194,8 @@
                 target_index += 1
 
             n_probes = nary - 1
             half = int(n_probes / 2)
             probes = [target_index + i for i in range(-half, n_probes - half)]
 
             return probes
+
```

### Comparing `checkthechain-0.3.0/src/ctc/evm/erc20_utils/erc20_events.py` & `checkthechain-0.3.4/src/ctc/evm/erc20_utils/erc20_events.py`

 * *Files 22% similar despite different names*

```diff
@@ -29,120 +29,171 @@
     *,
     start_block: typing.Optional[spec.BlockNumberReference] = None,
     end_block: typing.Optional[spec.BlockNumberReference] = None,
     start_time: tooltime.Timestamp | None = None,
     end_time: tooltime.Timestamp | None = None,
     include_timestamps: bool = False,
     normalize: bool = True,
-    convert_from_str: bool = True,
     verbose: bool = False,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     **event_kwargs: typing.Any,
 ) -> spec.DataFrame:
     """get transfer events of ERC20 token"""
 
-    from ctc import rpc
-
-    network = rpc.get_provider_network(provider)
     token_address = await erc20_metadata.async_get_erc20_address(
-        token, network=network
+        token, context=context
     )
 
     # use token's own abi if available, otherwise fallback to standard
     # do this because tokens sometimes have different values for event args
     try:
         event_abi = await abi_utils.async_get_event_abi(
-            contract_address=token, event_name='Transfer'
+            contract_address=token,
+            event_name='Transfer',
+            context=context,
         )
     except Exception:
         event_abi = erc20_spec.erc20_event_abis['Transfer']
 
     transfers = await event_utils.async_get_events(
         contract_address=token_address,
         event_abi=event_abi,
         start_block=start_block,
         end_block=end_block,
         start_time=start_time,
         end_time=end_time,
         include_timestamps=include_timestamps,
         verbose=verbose,
-        provider=provider,
+        context=context,
         **event_kwargs,
     )
 
     # make amount column name the same across all tokens
     old_column = 'arg__' + event_abi['inputs'][2]['name']
     column = 'arg__amount'
-    transfers = transfers.rename(columns={old_column: column})
-
-    # convert from str amounts to int amounts
-    if convert_from_str:
-        transfers[column] = transfers[column].map(int)
+    transfers = transfers.rename({old_column: column})
 
     # normalize
     if normalize and len(transfers) > 0:
 
-        if not convert_from_str:
-            raise Exception(
-                'cannot normalize without str conversion'
-                ', use normalize=False or convert_from_str=True'
-            )
+        import polars as pl
+        import numpy as np
 
         decimals = await erc20_metadata.async_get_erc20_decimals(
             token=token_address,
-            block=transfers.index.values[0][0],
+            block=transfers['block_number'][0],
+            context=context,
         )
-        dtype = float
-        transfers[column] = transfers[column] / dtype('1e' + str(decimals))
-
-    else:
-
-        # prevent implicit conversion to int64
-        # - this happens to ERC20's that use small number of decimals
-        # - keep all quantities as native python ints for consistency
-        if transfers[column].dtype.name != 'object':
-            transfers[column] = transfers[column].astype(object)
+        factor = float('1e' + str(decimals))
+        normalized = np.array(transfers[column].to_list(), dtype=float) / factor
+        transfers = transfers.with_columns(pl.Series(column, normalized))
 
     return transfers
 
 
 async def async_get_erc20_balances_from_transfers(
     transfers: spec.DataFrame,
     *,
     block: typing.Optional[spec.BlockNumberReference] = None,
-    dtype: typing.Optional[
-        typing.Union[typing.Type[int], typing.Type[float]]
-    ] = None,
     normalize: bool = False,
+    context: spec.Context = None,
 ) -> spec.DataFrame:
     """compute ERC20 balance of each wallet using Transfer events"""
 
+    import polars as pl
+
     # filter block
     if block is not None:
-        blocks = transfers.index.get_level_values('block_number').values
-        mask = blocks <= block
-        transfers = transfers[mask]
+        transfers = transfers.filter(pl.col('block_number') <= block)
 
     amount_key = _get_token_amount_column(transfers)
 
-    # convert to float
-    if dtype is not None:
-        transfers[amount_key] = transfers[amount_key].map(dtype)
-
     # subtract transfers out from transfers in
-    from_transfers = transfers.groupby('arg__from')[amount_key].sum()
-    to_transfers = transfers.groupby('arg__to')[amount_key].sum()
-    balances: spec.DataFrame = to_transfers.sub(from_transfers, fill_value=0)
+    from_transfers = transfers.groupby('arg__from').agg(pl.sum(amount_key))
+    to_transfers = transfers.groupby('arg__to').agg(pl.sum(amount_key))
+    balances: spec.DataFrame = to_transfers.sub(from_transfers, fill_value=0)  # type: ignore
 
     if normalize:
         decimals = await erc20_metadata.async_get_erc20_decimals(
-            transfers['contract_address'].values[0]
+            typing.cast(str, transfers['contract_address'][0]),
+            context=context,
         )
-        balances /= 10 ** decimals
+        balances /= 10**decimals
 
     # sort
     balances = balances.sort_values(ascending=False)  # type: ignore
 
-    balances.name = 'balance'
-    balances.index.name = 'address'
-
     return balances
+
+
+def _decode_erc20_transfers(transfers: spec.DataFrame) -> spec.DataFrame:
+
+    import polars as pl
+    from ctc.toolbox import pl_utils
+
+    # filter ERC721 based on whether topic3 is indexed
+    decoded = transfers.filter(pl.col('topic3').is_null())
+
+    # filter transfers that do not conform to ERC20 specification
+    decoded = decoded.filter(
+        (~pl.col('topic1').is_null()) & (~pl.col('topic2').is_null())
+    )
+
+    if len(decoded) == 0:
+        return pl.DataFrame(
+            [],
+            schema={
+                'block_number': pl.Int64,
+                'transaction_index': pl.Int64,
+                'log_index': pl.Int64,
+                'transaction_hash': pl.Binary,
+                'contract_address': pl.Binary,
+                'from': pl.Binary,
+                'to': pl.Binary,
+                'value_binary': pl.Binary,
+                'value_float': pl.Float64,
+            },
+        )
+
+    # drop extra columns
+    decoded = decoded.drop(['event_hash', 'topic3'])
+
+    # slice topic1 and topic2 to address width
+    decoded = decoded.with_columns(
+        '0x' + decoded['topic1'].str.slice(-40),
+        '0x' + decoded['topic2'].str.slice(-40),
+    )
+
+    # strip zeros on unindexed data
+    decoded = decoded.with_columns(
+        pl.when(pl.col('unindexed').str.lstrip('0x').str.lengths() % 2 == 0)
+        .then(pl.col('unindexed').str.lstrip('0x'))
+        .otherwise('0' + pl.col('unindexed').str.lstrip('0x'))
+    )
+
+    # create value_float column
+    decoded = decoded.with_columns(
+        decoded['unindexed']
+        .apply(lambda x: 0.0 if x == '' else float(int(x, 16)))
+        .alias('value_float')
+    )
+
+    # convert binary fields
+    decoded = pl_utils.prefix_hex_columns_to_binary(
+        decoded,
+        columns=['transaction_hash', 'contract_address', 'topic1', 'topic2'],
+    )
+    decoded = pl_utils.raw_hex_columns_to_binary(
+        decoded,
+        columns=['unindexed'],
+    )
+
+    # rename according to ERC20 conventions
+    rename = {
+        'topic1': 'from',
+        'topic2': 'to',
+        'unindexed': 'value_binary',
+    }
+    decoded = decoded.rename(rename)
+
+    return decoded
+
```

### Comparing `checkthechain-0.3.0/src/ctc/evm/erc20_utils/erc20_generic.py` & `checkthechain-0.3.4/src/ctc/evm/erc20_utils/erc20_generic.py`

 * *Files 13% similar despite different names*

```diff
@@ -8,64 +8,76 @@
 
 
 async def async_erc20_eth_call(
     function_name: str,
     token: spec.ERC20Reference,
     *,
     block: typing.Optional[spec.BlockNumberReference] = None,
+    context: spec.Context = None,
     **rpc_kwargs: typing.Any,
 ) -> typing.Any:
     """perform eth_call for an erc20"""
 
     from ctc import rpc
 
-    address = await erc20_metadata.async_get_erc20_address(token)
+    address = await erc20_metadata.async_get_erc20_address(
+        token, context=context
+    )
     return await rpc.async_eth_call(
         to_address=address,
         function_abi=erc20_spec.erc20_function_abis[function_name],
         block_number=block,
+        context=context,
         **rpc_kwargs,
     )
 
 
 async def async_erc20s_eth_calls(
     function_name: str,
     tokens: typing.Iterable[spec.ERC20Reference],
     *,
     block: typing.Optional[spec.BlockNumberReference] = None,
+    context: spec.Context = None,
     **rpc_kwargs: typing.Any,
-) -> list[typing.Any]:
+) -> typing.Sequence[typing.Any]:
     """perform eth_call for multiple erc20s"""
 
     import asyncio
     from ctc import rpc
 
     coroutines = [
-        erc20_metadata.async_get_erc20_address(token) for token in tokens
+        erc20_metadata.async_get_erc20_address(token, context=context)
+        for token in tokens
     ]
     addresses = await asyncio.gather(*coroutines)
     return await rpc.async_batch_eth_call(
         to_addresses=addresses,
         function_abi=erc20_spec.erc20_function_abis[function_name],
         block_number=block,
+        context=context,
         **rpc_kwargs,
     )
 
 
 async def async_erc20_eth_call_by_block(
     function_name: str,
     token: spec.ERC20Reference,
     *,
     blocks: typing.Iterable[spec.BlockNumberReference],
+    context: spec.Context = None,
     **rpc_kwargs: typing.Any,
-) -> list[typing.Any]:
+) -> typing.Sequence[typing.Any]:
     """perform eth_call for an erc20 across multiple blocks"""
 
     from ctc import rpc
 
-    address = await erc20_metadata.async_get_erc20_address(token)
+    address = await erc20_metadata.async_get_erc20_address(
+        token, context=context
+    )
     return await rpc.async_batch_eth_call(
         to_address=address,
         function_abi=erc20_spec.erc20_function_abis[function_name],
         block_numbers=blocks,
+        context=context,
         **rpc_kwargs,
     )
+
```

### Comparing `checkthechain-0.3.0/src/ctc/evm/erc20_utils/erc20_metadata.py` & `checkthechain-0.3.4/src/ctc/evm/erc20_utils/erc20_metadata.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,65 +1,68 @@
 from __future__ import annotations
 
 import typing
 
-from ctc import config
 from ctc import spec
 from .. import abi_utils
 from .. import address_utils
 from .. import binary_utils
 from . import erc20_generic
 from . import erc20_spec
 
 
 async def async_get_erc20_address(
     token: spec.ERC20Reference,
-    network: spec.NetworkReference | None = None,
     *,
+    context: spec.Context = None,
     case_insensitive_query: bool = True,
 ) -> spec.ERC20Address:
     """return address of input token, input as either symbol or address"""
 
+    if isinstance(token, bytes):
+        token = binary_utils.to_hex(token)
+
     if address_utils.is_address_str(token):
         return token
     elif isinstance(token, str):
         from ctc import db
 
-        if network is None:
-            network = config.get_default_network()
-
         metadata = await db.async_query_erc20_metadata(
             symbol=token,
-            network=network,
+            context=context,
         )
 
         # if no result, try again case insensitive
         if metadata is None:
             metadata = await db.async_query_erc20_metadata(
                 symbol=token,
-                network=network,
+                context=context,
                 case_insensitive_symbol=case_insensitive_query,
             )
 
         if metadata is not None:
             address = metadata['address']
             if isinstance(address, str):
                 return address
 
     raise Exception('could not get token address')
 
 
 async def async_is_erc20(
     address_or_abi: spec.Address | spec.ContractABI,
+    *,
+    context: spec.Context = None,
 ) -> bool:
     """return whether an address implements ERC20 spec in its abi"""
 
     # get contract abi
     if address_utils.is_address_str(address_or_abi):
-        contract_abi = await abi_utils.async_get_contract_abi(address_or_abi)
+        contract_abi = await abi_utils.async_get_contract_abi(
+            address_or_abi, context=context
+        )
     elif isinstance(address_or_abi, list):
         contract_abi = address_or_abi
     contract_abi_by_selectors = abi_utils.get_contract_abi_by_selectors(
         contract_abi
     )
 
     # get erc20 abi
@@ -70,50 +73,47 @@
     # compare abis
     for selector in erc20_abi_by_selectors.keys():
         if selector not in contract_abi_by_selectors:
             return False
     return True
 
 
-async def async_get_default_erc20_tokens() -> typing.Sequence[
-    spec.ERC20Metadata
-]:
+async def async_get_default_erc20_tokens(
+    context: spec.Context = None,
+) -> typing.Sequence[spec.ERC20Metadata]:
     """get list of default ERC20s
 
     TODO: add db table for tracking erc20 token lists
     - use a token list as tokens to check during block exploration
     - "default" can be one of the token lists
     """
     from ctc.config.setup_utils.default_data import default_erc20s
 
-    return default_erc20s.load_default_erc20s()
+    return default_erc20s.load_default_erc20s(context=context)
 
 
 async def async_get_erc20_metadata(
     token: spec.ERC20Reference,
     *,
     block: typing.Optional[spec.BlockNumberReference] = None,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     **rpc_kwargs: typing.Any,
 ) -> spec.ERC20Metadata:
     """get metadata for ERC20 token"""
 
-    from ctc import rpc
-
-    network = rpc.get_provider_network(provider)
-    address = await async_get_erc20_address(token, network=network)
+    address = await async_get_erc20_address(token, context=context)
 
     symbol_coroutine = async_get_erc20_symbol(
-        token=token, block=block, provider=provider, **rpc_kwargs
+        token=token, block=block, context=context, **rpc_kwargs
     )
     decimals_coroutine = async_get_erc20_decimals(
-        token=token, block=block, provider=provider, **rpc_kwargs
+        token=token, block=block, context=context, **rpc_kwargs
     )
     name_coroutine = async_get_erc20_name(
-        token=token, block=block, provider=provider, **rpc_kwargs
+        token=token, block=block, context=context, **rpc_kwargs
     )
 
     import asyncio
 
     symbol, decimals, name = await asyncio.gather(
         symbol_coroutine,
         decimals_coroutine,
@@ -133,253 +133,340 @@
 #
 
 
 async def async_get_erc20_decimals(
     token: spec.ERC20Reference,
     *,
     block: typing.Optional[spec.BlockNumberReference] = None,
-    use_db: bool = True,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     **rpc_kwargs: typing.Any,
 ) -> int:
     """get decimals of an erc20"""
 
+    from ctc import config
+
     result: spec.ERC20Metadata | None = None
 
-    if use_db:
+    read_cache, write_cache = config.get_context_cache_read_write(
+        schema_name='erc20_metadata', context=context
+    )
+
+    if read_cache:
         from ctc import db
-        from ctc import rpc
 
-        network = rpc.get_provider_network(provider)
-        token = await async_get_erc20_address(token, network=network)
+        token = await async_get_erc20_address(token, context=context)
         result = await db.async_query_erc20_metadata(
-            address=token, network=network
+            address=token, context=context
         )
         if result is not None and result['decimals'] is not None:
             return result['decimals']
 
     decimals_result = await erc20_generic.async_erc20_eth_call(
         function_name='decimals',
         token=token,
         block=block,
-        provider=provider,
+        context=context,
         **rpc_kwargs,
     )
-    if not isinstance(decimals_result, int):
+    if not isinstance(decimals_result, int) and not rpc_kwargs.get(
+        'convert_reverts_to_none'
+    ):
         raise Exception('invalid rpc result')
     decimals = decimals_result
 
-    if use_db:
+    if write_cache:
         if result is not None:
             result['decimals'] = decimals
         else:
             data = {'address': token, 'decimals': decimals}
             if typing.TYPE_CHECKING:
                 result = typing.cast(spec.ERC20Metadata, data)
             else:
                 result = data
-        await db.async_intake_erc20_metadata(network=network, **result)
+        await db.async_intake_erc20_metadata(context=context, **result)
 
     return decimals
 
 
 async def async_get_erc20s_decimals(
     tokens: typing.Iterable[spec.ERC20Reference],
     *,
     block: typing.Optional[spec.BlockNumberReference] = None,
+    context: spec.Context = None,
     **rpc_kwargs: typing.Any,
-) -> list[int]:
+) -> typing.Sequence[int]:
     """get decimals of multiple erc20s"""
     return await erc20_generic.async_erc20s_eth_calls(
-        function_name='decimals', tokens=tokens, block=block, **rpc_kwargs
+        function_name='decimals',
+        tokens=tokens,
+        block=block,
+        context=context,
+        **rpc_kwargs,
     )
 
 
 async def async_get_erc20_decimals_by_block(
     token: spec.ERC20Reference,
     *,
     blocks: typing.Sequence[spec.BlockNumberReference],
+    context: spec.Context = None,
     **rpc_kwargs: typing.Any,
-) -> list[int]:
+) -> typing.Sequence[int]:
     """get decimals of an erc20 across multiple blocks"""
     return await erc20_generic.async_erc20_eth_call_by_block(
         function_name='decimals',
         token=token,
         blocks=blocks,
+        context=context,
         **rpc_kwargs,
     )
 
 
 #
 # # name
 #
 
 
+@typing.overload
+async def async_get_erc20_name(
+    token: spec.ERC20Reference,
+    *,
+    block: typing.Optional[spec.BlockNumberReference] = None,
+    context: spec.Context = None,
+    convert_reverts_to_none: typing.Literal[True],
+    **rpc_kwargs: typing.Any,
+) -> str | None:
+    ...
+
+
+@typing.overload
 async def async_get_erc20_name(
     token: spec.ERC20Reference,
     *,
     block: typing.Optional[spec.BlockNumberReference] = None,
-    use_db: bool = True,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
+    convert_reverts_to_none: typing.Literal[False] = False,
     **rpc_kwargs: typing.Any,
 ) -> str:
+    ...
+
+
+@typing.overload
+async def async_get_erc20_name(
+    token: spec.ERC20Reference,
+    *,
+    block: typing.Optional[spec.BlockNumberReference] = None,
+    context: spec.Context = None,
+    convert_reverts_to_none: bool,
+    **rpc_kwargs: typing.Any,
+) -> str | None:
+    ...
+
+
+async def async_get_erc20_name(
+    token: spec.ERC20Reference,
+    *,
+    block: typing.Optional[spec.BlockNumberReference] = None,
+    context: spec.Context = None,
+    convert_reverts_to_none: bool = False,
+    **rpc_kwargs: typing.Any,
+) -> str | None:
     """get name of an erc20"""
 
+    from ctc import config
+
+    read_cache, write_cache = config.get_context_cache_read_write(
+        schema_name='erc20_metadata', context=context
+    )
+
     result: spec.ERC20Metadata | None = None
-    if use_db:
+    if read_cache:
         from ctc import db
-        from ctc import rpc
 
-        network = rpc.get_provider_network(provider)
-        token = await async_get_erc20_address(token, network=network)
+        token = await async_get_erc20_address(token, context=context)
         result = await db.async_query_erc20_metadata(
-            address=token, network=network
+            address=token, context=context
         )
         if result is not None and result['name'] is not None:
             return result['name']
 
-    rpc_result = await erc20_generic.async_erc20_eth_call(
+    rpc_result: str | None = await erc20_generic.async_erc20_eth_call(
         function_name='name',
         token=token,
         block=block,
-        provider=provider,
+        context=context,
         **rpc_kwargs,
     )
-    if not isinstance(rpc_result, str):
+    if not isinstance(rpc_result, str) and not convert_reverts_to_none:
         raise Exception('invalid rpc result')
     name = rpc_result
 
-    if use_db:
+    if write_cache:
         if result is not None:
             result['name'] = name
         else:
             data = {'address': token, 'name': name}
             if typing.TYPE_CHECKING:
                 result = typing.cast(spec.ERC20Metadata, data)
             else:
                 result = data
 
-        await db.async_intake_erc20_metadata(network=network, **result)
+        await db.async_intake_erc20_metadata(context=context, **result)
 
     return name
 
 
 async def async_get_erc20s_names(
     tokens: typing.Iterable[spec.ERC20Reference],
+    *,
     block: typing.Optional[spec.BlockNumberReference] = None,
+    context: spec.Context = None,
     **rpc_kwargs: typing.Any,
-) -> list[str]:
+) -> typing.Sequence[str]:
     """get name of multiple erc20s"""
     return await erc20_generic.async_erc20s_eth_calls(
-        function_name='name', tokens=tokens, block=block, **rpc_kwargs
+        function_name='name',
+        tokens=tokens,
+        block=block,
+        context=context,
+        **rpc_kwargs,
     )
 
 
 async def async_get_erc20_name_by_block(
     token: spec.ERC20Reference,
+    *,
     blocks: typing.Iterable[spec.BlockNumberReference],
+    context: spec.Context = None,
     **rpc_kwargs: typing.Any,
-) -> list[str]:
+) -> typing.Sequence[str]:
     """get name of an erc20 across multiple blocks"""
     return await erc20_generic.async_erc20_eth_call_by_block(
-        function_name='name', token=token, blocks=blocks, **rpc_kwargs
+        function_name='name',
+        token=token,
+        blocks=blocks,
+        context=context,
+        **rpc_kwargs,
     )
 
 
 #
 # # symbol
 #
 
 
-def _decode_raw_symbol(data: str | None) -> str:
+def _decode_raw_symbol(data: str | None, none_value: str | None = None) -> str:
     """special case decode of ancient non-compliant implementations of symbol"""
+
     if data is None:
-        return ''
+        if none_value is None:
+            none_value = ''
+        return none_value
     elif len(data) == 66:
         return binary_utils.binary_to_text(data).strip('\x00')
     elif len(data) == 0 or data == '0x':
         return ''
     else:
-        as_binary = binary_utils.binary_convert(data, 'binary')
+        as_binary = binary_utils.to_binary(data)
         as_str: str = abi_utils.abi_decode(as_binary, '(string)')[0]
         return as_str
 
 
 async def async_get_erc20_symbol(
     token: spec.ERC20Reference,
     *,
     block: typing.Optional[spec.BlockNumberReference] = None,
-    use_db: bool = True,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
+    convert_reverts_to: str | None = None,
     **rpc_kwargs: typing.Any,
 ) -> str:
     """get symbol of an erc20"""
 
-    if use_db:
+    from ctc import config
+
+    read_cache, write_cache = config.get_context_cache_read_write(
+        schema_name='erc20_metadata', context=context
+    )
+
+    if read_cache:
         from ctc import db
-        from ctc import rpc
 
-        network = rpc.get_provider_network(provider)
-        token = await async_get_erc20_address(token, network=network)
+        token = await async_get_erc20_address(token, context=context)
         result: spec.ERC20Metadata | None = await db.async_query_erc20_metadata(
-            address=token, network=network
+            address=token, context=context
         )
         if result is not None and result['symbol'] is not None:
             return result['symbol']
 
     symbol_raw = await erc20_generic.async_erc20_eth_call(
         function_name='symbol',
         token=token,
         block=block,
         decode_response=False,
-        provider=provider,
+        context=context,
+        convert_reverts_to_none=(convert_reverts_to is not None),
         **rpc_kwargs,
     )
-    symbol = _decode_raw_symbol(symbol_raw)
+    symbol = _decode_raw_symbol(symbol_raw, none_value=convert_reverts_to)
 
-    if use_db:
+    if write_cache:
         if result is not None:
             result['symbol'] = symbol
         else:
             data = {'address': token, 'symbol': symbol}
             if typing.TYPE_CHECKING:
                 result = typing.cast(spec.ERC20Metadata, data)
             else:
                 result = data
 
-        await db.async_intake_erc20_metadata(network=network, **result)
+        await db.async_intake_erc20_metadata(context=context, **result)
 
     return symbol
 
 
 async def async_get_erc20s_symbols(
     tokens: typing.Iterable[spec.ERC20Reference],
     *,
     block: typing.Optional[spec.BlockNumberReference] = None,
+    context: spec.Context = None,
+    convert_reverts_to: str | None = None,
     **rpc_kwargs: typing.Any,
-) -> list[str]:
+) -> typing.Sequence[str]:
     """get symbol of multiple erc20s"""
     results = await erc20_generic.async_erc20s_eth_calls(
         function_name='symbol',
         tokens=tokens,
         block=block,
         decode_response=False,
+        context=context,
+        convert_reverts_to_none=(convert_reverts_to is not None),
         **rpc_kwargs,
     )
-    return [_decode_raw_symbol(result) for result in results]
+    return [
+        _decode_raw_symbol(result, none_value=convert_reverts_to)
+        for result in results
+    ]
 
 
 async def async_get_erc20_symbol_by_block(
     token: spec.ERC20Reference,
     *,
     blocks: typing.Iterable[spec.BlockNumberReference],
+    context: spec.Context = None,
+    convert_reverts_to: str | None = None,
     **rpc_kwargs: typing.Any,
-) -> list[str]:
+) -> typing.Sequence[str]:
     """get symbol of an erc20 across multiple blocks"""
     results = await erc20_generic.async_erc20_eth_call_by_block(
         function_name='symbol',
         token=token,
         blocks=blocks,
         decode_response=False,
+        context=context,
+        convert_reverts_to_none=(convert_reverts_to is not None),
         **rpc_kwargs,
     )
-    return [_decode_raw_symbol(result) for result in results]
+    return [
+        _decode_raw_symbol(result, none_value=convert_reverts_to)
+        for result in results
+    ]
+
```

### Comparing `checkthechain-0.3.0/src/ctc/evm/erc20_utils/erc20_normalize.py` & `checkthechain-0.3.4/src/ctc/evm/erc20_utils/erc20_normalize.py`

 * *Files 16% similar despite different names*

```diff
@@ -7,74 +7,101 @@
 from . import erc20_metadata
 
 
 async def async_normalize_erc20_quantity(
     quantity: typing.SupportsFloat,
     token: typing.Optional[spec.ERC20Address] = None,
     *,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     decimals: typing.Optional[typing.SupportsInt] = None,
     block: typing.Optional[spec.BlockNumberReference] = None,
 ) -> float:
     """convert raw erc20 quantity by adjusting radix by (10 ** decimals)"""
 
     if quantity == 0:
         return 0
 
     # get decimals
     if decimals is None:
         if token is None:
             raise Exception('must specify token or decimals')
         decimals_value: int = await erc20_metadata.async_get_erc20_decimals(
             token,
-            provider=provider,
+            context=context,
             block=block,
         )
     else:
         decimals_value = int(decimals)
 
     # normalize
-    return float(quantity) / int(10 ** decimals_value)
+    return float(quantity) / int(10**decimals_value)
 
 
+@typing.overload
 async def async_normalize_erc20_quantities(
-    quantities: typing.Sequence[typing.SupportsInt] | spec.Series,
+    quantities: typing.Sequence[typing.SupportsInt],
+    token: spec.ERC20Address | None = None,
+    *,
+    context: spec.Context = None,
+    decimals: typing.Optional[typing.SupportsInt] = None,
+    block: typing.Optional[spec.BlockNumberReference] = None,
+) -> typing.Sequence[float]:
+    ...
+
+
+@typing.overload
+async def async_normalize_erc20_quantities(
+    quantities: typing.Sequence[typing.SupportsInt | None] | spec.Series,
     token: spec.ERC20Address | None = None,
     *,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     decimals: typing.Optional[typing.SupportsInt] = None,
     block: typing.Optional[spec.BlockNumberReference] = None,
-) -> list[float]:
+) -> typing.Sequence[float | None]:
+    ...
+
+
+async def async_normalize_erc20_quantities(
+    quantities: typing.Sequence[typing.SupportsInt | None] | spec.Series,
+    token: spec.ERC20Address | None = None,
+    *,
+    context: spec.Context = None,
+    decimals: typing.Optional[typing.SupportsInt] = None,
+    block: typing.Optional[spec.BlockNumberReference] = None,
+) -> typing.Sequence[float | None]:
     """normalize ERC20 quantites by adjusting radix by (10 ** decimals)"""
 
     if all(quantity == 0 for quantity in quantities):
         return [float(0) for quantity in quantities]
 
     if decimals is None:
         if token is None:
             raise Exception('must specify token or decimals')
         decimals = await erc20_metadata.async_get_erc20_decimals(
             token=token,
             block=block,
-            provider=provider,
+            context=context,
         )
     else:
         decimals = int(decimals)
 
-    return [quantity / (10 ** decimals) for quantity in quantities]
+    return [
+        quantity / (10**decimals) if quantity is not None else None
+        for quantity in quantities
+    ]
 
 
 async def async_normalize_erc20s_quantities(
     quantities: typing.Sequence[typing.SupportsInt] | spec.Series,
     tokens: typing.Optional[typing.Sequence[spec.ERC20Address]] = None,
     *,
     decimals: typing.Optional[typing.Sequence[typing.SupportsInt]] = None,
     block: typing.Optional[spec.BlockNumberReference] = None,
-    provider: spec.ProviderReference = None,
-) -> list[float]:
+    context: spec.Context = None,
+) -> typing.Sequence[float]:
     """normalize ERC20 quantites by adjusting radix by (10 ** decimals)"""
 
     # take subset of non zero values
     mask = [quantity != 0 for quantity in quantities]
     any_zero = not all(mask)
     if any_zero:
         old_quantities = quantities
@@ -90,15 +117,15 @@
 
     if decimals is None:
         if tokens is None:
             raise Exception('must specify tokens or decimals')
         use_decimals = await erc20_metadata.async_get_erc20s_decimals(
             tokens=tokens,
             block=block,
-            provider=provider,
+            context=context,
         )
     else:
         use_decimals = [int(decimal) for decimal in decimals]
 
     if len(use_decimals) != len(quantities):
         raise Exception('number of quantities must match number of decimals')
 
@@ -111,27 +138,27 @@
             if nonzero:
                 new_use_decimals.append(next(use_decimals_iterator))
             else:
                 new_use_decimals.append(1)
         use_decimals = new_use_decimals
 
     return [
-        quantity / (10 ** decimal)
+        quantity / (10**decimal)
         for quantity, decimal in zip(quantities, use_decimals)
     ]
 
 
 async def async_normalize_erc20_quantities_by_block(
     quantities: typing.Sequence[typing.SupportsInt] | spec.Series,
     blocks: typing.Sequence[spec.BlockNumberReference],
     *,
     token: typing.Optional[spec.ERC20Address] = None,
-    decimals: typing.Optional[list[typing.SupportsInt]] = None,
-    provider: spec.ProviderReference = None,
-) -> list[float]:
+    decimals: typing.Optional[typing.Sequence[typing.SupportsInt]] = None,
+    context: spec.Context = None,
+) -> typing.Sequence[float]:
     """normalize ERC20 quantites by adjusting radix by (10 ** decimals)"""
 
     # take subset of non zero values
     mask = [quantity != 0 for quantity in quantities]
     any_zero = not all(mask)
     if any_zero:
         old_quantities = quantities
@@ -146,15 +173,15 @@
 
     if decimals is None:
         if token is None:
             raise Exception('must specify token or decimals')
         use_decimals = await erc20_metadata.async_get_erc20_decimals_by_block(
             token=token,
             blocks=blocks,
-            provider=provider,
+            context=context,
         )
     else:
         use_decimals = [int(decimal) for decimal in decimals]
 
     if len(use_decimals) != len(quantities):
         raise Exception('number of quantities must match number of decimals')
 
@@ -166,10 +193,11 @@
             if nonzero:
                 new_use_decimals.append(next(use_decimals_iterator))
             else:
                 new_use_decimals.append(1)
         use_decimals = new_use_decimals
 
     return [
-        quantity / (10 ** decimal)
+        quantity / (10**decimal)
         for quantity, decimal in zip(quantities, use_decimals)
     ]
+
```

### Comparing `checkthechain-0.3.0/src/ctc/evm/erc20_utils/erc20_spec.py` & `checkthechain-0.3.4/src/ctc/evm/erc20_utils/erc20_spec.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/evm/erc20_utils/erc20_state.py` & `checkthechain-0.3.4/src/ctc/evm/erc20_utils/erc20_state.py`

 * *Files 26% similar despite different names*

```diff
@@ -16,92 +16,92 @@
 
 
 async def async_get_erc20_total_supply(
     token: spec.ERC20Reference,
     *,
     block: typing.Optional[spec.BlockNumberReference] = None,
     normalize: bool = True,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     **rpc_kwargs: typing.Any,
-) -> typing.Union[int, float]:
+) -> typing.Union[int, float] | None:
     """get total supply of ERC20"""
 
     if block is None:
         block = 'latest'
 
     result = await erc20_generic.async_erc20_eth_call(
         token=token,
         function_name='totalSupply',
         block=block,
-        provider=provider,
+        context=context,
         **rpc_kwargs,
     )
-    if not isinstance(result, int):
-        raise Exception('invalid rpc result')
+    if rpc_kwargs.get('convert_reverts_to_none') and result is None:
+        return result
     total_supply: int | float = result
 
     if normalize:
         total_supply = await erc20_normalize.async_normalize_erc20_quantity(
-            quantity=total_supply, token=token, provider=provider
+            quantity=total_supply, token=token, context=context
         )
 
     return total_supply
 
 
 async def async_get_erc20s_total_supplies(
     tokens: typing.Sequence[spec.ERC20Reference],
     *,
     block: typing.Optional[spec.BlockNumberReference] = None,
     normalize: bool = True,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     **rpc_kwargs: typing.Any,
-) -> typing.Union[list[int], list[float]]:
+) -> typing.Union[typing.Sequence[int], typing.Sequence[float]]:
     """get total supplies of ERC20s"""
 
     if block is None:
         block = 'latest'
 
     total_supplies = await erc20_generic.async_erc20s_eth_calls(
-        tokens=tokens, function_name='totalSupply', block=block, **rpc_kwargs
+        tokens=tokens, function_name='totalSupply', block=block, context=context, **rpc_kwargs
     )
 
     if normalize:
         total_supplies = (
             await erc20_normalize.async_normalize_erc20s_quantities(
-                tokens=tokens, quantities=total_supplies, provider=provider
+                tokens=tokens, quantities=total_supplies, context=context
             )
         )
 
     return total_supplies
 
 
 async def async_get_erc20_total_supply_by_block(
     token: spec.ERC20Reference,
     blocks: typing.Sequence[spec.BlockNumberReference],
     *,
     normalize: bool = True,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     **rpc_kwargs: typing.Any,
-) -> typing.Union[list[int], list[float]]:
+) -> typing.Union[typing.Sequence[int], typing.Sequence[float]]:
     """get historical total supply of ERC20 across multiple blocks"""
 
     total_supplies = await erc20_generic.async_erc20_eth_call_by_block(
         token=token,
         function_name='totalSupply',
         blocks=blocks,
-        provider=provider,
+        context=context,
         **rpc_kwargs,
     )
 
     if normalize:
         total_supplies = (
             await erc20_normalize.async_normalize_erc20_quantities_by_block(
                 token=token,
                 quantities=total_supplies,
-                provider=provider,
+                context=context,
                 blocks=blocks,
             )
         )
 
     return total_supplies
 
 
@@ -112,313 +112,366 @@
 
 async def async_get_erc20_balance(
     wallet: spec.Address,
     token: spec.ERC20Address,
     *,
     block: typing.Optional[spec.BlockNumberReference] = None,
     normalize: bool = True,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     **rpc_kwargs: typing.Any,
-) -> typing.Union[int, float]:
+) -> typing.Union[int, float] | None:
     """get ERC20 balance"""
 
     if block is None:
         block = 'latest'
 
     wallet = await address_utils.async_resolve_address(
         wallet,
         block=block,
-        provider=provider,
+        context=context,
     )
 
     result = await erc20_generic.async_erc20_eth_call(
         token=token,
         function_name='balanceOf',
         block=block,
         function_parameters=[wallet],
-        provider=provider,
+        context=context,
         **rpc_kwargs,
     )
-    if not isinstance(result, int):
-        raise Exception('invalid rpc result')
+    if result is None:
+        if not rpc_kwargs.get('convert_reverts_to_none'):
+            raise Exception('invalid result')
+        return result
     balance: int | float = result
 
     if normalize:
         balance = await erc20_normalize.async_normalize_erc20_quantity(
-            quantity=balance, token=token, provider=provider, block=block
+            quantity=balance, token=token, context=context, block=block
         )
 
     return balance
 
 
 async def async_get_erc20_balances_of_addresses(
     wallets: typing.Sequence[spec.Address],
     token: spec.ERC20Address,
     *,
     block: typing.Optional[spec.BlockNumberReference] = None,
     normalize: bool = True,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     **rpc_kwargs: typing.Any,
-) -> typing.Union[list[int], list[float]]:
+) -> typing.Union[typing.Sequence[int], typing.Sequence[float]]:
     """get ERC20 balance of multiple addresses"""
 
     from ctc import rpc
 
     if block is None:
         block = 'latest'
 
     wallets = await address_utils.async_resolve_addresses(
         wallets,
         block=block,
-        provider=provider,
+        context=context,
     )
 
     balances = await rpc.async_batch_eth_call(
         to_address=token,
         block_number=block,
         function_abi=erc20_spec.erc20_function_abis['balanceOf'],
         function_parameter_list=[[wallet] for wallet in wallets],
-        provider=provider,
+        context=context,
         **rpc_kwargs,
     )
 
     if normalize:
-        balances = await erc20_normalize.async_normalize_erc20_quantities(
-            quantities=balances, token=token, provider=provider, block=block
+        return await erc20_normalize.async_normalize_erc20_quantities(
+            quantities=balances, token=token, context=context, block=block
         )
-
-    return balances
+    else:
+        return balances
 
 
 async def async_get_erc20s_balances(
     wallet: spec.Address,
     tokens: typing.Sequence[spec.ERC20Address],
     *,
     block: typing.Optional[spec.BlockNumberReference] = None,
     normalize: bool = True,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     **rpc_kwargs: typing.Any,
-) -> typing.Union[list[int], list[float]]:
+) -> typing.Union[typing.Sequence[int], typing.Sequence[float]]:
     """get ERC20 balance of wallet for multiple tokens"""
 
-    from ctc import rpc
+    from ctc import config
 
     if block is None:
         block = 'latest'
 
     wallet = await address_utils.async_resolve_address(
         wallet,
         block=block,
-        provider=provider,
+        context=context,
     )
 
-    provider = rpc.get_provider(provider)
-
-    if typing.TYPE_CHECKING:
-        provider = typing.cast(spec.Provider, dict(provider))
-
-    provider['chunk_size'] = 100
+    context = config.update_context(
+        context=context,
+        merge_provider={'chunk_size': 100},
+    )
     balances = await erc20_generic.async_erc20s_eth_calls(
         tokens=tokens,
         function_name='balanceOf',
         block=block,
         function_parameters=[wallet],
-        provider=provider,
+        context=context,
         **rpc_kwargs,
     )
 
     if normalize:
         balances = await erc20_normalize.async_normalize_erc20s_quantities(
             quantities=balances,
             tokens=tokens,
-            provider=provider,
+            context=context,
             block=block,
         )
 
     return balances
 
 
 async def async_get_erc20_balance_by_block(
     wallet: spec.Address,
     token: spec.ERC20Reference,
     *,
     blocks: typing.Sequence[spec.BlockNumberReference],
     normalize: bool = True,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     empty_token: typing.Any = 0,
     **rpc_kwargs: typing.Any,
-) -> typing.Union[list[int], list[float]]:
+) -> typing.Union[typing.Sequence[int], typing.Sequence[float]]:
     """get historical ERC20 balance over multiple blocks"""
 
     wallet = await address_utils.async_resolve_address(
         wallet,
         block=blocks[-1],
-        provider=provider,
+        context=context,
     )
 
     balances = await erc20_generic.async_erc20_eth_call_by_block(
         token=token,
         function_name='balanceOf',
         blocks=blocks,
         function_parameters=[wallet],
-        provider=provider,
+        context=context,
         empty_token=empty_token,
         **rpc_kwargs,
     )
 
     if normalize:
         balances = (
             await erc20_normalize.async_normalize_erc20_quantities_by_block(
                 quantities=balances,
                 token=token,
-                provider=provider,
+                context=context,
                 blocks=blocks,
             )
         )
 
     return balances
 
 
 #
 # # allowance
 #
 
 
 async def async_get_erc20_allowance(
     token: spec.ERC20Reference,
-    wallet: spec.Address,
+    owner: spec.Address,
     *,
+    spender: spec.Address,
     block: spec.BlockNumberReference | None = None,
     normalize: bool = True,
-    provider: spec.ProviderReference = None,
-) -> typing.Union[int, float]:
+    context: spec.Context = None,
+    **rpc_kwargs: typing.Any,
+) -> typing.Union[int, float] | None:
     """get ERC20 allowance"""
 
     if block is None:
         block = 'latest'
 
-    wallet = await address_utils.async_resolve_address(
-        wallet,
+    owner = await address_utils.async_resolve_address(
+        owner,
         block=block,
-        provider=provider,
+        context=context,
     )
 
     result = await erc20_generic.async_erc20_eth_call(
         token=token,
         function_name='allowance',
         block=block,
-        function_parameters=[wallet],
-        provider=provider,
+        function_parameters=[owner, spender],
+        context=context,
+        **rpc_kwargs,
     )
-    if not isinstance(result, int):
-        raise Exception('invalid rpc result')
+    if result is None:
+        if not rpc_kwargs.get('convert_reverts_to_none'):
+            raise Exception('invalid result')
+        return result
+
     allowance: int | float = result
 
     if normalize:
         allowance = await erc20_normalize.async_normalize_erc20_quantity(
-            quantity=allowance, token=token, provider=provider, block=block
+            quantity=allowance, token=token, context=context, block=block
         )
 
     return allowance
 
 
 async def async_get_erc20_allowance_by_block(
     token: spec.ERC20Reference,
-    wallet: spec.Address,
+    owner: spec.Address,
     *,
+    spender: spec.Address,
     blocks: typing.Sequence[spec.BlockNumberReference],
     normalize: bool = True,
-    provider: spec.ProviderReference = None,
-) -> typing.Union[list[int], list[float]]:
+    context: spec.Context = None,
+    **rpc_kwargs: typing.Any,
+) -> typing.Union[typing.Sequence[int], typing.Sequence[float]]:
     """get historical ERC20 allowance over range of blocks"""
 
-    wallet = await address_utils.async_resolve_address(
-        wallet,
+    owner = await address_utils.async_resolve_address(
+        owner,
         block=blocks[-1],
-        provider=provider,
+        context=context,
     )
 
     allowances = await erc20_generic.async_erc20_eth_call_by_block(
         token=token,
         function_name='allowance',
         blocks=blocks,
-        function_parameters=[wallet],
-        provider=provider,
+        function_parameters=[owner, spender],
+        context=context,
+        **rpc_kwargs,
     )
 
     if normalize:
         allowances = (
             await erc20_normalize.async_normalize_erc20_quantities_by_block(
                 quantities=allowances,
                 token=token,
-                provider=provider,
+                context=context,
                 blocks=blocks,
             )
         )
 
     return allowances
 
 
 async def async_get_erc20s_allowances(
     tokens: typing.Sequence[spec.ERC20Reference],
-    wallet: spec.Address,
+    owner: spec.Address,
     *,
+    spender: spec.Address,
     block: spec.BlockNumberReference | None = None,
     normalize: bool = True,
-    provider: spec.ProviderReference = None,
-) -> typing.Union[list[int], list[float]]:
+    context: spec.Context = None,
+    **rpc_kwargs: typing.Any,
+) -> typing.Union[typing.Sequence[int], typing.Sequence[float]]:
     """get ERC20 allowance of wallet for multiple tokens"""
 
-    wallet = await address_utils.async_resolve_address(
-        wallet,
+    owner = await address_utils.async_resolve_address(
+        owner,
         block=block,
-        provider=provider,
+        context=context,
     )
 
     allowances = await erc20_generic.async_erc20s_eth_calls(
         tokens=tokens,
         function_name='allowance',
         block=block,
-        function_parameters=[wallet],
-        provider=provider,
+        function_parameters=[owner, spender],
+        context=context,
+        **rpc_kwargs,
     )
 
     if normalize:
         allowances = await erc20_normalize.async_normalize_erc20s_quantities(
-            quantities=allowances, tokens=tokens, provider=provider, block=block
+            quantities=allowances, tokens=tokens, context=context, block=block
         )
 
     return allowances
 
 
-async def async_get_erc20s_allowances_of_addresses(
+async def async_get_erc20_allowances_of_owners(
     token: spec.ERC20Reference,
-    wallets: typing.Sequence[spec.Address],
+    owners: typing.Sequence[spec.Address],
     *,
+    spender: spec.Address,
     block: spec.BlockNumberReference | None = None,
     normalize: bool = True,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
+    **rpc_kwargs: typing.Any,
 ) -> typing.Sequence[int | float]:
-    """get ERC20 allowance of multiple addresses"""
+    """get ERC20 allowance of multiple owners"""
 
     from ctc import rpc
 
-    wallets = await address_utils.async_resolve_addresses(
-        wallets,
+    owners = await address_utils.async_resolve_addresses(
+        owners,
         block=block,
-        provider=provider,
+        context=context,
     )
 
     allowances = await rpc.async_batch_eth_call(
         to_address=token,
         block_number=block,
         function_abi=erc20_spec.erc20_function_abis['allowance'],
-        function_parameter_list=[[wallet] for wallet in wallets],
-        provider=provider,
+        function_parameter_list=[[owner, spender] for owner in owners],
+        context=context,
+        **rpc_kwargs,
     )
 
     if normalize:
-        allowances = await erc20_normalize.async_normalize_erc20_quantities(
-            quantities=allowances, token=token, provider=provider, block=block
+        return await erc20_normalize.async_normalize_erc20_quantities(
+            quantities=allowances, token=token, context=context, block=block
         )
+    else:
+        return allowances
+
+
+async def async_get_erc20_allowances_of_spenders(
+    token: spec.ERC20Reference,
+    owner: spec.Address,
+    *,
+    spenders: typing.Sequence[spec.Address],
+    block: spec.BlockNumberReference | None = None,
+    normalize: bool = True,
+    context: spec.Context = None,
+    **rpc_kwargs: typing.Any,
+) -> typing.Sequence[int | float]:
+    """get ERC20 allowance of multiple spenders"""
+
+    from ctc import rpc
+
+    owner = await address_utils.async_resolve_address(
+        owner,
+        block=block,
+        context=context,
+    )
+
+    allowances = await rpc.async_batch_eth_call(
+        to_address=token,
+        block_number=block,
+        function_abi=erc20_spec.erc20_function_abis['allowance'],
+        function_parameter_list=[[owner, spender] for spender in spenders],
+        context=context,
+        **rpc_kwargs,
+    )
+
+    if normalize:
+        return await erc20_normalize.async_normalize_erc20_quantities(
+            quantities=allowances, token=token, context=context, block=block
+        )
+    else:
+        return allowances
 
-    return allowances
```

### Comparing `checkthechain-0.3.0/src/ctc/evm/erc20_utils/erc20_summary.py` & `checkthechain-0.3.4/src/ctc/evm/erc20_utils/erc20_summary.py`

 * *Files 21% similar despite different names*

```diff
@@ -5,31 +5,41 @@
 from ctc import spec
 from . import erc20_metadata
 from . import erc20_state
 
 
 async def async_print_erc20_summary(
     erc20: spec.Address,
+    *,
     include_address: bool = True,
+    context: spec.Context = None,
 ) -> None:
     """print ERC20 summary"""
 
     import asyncio
     import toolstr
     from ctc import cli
 
     name_coroutine = erc20_metadata.async_get_erc20_name(
         erc20,
+        context=context,
     )
     address_coroutine = erc20_metadata.async_get_erc20_address(
         erc20,
+        context=context,
+    )
+    decimals_coroutine = erc20_metadata.async_get_erc20_decimals(
+        erc20, context=context
+    )
+    symbol_coroutine = erc20_metadata.async_get_erc20_symbol(
+        erc20, context=context
+    )
+    total_supply_coroutine = erc20_state.async_get_erc20_total_supply(
+        erc20, context=context
     )
-    decimals_coroutine = erc20_metadata.async_get_erc20_decimals(erc20)
-    symbol_coroutine = erc20_metadata.async_get_erc20_symbol(erc20)
-    total_supply_coroutine = erc20_state.async_get_erc20_total_supply(erc20)
 
     name, address, decimals, symbol, total_supply = await asyncio.gather(
         name_coroutine,
         address_coroutine,
         decimals_coroutine,
         symbol_coroutine,
         total_supply_coroutine,
@@ -58,7 +68,8 @@
         border=styles['comment'],
         column_styles=[styles['option'], styles['description']],
     )
 
     if include_address:
         print()
         toolstr.print(address, style=styles['metavar'])
+
```

### Comparing `checkthechain-0.3.0/src/ctc/evm/eth_utils/eth_crud.py` & `checkthechain-0.3.4/src/ctc/evm/eth_utils/eth_crud.py`

 * *Files 14% similar despite different names*

```diff
@@ -6,46 +6,57 @@
 
 
 @typing.overload
 async def async_get_eth_balance(
     address: spec.Address,
     *,
     normalize: typing.Literal[False],
-    provider: typing.Optional[spec.ProviderReference] = None,
+    context: spec.Context = None,
     block: typing.Optional[spec.BlockNumberReference] = None,
 ) -> int:
     ...
 
 
 @typing.overload
 async def async_get_eth_balance(
     address: spec.Address,
     *,
-    normalize: bool = True,
-    provider: typing.Optional[spec.ProviderReference] = None,
+    normalize: typing.Literal[True] = True,
+    context: spec.Context = None,
     block: typing.Optional[spec.BlockNumberReference] = None,
 ) -> float:
     ...
 
 
+@typing.overload
+async def async_get_eth_balance(
+    address: spec.Address,
+    *,
+    normalize: bool,
+    context: spec.Context = None,
+    block: typing.Optional[spec.BlockNumberReference] = None,
+) -> int | float:
+    ...
+
+
 async def async_get_eth_balance(
     address: spec.Address,
     *,
     normalize: bool = True,
-    provider: typing.Optional[spec.ProviderReference] = None,
+    context: spec.Context = None,
     block: typing.Optional[spec.BlockNumberReference] = None,
 ) -> typing.Union[int, float]:
     """get ETH balance"""
 
     from ctc import rpc
 
     result = await rpc.async_eth_get_balance(
         address=address,
-        provider=provider,
         block_number=block,
+        context=context,
     )
     if not isinstance(result, int):
         raise Exception('invalid rpc result')
     balance: int | float = result
 
     if normalize:
         balance /= 1e18
@@ -55,109 +66,109 @@
 
 @typing.overload
 async def async_get_eth_balance_by_block(
     address: spec.Address,
     *,
     blocks: typing.Sequence[spec.BlockNumberReference],
     normalize: typing.Literal[False],
-    provider: typing.Optional[spec.ProviderReference] = None,
+    context: spec.Context = None,
 ) -> list[int]:
     ...
 
 
 @typing.overload
 async def async_get_eth_balance_by_block(
     address: spec.Address,
     *,
     blocks: typing.Sequence[spec.BlockNumberReference],
     normalize: typing.Literal[True] = True,
-    provider: typing.Optional[spec.ProviderReference] = None,
+    context: spec.Context = None,
 ) -> list[float]:
     ...
 
 
 @typing.overload
 async def async_get_eth_balance_by_block(
     address: spec.Address,
     *,
     normalize: bool = True,
     blocks: typing.Sequence[spec.BlockNumberReference],
-    provider: typing.Optional[spec.ProviderReference] = None,
+    context: spec.Context = None,
 ) -> typing.Union[list[int], list[float]]:
     ...
 
 
 async def async_get_eth_balance_by_block(
     address: spec.Address,
     *,
     blocks: typing.Sequence[spec.BlockNumberReference],
     normalize: bool = True,
-    provider: typing.Optional[spec.ProviderReference] = None,
+    context: spec.Context = None,
 ) -> typing.Union[list[int], list[float]]:
     """get historical ETH balance over multiple blocks"""
 
     coroutines = []
     for block in blocks:
         coroutine = async_get_eth_balance(
-            address=address, provider=provider, block=block, normalize=normalize
+            address=address, context=context, block=block, normalize=normalize
         )
         coroutines.append(coroutine)
 
     import asyncio
 
     return await asyncio.gather(*coroutines)
 
 
 @typing.overload
 async def async_get_eth_balance_of_addresses(
     addresses: typing.Sequence[spec.Address],
     *,
     normalize: typing.Literal[False],
     block: typing.Optional[spec.BlockNumberReference] = None,
-    provider: typing.Optional[spec.ProviderReference] = None,
+    context: spec.Context = None,
 ) -> list[int]:
     ...
 
 
 @typing.overload
 async def async_get_eth_balance_of_addresses(
     addresses: typing.Sequence[spec.Address],
     *,
     block: typing.Optional[spec.BlockNumberReference] = None,
     normalize: typing.Literal[True] = True,
-    provider: typing.Optional[spec.ProviderReference] = None,
+    context: spec.Context = None,
 ) -> list[float]:
     ...
 
 
 @typing.overload
 async def async_get_eth_balance_of_addresses(
     addresses: typing.Sequence[spec.Address],
     *,
     normalize: bool = True,
     block: typing.Optional[spec.BlockNumberReference] = None,
-    provider: typing.Optional[spec.ProviderReference] = None,
+    context: spec.Context = None,
 ) -> typing.Union[list[int], list[float]]:
     ...
 
 
 async def async_get_eth_balance_of_addresses(
     addresses: typing.Sequence[spec.Address],
     *,
     normalize: bool = True,
-    provider: typing.Optional[spec.ProviderReference] = None,
     block: typing.Optional[spec.BlockNumberReference] = None,
+    context: spec.Context = None,
 ) -> typing.Union[list[int], list[float]]:
     """get ETH balance of multiple addresses"""
 
     from ctc import rpc
 
     balances = await rpc.async_batch_eth_get_balance(
         addresses=addresses,
-        provider=provider,
+        context=context,
         block_number=block,
     )
 
     if normalize:
         balances = [balance / 1e18 for balance in balances]
 
     return balances
```

### Comparing `checkthechain-0.3.0/src/ctc/evm/event_utils/event_backends/filesystem_events.py` & `checkthechain-0.3.4/src/ctc/evm/abi_utils/event_abi_utils/event_abi_coding_polars.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,477 +1,439 @@
-"""need to refactor with common backend interface"""
-
 from __future__ import annotations
 
-import ast
-import functools
-import os
 import typing
 
-import ctc.config
-from ctc import config
 from ctc import spec
-from ctc.toolbox import backend_utils
-from ctc.toolbox import filesystem_utils
-from ... import abi_utils
-from ... import binary_utils
-from ... import block_utils
-from ... import network_utils
+from .. import abi_coding_utils
+from . import event_abi_parsing
+from . import event_abi_queries
 
 if typing.TYPE_CHECKING:
-    from typing_extensions import TypedDict
-
-    _PathEventsResult = typing.Dict[str, typing.Tuple[int, int]]
-
-    class _ListEventsResult(TypedDict):
-        paths: _PathEventsResult
-        block_range: spec.NumpyArray
-        block_mask: spec.NumpyArray
-        missing_blocks: spec.NumpyArray
-
-
-filesystem_layout = {
-    'evm_events_path': 'events/contract__{contract_address}/event__{event_hash}/{start_block}__to__{end_block}.csv',
-    'evm_contract_abis_path': 'contract_abis/contract__{contract_address}/{name}.json',
-    'evm_named_contract_abis_path': '{data_root}/{network}/evm/named_contract_abis',
-}
-
-
-#
-# # paths
-#
-
-
-def get_events_root(
-    network: typing.Optional[spec.NetworkReference] = None,
-) -> str:
-    if network is None:
-        network = config.get_default_network()
-        if network is None:
-            raise Exception('must specify network or configure default network')
-    network_name = network_utils.get_network_name(network, require=True)
-    return os.path.join(
-        ctc.config.get_data_dir(), 'evm/networks', network_name, 'events'
-    )
+    from typing_extensions import Literal
 
-
-def get_events_contract_dir(
-    contract_address: spec.Address,
-    network: typing.Optional[spec.NetworkReference] = None,
-) -> str:
-    contract_address = contract_address.lower()
-    return os.path.join(
-        get_events_root(network=network), 'contract__' + contract_address
-    )
+    EventABIList = typing.Sequence[spec.EventABI]
+    EventABIMap = typing.Mapping[str, spec.EventABI]
+    ColumnPrefixType = Literal['arg', 'event_name', 'event_hash']
 
 
-def get_events_event_dir(
-    contract_address: spec.Address,
+async def async_decode_events_dataframe(
+    events: spec.DataFrame,
+    event_abis: EventABIList | EventABIMap | None = None,
     *,
-    event_hash: typing.Optional[str] = None,
-    event_abi: typing.Optional[spec.EventABI] = None,
-    network: typing.Optional[spec.NetworkReference] = None,
-) -> str:
-    contract_address = contract_address.lower()
-    if event_hash is None:
-        if event_abi is None:
-            raise Exception('must specify more event data')
-        event_hash = abi_utils.get_event_hash(event_abi)
-    contract_dir = get_events_contract_dir(contract_address, network=network)
-    return os.path.join(contract_dir, 'event__' + event_hash)
+    context: spec.Context,
+    column_prefix_type: ColumnPrefixType | None = None,
+    column_prefix: str | None = None,
+    binary_output_format: Literal['binary', 'prefix_hex'] = 'prefix_hex',
+    integer_output_format: spec.IntegerOutputFormat | None = None,
+    convert_invalid_str_to_none: bool = False,
+    convert_invalid_str_to: None | str = None,
+) -> spec.DataFrame:
+    """decode a dataframe that contains raw logs
 
+    TODO: specifically handle logs that do not provide event topics
 
-def get_events_filepath(
-    contract_address: spec.Address,
-    *,
-    start_block: int,
-    end_block: int,
-    event_hash: typing.Optional[str] = None,
-    event_abi: typing.Optional[spec.EventABI] = None,
-    network: typing.Optional[spec.NetworkReference] = None,
-) -> str:
-
-    # create lowercase versions of contract_address and event_hash
-    contract_address = contract_address.lower()
-    if event_hash is None:
-        if event_abi is None:
-            raise Exception('must specify more event data')
-        event_hash = abi_utils.get_event_hash(event_abi)
-    event_hash = event_hash.lower()
-
-    # assemble items into subpath
-    subpath = filesystem_layout['evm_events_path'].format(
-        contract_address=contract_address,
-        event_hash=event_hash,
-        start_block=start_block,
-        end_block=end_block,
-    )
+    columns are prefixed according to input settings
+    - column_prefix_type == 'arg' --> use 'arg__' as prefix
+    - column_prefix_type == 'event_name' --> use '{event_name}__' as prefix
+    - column_prefix_type == 'event_hash' --> use '{event_hash}__' as prefix
+    - column_prefix_type == None --> use column_prefix if not None, otherwise ''
+    """
+
+    import polars as pl
+    from ctc.toolbox import pl_utils
+
+    # handle case of no events
+    if len(events) == 0:
+        _, df_schema, _ = _create_event_arg_schema(
+            event_abis=event_abis,
+            column_prefix_type=column_prefix_type,
+            column_prefix=column_prefix,
+            integer_output_format=integer_output_format,
+        )
+        arg_df = pl.DataFrame(schema=df_schema)  # type: ignore
+        return pl.concat([events, arg_df], how='horizontal')
 
-    # add parent directory
-    if network is None:
-        network = config.get_default_network()
-        if network is None:
-            raise Exception('must specify network or configure default network')
-    network_name = network_utils.get_network_name(network, require=True)
-    return os.path.join(
-        ctc.config.get_data_dir(), 'evm/networks', network_name, subpath
+    # get event abis
+    event_abis = await _async_get_events_abis(
+        events=events, event_abis=event_abis, context=context
     )
 
-
-#
-# # list saved data
-#
-
-
-def list_events_contracts(
-    network: typing.Optional[spec.NetworkReference] = None,
-) -> list[str]:
-    contracts = []
-    events_root = get_events_root(network=network)
-    if not os.path.isdir(events_root):
-        return []
-    for contract_dir in os.listdir(events_root):
-        contract_address = contract_dir.split('__')[-1]
-        contracts.append(contract_address)
-    return contracts
-
-
-def list_contract_events(
-    contract_address: spec.Address,
-    *,
-    event_hash: typing.Optional[str] = None,
-    event_abi: typing.Optional[spec.EventABI] = None,
-    allow_missing_blocks: bool = False,
-    network: typing.Optional[spec.NetworkReference] = None,
-) -> dict[str, _ListEventsResult]:
-
-    if event_hash is not None:
-        query_event_hash = event_hash
-    elif event_abi is not None:
-        query_event_hash = abi_utils.get_event_hash(event_abi)
-    else:
-        query_event_hash = None
-
-    # compile path data
-    contract_address = contract_address.lower()
-    contract_dir = get_events_contract_dir(contract_address, network=network)
-    paths: dict[str, _PathEventsResult] = {}
-    if not os.path.isdir(contract_dir):
-        return {}
-    for event_dirname in os.listdir(contract_dir):
-        event_dir = os.path.join(contract_dir, event_dirname)
-        _, event_hash = event_dirname.split('__')
-        if query_event_hash is not None and event_hash != query_event_hash:
-            continue
-        for filename in os.listdir(event_dir):
-            path = os.path.join(event_dir, filename)
-            start_block_str, _, end_block_str = os.path.splitext(filename)[
-                0
-            ].split('__')
-            paths.setdefault(event_hash, {})
-            paths[event_hash][path] = (int(start_block_str), int(end_block_str))
-
-    import numpy as np
-
-    # create block_range and block_mask
-    events: dict[str, _ListEventsResult] = {}
-    for event_hash in paths.keys():
-
-        # gather start and end blocks
-        start_blocks = []
-        end_blocks = []
-        for path, (start_block, end_block) in paths[event_hash].items():
-            start_blocks.append(start_block)
-            end_blocks.append(end_block)
-
-        # create block_range
-        min_block = min(start_blocks)
-        max_block = max(end_blocks) + 1
-        block_range = np.arange(min_block, max_block)
-
-        # create block_mask
-        n_blocks = block_range.size
-        block_mask = np.zeros(n_blocks)
-        for path, (start_block, end_block) in paths[event_hash].items():
-            start_index = start_block - min_block
-            end_index = n_blocks - (max_block - end_block) + 1
-            block_mask[start_index:end_index] += 1
-        if (block_mask > 1).sum() > 0:
-            raise Exception('overlapping chunks')
-        block_mask = block_mask.astype(bool)
-
-        # check if blocks missing
-        missing_blocks = block_mask.sum() != n_blocks
-        if missing_blocks and not allow_missing_blocks:
-            raise Exception('missing blocks')
-
-        events[event_hash] = {
-            'paths': paths[event_hash],
-            'block_range': block_range,
-            'block_mask': block_mask,
-            'missing_blocks': missing_blocks,
-        }
-
-    return events
-
-
-def list_events(
-    contract_address: str,
-    *,
-    event_hash: typing.Optional[str] = None,
-    event_abi: typing.Optional[spec.EventABI] = None,
-    allow_missing_blocks: bool = False,
-    network: typing.Optional[spec.NetworkReference] = None,
-) -> typing.Optional[_ListEventsResult]:
-
-    contract_events = list_contract_events(
-        contract_address=contract_address,
-        event_hash=event_hash,
-        event_abi=event_abi,
-        allow_missing_blocks=allow_missing_blocks,
-        network=network,
+    # create dataframe schema
+    event_schemas, df_schema, event_hash_offsets = _create_event_arg_schema(
+        event_abis=event_abis,
+        column_prefix_type=column_prefix_type,
+        column_prefix=column_prefix,
+        integer_output_format=integer_output_format,
     )
 
-    if len(contract_events) == 1:
-        event_hash = list(contract_events.keys())[0]
-        return contract_events[event_hash]
+    # create iterators for relevant columns
+    n_decode_topics = max(
+        len(event_schema['indexed_types'])
+        for event_schema in event_schemas.values()
+    )
+    if n_decode_topics >= 1:
+        topic1 = events['topic1'].to_list()
+    else:
+        topic1 = None
+    if n_decode_topics >= 2:
+        topic2 = events['topic2'].to_list()
     else:
-        return None
+        topic2 = None
+    if n_decode_topics >= 3:
+        topic3 = events['topic3'].to_list()
+    else:
+        topic3 = None
+    decode_unindexed = any(
+        len(event_schema['unindexed_types']) > 0
+        for event_schema in event_schemas.values()
+    )
+    if decode_unindexed:
+        unindexed = events['unindexed'].to_list()
+    topic_iterators = [topic1, topic2, topic3]
+
+    # decode
+    decoded_events: typing.Sequence[typing.MutableSequence[typing.Any]]
+    decoded_events = [[] for i in range(len(df_schema))]
+    for e, event_hash in enumerate(events['event_hash'].to_list()):
+        i = event_hash_offsets[event_hash]
+        event_schema = event_schemas[event_hash]
+
+        for c in range(i):
+            decoded_events[c].append(None)
+
+        # decode indexed data
+        for indexed_type, indexed_name, topic_iterator in zip(
+            event_schema['indexed_types'],
+            event_schema['indexed_names'],
+            topic_iterators,
+        ):
+            if topic_iterator is None:
+                raise Exception('topic_iterator not set')
+            if (
+                indexed_type in ['bytes', 'string']
+                or indexed_type.endswith(']')
+                or indexed_type.endswith(')')
+            ):
+                value = topic_iterator[e]
+            else:
+                raw_value = topic_iterator[e]
+                if raw_value is not None:
+                    value = abi_coding_utils.abi_decode(
+                        topic_iterator[e],
+                        indexed_type,
+                        convert_invalid_str_to=convert_invalid_str_to,
+                        convert_invalid_str_to_none=convert_invalid_str_to_none,
+                    )
+                else:
+                    value = raw_value
+            decoded_events[i].append(value)
+            i = i + 1
+
+        # decode unindexed data
+        if len(event_schema['unindexed_types']) > 0:
+            # unindexed_decoded = abi_coding_utils.abi_decode(
+            #     unindexed[e],
+            #     event_schema['unindexed_types'],
+            #     convert_invalid_str_to=convert_invalid_str_to,
+            #     convert_invalid_str_to_none=convert_invalid_str_to_none,
+            # )
+            if len(event_schema['unindexed_types']) == 1:
+                result = abi_coding_utils.abi_decode(
+                    unindexed[e],
+                    event_schema['unindexed_types'][0],
+                    convert_invalid_str_to=convert_invalid_str_to,
+                    convert_invalid_str_to_none=convert_invalid_str_to_none,
+                )
+                unindexed_decoded = [result]
+            else:
+                unindexed_decoded = abi_coding_utils.abi_decode(
+                    unindexed[e],
+                    event_schema['unindexed_types'],
+                    convert_invalid_str_to=convert_invalid_str_to,
+                    convert_invalid_str_to_none=convert_invalid_str_to_none,
+                )
+            for value in unindexed_decoded:
+                decoded_events[i].append(value)
+                i = i + 1
+
+        for c in range(i, len(df_schema)):
+            decoded_events[c].append(None)
+
+    # convert decimals (can remove if polars allows direct creation in future)
+    new_columns = []
+    for column, (column_name, dtype) in zip(decoded_events, df_schema):
+        if dtype == pl.Decimal:
+            import decimal
 
+            new_columns.append([decimal.Decimal(value) for value in column])
+        else:
+            new_columns.append(column)
+    decoded_events = new_columns
 
-def list_contracts_events(
-    network: typing.Optional[spec.NetworkReference] = None,
-    **kwargs: typing.Any,
-) -> dict[str, dict[str, _ListEventsResult]]:
-    contracts_events = {}
-    for contract_address in list_events_contracts(network=network):
-        contracts_events[contract_address] = list_contract_events(
-            contract_address=contract_address, network=network, **kwargs
-        )
-    return contracts_events
+    # convert to dataframe
+    decoded = pl.DataFrame(decoded_events, schema=df_schema, orient='col')  # type: ignore
 
+    # convert binary columns to hex
+    if binary_output_format == 'prefix_hex':
+        decoded = pl_utils.binary_columns_to_prefix_hex(decoded)
 
-#
-# # disk
-#
-
-
-def print_events_summary() -> None:
-    print_events_summary_filesystem()
-
-
-def print_events_summary_filesystem() -> None:
-    contracts_events = list_contracts_events()
-    print('## Contracts (' + str(len(contracts_events)) + ')')
-    for contract_address in sorted(contracts_events.keys()):
-        n_events = len(contracts_events[contract_address])
-        print('-', contract_address, '(' + str(n_events) + ' events)')
-        contract_events = contracts_events[contract_address]
-        for event_hash, event_data in contract_events.items():
-            block_range = [
-                event_data['block_range'][0],
-                event_data['block_range'][-1],
-            ]
-            n_files = str(len(event_data['paths']))
-            dirpath = get_events_event_dir(
-                contract_address=contract_address, event_hash=event_hash
-            )
-            n_bytes = filesystem_utils.get_directory_nbytes_human(dirpath)
-            short_hash = event_hash[:6] + '...' + event_hash[-6:]
-            print(
-                '    -',
-                short_hash,
-                block_range,
-                '(' + n_bytes + 'B in ' + n_files + ' files)',
-            )
+    return decoded
 
 
-async def async_save_events_to_filesystem(
-    events: spec.DataFrame,
-    contract_address: spec.Address,
+def _create_event_arg_schema(
     *,
-    start_block: int,
-    end_block: int,
-    event_abi: typing.Optional[spec.EventABI] = None,
-    event_hash: typing.Optional[str] = None,
-    event_name: typing.Optional[str] = None,
-    overwrite: bool = False,
-    verbose: bool = True,
-    provider: spec.ProviderReference = None,
-    network: typing.Optional[spec.NetworkReference] = None,
-) -> spec.DataFrame:
-
-    from ctc import rpc
+    event_abis: EventABIList | EventABIMap | None = None,
+    column_prefix_type: ColumnPrefixType | None = None,
+    column_prefix: str | None = None,
+    integer_output_format: spec.IntegerOutputFormat | None = None,
+) -> tuple[
+    typing.Mapping[str, spec.EventSchema],
+    typing.Sequence[tuple[str, spec.IntegerOutputFormat]],
+    typing.Mapping[str, int],
+]:
+    """does not take binary_output_format into account, that happens later"""
+
+    # format event_abi's as dict
+    if not isinstance(event_abis, dict):
+        if isinstance(event_abis, (list, tuple)):
+            event_abis = {
+                event_abi_parsing.get_event_hash(event_abi): event_abi
+                for event_abi in event_abis
+            }
+        elif event_abis is None:
+            event_abis = {}
+        else:
+            raise Exception('unknown events format')
 
-    if network is None:
-        provider = rpc.get_provider(provider)
-        network = provider['network']
-        if network is None:
-            raise Exception('could not determine network')
+    # get event schemas
+    event_schemas: typing.Mapping[str, spec.EventSchema] = {
+        event_hash: event_abi_parsing.get_event_schema(event_abi)
+        for event_hash, event_abi in event_abis.items()
+    }
+
+    # get column prefix
+    if column_prefix_type is None and column_prefix is None:
+        if len(event_abis) == 1:
+            column_prefix_type = 'arg'
+        else:
+            event_names = {
+                abi.get('name')
+                for abi in event_abis.values()
+                if abi.get('name') is not None
+            }
+            if len(event_names) == len(event_abis):
+                column_prefix_type = 'event_name'
+            else:
+                column_prefix_type = 'event_hash'
+    if column_prefix_type == 'arg':
+        column_prefix = 'arg__'
+    elif column_prefix_type == 'event_name':
+        column_prefix = '{event_name}__'
+    elif column_prefix_type == 'event_hash':
+        column_prefix = '{event_hash}__'
     else:
-        network = network_utils.get_network_name(network)
+        if column_prefix is None:
+            column_prefix = ''
 
-    contract_address = contract_address.lower()
-
-    if event_abi is None:
-        event_abi = await abi_utils.async_get_event_abi(
-            contract_address=contract_address,
-            event_name=event_name,
-            event_hash=event_hash,
-            network=network,
-        )
-
-    # compute path
-    path = get_events_filepath(
-        contract_address=contract_address,
-        event_hash=event_hash,
-        event_abi=event_abi,
-        start_block=start_block,
-        end_block=end_block,
-        network=network,
-    )
-    if os.path.exists(path) and not overwrite:
-        raise Exception('path already exists, use overwrite=True')
-
-    if verbose:
-        print('saving events to file:', path)
+    # create dataframe schema
+    df_schema = []
+    used_names = []
+    offsets = [0]
+    for event_hash in event_schemas.keys():
+        event_schema = event_schemas[event_hash]
+        if '{event_name}' in column_prefix:
+            if 'name' in event_abis[event_hash]:
+                event_name = event_abis[event_hash]['name']
+            else:
+                raise Exception('event name not specified in event abi')
+            used_column_prefix = column_prefix.format(
+                event_hash=event_hash,
+                event_name=event_name,
+            )
+        else:
+            used_column_prefix = column_prefix.format(event_hash=event_hash)
+        for abi_type, name in zip(event_schema['types'], event_schema['names']):
+            pl_type = _abi_type_to_polars_dtype(
+                abi_type=abi_type,
+                name=name,
+                integer_output_format=integer_output_format,
+            )
+            name = used_column_prefix + name
+            if name in used_names:
+                raise Exception('naming conflict ' + str(name))
 
-    # save
-    os.makedirs(os.path.dirname(path), exist_ok=True)
-    events.to_csv(path)
+            df_schema.append((name, pl_type))
+            used_names.append(name)
+        offsets.append(len(df_schema))
+    event_hash_offsets = dict(zip(event_schemas.keys(), offsets))
 
-    return events
+    return event_schemas, df_schema, event_hash_offsets
 
 
-async def async_get_events_from_filesystem(
-    contract_address: spec.ContractAddress,
+async def _async_get_events_abis(
+    events: spec.DataFrame,
+    event_abis: EventABIList | EventABIMap | None = None,
     *,
-    event_hash: typing.Optional[str] = None,
-    event_name: typing.Optional[str] = None,
-    event_abi: typing.Optional[spec.EventABI] = None,
-    verbose: bool = True,
-    start_block: typing.Optional[spec.BlockNumberReference] = None,
-    end_block: typing.Optional[spec.BlockNumberReference] = None,
-    provider: spec.ProviderReference = None,
-    network: spec.NetworkReference | None = None,
-) -> spec.DataFrame:
-
-    from ctc import rpc
-
-    # get network
-    if network is None:
-        provider = rpc.get_provider(provider)
-        network = provider['network']
-        if network is None:
-            raise Exception('could not determine network')
+    context: spec.Context,
+) -> typing.Mapping[str, spec.EventABI]:
+    import polars as pl
+
+    # package input abi's
+    if isinstance(event_abis, dict):
+        abis: typing.MutableMapping[str, spec.EventABI] = event_abis
+    elif event_abis is None:
+        abis = {}
+    elif isinstance(event_abis, list):
+        abis = {}
+        for event_abi in event_abis:
+            event_hash = event_abi_parsing.get_event_hash(event_abi)
+            abis[event_hash] = event_abi
     else:
-        network = network_utils.get_network_name(network)
+        raise Exception()
 
-    # resolve start_block and end_block
-    if start_block is not None:
-        start_block = await block_utils.async_block_number_to_int(
-            start_block,
-            provider=provider,
+    # acquire missing event abi's
+    event_hashes = list(events['event_hash'].unique())
+    missing_event_types = set(event_hashes) - set(abis.keys())
+    if len(missing_event_types) > 0:
+        import asyncio
+
+        event_types = events.groupby('event_hash').agg(
+            pl.col('contract_address').unique()
         )
-    if end_block is not None:
-        end_block = await block_utils.async_block_number_to_int(
-            end_block,
-            provider=provider,
+        coroutines = []
+        for event_hash, contract_addresses in event_types.rows():
+            coroutine = event_abi_queries.async_get_event_abi(
+                event_hash=event_hash,
+                contract_addresses=contract_addresses,
+                context=context,
+            )
+            coroutines.append(coroutine)
+        new_event_abis = await asyncio.gather(*coroutines)
+        abis.update(
+            dict(zip(event_types['event_hash'].to_list(), new_event_abis))
         )
 
-    # get event hash
-    if event_hash is None:
-        if event_abi is None:
-            if event_name is None:
-                raise Exception('must specify more event information')
-            event_abi = await abi_utils.async_get_event_abi(
-                contract_address=contract_address,
-                event_name=event_name,
-                network=network,
-            )
+    # remove unused abi's
+    abis = {k: v for k, v in abis.items() if k in event_hashes}
 
-        event_hash = abi_utils.get_event_hash(event_abi)
+    return abis
 
-    events = list_contract_events(
-        contract_address=contract_address,
-        event_abi=event_abi,
-        event_hash=event_hash,
-        network=network,
-    )
-    if event_hash not in events or len(events[event_hash]['paths']) == 0:
-        raise backend_utils.DataNotFound('no files for event')
 
-    # get paths to load
-    paths_to_load = []
-    for path, (path_start, path_end) in events[event_hash]['paths'].items():
-        if start_block is not None:
-            if path_end < start_block:
-                continue
-        if end_block is not None:
-            if end_block < path_start:
-                continue
-        paths_to_load.append(path)
-    if len(paths_to_load) == 0:
-        raise backend_utils.DataNotFound('no files for event')
-
-    # print summary
-    if verbose:
-        if len(paths_to_load) > 0:
-            import toolstr
-
-            n_files = len(paths_to_load)
-            n_bytes_int = sum(os.path.getsize(path) for path in paths_to_load)
-            n_bytes = toolstr.format(n_bytes_int / 1024 / 1024) + 'M'
+def _abi_type_to_polars_dtype(
+    *,
+    abi_type: str,
+    name: str,
+    integer_output_format: spec.IntegerOutputFormat | None = None,
+) -> type[object]:
+    import polars as pl
+
+    if (
+        abi_type.startswith('int') or abi_type.startswith('uint')
+    ) and integer_output_format is not None:
+        # if a dict, using integer_output_format is optional. otherwise must use
+        if isinstance(integer_output_format, dict):
+            if name in integer_output_format:
+                return integer_output_format[name]  # type: ignore
         else:
-            n_bytes = '0'
-            n_files = 0
-        print('loading events (' + n_bytes + 'B', 'across', n_files, 'files)')
-        if verbose >= 2:
-            for path in paths_to_load:
-                print('-', path)
-
-    import pandas as pd
-
-    # load paths
-    dfs = []
-    for path in paths_to_load:
-        df = pd.read_csv(path, low_memory=False)
-        df = df.set_index(['block_number', 'transaction_index', 'log_index'])
-        dfs.append(df)
-    df = pd.concat(dfs, axis=0)
-    df = df.sort_index()
-
-    # trim unwanted
-    if start_block is not None:
-        if start_block < events[event_hash]['block_range'][0]:
-            raise backend_utils.DataNotFound(
-                'start_block outside of filesystem contents'
-            )
-        mask = df.index.get_level_values(level='block_number') >= start_block
-        df = df[mask]
-    if end_block is not None:
-        if end_block > events[event_hash]['block_range'][-1]:
-            raise backend_utils.DataNotFound(
-                'end_block outside of filesystem contents'
-            )
-        mask = df.index.get_level_values(level='block_number') <= end_block
-        df = df[mask]
-
-    # convert any bytes
-    prefix = 'arg__'
-    if event_abi is None:
-        event_abi = await abi_utils.async_get_event_abi(
-            contract_address=contract_address,
-            event_name=event_name,
-            event_hash=event_hash,
-            network=network,
-        )
-    for arg in event_abi['inputs']:
-        if arg['type'] in ['bytes32']:
-            column = prefix + arg['name']
-            lam = functools.partial(
-                binary_utils.binary_convert,
-                output_format='prefix_hex',
-            )
-            df[column] = df[column].map(ast.literal_eval).map(lam)
+            if integer_output_format in [int, 'integer']:
+                return int
+            elif integer_output_format in [object, 'object']:
+                return pl.Object
+            elif integer_output_format in [float, 'float']:
+                return pl.Float64
+            elif isinstance(integer_output_format, pl.datatypes.DataTypeClass):
+                return integer_output_format
+            elif (
+                integer_output_format == 'decimal'
+                or str(type(integer_output_format)) == "<class 'decimal.Decimal'>"
+            ):
+                return pl.Decimal
+            else:
+                raise Exception(
+                    'invalid integer_output_format: ' + str(integer_output_format)
+                )
+
+    if abi_type == 'bool':
+        return pl.datatypes.Boolean
+    elif abi_type == 'address':
+        return pl.datatypes.Utf8
+    elif abi_type == 'string':
+        return pl.datatypes.Utf8
+    elif abi_type in ['bytes', 'bytes8', 'bytes16', 'bytes24', 'bytes32']:
+        return pl.datatypes.Binary
+    elif abi_type == 'function':
+        return pl.datatypes.Object
+    elif abi_type in [
+        'int8',
+        'int16',
+        'int24',
+        'int32',
+        'int40',
+        'int48',
+        'int56',
+        'int64',
+        'uint8',
+        'uint16',
+        'uint24',
+        'uint32',
+    ]:
+        return pl.datatypes.Int64
+    elif abi_type in [
+        'int72',
+        'int80',
+        'int88',
+        'int96',
+        'int104',
+        'int112',
+        'int120',
+        'int128',
+        'int136',
+        'int144',
+        'int152',
+        'int160',
+        'int168',
+        'int176',
+        'int184',
+        'int192',
+        'int200',
+        'int208',
+        'int216',
+        'int224',
+        'int232',
+        'int240',
+        'int248',
+        'int256',
+        'uint72',
+        'uint80',
+        'uint88',
+        'uint96',
+        'uint104',
+        'uint112',
+        'uint120',
+        'uint128',
+        'uint136',
+        'uint144',
+        'uint152',
+        'uint160',
+        'uint168',
+        'uint176',
+        'uint184',
+        'uint192',
+        'uint200',
+        'uint208',
+        'uint216',
+        'uint224',
+        'uint232',
+        'uint240',
+        'uint248',
+        'uint256',
+    ]:
+        return pl.datatypes.Object
+    elif (
+        abi_type.startswith('fixed') or abi_type.startswith('ufixed')
+    ) and not abi_type.endswith(']'):
+        return pl.datatypes.Decimal
+    elif abi_type.endswith(']') or abi_type.endswith(')'):
+        return pl.datatypes.Object
+    else:
+        raise Exception('unknown abi type')
 
-    return df
```

### Comparing `checkthechain-0.3.0/src/ctc/evm/event_utils/event_crud.py` & `checkthechain-0.3.4/src/ctc/evm/event_utils/event_node_utils.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,275 +1,244 @@
 from __future__ import annotations
 
 import typing
 
-from ctc import evm
-from ctc import spec
+import toolstr
 
+from ctc import spec
 from .. import binary_utils
 from .. import block_utils
-from .. import abi_utils
+from . import event_query_utils
 
 if typing.TYPE_CHECKING:
-    import tooltime
-
+    from typing_extensions import Literal
 
-def is_event_hash(data: spec.BinaryData) -> bool:
-    """return whether input is an event hash"""
 
-    try:
-        as_bytes = binary_utils.binary_convert(data, 'binary')
-        return len(as_bytes) == 32
-    except Exception:
-        return False
-
-
-def get_event_backend_functions() -> dict[
-    str,
-    dict[
-        str,
-        typing.Callable[
-            ..., typing.Coroutine[typing.Any, typing.Any, spec.DataFrame]
-        ],
-    ],
-]:
-    from .event_backends import filesystem_events
-    from .event_backends import node_events
-
-    return {
-        'get': {
-            'filesystem': filesystem_events.async_get_events_from_filesystem,
-            'download': async_download_events,
-            'node': node_events.async_get_events_from_node,
-        },
-        'save': {
-            'filesystem': filesystem_events.async_save_events_to_filesystem,
-        },
-    }
-
-
-async def async_get_events(
-    contract_address: spec.Address,
+async def _async_query_events_from_node(
     *,
-    start_block: spec.BlockNumberReference | None = None,
-    end_block: spec.BlockNumberReference | None = None,
-    start_time: tooltime.Timestamp | None = None,
-    end_time: tooltime.Timestamp | None = None,
-    include_timestamps: bool = False,
-    backend_order: typing.Sequence[str] | None = None,
-    keep_multiindex: bool = True,
-    verbose: bool = True,
-    provider: spec.ProviderReference = None,
-    **query: typing.Any,
+    contract_address: spec.Address | None,
+    event_hash: typing.Any | None,
+    topic1: typing.Any | None,
+    topic2: typing.Any | None,
+    topic3: typing.Any | None,
+    start_block: int,
+    end_block: int,
+    context: spec.Context = None,
+    verbose: bool | int,
+    binary_output_format: Literal['binary', 'prefix_hex'] = 'binary',
+    chunk_size: int = 100000,
+    max_blocks_per_request: int = 2000,
 ) -> spec.DataFrame:
-    """get events matching given inputs"""
+    """query events from node and cache results in db if desired"""
 
-    from ctc.toolbox import backend_utils
+    import asyncio
+    import polars as pl
+    from ctc.toolbox import pl_utils
+    from ctc.toolbox import range_utils
 
-    start_block, end_block = await block_utils.async_resolve_block_range(
-        start_block=start_block,
-        end_block=end_block,
-        start_time=start_time,
-        end_time=end_time,
-        allow_none=True,
-        provider=provider,
-    )
-    if start_block is None:
-        start_block = await block_utils.async_get_contract_creation_block(
-            contract_address,
-            verbose=verbose,
+    # parse query type
+    query_type = event_query_utils._parse_event_query_type(
+        contract_address=contract_address,
+        event_hash=event_hash,
+        topic1=topic1,
+        topic2=topic2,
+        topic3=topic3,
+    )
+    if query_type == 8:
+        raise Exception(
+            'querying only by non-event-type topics is unsupported by some providers'
         )
-    if start_block is not None:
-        start_block = await block_utils.async_block_number_to_int(start_block)
-    if end_block is None:
-        end_block = 'latest'
-    if end_block is not None:
-        end_block = await block_utils.async_block_number_to_int(end_block)
-
-    if backend_order is None:
-        backend_order = ['filesystem', 'download']
 
-    events = await backend_utils.async_run_on_backend(
-        get_event_backend_functions()['get'],
-        contract_address=contract_address,
-        start_block=start_block,
-        end_block=end_block,
-        backend_order=backend_order,
-        verbose=verbose,
-        provider=provider,
-        **query,
+    # break into chunks, each will be independently written to db
+    chunk_ranges = range_utils.range_to_chunks(
+        start=start_block,
+        end=end_block,
+        chunk_size=chunk_size,
     )
 
-    if not keep_multiindex:
-        from ctc.toolbox import pd_utils
+    if verbose >= 1:
+        n_blocks = end_block - start_block + 1
+        print('fetching events from node over', toolstr.format(n_blocks), 'blocks')
+    if verbose >= 2:
+        from ctc import cli
+        from ctc import config
 
-        events.index = pd_utils.keep_level(
-            index=events.index, level='block_number'
+        event_query_utils.print_event_query_summary(
+            contract_address=contract_address,
+            event_hash=event_hash,
+            topic1=topic1,
+            topic2=topic2,
+            topic3=topic3,
+            start_block=start_block,
+            end_block=end_block,
         )
-
-    if include_timestamps:
-        timestamps = await async_get_event_timestamps(events, provider=provider)
-        events.insert(0, 'timestamp', timestamps)  # type: ignore
-
-    return events
-
-
-async def async_save_events(
-    events: spec.DataFrame, **query: typing.Any
-) -> spec.DataFrame:
-
-    from ctc.toolbox import backend_utils
-
-    return await backend_utils.async_run_on_backend(
-        get_event_backend_functions()['save'], events=events, **query
+        network = config.get_context_chain_id(context)
+        cli.print_bullet(key='network', value=network)
+        cli.print_bullet(key='chunk_size', value=chunk_size)
+        cli.print_bullet(key='n_chunks', value=len(chunk_ranges))
+
+    # TODO: make this async, store indirect reference in dict and pass dict
+    latest_block_number = await block_utils.async_get_latest_block_number(
+        context=context
     )
 
+    # process each meta chunk
+    coroutines = []
+    for chunk_start, chunk_end in chunk_ranges:
+        coroutine = _async_query_node_events_chunk(
+            contract_address=contract_address,
+            event_hash=event_hash,
+            topic1=topic1,
+            topic2=topic2,
+            topic3=topic3,
+            chunk_start=chunk_start,
+            chunk_end=chunk_end,
+            context=context,
+            latest_block_number=latest_block_number,
+            max_blocks_per_request=max_blocks_per_request,
+        )
+        coroutines.append(coroutine)
+    chunks = await asyncio.gather(*coroutines)
 
-async def async_transfer_events(
-    *,
-    contract_address: spec.Address,
-    start_block: spec.BlockNumberReference | None = None,
-    end_block: spec.BlockNumberReference | None = None,
-    **query: typing.Any,
-) -> spec.DataFrame:
-
-    from ctc.toolbox import backend_utils
-
-    if start_block is not None and end_block is not None:
-        start_block, end_block = await block_utils.async_block_numbers_to_int(
-            blocks=[start_block, end_block],
+    # package result in dataframe
+    result = [response for chunk in chunks for response in chunk]
+    columns = event_query_utils.get_event_df_columns(binary_format='prefix_hex')
+    df = pl.DataFrame(result, schema=columns)
+
+    # convert binary output columns
+    if binary_output_format == 'prefix_hex':
+        # already in prefix hex
+        pass
+    elif binary_output_format == 'binary':
+        df = pl_utils.prefix_hex_columns_to_binary(
+            df=df,
+            columns=['topic1', 'topic2', 'topic3', 'unindexed'],
         )
-    elif start_block is not None:
-        start_block = await block_utils.async_block_number_to_int(start_block)
-    elif end_block is not None:
-        end_block = await block_utils.async_block_number_to_int(end_block)
-
-    result: spec.DataFrame = await backend_utils.async_transfer_backends(
-        get=async_get_events,
-        save=async_save_events,
-        contract_address=contract_address,
-        start_block=start_block,
-        end_block=end_block,
-        **query,
-    )
+    else:
+        raise Exception('unknown binary_output_format')
 
-    return result
+    return df
 
 
-async def async_download_events(
-    contract_address: spec.Address,
+async def _async_query_node_events_chunk(
     *,
-    event_hash: str | None = None,
-    event_name: str | None = None,
-    event_abi: spec.EventABI | None = None,
-    start_block: spec.BlockNumberReference | None = None,
-    end_block: spec.BlockNumberReference | None = None,
-    provider: spec.ProviderReference = None,
-    verbose: bool = True,
-) -> spec.DataFrame:
+    contract_address: spec.Address | None,
+    event_hash: bytes | str | None,
+    topic1: bytes | str | None,
+    topic2: bytes | str | None,
+    topic3: bytes | str | None,
+    chunk_start: int,
+    chunk_end: int,
+    context: spec.Context,
+    max_blocks_per_request: int = 2000,
+    latest_block_number: int | None = None,
+) -> typing.Sequence[spec.EncodedEvent]:
+    """process a chunk of events from node"""
 
+    import asyncio
+    from ctc import config
     from ctc import rpc
-    from .event_backends import filesystem_events
+    from ctc.toolbox import range_utils
 
-    if event_hash is None and event_name is None and event_abi is None:
-        raise Exception('must specify either event_hash or event_name')
-
-    contract_address = contract_address.lower()
+    # break each meta chunk into requests
+    chunk_requests = range_utils.range_to_chunks(
+        start=chunk_start,
+        end=chunk_end,
+        chunk_size=max_blocks_per_request,
+    )
+
+    # encode topics
+    if event_hash is not None:
+        event_hash = binary_utils.to_hex(event_hash)
+    if topic1 is not None:
+        topic1 = binary_utils.to_hex(topic1)
+    if topic2 is not None:
+        topic2 = binary_utils.to_hex(topic2)
+    if topic3 is not None:
+        topic3 = binary_utils.to_hex(topic3)
+
+    # assemble topics
+    if topic3 is not None:
+        topics = [event_hash, topic1, topic2, topic3]
+    elif topic2 is not None:
+        topics = [event_hash, topic1, topic2]
+    elif topic1 is not None:
+        topics = [event_hash, topic1]
+    else:
+        topics = [event_hash]
 
-    if start_block is not None and end_block is not None:
-        start_block, end_block = await block_utils.async_block_numbers_to_int(
-            blocks=[start_block, end_block],
+    # request from node
+    coroutines = []
+    for request_start, request_end in chunk_requests:
+        coroutine = rpc.async_eth_get_logs(
+            address=contract_address,
+            topics=topics,
+            start_block=request_start,
+            end_block=request_end,
+            context=context,
         )
-    elif start_block is not None:
-        start_block = await block_utils.async_block_number_to_int(start_block)
-    elif end_block is not None:
-        end_block = await block_utils.async_block_number_to_int(end_block)
-
-    provider = rpc.get_provider(provider)
-    network = provider['network']
-    if network is None:
-        raise Exception('could not determine network')
-
-    # get event hash
-    if event_hash is None:
-        if event_abi is None:
-            if event_name is None:
-                raise Exception('must specify more event information')
-            event_abi = await abi_utils.async_get_event_abi(
-                contract_address=contract_address,
-                event_name=event_name,
-                network=network,
-            )
-
-        event_hash = evm.get_event_hash(event_abi)
+        coroutines.append(coroutine)
+    results = await asyncio.gather(*coroutines)
 
-    # determine what needs to be downloaded
-    listed_events = filesystem_events.list_events(
-        contract_address=contract_address,
-        event_hash=event_hash,
+    # process raw events
+    raw_logs = [event for result in results for event in result]
+    encoded_events = [
+        log[:5] + log[5] + ((None,) * (4 - len(log[5]))) + (log[6],)
+        for log in raw_logs
+    ]
+
+    # write encoded events to database
+    read_cache, write_cache = config.get_context_cache_read_write(
+        schema_name='events', context=context
     )
-    downloads: list[typing.Mapping[str, typing.Any]] = []
-    if listed_events is None:
-        download: typing.Mapping[str, typing.Any] = {
-            'start_block': start_block,
-            'end_block': end_block,
-        }
-        downloads.append(download)
-    else:
+    if write_cache:
+        from ctc import db
 
-        block_range = listed_events['block_range']
-        if start_block < block_range[0]:
-            download = {
-                'start_block': start_block,
-                'end_block': block_range[0] - 1,
-                'common_kwargs': {'verbose': verbose},
-            }
-            downloads.append(download)
-        if end_block > block_range[-1]:
-            download = {
-                'start_block': block_range[-1] + 1,
-                'end_block': end_block,
-                'common_kwargs': {'verbose': verbose},
-            }
-            downloads.append(download)
-
-    # perform downloads
-    for download in downloads:
-        await async_transfer_events(
-            from_backend='node',
-            to_backend='filesystem',
-            event_hash=event_hash,
-            event_abi=event_abi,
+        query_type = event_query_utils._parse_event_query_type(
             contract_address=contract_address,
-            provider=provider,
-            **download,
+            event_hash=event_hash,
+            topic1=topic1,
+            topic2=topic2,
+            topic3=topic3,
         )
 
-    # load from filesystem
-    return await filesystem_events.async_get_events_from_filesystem(
-        event_hash=event_hash,
-        event_abi=event_abi,
-        contract_address=contract_address,
-        start_block=start_block,
-        end_block=end_block,
-        verbose=verbose,
-        provider=provider,
-    )
+        query: spec.DBEventQuery = {
+            'query_type': query_type,
+            'contract_address': contract_address,
+            'event_hash': event_hash,
+            'topic1': topic1,
+            'topic2': topic2,
+            'topic3': topic3,
+            'start_block': chunk_start,
+            'end_block': chunk_end,
+        }
+        await db.async_intake_encoded_events(
+            encoded_events=encoded_events,
+            query=query,
+            context=context,
+            latest_block=latest_block_number,
+        )
 
+    return encoded_events
 
-async def async_get_event_timestamps(
-    events: spec.DataFrame,
-    provider: spec.ProviderReference = None,
-) -> typing.Sequence[int]:
-
-    # get block_numbers
-    multi_index = 'block_number' in events.index.names
-    if multi_index:
-        block_numbers = events.index.get_level_values('block_number')
-    else:
-        block_numbers = events.index.values
 
-    # get timestamps
-    return await block_utils.async_get_block_timestamps(
-        block_numbers,
-        provider=provider,
-    )
+# async def _async_process_raw_node_logs(
+#     raw_logs: typing.Sequence[spec.RawLog],
+# ) -> typing.Sequence[spec.EncodedEvent]:
+#     """convert from raw logs from node into encoded events for db"""
+#     for log in raw_logs:
+#         event: spec.EncodedEvent = log  # type: ignore
+#         event['contract_address'] = log.pop('address')  # type: ignore
+#         event['unindexed'] = log.pop('data')  # type: ignore
+#         topics = log.pop('topics')  # type: ignore
+#         if topics is not None and len(topics) > 0:
+#             topic_iter = iter(topics)
+#             if len(topics) >= 1:
+#                 event['event_hash'] = next(topic_iter)
+#             if len(topics) >= 2:
+#                 event['topic1'] = next(topic_iter)
+#             if len(topics) >= 3:
+#                 event['topic2'] = next(topic_iter)
+#             if len(topics) >= 4:
+#                 event['topic3'] = next(topic_iter)
+#     return raw_logs  # type: ignore
+
```

### Comparing `checkthechain-0.3.0/src/ctc/evm/transaction_utils/transaction_hashes.py` & `checkthechain-0.3.4/src/ctc/evm/transaction_utils/transaction_hashes.py`

 * *Files 6% similar despite different names*

```diff
@@ -2,25 +2,25 @@
 
 from ctc import spec
 from .. import binary_utils
 from . import transaction_serialize
 
 
 def hash_unsigned_transaction(
-    transaction: spec.TransactionData,
+    transaction: spec.PrechainTransaction,
     *,
     chain_id: int | None = None,
 ) -> spec.Data:
     """compute hash of unsigned transaction"""
 
     serialized = transaction_serialize.serialize_unsigned_transaction(
         transaction,
         chain_id=chain_id,
     )
     return binary_utils.keccak(serialized)
 
 
-def hash_signed_transaction(transaction: spec.TransactionData) -> spec.Data:
+def hash_signed_transaction(transaction: spec.PrechainTransaction) -> spec.Data:
     """compute hash of signed transaction"""
 
     serialized = transaction_serialize.serialize_signed_transaction(transaction)
     return binary_utils.keccak(serialized)
```

### Comparing `checkthechain-0.3.0/src/ctc/evm/transaction_utils/transaction_serialize.py` & `checkthechain-0.3.4/src/ctc/evm/transaction_utils/transaction_types.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,67 +1,95 @@
 from __future__ import annotations
 
+import typing
+
 from ctc import spec
 from .. import binary_utils
-from . import transaction_types
 
 
-def serialize_unsigned_transaction(
-    transaction: spec.TransactionData,
-    *,
-    chain_id: int | None = None,
-) -> spec.PrefixHexData:
-    """serialize unsigned transaction"""
-
-    # collect keys for transaction type
-    type = transaction_types.get_transaction_type(transaction)
-    keys = transaction_types.get_transaction_type_keys(type, signed=False)
-
-    # represent as list
-    as_list = [transaction[key] for key in keys]  # type: ignore
-
-    # add EIP-155 chain_id
-    if type == 0:
-        if chain_id is None and transaction.get('chain_id') is not None:
-            chain_id = binary_utils.binary_convert(transaction.get('chain_id'), 'integer')  # type: ignore
-        if chain_id is not None:
-            as_list.append(chain_id)
-            as_list.append(0)
-            as_list.append(0)
-
-    # get transaction type prefix
-    if type == 0:
-        prefix = '0x'
-    elif type == 1:
-        prefix = '0x01'
-    elif type == 2:
-        prefix = '0x02'
+def get_transaction_type(
+    transaction_or_type: spec.Data | typing.Mapping[str, typing.Any]
+) -> int:
+    """get transaction type"""
+
+    if isinstance(transaction_or_type, (int, str, bytes)):
+        # if type provided directly, convert to int
+        return binary_utils.binary_convert(transaction_or_type, 'integer')
+
+    elif isinstance(transaction_or_type, dict):
+        transaction = transaction_or_type
+
+        # if type explicitly provided, use it
+        if 'type' in transaction:
+            return binary_utils.binary_convert(transaction['type'], 'integer')
+
+        # otherwise, infer type based on fields
+        if 'max_fee_per_gas' in transaction:
+            return 2
+        if 'access_list' in transaction or 'accessList' in transaction:
+            return 1
+        else:
+            return 0
+
     else:
-        raise Exception('unknown transaction type: ' + str(type))
+        raise Exception('unknown transaction format')
 
-    return prefix + binary_utils.rlp_encode(as_list, 'raw_hex')
+
+def get_transaction_type_name(
+    transaction_or_type: typing.Mapping[str, typing.Any] | spec.Data
+) -> str:
+    """get transaction type name"""
+
+    transaction_type = get_transaction_type(transaction_or_type)
+
+    # return name
+    if transaction_type == 0:
+        return 'legacy'
+    elif transaction_type == 1:
+        return 'eip2930'
+    elif transaction_type == 2:
+        return 'eip1559'
+    else:
+        raise Exception('unknown transaction type: ' + str(transaction_type))
 
 
-def serialize_signed_transaction(
-    transaction: spec.TransactionData,
-) -> spec.PrefixHexData:
-    """serialize signed transaction"""
-
-    # collect keys for transaction type
-    type = transaction_types.get_transaction_type(transaction)
-    keys = transaction_types.get_transaction_type_keys(type, signed=True)
-
-    # get list of fields
-    as_list = [transaction[key] for key in keys]  # type: ignore
-
-    # get transaction type prefix
-    if type == 0:
-        prefix = '0x'
-    elif type == 1:
-        prefix = '0x01'
-    elif type == 2:
-        prefix = '0x02'
+def get_transaction_type_keys(
+    transaction: typing.Mapping[str, typing.Any],
+    *,
+    signed: bool,
+) -> tuple[str, ...]:
+    """return list of keys that are used by a given transaction type"""
+
+    transaction_type = get_transaction_type(transaction)
+
+    # determine whether camelcase
+    if transaction_type in [1, 2]:
+        if 'accessList' in transaction:
+            snake = False
+        elif 'access_list' in transaction:
+            snake = True
+        else:
+            raise Exception('transaction does not specify access_list or accessList')
+    elif transaction_type == 0:
+        snake = 'chain_id' in transaction
+    else:
+        raise Exception('unknown transaction type: ' + str(transaction_type))
+
+    # get keys
+    if transaction_type == 0:
+        keys: tuple[str, ...] = spec.transaction_keys_legacy
+    elif transaction_type == 1 and snake:
+        keys = spec.transaction_keys_eip2930
+    elif transaction_type == 1 and not snake:
+        keys = spec.transaction_keys_eip2930_camel
+    elif transaction_type == 2 and snake:
+        keys = spec.transaction_keys_eip1559
+    elif transaction_type == 2 and not snake:
+        keys = spec.transaction_keys_eip1559_camel
     else:
-        raise Exception('unknown transaction type: ' + str(type))
+        raise Exception('unknown transaction type: ' + str(transaction_type))
+
+    # remove signature keys if unsigned
+    if not signed:
+        keys = tuple(key for key in keys if key not in ('v', 'r', 's'))
 
-    # encode as rlp
-    return prefix + binary_utils.rlp_encode(as_list, 'raw_hex')
+    return keys
```

### Comparing `checkthechain-0.3.0/src/ctc/evm/transaction_utils/transaction_signatures.py` & `checkthechain-0.3.4/src/ctc/evm/transaction_utils/transaction_signatures.py`

 * *Files 5% similar despite different names*

```diff
@@ -6,40 +6,47 @@
 from .. import binary_utils
 from . import transaction_serialize
 from . import transaction_hashes
 from . import transaction_types
 
 
 def sign_transaction(
-    transaction: spec.TransactionData,
+    transaction: spec.PrechainTransaction,
     *,
     private_key: str,
     chain_id: int | None = None,
 ) -> tuple[int, int, int]:
     """sign transaction using private key"""
 
+    tx_chain_id: typing.Union[int, bytes, str, None]
     if chain_id is None and 'chain_id' in transaction:
         tx_chain_id = transaction['chain_id']
         if tx_chain_id is not None:
             chain_id = binary_utils.binary_convert(tx_chain_id, 'integer')
+    elif chain_id is None and 'chainId' in transaction:
+        tx_chain_id = typing.cast(
+            typing.Union[int, bytes, str, None], transaction.get('chainId')
+        )
+        if tx_chain_id is not None:
+            chain_id = binary_utils.binary_convert(tx_chain_id, 'integer')
     message = transaction_serialize.serialize_unsigned_transaction(
         transaction,
         chain_id=chain_id,
     )
     return binary_utils.sign_data_message(
         message=message,
         private_key=private_key,
         chain_id=chain_id,
         mode='eth_sign',
     )
 
 
 def verify_transaction_signature(
     *,
-    transaction: spec.TransactionData,
+    transaction: spec.PrechainTransaction,
     signature: spec.Signature | None = None,
     public_key: spec.Data | None = None,
     address: spec.Data | None = None,
 ) -> bool:
     """verify that transaction was signed by given public key"""
 
     # extract signature from transaction
@@ -68,15 +75,15 @@
         message_hash=transaction_hash,
         public_key=public_key,
         address=address,
     )
 
 
 def recover_transaction_sender(
-    transaction: spec.TransactionData,
+    transaction: spec.PrechainTransaction,
     signature: spec.Signature,
 ) -> spec.Address:
     """recover signing address of transaction from signature
 
     adapted from https://github.com/ethereum/pyethereum/blob/ecb14c937a0b6cb0a0dc4f06be3a88e6d53dcce3/ethereum/transactions.py#L68
     """
 
@@ -127,7 +134,8 @@
     """return whether transaction is signed"""
 
     return (
         transaction.get('v') is not None
         and transaction.get('r') is not None
         and transaction.get('s') is not None
     )
+
```

### Comparing `checkthechain-0.3.0/src/ctc/evm/transaction_utils/transaction_summary.py` & `checkthechain-0.3.4/src/ctc/evm/transaction_utils/transaction_summary.py`

 * *Files 12% similar despite different names*

```diff
@@ -2,45 +2,54 @@
 
 import time
 
 from ctc import evm
 from ctc import spec
 from .. import binary_utils
 from .. import block_utils
+from .. import trace_utils
 from . import transaction_types
 
 
 async def async_print_transaction_summary(
     transaction_hash: str,
+    *,
+    context: spec.Context = None,
     sort_logs_by: str | None = None,
 ) -> None:
     """print summary of transaction"""
 
     import asyncio
     import toolstr
     import tooltime
     from ctc import cli
     from ctc import rpc
     from ctc.protocols import chainlink_utils
 
     transaction_coroutine = rpc.async_eth_get_transaction_by_hash(
-        transaction_hash
+        transaction_hash,
+        context=context,
     )
     transaction_receipt_task = asyncio.create_task(
-        rpc.async_eth_get_transaction_receipt(transaction_hash=transaction_hash)
+        rpc.async_eth_get_transaction_receipt(
+            transaction_hash=transaction_hash, context=context
+        )
     )
 
     transaction = await transaction_coroutine
     block_task = asyncio.create_task(
         block_utils.async_get_block(
-            transaction['block_number'], include_full_transactions=False
+            transaction['block_number'],
+            context=context,
         )
     )
     eth_usd_task = asyncio.create_task(
-        chainlink_utils.async_get_eth_price(block=transaction['block_number'])
+        chainlink_utils.async_get_eth_price(
+            block=transaction['block_number'], context=context
+        )
     )
 
     styles = cli.get_cli_styles()
     toolstr.print_text_box('Transaction Summary', style=styles['title'])
     cli.print_bullet(key='hash', value=transaction['hash'])
     cli.print_bullet(key='from', value=transaction['from'])
     cli.print_bullet(key='to', value=transaction['to'])
@@ -66,17 +75,15 @@
     print()
     print()
     transaction_receipt = await transaction_receipt_task
     toolstr.print_text_box('Transaction Receipt', style=styles['title'])
     cli.print_bullet(key='success', value=bool(transaction_receipt['status']))
     cli.print_bullet(
         key='transaction index',
-        value=str(transaction_receipt['transaction_index'])
-        + ' / '
-        + str(len(block['transactions'])),
+        value=str(transaction_receipt['transaction_index']),
     )
     cli.print_bullet(
         key='gas used',
         value=toolstr.format(transaction_receipt['gas_used'])
         + ' / '
         + toolstr.format(transaction['gas']),
     )
@@ -109,27 +116,29 @@
         print('[none]')
     else:
         try:
             contract_abi_task = asyncio.create_task(
                 evm.async_get_contract_abi(
                     contract_address=transaction['to'],
                     verbose=False,
+                    context=context,
                 )
             )
             contract_abi = await contract_abi_task
         except spec.AbiNotFoundException:
             print()
             print()
             print('[no contract ABI available]')
             return
 
         try:
             function_abi = await evm.async_get_function_abi(
                 contract_address=transaction['to'],
                 function_selector=transaction['input'][:10],
+                context=context,
             )
         except Exception:
             print()
             print()
             print('could not find function ABI. custom proxy being used?')
             return
 
@@ -141,14 +150,15 @@
         print()
 
         from ctc.cli.commands.compute import decode_call_command
 
         await decode_call_command.async_decode_call_command(
             args=[transaction_hash],
             title='Call Data',
+            context=context,
         )
 
     print()
     print()
     toolstr.print_text_box('Logs', style=styles['title'])
     logs = transaction_receipt['logs']
     if len(logs) == 0:
@@ -166,14 +176,15 @@
         for li, log in enumerate(logs):
             if li != 0:
                 print()
 
             event_abi = await evm.async_get_event_abi(
                 contract_address=log['address'],
                 event_hash=log['topics'][0],
+                context=context,
             )
             normalized_event = evm.normalize_event(
                 event=log,
                 arg_prefix=None,
                 event_abi=event_abi,
             )
             # event_signature = binary_utils.get_event_signature(event_abi=event_abi)
@@ -197,16 +208,30 @@
                     value
                     == 115792089237316195423570985008687907853269984665640564039457584007913129639935
                 ):
                     value = 'INT_MAX'
 
                 # not sure if this is what should be done
                 if isinstance(value, bytes):
-                    value = binary_utils.binary_convert(value, 'prefix_hex')
+                    value = binary_utils.to_hex(value)
 
                 cli.print_bullet(
                     key=name,
                     value=value,
                     colon_str=' = ',
                     number=e + 1,
                     indent=4,
                 )
+
+    print()
+    await trace_utils.async_print_transaction_balance_diffs(
+        transaction_hash,
+        styles=styles,
+        context=context,
+    )
+    print()
+    await trace_utils.async_print_transaction_storage_diffs(
+        transaction_hash,
+        styles=styles,
+        context=context,
+    )
+
```

### Comparing `checkthechain-0.3.0/src/ctc/evm/transaction_utils/transaction_types.py` & `checkthechain-0.3.4/src/ctc/evm/transaction_utils/transaction_serialize.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,104 +1,96 @@
 from __future__ import annotations
 
 import typing
 
 from ctc import spec
 from .. import binary_utils
+from . import transaction_types
 
 
-def standardize_transaction(
-    transaction: typing.Mapping[str, typing.Any]
-) -> typing.Mapping[str, typing.Any]:
-    """return standardized version of transaction
-
-    - convert any camelcase keys or non-standard keys to single format
-    - fill in missing keys
-    """
-
-    standardized = {}
-    for key, value in transaction.items():
-        if key in spec.transaction_keys_standardized:
-            key = spec.transaction_keys_standardized[key]
-        standardized[key] = value
-
-    if 'input' not in standardized:
-        standardized['input'] = bytes()
-    if (
-        'max_priority_fee_per_gas' in standardized
-        and 'access_list' not in standardized
-    ):
-        standardized['access_list'] = []
-
-    return standardized
-
-
-def get_transaction_type(
-    transaction_or_type: spec.Data | typing.Mapping[str, typing.Any]
-) -> int:
-    """get transaction type"""
-
-    if isinstance(transaction_or_type, (int, str, bytes)):
-        # if type provided directly, convert to int
-        return binary_utils.binary_convert(transaction_or_type, 'integer')
-
-    elif isinstance(transaction_or_type, dict):
-        transaction = transaction_or_type
-
-        # if type explicitly provided, use it
-        if 'type' in transaction:
-            return binary_utils.binary_convert(transaction['type'], 'integer')
-
-        # otherwise, infer type based on fields
-        if 'max_fee_per_gas' in transaction:
-            return 2
-        if 'access_list' in transaction or 'accessList' in transaction:
-            return 1
+def serialize_unsigned_transaction(
+    transaction: spec.PrechainTransaction,
+    *,
+    chain_id: int | None = None,
+) -> spec.PrefixHexData:
+    """serialize unsigned transaction"""
+
+    # collect keys for transaction type
+    type = transaction_types.get_transaction_type(transaction)
+    keys = transaction_types.get_transaction_type_keys(transaction, signed=False)
+
+    # represent as list
+    as_list: list[typing.Any] = []
+    for key in keys:
+        if key == 'chain_id':
+            if transaction.get('chain_id') is not None:
+                as_list.append(transaction.get('chain_id'))
+            elif transaction.get('chainId') is not None:
+                as_list.append(transaction.get('chainId'))
+            elif chain_id is not None:
+                as_list.append(chain_id)
+            else:
+                raise Exception('must specify chain_id')
+        elif key in ['access_list', 'accessList']:
+            access_list = transaction[key]  # type: ignore
+            if len(access_list) > 0 and isinstance(access_list[0], dict):
+                if 'storageKeys' in access_list[0]:
+                    access_list = [
+                        [item['address'], item['storageKeys']]
+                        for item in access_list
+                    ]
+                else:
+                    access_list = [
+                        [item['address'], item['storage_keys']]
+                        for item in access_list
+                    ]
+            as_list.append(access_list)
         else:
-            return 0
+            as_list.append(transaction[key])  # type: ignore
 
+    # add EIP-155 chain_id
+    if type == 0:
+        if chain_id is None and transaction.get('chain_id') is not None:
+            chain_id = binary_utils.binary_convert(transaction.get('chain_id'), 'integer')  # type: ignore
+        if chain_id is not None:
+            as_list.append(chain_id)
+            as_list.append(0)
+            as_list.append(0)
+
+    # get transaction type prefix
+    if type == 0:
+        prefix = '0x'
+    elif type == 1:
+        prefix = '0x01'
+    elif type == 2:
+        prefix = '0x02'
     else:
-        raise Exception('unknown transaction format')
-
+        raise Exception('unknown transaction type: ' + str(type))
 
-def get_transaction_type_name(
-    transaction_or_type: typing.Mapping[str, typing.Any] | spec.Data
-) -> str:
-    """get transaction type name"""
-
-    transaction_type = get_transaction_type(transaction_or_type)
-
-    # return name
-    if transaction_type == 0:
-        return 'legacy'
-    elif transaction_type == 1:
-        return 'eip2930'
-    elif transaction_type == 2:
-        return 'eip1559'
-    else:
-        raise Exception('unknown transaction type: ' + str(transaction_type))
+    return prefix + binary_utils.rlp_encode(as_list, 'raw_hex')
 
 
-def get_transaction_type_keys(
-    transaction_or_type: typing.Mapping[str, typing.Any] | spec.Data,
-    *,
-    signed: bool,
-) -> tuple[str, ...]:
-    """return list of keys that are used by a given transaction type"""
-
-    transaction_type = get_transaction_type(transaction_or_type)
-
-    # get keys
-    if transaction_type == 0:
-        keys: tuple[str, ...] = spec.transaction_keys_legacy
-    elif transaction_type == 1:
-        keys = spec.transaction_keys_eip2930
-    elif transaction_type == 2:
-        keys = spec.transaction_keys_eip1559
+def serialize_signed_transaction(
+    transaction: spec.PrechainTransaction,
+) -> spec.PrefixHexData:
+    """serialize signed transaction"""
+
+    # collect keys for transaction type
+    type = transaction_types.get_transaction_type(transaction)
+    keys = transaction_types.get_transaction_type_keys(transaction, signed=True)
+
+    # get list of fields
+    as_list = [transaction[key] for key in keys]  # type: ignore
+
+    # get transaction type prefix
+    if type == 0:
+        prefix = '0x'
+    elif type == 1:
+        prefix = '0x01'
+    elif type == 2:
+        prefix = '0x02'
     else:
-        raise Exception('unknown transaction type: ' + str(transaction_type))
+        raise Exception('unknown transaction type: ' + str(type))
 
-    # remove signature keys if unsigned
-    if not signed:
-        keys = tuple(key for key in keys if key not in ('v', 'r', 's'))
+    # encode as rlp
+    return prefix + binary_utils.rlp_encode(as_list, 'raw_hex')
 
-    return keys
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/aave_v2_utils/aave_interest_rates.py` & `checkthechain-0.3.4/src/ctc/protocols/aave_v2_utils/aave_interest_rates.py`

 * *Files 10% similar despite different names*

```diff
@@ -3,78 +3,76 @@
 
 incentives not currently included
 """
 from __future__ import annotations
 
 import asyncio
 import typing
-from typing_extensions import TypedDict
 
 from ctc import evm
 from ctc import rpc
 from ctc import spec
 from ctc.toolbox import nested_utils
 from . import aave_pool_tokens
 
+if typing.TYPE_CHECKING:
+    from typing_extensions import TypedDict
+
+    class AaveV2ReserveData(TypedDict):
+        configuration: int
+        liquidity_index: int
+        variable_borrow_index: int
+        current_liquidity_rate: int
+        current_variable_borrow_rate: int
+        current_stable_borrow_rate: int
+        last_update_timestamp: int
+        atoken_address: spec.Address
+        stable_debt_token_address: spec.Address
+        variable_debt_token_address: spec.Address
+        interest_rate_strategy_address: spec.Address
+        id: int
+
+    class AaveV2ReserveListData(TypedDict):
+        configuration: list[int]
+        liquidity_index: list[int]
+        variable_borrow_index: list[int]
+        current_liquidity_rate: list[int]
+        current_variable_borrow_rate: list[int]
+        current_stable_borrow_rate: list[int]
+        last_update_timestamp: list[int]
+        atoken_address: list[spec.Address]
+        stable_debt_token_address: list[spec.Address]
+        variable_debt_token_address: list[spec.Address]
+        interest_rate_strategy_address: list[spec.Address]
+        id: list[int]
+
+    class AaveV2TokenMarket(TypedDict):
+        underlying: spec.Address
+        symbol: str
+        reserve_data: AaveV2ReserveData
+
 
 ray = 10**27
 seconds_per_year = 31536000
 
 aave_lending_pool = '0x7d2768de32b0b80b7a3454c06bdac94a69ddc7a9'
 
 
-class AaveV2ReserveData(TypedDict):
-    configuration: int
-    liquidity_index: int
-    variable_borrow_index: int
-    current_liquidity_rate: int
-    current_variable_borrow_rate: int
-    current_stable_borrow_rate: int
-    last_update_timestamp: int
-    atoken_address: spec.Address
-    stable_debt_token_address: spec.Address
-    variable_debt_token_address: spec.Address
-    interest_rate_strategy_address: spec.Address
-    id: int
-
-
-class AaveV2ReserveListData(TypedDict):
-    configuration: list[int]
-    liquidity_index: list[int]
-    variable_borrow_index: list[int]
-    current_liquidity_rate: list[int]
-    current_variable_borrow_rate: list[int]
-    current_stable_borrow_rate: list[int]
-    last_update_timestamp: list[int]
-    atoken_address: list[spec.Address]
-    stable_debt_token_address: list[spec.Address]
-    variable_debt_token_address: list[spec.Address]
-    interest_rate_strategy_address: list[spec.Address]
-    id: list[int]
-
-
-class AaveV2TokenMarket(TypedDict):
-    underlying: spec.Address
-    symbol: str
-    reserve_data: AaveV2ReserveData
-
-
 async def async_get_reserve_data(
     asset: spec.Address,
     block: spec.BlockNumberReference | None = None,
     *,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
 ) -> AaveV2ReserveData:
-
     result = await rpc.async_eth_call(
         to_address=aave_lending_pool,
         function_name='getReserveData',
         function_parameters=[asset],
         block_number=block,
-        provider=provider,
+        context=context,
     )
 
     return {
         'configuration': result[0],
         'liquidity_index': result[1],
         'variable_borrow_index': result[2],
         'current_liquidity_rate': result[3],
@@ -89,45 +87,43 @@
     }
 
 
 async def async_get_reserve_data_by_block(
     asset: spec.Address,
     blocks: typing.Sequence[spec.BlockNumberReference],
     *,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
 ) -> AaveV2ReserveListData:
-
     coroutines = [
-        async_get_reserve_data(asset, block=block, provider=provider)
+        async_get_reserve_data(asset, block=block, context=context)
         for block in blocks
     ]
 
     results = await asyncio.gather(*coroutines)
-    return typing.cast(
-        AaveV2ReserveListData,
-        nested_utils.list_of_dicts_to_dict_of_lists(results),
-    )
+    return nested_utils.list_of_dicts_to_dict_of_lists(results)  # type: ignore
 
 
 async def async_get_reserves_data(
     *,
     reserves_list: typing.Sequence[spec.Address] | None = None,
     block: spec.BlockNumberReference | None = None,
+    context: spec.Context = None,
 ) -> typing.Sequence[AaveV2ReserveData]:
-
     if reserves_list is None:
         reserves_list = await aave_pool_tokens.async_get_reserves_list(
-            block=block
+            block=block,
+            context=context,
         )
 
     results = await rpc.async_batch_eth_call(
         to_address=aave_lending_pool,
         function_name='getReserveData',
         function_parameter_list=[[asset] for asset in reserves_list],
         block_number=block,
+        context=context,
     )
 
     return [
         {
             'configuration': result[0],
             'liquidity_index': result[1],
             'variable_borrow_index': result[2],
@@ -145,26 +141,28 @@
     ]
 
 
 async def async_get_token_markets(
     *,
     reserves_list: typing.Sequence[spec.Address] | None = None,
     block: spec.BlockNumberReference | None = None,
+    context: spec.Context = None,
 ) -> typing.Sequence[AaveV2TokenMarket]:
-
     if reserves_list is None:
         reserves_list = await aave_pool_tokens.async_get_reserves_list(
-            block=block
+            block=block, context=context
         )
 
     reserves_data_task = asyncio.create_task(
-        async_get_reserves_data(reserves_list=reserves_list, block=block)
+        async_get_reserves_data(
+            reserves_list=reserves_list, block=block, context=context
+        )
     )
     symbols_task = asyncio.create_task(
-        evm.async_get_erc20s_symbols(reserves_list)
+        evm.async_get_erc20s_symbols(reserves_list, context=context)
     )
 
     reserves_data = await reserves_data_task
     symbols = await symbols_task
 
     markets = []
     for r in range(len(reserves_list)):
@@ -178,20 +176,22 @@
 
 
 async def async_get_interest_rates(
     *,
     token: spec.Address | None = None,
     block: spec.BlockNumberReference | None = None,
     reserve_data: AaveV2ReserveData | None = None,
+    context: spec.Context = None,
 ) -> dict[str, float]:
-
     if reserve_data is None:
         if token is None:
             raise Exception('must specify token or reserve_data')
-        reserve_data = await async_get_reserve_data(asset=token, block=block)
+        reserve_data = await async_get_reserve_data(
+            asset=token, block=block, context=context
+        )
 
     supply_apr = reserve_data['current_liquidity_rate'] / ray
     supply_apy = (1 + supply_apr / seconds_per_year) ** seconds_per_year - 1
     borrow_apr = reserve_data['current_variable_borrow_rate'] / ray
     borrow_apy = (1 + borrow_apr / seconds_per_year) ** seconds_per_year - 1
 
     return {
@@ -203,20 +203,21 @@
 
 
 async def async_get_interest_rates_by_block(
     token: spec.Address,
     blocks: typing.Sequence[spec.BlockNumberReference],
     *,
     reserve_data_by_block: AaveV2ReserveListData | None = None,
+    context: spec.Context = None,
 ) -> dict[str, list[float]]:
     import numpy as np
 
     if reserve_data_by_block is None:
         reserve_data_by_block = await async_get_reserve_data_by_block(
-            asset=token, blocks=blocks
+            asset=token, blocks=blocks, context=context
         )
 
     currrent_liquidity_rate: spec.NumpyArray = np.array(
         reserve_data_by_block['current_liquidity_rate']
     )
     current_variable_borrow_rate: spec.NumpyArray = np.array(
         reserve_data_by_block['current_variable_borrow_rate']
@@ -229,7 +230,8 @@
 
     return {
         'supply_apr': list(supply_apr),
         'supply_apy': list(supply_apy),
         'borrow_apr': list(borrow_apr),
         'borrow_apy': list(borrow_apy),
     }
+
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/aave_v2_utils/aave_lending_pool.py` & `checkthechain-0.3.4/src/ctc/protocols/chainlink_utils/chainlink_data/feed_data.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,102 +1,106 @@
 from __future__ import annotations
 
 import typing
 
 from ctc import evm
-from ctc import rpc
 from ctc import spec
 
-from . import aave_spec
+from .. import chainlink_feed_metadata
+from .. import chainlink_spec
+from . import feed_datum_by_block
+from . import feed_events
+
 
 if typing.TYPE_CHECKING:
     import tooltime
 
 
-async def async_get_deposits(
+async def async_get_feed_data(
+    feed: chainlink_spec._FeedReference,
     *,
+    fields: typing.Literal['answer', 'full'] = 'answer',
+    blocks: typing.Sequence[spec.BlockNumberReference] | None = None,
     start_block: spec.BlockNumberReference | None = None,
     end_block: spec.BlockNumberReference | None = None,
     start_time: tooltime.Timestamp | None = None,
     end_time: tooltime.Timestamp | None = None,
-    include_timestamps: bool = False,
-    provider: spec.ProviderReference = None,
+    invert: bool = False,
+    normalize: bool = True,
+    interpolate: bool = False,
+    context: spec.Context = None,
 ) -> spec.DataFrame:
 
-    provider = rpc.get_provider(provider)
-
     start_block, end_block = await evm.async_resolve_block_range(
         start_block=start_block,
         end_block=end_block,
         start_time=start_time,
         end_time=end_time,
         allow_none=True,
-        provider=provider,
-    )
-
-    network = provider['network']
-    if network is None:
-        raise Exception('could not determine network')
-
-    if end_block is None:
-        end_block = 'latest'
-
-    aave_lending_pool = aave_spec.get_aave_address(
-        name='LendingPool',
-        network=network,
+        context=context,
     )
-    events = await evm.async_get_events(
-        contract_address=aave_lending_pool,
-        event_name='Deposit',
-        start_block=start_block,
-        end_block=end_block,
-        include_timestamps=include_timestamps,
-        verbose=False,
-    )
-    events['arg__amount'] = events['arg__amount'].map(int)
-
-    return events
 
+    # determine blocks
+    if (blocks is not None) and [start_block, end_block].count(None) < 2:
+        raise Exception('should only provide one block specification')
+    if blocks is None:
+        if start_block is None:
+            start_block = (
+                await chainlink_feed_metadata.async_get_feed_first_block(
+                    feed=feed,
+                    context=context,
+                )
+            )
+        if end_block is None:
+            end_block = 'latest'
+
+    # perform query
+    if fields == 'answer':
+
+        if blocks is not None:
+            return (
+                await feed_datum_by_block.async_get_feed_answer_datum_by_block(
+                    feed,
+                    blocks=blocks,
+                    normalize=normalize,
+                    interpolate=interpolate,
+                    invert=invert,
+                    context=context,
+                )
+            )
+
+        else:
+            return await feed_events.async_get_answer_feed_event_data(
+                feed,
+                normalize=normalize,
+                start_block=start_block,
+                end_block=end_block,
+                interpolate=interpolate,
+                invert=invert,
+                context=context,
+            )
+
+    elif fields == 'full':
+
+        if blocks is not None:
+            return await feed_datum_by_block.async_get_feed_full_datum_by_block(
+                feed,
+                blocks=blocks,
+                normalize=normalize,
+                interpolate=interpolate,
+                invert=invert,
+                context=context,
+            )
+
+        else:
+            return await feed_events.async_get_full_feed_event_data(
+                feed,
+                normalize=normalize,
+                start_block=start_block,
+                end_block=end_block,
+                interpolate=interpolate,
+                invert=invert,
+                context=context,
+            )
 
-async def async_get_withdrawals(
-    *,
-    start_block: spec.BlockNumberReference | None = None,
-    end_block: spec.BlockNumberReference | None = None,
-    start_time: tooltime.Timestamp | None = None,
-    end_time: tooltime.Timestamp | None = None,
-    include_timestamps: bool = False,
-    provider: spec.ProviderReference = None,
-) -> spec.DataFrame:
-
-    provider = rpc.get_provider(provider)
-
-    start_block, end_block = await evm.async_resolve_block_range(
-        start_block=start_block,
-        end_block=end_block,
-        start_time=start_time,
-        end_time=end_time,
-        allow_none=True,
-        provider=provider,
-    )
-
-    network = provider['network']
-    if network is None:
-        raise Exception('could not determine network')
-
-    if end_block is None:
-        end_block = 'latest'
-
-    aave_lending_pool = aave_spec.get_aave_address(
-        name='LendingPool',
-        network=network,
-    )
-    events = await evm.async_get_events(
-        contract_address=aave_lending_pool,
-        event_name='Withdraw',
-        start_block=start_block,
-        include_timestamps=include_timestamps,
-        end_block=end_block,
-        verbose=False,
-    )
-    events['arg__amount'] = events['arg__amount'].map(int)
-
-    return events
+    else:
+        raise Exception('unknown fields format: ' + str(fields))
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/aave_v2_utils/aave_oracle.py` & `checkthechain-0.3.4/src/ctc/protocols/aave_v2_utils/aave_oracle.py`

 * *Files 19% similar despite different names*

```diff
@@ -9,40 +9,37 @@
 
 from . import aave_spec
 
 
 async def async_get_asset_price(
     asset: spec.Address,
     *,
-    provider: spec.ProviderReference = None,
     block: spec.BlockNumberReference = 'latest',
     normalize: bool = True,
     units: typing.Literal['usd', 'eth'] = 'usd',
+    context: spec.Context = None,
 ) -> int | float:
 
-    provider = rpc.get_provider(provider)
-    network = provider['network']
-    if network is None:
-        raise Exception('could not determine network')
-
-    oracle = aave_spec.get_aave_address('PriceOracle', network=network)
+    oracle = aave_spec.get_aave_address('PriceOracle', context=context)
     price_coroutine = rpc.async_eth_call(
         to_address=oracle,
-        provider=provider,
         block_number=block,
         function_name='getAssetPrice',
         function_parameters=[asset],
+        context=context,
     )
 
     if units == 'eth':
-        price = await price_coroutine
+        price: int | float = await price_coroutine
 
     elif units == 'usd':
         eth_usd_coroutine = chainlink_utils.async_get_eth_price(
-            block=block, normalize=True
+            block=block,
+            normalize=True,
+            context=context,
         )
         asset_price, eth_usd = await asyncio.gather(
             price_coroutine, eth_usd_coroutine
         )
         price = asset_price * eth_usd
 
     else:
@@ -56,40 +53,35 @@
 
     return price
 
 
 async def async_get_asset_prices(
     assets: typing.Sequence[spec.Address],
     *,
-    provider: spec.ProviderReference = None,
     block: spec.BlockNumberReference = 'latest',
     normalize: bool = True,
     units: typing.Literal['usd', 'eth'] = 'usd',
+    context: spec.Context = None,
 ) -> typing.Sequence[int | float]:
 
-    provider = rpc.get_provider(provider)
-    network = provider['network']
-    if network is None:
-        raise Exception('could not determine network')
-
-    oracle = aave_spec.get_aave_address('PriceOracle', network=network)
+    oracle = aave_spec.get_aave_address('PriceOracle', context=context)
     price_coroutine = rpc.async_batch_eth_call(
         to_address=oracle,
-        provider=provider,
         block_number=block,
         function_name='getAssetPrice',
         function_parameter_list=[[asset] for asset in assets],
+        context=context,
     )
 
     if units == 'eth':
         prices = await price_coroutine
 
     elif units == 'usd':
         eth_usd_coroutine = chainlink_utils.async_get_eth_price(
-            block=block, normalize=True
+            block=block, normalize=True, context=context,
         )
         asset_prices, eth_usd = await asyncio.gather(
             price_coroutine, eth_usd_coroutine
         )
         prices = [asset_price * eth_usd for asset_price in asset_prices]
 
     else:
@@ -101,22 +93,23 @@
     return prices
 
 
 async def async_get_asset_price_by_block(
     asset: spec.Address,
     *,
     blocks: typing.Sequence[spec.BlockNumberReference],
-    provider: spec.ProviderReference = None,
     normalize: bool = True,
     units: typing.Literal['usd', 'eth'] = 'usd',
+    context: spec.Context = None,
 ) -> typing.Sequence[int | float]:
     coroutines = [
         async_get_asset_price(
             asset=asset,
-            provider=provider,
             block=block,
             normalize=normalize,
             units=units,
+            context=context,
         )
         for block in blocks
     ]
     return await asyncio.gather(*coroutines)
+
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/aave_v2_utils/aave_pool_tokens.py` & `checkthechain-0.3.4/src/ctc/protocols/rari_utils/fuse_queries/token_metadata.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,50 +1,48 @@
 from __future__ import annotations
 
-import typing
-
-from ctc import evm
 from ctc import rpc
 from ctc import spec
 
-from . import aave_spec
+from .. import rari_abis
 
 
-async def async_get_underlying_asset(
-    pool_token: spec.Address,
-    provider: spec.ProviderReference = None,
+async def async_get_ctoken_comptroller(
+    ctoken: spec.Address,
+    block: spec.BlockNumberReference = 'latest',
 ) -> spec.Address:
-    function_abi: spec.FunctionABI = {
-        'name': 'UNDERLYING_ASSET_ADDRESS',
-        'inputs': [],
-        'outputs': [{'type': 'address'}],
-    }
     result = await rpc.async_eth_call(
-        to_address=pool_token,
-        function_abi=function_abi,
-        provider=provider,
+        to_address=ctoken,
+        block_number=block,
+        function_abi=rari_abis.ctoken_function_abis['comptroller'],
     )
     if not isinstance(result, str):
         raise Exception('invalid rpc result')
     return result
 
 
-async def async_get_reserves_list(
-    *,
-    block: spec.BlockNumberReference | None = None,
-    provider: spec.ProviderReference = None,
-) -> typing.Sequence[spec.Address]:
-
-    network = rpc.get_provider_network(provider)
-    address = aave_spec.get_aave_address('LendingPool', network=network)
-
-    if block is not None:
-        block = evm.standardize_block_number(block)
-
-    reserves: typing.Sequence[spec.Address] = await rpc.async_eth_call(
-        to_address=address,
-        function_name='getReservesList',
-        provider=provider,
+async def async_get_ctoken_underlying(
+    ctoken: spec.Address,
+    block: spec.BlockNumberReference = 'latest',
+) -> spec.Address:
+    result = await rpc.async_eth_call(
+        to_address=ctoken,
         block_number=block,
+        function_abi=rari_abis.ctoken_function_abis['underlying'],
     )
+    if not isinstance(result, str):
+        raise Exception('invalid rpc result')
+    return result
+
 
-    return reserves
+async def async_get_ctoken_irm(
+    ctoken: spec.Address,
+    block: spec.BlockNumberReference = 'latest',
+) -> spec.Address:
+    result = await rpc.async_eth_call(
+        to_address=ctoken,
+        block_number=block,
+        function_abi=rari_abis.ctoken_function_abis['interestRateModel'],
+    )
+    if not isinstance(result, str):
+        raise Exception('invalid rpc result')
+    return result
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/aave_v2_utils/aave_rewards.py` & `checkthechain-0.3.4/src/ctc/protocols/aave_v2_utils/aave_rewards.py`

 * *Files 20% similar despite different names*

```diff
@@ -11,81 +11,81 @@
 from . import aave_spec
 
 
 async def async_get_unclaimed_rewards(
     wallet: spec.Address,
     *,
     block: spec.BlockNumberReference | None = None,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
 ) -> int:
     aave_incentives_controller = aave_spec.get_aave_address(
         'IncentivesController',
-        network=rpc.get_provider_network(provider),
+        context=context,
     )
 
     result = await rpc.async_eth_call(
         to_address=aave_incentives_controller,
         function_name='getUserUnclaimedRewards',
         function_parameters=[wallet],
         block_number=block,
-        provider=provider,
+        context=context,
     )
 
     if not isinstance(result, int):
         raise Exception('invalid rpc result')
 
     return result
 
 
 async def async_get_unclaimed_rewards_by_block(
     wallet: spec.Address,
     blocks: typing.Sequence[spec.BlockNumberReference],
     *,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
 ) -> typing.Sequence[int]:
     coroutines = [
         async_get_unclaimed_rewards(
             wallet=wallet,
             block=block,
-            provider=provider,
+            context=context,
         )
         for block in blocks
     ]
     return await asyncio.gather(*coroutines)
 
 
 async def async_compute_wallet_rewards(
     wallet: spec.Address,
     blocks: typing.Sequence[spec.BlockNumberReference],
     *,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     replace_symbol: bool = True,
 ) -> typing.Mapping[str, spec.NumpyArray]:
 
     import numpy as np
 
     # add reward token
     reward_token = '0x4da27a545c0c5b758a6ba100e3a049001de870f5'
     reward_token_unstaked = '0x7fc66500c84a76ad7e9c93437bfc5ac33e2ddae9'
 
     reward_unclaimed_coroutine = async_get_unclaimed_rewards_by_block(
         wallet=wallet,
         blocks=blocks,
-        provider=provider,
+        context=context,
     )
     reward_in_wallet_coroutine = evm.async_get_erc20_balance_by_block(
         wallet=wallet,
         token=reward_token,
         blocks=blocks,
-        provider=provider,
+        context=context,
     )
     reward_price_coroutine = aave_oracle.async_get_asset_price_by_block(
         asset=reward_token_unstaked,
         blocks=blocks,
-        provider=provider,
+        context=context,
     )
 
     (reward_unclaimed, reward_in_wallet, reward_price,) = await asyncio.gather(
         reward_unclaimed_coroutine,
         reward_in_wallet_coroutine,
         reward_price_coroutine,
     )
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/aave_v2_utils/aave_spec.py` & `checkthechain-0.3.4/src/ctc/protocols/aave_v2_utils/aave_spec.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,25 +1,29 @@
 from __future__ import annotations
 
 from ctc import spec
 
 
 def get_aave_address(
     name: str,
-    network: spec.NetworkReference | None = None,
+    context: spec.Context = None,
 ) -> spec.Address:
+    from ctc import config
+
+    network = config.get_context_chain_id(context)
     # TODO: move to directory
-    if network in ('mainnet', 1):
+    if network in ('ethereum', 1):
         if name == 'PriceOracle':
             return '0xa50ba011c48153de246e5192c8f9258a2ba79ca9'
         elif name == 'LendingPoolProvider':
             return '0xb53c1a33016b2dc2ff3653530bff1848a515c8c5'
         elif name == 'LendingPool':
             return '0x7d2768de32b0b80b7a3454c06bdac94a69ddc7a9'
         elif name == 'IncentivesController':
             return '0xd784927ff2f95ba542bfc824c8a8a98f3495f6b5'
         elif name == 'Collector':
             return '0x464C71f6c2F760DdA6093dCB91C24c39e5d6e18c'
         else:
             raise Exception('unknown contract: ' + str(name))
     else:
         raise Exception('invalid network: ' + str(network))
+
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/aave_v2_utils/aave_summaries.py` & `checkthechain-0.3.4/src/ctc/protocols/aave_v2_utils/aave_summaries.py`

 * *Files 16% similar despite different names*

```diff
@@ -2,50 +2,52 @@
 
 import asyncio
 import typing
 
 import toolstr
 import numpy as np
 
+from ctc import config
 from ctc import evm
 from ctc import spec
 from . import aave_spec
 from . import aave_interest_rates
 from . import aave_oracle
 
 
 async def async_print_aave_addresses(
     *,
     verbose: bool = False,
     block: spec.BlockNumberReference | None = None,
     max_width: int | None = None,
+    context: spec.Context = None,
 ) -> None:
 
     from ctc import cli
 
     indent = 4
 
     styles = cli.get_cli_styles()
 
     toolstr.print_text_box('Aave V2 Addresses', style=styles['title'])
 
-    network = 'mainnet'
+    network = config.get_context_chain_id(context)
     toolstr.print('network = ' + str(network), style=styles['comment'])
 
     # print general contracts
     contracts = [
         'PriceOracle',
         'LendingPoolProvider',
         'LendingPool',
         'IncentivesController',
         'Collector',
     ]
     rows = []
     for contract in contracts:
-        address = aave_spec.get_aave_address(contract, network=network)
+        address = aave_spec.get_aave_address(contract, context=context)
         row = [contract, address]
         rows.append(row)
     print()
     if max_width is not None:
         max_table_width = max_width - indent
     else:
         max_table_width = None
@@ -55,15 +57,15 @@
         border=styles['comment'],
         column_styles=[styles['option'], styles['metavar']],
         max_table_width=max_table_width,
     )
 
     # print token markets
     token_markets = await aave_interest_rates.async_get_token_markets(
-        block=block
+        block=block, context=context
     )
 
     print()
     print()
     toolstr.print_header('Token Markets', style=styles['title'])
     print()
     if verbose:
@@ -142,56 +144,60 @@
 
 
 async def async_print_token_markets_summary(
     *,
     verbose: bool = False,
     block: spec.BlockNumberReference | None = None,
     max_width: int | None = None,
+    context: spec.Context = None,
 ) -> None:
 
     from ctc import cli
 
     if block is None:
         block = 'latest'
 
     token_markets = await aave_interest_rates.async_get_token_markets(
-        block=block
+        block=block, context=context
     )
 
     total_supplies_coroutine = evm.async_get_erc20s_total_supplies(
         [
             token_market['reserve_data']['atoken_address']
             for token_market in token_markets
         ],
         block=block,
+        context=context,
     )
     total_supplies_task = asyncio.create_task(total_supplies_coroutine)
 
     coroutines = [
         aave_interest_rates.async_get_interest_rates(
             reserve_data=token_market['reserve_data'],
             block=block,
+            context=context,
         )
         for token_market in token_markets
     ]
     interest_rates_task = asyncio.gather(*coroutines)
 
     reserves_list = [
         token_market['underlying'] for token_market in token_markets
     ]
     prices_coroutine = aave_oracle.async_get_asset_prices(
-        reserves_list, block=block
+        reserves_list, block=block, context=context
     )
     prices_task = asyncio.create_task(prices_coroutine)
 
     reserve_balances_coroutines = [
         evm.async_get_erc20_balance(
             wallet=token_market['reserve_data']['atoken_address'],
             token=token_market['underlying'],
             block=block,
+            context=context,
         )
         for token_market in token_markets
     ]
     reserve_balances = await asyncio.gather(*reserve_balances_coroutines)
 
     interest_rates = await interest_rates_task
     prices = await prices_task
@@ -335,40 +341,39 @@
             'TVB': styles['description'],
             'util %': styles['description'],
             'price': styles['description'],
         },
         max_table_width=max_width,
     )
     print()
-    toolstr.print('network = mainnet', style=styles['comment'])
+    toolstr.print('network = ethereum', style=styles['comment'])
 
 
-async def async_print_token_market_summary(
+async def async_get_token_market_summary(
     token: str | spec.Address,
     *,
     blocks: typing.Sequence[int],
     verbose: bool = False,
-) -> None:
-
-    from ctc import cli
+    context: spec.Context = None,
+) -> typing.Mapping[str, typing.Any]:
 
     if not evm.is_address_str(token):
-        token_address = await evm.async_get_erc20_address(token)
+        token_address = await evm.async_get_erc20_address(
+            token, context=context
+        )
     else:
         token_address = token
 
-    timestamps_task = asyncio.create_task(
-        evm.async_get_block_timestamps(blocks)
-    )
-
     reserve_data_by_block = (
         await aave_interest_rates.async_get_reserve_data_by_block(
             asset=token_address,
             blocks=blocks,
-            provider={'chunk_size': 1},
+            context=config.update_context(
+                context, merge_provider={'chunk_size': 1}
+            ),
         )
     )
 
     atoken_address = reserve_data_by_block['atoken_address'][0]
 
     interest_rates_task = asyncio.create_task(
         aave_interest_rates.async_get_interest_rates_by_block(
@@ -379,51 +384,90 @@
     )
 
     # compute tvls
     total_supplies_task = asyncio.create_task(
         evm.async_get_erc20_total_supply_by_block(
             atoken_address,
             blocks=blocks,
+            context=context,
         )
     )
 
     # compute tvbs
     balances_task = asyncio.create_task(
         evm.async_get_erc20_balance_by_block(
             wallet=atoken_address,
             token=token,
             blocks=blocks,
+            context=context,
         )
     )
 
     total_supplies = await total_supplies_task
     total_supplies_array = np.array(total_supplies)
     prices_task = asyncio.create_task(
         aave_oracle.async_get_asset_price_by_block(
             token_address,
             blocks=blocks,
+            context=context,
         )
     )
 
     prices = await prices_task
     prices_array = np.array(prices)
     tvls = total_supplies_array * prices_array
 
     balances = await balances_task
     balances_array = np.array(balances)
     tvbs = (total_supplies_array - balances_array) * prices_array
 
     if verbose:
         utilization = tvbs / tvls
+    else:
+        utilization = None
 
     # compute interest rates
     interest_rates = await interest_rates_task
     supply_apy = np.array(interest_rates['supply_apy']) * 100
     borrow_apy = np.array(interest_rates['borrow_apy']) * 100
 
+    return {
+        'prices': prices_array,
+        'tvl': tvls,
+        'tvb': tvbs,
+        'supply_apy': supply_apy,
+        'borrow_apy': borrow_apy,
+        'utilization': utilization,
+    }
+
+
+async def async_print_token_market_summary(
+    token: str | spec.Address,
+    *,
+    blocks: typing.Sequence[int],
+    verbose: bool = False,
+    context: spec.Context = None,
+) -> None:
+
+    from ctc import cli
+
+    summary = await async_get_token_market_summary(
+        token=token, blocks=blocks, verbose=verbose, context=context
+    )
+    prices_array = summary['prices']
+    tvls = summary['tvl']
+    tvbs = summary['tvb']
+    supply_apy = summary['supply_apy']
+    borrow_apy = summary['borrow_apy']
+    utilization = summary['utilization']
+
+    timestamps_task = asyncio.create_task(
+        evm.async_get_block_timestamps(blocks, context=context)
+    )
+
     styles = cli.get_cli_styles()
     toolstr.print_text_box(
         'Summary of ' + token + ' on Aave v2', style=styles['title']
     )
 
     percentage_kwargs = {
         'yaxis_kwargs': {
@@ -446,23 +490,25 @@
         plots.append(('Price', prices_array, dollar_kwargs))
     timestamps = await timestamps_task
     for title, data, plot_kwargs in plots:
         print()
         plot = toolstr.render_line_plot(
             xvals=timestamps,
             yvals=data,
-            n_rows=40,
-            n_columns=120,
+            n_rows=10,
+            n_columns=60,
             line_style=styles['description'],
             chrome_style=styles['comment'],
             tick_label_style=styles['metavar'],
+            char_dict=config.get_cli_chart_charset(),
             **plot_kwargs,  # type: ignore
         )
         toolstr.print(
             toolstr.hjustify(title, 'center', 70),
             indent=4,
             style=styles['title'],
         )
         print()
         toolstr.print(plot, indent=4)
         print()
-        print()
+        print()
+
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/aave_v2_utils/cli/aave_addresses_command.py` & `checkthechain-0.3.4/src/ctc/protocols/aave_v2_utils/cli/aave_addresses_command.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/protocols/aave_v2_utils/cli/aave_command.py` & `checkthechain-0.3.4/src/ctc/protocols/aave_v2_utils/cli/aave_command.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/protocols/balancer_utils/balancer_spec.py` & `checkthechain-0.3.4/src/ctc/protocols/balancer_utils/balancer_spec.py`

 * *Files 3% similar despite different names*

```diff
@@ -60,15 +60,15 @@
             },
         ],
         'stateMutability': 'view',
         'type': 'function',
     },
 }
 
-vault_event_abis = {
+vault_event_abis: typing.Mapping[str, spec.EventABI] = {
     'PoolRegistered': {
         'anonymous': False,
         'inputs': [
             {
                 'indexed': True,
                 'internalType': 'bytes32',
                 'name': 'poolId',
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/balancer_utils/pool_metadata.py` & `checkthechain-0.3.4/src/ctc/protocols/balancer_utils/pool_metadata.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,10 +1,9 @@
 from __future__ import annotations
 
-import ast
 import typing
 
 from ctc import evm
 from ctc import rpc
 from ctc import spec
 
 from . import balancer_spec
@@ -13,15 +12,15 @@
     import tooltime
 
 
 async def async_get_pool_id(
     pool_address: spec.Address,
     block: spec.BlockNumberReference | None = None,
     *,
-    provider: spec.ProviderReference | None = None,
+    context: spec.Context = None,
 ) -> str:
 
     function_abi: spec.FunctionABI = {
         'inputs': [],
         'name': 'getPoolId',
         'outputs': [
             {
@@ -34,90 +33,93 @@
         'type': 'function',
     }
 
     result = await rpc.async_eth_call(
         to_address=pool_address,
         function_abi=function_abi,
         block_number=block,
-        provider=provider,
+        context=context,
     )
     if not isinstance(result, str):
         raise Exception('invalid rpc result')
     return result
 
 
 async def async_get_pool_address(
     pool_id: str,
     block: spec.BlockNumberReference | None = None,
+    *,
+    context: spec.Context = None,
 ) -> spec.Address:
 
     vault = balancer_spec.vault
 
     pool = await rpc.async_eth_call(
         to_address=vault,
         function_abi=balancer_spec.vault_function_abis['getPool'],
         function_parameters=[pool_id],
         block_number=block,
+        context=context,
     )
     address = pool[0]
     if not isinstance(address, str):
         raise Exception('invalid rpc result')
     return address
 
 
 async def async_get_pool_tokens(
     *,
     pool_address: spec.Address | None = None,
     pool_id: str | None = None,
     block: spec.BlockNumberReference | None = None,
+    context: spec.Context = None,
 ) -> list[spec.Address]:
 
     vault = balancer_spec.vault
     if pool_id is None:
         if pool_address is None:
             raise Exception('must specify pool_id or pool_address')
-        pool_id = await async_get_pool_id(pool_address)
+        pool_id = await async_get_pool_id(pool_address, context=context)
 
     pool_tokens = await rpc.async_eth_call(
         to_address=vault,
         function_abi=balancer_spec.vault_function_abis['getPoolTokens'],
         function_parameters=[pool_id],
         block_number=block,
         package_named_outputs=True,
+        context=context,
     )
     return list(pool_tokens['tokens'])
 
 
 async def async_get_token_registrations(
     factory: spec.Address,
     *,
     start_block: spec.BlockNumberReference | None = None,
     end_block: spec.BlockNumberReference | None = None,
     start_time: tooltime.Timestamp | None = None,
     end_time: tooltime.Timestamp | None = None,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
 ) -> typing.Mapping[str, typing.Sequence[str]]:
 
     balancer_token_registrations = await evm.async_get_events(
         factory,
         event_abi=balancer_spec.vault_event_abis['TokensRegistered'],
         verbose=False,
         start_block=start_block,
         end_block=end_block,
         start_time=start_time,
         end_time=end_time,
-        provider=provider,
+        context=context,
     )
-    balancer_token_registrations['arg__tokens'] = balancer_token_registrations[
-        'arg__tokens'
-    ].map(ast.literal_eval)
 
     token_registrations_by_pool: typing.MutableMapping[
         str, typing.MutableSequence[str]
     ] = {}
-    for index, row in balancer_token_registrations.iterrows():
+    for row in balancer_token_registrations.to_dicts():
         pool = row['arg__poolId']
 
         token_registrations_by_pool.setdefault(pool, [])
         token_registrations_by_pool[pool].extend(row['arg__tokens'])
 
     return token_registrations_by_pool
+
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/balancer_utils/pool_plots.py` & `checkthechain-0.3.4/src/ctc/protocols/balancer_utils/pool_plots.py`

 * *Files 16% similar despite different names*

```diff
@@ -4,121 +4,127 @@
 
 from ctc import evm
 from ctc import spec
 
 from . import pool_summary
 
 
-async def async_plot_lbp_summary(
-    *,
-    swaps: spec.DataFrame,
-    weights: spec.DataFrame,
-    pool_name: str,
-    pool_tokens: typing.Sequence[spec.Address],
-    pool_address: spec.Address,
-    price_range: typing.Sequence[int | float] | None = None,
-    premium_range: typing.Sequence[int | float] | None = None,
-    oracle_data: spec.DataFrame | None = None,
-) -> None:
-
-    summary = pool_summary.summarize_pool_swaps(swaps=swaps, weights=weights)
-
-    for pair in summary.keys():
-
-        blocks = summary[pair].index.get_level_values('block_number')
-
-        token_0, token_1 = await evm.async_get_erc20s_symbols(pool_tokens)
-        in_address, out_address = pair
-        if in_address == pool_tokens[0]:
-            in_token = token_0
-            out_token = token_1
-            in_weights = summary[pair]['weight_0']
-            out_weights = summary[pair]['weight_1']
-        else:
-            out_token = token_0
-            in_token = token_1
-            out_weights = summary[pair]['weight_0']
-            in_weights = summary[pair]['weight_1']
-
-        title = pool_name + ', in=' + in_token + ', out=' + out_token
-
-        if oracle_data is not None:
-            min_block = swaps.index[0][0]
-            max_block = swaps.index[-1][0]
-            oracle_mask = (oracle_data.index >= min_block) & (
-                oracle_data.index <= max_block
-            )
-            oracle_data = oracle_data[oracle_mask]
-            if oracle_data is None:
-                raise Exception('invalid oracle_data')
-            ys = [
-                {
-                    'y': oracle_data.values,
-                    'x': oracle_data.index.values,
-                    'y_kwargs': {'label': 'oracle'},
-                },
-            ]
-
-            if oracle_data is None:
-                raise Exception('invalid oracle_data')
-            premium = []
-            for index, row in summary[pair].iterrows():
-                block_number = index[0]  # type: ignore
-                oracle_price = oracle_data[block_number]
-                actual_price = row['price_out_per_in']
-                premium.append(float(actual_price) / oracle_price - 1)
-        else:
-            ys = None
-            premium = []
-
-        y_kwargs = {'marker': '.', 'markersize': 10, 'linewidth': 1}
-        plot_data = {
-            'subplot_height': 5,
-            'common': {
-                'x': blocks,
-                'name_position': 'ylabel',
-                'tickgrid': True,
-                'y_kwargs': y_kwargs,
-            },
-            'plots': {
-                'price': {
-                    'title': title,
-                    'name': 'price\n(' + out_token + ' / ' + in_token + ')',
-                    'y': summary[pair]['price_out_per_in'],
-                    'y_kwargs': dict(label='actual', **y_kwargs),
-                    'ys': ys,
-                    'ylim': price_range,
-                    # 'legend_kwargs': {'loc': 'lower left'},
-                },
-                'premium': {
-                    'name': 'price premium',
-                    'y': premium,
-                    'ylim': premium_range,
-                },
-                'weight': {
-                    'name': out_token + ' Weights',
-                    'y': out_weights,
-                },
-                'token0 Sold': {
-                    'name': in_token + ' Amount',
-                    'y': summary[pair]['in_amounts'],
-                },
-                'Cummulative token0 Bought': {
-                    'name': 'Cummulative\n' + in_token + ' Bought',
-                    'y': summary[pair]['cummulative_in_amount'],
-                },
-                'Cummulative token1 Sold': {
-                    'name': 'Cummulative\n' + out_token + 'Sold',
-                    'y': summary[pair]['cummulative_out_amount'],
-                },
-                'Volume Weighted Price': {
-                    'name': 'Cummulative\nVolume Weighted\nPrice',
-                    'y': summary[pair]['cummulative_price_out_per_in'],
-                    'xlabel': 'block',
-                    'ylim': price_range,
-                },
-            },
-        }
+# async def async_plot_lbp_summary(
+#     *,
+#     swaps: spec.DataFrame,
+#     weights: spec.DataFrame,
+#     pool_name: str,
+#     pool_tokens: typing.Sequence[spec.Address],
+#     pool_address: spec.Address,
+#     price_range: typing.Sequence[int | float] | None = None,
+#     premium_range: typing.Sequence[int | float] | None = None,
+#     oracle_data: spec.DataFrame | None = None,
+#     context: spec.Context = None,
+# ) -> None:
+
+#     import polars as pl
+
+#     summary = pool_summary.summarize_pool_swaps(swaps=swaps, weights=weights)
+
+#     for pair in summary.keys():
+
+#         blocks = summary[pair]['block_number'].to_list()
+
+#         token_0, token_1 = await evm.async_get_erc20s_symbols(
+#             pool_tokens, context=context
+#         )
+#         in_address, out_address = pair
+#         if in_address == pool_tokens[0]:
+#             in_token = token_0
+#             out_token = token_1
+#             out_weights = summary[pair]['weight_1']
+#             # in_weights = summary[pair]['weight_0']
+#         else:
+#             out_token = token_0
+#             in_token = token_1
+#             out_weights = summary[pair]['weight_0']
+#             # in_weights = summary[pair]['weight_1']
+
+#         title = pool_name + ', in=' + in_token + ', out=' + out_token
+
+#         if oracle_data is not None:
+#             min_block = swaps['block_number'][0]
+#             max_block = swaps['block_number'][-1]
+#             oracle_data = oracle_data.filter(
+#                 (pl.col('block_number') >= min_block)
+#                 & (pl.col('block_number') <= max_block)
+#             )
+#             if oracle_data is None:
+#                 raise Exception('invalid oracle_data')
+#             ys = [
+#                 {
+#                     'y': oracle_data.values,
+#                     'x': oracle_data['block_number'].to_list(),
+#                     'y_kwargs': {'label': 'oracle'},
+#                 },
+#             ]
+
+#             if oracle_data is None:
+#                 raise Exception('invalid oracle_data')
+#             premium = []
+#             for index, row in summary[pair].iterrows():
+#                 block_number = index[0]
+#                 oracle_price = oracle_data[block_number]
+#                 actual_price = row['price_out_per_in']
+#                 premium.append(float(actual_price) / oracle_price - 1)
+#         else:
+#             ys = None
+#             premium = []
+
+#         y_kwargs = {'marker': '.', 'markersize': 10, 'linewidth': 1}
+#         plot_data = {
+#             'subplot_height': 5,
+#             'common': {
+#                 'x': blocks,
+#                 'name_position': 'ylabel',
+#                 'tickgrid': True,
+#                 'y_kwargs': y_kwargs,
+#             },
+#             'plots': {
+#                 'price': {
+#                     'title': title,
+#                     'name': 'price\n(' + out_token + ' / ' + in_token + ')',
+#                     'y': summary[pair]['price_out_per_in'],
+#                     'y_kwargs': dict(label='actual', **y_kwargs),
+#                     'ys': ys,
+#                     'ylim': price_range,
+#                     # 'legend_kwargs': {'loc': 'lower left'},
+#                 },
+#                 'premium': {
+#                     'name': 'price premium',
+#                     'y': premium,
+#                     'ylim': premium_range,
+#                 },
+#                 'weight': {
+#                     'name': out_token + ' Weights',
+#                     'y': out_weights,
+#                 },
+#                 'token0 Sold': {
+#                     'name': in_token + ' Amount',
+#                     'y': summary[pair]['in_amounts'],
+#                 },
+#                 'Cummulative token0 Bought': {
+#                     'name': 'Cummulative\n' + in_token + ' Bought',
+#                     'y': summary[pair]['cummulative_in_amount'],
+#                 },
+#                 'Cummulative token1 Sold': {
+#                     'name': 'Cummulative\n' + out_token + 'Sold',
+#                     'y': summary[pair]['cummulative_out_amount'],
+#                 },
+#                 'Volume Weighted Price': {
+#                     'name': 'Cummulative\nVolume Weighted\nPrice',
+#                     'y': summary[pair]['cummulative_price_out_per_in'],
+#                     'xlabel': 'block',
+#                     'ylim': price_range,
+#                 },
+#             },
+#         }
 
-        import toolplot  # type: ignore
+#         import toolplot  # type: ignore
+
+#         toolplot.plot_subplots(plot_data)
 
-        toolplot.plot_subplots(plot_data)
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/balancer_utils/pool_state.py` & `checkthechain-0.3.4/src/ctc/protocols/balancer_utils/pool_state.py`

 * *Files 20% similar despite different names*

```diff
@@ -46,20 +46,23 @@
 # # weights
 #
 
 
 async def async_get_pool_weights_raw(
     pool_address: spec.ContractAddress,
     block: spec.BlockNumberReference = 'latest',
+    *,
+    context: spec.Context = None,
 ) -> typing.Union[typing.Sequence[int], typing.Sequence[float]]:
 
     result = await rpc.async_eth_call(
         to_address=pool_address,
         function_abi=pool_function_abis['getNormalizedWeights'],
         block_number=block,
+        context=context,
     )
     if not isinstance(result, (tuple, list)) or not all(
         isinstance(item, (int, float)) for item in result
     ):
         raise Exception('invalid rpc result')
     return typing.cast(
         typing.Union[typing.Sequence[int], typing.Sequence[float]], result
@@ -67,25 +70,26 @@
 
 
 async def async_get_pool_weights(
     pool_address: spec.ContractAddress,
     block: spec.BlockNumberReference = 'latest',
     *,
     normalize: bool = True,
+    context: spec.Context = None,
 ) -> typing.Union[
     dict[spec.ContractAddress, int],
     dict[spec.ContractAddress, float],
 ]:
     import asyncio
 
     tokens_coroutine = pool_metadata.async_get_pool_tokens(
-        pool_address=pool_address, block=block
+        pool_address=pool_address, block=block, context=context
     )
     weights_coroutine = async_get_pool_weights_raw(
-        pool_address=pool_address, block=block
+        pool_address=pool_address, block=block, context=context
     )
 
     tokens, weights = await asyncio.gather(tokens_coroutine, weights_coroutine)
 
     if normalize:
         weights = [weight / 1e18 for weight in weights]
 
@@ -93,24 +97,28 @@
 
 
 async def async_get_pool_weights_by_block(
     pool_address: spec.ContractAddress,
     blocks: typing.Sequence[spec.BlockNumberReference],
     *,
     normalize: bool = True,
+    context: spec.Context = None,
 ) -> typing.Union[
     dict[spec.BlockNumberReference, int],
     dict[spec.BlockNumberReference, float],
 ]:
+    from ctc import config
+
+    context = config.update_context(context, merge_provider={'chunk_size': 100})
 
     weights = await rpc.async_batch_eth_call(
         to_address=pool_address,
         function_abi=pool_function_abis['getNormalizedWeights'],
         block_numbers=blocks,
-        provider={'chunk_size': 100},
+        context=context,
     )
 
     if normalize:
         weights = [
             [block_weight / 1e18 for block_weight in block_weights]
             for block_weights in weights
         ]
@@ -124,20 +132,22 @@
 
 
 async def async_get_pool_fees(
     pool_address: spec.ContractAddress,
     *,
     block: spec.BlockNumberReference = 'latest',
     normalize: bool = True,
+    context: spec.Context = None,
 ) -> typing.Union[int, float]:
 
     fees = await rpc.async_eth_call(
         to_address=pool_address,
         function_abi=pool_function_abis['getSwapFeePercentage'],
         block_number=block,
+        context=context,
     )
 
     if not isinstance(fees, int):
         raise Exception('invalid rpc result')
     fees_result: int | float = fees
 
     if normalize:
@@ -154,72 +164,74 @@
 async def async_get_pool_balances(
     *,
     pool_address: typing.Optional[spec.ContractAddress] = None,
     pool_id: typing.Optional[spec.HexData] = None,
     block: spec.BlockNumberReference | None = None,
     vault: typing.Optional[spec.ContractAddress] = None,
     normalize: bool = True,
-    provider: spec.ProviderReference | None = None,
+    context: spec.Context = None,
 ) -> typing.Union[dict[spec.Address, int], dict[spec.Address, float]]:
 
     if block is None:
         block = 'latest'
 
     if vault is None:
         vault = balancer_spec.vault
     if pool_id is None:
         if pool_address is None:
             raise Exception('must specify pool_id or pool_address')
         pool_id = await pool_metadata.async_get_pool_id(
             pool_address,
             block=block,
-            provider=provider,
+            context=context,
         )
 
     pool_tokens = await rpc.async_eth_call(
         to_address=vault,
         function_abi=balancer_spec.vault_function_abis['getPoolTokens'],
         function_parameters=[pool_id],
         block_number=block,
         package_named_outputs=True,
-        provider=provider,
+        context=context,
     )
 
     pool_balances = dict(zip(pool_tokens['tokens'], pool_tokens['balances']))
 
     if normalize:
         tokens = pool_balances.keys()
         decimals = await evm.async_get_erc20s_decimals(
             tokens=tokens,
             block=block,
-            provider=provider,
+            context=context,
         )
         for token, decimal in zip(tokens, decimals):
             pool_balances[token] /= 10**decimal
 
     return pool_balances
 
 
 async def async_get_pool_balances_by_block(
     *,
     blocks: typing.Sequence[spec.BlockNumberReference],
     pool_address: typing.Optional[spec.ContractAddress] = None,
     pool_id: typing.Optional[spec.HexData] = None,
     vault: typing.Optional[spec.ContractAddress] = None,
     normalize: bool = True,
+    context: spec.Context = None,
 ) -> typing.Union[dict[spec.Address, list[int | float]]]:
     import asyncio
 
     coroutines = [
         async_get_pool_balances(
             pool_address=pool_address,
             pool_id=pool_id,
             block=block,
             vault=vault,
             normalize=normalize,
+            context=context,
         )
         for block in blocks
     ]
 
     balances_by_block = await asyncio.gather(*coroutines)
 
     return nested_utils.list_of_dicts_to_dict_of_lists(balances_by_block)
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/balancer_utils/pool_summary.py` & `checkthechain-0.3.4/src/ctc/protocols/balancer_utils/pool_summary.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,60 +1,66 @@
 from __future__ import annotations
 
 import decimal
 import typing
-from typing_extensions import TypedDict
 
 from ctc import evm
 from ctc import spec
 
 from . import balancer_spec
 from . import pool_metadata
 from . import pool_state
 
 if typing.TYPE_CHECKING:
+    from typing_extensions import TypedDict
+
     import tooltime
 
 
-class BalancerPoolState(TypedDict):
-    block: int
-    pool_tokens: typing.Sequence[spec.Address]
-    pool_fees: typing.Union[int, float]
-    pool_weights: typing.Union[
-        dict[spec.ContractAddress, int],
-        dict[spec.ContractAddress, float],
-    ]
-    pool_balances: typing.Union[
-        dict[spec.Address, int],
-        dict[spec.Address, float],
-    ]
+    class BalancerPoolState(TypedDict):
+        block: int
+        pool_tokens: typing.Sequence[spec.Address]
+        pool_fees: typing.Union[int, float]
+        pool_weights: typing.Union[
+            dict[spec.ContractAddress, int],
+            dict[spec.ContractAddress, float],
+        ]
+        pool_balances: typing.Union[
+            dict[spec.Address, int],
+            dict[spec.Address, float],
+        ]
 
 
 async def async_summarize_pool_state(
     pool_address: spec.Address,
     block: spec.BlockNumberReference = 'latest',
+    *,
+    context: spec.Context = None,
 ) -> BalancerPoolState:
-
-    block = await evm.async_block_number_to_int(block)
+    block = await evm.async_block_number_to_int(block, context=context)
 
     pool_tokens_coroutine = await pool_metadata.async_get_pool_tokens(
         pool_address=pool_address,
         block=block,
+        context=context,
     )
     pool_fees_coroutine = await pool_state.async_get_pool_fees(
         pool_address=pool_address,
         block=block,
+        context=context,
     )
     pool_weights_coroutine = await pool_state.async_get_pool_weights(
         pool_address=pool_address,
         block=block,
+        context=context,
     )
     pool_balances_coroutine = await pool_state.async_get_pool_balances(
         pool_address=pool_address,
         block=block,
+        context=context,
     )
 
     return {
         'pool_tokens': pool_tokens_coroutine,
         'pool_fees': pool_fees_coroutine,
         'pool_weights': pool_weights_coroutine,
         'pool_balances': pool_balances_coroutine,
@@ -66,15 +72,17 @@
     pool_address: typing.Optional[spec.Address] = None,
     *,
     start_block: typing.Optional[spec.BlockNumberReference] = None,
     end_block: typing.Optional[spec.BlockNumberReference] = None,
     start_time: tooltime.Timestamp | None = None,
     end_time: tooltime.Timestamp | None = None,
     include_timestamps: bool = False,
+    context: spec.Context = None,
 ) -> spec.DataFrame:
+    import polars as pl
 
     event_abi: spec.EventABI = {
         'anonymous': False,
         'inputs': [
             {
                 'indexed': True,
                 'internalType': 'bytes32',
@@ -114,50 +122,55 @@
 
     start_block, end_block = await evm.async_resolve_block_range(
         start_block=start_block,
         end_block=end_block,
         start_time=start_time,
         end_time=end_time,
         allow_none=True,
+        context=context,
     )
 
     if start_block is None:
-        start_block = await evm.async_get_contract_creation_block(vault)
+        start_block = await evm.async_get_contract_creation_block(
+            vault, context=context
+        )
 
     swaps = await evm.async_get_events(
         contract_address=vault,
         event_abi=event_abi,
         start_block=start_block,
         end_block=end_block,
         include_timestamps=include_timestamps,
         verbose=False,
+        context=context,
     )
 
     if pool_address is not None:
-        swaps = swaps[swaps['arg__poolId'].str.startswith(pool_address)]
+        swaps = swaps.filter(
+            pl.col('arg__poolId').str.starts_with(pool_address)
+        )
 
     return swaps
 
 
 def summarize_pool_swaps(
     swaps: spec.DataFrame,
     weights: spec.DataFrame,
     *,
     as_dataframe: bool = True,
 ) -> typing.Mapping[tuple[str, str], spec.DataFrame]:
-
     import numpy as np
+    import polars as pl
 
     trade_pairs = set()
-    for i, row in swaps[['arg__tokenIn', 'arg__tokenOut']].iterrows():
-        trade_pairs.add(tuple(row.values))
+    for row in swaps[['arg__tokenIn', 'arg__tokenOut']].rows():
+        trade_pairs.add(tuple(row))
 
-    pair_data = {}
+    pair_data: typing.MutableMapping[tuple[str, str], spec.DataFrame] = {}
     for token_in, token_out in trade_pairs:
-
         mask = (swaps['arg__tokenIn'] == token_in) & (
             swaps['arg__tokenOut'] == token_out
         )
         pair_swaps = swaps[mask]
         pair_weights = weights[mask.values]
         in_amounts = pair_swaps['arg__amountIn'].map(
             decimal.Decimal
@@ -186,15 +199,11 @@
             'cummulative_price_in_per_out': cummulative_price_in_per_out,
             'cummulative_price_out_per_in': cummulative_price_out_per_in,
         }
 
         for c, weight_column in enumerate(pair_weights.columns):
             data['weight_' + str(c)] = pair_weights[weight_column].values
 
-        if as_dataframe:
-            import pandas as pd
-
-            df = pd.DataFrame(data)
-
-        pair_data[(token_in, token_out)] = df
+        pair_data[(token_in, token_out)] = pl.DataFrame(data)
 
     return pair_data
+
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/balancer_utils/pool_trades.py` & `checkthechain-0.3.4/src/ctc/protocols/balancer_utils/pool_trades.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/protocols/chainlink_utils/chainlink_data/feed_composites.py` & `checkthechain-0.3.4/src/ctc/protocols/chainlink_utils/chainlink_data/feed_composites.py`

 * *Files 13% similar despite different names*

```diff
@@ -16,59 +16,61 @@
     composite_feed: typing.Sequence[chainlink_spec._FeedReference],
     *,
     start_block: typing.Optional[spec.BlockNumberReference] = None,
     end_block: typing.Optional[spec.BlockNumberReference] = None,
     start_time: tooltime.Timestamp | None = None,
     end_time: tooltime.Timestamp | None = None,
     invert: bool = False,
-    provider: spec.ProviderReference = None,
-) -> spec.Series:
+    context: spec.Context = None,
+) -> spec.DataFrame:
     # TODO: other ways of specifying composites
     import asyncio
+    import polars as pl
 
     start_block, end_block = await evm.async_resolve_block_range(
         start_block=start_block,
         end_block=end_block,
         start_time=start_time,
         end_time=end_time,
         allow_none=True,
-        provider=provider,
+        context=context,
     )
 
     # queue requests
     coroutines = []
     for feed in composite_feed:
         coroutine = feed_data.async_get_feed_data(
             feed,
             start_block=start_block,
             end_block=end_block,
             normalize=False,
             invert=False,
             interpolate=True,
             fields='answer',
+            context=context,
         )
         coroutines.append(coroutine)
 
-    datas: typing.Sequence[spec.Series] = await asyncio.gather(*coroutines)
+    datas: typing.Sequence[spec.DataFrame] = await asyncio.gather(*coroutines)
 
     # compute product
     product = datas[0] * datas[1]
     for data in datas[2:]:
         product = product * data
 
     # normalize
     feeds_decimals_coroutines = [
         chainlink_feed_metadata.async_get_feed_decimals(
             feed=feed,
-            provider=provider,
+            context=context,
         )
         for feed in composite_feed
     ]
     feeds_decimals = await asyncio.gather(*feeds_decimals_coroutines)
     composite_decimals = sum(feeds_decimals)
     product = product / (10 ** composite_decimals)
 
     # invert
     if invert:
-        product = 1 / product
+        product = product.with_columns(1 / pl.col('answer'))
 
     return product
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/chainlink_utils/chainlink_data/feed_datum.py` & `checkthechain-0.3.4/src/ctc/protocols/chainlink_utils/chainlink_data/feed_datum.py`

 * *Files 8% similar despite different names*

```diff
@@ -14,104 +14,110 @@
 async def async_get_feed_datum(
     feed: chainlink_spec._FeedReference,
     *,
     fields: typing.Literal['full'],
     normalize: bool = True,
     invert: bool = False,
     block: typing.Optional[spec.BlockNumberReference] = None,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
 ) -> chainlink_spec.FeedRoundData:
     ...
 
 
 @typing.overload
 async def async_get_feed_datum(
     feed: chainlink_spec._FeedReference,
     *,
     fields: typing.Literal['answer'] = 'answer',
     normalize: bool = True,
     invert: bool = False,
     block: typing.Optional[spec.BlockNumberReference] = None,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
 ) -> typing.Union[int, float]:
     ...
 
 
 async def async_get_feed_datum(
     feed: chainlink_spec._FeedReference,
     *,
     fields: typing.Literal['answer', 'full'] = 'answer',
     normalize: bool = True,
     invert: bool = False,
     block: typing.Optional[spec.BlockNumberReference] = None,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
 ) -> typing.Union[int, float, chainlink_spec.FeedRoundData]:
     """get feed data for a single block"""
 
     if block is None:
         block = 'latest'
 
-    feed = await chainlink_feed_metadata.async_resolve_feed_address(feed)
+    feed = await chainlink_feed_metadata.async_resolve_feed_address(
+        feed, context=context
+    )
 
     if fields == 'answer':
 
         result = await rpc.async_eth_call(
             to_address=feed,
             function_abi=chainlink_spec.feed_function_abis['latestAnswer'],
             block_number=block,
-            provider=provider,
             fill_empty=True,
             empty_token=None,
+            context=context,
         )
 
         if not isinstance(result, (int, float)):
             raise Exception('invalid rpc result')
         answer = result
 
         if normalize:
             decimals = await chainlink_feed_metadata.async_get_feed_decimals(
-                feed
+                feed,
+                context=context,
             )
-            answer /= 10 ** decimals
+            answer /= 10**decimals
 
         if invert:
             answer = 1 / answer
 
         return answer
 
     elif fields == 'full':
 
         data = await rpc.async_eth_call(
             to_address=feed,
             function_abi=chainlink_spec.feed_function_abis['latestRoundData'],
             block_number=block,
-            provider=provider,
             fill_empty=True,
             empty_token=None,
+            context=context,
         )
 
         round_id, answer, _started_at, updated_at, _answered_in_round_id = data
 
         full: chainlink_spec.FeedRoundData = {
             'answer': answer,
             'timestamp': updated_at,
             'round_id': round_id,
         }
 
         if answer is not None:
             if normalize:
                 decimals = (
-                    await chainlink_feed_metadata.async_get_feed_decimals(feed)
+                    await chainlink_feed_metadata.async_get_feed_decimals(
+                        feed, context=context
+                    )
                 )
-                full['answer'] /= 10 ** decimals
+                full['answer'] /= 10**decimals
 
             if invert:
                 full['answer'] = 1 / full['answer']
 
             return full
 
         else:
 
             return full
 
     else:
         raise Exception('unknown fields type: ' + str(fields))
+
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/chainlink_utils/chainlink_data/feed_datum_by_block.py` & `checkthechain-0.3.4/src/ctc/protocols/chainlink_utils/chainlink_data/feed_datum_by_block.py`

 * *Files 19% similar despite different names*

```diff
@@ -9,79 +9,84 @@
 from . import feed_datum
 
 
 async def async_get_feed_answer_datum_by_block(
     feed: chainlink_spec._FeedReference,
     blocks: typing.Sequence[spec.BlockNumberReference],
     *,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     normalize: bool = True,
     interpolate: bool = True,
     invert: bool = False,
-) -> spec.Series:
+) -> spec.DataFrame:
     import asyncio
-    import pandas as pd
-    from ctc.toolbox import pd_utils
+    from ctc.toolbox import pl_utils
+    import polars as pl
 
-    int_blocks = await evm.async_block_numbers_to_int(blocks=blocks)
+    int_blocks = await evm.async_block_numbers_to_int(
+        blocks=blocks, context=context
+    )
 
     # query data
     coroutines = []
     for block in int_blocks:
         coroutine = feed_datum.async_get_feed_datum(
             feed=feed,
             fields='answer',
             normalize=normalize,
             block=block,
-            provider=provider,
             invert=invert,
+            context=context,
         )
         coroutines.append(coroutine)
     result = await asyncio.gather(*coroutines)
 
     # create series
-    series = pd.Series(data=result, index=int_blocks)
+    df = pl.DataFrame({'block_number': int_blocks, 'answer': result})
 
     # interpolate blocks
     if interpolate:
-        series = pd_utils.interpolate_series(series=series)
+        df = pl_utils.interpolate(df, index_column='block_number')
 
-    return series
+    return df
 
 
 async def async_get_feed_full_datum_by_block(
     feed: chainlink_spec._FeedReference,
     blocks: typing.Sequence[spec.BlockNumberReference],
     *,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     normalize: bool = True,
     interpolate: bool = True,
     invert: bool = False,
 ) -> spec.DataFrame:
     import asyncio
-    import pandas as pd
-    from ctc.toolbox import pd_utils
+    import polars as pl
+    from ctc.toolbox import pl_utils
 
-    int_blocks = await evm.async_block_numbers_to_int(blocks=blocks)
+    int_blocks = await evm.async_block_numbers_to_int(
+        blocks=blocks, context=context
+    )
 
     # query data
     coroutines = []
     for block in int_blocks:
         coroutine = feed_datum.async_get_feed_datum(
             feed=feed,
             block=block,
-            provider=provider,
             normalize=normalize,
             fields='full',
             invert=invert,
+            context=context,
         )
         coroutines.append(coroutine)
     result = await asyncio.gather(*coroutines)
 
     # create series
-    df = pd.DataFrame(result, index=int_blocks)
+    df = pl.DataFrame({'block_number': int_blocks, 'answer': result})
 
     # interpolate blocks
     if interpolate:
-        df = pd_utils.interpolate_dataframe(df=df)
+        df = pl_utils.interpolate(df, index_column='block_number')
 
     return df
+
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/chainlink_utils/chainlink_data/feed_events.py` & `checkthechain-0.3.4/src/ctc/protocols/chainlink_utils/chainlink_data/feed_events.py`

 * *Files 15% similar despite different names*

```diff
@@ -9,81 +9,86 @@
 from .. import chainlink_aggregators
 from .. import chainlink_feed_metadata
 from .. import chainlink_spec
 from . import feed_datum
 
 if typing.TYPE_CHECKING:
     import tooltime
+    import polars as pl
 
 
 async def async_get_full_feed_event_data(
     feed: chainlink_spec._FeedReference,
     *,
     start_block: typing.Optional[spec.BlockNumberReference] = None,
     end_block: typing.Optional[spec.BlockNumberReference] = None,
     start_time: tooltime.Timestamp | None = None,
     end_time: tooltime.Timestamp | None = None,
     normalize: bool = True,
     interpolate: bool = False,
-    provider: spec.ProviderReference = None,
-    keep_multiindex: bool = False,
+    context: spec.Context = None,
     invert: bool = False,
 ) -> spec.DataFrame:
     """
     TODO: be able to gather data across multiple aggregator changes
     """
-    import pandas as pd
-    from ctc.toolbox import pd_utils
+
+    from ctc.toolbox import pl_utils
+    import polars as pl
 
     # get feed address
     feed = await chainlink_feed_metadata.async_resolve_feed_address(
-        feed, provider=provider
+        feed, context=context
     )
 
     # get aggregator
     start_block, end_block = await evm.async_resolve_block_range(
         start_block=start_block,
         end_block=end_block,
         start_time=start_time,
         end_time=end_time,
         allow_none=True,
-        provider=provider,
+        context=context,
     )
     if start_block is None:
         start_block = await chainlink_feed_metadata.async_get_feed_first_block(
             feed=feed,
-            provider=provider,
+            context=context,
         )
     if end_block is None:
-        end_block = await evm.async_get_latest_block_number()
+        end_block = await evm.async_get_latest_block_number(context=context)
     aggregator_address = (
         await chainlink_feed_metadata.async_get_feed_aggregator(
             feed=feed,
             block=end_block,
-            provider=provider,
+            context=context,
         )
     )
 
     # check if dealing with multiple aggregators
     initial_aggregator_address = (
         await chainlink_feed_metadata.async_get_feed_aggregator(
             feed=feed,
             block=start_block,
-            provider=provider,
+            context=context,
         )
     )
     if aggregator_address != initial_aggregator_address:
         history = await chainlink_aggregators.async_get_feed_aggregator_history(
             feed=feed,
-            provider=provider,
+            context=context,
         )
         aggregator_starts = list(history.values())
         aggregator_ends = [block - 1 for block in aggregator_starts[1:]]
-        start_block = await evm.async_block_number_to_int(start_block)
-        end_block = await evm.async_block_number_to_int(end_block)
+        start_block = await evm.async_block_number_to_int(
+            start_block, context=context
+        )
+        end_block = await evm.async_block_number_to_int(
+            end_block, context=context
+        )
         aggregator_ends.append(end_block)
         coroutines = []
         for aggregator, aggregator_start, aggregator_end in zip(
             history.keys(), aggregator_starts, aggregator_ends
         ):
             if aggregator_start < start_block:
                 use_start = start_block
@@ -100,108 +105,134 @@
 
             coroutine = evm.async_get_events(
                 contract_address=aggregator,
                 event_abi=chainlink_spec.aggregator_event_abis['AnswerUpdated'],
                 start_block=use_start,
                 end_block=use_end,
                 verbose=False,
+                context=context,
+                integer_output_format={'updatedAt': int},
             )
             coroutines.append(coroutine)
         results = await asyncio.gather(*coroutines)
-        df: spec.DataFrame = pd.concat(results)
+
+        # currently need this check as empty results do not have arg columns
+        non_empty_results = [result for result in results if len(result) > 0]
+        if len(non_empty_results) == 0:
+            df: spec.DataFrame = results[0]
+        else:
+            df = pl_utils.concat(non_empty_results)
 
     else:
+
         df = await evm.async_get_events(
             contract_address=aggregator_address,
             event_abi=chainlink_spec.aggregator_event_abis['AnswerUpdated'],
             start_block=start_block,
             end_block=end_block,
             verbose=False,
+            context=context,
+            integer_output_format={'updatedAt': pl.Int64},
         )
 
     # rename columns
     new_columns = {
         'arg__current': 'answer',
         'arg__updatedAt': 'timestamp',
         'arg__roundId': 'round_id',
     }
-    df = df.rename(columns=new_columns)
-    df = df[['answer', 'timestamp', 'round_id']]
+    df = df.rename(new_columns)
+    df = df[['block_number', 'answer', 'timestamp', 'round_id']]
 
     # normalize
     if normalize:
+        import numpy as np
+
         decimals = await chainlink_feed_metadata.async_get_feed_decimals(
-            feed=feed, provider=provider
+            feed=feed, context=context
+        )
+        df = df.with_columns(
+            pl.Series(
+                'answer',
+                np.array(df['answer'].to_list(), dtype=float) / (10**decimals),
+            )
         )
-        df['answer'] /= 10**decimals
 
     # interpolate
     if interpolate:
 
-        if keep_multiindex:
-            raise Exception('cannot use keep_multiindex and interpolate')
-        df.index = pd_utils.keep_level(df.index, level='block_number')
-
         # TODO: better detection of initial feed data point
         first_feed_block = (
-            await chainlink_feed_metadata.async_get_feed_first_block(feed)
+            await chainlink_feed_metadata.async_get_feed_first_block(
+                feed, context=context
+            )
         )
         if start_block == first_feed_block:
             pass
         else:
 
             # add initial data
-            if start_block < df.index.values[0]:
-                import pandas as pd
-
+            if len(df) == 0 or start_block < df['block_number'][0]:
                 initial_data = await feed_datum.async_get_feed_datum(
                     feed=feed,
                     block=start_block,
-                    provider=provider,
                     normalize=normalize,
                     fields='full',
+                    context=context,
                 )
-                initial_df = pd.DataFrame(initial_data, index=[start_block])
-                df = pd.concat([initial_df, df])
+                schema = {
+                    'block_number': pl.Int64,
+                    'timestamp': pl.Int64,
+                    'round_id': pl.Object,
+                }
+                if normalize:
+                    schema['answer'] = pl.Float64
+                else:
+                    schema['answer'] = pl.Decimal
+                initial_data['block_number'] = start_block
+                initial_df = pl.DataFrame(initial_data, schema=schema)
+                df = pl_utils.concat([initial_df, df])
 
         end_block = await evm.async_block_number_to_int(
-            end_block, provider=provider
+            end_block, context=context
+        )
+        df = pl_utils.interpolate(
+            df, index_column='block_number', end_index=end_block
         )
-        df = pd_utils.interpolate_dataframe(df, end_index=end_block)
-
-    elif not keep_multiindex:
-        df.index = pd_utils.keep_level(df.index, level='block_number')
 
     if invert:
-        df['answer'] = 1 / df['answer']
+        df = df.with_columns(1 / df['answer'])
 
     return df
 
 
 async def async_get_answer_feed_event_data(
     feed: chainlink_spec._FeedReference,
     *,
     start_block: typing.Optional[spec.BlockNumberReference] = None,
     end_block: typing.Optional[spec.BlockNumberReference] = None,
     start_time: tooltime.Timestamp | None = None,
     end_time: tooltime.Timestamp | None = None,
     normalize: bool = True,
     interpolate: bool = False,
-    provider: spec.ProviderReference = None,
-    keep_multiindex: bool = False,
     invert: bool = False,
-) -> spec.Series:
+    context: spec.Context = None,
+) -> spec.DataFrame:
+
+    from ctc.toolbox import pl_utils
 
     df = await async_get_full_feed_event_data(
         feed=feed,
         start_block=start_block,
         end_block=end_block,
         start_time=start_time,
         end_time=end_time,
         normalize=normalize,
         interpolate=interpolate,
-        provider=provider,
-        keep_multiindex=keep_multiindex,
+        context=context,
         invert=invert,
     )
 
-    return df['answer']
+    output = df[['block_number', 'answer']]
+
+    return output
+
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/chainlink_utils/chainlink_db/chainlink_intake.py` & `checkthechain-0.3.4/src/ctc/protocols/chainlink_utils/chainlink_db/chainlink_intake.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,14 +1,17 @@
 from __future__ import annotations
 
 import typing
 
-from ctc import db
+import toolsql
+
+from ctc import config
 from ctc import evm
 from ctc import spec
+from ctc import db
 
 from . import chainlink_schema_defs
 from . import chainlink_statements
 
 
 if typing.TYPE_CHECKING:
 
@@ -42,15 +45,15 @@
         proxy: str
         feedCategory: str
         feedType: str
 
 
 # # legacy version of chainlink payload data
 # _legacy_network_payload_locations: typing.Mapping[spec.NetworkName, tuple[str, str]] = {
-#     'mainnet': ('ethereum-addresses', 'Ethereum Mainnet'),
+#     'ethereum': ('ethereum-addresses', 'Ethereum Mainnet'),
 #     'kovan': ('ethereum-addresses', 'Kovan Testnet'),
 #     'rinkeby': ('ethereum-addresses', 'Rinkeby Testnet'),
 #     'bnb': ('bnb-chain-addresses-price', 'BNB Chain Mainnet'),
 #     'bnb_testnet': ('bnb-chain-addresses-price', 'BNB Chain Testnet'),
 #     'polygon': ('matic-addresses', 'Polygon Mainnet'),
 #     'polygon_mumbai': ('matic-addresses', 'Mumbai Testnet'),
 #     'gnosis': ('data-feeds-gnosis-chain', 'Gnosis Chain Mainnet'),
@@ -67,15 +70,15 @@
 #     'optimism': ('optimism-price-feeds', 'Optimism Mainnet'),
 #     'optimism_kovan': ('optimism-price-feeds', 'Optimism Kovan'),
 #     'moonriver': ('data-feeds-moonriver', 'Moonriver Mainnet'),
 #     'moonbeam': ('data-feeds-moonbeam', 'Moonbeam Mainnet'),
 # }
 
 network_payload_locations: typing.Mapping[spec.NetworkName, tuple[str, int]] = {
-    'mainnet': ('ethereum', 0),
+    'ethereum': ('ethereum', 0),
     'goerli': ('ethereum', 1),
     'bnb': ('bnb-chain', 0),
     'bnb_testnet': ('bnb-chain', 1),
     'polygon': ('polygon', 0),
     'polygon_mumbai': ('polygon', 0),
     'gnosis': ('gnosis-chain', 0),
     'heco': ('heco-chain', 0),
@@ -124,30 +127,32 @@
 
     return payload[network_group]['networks'][index]['proxies']
 
 
 async def async_import_networks_to_db(
     networks: typing.Sequence[ChainlinkNetworkName] | None = None,
     *,
+    db_config: toolsql.DBConfig,
     payload: ChainlinkFeedPayload | None = None,
-    engine: toolsql.SAEngine | None = None,
     verbose: bool = True,
 ) -> None:
     """import multiple networks of feeds to db
 
     by default import all networks
     """
 
     if payload is None:
         payload = await async_get_complete_feed_payload()
 
     # determine which networks to use
     if networks is None:
 
-        known_networks = {datum['name'] for datum in evm.get_networks().values()}
+        known_networks = {
+            datum['name'] for datum in evm.get_networks().values()
+        }
 
         networks = []
         for network_name in network_payload_locations.keys():
             network_group, index = network_payload_locations[network_name]
             if (
                 network_name in known_networks
                 and network_group in payload
@@ -164,36 +169,58 @@
     #             for network_data in payload[key]['networks']:
     #                 subkey = network_data['name']
     #                 if (key, subkey) in locations_to_network:
     #                     network = locations_to_network[(key, subkey)]
     #                     networks.append(network)
 
     if verbose:
-        print(
+        import toolstr
+        from ctc import cli
+
+        styles = cli.get_cli_styles()
+
+        toolstr.print(
             'Adding Chainlink feed metadata to db for',
-            len(networks),
+            toolstr.add_style(
+                str(len(networks)), styles['description'] + ' bold'
+            ),
             'networks...',
         )
 
     # add each network
     for network in networks:
-        await async_import_network_to_db(
-            network=network,
-            payload=payload,
-            engine=engine,
-            verbose=verbose,
-            indent=4,
+
+        # create table
+        table_schema = db.get_table_schema(
+            'chainlink_feeds', context={'network': network}
         )
+        with toolsql.connect(db_config) as conn:
+            toolsql.create_table(
+                table_schema,
+                if_not_exists=True,
+                conn=conn,
+                confirm=True,
+            )
+
+        # insert feed rows
+        async with toolsql.async_connect(db_config) as conn:
+            await async_import_network_to_db(
+                network=network,
+                payload=payload,
+                conn=conn,
+                verbose=verbose,
+                indent=4,
+            )
 
 
 async def async_import_network_to_db(
     network: ChainlinkNetworkName,
     *,
     payload: ChainlinkFeedPayload | None = None,
-    engine: toolsql.SAEngine | None = None,
+    conn: toolsql.AsyncConnection,
     verbose: bool = True,
     indent: int | str | None = None,
 ) -> None:
 
     raw_feeds = await async_get_network_feed_data(
         network=network, payload=payload
     )
@@ -210,34 +237,37 @@
     }
 
     feeds: typing.Sequence[typing.Mapping[str, typing.Any]] = [
         {key: raw_feed[raw_key] for raw_key, key in rename_fields.items()}  # type: ignore
         for raw_feed in raw_feeds
     ]
 
-    if engine is None:
-        engine = db.create_engine(schema_name='chainlink', network=network)
-
-    if engine is None:
-        raise Exception('cannot find db table to import to')
-
-    with engine.begin() as conn:
-
-        await chainlink_statements.async_upsert_feeds(
-            feeds=feeds,
-            network=network,
-            conn=conn,
-        )
+    await chainlink_statements.async_upsert_feeds(
+        feeds=feeds,
+        context=dict(network=network),
+        conn=conn,
+    )
 
     if verbose:
+        import toolstr
+        from ctc import cli
+
         if indent is None:
             indent = ''
         if isinstance(indent, int):
             indent = ' ' * indent
-        print(indent + 'added', len(feeds), network, 'Chainlink feeds to db')
+
+        styles = cli.get_cli_styles()
+
+        toolstr.print(
+            indent + 'added',
+            toolstr.add_style(str(len(feeds)), styles['description'] + ' bold'),
+            toolstr.add_style(network, styles['metavar']),
+            'Chainlink feeds to db',
+        )
 
 
 def print_payload_summary(payload: ChainlinkFeedPayload) -> None:
     for group in payload.keys():
         print(group)
         for network in payload[group]['networks']:
             print(
@@ -248,41 +278,40 @@
 
 
 async def async_intake_aggregator_update(
     *,
     feed: spec.Address,
     aggregator: spec.Address,
     block_number: int,
-    network: spec.NetworkReference,
+    context: spec.Context,
 ) -> None:
 
-    engine = db.create_engine(
+    db_config = config.get_context_db_config(
         schema_name='chainlink',
-        network=network,
+        context=context,
     )
-    if engine is not None:
-        with engine.begin() as conn:
-            await chainlink_statements.async_upsert_aggregator_update(
-                feed=feed,
-                aggregator=aggregator,
-                block_number=block_number,
-                network=network,
-                conn=conn,
-            )
+    async with toolsql.async_connect(db_config) as conn:
+        await chainlink_statements.async_upsert_aggregator_update(
+            feed=feed,
+            aggregator=aggregator,
+            block_number=block_number,
+            context=context,
+            conn=conn,
+        )
 
 
 async def async_intake_aggregator_updates(
     updates: typing.Sequence[chainlink_schema_defs._FeedAggregatorUpdate],
-    network: spec.NetworkReference,
+    context: spec.Context,
 ) -> None:
 
-    engine = db.create_engine(
+    db_config = config.get_context_db_config(
         schema_name='chainlink',
-        network=network,
+        context=context,
     )
-    if engine is not None:
-        with engine.begin() as conn:
-            await chainlink_statements.async_upsert_aggregator_updates(
-                updates=updates,
-                network=network,
-                conn=conn,
-            )
+    async with toolsql.async_connect(db_config) as conn:
+        await chainlink_statements.async_upsert_aggregator_updates(
+            updates=updates,
+            conn=conn,
+            context=context,
+        )
+
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/chainlink_utils/chainlink_db/chainlink_schema_defs.py` & `checkthechain-0.3.4/src/ctc/protocols/chainlink_utils/chainlink_db/chainlink_schema_defs.py`

 * *Files 2% similar despite different names*

```diff
@@ -22,15 +22,15 @@
 
     class _FeedAggregatorUpdate(TypedDict):
         feed: spec.Address
         aggregator: spec.Address
         block_number: int
 
 
-chainlink_schema: toolsql.DBSchema = {
+chainlink_schema: toolsql.DBSchemaShorthand = {
     'tables': {
         'chainlink_feeds': {
             'columns': [
                 {'name': 'address', 'type': 'Text', 'primary': True},
                 {'name': 'name', 'type': 'Text', 'index': True},
                 {'name': 'deviation', 'type': 'Text'},
                 {'name': 'heartbeat', 'type': 'Text'},
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/chainlink_utils/chainlink_feed_metadata.py` & `checkthechain-0.3.4/src/ctc/protocols/chainlink_utils/cli/chainlink_command.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,152 +1,156 @@
 from __future__ import annotations
 
+import time
 import typing
 
+import toolcli
+import toolstr
+import tooltime
+
 from ctc import config
 from ctc import evm
 from ctc import rpc
 from ctc import spec
-
-from . import chainlink_db
-from . import chainlink_spec
+from ctc.cli import cli_utils
+from ctc.protocols import chainlink_utils
 
 
-def _build_feed_query(
-    feed: chainlink_spec._FeedReference,
-) -> typing.Mapping[str, typing.Any]:
-    if isinstance(feed, str):
-        if evm.is_address_str(feed):
-            return {'address': feed}
-        elif '_' in feed:
-            return {'name': feed.replace('_', ' / ')}
-        else:
-            return {'name': feed}
-    else:
-        raise Exception('unknown feed reference type')
+def get_command_spec() -> toolcli.CommandSpec:
+    return {
+        'f': async_chainlink_command,
+        'help': 'output Chainlink feed data',
+        'args': [
+            {'name': 'feed', 'nargs': '+', 'help': 'name or address of feed'},
+            {
+                'name': ['--verbose', '-v'],
+                'help': 'show additional information',
+                'action': 'store_true',
+            },
+            {
+                'name': '--blocks',
+                'help': 'block range of datapoints',
+            },
+            {
+                'name': '--time',
+                'dest': 'timelength',
+                'help': 'historical duration to show feed data',
+            },
+            {
+                'name': '--export',
+                'default': 'stdout',
+                'help': 'file path for output (.json or .csv)',
+            },
+            {
+                'name': '--overwrite',
+                'action': 'store_true',
+                'help': 'specify that output path can be overwritten',
+            },
+            {'name': '--provider', 'help': 'rpc provider name or url'},
+            {'name': '--network', 'help': 'network name or chain_id'},
+            {
+                'name': '--all-fields',
+                'action': 'store_true',
+                'help': 'include all output fields',
+            },
+            {
+                'name': '--interpolate',
+                'help': 'interpolate all blocks in range',
+                'action': 'store_true',
+            },
+        ],
+        'examples': [
+            'DAI_USD',
+            '0xaed0c38402a5d19df6e4c03f4e2dced6e29c1ee9',
+            'DAI_USD --blocks 14000000:14001000',
+        ],
+    }
 
 
-async def async_get_feed_metadata(
-    feed: chainlink_spec._FeedReference,
+async def async_chainlink_command(
     *,
-    network: spec.NetworkReference | None = None,
-) -> chainlink_db.ChainlinkFeed:
-    query = _build_feed_query(feed)
-    if network is None:
-        network = config.get_default_network()
-
-    feed_data = await chainlink_db.async_query_feed(network=network, **query)
-    if feed_data is None:
-        raise Exception('could not find data for feed: ' + str(feed))
-    return feed_data
-
+    feed: typing.Sequence[str],
+    verbose: bool,
+    blocks: str | None,
+    timelength: str,
+    export: str,
+    overwrite: bool,
+    provider: str | None,
+    network: spec.NetworkReference | None,
+    all_fields: bool | None,
+    interpolate: bool,
+) -> None:
+
+    context = config.create_user_input_context(
+        provider=provider,
+        network=network,
+    )
 
-async def async_get_feed_decimals(
-    feed: chainlink_spec._FeedReference,
-    *,
-    network: spec.NetworkReference | None = None,
-    provider: spec.ProviderReference = None,
-    use_db: bool = True,
-) -> int:
-
-    # try database
-    if use_db:
-        query = _build_feed_query(feed)
-        if network is None:
-            if provider is not None:
-                network = rpc.get_provider_network(provider)
-            else:
-                network = config.get_default_network()
+    feed_str = '_'.join(feed)
 
-        feed_data = await chainlink_db.async_query_feed(
-            network=network, **query
-        )
-        if feed_data is not None:
-            return feed_data['decimals']
+    feed_str = await evm.async_resolve_address(feed_str, context=context)
 
-    # query rpc
-    if evm.is_address_str(feed):
-        if provider is None and network is not None:
-            provider = {'network': network}
-        result = await rpc.async_eth_call(
-            feed,
-            provider=provider,
-            function_abi=chainlink_spec.feed_function_abis['decimals'],
+    if timelength is not None:
+        timelength_seconds = tooltime.timelength_to_seconds(timelength)
+        start_block: int | None = await evm.async_get_block_of_timestamp(
+            time.time() - timelength_seconds,
+            mode='<=',
+            context=context,
         )
-        if not isinstance(result, int):
-            raise Exception('invalid rpc result')
-        return result
-
     else:
-        raise Exception('could not find address for feed: ' + str(feed))
+        start_block = None
 
-
-async def async_resolve_feed_address(
-    feed: str,
-    *,
-    network: spec.NetworkReference | None = None,
-    provider: spec.ProviderReference = None,
-) -> spec.Address:
-
-    if evm.is_address_str(feed):
-        return feed
-
-    query = _build_feed_query(feed)
-    if network is None:
-        if provider is not None:
-            network = rpc.get_provider_network(provider)
-        else:
-            network = config.get_default_network()
-
-    feed_data = await chainlink_db.async_query_feed(network=network, **query)
-    if feed_data is not None:
-        return feed_data['address']
+    if all_fields:
+        fields: typing.Literal['full', 'answer'] = 'full'
     else:
-        raise Exception('could not resolve feed address')
-
+        fields = 'answer'
 
-async def async_get_feed_aggregator(
-    feed: chainlink_spec._FeedReference,
-    *,
-    block: spec.BlockNumberReference = 'latest',
-    provider: spec.ProviderReference = None,
-    fill_empty: bool = True,
-) -> spec.Address:
-
-    feed = await async_resolve_feed_address(feed, provider=provider)
-
-    aggregator = await rpc.async_eth_call(
-        to_address=feed,
-        function_abi=chainlink_spec.feed_function_abis['aggregator'],
-        block_number=block,
-        fill_empty=fill_empty,
-    )
-    if aggregator is None:
-        raise Exception('aggregator not specified')
-    if not isinstance(aggregator, str):
-        raise Exception('invalid rpc result')
-
-    return aggregator
-
-
-async def async_get_feed_first_block(
-    feed: chainlink_spec._FeedReference,
-    *,
-    provider: spec.ProviderReference = None,
-    start_search: typing.Optional[spec.BlockNumberReference] = None,
-    end_search: typing.Optional[spec.BlockNumberReference] = None,
-    verbose: bool = False,
-) -> int:
-
-    feed = await async_resolve_feed_address(feed, provider=provider)
-
-    creation_block = await evm.async_get_contract_creation_block(
-        contract_address=feed,
-        start_block=start_search,
-        end_block=end_search,
-        verbose=verbose,
-    )
-
-    if creation_block is None:
-        raise Exception('could not determine creation_block for feed')
+    if blocks is None:
+        await chainlink_utils.async_print_feed_summary(
+            feed=feed_str,
+            verbose=verbose,
+            start_block=start_block,
+            context=context,
+        )
+    else:
+        feed_address = await chainlink_utils.async_resolve_feed_address(
+            feed=feed_str,
+            context=context,
+        )
+        name = await rpc.async_eth_call(
+            feed_address,
+            function_abi=chainlink_utils.feed_function_abis['description'],
+            context=context,
+        )
+        toolstr.print_text_box('Chainlink Feed: ' + name)
+        print('- feed address')
+        print('- feed:', feed_str)
+        print('- fields:', fields)
+        print('- output:', export)
+
+        if blocks is not None:
+            start_block, end_block = await cli_utils.async_parse_block_range(
+                blocks,
+                context=context,
+            )
+        else:
+            start_block = None
+            end_block = None
+        # block_kwargs = {'blocks': resolved_blocks}
+        # print('- n_blocks:', len(resolved_blocks))
+        if start_block is not None:
+            print('- start_block:', start_block)
+        if end_block is not None:
+            print('- end_block:', end_block)
+
+        feed_data = await chainlink_utils.async_get_feed_data(
+            feed_str,
+            fields=fields,
+            start_block=start_block,
+            end_block=end_block,
+            interpolate=interpolate,
+            context=context,
+        )
+        df = feed_data
 
-    return creation_block
+        print()
+        cli_utils.output_data(df, output=export, overwrite=overwrite, raw=True)
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/chainlink_utils/chainlink_registry.py` & `checkthechain-0.3.4/src/ctc/protocols/chainlink_utils/chainlink_registry.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,17 +1,18 @@
 from __future__ import annotations
 
 import typing
 
+from ctc import config
 from ctc import rpc
 from ctc import spec
 
 
 feed_registry = {
-    # mainnet
+    # ethereum
     1: '0x47fb2585d2c56fe188d0e6ec628a38b74fceeedf',
     # kovan
     42: '0xAa7F6f7f507457a1EE157fE97F6c7DB2BEec5cD0',
 }
 
 feed_registry_asset_addresses = {
     'BTC': '0xbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb',
@@ -101,47 +102,50 @@
 }
 
 
 async def async_get_registry_feed(
     base: str,
     quote: str,
     *,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
 ) -> spec.Address:
-    network = rpc.get_provider_network(provider)
+
+    network = config.get_context_chain_id(context)
     registry_address = feed_registry[network]
 
     result = await rpc.async_eth_call(
         to_address=registry_address,
         function_abi=registry_function_abis['getFeed'],
         function_parameters=[base, quote],
-        provider=provider,
+        context=context,
     )
 
     if not isinstance(result, str):
         raise Exception('invalid rpc result')
     return result
 
 
 async def async_get_phase_range(
     *,
     base: str,
     quote: str,
     phase: int,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
 ) -> typing.Tuple[int, ...]:
-    network = rpc.get_provider_network(provider)
+
+    network = config.get_context_chain_id(context)
     registry_address = feed_registry[network]
 
     result = await rpc.async_eth_call(
         to_address=registry_address,
         # function_abi=registry_function_abis['getPhaseRange'],
         function_abi=registry_function_abis['getPhase'],
         function_parameters=[base, quote, phase],
-        provider=provider,
+        context=context,
     )
 
     if not isinstance(result, tuple) or not all(
         isinstance(item, int) for item in result
     ):
         raise Exception('invalid rpc result')
     return result
+
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/chainlink_utils/chainlink_spec.py` & `checkthechain-0.3.4/src/ctc/protocols/chainlink_utils/chainlink_spec.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,17 +1,18 @@
 # https://docs.chain.link/docs/faq/
 from __future__ import annotations
 
 import os
 import typing
-from typing_extensions import TypedDict
 
 from ctc import spec
 
 if typing.TYPE_CHECKING or os.environ.get('BUILDING_SPHINX') == '1':
+    from typing_extensions import TypedDict
+
     _FeedReference = typing.Union[spec.Address, str]
 
     class FeedRoundData(TypedDict):
         answer: typing.Union[int, float]
         round_id: int
         timestamp: int
 
@@ -98,7 +99,8 @@
                 'type': 'uint256',
             },
         ],
         'name': 'AnswerUpdated',
         'type': 'event',
     },
 }
+
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/chainlink_utils/chainlink_summary.py` & `checkthechain-0.3.4/src/ctc/protocols/chainlink_utils/chainlink_summary.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,14 +1,15 @@
 from __future__ import annotations
 
 import time
 
 import tooltime
 import toolstr
 
+import ctc.config
 from ctc import cli
 from ctc import evm
 from ctc import rpc
 from ctc import spec
 from ctc.protocols import chainlink_utils
 from . import chainlink_feed_metadata
 from . import chainlink_spec
@@ -16,57 +17,62 @@
 
 async def async_print_feed_summary(
     feed: str,
     *,
     start_block: spec.BlockNumberReference | None = None,
     n_recent: int | None = None,
     verbose: bool = False,
+    context: spec.Context = None,
 ) -> None:
 
     import asyncio
 
     styles = cli.get_cli_styles()
 
     feed_address = await chainlink_feed_metadata.async_resolve_feed_address(
         feed,
+        context=context,
     )
 
     name_coroutine = rpc.async_eth_call(
         function_abi=chainlink_spec.feed_function_abis['description'],
         to_address=feed_address,
+        context=context,
     )
     decimals_coroutine = rpc.async_eth_call(
         function_abi=chainlink_spec.feed_function_abis['decimals'],
         to_address=feed_address,
+        context=context,
     )
     aggregator_coroutine = rpc.async_eth_call(
         function_abi=chainlink_spec.feed_function_abis['aggregator'],
         to_address=feed_address,
+        context=context,
     )
     name_task = asyncio.create_task(name_coroutine)
     decimals_task = asyncio.create_task(decimals_coroutine)
     aggregator_task = asyncio.create_task(aggregator_coroutine)
 
     if start_block is None:
         if n_recent is None:
             n_recent = 20
-        latest_block = await rpc.async_eth_block_number()
+        latest_block = await rpc.async_eth_block_number(context=context)
         start_block = latest_block - 6000 * n_recent
     else:
         n_recent = 999999999999
     data = await chainlink_utils.async_get_feed_data(
         feed_address,
         fields='full',
         start_block=start_block,
+        context=context,
     )
-    most_recent = data.iloc[-1]
-    timestamp = most_recent['timestamp']
+    timestamp = data['timestamp'][-1]
 
     updates = []
-    for i, row in data.iterrows():
+    for i, row in enumerate(data.to_dicts()):
         timestamp = int(row['timestamp'])
         age = tooltime.timelength_to_phrase(int(time.time() - timestamp))
         age = ' '.join(age.split(' ')[:2]).strip(',')
         update = [
             toolstr.format(row['answer'], decimals=4, trailing_zeros=True),
             age,
             str(i),
@@ -80,28 +86,35 @@
     aggregator = await aggregator_task
 
     title = 'Chainlink Feed Summary: ' + name
     toolstr.print_text_box(title, double=False, style=styles['title'])
     cli.print_bullet(key='name', value=name)
     cli.print_bullet(key='decimals', value=str(decimals))
 
-    metadata = await chainlink_feed_metadata.async_get_feed_metadata(feed)
+    metadata = await chainlink_feed_metadata.async_get_feed_metadata(
+        feed,
+        context=context,
+    )
     deviation = toolstr.format(
         float(metadata['deviation']) / 100,
         percentage=True,
     )
     cli.print_bullet(key='deviation threshold', value=deviation)
     cli.print_bullet(key='heartbeat', value=metadata['heartbeat'])
     cli.print_bullet(key='address', value=feed_address)
     cli.print_bullet(key='aggregator', value=aggregator)
 
     creation_block = await chainlink_feed_metadata.async_get_feed_first_block(
-        feed
+        feed,
+        context=context,
+    )
+    creation_timestamp = await evm.async_get_block_timestamp(
+        creation_block,
+        context=context,
     )
-    creation_timestamp = await evm.async_get_block_timestamp(creation_block)
     cli.print_bullet(key='feed creation block', value=str(creation_block))
     cli.print_bullet(
         key='feed creation timestamp',
         value=str(creation_timestamp),
     )
     cli.print_bullet(
         key='feed age',
@@ -109,20 +122,22 @@
     )
 
     if verbose:
         print()
         print('fetching aggregator history...')
         history = await chainlink_utils.async_get_feed_aggregator_history(
             feed_address,
-            provider=None,
+            context=context,
         )
         print()
         toolstr.print_header('Aggregator History', style=styles['title'])
         history_blocks = sorted(history.values())
-        raw_timestamps = await evm.async_get_block_timestamps(history_blocks)
+        raw_timestamps = await evm.async_get_block_timestamps(
+            history_blocks, context=context
+        )
         history_timestamps = dict(zip(history.keys(), raw_timestamps))
         history_rows = []
         for old_aggregator, block in history.items():
             age_seconds: str = tooltime.get_age(
                 history_timestamps[old_aggregator],
                 'TimelengthPhrase',
             )
@@ -162,28 +177,30 @@
             'age': styles['description'],
             'block': styles['option'],
             'timestamp': styles['option'],
             'time': styles['option'],
         },
     )
 
-    xvals = data['timestamp'].values.astype(float)
-    yvals = data['answer'].values.astype(float)
+    xvals = data['timestamp'].to_list()
+    yvals = data['answer'].to_list()
     plot = toolstr.render_line_plot(
-        xvals=xvals,  # type: ignore
-        yvals=yvals,  # type: ignore
-        n_rows=40,
-        n_columns=120,
+        xvals=xvals,
+        yvals=yvals,
+        n_rows=10,
+        n_columns=60,
         line_style=styles['description'],
         chrome_style=styles['comment'],
         tick_label_style=styles['metavar'],
         xaxis_kwargs={'tick_label_format': 'age'},
+        char_dict=ctc.config.get_cli_chart_charset(),
     )
     print()
     print()
     print()
     toolstr.print(
         toolstr.hjustify(name + ' feed over time', 'center', 70),
         indent=4,
         style=styles['title'],
     )
     toolstr.print(plot, indent=4)
+
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/chainlink_utils/cli/chainlink_ls_command.py` & `checkthechain-0.3.4/src/ctc/protocols/chainlink_utils/cli/chainlink_ls_command.py`

 * *Files 20% similar despite different names*

```diff
@@ -27,22 +27,21 @@
         'examples': [
             '',
             'DAI',
         ],
     }
 
 
-async def async_chainlink_ls_command(query: str, network: str | int | None) -> None:
+async def async_chainlink_ls_command(
+    query: str, network: str | int | None
+) -> None:
 
-    if network is None:
-        network = config.get_default_network()
-    if isinstance(network, str) and network.isnumeric():
-        network = int(network)
+    context = config.create_user_input_context(network=network)
 
-    oracle_feeds = await chainlink_db.async_query_feeds(network=network)
+    oracle_feeds = await chainlink_db.async_query_feeds(context=context)
     if oracle_feeds is None:
         return
     rows = []
     for feed in oracle_feeds:
         if feed is None:
             continue
         if query is not None and query.lower() not in feed['name'].lower():
@@ -52,20 +51,15 @@
             feed['deviation'],
             feed['heartbeat'],
             feed['address'][:42],
         ]
         rows.append(row)
     labels = ['name', 'delta', 'rate', 'address']
     styles = cli.get_cli_styles()
-    if network is None:
-        network_name = None
-    else:
-        network_name = evm.get_network_name(network)
-    if network_name is None:
-        network_name = 'Unknown Network'
+    network_name = evm.get_network_name(config.get_context_chain_id(context))
     toolstr.print_text_box(
         'Chainlink feeds on ' + network_name.title(),
         style=styles['title'],
     )
     toolstr.print_table(
         rows,
         labels=labels,
@@ -76,7 +70,8 @@
             'name': styles['option'],
             'delta': styles['description'],
             'rate': styles['description'],
             'address': styles['metavar'],
         },
         max_column_widths={'name': 14},
     )
+
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/coingecko_utils/cli/cg_command.py` & `checkthechain-0.3.4/src/ctc/protocols/coingecko_utils/cli/cg_command.py`

 * *Files 20% similar despite different names*

```diff
@@ -33,21 +33,21 @@
             {'name': '--width', 'help': 'width of sparklines'},
             {
                 'name': '--update',
                 'help': 'update stored coingecko token db',
                 'action': 'store_true',
             },
         ],
-        'examples': [
-            '',
-            'CRV -t 100d',
-            'ETH / BTC',
-            'LINK / ETH -t 24h',
-            '--update',
-        ],
+        'examples': {
+            '': {'runnable': False},
+            'CRV -t 100d': {'runnable': False},
+            'ETH / BTC': {'runnable': False},
+            'LINK / ETH -t 24h': {'runnable': False},
+            '--update': {'runnable': False},
+        },
     }
 
 
 async def async_cg_command(
     *,
     tokens: str,
     n: int,
@@ -55,15 +55,17 @@
     height: int | None,
     width: str | int | None,
     update: bool,
     timelength: str | None,
 ) -> None:
 
     if update:
-        await coingecko_utils.async_get_token_list(use_db=False, update=True)
+        await coingecko_utils.async_get_token_list(
+            context={'cache': False}, update=True
+        )
         return
 
     if height is None:
         height = 1
     height = int(height)
 
     if isinstance(width, str):
@@ -134,7 +136,8 @@
             verbose=verbose,
             update=update,
             days=days,
         )
 
     else:
         raise Exception('could not parse inputs, use --help for details')
+
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/coingecko_utils/coingecko_db/coingecko_schema_defs.py` & `checkthechain-0.3.4/src/ctc/protocols/coingecko_utils/coingecko_db/coingecko_schema_defs.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,24 +1,25 @@
 from __future__ import annotations
 
 import typing
 
 if typing.TYPE_CHECKING:
 
     from typing_extensions import TypedDict
+
     import toolsql
 
     class CoingeckoToken(TypedDict):
         id: str
         symbol: str
         name: str
         market_cap_rank: int
 
 
-coingecko_schema: toolsql.DBSchema = {
+coingecko_schema: toolsql.DBSchemaShorthand = {
     'tables': {
         'coingecko_tokens': {
             'columns': [
                 {'name': 'id', 'type': 'Text', 'primary': True},
                 {
                     'name': 'symbol',
                     'type': 'Text',
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/coingecko_utils/coingecko_db/coingecko_statements.py` & `checkthechain-0.3.4/src/ctc/protocols/coingecko_utils/coingecko_db/coingecko_statements.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,126 +1,124 @@
 from __future__ import annotations
 
 import typing
 
 import toolsql
 
+from ctc import spec
 from . import coingecko_schema_defs
 
 
 async def async_upsert_tokens(
     *,
     tokens: typing.Sequence[coingecko_schema_defs.CoingeckoToken],
-    conn: toolsql.SAConnection,
+    conn: toolsql.AsyncConnection,
+    context: spec.Context = None,
 ) -> None:
 
     if len(tokens) == 0:
         return
 
-    toolsql.insert(
+    await toolsql.async_insert(
         conn=conn,
         table='coingecko_tokens',
         rows=tokens,
-        upsert='do_update',
+        upsert=True,
     )
 
 
 async def async_delete_tokens(
     *,
     ids: typing.Sequence[str],
-    conn: toolsql.SAConnection,
+    conn: toolsql.AsyncConnection,
+    context: spec.Context = None,
 ) -> None:
 
     if len(ids) == 0:
         return
 
-    toolsql.delete(
+    await toolsql.async_delete(
         conn=conn,
         table='coingecko_tokens',
         where_in={'id': ids},
     )
 
 
 async def async_select_token(
     *,
-    conn: toolsql.SAConnection,
+    conn: toolsql.AsyncConnection,
     id: str | None = None,
+    context: spec.Context = None,
 ) -> coingecko_schema_defs.CoingeckoToken | None:
 
     if id is not None:
         where_equals = {'id': id}
     else:
         raise Exception('must specify id')
 
-    result: coingecko_schema_defs.CoingeckoToken = toolsql.select(
+    result: coingecko_schema_defs.CoingeckoToken = await toolsql.async_select(  # type: ignore
         conn=conn,
         table='coingecko_tokens',
         where_equals=where_equals,
-        return_count='one',
-        raise_if_table_dne=False,
+        output_format='single_dict',
     )
 
     return result
 
 
 async def async_select_tokens(
     *,
     symbol_query: str | None = None,
     name_query: str | None = None,
-    conn: toolsql.SAConnection,
+    conn: toolsql.AsyncConnection,
+    context: spec.Context = None,
 ) -> typing.Sequence[coingecko_schema_defs.CoingeckoToken] | None:
 
-    # get table object
-    if symbol_query is not None or name_query is not None:
-        try:
-            sqla_table = toolsql.create_table_object_from_db(
-                table_name='coingecko_tokens',
-                conn=conn,
-            )
-        except toolsql.TableNotFound:
-            return None
-
     # symbol query
     if symbol_query is not None:
-        symbol_query = symbol_query.lower()
-        symbol_filter = sqla_table.c['symbol'].contains(symbol_query)
+        symbol_filter: toolsql.WhereGroup | None = {
+            'where_ilike': {'symbol': '%' + symbol_query.lower() + '%'}
+        }
     else:
         symbol_filter = None
 
     # name query
     if name_query is not None:
-        name_query = name_query.lower()
-        name_filter = sqla_table.c['name'].contains(name_query)
+        name_filter: toolsql.WhereGroup | None = {
+            'where_ilike': {'symbol': '%' + name_query.lower() + '%'}
+        }
     else:
         name_filter = None
 
     # combine filters
     if symbol_filter is not None and name_filter is not None:
-        import sqlalchemy  # type: ignore
-        query_filter = sqlalchemy.or_(symbol_filter, name_filter)
-        filters = [query_filter]
+        select_kwargs: toolsql.SelectKwargs = {'where_or': [symbol_filter, name_filter]}
     elif symbol_filter is not None:
-        filters = [symbol_filter]
+        select_kwargs = symbol_filter  # type: ignore
     elif name_filter is not None:
-        filters = [name_filter]
+        select_kwargs = name_filter  # type: ignore
     else:
-        filters = None
+        select_kwargs = {}
 
-    result: typing.Sequence[coingecko_schema_defs.CoingeckoToken] = toolsql.select(
+    result: typing.Sequence[
+        coingecko_schema_defs.CoingeckoToken
+    ] = await toolsql.async_select(  # type: ignore
         conn=conn,
         table='coingecko_tokens',
-        raise_if_table_dne=False,
-        filters=filters,
         order_by='market_cap_rank',
+        **select_kwargs,
     )
 
     ranked: list[coingecko_schema_defs.CoingeckoToken] = []
     unranked: list[coingecko_schema_defs.CoingeckoToken] = []
     for item in result:
         if item['market_cap_rank'] is not None:
             ranked.append(item)
         else:
             unranked.append(item)
 
-    together: typing.MutableSequence[coingecko_schema_defs.CoingeckoToken] = ranked + unranked
+    together: typing.MutableSequence[coingecko_schema_defs.CoingeckoToken] = (
+        ranked + unranked
+    )
 
     return together
+
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/coingecko_utils/market_utils.py` & `checkthechain-0.3.4/src/ctc/protocols/coingecko_utils/market_utils.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,35 +1,47 @@
 from __future__ import annotations
 
 import math
-import os
 import typing
 
 if typing.TYPE_CHECKING:
     import aiohttp
 
 import toolstr
 
 
 url_template = 'https://api.coingecko.com/api/v3/coins/markets?vs_currency=usd&order=market_cap_desc&per_page=100&page={page}&sparkline=true&price_change_percentage=1h%2C24h%2C7d'
 token_url_template = 'https://www.coingecko.com/en/coins/{name}'
 
 
 async def async_get_market_data(
     n: int,
+    *,
+    mode: str = 'serial',
 ) -> typing.Sequence[typing.Mapping[typing.Any, typing.Any]]:
     import asyncio
     import aiohttp
 
     n_per_page = 100
     n_pages = math.ceil(n / n_per_page)
 
-    async with aiohttp.ClientSession() as session:
-        coroutines = [async_get_page(session, p) for p in range(n_pages)]
-        pages = await asyncio.gather(*coroutines)
+    if mode == 'concurrent':
+        async with aiohttp.ClientSession() as session:
+            coroutines = [async_get_page(session, p) for p in range(n_pages)]
+            pages = await asyncio.gather(*coroutines)
+
+    elif mode == 'serial':
+        for p in range(n_pages):
+            pages = []
+            async with aiohttp.ClientSession() as session:
+                page = await async_get_page(session, p)
+                pages.append(page)
+
+    else:
+        raise Exception('unknown mode: ' + str(mode))
 
     items = [item for page in pages for item in page]
 
     return items[:n]
 
 
 async def async_get_page(
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/coingecko_utils/token_utils.py` & `checkthechain-0.3.4/src/ctc/protocols/coingecko_utils/token_utils.py`

 * *Files 4% similar despite different names*

```diff
@@ -3,14 +3,15 @@
 import asyncio
 import time
 import typing
 
 import aiohttp
 import toolstr
 
+import ctc.config
 from ctc import spec
 from . import coingecko_db
 
 if typing.TYPE_CHECKING:
     from typing_extensions import TypedDict
 
     class CoinGeckoRatelimit(TypedDict):
@@ -51,19 +52,27 @@
 
 #
 # # lists of tokens
 #
 
 
 async def async_get_token_list(
-    use_db: bool = True, update: bool | None = None
+    *,
+    context: spec.Context | None = None,
+    update: bool | None = None
 ) -> typing.Sequence[coingecko_db.CoingeckoToken]:
 
-    if use_db and not update:
-        result = await coingecko_db.async_query_tokens()
+    from ctc import config
+
+    read_cache, write_cache = config.get_context_cache_read_write(
+        schema_name='coingecko', context=context
+    )
+
+    if read_cache and not update:
+        result = await coingecko_db.async_query_tokens(context={})
         if isinstance(result, list) and len(result) > 0:
             return result
 
     token_list = await _async_get_token_list_from_server(include_platform=False)
     for item in token_list:
         item['market_cap_rank'] = None
 
@@ -98,20 +107,28 @@
 
 
 #
 # # token symbol --> token id
 #
 
 
-async def async_get_token_name(query: str, use_db: bool = True) -> str:
+async def async_get_token_name(query: str, *, context: spec.Context = None) -> str:
     """given a token symbol query top token id"""
 
-    if use_db:
+    from ctc import config
+
+    read_cache, write_cache = config.get_context_cache_read_write(
+        schema_name='coingecko', context=context
+    )
+
+    if read_cache:
         result = await coingecko_db.async_query_tokens(
-            symbol_query=query, name_query=query
+            symbol_query=query,
+            name_query=query,
+            context={},
         )
         if result is not None and len(result) > 0:
 
             # check for direct symbol matches
             query = query.lower()
             symbol_matches = [
                 result for result in result if result['symbol'].lower() == query
@@ -121,20 +138,28 @@
 
             return result[0]['name']
 
     raise Exception()
     # return await async_get_token_id_from_server(query)
 
 
-async def async_get_token_id(query: str, use_db: bool = True) -> str:
+async def async_get_token_id(
+    query: str, *, context: spec.Context = None
+) -> str:
     """given a token symbol query top token id"""
 
-    if use_db:
+    from ctc import config
+
+    read_cache, write_cache = config.get_context_cache_read_write(
+        schema_name='coingecko', context=context
+    )
+
+    if read_cache:
         result = await coingecko_db.async_query_tokens(
-            symbol_query=query, name_query=query
+            symbol_query=query, name_query=query, context={}
         )
         if result is not None and len(result) > 0:
 
             # check for direct symbol matches
             query = query.lower()
             symbol_matches = [
                 result for result in result if result['symbol'].lower() == query
@@ -151,15 +176,16 @@
     """return first result from server token list"""
 
     token_ids = await async_get_token_ids_from_server(symbol)
 
     if len(token_ids) == 0:
         raise Exception('cannot find token_id')
     elif len(token_ids) > 1:
-        raise Exception('too many token_ids for symbol')
+        # raise Exception('too many token_ids for symbol')
+        return token_ids[0]
     else:
         return token_ids[0]
 
 
 async def async_get_token_ids_from_server(
     symbol: str,
 ) -> typing.Sequence[str]:
@@ -365,20 +391,21 @@
         ('Market Cap', market_caps_times, market_caps),
         ('Volume', total_volumes_times, total_volumes),
     ]
     for title, xvals, yvals in plots:
         plot = toolstr.render_line_plot(
             xvals=xvals,
             yvals=yvals,
-            n_rows=40,
-            n_columns=120,
+            n_rows=10,
+            n_columns=60,
             line_style=styles['description'],
             chrome_style=styles['comment'],
             tick_label_style=styles['metavar'],
             yaxis_kwargs={'tick_label_format': {'prefix': '$'}},
+            char_dict=ctc.config.get_cli_chart_charset(),
         )
         print()
 
         if yvals[0] != 0:
             delta = yvals[-1] / yvals[0] - 1
         else:
             delta = float('inf')
@@ -473,38 +500,40 @@
         toolstr.hjustify(coin1 + ' / ' + coin2, 'center', 70),
         indent=4,
         style=styles['title'],
     )
     plot = toolstr.render_line_plot(
         xvals=coin1_over_coin2_times,  # type: ignore
         yvals=coin1_over_coin2_prices,  # type: ignore
-        n_rows=40,
-        n_columns=120,
+        n_rows=10,
+        n_columns=60,
         line_style=styles['description'],
         chrome_style=styles['comment'],
         tick_label_style=styles['metavar'],
+        char_dict=ctc.config.get_cli_chart_charset(),
     )
     toolstr.print(plot, indent=4)
 
     print()
     print()
     print()
     toolstr.print(
         toolstr.hjustify(coin2 + ' / ' + coin1, 'center', 70),
         indent=4,
         style=styles['title'],
     )
     plot = toolstr.render_line_plot(
         xvals=coin2_over_coin1_times,  # type: ignore
         yvals=coin2_over_coin1_prices,  # type: ignore
-        n_rows=40,
-        n_columns=120,
+        n_rows=10,
+        n_columns=60,
         line_style=styles['description'],
         chrome_style=styles['comment'],
         tick_label_style=styles['metavar'],
+        char_dict=ctc.config.get_cli_chart_charset(),
     )
     toolstr.print(plot, indent=4)
 
 
 def _compute_token_quotient(
     *,
     coin1_times: spec.NumpyArray,
@@ -518,7 +547,8 @@
 
     indices = np.searchsorted(coin1_times, coin2_times)
     nonzero_mask = (indices != 0) * (indices < len(coin1_times))
     nonzero_indices = indices[nonzero_mask]
     comparison_prices = coin1_prices[nonzero_indices]
     coin1_over_coin2_prices = comparison_prices / coin2_prices[nonzero_mask]
     return coin2_times[nonzero_mask], coin1_over_coin2_prices
+
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/compound_utils/compound_crud.py` & `checkthechain-0.3.4/src/ctc/protocols/compound_utils/compound_crud.py`

 * *Files 20% similar despite different names*

```diff
@@ -8,69 +8,81 @@
 
 blocks_per_day = 6570
 days_per_year = 365
 
 
 async def async_get_supply_apy(
     ctoken: spec.Address,
+    *,
     block: spec.BlockNumberReference | None = None,
+    context: spec.Context = None,
 ) -> float:
     result = await rpc.async_eth_call(
         to_address=ctoken,
         function_name='supplyRatePerBlock',
         block_number=block,
+        context=context,
     )
     if not isinstance(result, int):
         raise Exception('invalid rpc result')
     supply_rate_per_block = result
     supply_apy = (1 + supply_rate_per_block / 1e18 * blocks_per_day) ** 365 - 1
     return supply_apy
 
 
 async def async_get_borrow_apy(
     ctoken: spec.Address,
+    *,
     block: spec.BlockNumberReference | None = None,
+    context: spec.Context = None,
 ) -> float:
     result = await rpc.async_eth_call(
         to_address=ctoken,
         function_name='borrowRatePerBlock',
         block_number=block,
+        context=context,
     )
     if not isinstance(result, int):
         raise Exception('invalid rpc result')
     borrow_rate_per_block = result
     borrow_apy = (1 + borrow_rate_per_block / 1e18 * blocks_per_day) ** 365 - 1
     return borrow_apy
 
 
 async def async_get_supply_apy_by_block(
     ctoken: spec.Address,
     blocks: typing.Sequence[spec.BlockNumberReference],
+    *,
+    context: spec.Context = None,
 ) -> list[float]:
 
     import numpy as np
 
     supply_rate_per_block = await rpc.async_batch_eth_call(
         to_address=ctoken,
         function_name='supplyRatePerBlock',
         block_numbers=blocks,
+        context=context,
     )
     as_array: spec.NumpyArray = np.array(supply_rate_per_block)
     supply_apy = (1 + as_array / 1e18 * blocks_per_day) ** 365 - 1
     return list(supply_apy)
 
 
 async def async_get_borrow_apy_by_block(
     ctoken: spec.Address,
     blocks: typing.Sequence[spec.BlockNumberReference],
+    *,
+    context: spec.Context = None,
 ) -> list[float]:
 
     import numpy as np
 
     borrow_rate_per_block = await rpc.async_batch_eth_call(
         to_address=ctoken,
         function_name='borrowRatePerBlock',
         block_numbers=blocks,
+        context=context,
     )
     as_array: spec.NumpyArray = np.array(borrow_rate_per_block)
     borrow_apy = (1 + as_array / 1e18 * blocks_per_day) ** 365 - 1
     return list(borrow_apy)
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/curve_utils/cli/curve_pools_command.py` & `checkthechain-0.3.4/src/ctc/protocols/curve_utils/cli/curve_pools_command.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/protocols/curve_utils/curve_spec.py` & `checkthechain-0.3.4/src/ctc/protocols/curve_utils/curve_spec.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,42 +1,42 @@
 """
 see https://github.com/curvefi/curve-pool-registry
 """
 from __future__ import annotations
 
 import typing
-from typing_extensions import TypedDict
 
 from ctc import spec
 
+if typing.TYPE_CHECKING:
+    from typing_extensions import TypedDict
+
+    class CurvePoolMetadata(TypedDict):
+        token_addresses: typing.Sequence[spec.Address]
+        token_symbols: typing.Sequence[str]
+        token_decimals: typing.Sequence[int]
+        A: int
+
+    class CurveTrade(TypedDict):
+        token_sold: spec.Address
+        token_bought: spec.Address
+        amount_sold: typing.Union[int, float]
+        amount_bought: typing.Union[int, float]
+
 
 three_pool_lp = '0x6c3f90f043a72fa612cbac8115ee7e52bde6e490'
 three_pool = '0xbebc44782c7db0a1a60cb6fe97d0b483032ff1c7'
 three_pool_token_index = {
     'DAI': 0,
     'USDC': 1,
     'USDT': 2,
 }
 three_pool_coins = ['DAI', 'USDC', 'USDT']
 
 
-class CurvePoolMetadata(TypedDict):
-    token_addresses: list[spec.Address]
-    token_symbols: list[str]
-    token_decimals: list[int]
-    A: int
-
-
-class CurveTrade(TypedDict):
-    token_sold: spec.Address
-    token_bought: spec.Address
-    amount_sold: typing.Union[int, float]
-    amount_bought: typing.Union[int, float]
-
-
 pool_function_abis: typing.Mapping[str, spec.FunctionABI] = {
     'A': {
         'inputs': [],
         'name': 'A',
         'outputs': [
             {
                 'name': '',
@@ -150,15 +150,15 @@
             },
         ],
         'stateMutability': 'view',
         'type': 'function',
     },
 }
 
-pool_event_abis = {
+pool_event_abis: typing.Mapping[str, spec.EventABI] = {
     'TokenExchange': {
         'anonymous': False,
         'inputs': [
             {
                 'indexed': True,
                 'name': 'buyer',
                 'type': 'address',
@@ -216,7 +216,8 @@
                 'type': 'uint256',
             },
         ],
         'name': 'TokenExchangeUnderlying',
         'type': 'event',
     },
 }
+
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/curve_utils/metapool_utils.py` & `checkthechain-0.3.4/src/ctc/protocols/curve_utils/metapool_utils.py`

 * *Files 12% similar despite different names*

```diff
@@ -15,39 +15,39 @@
     metapool: spec.Address,
     *,
     token_sold: typing.Union[spec.Address, str],
     token_bought: typing.Union[spec.Address, str],
     amount_sold: typing.Union[int, float],
     input_normalized: bool = True,
     normalize_output: bool = True,
-    provider: spec.ProviderReference = None,
     parent_pool: typing.Optional[spec.Address] = None,
     parent_lp: typing.Optional[spec.Address] = None,
     parent_coins: typing.Optional[list[str]] = None,
+    context: spec.Context = None,
 ) -> curve_spec.CurveTrade:
 
     if parent_pool is None and parent_lp is None:
         parent_pool = curve_spec.three_pool
         parent_lp = curve_spec.three_pool_lp
         parent_coins = curve_spec.three_pool_coins
     if parent_pool is None or parent_lp is None or parent_coins is None:
         raise Exception('must specify more parent parameters')
 
     metadata = await pool_metadata.async_get_pool_metadata(
         pool=metapool,
-        provider=provider,
+        context=context,
     )
 
     if token_bought in parent_coins:
 
         sold_index = await pool_metadata.async_get_token_index(
-            pool=metapool, token=token_sold, metadata=metadata
+            pool=metapool, token=token_sold, metadata=metadata, context=context,
         )
         bought_index = await pool_metadata.async_get_token_index(
-            pool=metapool, token=parent_lp, metadata=metadata
+            pool=metapool, token=parent_lp, metadata=metadata, context=context,
         )
 
         if input_normalized:
             amount_sold *= 10 ** metadata['token_decimals'][sold_index]
 
         function_abi: spec.FunctionABI = {
             'inputs': [
@@ -75,40 +75,40 @@
             'type': 'function',
         }
 
         lp_bought = await rpc.async_eth_call(
             to_address=metapool,
             function_abi=function_abi,
             function_parameters=[sold_index, bought_index, amount_sold],
-            provider=provider,
+            context=context,
         )
 
         amount_bought = await pool_state.async_get_lp_withdrawal(
             pool=parent_pool,
             amount_lp=lp_bought,
             token_withdrawn=token_bought,
-            provider=provider,
+            context=context,
         )
 
         if normalize_output:
             # bought token can be different from lp token
             bought_decimals = await evm.async_get_erc20_decimals(
                 metadata['token_addresses'][bought_index],
-                provider=provider,
+                context=context,
             )
             amount_bought /= 10 ** bought_decimals
             amount_sold /= 10 ** metadata['token_decimals'][sold_index]
 
     elif token_sold in parent_coins:
 
         sold_index = await pool_metadata.async_get_token_index(
-            pool=metapool, token=parent_lp, metadata=metadata
+            pool=metapool, token=parent_lp, metadata=metadata, context=context
         )
         bought_index = await pool_metadata.async_get_token_index(
-            pool=metapool, token=token_bought, metadata=metadata
+            pool=metapool, token=token_bought, metadata=metadata, context=context
         )
 
         raise NotImplementedError()
 
     else:
         raise Exception('could not determine token indices')
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/curve_utils/pool_lists.py` & `checkthechain-0.3.4/src/ctc/protocols/curve_utils/pool_lists.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,20 +1,27 @@
 from __future__ import annotations
 
 import asyncio
 import typing
-from typing_extensions import TypedDict
 
 from ctc import evm
 from ctc import rpc
 from ctc import spec
 
 if typing.TYPE_CHECKING:
+    from typing_extensions import TypedDict
+
     import tooltime
 
+    class CurvePoolData(TypedDict):
+        address: spec.Address
+        tokens: typing.Sequence[spec.Address]
+        symbols: typing.Sequence[str]
+        balances: typing.Sequence[int | float | None]
+
 
 # factories
 curve_deployer_eoa = '0xbabe61887f1de2713c6f97e567623453d3c79f67'
 old_pool_factory = '0x0959158b6040d32d04c301a72cbfd6b39e21c9ae'
 pool_factory = '0xb9fc157394af804a3578134a6585c0dc9cc990d4'
 deposit_separated_factory = '0xf18056bbd320e96a48e3fbf8bc061322531aac99'
 crypto_factory = '0x8f942c20d02befc377d41445793068908e2250d0'
@@ -158,80 +165,85 @@
 #
 # # call based
 #
 
 
 async def async_get_factory_pool_data(
     factory: spec.Address,
+    *,
     include_balances: bool = False,
+    context: spec.Context = None,
 ) -> list[CurvePoolData]:
     import asyncio
 
     n_pools = await rpc.async_eth_call(
         to_address=factory,
         function_abi=function_abis['pool_count'],
+        context=context,
     )
 
     coroutines = [
-        _async_get_pool_data(p, factory, include_balances=include_balances)
+        _async_get_pool_data(
+            p, factory, include_balances=include_balances, context=context
+        )
         for p in range(n_pools)
     ]
 
     return await asyncio.gather(*coroutines)
 
 
-class CurvePoolData(TypedDict):
-    address: spec.Address
-    tokens: typing.Sequence[spec.Address]
-    symbols: typing.Sequence[str]
-    balances: typing.Sequence[int | float | None]
-
-
 async def _async_get_pool_data(
     p: int,
     factory: spec.Address,
     *,
     include_balances: bool = False,
+    context: spec.Context = None,
 ) -> CurvePoolData:
     pool = await rpc.async_eth_call(
         to_address=factory,
         function_abi=function_abis['pool_list'],
         function_parameters=[p],
+        context=context,
     )
 
     coins = await rpc.async_eth_call(
         to_address=factory,
         function_name='get_coins',  # cannot inline because different new / old
         function_parameters=[pool],
+        context=context,
     )
     coins = [coin for coin in coins if coin not in [eth_address]]
 
     valid_coins = [
         coin
         for coin in coins
         if coin
         not in ['0x0000000000000000000000000000000000000000', eth_address]
     ]
-    symbols = await evm.async_get_erc20s_symbols(
+    symbols_result = await evm.async_get_erc20s_symbols(
         valid_coins,
+        context=context,
+        convert_reverts_to='<UNKNOWN>',
     )
+    symbols = typing.cast(list[str], symbols_result)
 
     if eth_address in coins:
         index = coins.index(eth_address)
         symbols.insert(index, 'ETH')
 
     if include_balances:
         balances: typing.MutableSequence[
             int | float | None
         ] = await evm.async_get_erc20s_balance_of(  # type: ignore
             tokens=valid_coins,
             address=pool,
+            context=context,
         )
         if eth_address in coins:
-            eth_balance = await evm.async_get_eth_balance(pool)
+            eth_balance = await evm.async_get_eth_balance(pool, context=context)
             balances.insert(index, eth_balance)
     else:
         balances = [None for coin in coins]
 
     return {
         'address': pool,
         'tokens': coins,
@@ -248,27 +260,27 @@
 async def async_get_base_pools(
     *,
     start_block: typing.Optional[spec.BlockNumberReference] = None,
     end_block: typing.Optional[spec.BlockNumberReference] = None,
     start_time: tooltime.Timestamp | None = None,
     end_time: tooltime.Timestamp | None = None,
     factory: spec.Address | None = None,
-    provider: spec.ProviderReference = None,
     verbose: bool = False,
+    context: spec.Context = None,
 ) -> spec.DataFrame:
     import asyncio
-    import pandas as pd
+    from ctc.toolbox import pl_utils
 
     start_block, end_block = await evm.async_resolve_block_range(
         start_block=start_block,
         end_block=end_block,
         start_time=start_time,
         end_time=end_time,
         allow_none=True,
-        provider=provider,
+        context=context,
     )
 
     if start_block is None:
         start_block = 12903979
 
     if factory is None:
         factory = pool_factory
@@ -285,30 +297,32 @@
         else:
             factory_start_block = start_block
         coroutine = evm.async_get_events(
             contract_address=factory,
             event_name='BasePoolAdded',
             start_block=factory_start_block,
             end_block=end_block,
-            provider=provider,
+            context=context,
             verbose=verbose,
         )
         coroutines.append(coroutine)
     dfs = await asyncio.gather(*coroutines)
 
-    if typing.TYPE_CHECKING:
-        events = typing.cast(spec.DataFrame, pd.concat(dfs))
+    # TODO: add event args to empty dataframes
+    non_empty_dfs = [df for df in dfs if len(df) > 0]
+    if len(non_empty_dfs) > 0:
+        events = pl_utils.concat(non_empty_dfs)
     else:
-        events = pd.concat(dfs)
+        events = dfs[0]
 
     # format data
-    events = events.sort_index()
-    events = events[['contract_address', 'transaction_hash', 'arg__base_pool']]
+    events = events.sort('block_number')
+    events = events[['block_number', 'transaction_index', 'log_index', 'contract_address', 'transaction_hash', 'arg__base_pool']]
     events = events.rename(
-        columns={
+        {
             'contract_address': 'factory',
             'arg__base_pool': 'pool',
         }
     )
 
     return events
 
@@ -316,15 +330,15 @@
 async def async_get_plain_pools(
     *,
     factory: spec.Address | None = None,
     start_block: typing.Optional[spec.BlockNumberReference] = None,
     end_block: typing.Optional[spec.BlockNumberReference] = None,
     start_time: tooltime.Timestamp | None = None,
     end_time: tooltime.Timestamp | None = None,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     verbose: bool = False,
 ) -> spec.DataFrame:
 
     if start_block is None:
         start_block = 12903979
 
     if factory is None:
@@ -333,29 +347,29 @@
     events = await evm.async_get_events(
         contract_address=factory,
         event_name='PlainPoolDeployed',
         start_block=start_block,
         end_block=end_block,
         start_time=start_time,
         end_time=end_time,
-        provider=provider,
+        context=context,
         verbose=verbose,
     )
     events = events[
         [
             'transaction_hash',
             'contract_address',
             'arg__coins',
             'arg__A',
             'arg__fee',
             'arg__deployer',
         ]
     ]
     events = events.rename(
-        columns={
+        {
             'contract_address': 'factory',
             'arg__coins': 'coins',
             'arg__A': 'A',
             'arg__fee': 'fee',
             'arg__deployer': 'deployer',
         }
     )
@@ -365,34 +379,34 @@
 async def async_get_meta_pools(
     *,
     start_block: typing.Optional[spec.BlockNumberReference] = None,
     end_block: typing.Optional[spec.BlockNumberReference] = None,
     start_time: tooltime.Timestamp | None = None,
     end_time: tooltime.Timestamp | None = None,
     factory: spec.Address | None = None,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     verbose: bool = False,
 ) -> spec.DataFrame:
 
-    import pandas as pd
+    from ctc.toolbox import pl_utils
 
     if factory is None:
         factory = pool_factory
     if factory == pool_factory:
         factories = [old_pool_factory, pool_factory]
     else:
         factories = [factory]
 
     start_block, end_block = await evm.async_resolve_block_range(
         start_block=start_block,
         end_block=end_block,
         start_time=start_time,
         end_time=end_time,
         allow_none=True,
-        provider=provider,
+        context=context,
     )
 
     # gather data
     coroutines = []
     for factory in factories:
         if start_block is None:
             factory_start_block: spec.BlockNumberReference = creation_blocks[
@@ -401,43 +415,49 @@
         else:
             factory_start_block = start_block
         coroutine = evm.async_get_events(
             contract_address=factory,
             event_name='MetaPoolDeployed',
             start_block=factory_start_block,
             end_block=end_block,
-            provider=provider,
+            context=context,
             verbose=verbose,
         )
         coroutines.append(coroutine)
     dfs = await asyncio.gather(*coroutines)
 
-    if typing.TYPE_CHECKING:
-        events = typing.cast(spec.DataFrame, pd.concat(dfs))
+    # TODO: add empty args to dataframes
+    non_empty_dfs = [df for df in dfs if len(df) > 0]
+    if len(non_empty_dfs) > 0:
+        events = pl_utils.concat(non_empty_dfs)
     else:
-        events = pd.concat(dfs)
+        events = dfs[0]
 
     # format data
-    events = events.sort_index()
+    events = events.sort('block_number')
     events = events[
         [
+            'block_number',
+            'transaction_index',
+            'log_index',
             'transaction_hash',
             'contract_address',
             'arg__coin',
             'arg__base_pool',
             'arg__A',
             'arg__fee',
             'arg__deployer',
         ]
     ]
     events = events.rename(
-        columns={
+        {
             'contract_address': 'factory',
             'arg__coin': 'coin',
             'arg__base_pool': 'base_pool',
             'arg__A': 'A',
             'arg__fee': 'fee',
             'arg__deployer': 'deployer',
         }
     )
 
     return events
+
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/curve_utils/pool_metadata.py` & `checkthechain-0.3.4/src/ctc/protocols/curve_utils/pool_metadata.py`

 * *Files 12% similar despite different names*

```diff
@@ -9,15 +9,15 @@
 from . import curve_spec
 
 
 async def async_get_pool_tokens(
     pool: spec.Address,
     *,
     n_tokens: int | None = None,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
 ) -> list[spec.Address]:
     import asyncio
 
     old_pools = {
         '0x79a8c46dea5ada233abaffd40f3a0a2b1e5a4f27',
         '0xa2b47e3d5c44877cca798226b7b8118f9bfb7a56',
         '0x06364f10b501e868329afbc005b3492902d6c763',
@@ -45,89 +45,89 @@
         t = 0
         while True:
             try:
                 token_address = await rpc.async_eth_call(
                     to_address=pool,
                     function_abi=function_abi,
                     function_parameters=[t],
-                    provider=provider,
+                    context=context,
                 )
                 token_addresses.append(token_address)
                 t += 1
             except spec.RpcException:
                 break
     else:
         address_coroutines = [
             rpc.async_eth_call(
                 to_address=pool,
                 function_abi=function_abi,
                 function_parameters=[i],
-                provider=provider,
+                context=context,
             )
             for i in range(n_tokens)
         ]
         token_addresses = await asyncio.gather(*address_coroutines)
 
     return token_addresses
 
 
 async def async_get_token_index(
     token: typing.Union[int, spec.Address, str],
     pool: spec.Address | None = None,
     *,
     metadata: curve_spec.CurvePoolMetadata | None = None,
     n_tokens: int | None = None,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
 ) -> int:
 
     if isinstance(token, int):
         # token already an index
         return token
 
     elif isinstance(token, str) and token.startswith('0x'):
         # token an address
         if metadata is not None:
             pool_addresses = metadata['token_addresses']
         elif pool is not None:
             pool_addresses = await async_get_pool_tokens(
                 pool=pool,
                 n_tokens=n_tokens,
-                provider=provider,
+                context=context,
             )
         else:
             raise Exception('must specify more parameters')
         return pool_addresses.index(token)
 
     elif isinstance(token, str):
         # token a symbol
         if metadata is not None:
             pool_addresses = metadata['token_addresses']
         elif pool is not None:
             pool_addresses = await async_get_pool_tokens(
                 pool=pool,
                 n_tokens=n_tokens,
-                provider=provider,
+                context=context,
             )
         else:
             raise Exception('must specify more parameters')
         token_symbols = await evm.async_get_erc20s_symbols(
             pool_addresses,
-            provider=provider,
+            context=context,
         )
         return token_symbols.index(token)
 
     else:
         raise Exception()
 
 
 async def async_get_pool_metadata(
     pool: spec.Address,
     *,
     n_tokens: int | None = None,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
 ) -> curve_spec.CurvePoolMetadata:
 
     import asyncio
 
     function_abi: spec.FunctionABI = {
         'inputs': [],
         'name': 'A',
@@ -141,33 +141,33 @@
         'type': 'function',
     }
 
     a_coroutine = rpc.async_eth_call(
         to_address=pool,
         function_abi=function_abi,
         function_parameters=[],
-        provider=provider,
+        context=context,
     )
     a_task = asyncio.create_task(a_coroutine)
 
     # get addresses
     token_addresses = await async_get_pool_tokens(
         pool,
         n_tokens=n_tokens,
-        provider=provider,
+        context=context,
     )
 
     # get additional metadata
     symbol_coroutine = evm.async_get_erc20s_symbols(
         token_addresses,
-        provider=provider,
+        context=context,
     )
     decimal_coroutine = evm.async_get_erc20s_decimals(
         token_addresses,
-        provider=provider,
+        context=context,
     )
     symbol_task = asyncio.create_task(symbol_coroutine)
     decimal_task = asyncio.create_task(decimal_coroutine)
 
     # await results
     token_symbols = await symbol_task
     token_decimals = await decimal_task
@@ -176,7 +176,8 @@
     return {
         'token_addresses': token_addresses,
         'token_symbols': token_symbols,
         'token_decimals': token_decimals,
         'A': A,
         # fee:
     }
+
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/curve_utils/pool_parameters.py` & `checkthechain-0.3.4/src/ctc/protocols/curve_utils/pool_parameters.py`

 * *Files 17% similar despite different names*

```diff
@@ -11,137 +11,140 @@
     import tooltime
 
 
 async def async_get_pool_A(
     pool: spec.Address,
     *,
     block: typing.Optional[spec.BlockNumberReference] = None,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
 ) -> int:
 
     result = await rpc.async_eth_call(
         to_address=pool,
         function_abi=curve_spec.pool_function_abis['A'],
         block_number=block,
-        provider=provider,
+        context=context,
     )
     if not isinstance(result, int):
         raise Exception('invalid rpc result')
     return result
 
 
 async def async_get_pool_future_A_time(
     pool: spec.Address,
     *,
     block: typing.Optional[spec.BlockNumberReference] = None,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
 ) -> int:
     result = await rpc.async_eth_call(
         to_address=pool,
         function_abi=curve_spec.pool_function_abis['future_A_time'],
         block_number=block,
-        provider=provider,
+        context=context,
     )
     if not isinstance(result, int):
         raise Exception('invalid rpc result')
     return result
 
 
 async def async_get_pool_initial_A(
     pool: spec.Address,
     *,
     block: typing.Optional[spec.BlockNumberReference] = None,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
 ) -> int:
     result = await rpc.async_eth_call(
         to_address=pool,
         function_abi=curve_spec.pool_function_abis['initial_A'],
         block_number=block,
-        provider=provider,
+        context=context,
     )
     if not isinstance(result, int):
         raise Exception('invalid rpc result')
     return result
 
 
 async def async_get_pool_initial_A_time(
     pool: spec.Address,
     *,
     block: typing.Optional[spec.BlockNumberReference] = None,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
 ) -> int:
     result = await rpc.async_eth_call(
         to_address=pool,
         function_abi=curve_spec.pool_function_abis['initial_A_time'],
         block_number=block,
-        provider=provider,
+        context=context,
     )
     if not isinstance(result, int):
         raise Exception('invalid rpc result')
     return result
 
 
 async def async_get_pool_future_A(
     pool: spec.Address,
     *,
     block: typing.Optional[spec.BlockNumberReference] = None,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
 ) -> int:
     result = await rpc.async_eth_call(
         to_address=pool,
         function_abi=curve_spec.pool_function_abis['future_A'],
         block_number=block,
-        provider=provider,
+        context=context,
     )
     if not isinstance(result, int):
         raise Exception('invalid rpc result')
     return result
 
 
-async def async_get_pool_ramps() -> spec.DataFrame:
+async def async_get_pool_ramps(
+    *,
+    context: spec.Context = None,
+) -> spec.DataFrame:
     """get Ramp events"""
     raise NotImplementedError()
 
 
 async def async_get_A_history(
     pool: spec.Address,
     *,
     start_block: typing.Optional[spec.BlockNumberReference] = None,
     end_block: typing.Optional[spec.BlockNumberReference] = None,
     start_time: tooltime.Timestamp | None = None,
     end_time: tooltime.Timestamp | None = None,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
 ) -> typing.Sequence[float]:
     """get history of pool's A parameter"""
 
     import asyncio
     import numpy as np
-    from ctc.toolbox import pd_utils
+    from ctc.toolbox import pl_utils
 
     start_block, end_block = await evm.async_resolve_block_range(
         start_block=start_block,
         end_block=end_block,
         start_time=start_time,
         end_time=end_time,
         allow_none=True,
-        provider=provider,
+        context=context,
     )
 
     # get ramp events
     pool_start_block = await evm.async_get_contract_creation_block(
         pool,
         verbose=False,
-        provider=provider,
+        context=context,
     )
-    latest_block = await evm.async_get_latest_block_number(provider=provider)
+    latest_block = await evm.async_get_latest_block_number(context=context)
     blocks: spec.NumpyArray = np.arange(start_block, end_block, dtype=int)
     block_timestamps_task = asyncio.create_task(
         evm.async_get_block_timestamps(
             blocks=typing.cast(typing.Sequence[int], blocks),
-            provider=provider,
+            context=context,
         )
     )
 
     event_abi: spec.EventABI = {
         'anonymous': False,
         'inputs': [
             {
@@ -170,30 +173,33 @@
     }
 
     events = await evm.async_get_events(
         contract_address=pool,
         event_abi=event_abi,
         start_block=pool_start_block,
         end_block=latest_block,
+        context=context,
     )
     events = events[
         ['arg__old_A', 'arg__new_A', 'arg__initial_time', 'arg__future_time']
     ]
 
     # initial deployment parameters
-    initial_A = await async_get_pool_initial_A(pool, block=pool_start_block)
+    initial_A = await async_get_pool_initial_A(
+        pool, block=pool_start_block, context=context
+    )
     initial_A_time = 0
-    events.loc[start_block, 0, 0] = [initial_A, initial_A, initial_A_time, 0]
-    events = events.sort_index()
+    events.loc[start_block, 0, 0] = [initial_A, initial_A, initial_A_time, 0]  # type: ignore
+    events = events.sort('block_number', 'log_index')
 
     # interpolate per block
-    events = pd_utils.interpolate_dataframe(
+    events = pl_utils.interpolate(
         events,
+        index_column='block_number',
         end_index=latest_block,
-        level='block_number',
     )
 
     # get blocks timestamps
     block_timestamps = await block_timestamps_task
 
     # need per-block timestamps over a long time range to continue :-\
     A = compute_A(
@@ -259,7 +265,8 @@
     mask = timestamps > future_A_time
     result[mask] = future_A
 
     if typing.TYPE_CHECKING:
         return typing.cast(spec.NumpyArray, result)
     else:
         return result
+
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/ens_utils/cli/ens/exists_command.py` & `checkthechain-0.3.4/src/ctc/protocols/ens_utils/cli/ens/exists_command.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/protocols/ens_utils/cli/ens/owner_command.py` & `checkthechain-0.3.4/src/ctc/protocols/ens_utils/cli/ens/owner_command.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/protocols/ens_utils/cli/ens/records_command.py` & `checkthechain-0.3.4/src/ctc/protocols/ens_utils/cli/ens/records_command.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/protocols/ens_utils/cli/ens/resolve_command.py` & `checkthechain-0.3.4/src/ctc/protocols/ens_utils/cli/ens/resolve_command.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/protocols/ens_utils/cli/ens/reverse_command.py` & `checkthechain-0.3.4/src/ctc/protocols/ens_utils/cli/ens/reverse_command.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/protocols/ens_utils/registrar.py` & `checkthechain-0.3.4/src/ctc/protocols/ens_utils/registrar.py`

 * *Files 15% similar despite different names*

```diff
@@ -7,110 +7,116 @@
 from . import ens_directory
 from . import resolver
 
 
 async def async_get_owner(
     name: str,
     *,
-    provider: spec.ProviderReference = None,
     block: spec.BlockNumberReference | None = None,
+    context: spec.Context = None,
 ) -> str:
     node = resolver.hash_name(name)
     function_abi: spec.FunctionABI = {
         'name': 'owner',
         'inputs': [{'type': 'bytes32'}],
         'outputs': [{'type': 'address'}],
     }
     result = await rpc.async_eth_call(
         to_address=ens_directory.registry,
         function_abi=function_abi,
         function_parameters=[node],
-        provider=provider,
+        context=context,
         block_number=block,
     )
     if not isinstance(result, str):
         raise Exception('invalid rpc result')
     return result
 
 
 async def async_record_exists(
     name: str,
     *,
-    provider: spec.ProviderReference = None,
     block: spec.BlockNumberReference | None = None,
+    context: spec.Context = None,
 ) -> bool:
     node = resolver.hash_name(name)
     function_abi: spec.FunctionABI = {
         'name': 'recordExists',
         'inputs': [{'type': 'bytes32'}],
         'outputs': [{'type': 'bool'}],
     }
     result = await rpc.async_eth_call(
         to_address=ens_directory.registry,
         function_abi=function_abi,
         function_parameters=[node],
-        provider=provider,
+        context=context,
         block_number=block,
     )
     if not isinstance(result, bool):
         raise Exception('invalid rpc result')
     return result
 
 
 async def async_get_resolver(
     name: str,
     *,
-    provider: spec.ProviderReference = None,
     block: spec.BlockNumberReference | None = None,
+    context: spec.Context = None,
 ) -> spec.Address:
     node = resolver.hash_name(name)
     function_abi: spec.FunctionABI = {
         'name': 'resolver',
         'inputs': [{'type': 'bytes32'}],
         'outputs': [{'type': 'address'}],
     }
     result = await rpc.async_eth_call(
         to_address=ens_directory.registry,
         function_abi=function_abi,
         function_parameters=[node],
-        provider=provider,
+        context=context,
         block_number=block,
     )
     if not isinstance(result, str):
         raise Exception('invalid rpc result')
     return result
 
 
-async def async_get_registration_block(name: str) -> int:
+async def async_get_registration_block(
+    name: str, *, context: spec.Context = None
+) -> int:
 
     if not name.endswith('.eth'):
         raise NotImplementedError()
 
     label, *parent = name.split('.')
     parent_node = resolver.hash_name('.'.join(parent))
 
-    registrations: spec.DataFrame = await async_get_registrations()
+    registrations: spec.DataFrame = await async_get_registrations(
+        context=context
+    )
     mask = (registrations['arg__label'] == evm.keccak_text(label)) & (
         registrations['arg__parent_node'] == parent_node
     )
     result = registrations[mask]
 
     if len(result) == 0:
         raise Exception('could not find registration')
 
-    block = result.iloc[0].name[0]
-    block = int(block)
+    block = registrations['block_number'][0]
 
     if not isinstance(block, int):
         raise Exception('invalid rpc result')
 
     return block
 
 
-async def async_get_registrations() -> spec.DataFrame:
+async def async_get_registrations(
+    *,
+    context: spec.Context = None,
+) -> spec.DataFrame:
     event_abi: spec.EventABI = {
         'name': 'NewOwner',
         'inputs': [
             {
                 'indexed': True,
                 'name': 'node',
                 'type': 'bytes32',
@@ -129,10 +135,12 @@
     }
 
     new_owners = await evm.async_get_events(
         contract_address='0x00000000000c2e074ec69a0dfb2997ba6c7d2e1e',
         event_abi=event_abi,
         start_block=9000000,
         verbose=False,
+        context=context,
     )
-    new_owners['arg__parent_node'] = new_owners.pop('arg__node')
+    new_owners = new_owners.rename({'arg__node': 'arg__parent_node'})
     return new_owners
+
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/ens_utils/resolver.py` & `checkthechain-0.3.4/src/ctc/protocols/ens_utils/resolver.py`

 * *Files 18% similar despite different names*

```diff
@@ -21,108 +21,112 @@
         output = evm.keccak(output + label_hash, output_format='raw_hex')
     return '0x' + output
 
 
 async def async_resolve_name(
     name: str,
     *,
-    provider: spec.ProviderReference = None,
     block: spec.BlockNumberReference | None = None,
+    context: spec.Context = None,
 ) -> spec.Address | None:
     name_hash = hash_name(name)
 
     function_abi: spec.FunctionABI = {
         'name': 'addr',
         'inputs': [{'type': 'bytes32'}],
         'outputs': [{'type': 'address'}],
     }
 
     result = await rpc.async_eth_call(
         to_address=ens_directory.resolver,
         block_number=block,
         function_abi=function_abi,
         function_parameters=[name_hash],
-        provider=provider,
+        context=context,
     )
     if not isinstance(result, str):
         raise Exception('invalid rpc result')
 
     if result == '0x0000000000000000000000000000000000000000':
         resolver = await registrar.async_get_resolver(
-            name=name, provider=provider, block=block
+            name=name, block=block, context=context
         )
         if resolver == '0x0000000000000000000000000000000000000000':
             return None
         result = await rpc.async_eth_call(
             to_address=resolver,
             block_number=block,
             function_abi={
                 'name': 'addr',
                 'inputs': [{'type': 'bytes32'}],
                 'outputs': [{'type': 'address'}],
             },
             function_parameters=[name_hash],
-            provider=provider,
+            context=context,
         )
         if not isinstance(result, str):
             raise Exception('invalid rpc result')
 
     return result
 
 
 async def async_resolve_names(
     names: typing.Sequence[str],
     *,
-    provider: spec.ProviderReference = None,
     block: spec.BlockNumberReference | None = None,
+    context: spec.Context = None,
 ) -> typing.Sequence[spec.Address | None]:
 
     import asyncio
 
     coroutines = [
-        async_resolve_name(name=name, provider=provider, block=block)
+        async_resolve_name(name=name, block=block, context=context)
         for name in names
     ]
 
     return await asyncio.gather(*coroutines)
 
 
 async def async_reverse_lookup(
     address: spec.Address,
     *,
-    provider: spec.ProviderReference = None,
     block: spec.BlockNumberReference | None = None,
+    context: spec.Context = None,
 ) -> str:
     function_abi: spec.FunctionABI = {
         'name': 'getNames',
         'inputs': [{'type': 'address[]'}],
         'outputs': [{'type': 'string[]'}],
     }
     names = await rpc.async_eth_call(
         to_address=ens_directory.reverse_records,
         block_number=block,
         function_abi=function_abi,
         function_parameters=[[address]],
-        provider=provider,
+        context=context,
     )
     output = names[0]
     if not isinstance(output, str):
         raise Exception('invalid rpc result')
     return output
 
 
-async def async_name_history() -> None:
+async def async_name_history(
+    *,
+    context: spec.Context = None,
+) -> None:
     raise NotImplementedError()
 
 
 async def async_get_text_record(
     key: str,
     *,
     name: str | None = None,
     node: str | None = None,
+    context: spec.Context = None,
 ) -> str:
 
     if node is None:
         if name is None:
             raise Exception('must specify name or node')
         node = hash_name(name)
 
@@ -135,49 +139,57 @@
         'outputs': [{'name': '', 'type': 'string'}],
     }
 
     result = await rpc.async_eth_call(
         to_address=ens_directory.resolver,
         function_abi=function_abi,
         function_parameters=[node, key],
+        context=context,
     )
     if not isinstance(result, str):
         raise Exception('invalid rpc result')
     return result
 
 
 async def async_get_text_records(
     *,
     name: str | None = None,
     node: str | None = None,
     keys: typing.Sequence[str] | None = None,
+    context: spec.Context = None,
 ) -> dict[str, str]:
     """
     https://docs.ens.domains/ens-improvement-proposals/ensip-5-text-records
     """
     import asyncio
 
     if node is None:
         if name is None:
             raise Exception('must specify name or node')
         node = hash_name(name)
 
     if keys is None:
-        text_changes = await async_get_text_changes(name=name, node=node)
-        keys = list(text_changes['arg__key'].values)
+        text_changes = await async_get_text_changes(
+            name=name, node=node, context=context
+        )
+        keys = text_changes['arg__key'].to_list()
 
-    coroutines = [async_get_text_record(key=key, node=node) for key in keys]
+    coroutines = [
+        async_get_text_record(key=key, node=node, context=context)
+        for key in keys
+    ]
     values = await asyncio.gather(*coroutines)
     return dict(zip(keys, values))
 
 
 async def async_get_text_changes(
     *,
     name: str | None = None,
     node: str | None = None,
+    context: spec.Context = None,
 ) -> spec.DataFrame:
 
     event_abi: spec.EventABI = {
         'name': 'TextChanged',
         'type': 'event',
         'inputs': [
             {
@@ -201,29 +213,33 @@
         ],
     }
 
     events = await evm.async_get_events(
         contract_address=ens_directory.resolver,
         event_abi=event_abi,
         start_block=9000000,
-        verbose=False,
+        verbose=2,
+        context=context,
+        convert_invalid_str_to_none=True,
     )
 
     if node is None:
         if name is None:
             raise Exception('must specify name or node')
         node = hash_name(name)
 
     mask = events['arg__node'] == node
-    return events[mask]
+    return events.filter(mask)
 
 
 async def async_get_content_hash(
     name: str | None = None,
     node: str | None = None,
+    *,
+    context: spec.Context = None,
 ) -> str:
 
     if node is None:
         if name is None:
             raise Exception('must specify name or node')
         node = hash_name(name)
 
@@ -235,21 +251,26 @@
         'outputs': [{'name': '', 'type': 'bytes'}],
     }
 
     result = await rpc.async_eth_call(
         to_address=ens_directory.resolver,
         function_abi=function_abi,
         function_parameters=[node],
+        context=context,
     )
     if not isinstance(result, str):
         raise Exception('invalid rpc result')
     return result
 
 
-async def async_get_expiration(name: str) -> int:
+async def async_get_expiration(
+    name: str,
+    *,
+    context: spec.Context = None,
+) -> int:
 
     if not name.endswith('.eth'):
         raise NotImplementedError('only implemented for .eth domains')
 
     label = name.split('.')[-2]
     label_id = evm.keccak_text(label, output_format='integer')
 
@@ -259,11 +280,13 @@
         'outputs': [{'type': 'uint256'}],
     }
 
     result = await rpc.async_eth_call(
         to_address=ens_directory.base_registrar,
         function_abi=function_abi,
         function_parameters=[label_id],
+        context=context,
     )
     if not isinstance(result, int):
         raise Exception('invalid rpc result')
     return result
+
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/etherscan_utils/abi_crud.py` & `checkthechain-0.3.4/src/ctc/protocols/etherscan_utils/abi_crud.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,28 +1,28 @@
 from __future__ import annotations
 
-import typing
-from typing_extensions import TypedDict
-
 import asyncio
 import json
 import time
+import typing
 
 from ctc import config
 from ctc import evm
 from ctc import spec
 
 from . import url_crud
 
+if typing.TYPE_CHECKING:
+    from typing_extensions import TypedDict
 
-class EtherscanRatelimit(TypedDict):
-    requests_per_second: int | float
-    last_request_time: int | float
-    lock: asyncio.Lock | None
-    recent_results: typing.MutableMapping[spec.Address, spec.ContractABI]
+    class EtherscanRatelimit(TypedDict):
+        requests_per_second: int | float
+        last_request_time: int | float
+        lock: asyncio.Lock | None
+        recent_results: typing.MutableMapping[spec.Address, spec.ContractABI]
 
 
 _etherscan_ratelimit: EtherscanRatelimit = {
     'requests_per_second': 0.2,
     'last_request_time': 0,
     'lock': None,
     'recent_results': {},
@@ -31,27 +31,25 @@
 
 def set_etherscan_ratelimit(requests_per_second: int | float) -> None:
     _etherscan_ratelimit['requests_per_second'] = requests_per_second
 
 
 async def async_get_contract_abi(
     contract_address: spec.Address,
-    network: spec.NetworkReference | None = None,
     *,
+    context: spec.Context = None,
     verbose: bool = True,
 ) -> spec.ContractABI:
     """fetch contract abi using etherscan"""
 
     import aiohttp
 
+    network = config.get_context_chain_id(context)
+
     # process inputs
-    if network is None:
-        network = config.get_default_network()
-    if network is None:
-        raise Exception('must specify network or configure default network')
     if not evm.is_address_str(contract_address):
         raise Exception('not a valid address: ' + str(contract_address))
 
     # create lock
     lock = _etherscan_ratelimit['lock']
     if lock is None:
         lock = asyncio.Lock()
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/etherscan_utils/url_crud.py` & `checkthechain-0.3.4/src/ctc/protocols/etherscan_utils/url_crud.py`

 * *Files 12% similar despite different names*

```diff
@@ -54,102 +54,103 @@
     elif network_name in api_dash_subdomains:
         return 'api-' + block_explorer
     else:
         return 'api.' + block_explorer
 
 
 def create_abi_url(
-    address: spec.Address, network: spec.NetworkReference = 'mainnet'
+    address: spec.Address, network: spec.NetworkReference = 'ethereum'
 ) -> str:
     api_subdomain = get_api_subdomain(network)
     template = url_templates['abi']
     return template.format(api_subdomain=api_subdomain, address=address)
 
 
 def create_address_url(
     address: spec.Address,
-    network: spec.NetworkReference = 'mainnet',
+    network: spec.NetworkReference = 'ethereum',
 ) -> str:
     hostname = get_hostname(network)
     template = url_templates['address']
     return template.format(hostname=hostname, address=address)
 
 
 def create_address_erc20_transfers_url(
     address: spec.Address,
-    network: spec.NetworkReference = 'mainnet',
+    network: spec.NetworkReference = 'ethereum',
 ) -> str:
     hostname = get_hostname(network)
     template = url_templates['address_erc20_transfers']
     return template.format(hostname=hostname, address=address)
 
 
 def create_address_internal_txs_url(
     address: spec.Address,
-    network: spec.NetworkReference = 'mainnet',
+    network: spec.NetworkReference = 'ethereum',
 ) -> str:
     hostname = get_hostname(network)
     template = url_templates['address_internal_txs']
     return template.format(hostname=hostname, address=address)
 
 
 def create_address_holdings_url(
     address: spec.Address,
-    network: spec.NetworkReference = 'mainnet',
+    network: spec.NetworkReference = 'ethereum',
 ) -> str:
     hostname = get_hostname(network)
     template = url_templates['address_holdings']
     return template.format(hostname=hostname, address=address)
 
 
 def create_block_url(
     block: int,
-    network: spec.NetworkReference = 'mainnet',
+    network: spec.NetworkReference = 'ethereum',
 ) -> str:
     hostname = get_hostname(network)
     template = url_templates['block']
     return template.format(hostname=hostname, block=block)
 
 
 def create_token_url(
     token_address: spec.Address,
-    network: spec.NetworkReference = 'mainnet',
+    network: spec.NetworkReference = 'ethereum',
 ) -> str:
     hostname = get_hostname(network)
     template = url_templates['token']
     return template.format(hostname=hostname, token_address=token_address)
 
 
 def create_token_holders_url(
     token_address: spec.Address,
-    network: spec.NetworkReference = 'mainnet',
+    network: spec.NetworkReference = 'ethereum',
 ) -> str:
     hostname = get_hostname(network)
     template = url_templates['token_holders']
     return template.format(hostname=hostname, token_address=token_address)
 
 
 def create_transaction_url(
     transaction_hash: str,
-    network: spec.NetworkReference = 'mainnet',
+    network: spec.NetworkReference = 'ethereum',
 ) -> str:
     hostname = get_hostname(network)
     template = url_templates['transaction']
     return template.format(hostname=hostname, transaction_hash=transaction_hash)
 
 
 def create_transaction_logs_url(
     transaction_hash: str,
-    network: spec.NetworkReference = 'mainnet',
+    network: spec.NetworkReference = 'ethereum',
 ) -> str:
     hostname = get_hostname(network)
     template = url_templates['transaction_logs']
     return template.format(hostname=hostname, transaction_hash=transaction_hash)
 
 
 def create_transaction_state_changes_url(
     transaction_hash: str,
-    network: spec.NetworkReference = 'mainnet',
+    network: spec.NetworkReference = 'ethereum',
 ) -> str:
     hostname = get_hostname(network)
     template = url_templates['transaction_state_changes']
     return template.format(hostname=hostname, transaction_hash=transaction_hash)
+
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/fei_utils/coracle/coracle_deposits.py` & `checkthechain-0.3.4/src/ctc/protocols/rari_utils/fuse_queries/token_state/token_price.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,106 +1,74 @@
 from __future__ import annotations
 
 import typing
 
-from ctc import evm
 from ctc import rpc
 from ctc import spec
-from . import coracle_spec
-from . import coracle_tokens
+from ... import rari_abis
+from .. import pool_metadata
+from .. import token_metadata
 
 
-coracle_function_abis: dict[str, spec.FunctionABI] = {
-    'getDepositsForToken': {
-        'inputs': [
-            {'internalType': 'address', 'name': '_token', 'type': 'address'}
-        ],
-        'name': 'getDepositsForToken',
-        'outputs': [
-            {'internalType': 'address[]', 'name': '', 'type': 'address[]'}
-        ],
-        'stateMutability': 'view',
-        'type': 'function',
-    },
-}
-
-
-async def async_get_tokens_deposits(
-    *,
-    tokens: typing.Optional[typing.Sequence[spec.Address]] = None,
-    block: typing.Optional[spec.BlockReference] = None,
-    provider: spec.ProviderReference = None,
-) -> dict[spec.Address, typing.Tuple[spec.ContractAddress, ...]]:
-    """get all deposits of all tokens in pcv"""
-
-    import asyncio
-
-    if block is None:
-        block = 'latest'
-    block = await evm.async_block_number_to_int(block=block, provider=provider)
-
-    # get tokens in pcv
-    if tokens is None:
-        tokens = await coracle_tokens.async_get_tokens_in_pcv(
-            block=block, provider=provider
-        )
-
-    # get deposits of each token
-    coroutines = []
-    for token in tokens:
-        coroutine = async_get_token_deposits(
-            token=token,
-            block=block,
-            provider=provider,
-        )
-        coroutines.append(coroutine)
-
-    # compile into tokens_deposits
-    results = await asyncio.gather(*coroutines)
-    tokens_deposits = dict(zip(tokens, results))
-    return tokens_deposits
-
-
-async def async_get_token_deposits(
-    token: spec.Address,
-    *,
-    block: typing.Optional[spec.BlockNumberReference] = None,
-    wrapper: bool = False,
-    provider: spec.ProviderReference = None,
-) -> typing.Tuple[spec.ContractAddress, ...]:
-    """get list of a token's deposits"""
-
-    if block is None:
-        block = 'latest'
-    block = await evm.async_block_number_to_int(block=block, provider=provider)
-
-    coracle = coracle_spec.get_coracle_address(wrapper=wrapper, block=block)
+async def async_get_ctoken_exchange_rate(
+    ctoken: spec.Address,
+    block: spec.BlockNumberReference = 'latest',
+) -> int:
     result = await rpc.async_eth_call(
-        to_address=coracle,
+        to_address=ctoken,
+        function_abi=rari_abis.ctoken_function_abis['exchangeRateCurrent'],
         block_number=block,
-        function_abi=coracle_function_abis['getDepositsForToken'],
-        function_parameters={'_token': token},
-        provider=provider,
+        empty_token=None,
     )
-    if not isinstance(result, tuple) or not all(
-        isinstance(item, str) for item in result
-    ):
+    if not isinstance(result, int):
         raise Exception('invalid rpc result')
     return result
 
 
-async def async_get_deposit_token(
-    deposit: spec.ContractAddress,
-    *,
-    block: typing.Optional[spec.BlockNumberReference] = None,
-    provider: spec.ProviderReference = None,
-) -> spec.Address:
-    """get the token address of a deposit"""
-    result = await rpc.async_eth_call(
-        to_address=deposit,
-        block_number=block,
-        function_name='token',
-        provider=provider,
+async def async_get_ctoken_exchange_rate_by_block(
+    ctoken: spec.Address,
+    blocks: typing.Sequence[spec.BlockNumberReference],
+) -> list[int]:
+    return await rpc.async_batch_eth_call(
+        to_address=ctoken,
+        function_abi=rari_abis.ctoken_function_abis['exchangeRateCurrent'],
+        block_numbers=blocks,
+        empty_token=None,
     )
-    if not isinstance(result, str):
-        raise Exception('invalid rpc result')
-    return result
+
+
+async def async_get_ctoken_price(
+    ctoken: spec.Address,
+    *,
+    oracle: spec.Address | None = None,
+    block: spec.BlockNumberReference = 'latest',
+    normalize: bool = True,
+    raise_on_revert: bool = False,
+) -> int | float:
+
+    if oracle is None:
+        oracle = await _async_get_ctoken_oracle(ctoken=ctoken)
+
+    try:
+        result = await rpc.async_eth_call(
+            to_address=oracle,
+            block_number=block,
+            function_abi=rari_abis.oracle_function_abis['getUnderlyingPrice'],
+            function_parameters=[ctoken],
+        )
+        if not isinstance(result, int):
+            raise Exception('invalid rpc result')
+        price: int | float = result
+        if normalize:
+            price /= 1e18
+    except spec.RpcException as e:
+        if raise_on_revert:
+            raise e
+        price = 0
+
+    return price
+
+
+async def _async_get_ctoken_oracle(ctoken: spec.Address) -> spec.Address:
+    comptroller = await token_metadata.async_get_ctoken_comptroller(ctoken)
+    oracle = await pool_metadata.async_get_pool_oracle(comptroller)
+    return oracle
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/fei_utils/coracle/coracle_stats.py` & `checkthechain-0.3.4/src/ctc/db/intake_utils.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,123 +1,100 @@
 from __future__ import annotations
 
 import typing
-from typing_extensions import TypedDict
 
-from ctc import evm
+if typing.TYPE_CHECKING:
+    import toolsql
+
 from ctc import rpc
 from ctc import spec
-from . import coracle_spec
+
+from . import management
+from . import schemas
 
 
-class FeiPcvStats(TypedDict):
-    pcv: int
-    user_fei: int
-    protocol_equity: int
-    valid: bool
+if typing.TYPE_CHECKING:
+    T = typing.TypeVar('T', int, spec.RPCBlock, spec.DBBlock)
 
 
-async def async_get_pcv_stats(
-    block: spec.BlockNumberReference | None = None,
+async def async_is_block_fully_confirmed(
+    block: int,
     *,
-    wrapper: bool = False,
-    provider: spec.ProviderReference = None,
-) -> FeiPcvStats:
-
-    if block is None:
-        block = 'latest'
-    if block is not None:
-        block = await evm.async_block_number_to_int(block=block)
-
-    to_address = coracle_spec.get_coracle_address(
-        wrapper,
-        block=block,
-    )
-    result = await rpc.async_eth_call(
-        function_name='pcvStats',
-        block_number=block,
-        provider=provider,
-        to_address=to_address,
+    context: spec.Context = None,
+    conn: toolsql.AsyncConnection | None,
+) -> bool:
+    """must pass conn=None if not planning on using db"""
+
+    # check whether block is older than newest block in db
+    if conn is not None:
+        max_db_block = await _async_get_max_block_number_in_db(
+            conn=conn, context=context
+        )
+        if max_db_block is not None and block < max_db_block:
+            return True
+
+    # check whether block has enough confirmations
+    rpc_latest_block = await rpc.async_eth_block_number(context=context)
+    required_confirmations = management.get_required_confirmations(
+        context=context
     )
-    return {
-        'pcv': result[0],
-        'user_fei': result[1],
-        'protocol_equity': result[2],
-        'valid': result[3],
-    }
+    return bool(block <= rpc_latest_block - required_confirmations)
 
 
-async def async_get_pcv_stats_by_block(
-    blocks: typing.Sequence[spec.BlockNumberReference],
+async def async_filter_fully_confirmed_blocks(
+    blocks: typing.Sequence[T],
     *,
-    wrapper: bool = False,
-    provider: spec.ProviderReference = None,
-    nullify_invalid: bool = True,
-) -> spec.DataFrame:
-
-    import asyncio
-    import numpy as np
-
-    if blocks is not None:
-        blocks = await evm.async_block_numbers_to_int(blocks=blocks)
-
-    # assemble kwargs
-    provider = rpc.get_provider(provider)
-    if provider['chunk_size'] is None:
-        provider['chunk_size'] = 1
-
-    async def _wrapped_call(
-        block: spec.BlockNumberReference, to_address: spec.Address
-    ) -> typing.Sequence[None | list[typing.Any]]:
-        try:
-            result = await rpc.async_eth_call(
-                function_name='pcvStats',
-                block_number=block,
-                provider=provider,
-                to_address=to_address,
-            )
-            return typing.cast(
-                typing.Sequence[typing.Optional[typing.List[typing.Any]]],
-                result,
-            )
-        except spec.RpcException as e:
-            invalid_message = 'execution reverted: chainlink is down'
-            if (
-                nullify_invalid
-                and len(e.args) > 0
-                and e.args[0].endswith(invalid_message)
-            ):
-                return [None] * 4
-            else:
-                raise e
+    context: spec.Context,
+    conn: toolsql.AsyncConnection | None,
+    latest_block_number: int | None = None,
+) -> typing.Sequence[T]:
 
-    coroutines = []
+    if len(blocks) == 0:
+        return []
+
+    block_numbers = []
     for block in blocks:
-        to_address = coracle_spec.get_coracle_address(
-            wrapper,
-            block=block,
+        if isinstance(block, dict):
+            block_numbers.append(block['number'])
+        elif isinstance(block, int):
+            block_numbers.append(block)
+        else:
+            raise Exception('unknown block format')
+
+    # check whether all blocks older than newest block in db
+    max_block_number = max(block_numbers)
+    if latest_block_number is not None:
+        max_db_block: int | None = latest_block_number
+    else:
+        if conn is None:
+            raise Exception('must provide conn or latest block number')
+        max_db_block = await _async_get_max_block_number_in_db(
+            context=context, conn=conn
         )
-        coroutine = _wrapped_call(block, to_address)
-        coroutines.append(coroutine)
-    result = await asyncio.gather(*coroutines)
-
-    # arrange results
-    transpose = list(zip(*result))
-    data = {}
-    keys = ['pcv', 'user_fei', 'protocol_equity', 'valid']
-    for k, key in enumerate(keys):
-        data[key] = transpose[k]
-
-    as_array = {
-        'pcv': np.array(data['pcv'], dtype=float) / 1e18,
-        'user_fei': np.array(data['user_fei'], dtype=float) / 1e18,
-        'protocol_equity': np.array(data['protocol_equity'], dtype=float)
-        / 1e18,
-        'valid': data['valid'],
-    }
+    if max_db_block is not None and max_db_block > max_block_number:
+        return blocks
+
+    # check whether blocks have enough confirmations
+    if latest_block_number is not None:
+        rpc_latest_block = latest_block_number
+    else:
+        rpc_latest_block = await rpc.async_eth_block_number(context=context)
+    required_confirmations = management.get_required_confirmations(
+        context=context,
+    )
+    max_allowed_block = rpc_latest_block - required_confirmations
+    return [
+        block
+        for block, block_number in zip(blocks, block_numbers)
+        if block_number <= max_allowed_block
+    ]
 
-    # create dataframe
-    import pandas as pd
 
-    df = pd.DataFrame(as_array, index=blocks)
+async def _async_get_max_block_number_in_db(
+    *,
+    context: spec.Context = None,
+    conn: toolsql.AsyncConnection,
+) -> int | None:
+    return await schemas.async_select_max_block_number(
+        conn=conn, context=context
+    )
 
-    return df
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/fei_utils/depth/fei_uniswap_depth.py` & `checkthechain-0.3.4/src/ctc/protocols/uniswap_v2_utils/cli/pool_command.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,89 +1,64 @@
 from __future__ import annotations
 
 import typing
 
-from ctc import evm
-from ctc.protocols import uniswap_v3_utils
+import toolcli
+import toolstr
 
-
-async def async_get_fei_uniswap_pools() -> list[list[typing.Any]]:
-    # TODO: automate
-
-    FEI = '0x956f47f50a910163d8bf957cf5846d573e7f87ca'
-    DAI = '0x6b175474e89094c44da98b954eedeac495271d0f'
-    USDC = '0xa0b86991c6218b36c1d19d4a2e9eb0ce3606eb48'
-
-    # token_in, token_out, fee
-    pools = [
-        [FEI, DAI, 500, 18, 18],
-        [FEI, USDC, 100, 18, 6],
-        [FEI, USDC, 500, 18, 6],
-    ]
-
-    return pools
-
-
-async def async_get_fei_uniswap_pool_price_depth(
-    pools: list[list[typing.Any]] | None = None,
-    prices: typing.Sequence[float] | None = None,
-) -> dict[str, dict[float, float]]:
-    import asyncio
-
-    if pools is None:
-        pools = await async_get_fei_uniswap_pools()
-
-    if prices is None:
-        prices = [
-            0.995,
-            0.993,
-            0.990,
-        ]
-
-    coroutines = {}
-    for price_level in prices:
-        for p in range(len(pools)):
-            (
-                token_in,
-                token_out,
-                fee,
-                token_in_decimals,
-                token_out_decimals,
-            ) = pools[p]
-            swap_kwargs = {
-                'token_in': token_in,
-                'token_out': token_out,
-                'fee': fee,
-                'token_in_decimals': token_in_decimals,
-                'token_out_decimals': token_out_decimals,
-            }
-
-            coroutines[
-                (p, price_level)
-            ] = uniswap_v3_utils.async_get_liquidity_depth(
-                new_price=price_level,
-                **swap_kwargs,
-            )
-
-    depths = await asyncio.gather(*coroutines.values())
-
-    pool_price_depth: dict[str, dict[float, float]] = {}
-    for (p, price_level), depth in zip(coroutines.keys(), depths):
-        token_in, token_out, fee, token_in_decimals, token_out_decimals = pools[
-            p
-        ]
-
-        symbol_in = await evm.async_get_erc20_symbol(token_in)
-        symbol_out = await evm.async_get_erc20_symbol(token_out)
-        pool = (
-            'Uniswap V3 '
-            + symbol_in
-            + '_'
-            + symbol_out
-            + ' '
-            + ('%.2d' % (fee / 100))
-        )
-
-        pool_price_depth.setdefault(pool, {})
-        pool_price_depth[pool][price_level] = depth
-
-    return pool_price_depth
+from ctc.protocols import uniswap_v2_utils
+from ctc.defi.dex_utils.amm_utils import cpmm
+from ctc import spec
+
+
+def get_command_spec() -> toolcli.CommandSpec:
+    return {
+        'f': async_pool_command,
+        'help': 'summarize pool',
+        'args': [
+            {'name': 'pool', 'help': 'pool address'},
+            {
+                'name': '--block',
+                'default': 'latest',
+                'help': 'block number range',
+            },
+            {'name': '--depths', 'help': 'liquidity depths', 'nargs': '+'},
+        ],
+        'examples': [
+            '0xae461ca67b15dc8dc81ce7615e0320da1a9ab8d5 --block 14000000',
+        ],
+    }
+
+
+async def async_pool_command(
+    *,
+    pool: spec.Address,
+    block: str,
+    depths: typing.Sequence[str] | None,
+) -> None:
+    tokens_metadata = await uniswap_v2_utils.async_get_pool_tokens_metadata(
+        pool
+    )
+    x_symbol = tokens_metadata['x_symbol']
+    y_symbol = tokens_metadata['y_symbol']
+    title = 'Uniswap V2 Pool: ' + x_symbol + ' x ' + y_symbol
+    toolstr.print_text_box(title)
+    print('-', x_symbol, 'address:', tokens_metadata['x_address'])
+    print('-', y_symbol, 'address:', tokens_metadata['y_address'])
+    print('-', x_symbol, 'decimals:', tokens_metadata['x_decimals'])
+    print('-', y_symbol, 'decimals:', tokens_metadata['y_decimals'])
+    print()
+    print()
+
+    if depths is not None:
+        depths_float: list[float] | None = [float(depth) for depth in depths]
+    else:
+        depths_float = None
+
+    toolstr.print_header('Pool State')
+    pool_state = await uniswap_v2_utils.async_get_pool_state(pool, block=block)
+    cpmm.print_pool_summary(
+        x_name=x_symbol,
+        y_name=y_symbol,
+        depths=depths_float,
+        **pool_state,
+    )
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/fei_utils/fei_psms.py` & `checkthechain-0.3.4/src/ctc/cli/commands/data/dex/chart_command.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,265 +1,227 @@
 from __future__ import annotations
 
-import time
+import asyncio
+import functools
+import math
 import typing
 
-import tooltime
+import rich.console
+import toolcli
 import toolstr
+import tooltime
 
+from ctc import cli
 from ctc import evm
 from ctc import spec
+from ctc.defi import dex_utils
+from ctc.defi.metric_utils import ohlc_utils
 
 
-address_psms = {
-    '0x2a188f9eb761f70ecea083ba6c2a40145078dfc2': 'DAI PSM',
-    '0xb0e731f036adfdec12da77c15aab0f90e8e45a0e': 'LUSD PSM',
-    '0x5dde9b4b14edf59cb23c1d4579b279846998205e': 'RAI PSM',
-    '0x98e5f5706897074a4664dd3a32eb80242d6e694b': 'ETH PSM',
-}
-
-
-psm_colors = {
-    'ETH PSM': 'mediumslateblue',
-    'RAI PSM': 'mediumspringgreen',
-    'DAI PSM': 'orange',
-    'LUSD PSM': 'dodgerblue',
-    'Old DAI PSM': 'grey',
-}
-
-
-def get_psms(
-    start_block: spec.BlockNumberReference | None = None,
-) -> typing.Mapping[str, spec.Address]:
-    psms = {v: k for k, v in address_psms.items()}
-    if isinstance(start_block, int) and start_block < 14098619:
-        psms['Old DAI PSM'] = '0x210300c158f95e1342fd008ae417ef68311c49c2'
-    return psms
+def get_command_spec() -> toolcli.CommandSpec:
+    return {
+        'f': async_dex_chart_command,
+        'help': 'display candlestick chart of DEX pool trades',
+        'args': [
+            {
+                'name': 'pool',
+                'help': 'Uniswap pool address',
+            },
+            {
+                'name': '--timescale',
+                'help': 'size of candlesticks, e.g. 1h, 1d, or 1w',
+            },
+            {
+                'name': '--invert',
+                'action': 'store_true',
+                'help': 'use inverse of price',
+            },
+            {
+                'name': '--no-volume',
+                'action': 'store_true',
+                'help': 'hide volume data',
+            },
+        ],
+        'examples': [
+            '0xf4ad61db72f114be877e87d62dc5e7bd52df4d9b',
+            '0xf4ad61db72f114be877e87d62dc5e7bd52df4d9b --invert',
+        ],
+    }
 
 
-async def async_get_fei_psm_mints(
+async def async_dex_chart_command(
     *,
-    start_block: spec.BlockNumberReference = 14000000,
-    end_block: spec.BlockNumberReference = 'latest',
-    psms: typing.Mapping[str, spec.Address] | None = None,
-    timestamp: bool = True,
-    normalize: bool = True,
-    include_price: bool = True,
-) -> spec.DataFrame:
-
-    import asyncio
-    import pandas as pd
-
-    if psms is None:
-        psms = get_psms()
-
-    coroutines = []
-    for psm_name, psm_address in psms.items():
-        coroutine = evm.async_get_events(
-            contract_address=psm_address,
-            event_name='Mint',
-            start_block=start_block,
-            end_block=end_block,
-            verbose=False,
-        )
-        coroutines.append(coroutine)
-    results = await asyncio.gather(*coroutines)
-
-    psm_mints = dict(zip(psms.keys(), results))
-    for psm in psm_mints.keys():
-        psm_mints[psm].index = psm_mints[psm].index.get_level_values(
-            'block_number'
-        )
-        psm_mints[psm]['token'] = psm[:-4]
+    pool: spec.Address,
+    invert: bool,
+    timescale: str,
+    no_volume: bool,
+) -> None:
 
-    if typing.TYPE_CHECKING:
-        mints = typing.cast(spec.DataFrame, pd.concat(list(psm_mints.values())))
+    dex = await dex_utils.async_get_dex_class(pool=pool)
+    asset_symbols_task = asyncio.create_task(
+        dex.async_get_pool_asset_symbols(pool=pool)
+    )
+
+    columns = toolcli.get_n_terminal_cols()
+    n_candles = math.floor((columns - 10) / 2)
+    if timescale is None:
+        candle_timescale = '1d'
     else:
-        mints = pd.concat(list(psm_mints.values()))
-    mints = mints.sort_index()
-
-    # add extra fields
-    redeem_blocks = mints.index.values
-    if timestamp:
-        mints['timestamp'] = await evm.async_get_block_timestamps(redeem_blocks)
-    if normalize:
-        mints['arg__amountFeiOut'] = (
-            mints['arg__amountFeiOut'].map(int) / 1e18
-        ).astype(float)
-        mints['arg__amountIn'] = mints['arg__amountIn'].astype(float)
-
-    if include_price:
-        if not normalize:
-            raise Exception('must normalize to compute price')
-        mints['fei_per_token'] = (
-            mints['arg__amountFeiOut'] / mints['arg__amountIn'] * 1e18
+        candle_timescale = timescale
+    candle_seconds = tooltime.timelength_to_seconds(candle_timescale)
+    window_seconds = candle_seconds * n_candles
+
+    window_end = tooltime.create_timestamp_seconds()
+    window_start = (
+        math.floor((window_end - window_seconds) / candle_seconds)
+        * candle_seconds
+    )
+    start_block = await evm.async_get_block_of_timestamp(window_start) - 1
+    end_block = await evm.async_get_latest_block_number()
+
+    # get data
+    swaps = await dex_utils.async_get_pool_trades(
+        pool,
+        start_block=start_block,
+        end_block=end_block,
+        normalize=True,
+        include_volumes=True,
+        include_prices=True,
+    )
+
+    # compute candlesticks
+    prices = swaps['price__0__per__1'].to_numpy()
+    x_volumes = swaps['volume__0'].to_numpy()
+    if invert:
+        prices = 1 / prices
+    block_numbers = swaps['block_number'].to_list()
+    block_timestamps = await evm.async_get_block_timestamps(
+        block_numbers,
+        context={'provider': {'chunk_size': 1}},
+    )
+    ohlc = ohlc_utils.compute_ohlc(
+        values=list(prices),
+        indices=block_timestamps,
+        bin_size=candle_seconds,
+        volumes=list(x_volumes),
+    )
+    ohlc = ohlc[-n_candles:]
+
+    min_price = typing.cast(typing.Union[int, float], min(prices))
+    max_price = typing.cast(typing.Union[int, float], max(prices))
+    min_time = typing.cast(typing.Union[int, float], ohlc['bin'][0])
+    max_time = typing.cast(typing.Union[int, float], ohlc['bin'][-1] + candle_seconds)
+    render_grid = toolstr.create_grid(
+        n_rows=20,
+        n_columns=n_candles * 2,
+        xmin=min_time - 0.05 * (max_time - min_time),
+        xmax=max_time + 0.05 * (max_time - min_time),
+        ymin=min_price - 0.05 * (max_price - min_price),
+        ymax=max_price + 0.05 * (max_price - min_price),
+    )
+    sample_grid = toolstr.create_grid(sample_mode='quadrants', **render_grid)
+    result = toolstr.raster_candlesticks(ohlc.rows(), sample_grid, render_grid)
+    raster = result['raster']
+    color_grid = result['color_grid']
+
+    as_str = toolstr.render_supergrid(
+        raster,
+        char_dict='quadrants',
+        color_grid=color_grid,
+        color_map=toolstr.candlestick_color_map,
+    )
+
+    console = rich.console.Console(theme=rich.theme.Theme(inherit=False))
+
+    styles = cli.get_cli_styles()
+    tick_label_style = 'bold'
+    chrome_style = '#888888'
+
+    y_axis = toolstr.render_y_axis(
+        grid=render_grid,
+        tick_label_style=tick_label_style,
+        chrome_style=chrome_style,
+    )
+    y_axis_width = rich.text.Text.from_markup(y_axis.split('\n')[0]).cell_len
+    graph = toolstr.concatenate_blocks([y_axis, as_str])
+
+    formatter = functools.partial(
+        toolstr.format_timestamp,
+        representation='TimestampDate',
+    )
+    x_axis = toolstr.render_x_axis(
+        grid=render_grid,
+        formatter=formatter,
+        tick_label_style=tick_label_style,
+        chrome_style=chrome_style,
+    )
+    x_axis = toolstr.indent_block(x_axis, indent=y_axis_width)
+
+    # compute volume
+    if not no_volume:
+        ymax = float(ohlc['volume'].max()) * 1.1  # type: ignore
+        volume_render_grid = toolstr.create_grid(
+            n_rows=5,
+            n_columns=n_candles * 2,
+            xmin=render_grid['xmin'],
+            xmax=render_grid['xmax'],
+            ymin=0 - ymax / 9,
+            ymax=ymax,
+        )
+        volume_sample_grid = toolstr.create_grid(
+            sample_mode='quadrants',
+            **volume_render_grid,
+        )
+        volume_raster = toolstr.raster_bar_chart(
+            values=ohlc['volume'].to_list(),
+            grid=volume_sample_grid,
+            bar_width=1,
+            bar_gap=3,
+            start_gap=1,
+        )
+        volume_y_axis = toolstr.render_y_axis(
+            grid=volume_render_grid,
+            n_ticks=1,
+            tick_label_style=tick_label_style,
+            chrome_style=chrome_style,
+        )
+
+    # wait for metadata
+    asset_symbols = await asset_symbols_task
+
+    if len(asset_symbols) != 2:
+        raise Exception('can only display candlesticks for pools with 2 assets')
+
+    # print output
+    token0 = asset_symbols[0]
+    token1 = asset_symbols[1]
+    toolstr.print_text_box(
+        token0 + '-' + token1 + ' ' + dex.get_dex_name() + ' Pool',
+        style=styles['title'],
+    )
+    cli.print_bullet(key='pool address', value=pool)
+    cli.print_bullet(key='each candle', value=candle_timescale)
+    cli.print_bullet(key='n_candles', value=n_candles)
+    if invert:
+        cli.print_bullet(
+            key='price units', value=str(token1) + ' per ' + str(token0)
         )
-        mints['token_per_fei'] = 1 / mints['fei_per_token']
-
-    return mints
-
-
-async def async_get_fei_psm_redemptions(
-    *,
-    start_block: spec.BlockNumberReference = 14000000,
-    end_block: spec.BlockNumberReference = 'latest',
-    psms: typing.Mapping[str, spec.Address] | None = None,
-    timestamp: bool = True,
-    normalize: bool = True,
-    include_price: bool = True,
-) -> spec.DataFrame:
-    import asyncio
-    import pandas as pd
-
-    if psms is None:
-        psms = get_psms()
-
-    coroutines = []
-    for psm_name, psm_address in psms.items():
-        coroutine = evm.async_get_events(
-            contract_address=psm_address,
-            event_name='Redeem',
-            start_block=start_block,
-            end_block=end_block,
-            verbose=False,
-        )
-        coroutines.append(coroutine)
-    results = await asyncio.gather(*coroutines)
-
-    psm_redeems = dict(zip(psms.keys(), results))
-    for psm in psm_redeems.keys():
-        psm_redeems[psm].index = psm_redeems[psm].index.get_level_values(
-            'block_number'
-        )
-        psm_redeems[psm]['token'] = psm[:-4]
-
-    data = pd.concat(list(psm_redeems.values()))
-    if typing.TYPE_CHECKING:
-        redemptions = typing.cast(spec.DataFrame, data)
     else:
-        redemptions = data
-    redemptions = redemptions.sort_index()
-
-    # add extra fields
-    redeem_blocks = redemptions.index.values
-    if timestamp:
-        redemptions['timestamp'] = await evm.async_get_block_timestamps(
-            redeem_blocks
+        cli.print_bullet(
+            key='price units', value=str(token0) + ' per ' + str(token1)
         )
-    if normalize:
-        redemptions['arg__amountFeiIn'] = (
-            redemptions['arg__amountFeiIn'].map(int) / 1e18
-        ).astype(float)
-        redemptions['arg__amountAssetOut'] = redemptions[
-            'arg__amountAssetOut'
-        ].astype(float)
-
-    if include_price:
-        if not normalize:
-            raise Exception('must normalize to compute price')
-        redemptions['fei_per_token'] = (
-            redemptions['arg__amountFeiIn']
-            / redemptions['arg__amountAssetOut']
-            * 1e18
-        )
-        redemptions['token_per_fei'] = 1 / redemptions['fei_per_token']
-
-    return redemptions
-
-
-def print_fei_psm_mints(
-    mints: spec.DataFrame, *, limit: int = 30, verbose: bool = False
-) -> None:
-
-    labels = [
-        'block',
-        'age',
-        'token',
-        'FEI',
-        'total',
-    ]
-    if verbose:
-        labels.append('hash')
-
-    mints = mints.iloc[-limit:].copy()
-    mints['cummulative'] = mints['arg__amountFeiOut'].cumsum()
-    now = int(time.time())
-    rows = []
-    for block, mint in mints.iterrows():
-        age = now - mint['timestamp']
-        age_str = tooltime.timelength_to_phrase(age)
-        age_str = ' '.join(age_str.split(' ')[:4])
-        age_str = age_str.rstrip(',')
-
-        row = [
-            #         tooltime.convert_timestamp(row['timestamp'], 'TimestampISOPretty'),
-            str(block),
-            age_str,
-            mint['token'],
-            mint['arg__amountFeiOut'],
-            mint['cummulative'],
-        ]
-
-        if verbose:
-            row.append(mint['transaction_hash'])
-
-        rows.append(row)
-
-    toolstr.print_text_box('Recent Mints')
+    if not no_volume:
+        cli.print_bullet(key='volume units', value=token0)
     print()
-    format = {
-        'order_of_magnitude': True,
-        'trailing_zeros': True,
-        'oom_blank': ' ',
-    }
-    toolstr.print_table(rows, labels=labels, format=format)
-
+    console.print(graph)
 
-def print_fei_psm_redemptions(
-    redemptions: spec.DataFrame,
-    *,
-    limit: int = 30,
-    verbose: bool = False,
-) -> None:
-
-    labels = [
-        'block',
-        'age',
-        'token',
-        'FEI',
-        'total',
-    ]
-    if verbose:
-        labels.append('hash')
-
-    redemptions = redemptions.iloc[-limit:].copy()
-    redemptions['cummulative'] = redemptions['arg__amountFeiIn'].cumsum()
-    now = int(time.time())
-    rows = []
-    for block, redeem in redemptions.iterrows():
-        age = now - redeem['timestamp']
-        age_str = tooltime.timelength_to_phrase(age)
-        age_str = ' '.join(age_str.split(' ')[:4])
-        age_str = age_str.rstrip(',')
-
-        row = [
-            #         tooltime.convert_timestamp(row['timestamp'], 'TimestampISOPretty'),
-            str(block),
-            age_str,
-            redeem['token'],
-            redeem['arg__amountFeiIn'],
-            redeem['cummulative'],
-        ]
-
-        if verbose:
-            row.append(redeem['transaction_hash'])
-
-        rows.append(row)
+    if not no_volume:
+        volume_bars_str = toolstr.render_supergrid(
+            volume_raster, char_dict='quadrants'
+        )
+        volume_graph = toolstr.concatenate_blocks(
+            [volume_y_axis, volume_bars_str]
+        )
+        toolstr.print(volume_graph)
 
-    toolstr.print_text_box('Recent Redeems')
-    print()
-    format = {
-        'order_of_magnitude': True,
-        'trailing_zeros': True,
-        'oom_blank': ' ',
-    }
-    toolstr.print_table(rows, labels=labels, format=format)
+    # print x axis
+    console.print(x_axis)
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/fourbyte_utils/cli/fourbyte_build_command.py` & `checkthechain-0.3.4/src/ctc/protocols/fourbyte_utils/cli/fourbyte_build_command.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/protocols/fourbyte_utils/cli/fourbyte_command.py` & `checkthechain-0.3.4/src/ctc/protocols/fourbyte_utils/cli/fourbyte_command.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/protocols/fourbyte_utils/fourbyte_db/fourbyte_schema_defs.py` & `checkthechain-0.3.4/src/ctc/protocols/fourbyte_utils/fourbyte_db/fourbyte_schema_defs.py`

 * *Files 9% similar despite different names*

```diff
@@ -2,15 +2,15 @@
 
 import typing
 
 if typing.TYPE_CHECKING:
     import toolsql
 
 
-fourbyte_schema: toolsql.DBSchema = {
+fourbyte_schema: toolsql.DBSchemaShorthand = {
     'tables': {
         'function_signatures': {
             'columns': [
                 {
                     'name': 'id',
                     'type': 'Integer',
                     'primary': True,
@@ -28,15 +28,15 @@
                 {
                     'name': 'text_signature',
                     'type': 'Text',
                     'index': True,
                 },
                 {
                     'name': 'bytes_signature',
-                    'type': 'Text',
+                    'type': 'Binary',
                     'index': True,
                 },
             ],
         },
         'event_signatures': {
             'columns': [
                 {
@@ -57,14 +57,14 @@
                 {
                     'name': 'text_signature',
                     'type': 'Text',
                     'index': True,
                 },
                 {
                     'name': 'bytes_signature',
-                    'type': 'Text',
+                    'type': 'Binary',
                     'index': True,
                 },
             ],
         },
     },
 }
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/fourbyte_utils/fourbyte_queries/general_queries.py` & `checkthechain-0.3.4/src/ctc/protocols/fourbyte_utils/fourbyte_queries/general_queries.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,90 +1,91 @@
 from __future__ import annotations
 
 import typing
 
+from ctc import spec
 from .. import fourbyte_db
 from .. import fourbyte_spec
 from . import local_queries
 from . import remote_queries
 
 
 async def async_query_function_signatures(
     hex_signature: typing.Optional[str] = None,
     *,
     id: typing.Optional[int] = None,
-    bytes_signature: typing.Optional[str] = None,
+    # bytes_signature: typing.Optional[str] = None,
     text_signature: typing.Optional[str] = None,
     use_local: bool = True,
     use_remote: bool = True,
+    context: spec.Context = None,
 ) -> typing.Sequence[fourbyte_spec.Entry]:
-
     if not use_local and not use_remote:
         raise Exception('should use at least one of use_local or use_remote')
 
     if use_local:
         result = await local_queries.async_query_local_function_signatures(
             id=id,
-            bytes_signature=bytes_signature,
+            # bytes_signature=bytes_signature,
             hex_signature=hex_signature,
             text_signature=text_signature,
+            context={},
         )
         if result is not None and len(result) > 0:
             return result
 
     if use_remote:
         result = await remote_queries.async_query_remote_function_signatures(
             id=id,
-            bytes_signature=bytes_signature,
+            # bytes_signature=bytes_signature,
             hex_signature=hex_signature,
             text_signature=text_signature,
         )
 
         # type ignoring because of mypy bug
-        await fourbyte_db.async_intake_function_signatures(
-            typing.cast(typing.Sequence[fourbyte_spec.PartialEntry], result)  # type: ignore
-        )
+        await fourbyte_db.async_intake_function_signatures(result)  # type: ignore
 
         return result
 
     return []
 
 
 async def async_query_event_signatures(
     hex_signature: typing.Optional[str] = None,
     *,
     id: typing.Optional[int] = None,
-    bytes_signature: typing.Optional[str] = None,
+    # bytes_signature: typing.Optional[str] = None,
     text_signature: typing.Optional[str] = None,
     use_local: bool = True,
     use_remote: bool = True,
 ) -> typing.Sequence[fourbyte_spec.Entry]:
-
     if not use_local and not use_remote:
         raise Exception('should use at least one of use_local or use_remote')
 
     if use_local:
         result = await local_queries.async_query_local_event_signatures(
             id=id,
-            bytes_signature=bytes_signature,
+            # bytes_signature=bytes_signature,
             hex_signature=hex_signature,
             text_signature=text_signature,
+            context={},
         )
         if result is not None and len(result) > 0:
             return result
 
     if use_remote:
         result = await remote_queries.async_query_remote_event_signatures(
             id=id,
-            bytes_signature=bytes_signature,
+            # bytes_signature=bytes_signature,
             hex_signature=hex_signature,
             text_signature=text_signature,
         )
 
         # type ignoring because of mypy bug
         await fourbyte_db.async_intake_event_signatures(
-            typing.cast(typing.Sequence[fourbyte_spec.PartialEntry], result)  # type: ignore
+            typing.cast(typing.Sequence[fourbyte_spec.PartialEntry], result)
         )
 
         return result
 
     return []
+
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/fourbyte_utils/fourbyte_queries/remote_queries.py` & `checkthechain-0.3.4/src/ctc/protocols/fourbyte_utils/fourbyte_queries/remote_queries.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,23 +1,22 @@
 from __future__ import annotations
 
 import time
 import typing
-from typing_extensions import TypedDict
-
-if typing.TYPE_CHECKING:
-    import asyncio
 
 from .. import fourbyte_spec
 
+if typing.TYPE_CHECKING:
+    import asyncio
+    from typing_extensions import TypedDict
 
-class FourbyteRatelimit(TypedDict):
-    requests_per_second: int | float
-    last_request_time: int | float
-    lock: asyncio.Lock | None
+    class FourbyteRatelimit(TypedDict):
+        requests_per_second: int | float
+        last_request_time: int | float
+        lock: asyncio.Lock | None
 
 
 _4byte_ratelimit: FourbyteRatelimit = {
     'lock': None,
     'last_request_time': 0,
     'requests_per_second': 4.0,
 }
@@ -26,15 +25,14 @@
 async def async_query_remote_function_signatures(
     hex_signature: typing.Optional[str] = None,
     *,
     id: typing.Optional[int] = None,
     bytes_signature: typing.Optional[str] = None,
     text_signature: typing.Optional[str] = None,
 ) -> typing.Sequence[fourbyte_spec.Entry]:
-
     import aiohttp
 
     # get url template
     if id is not None:
         url_template = fourbyte_spec.endpoints['function_id']
     elif hex_signature is not None:
         url_template = fourbyte_spec.endpoints['function_hex']
@@ -74,15 +72,14 @@
                     + str(time_to_sleep)
                     + ' seconds (build local 4byte db to avoid)'
                 )
             await asyncio.sleep(time_to_sleep)
 
         # perform request
         async with aiohttp.ClientSession() as session:
-
             # acquire, and retry if initial bad response
             async with session.get(url) as response:
                 if response.status == 502:
                     await asyncio.sleep(3)
                 else:
                     result = await response.json()
             async with session.get(url) as response:
@@ -100,15 +97,14 @@
 async def async_query_remote_event_signatures(
     hex_signature: typing.Optional[str] = None,
     *,
     id: typing.Optional[int] = None,
     bytes_signature: typing.Optional[str] = None,
     text_signature: typing.Optional[str] = None,
 ) -> typing.Sequence[fourbyte_spec.Entry]:
-
     import aiohttp
 
     # get url template
     if id is not None:
         url_template = fourbyte_spec.endpoints['event_id']
     elif hex_signature is not None:
         url_template = fourbyte_spec.endpoints['event_hex']
@@ -130,7 +126,8 @@
     async with aiohttp.ClientSession() as session:
         async with session.get(url) as response:
             result = await response.json()
             if id is not None:
                 return [result]
             else:
                 return result['results']  # type: ignore
+
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/fourbyte_utils/fourbyte_scrape.py` & `checkthechain-0.3.4/src/ctc/protocols/fourbyte_utils/fourbyte_scrape.py`

 * *Files 1% similar despite different names*

```diff
@@ -19,15 +19,15 @@
 
     if signature_data is None:
         # TODO: smarter detection of what is currently in database
         print('building function signatures db from scratch, may take awhile')
         signature_data = await async_scrape_function_signatures()
 
     await fourbyte_db.async_intake_function_signatures(
-        function_signatures=signature_data
+        function_signatures=signature_data  # type: ignore
     )
 
 
 async def async_build_event_signatures_dataset(
     signature_data: typing.Sequence[fourbyte_spec.PartialEntry]
     | typing.Sequence[fourbyte_spec.Entry]
     | None = None,
@@ -35,15 +35,15 @@
 
     if signature_data is None:
         # TODO: smarter detection of what is currently in database
         print('building event signatures db from scratch, may take awhile')
         signature_data = await async_scrape_event_signatures()
 
     await fourbyte_db.async_intake_event_signatures(
-        event_signatures=signature_data
+        event_signatures=signature_data,  # type: ignore
     )
 
 
 #
 # # entry scraping functions
 #
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/fourbyte_utils/fourbyte_spec.py` & `checkthechain-0.3.4/src/ctc/protocols/fourbyte_utils/fourbyte_spec.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,12 +1,28 @@
 from __future__ import annotations
 
 import os
+import typing
 
-from typing_extensions import TypedDict
+if typing.TYPE_CHECKING:
+    from typing_extensions import TypedDict
+
+    class Entry(TypedDict):
+        id: int
+        created_at: str
+        text_signature: str
+        hex_signature: str
+        bytes_signature: str
+
+    class PartialEntry(TypedDict, total=False):
+        id: int
+        created_at: str
+        text_signature: str
+        hex_signature: str
+        bytes_signature: str
 
 
 root_url = 'https://www.4byte.directory'
 
 endpoints = {
     'functions': root_url + '/api/v1/signatures/',
     'function_id': root_url + '/api/v1/signatures/{id}',
@@ -20,34 +36,19 @@
     'event_hex': root_url
     + '/api/v1/event-signatures/?hex_signature={hex_signature}',
     'event_text': root_url
     + '/api/v1/event-signatures/?text_signature={text_signature}',
 }
 
 
-class Entry(TypedDict):
-    id: int
-    created_at: str
-    text_signature: str
-    hex_signature: str
-    bytes_signature: str
-
-
-class PartialEntry(TypedDict, total=False):
-    id: int
-    created_at: str
-    text_signature: str
-    hex_signature: str
-    bytes_signature: str
-
-
 def get_default_path(datatype: str) -> str:
     import ctc.config
 
     if datatype not in ['function_signatures', 'event_signatures']:
         raise Exception('unknown datatype: ' + str(datatype))
 
     return os.path.join(
         ctc.config.get_data_dir(),
         '4byte',
         datatype + '.json',
     )
+
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/g_uni_utils/crud.py` & `checkthechain-0.3.4/src/ctc/protocols/g_uni_utils/crud.py`

 * *Files 18% similar despite different names*

```diff
@@ -22,44 +22,57 @@
         'constant': True,
         'inputs': [],
         'name': 'token1',
         'outputs': [{'internalType': 'address', 'name': '', 'type': 'address'}],
         'payable': False,
         'stateMutability': 'view',
         'type': 'function',
-    }
+    },
 }
 
 
 async def async_get_tokens(
     g_uni_pool: spec.Address,
+    *,
+    context: spec.Context = None,
 ) -> tuple[spec.Address, spec.Address]:
     return await asyncio.gather(
-        rpc.async_eth_call(to_address=g_uni_pool, function_name='token0'),
-        rpc.async_eth_call(to_address=g_uni_pool, function_name='token1'),
+        rpc.async_eth_call(
+            to_address=g_uni_pool, function_name='token0', context=context
+        ),
+        rpc.async_eth_call(
+            to_address=g_uni_pool, function_name='token1', context=context
+        ),
     )
 
 
 async def async_get_token_balances(
     g_uni_pool: spec.Address,
+    *,
     normalize: bool = True,
+    context: spec.Context = None,
 ) -> typing.Sequence[int | float]:
     balances_coroutine = rpc.async_eth_call(
         to_address=g_uni_pool,
         function_name='getUnderlyingBalances',
+        context=context,
     )
     balances_task = asyncio.create_task(balances_coroutine)
 
     if normalize:
-        tokens_coroutine = async_get_tokens(g_uni_pool)
+        tokens_coroutine = async_get_tokens(
+            g_uni_pool,
+            context=context,
+        )
         tokens_task = asyncio.create_task(tokens_coroutine)
 
         return await evm.async_normalize_erc20s_quantities(
             quantities=(await balances_task),
             tokens=(await tokens_task),
+            context=context,
         )
 
     else:
 
         result = await balances_task
         if not isinstance(result, (tuple, list)) or not all(
             isinstance(item, int) for item in result
@@ -69,42 +82,47 @@
 
 
 async def async_get_token_balances_by_block(
     g_uni_pool: spec.Address,
     blocks: typing.Sequence[spec.BlockNumberReference],
     *,
     normalize: bool = True,
+    context: spec.Context = None,
 ) -> typing.Sequence[typing.Sequence[int | float]]:
     balances_coroutine = rpc.async_batch_eth_call(
         to_address=g_uni_pool,
         function_name='getUnderlyingBalances',
         block_numbers=blocks,
+        context=context,
     )
     balances_task = asyncio.create_task(balances_coroutine)
 
     if normalize:
-        tokens_coroutine = async_get_tokens(g_uni_pool)
+        tokens_coroutine = async_get_tokens(g_uni_pool, context=context)
         tokens_task = asyncio.create_task(tokens_coroutine)
 
         balances = await balances_task
         token0_balances, token1_balances = list(zip(*balances))
 
         # normalize
         tokens = await tokens_task
         token0_coroutine = evm.async_normalize_erc20_quantities_by_block(
             quantities=token0_balances,
             token=tokens[0],
             blocks=blocks,
+            context=context,
         )
         token1_coroutine = evm.async_normalize_erc20_quantities_by_block(
             quantities=token1_balances,
             token=tokens[1],
             blocks=blocks,
+            context=context,
         )
         token0_task = asyncio.create_task(token0_coroutine)
         token1_task = asyncio.create_task(token1_coroutine)
 
         result = await asyncio.gather(token0_task, token1_task)
         return list(list(item) for item in zip(*result))
 
     else:
         return await balances_task
+
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/gnosis_utils/README.md` & `checkthechain-0.3.4/src/ctc/protocols/gnosis_utils/README.md`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/protocols/gnosis_utils/cli/gnosis_command.py` & `checkthechain-0.3.4/src/ctc/protocols/gnosis_utils/cli/gnosis_command.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/protocols/gnosis_utils/safe_events.py` & `checkthechain-0.3.4/src/ctc/protocols/gnosis_utils/safe_events.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,93 +1,111 @@
 from __future__ import annotations
 
 import ast
+import typing
 
 from ctc import evm
 from ctc import spec
 from . import safe_spec
 
 
-async def async_get_safe_setup(safe_address: spec.Address) -> spec.Series | None:
-    creation_block = await evm.async_get_contract_creation_block(safe_address)
+async def async_get_safe_setup(
+    safe_address: spec.Address,
+    *,
+    context: spec.Context = None,
+) -> typing.Mapping[str, typing.Any] | None:
+    creation_block = await evm.async_get_contract_creation_block(safe_address, context=context)
     events = await evm.async_get_events(
         safe_address,
         event_abi=safe_spec.event_abis['SafeSetup'],
         verbose=False,
         start_block=creation_block,
         end_block=creation_block,
+        context=context,
     )
     if len(events) == 0:
         return None
-    setup: spec.Series = events.iloc[0].copy()
+    setup = events[:1].to_dicts()[0]
     setup['arg__owners'] = ast.literal_eval(setup['arg__owners'])
     return setup
 
 
 async def async_get_safe_executions(
     safe_address: spec.Address,
     *,
     start_block: spec.BlockReference | None = None,
     end_block: spec.BlockReference | None = None,
+    context: spec.Context = None,
 ) -> spec.DataFrame:
     return await evm.async_get_events(
         safe_address,
         event_abi=safe_spec.event_abis['ExecutionSuccess'],
         start_block=start_block,
         end_block=end_block,
         verbose=False,
+        context=context,
     )
 
 
 async def async_get_safe_owner_adds(
     safe_address: spec.Address,
     *,
     start_block: spec.BlockReference | None = None,
     end_block: spec.BlockReference | None = None,
+    context: spec.Context = None,
 ) -> spec.DataFrame:
     return await evm.async_get_events(
         safe_address,
         event_abi=safe_spec.event_abis['AddedOwner'],
         start_block=start_block,
         end_block=end_block,
         verbose=False,
+        context=context,
     )
 
 
 async def async_get_safe_owner_removes(
     safe_address: spec.Address,
     *,
     start_block: spec.BlockReference | None = None,
     end_block: spec.BlockReference | None = None,
+    context: spec.Context = None,
 ) -> spec.DataFrame:
     return await evm.async_get_events(
         safe_address,
         event_abi=safe_spec.event_abis['RemovedOwner'],
         start_block=start_block,
         end_block=end_block,
         verbose=False,
+        context=context,
     )
 
 
 async def async_get_safe_threshold_changes(
     safe_address: spec.Address,
     *,
     start_block: spec.BlockReference | None = None,
     end_block: spec.BlockReference | None = None,
+    context: spec.Context = None,
 ) -> spec.DataFrame:
     return await evm.async_get_events(
         safe_address,
         event_abi=safe_spec.event_abis['ChangedThreshold'],
         start_block=start_block,
         end_block=end_block,
         verbose=False,
+        context=context,
     )
 
 
 async def async_get_safe_guard_changes(
     safe_address: spec.Address,
+    *,
+    context: spec.Context = None,
 ) -> spec.DataFrame:
     return await evm.async_get_events(
         safe_address,
         event_abi=safe_spec.event_abis['ChangedGuard'],
         verbose=False,
+        context=context,
     )
+
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/gnosis_utils/safe_factory_events.py` & `checkthechain-0.3.4/src/ctc/protocols/gnosis_utils/safe_factory_events.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,45 +1,50 @@
 from __future__ import annotations
 
 import asyncio
-import typing
 
 from ctc import config
 from ctc import evm
 from ctc import spec
 from . import safe_spec
 
 
 async def async_get_all_safes(
     *,
     start_block: spec.BlockReference | None = None,
     end_block: spec.BlockReference | None = None,
-) -> typing.Sequence[safe_spec.GnosisSafeCreation]:
+    context: spec.Context = None,
+) -> spec.DataFrame:
+
+    import polars as pl
 
     safes__1_1, safes__1_3 = await asyncio.gather(
-        async_get_all_safes__1_1(start_block=start_block, end_block=end_block),
-        async_get_all_safes__1_3(start_block=start_block, end_block=end_block),
+        async_get_all_safes__1_1(
+            start_block=start_block, end_block=end_block, context=context
+        ),
+        async_get_all_safes__1_3(
+            start_block=start_block, end_block=end_block, context=context
+        ),
     )
 
-    return [
-        item
-        for safes in [safes__1_1, safes__1_3]
-        for item in safes
-    ]
+    return pl.concat([safes__1_1, safes__1_3])
 
 
 async def async_get_all_safes__1_1(
     factory: spec.Address | None = None,
     *,
     start_block: spec.BlockReference | None = None,
     end_block: spec.BlockReference | None = None,
-) -> typing.Sequence[safe_spec.GnosisSafeCreation]:
+    context: spec.Context | None = None,
+) -> spec.DataFrame:
 
+    import polars as pl
+
+    chain_id = config.get_context_chain_id(context)
     if factory is None:
-        chain_id = config.get_default_network()
         if (
             chain_id not in safe_spec.deployments
             or 'factory__1.1.1' not in safe_spec.deployments[chain_id]
         ):
             raise NotImplementedError(
                 'must manually specify factory addresses, see '
                 + safe_spec.safe_deployments_repository
@@ -48,50 +53,52 @@
             factory = safe_spec.deployments[chain_id]['factory__1.1.1']
 
     df = await evm.async_get_events(
         factory,
         event_name='ProxyCreation',
         start_block=start_block,
         end_block=end_block,
-        keep_multiindex=False,
+        context=context,
     )
-    df = df.reset_index()
     old_columns = [
         'arg__proxy',
         'contract_address',
         'transaction_hash',
         'block_number',
     ]
     df = df[old_columns]
 
-    chain_id = config.get_default_network()
     if chain_id not in safe_spec.deployments:
         raise Exception('safe 1.1.1 deployment unknown for ' + str(chain_id))
-    df['implementation'] = safe_spec.deployments[chain_id]['safe__1.1.1']
-
-    df['version'] = '1.1'
+    df = df.with_columns(
+        pl.lit(safe_spec.deployments[chain_id]['safe__1.1.1']).alias('implementation'),
+        pl.lit('1.1').alias('version'),
+    )
     new_columns = {
         'arg__proxy': 'address',
         'contract_address': 'factory',
         'block_number': 'creation_block',
         'transaction_hash': 'creation_transaction',
     }
-    df = df.rename(columns=new_columns)
-    return df.to_dict(orient='records')  # type: ignore
+    df = df.rename(new_columns)
+    return df
 
 
 async def async_get_all_safes__1_3(
     factory: spec.Address | None = None,
     *,
     start_block: spec.BlockReference | None = None,
     end_block: spec.BlockReference | None = None,
-) -> typing.Sequence[safe_spec.GnosisSafeCreation]:
+    context: spec.Context = None,
+) -> spec.DataFrame:
+
+    import polars as pl
 
     if factory is None:
-        chain_id = config.get_default_network()
+        chain_id = config.get_context_chain_id(context)
         if (
             chain_id not in safe_spec.deployments
             or 'factory__1.3.0' not in safe_spec.deployments[chain_id]
         ):
             raise NotImplementedError(
                 'must manually specify factory addresses, see '
                 + safe_spec.safe_deployments_repository
@@ -100,28 +107,30 @@
             factory = safe_spec.deployments[chain_id]['factory__1.3.0']
 
     df = await evm.async_get_events(
         factory,
         event_name='ProxyCreation',
         start_block=start_block,
         end_block=end_block,
-        keep_multiindex=False,
+        context=context,
     )
-    df = df.reset_index()
     old_columns = [
         'arg__proxy',
         'contract_address',
         'transaction_hash',
         'block_number',
         'arg__singleton',
     ]
     df = df[old_columns]
-    df['version'] = '1.3'
+    df = df.with_columns(
+        pl.lit('1.3').alias('version'),
+    )
     new_columns = {
         'arg__proxy': 'address',
         'contract_address': 'factory',
         'block_number': 'creation_block',
         'transaction_hash': 'creation_transaction',
         'arg__singleton': 'implementation',
     }
-    df = df.rename(columns=new_columns)
-    return df.to_dict(orient='records')  # type: ignore
+    df = df.rename(new_columns)
+    return df
+
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/gnosis_utils/safe_metadata.py` & `checkthechain-0.3.4/src/ctc/protocols/gnosis_utils/safe_metadata.py`

 * *Files 17% similar despite different names*

```diff
@@ -7,48 +7,54 @@
 from . import safe_spec
 
 
 async def async_get_safe_owners(
     address: spec.Address,
     *,
     block: spec.BlockReference | None = None,
+    context: spec.Context = None,
 ) -> typing.Sequence[spec.Address]:
     result = await rpc.async_eth_call(
         to_address=address,
         function_abi=safe_spec.function_abis['getOwners'],
         block_number=block,
+        context=context,
     )
     if not isinstance(result, (tuple, list)) or not all(
         isinstance(item, str) for item in result
     ):
         raise Exception('invalid rpc result')
     return result
 
 
 async def async_get_safe_threshold(
     address: spec.Address,
     *,
     block: spec.BlockReference | None = None,
+    context: spec.Context = None,
 ) -> int:
     result = await rpc.async_eth_call(
         to_address=address,
         function_abi=safe_spec.function_abis['getThreshold'],
         block_number=block,
+        context=context,
     )
     if not isinstance(result, int):
         raise Exception('invalid rpc result')
     return result
 
 
 async def async_get_safe_nonce(
     address: spec.Address,
     *,
     block: spec.BlockReference | None = None,
+    context: spec.Context = None,
 ) -> int:
     result = await rpc.async_eth_call(
         to_address=address,
         function_abi=safe_spec.function_abis['nonce'],
         block_number=block,
+        context=context,
     )
     if not isinstance(result, int):
         raise Exception('invalid rpc result')
     return result
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/gnosis_utils/safe_spec.py` & `checkthechain-0.3.4/src/ctc/protocols/gnosis_utils/safe_spec.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,12 +1,14 @@
 from __future__ import annotations
 
 import typing
 from ctc import spec
-from typing_extensions import TypedDict, Literal
+
+if typing.TYPE_CHECKING:
+    from typing_extensions import TypedDict, Literal
 
 
 if typing.TYPE_CHECKING:
 
     class GnosisSafeCreation(TypedDict):
         creation_block: int
         creation_transaction: spec.PrefixHexData
@@ -164,15 +166,15 @@
             },
         ],
         'stateMutability': 'payable',
         'type': 'function',
     },
 }
 
-event_abis = {
+event_abis: typing.Mapping[str, spec.EventABI] = {
     'AddedOwner': {
         'anonymous': False,
         'inputs': [
             {
                 'indexed': False,
                 'internalType': 'address',
                 'name': 'owner',
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/gnosis_utils/safe_summary.py` & `checkthechain-0.3.4/src/ctc/protocols/gnosis_utils/safe_summary.py`

 * *Files 23% similar despite different names*

```diff
@@ -9,32 +9,45 @@
 from ctc import evm
 from ctc import spec
 from . import safe_events
 from . import safe_metadata
 
 
 async def async_print_safe_summary(
-    address: spec.Address, verbose: bool = False
+    address: spec.Address,
+    *,
+    verbose: bool = False,
+    context: spec.Context = None,
 ) -> None:
     import tooltime
 
-    owners_coroutine = safe_metadata.async_get_safe_owners(address)
-    threshold_coroutine = safe_metadata.async_get_safe_threshold(address)
-    nonce_coroutine = safe_metadata.async_get_safe_nonce(address)
-    creation_block_coroutine = evm.async_get_contract_creation_block(address)
+    owners_coroutine = safe_metadata.async_get_safe_owners(
+        address, context=context
+    )
+    threshold_coroutine = safe_metadata.async_get_safe_threshold(
+        address, context=context
+    )
+    nonce_coroutine = safe_metadata.async_get_safe_nonce(
+        address, context=context
+    )
+    creation_block_coroutine = evm.async_get_contract_creation_block(
+        address, context=context
+    )
 
     owners, threshold, nonce, creation_block = await asyncio.gather(
         owners_coroutine,
         threshold_coroutine,
         nonce_coroutine,
         creation_block_coroutine,
     )
 
     if creation_block is not None:
-        creation_timestamp = await evm.async_get_block_timestamp(creation_block)
+        creation_timestamp = await evm.async_get_block_timestamp(
+            creation_block, context=context
+        )
         creation_date = tooltime.timestamp_to_iso_pretty(creation_timestamp)
         age = tooltime.get_age(creation_timestamp, 'TimelengthPhrase')
     else:
         creation_timestamp = None
         creation_date = None
         age = None
 
@@ -63,25 +76,27 @@
         print()
         await async_print_safe_owner_history(address)
         print()
         print()
         await async_print_safe_erc20s(address)
 
 
-async def async_print_safe_erc20s(address: spec.Address) -> None:
-
+async def async_print_safe_erc20s(
+    address: spec.Address, *, context: spec.Context = None
+) -> None:
     styles = cli.get_cli_styles()
 
-    default_erc20s = await evm.async_get_default_erc20_tokens()
+    default_erc20s = await evm.async_get_default_erc20_tokens(context=context)
     erc20_addresses = [default['address'] for default in default_erc20s]
 
     toolstr.print_text_box('Common ERC20s in safe', style=styles['title'])
     balances = await evm.async_get_erc20s_balances(
         wallet=address,
         tokens=erc20_addresses,
+        context=context,
     )
 
     rows = []
     for erc20, balance in zip(default_erc20s, balances):
         if balance > 0:
             row = [erc20['symbol'], balance]
             rows.append(row)
@@ -99,17 +114,20 @@
             column_styles={
                 'token': styles['option'],
                 'balance': styles['description'],
             },
         )
 
 
-async def async_print_safe_executions(address: spec.Address) -> None:
-
-    executions = await safe_events.async_get_safe_executions(address)
+async def async_print_safe_executions(
+    address: spec.Address, *, context: spec.Context = None
+) -> None:
+    executions = await safe_events.async_get_safe_executions(
+        address, context=context
+    )
 
     # # TODO: output more data about each transaction
     # transaction_hashes = list(executions['transaction_hash'].unique())
     # transactions = await evm.async_get_transactions(transaction_hashes)
 
     styles = cli.get_cli_styles()
 
@@ -120,19 +138,16 @@
         #     'age',
         'transaction',
         #     'safeTransaction',
     ]
 
     rows = []
     for i in range(len(executions)):
-        row = [
-            i,
-            executions.index[i][0],
-        ]
-        row.append(executions['transaction_hash'].values[i])
+        row = [i, executions['block_number'][i]]
+        row.append(executions['transaction_hash'][i])
         rows.append(row)
 
     toolstr.print_text_box('Safe Executions', style=styles['title'])
     print()
     toolstr.print_table(
         rows,
         labels=labels,
@@ -144,93 +159,113 @@
             'transaction': styles['metavar'],
         },
         compact=2,
     )
 
 
 async def async_print_safe_owner_history(
-    address: spec.Address, end_block: spec.BlockReference | None = None
+    address: spec.Address,
+    *,
+    end_block: spec.BlockReference | None = None,
+    context: spec.Context = None,
 ) -> None:
-
     if end_block is None:
-        end_block = await evm.async_get_latest_block_number()
+        end_block = await evm.async_get_latest_block_number(context=context)
 
-    safe_setup_coroutine = safe_events.async_get_safe_setup(address)
+    safe_setup_coroutine = safe_events.async_get_safe_setup(
+        address, context=context
+    )
     owner_adds_coroutine = safe_events.async_get_safe_owner_adds(
-        address, end_block=end_block
+        address, end_block=end_block, context=context
     )
     owner_removes_coroutine = safe_events.async_get_safe_owner_removes(
-        address, end_block=end_block
+        address, end_block=end_block, context=context
     )
     threshold_changes_coroutine = safe_events.async_get_safe_threshold_changes(
-        address, end_block=end_block
+        address, end_block=end_block, context=context
     )
 
     safe_setup: typing.Any = await safe_setup_coroutine
     owner_adds = await owner_adds_coroutine
     owner_removes = await owner_removes_coroutine
     threshold_changes = await threshold_changes_coroutine
 
     changes: typing.Sequence[typing.Any] = (
-        list(owner_adds.itertuples())
-        + list(owner_removes.itertuples())
-        + list(threshold_changes.itertuples())
+        list(owner_adds.to_dicts())
+        + list(owner_removes.to_dicts())
+        + list(threshold_changes.to_dicts())
     )
-    changes = sorted(changes, key=lambda change: change.Index)  #  type: ignore
+    changes = sorted(changes, key=lambda change: change['block_number'])  # type: ignore
 
     styles = cli.get_cli_styles()
 
     if safe_setup is not None:
         blocks = [safe_setup.name[0]]
         owners = [set(safe_setup['arg__owners'])]
         threshold = [safe_setup['arg__threshold']]
     else:
         creation_block_coroutine = evm.async_get_contract_creation_block(
-            address
+            address, context=context
         )
         creation_block = await creation_block_coroutine
         owners_coroutine = safe_metadata.async_get_safe_owners(
-            address, block=creation_block
+            address, block=creation_block, context=context
         )
         threshold_coroutine = safe_metadata.async_get_safe_threshold(
-            address, block=creation_block
+            address, block=creation_block, context=context
         )
         blocks = [creation_block]
         owners = [set(await owners_coroutine)]
         threshold = [await threshold_coroutine]
     diffs = ['safe initialized']
     for change in changes:
-        blocks.append(change.Index[0])
-        if change.event_name == 'AddedOwner':
+        blocks.append(change['block_number'])
+
+        # AddedOwner
+        if (
+            change['event_hash']
+            == '0x9465fa0c962cc76958e6373a993326400c1c94f8be2fe3a952adfa7f60b2ea26'
+        ):
             diffs.append(
                 'add owner '
-                + toolstr.add_style(change.arg__owner, styles['metavar'])
+                + toolstr.add_style(change['arg__owner'], styles['metavar'])
             )
             new_owners = set(owners[-1])
-            new_owners.add(change.arg__owner)
+            new_owners.add(change['arg__owner'])
             owners.append(new_owners)
             threshold.append(threshold[-1])
-        elif change.event_name == 'RemovedOwner':
+
+        # RemovedOwner
+        elif (
+            change['event_hash']
+            == '0xf8d49fc529812e9a7c5c50e69c20f0dccc0db8fa95c98bc58cc9a4f1c1299eaf'
+        ):
             diffs.append(
                 'remove owner '
-                + toolstr.add_style(change.arg__owner, styles['metavar'])
+                + toolstr.add_style(change['arg__owner'], styles['metavar'])
             )
             new_owners = set(owners[-1])
-            new_owners.remove(change.arg__owner)
+            new_owners.remove(change['arg__owner'])
             owners.append(new_owners)
             threshold.append(threshold[-1])
-        elif change.event_name == 'ChangedThreshold':
+
+        # ChangedThreshold
+        elif (
+            change['event_hash']
+            == '0x610f7ff2b304ae8903c3de74c60c6ab1f7d6226b3f52c5161905bb5ad4039c93'
+        ):
             diffs.append(
                 'change signing threshold to '
                 + toolstr.add_style(
-                    str(change.arg__threshold), styles['description']
+                    str(change['arg__threshold']), styles['description']
                 )
             )
             owners.append(owners[-1])
-            threshold.append(change.arg__threshold)
+            threshold.append(change['arg__threshold'])
+
         else:
             raise Exception()
 
     # convert to rows for printout
     rows = []
     for d, diff in enumerate(diffs):
         row = [
@@ -256,7 +291,8 @@
         border=styles['comment'],
         label_style=styles['title'],
         column_styles={
             'block': styles['description'],
             'threshold': styles['description'],
         },
     )
+
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/gnosis_utils/safe_transactions.py` & `checkthechain-0.3.4/src/ctc/protocols/gnosis_utils/safe_transactions.py`

 * *Files 10% similar despite different names*

```diff
@@ -9,15 +9,15 @@
 
 def parse_safe_signatures(
     signatures: spec.Data,
 ) -> typing.Sequence[typing.Mapping[str, typing.Any]]:
     """
     reference: https://docs.gnosis-safe.io/contracts/signatures
     """
-    as_bytes = evm.binary_convert(signatures, 'binary')
+    as_bytes = evm.to_binary(signatures)
 
     eip_1271_positions = []
     eip_1271_indices = []
     s = 0
     parsed_signatures = []
     while True:
         signature = as_bytes[:65]
@@ -25,46 +25,42 @@
 
         assert len(signature) == 65
 
         signature_type = signature[-1]
         if 31 > signature_type and signature_type > 26:
             parsed = {
                 'type': 'ecdsa',
-                'signature': evm.binary_convert(signature, 'prefix_hex'),
+                'signature': evm.to_hex(signature),
                 'r': evm.binary_convert(signature[:32], 'integer'),
                 's': evm.binary_convert(signature[32:64], 'integer'),
                 'v': evm.binary_convert(signature_type, 'integer'),
             }
         elif signature_type > 30:
             parsed = {
                 'type': 'eth_sign',
-                'signature': evm.binary_convert(signature, 'prefix_hex'),
+                'signature': evm.to_hex(signature),
                 'r': evm.binary_convert(signature[:32], 'integer'),
                 's': evm.binary_convert(signature[32:64], 'integer'),
                 'v': evm.binary_convert(signature_type - 4, 'integer'),
             }
         elif signature_type == 0:
             parsed = {
                 'type': 'eip1271',
-                'signature': evm.binary_convert(signature, 'prefix_hex'),
-                'verifier': evm.binary_convert(
-                    signature[:32][-20:], 'prefix_hex'
-                ),
+                'signature': evm.to_hex(signature),
+                'verifier': evm.to_hex(signature[:32][-20:]),
                 'position': evm.binary_convert(signature[32:64], 'integer'),
             }
             position: int = typing.cast(int, parsed['position'])
             eip_1271_positions.append(position)
             eip_1271_indices.append(s)
         elif signature_type == 1:
             parsed = {
                 'type': 'prevalidated',
-                'signature': evm.binary_convert(signature, 'prefix_hex'),
-                'validator': evm.binary_convert(
-                    signature[:32][-20:], 'prefix_hex'
-                ),
+                'signature': evm.to_hex(signature),
+                'validator': evm.to_hex(signature[:32][-20:]),
             }
         else:
             raise Exception('unknown signature type: ' + str(signature_type))
 
         parsed_signatures.append(parsed)
         s += 1
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/llama_utils/cli/llama_chain_command.py` & `checkthechain-0.3.4/src/ctc/protocols/llama_utils/cli/llama_chain_command.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/protocols/llama_utils/cli/llama_chains_command.py` & `checkthechain-0.3.4/src/ctc/protocols/llama_utils/cli/llama_chains_command.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/protocols/llama_utils/cli/llama_pool_command.py` & `checkthechain-0.3.4/src/ctc/protocols/llama_utils/cli/llama_pool_command.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/protocols/llama_utils/cli/llama_pools_command.py` & `checkthechain-0.3.4/src/ctc/protocols/llama_utils/cli/llama_pools_command.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,16 +1,18 @@
 from __future__ import annotations
 
 import typing
-from typing_extensions import Literal
 
 import toolcli
 
 from .. import llama_yields
 
+if typing.TYPE_CHECKING:
+    from typing_extensions import Literal
+
 
 def get_command_spec() -> toolcli.CommandSpec:
     return {
         'f': async_llama_pools_command,
         'help': 'output data about pools tracked by Defi Llama',
         'args': [
             {
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/llama_utils/cli/llama_protocol_command.py` & `checkthechain-0.3.4/src/ctc/protocols/llama_utils/cli/llama_protocol_command.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/protocols/llama_utils/cli/llama_protocols_command.py` & `checkthechain-0.3.4/src/ctc/protocols/llama_utils/cli/llama_protocols_command.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/protocols/llama_utils/llama_requests.py` & `checkthechain-0.3.4/src/ctc/protocols/llama_utils/llama_requests.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,29 +1,27 @@
 from __future__ import annotations
 
 import typing
 
+import aiohttp
+
 if typing.TYPE_CHECKING:
+    from typing_extensions import Literal
     from typing_extensions import TypedDict
 
     class TVLTimeseries(TypedDict):
         timestamp: typing.Sequence[int]
         tvl: typing.Sequence[int | float]
 
     class YieldTimeseries(TypedDict):
         timestamp: typing.Sequence[int]
         tvl: typing.Sequence[int | float]
         apy: typing.Sequence[int | float]
 
 
-from typing_extensions import Literal
-
-import aiohttp
-
-
 tvl_url_root = 'https://api.llama.fi'
 yields_url_root = 'https://yields.llama.fi'
 
 url_templates = {
     'historical_defi_tvl': '/charts',
     'protocols_tvls': '/protocols',
     'historical_protocol_tvl': '/protocol/{protocol}',
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/llama_utils/llama_tvls.py` & `checkthechain-0.3.4/src/ctc/protocols/llama_utils/llama_tvls.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,11 +1,12 @@
 from __future__ import annotations
 
 import toolstr
 
+import ctc.config
 from ctc import cli
 from . import llama_requests
 
 
 #
 # # comparisons
 #
@@ -120,20 +121,21 @@
     styles = cli.get_cli_styles()
 
     data = await llama_requests.async_get_historical_defi_tvl()
 
     plot = toolstr.render_line_plot(
         xvals=data['timestamp'],
         yvals=data['tvl'],
-        n_rows=40,
-        n_columns=120,
+        n_rows=10,
+        n_columns=60,
         line_style=styles['description'],
         chrome_style=styles['comment'],
         tick_label_style=styles['metavar'],
         yaxis_kwargs={'tick_label_format': {'prefix': '$'}},
+        char_dict=ctc.config.get_cli_chart_charset(),
     )
 
     toolstr.print_text_box('Historical Defi TVL', style=styles['title'])
     print()
     toolstr.print(plot)
 
 
@@ -142,20 +144,21 @@
     styles = cli.get_cli_styles()
 
     data = await llama_requests.async_get_historical_chain_tvl(chain)
 
     plot = toolstr.render_line_plot(
         xvals=data['timestamp'],
         yvals=data['tvl'],
-        n_rows=40,
-        n_columns=120,
+        n_rows=10,
+        n_columns=60,
         line_style=styles['description'],
         chrome_style=styles['comment'],
         tick_label_style=styles['metavar'],
         yaxis_kwargs={'tick_label_format': {'prefix': '$'}},
+        char_dict=ctc.config.get_cli_chart_charset(),
     )
 
     toolstr.print_text_box(
         'Historical ' + chain + ' TVL', style=styles['title']
     )
     print()
     toolstr.print(plot, indent=4)
@@ -174,20 +177,21 @@
     for datum in uniswap['tvl']:
         timestamp.append(datum['date'])
         tvl.append(datum['totalLiquidityUSD'])
 
     plot = toolstr.render_line_plot(
         xvals=timestamp,
         yvals=tvl,
-        n_rows=40,
-        n_columns=120,
+        n_rows=10,
+        n_columns=60,
         line_style=styles['description'],
         chrome_style=styles['comment'],
         tick_label_style=styles['metavar'],
         yaxis_kwargs={'tick_label_format': {'prefix': '$'}},
+        char_dict=ctc.config.get_cli_chart_charset(),
     )
 
     toolstr.print_text_box(
         'Historical ' + protocol + ' TVL', style=styles['title']
     )
     print()
 
@@ -214,20 +218,21 @@
             for datum in raw_data:
                 timestamp.append(datum['date'])
                 tvl.append(datum['totalLiquidityUSD'])
 
             plot = toolstr.render_line_plot(
                 xvals=timestamp,
                 yvals=tvl,
-                n_rows=40,
-                n_columns=120,
+                n_rows=10,
+                n_columns=60,
                 line_style=styles['description'],
                 chrome_style=styles['comment'],
                 tick_label_style=styles['metavar'],
                 yaxis_kwargs={'tick_label_format': {'prefix': '$'}},
+                char_dict=ctc.config.get_cli_chart_charset(),
             )
             print()
             toolstr.print(
                 toolstr.hjustify(chain, 'center', 70),
                 indent=4,
                 style=styles['title'],
             )
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/llama_utils/llama_yields.py` & `checkthechain-0.3.4/src/ctc/protocols/llama_utils/llama_yields.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,18 +1,19 @@
 from __future__ import annotations
 
 import typing
 
-from typing_extensions import Literal
-
 import toolstr
 
+import ctc.config
 from ctc import cli
 from . import llama_requests
 
+if typing.TYPE_CHECKING:
+    from typing_extensions import Literal
 
 #
 # # pool comparison and aggregation
 #
 
 
 async def async_print_llama_pools_summary(
@@ -340,38 +341,40 @@
         style=styles['title'],
     )
     print()
 
     plot = toolstr.render_line_plot(
         xvals=data['timestamp'],
         yvals=data['apy'],
-        n_rows=40,
-        n_columns=120,
+        n_rows=10,
+        n_columns=60,
         line_style=styles['description'],
         chrome_style=styles['comment'],
         tick_label_style=styles['metavar'],
         yaxis_kwargs={'tick_label_format': {'postfix': '%'}},
+        char_dict=ctc.config.get_cli_chart_charset(),
     )
     toolstr.print(
         toolstr.hjustify('APY', 'center', 70),
         indent=4,
         style=styles['title'],
     )
     toolstr.print(plot, indent=4)
     print()
 
     plot = toolstr.render_line_plot(
         xvals=data['timestamp'],
         yvals=data['tvl'],
-        n_rows=40,
-        n_columns=120,
+        n_rows=10,
+        n_columns=60,
         line_style=styles['description'],
         chrome_style=styles['comment'],
         tick_label_style=styles['metavar'],
         yaxis_kwargs={'tick_label_format': {'prefix': '$'}},
+        char_dict=ctc.config.get_cli_chart_charset(),
     )
     toolstr.print(
         toolstr.hjustify('TVL', 'center', 70),
         indent=4,
         style=styles['title'],
     )
     toolstr.print(plot, indent=4)
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/multicall_utils/call_utils.py` & `checkthechain-0.3.4/src/ctc/protocols/multicall_utils/call_utils.py`

 * *Files 10% similar despite different names*

```diff
@@ -17,24 +17,26 @@
         return result
     else:
         raise Exception('unknown call format')
 
 
 async def async_encode_call(
     call: multicall_spec.Call,
-    network: typing.Optional[spec.NetworkReference] = None,
+    *,
+    context: spec.Context = None,
 ) -> tuple[spec.Address, spec.BinaryData]:
     contract = get_call_contract(call)
-    call_data = await async_encode_call_data(call=call, network=network)
+    call_data = await async_encode_call_data(call=call, context=context)
     return (contract, call_data)
 
 
 async def async_encode_call_data(
     call: multicall_spec.Call,
-    network: typing.Optional[spec.NetworkReference] = None,
+    *,
+    context: spec.Context = None,
 ) -> spec.BinaryData:
 
     # parse components
     if isinstance(call, dict):
         if 'call_data' in call:
             return typing.cast(multicall_spec.EncodedCallDict, call)[
                 'call_data'
@@ -60,43 +62,44 @@
     # get abi
     if isinstance(function, dict):
         function_abi = function
     elif isinstance(function, str):
         function_abi = await evm.async_get_function_abi(
             contract_address=contract,
             function_name=function,
-            network=network,
+            context=context,
         )
     else:
         raise Exception('could not determine function_abi')
 
     # encode
     encoded_data = evm.encode_call_data(
         function_abi=function_abi,
         parameters=function_parameters,
     )
-    return evm.binary_convert(encoded_data, 'binary')
+    return evm.to_binary(encoded_data)
 
 
 async def async_decode_call_output(
     call: multicall_spec.Call,
     encoded_output: spec.BinaryData,
     *,
-    network: typing.Optional[spec.NetworkReference] = None,
+    context: spec.Context = None,
 ) -> typing.Any:
-    function_abi = await async_get_call_function_abi(call)
+    function_abi = await async_get_call_function_abi(call, context=context)
     return evm.decode_function_output(
         encoded_output=encoded_output,
         function_abi=function_abi,
     )
 
 
 async def async_get_call_function_abi(
     call: multicall_spec.Call,
-    network: typing.Optional[spec.NetworkReference] = None,
+    *,
+    context: spec.Context = None,
 ) -> spec.FunctionABI:
 
     function: spec.FunctionABI | str | None = None
     call_data: spec.BinaryData | None = None
     if isinstance(call, dict):
         if 'function' in call:
             function = typing.cast(multicall_spec.UnencodedCallDict, call)[
@@ -124,23 +127,23 @@
     if function is not None:
         if isinstance(function, dict):
             return function
         elif isinstance(function, str):
             return await evm.async_get_function_abi(
                 contract_address=get_call_contract(call),
                 function_name=function,
-                network=network,
+                context=context,
             )
         else:
             raise Exception('unknown call format')
 
     elif call_data is not None:
-        call_data = evm.binary_convert(call_data, 'prefix_hex')
+        call_data = evm.to_hex(call_data)
         function_selector = call_data[:10]
         return await evm.async_get_function_abi(
             contract_address=get_call_contract(call),
             function_selector=function_selector,
-            network=network,
+            context=context,
         )
 
     else:
         raise Exception('unknown call format')
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/multicall_utils/multicall_spec.py` & `checkthechain-0.3.4/src/ctc/protocols/multicall_utils/multicall_spec.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 from __future__ import annotations
 
 import typing
-from typing_extensions import TypedDict
+
+from ctc import spec
 
 if typing.TYPE_CHECKING:
+    from typing_extensions import TypedDict
     from typing_extensions import NotRequired
 
-from ctc import spec
-
 
 #
 # # calls
 #
 
 if typing.TYPE_CHECKING:
     FunctionParameterList = typing.Sequence[typing.Any]
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/multicall_utils/multicalls_utils.py` & `checkthechain-0.3.4/src/ctc/protocols/multicall_utils/multicalls_utils.py`

 * *Files 19% similar despite different names*

```diff
@@ -8,14 +8,15 @@
 """
 
 from __future__ import annotations
 
 import asyncio
 import typing
 
+from ctc import config
 from ctc import evm
 from ctc import spec
 from ctc import rpc
 from . import call_utils
 from . import multicall_spec
 
 
@@ -40,23 +41,24 @@
         'type': 'function',
     }
 }
 
 
 def get_multicall_address(
     *,
-    network: spec.NetworkReference = 'mainnet',
+    context: spec.Context = None,
     version: str = 'maker',
 ) -> spec.Address:
 
-    network_name = evm.get_network_name(network, require=True)
+    network = config.get_context_chain_id(context)
+    network_name = evm.get_network_name(network)
 
     if version.lower() == 'Maker'.lower():
         multicall = {
-            'mainnet': '0xeefba1e63905ef1d7acba5a8513c70307c1ce441',
+            'ethereum': '0xeefba1e63905ef1d7acba5a8513c70307c1ce441',
             'kovan': '0x2cc8688c5f75e365aaeeb4ea8d6a480405a48d2a',
             'rinkeby': '0x42ad527de7d4e9d9d011ac45b31d8551f8fe9821',
             'gorli': '0x77dca2c955b15e9de4dbbcf1246b4b85b651e50e',
             'ropsten': '0x53c43764255c17bd724f74c4ef150724ac50a3ed',
             'xdai': '0xb5b692a88bdfc81ca69dcb1d924f59f0413a602a',
             'polygon': '0x11ce4b23bd875d7f5c6a31084f55fde1e9a87507',
             'mumbai': '0x08411add0b5aa8ee47563b146743c13b3556c9cc',
@@ -69,61 +71,59 @@
         raise Exception('unknown version: ' + str(version))
 
 
 async def async_multicall(
     calls: typing.Sequence[multicall_spec.Call],
     *,
     block: spec.BlockNumberReference | None = None,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
 ) -> typing.List[typing.Any]:
 
-    network = rpc.get_provider_network(provider)
-
     # encode calls
     coroutines = [
-        call_utils.async_encode_call(call, network=network) for call in calls
+        call_utils.async_encode_call(call, context=context) for call in calls
     ]
     encoded_calls = await asyncio.gather(*coroutines)
 
     # get multicall contract address
-    multicall_address = get_multicall_address(network=network)
+    multicall_address = get_multicall_address(context=context)
 
     # make call
     results = await rpc.async_eth_call(
         to_address=multicall_address,
         function_abi=function_abis['aggregate'],
         function_parameters=[encoded_calls],
         block_number=block,
-        provider=provider,
+        context=context,
     )
     block_number, encoded_outputs = results
 
     # decode outputs
     coroutines = [
         call_utils.async_decode_call_output(
             call=call,
             encoded_output=encoded_output,
-            network=network,
+            context=context,
         )
         for call, encoded_output in zip(calls, encoded_outputs)
     ]
     decoded_outputs = await asyncio.gather(*coroutines)
 
     return decoded_outputs
 
 
 async def async_multicall_by_block(
     calls: typing.Sequence[multicall_spec.Call],
     *,
     blocks: typing.Sequence[spec.BlockNumberReference],
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
 ) -> typing.Sequence[typing.Sequence[typing.Any]]:
     coroutines = [
         async_multicall(
             calls=calls,
             block=block,
-            provider=provider,
+            context=context,
         )
         for block in blocks
     ]
     results = asyncio.gather(*coroutines)
     return list(zip(*results))
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/rari_utils/cli/rari/fuse_command.py` & `checkthechain-0.3.4/src/ctc/protocols/rari_utils/cli/rari/fuse_command.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/protocols/rari_utils/cli/rari/pools_command.py` & `checkthechain-0.3.4/src/ctc/protocols/rari_utils/cli/rari/pools_command.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/protocols/rari_utils/fuse_lens/README.md` & `checkthechain-0.3.4/src/ctc/protocols/rari_utils/fuse_lens/README.md`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/protocols/rari_utils/fuse_lens/lens_abis.py` & `checkthechain-0.3.4/src/ctc/protocols/rari_utils/fuse_lens/lens_abis.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/protocols/rari_utils/fuse_lens/lens_spec.py` & `checkthechain-0.3.4/src/ctc/protocols/rari_utils/fuse_lens/lens_spec.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,174 +1,154 @@
 from __future__ import annotations
 
 import typing
-from typing_extensions import TypedDict
 
-from ctc import rpc
+from ctc import evm
 from ctc import spec
 
+if typing.TYPE_CHECKING:
+    from typing_extensions import TypedDict
+
+    class FusePool(TypedDict):
+        name: str
+        creator: spec.Address
+        comptroller: spec.Address
+        block_posted: int
+        timestamp_posted: int
+
+    class FusePoolData(TypedDict):
+        total_supply: int
+        total_borrow: int
+        underlying_tokens: typing.Sequence[spec.Address]
+        underlying_symbols: typing.Sequence[str]
+        whitelisted_admin: bool
+
+    class FusePoolAsset(TypedDict):
+        ftoken: spec.Address
+        underlying_token: spec.Address
+        underlying_name: str
+        underlying_symbol: str
+        underlying_decimals: int
+        underlying_balance: int
+        supply_rate_per_block: int
+        borrow_rate_per_block: int
+        total_supply: int
+        total_borrow: int
+        supply_balance: int
+        borrow_balance: int
+        liquidity: int
+        membership: bool
+        exchange_rate: int
+        underlying_price: int
+        oracle: spec.Address
+        collateral_factor: int
+        reserve_factor: int
+        admin_fee: int
+        fuse_fee: int
+        borrow_guardian_paused: bool
+
+    class FusePoolUser(TypedDict):
+        account: spec.Address
+        total_borrow: int
+        total_collateral: int
+        health: int
+        assets: typing.Sequence[FusePoolAsset]
+
+    class CTokenOwnership(TypedDict):
+        ctoken: spec.Address
+        admin: spec.Address
+        admin_has_rights: bool
+        fuse_admin_has_rights: bool
+
+    class PublicPoolsWithData(TypedDict):
+        public_pools: typing.Sequence[FusePool]
+        data: typing.Sequence['ReturnPoolSummary']
+        errored: typing.Sequence[bool]
+
+    class ReturnPoolSummary(TypedDict):
+        total_supply: int
+        total_borrow: int
+        underlying_tokens: typing.Sequence[spec.Address]
+        underlying_symbols: typing.Sequence[str]
+        whitelisted_admin: bool
+
+    class ReturnPoolUsersWithData(TypedDict):
+        users: typing.Sequence[FusePoolUser]
+        close_factor: int
+        liquidation_incentive: int
+
+    class ReturnPoolsUsersWithData(TypedDict):
+        users: typing.Sequence[typing.Sequence[FusePoolUser]]
+        close_factors: typing.Sequence[int]
+        liquidation_incentives: typing.Sequence[int]
+        errored: typing.Sequence[bool]
+
+    class ReturnPublicPoolUsersWithData(TypedDict):
+        comptrollers: typing.Sequence[spec.Address]
+        users: typing.Sequence[FusePoolUser]
+        close_factors: typing.Sequence[int]
+        liquidation_incentives: typing.Sequence[int]
+        errored: typing.Sequence[bool]
+
+    class ReturnPoolsBySupplier(TypedDict):
+        indices: typing.Sequence[spec.Address]
+        account_pools: typing.Sequence[FusePool]
+
+    class ReturnPoolsBySupplierWithData(TypedDict):
+        indices: typing.Sequence[spec.Address]
+        account_pools: typing.Sequence[FusePool]
+        data: typing.Sequence[FusePoolData]
+        errored: typing.Sequence[bool]
+
+    class UserSummary(TypedDict):
+        supply_balance: int
+        borrow_balance: int
+        error: bool
+
+    class PoolUserSummary(TypedDict):
+        supply_balance: int
+        borrow_balance: int
+
+    class ReturnWhitelistedPoolsByAccountWithData(TypedDict):
+        indices: typing.Sequence[int]
+        account_pools: typing.Sequence[FusePool]
+        data: typing.Sequence[FusePoolData]
+        errored: typing.Sequence[bool]
+
 
 def get_lens_address(
     lens_name: str,
-    network: spec.NetworkReference | None = None,
-    *,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
 ) -> spec.Address:
+    from ctc import config
 
-    if network is None:
-        provider = rpc.get_provider(provider)
-        network = provider['network']
-        if network is None:
-            raise Exception('could not determine network')
-
-    if network == 'mainnet':
+    network = config.get_context_chain_id(context)
+    network_name = evm.get_network_name(network)
 
+    if network_name == 'ethereum':
         if lens_name == 'primary':
             return '0x6dc585ad66a10214ef0502492b0cc02f0e836eec'
         elif lens_name == 'secondary':
             return '0xc76190e04012f26a364228cfc41690429c44165d'
         else:
             raise Exception('unknown lens name: ' + str(lens_name))
 
-    elif network == 'arbitrum':
-
+    elif network_name == 'arbitrum':
         if lens_name == 'primary':
             return '0xd6e194af3d9674b62d1b30ec676030c23961275e'
         elif lens_name == 'secondary':
             return '0x32ca4e5d75ecb06f33846055652c831f6e7a6924'
         else:
             raise Exception('unknown lens name: ' + str(lens_name))
 
     else:
         raise Exception('no lens for network: ' + str(network))
 
 
-class FusePool(TypedDict):
-    name: str
-    creator: spec.Address
-    comptroller: spec.Address
-    block_posted: int
-    timestamp_posted: int
-
-
-class FusePoolData(TypedDict):
-    total_supply: int
-    total_borrow: int
-    underlying_tokens: typing.Sequence[spec.Address]
-    underlying_symbols: typing.Sequence[str]
-    whitelisted_admin: bool
-
-
-class FusePoolAsset(TypedDict):
-    ftoken: spec.Address
-    underlying_token: spec.Address
-    underlying_name: str
-    underlying_symbol: str
-    underlying_decimals: int
-    underlying_balance: int
-    supply_rate_per_block: int
-    borrow_rate_per_block: int
-    total_supply: int
-    total_borrow: int
-    supply_balance: int
-    borrow_balance: int
-    liquidity: int
-    membership: bool
-    exchange_rate: int
-    underlying_price: int
-    oracle: spec.Address
-    collateral_factor: int
-    reserve_factor: int
-    admin_fee: int
-    fuse_fee: int
-    borrow_guardian_paused: bool
-
-
-class FusePoolUser(TypedDict):
-    account: spec.Address
-    total_borrow: int
-    total_collateral: int
-    health: int
-    assets: typing.Sequence[FusePoolAsset]
-
-
-class CTokenOwnership(TypedDict):
-    ctoken: spec.Address
-    admin: spec.Address
-    admin_has_rights: bool
-    fuse_admin_has_rights: bool
-
-
-class PublicPoolsWithData(TypedDict):
-    public_pools: typing.Sequence[FusePool]
-    data: typing.Sequence['ReturnPoolSummary']
-    errored: typing.Sequence[bool]
-
-
-class ReturnPoolSummary(TypedDict):
-    total_supply: int
-    total_borrow: int
-    underlying_tokens: typing.Sequence[spec.Address]
-    underlying_symbols: typing.Sequence[str]
-    whitelisted_admin: bool
-
-
-class ReturnPoolUsersWithData(TypedDict):
-    users: typing.Sequence[FusePoolUser]
-    close_factor: int
-    liquidation_incentive: int
-
-
-class ReturnPoolsUsersWithData(TypedDict):
-    users: typing.Sequence[typing.Sequence[FusePoolUser]]
-    close_factors: typing.Sequence[int]
-    liquidation_incentives: typing.Sequence[int]
-    errored: typing.Sequence[bool]
-
-
-class ReturnPublicPoolUsersWithData(TypedDict):
-    comptrollers: typing.Sequence[spec.Address]
-    users: typing.Sequence[FusePoolUser]
-    close_factors: typing.Sequence[int]
-    liquidation_incentives: typing.Sequence[int]
-    errored: typing.Sequence[bool]
-
-
-class ReturnPoolsBySupplier(TypedDict):
-    indices: typing.Sequence[spec.Address]
-    account_pools: typing.Sequence[FusePool]
-
-
-class ReturnPoolsBySupplierWithData(TypedDict):
-    indices: typing.Sequence[spec.Address]
-    account_pools: typing.Sequence[FusePool]
-    data: typing.Sequence[FusePoolData]
-    errored: typing.Sequence[bool]
-
-
-class UserSummary(TypedDict):
-    supply_balance: int
-    borrow_balance: int
-    error: bool
-
-
-class PoolUserSummary(TypedDict):
-    supply_balance: int
-    borrow_balance: int
-
-
-class ReturnWhitelistedPoolsByAccountWithData(TypedDict):
-    indices: typing.Sequence[int]
-    account_pools: typing.Sequence[FusePool]
-    data: typing.Sequence[FusePoolData]
-    errored: typing.Sequence[bool]
-
-
 def fuse_pool_to_dict(as_list: typing.Sequence[typing.Any]) -> FusePool:
-
     keys = list(FusePool.__annotations__.keys())
     if len(as_list) != len(keys):
         raise Exception('invalid number of items')
 
     return {
         'name': as_list[0],
         'creator': as_list[1],
@@ -177,15 +157,14 @@
         'timestamp_posted': as_list[4],
     }
 
 
 def fuse_pool_data_to_dict(
     as_list: typing.Sequence[typing.Any],
 ) -> FusePoolData:
-
     keys = list(FusePoolData.__annotations__.keys())
     if len(as_list) != len(keys):
         raise Exception('invalid number of items')
 
     return {
         'total_supply': as_list[0],
         'total_borrow': as_list[1],
@@ -194,15 +173,14 @@
         'whitelisted_admin': as_list[4],
     }
 
 
 def fuse_pool_asset_to_dict(
     as_list: typing.Sequence[typing.Any],
 ) -> FusePoolAsset:
-
     keys = list(FusePoolAsset.__annotations__.keys())
     if len(as_list) != len(keys):
         raise Exception('invalid number of items')
 
     return {
         'ftoken': as_list[0],
         'underlying_token': as_list[1],
@@ -228,15 +206,14 @@
         'borrow_guardian_paused': as_list[21],
     }
 
 
 def fuse_pool_user_to_dict(
     as_list: typing.Sequence[typing.Any],
 ) -> FusePoolUser:
-
     keys = list(FusePoolUser.__annotations__.keys())
     if len(as_list) != len(keys):
         raise Exception('invalid number of items')
 
     result: FusePoolUser = {
         'account': as_list[0],
         'total_borrow': as_list[1],
@@ -251,15 +228,14 @@
     ]
     return result
 
 
 def return_pool_summary_to_dict(
     as_list: typing.Sequence[typing.Any],
 ) -> ReturnPoolSummary:
-
     keys = list(ReturnPoolSummary.__annotations__.keys())
     if len(as_list) != len(keys):
         raise Exception('invalid number of items')
 
     return {
         'total_supply': as_list[0],
         'total_borrow': as_list[1],
@@ -284,7 +260,8 @@
 
     result['users'] = [
         fuse_pool_user_to_dict(user)
         for user in typing.cast(typing.List[typing.Any], result['users'])
     ]
 
     return result
+
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/rari_utils/fuse_lens/primary_lens.py` & `checkthechain-0.3.4/src/ctc/protocols/rari_utils/fuse_lens/primary_lens.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,38 +1,44 @@
 from __future__ import annotations
 
 import asyncio
 import typing
-from typing_extensions import TypedDict
 
 from ctc import rpc
 from ctc import spec
 
 from .. import fuse_queries
 from . import lens_abis
 from . import lens_spec
 
+if typing.TYPE_CHECKING:
+    from typing_extensions import TypedDict
+
+    class _ReturnPoolSummaryOrError(TypedDict):
+        summary: typing.Optional[lens_spec.ReturnPoolSummary]
+        error: typing.Optional[str]
+
 
 async def async_get_public_pools_with_data(
     *,
     lens_address: spec.Address | None = None,
-    provider: spec.ProviderReference = None,
     block: typing.Optional[spec.BlockNumberReference] = None,
+    context: spec.Context = None,
 ) -> lens_spec.PublicPoolsWithData:
     if lens_address is None:
-        lens_address = lens_spec.get_lens_address('primary', provider=provider)
+        lens_address = lens_spec.get_lens_address('primary', context=context)
 
     # on-chain implementation reverts, python implementation instead
     all_pools = await fuse_queries.async_get_all_pools(
-        block=block, provider=provider
+        block=block, context=context
     )
     comptrollers = [pool[2] for pool in all_pools]
     coroutines = [
         _async_get_pool_summary_or_error(
-            comptroller, block=block, provider=provider
+            comptroller, block=block, context=context
         )
         for comptroller in comptrollers
     ]
     results = await asyncio.gather(*coroutines)
     summaries = [result['summary'] for result in results]
     errors = [result['error'] is not None for result in results]
 
@@ -41,56 +47,51 @@
             lens_spec.fuse_pool_to_dict(pool) for pool in all_pools
         ],
         'data': summaries,
         'errored': errors,
     }
 
 
-class _ReturnPoolSummaryOrError(TypedDict):
-    summary: typing.Optional[lens_spec.ReturnPoolSummary]
-    error: typing.Optional[str]
-
-
 async def _async_get_pool_summary_or_error(
     comptroller: spec.Address,
     *,
     lens_address: spec.Address | None = None,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     block: typing.Optional[spec.BlockNumberReference] = None,
 ) -> _ReturnPoolSummaryOrError:
     try:
         summary = await async_get_pool_summary(
             comptroller=comptroller,
             lens_address=lens_address,
-            provider=provider,
             block=block,
+            context=context,
         )
         return {'summary': summary, 'error': None}
     except spec.RpcException as e:
         return {'summary': None, 'error': e.args[0]}
 
 
 async def async_get_public_pools_by_verification_with_data(
     *,
     whitelisted_admin: bool,
     lens_address: spec.Address | None = None,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     block: typing.Optional[spec.BlockNumberReference] = None,
 ) -> lens_spec.PublicPoolsWithData:
     if lens_address is None:
-        lens_address = lens_spec.get_lens_address('primary', provider=provider)
+        lens_address = lens_spec.get_lens_address('primary', context=context)
 
     # on-chain implementation reverts, python implementation instead
     all_pools = await fuse_queries.async_get_all_pools(
-        block=block, provider=provider
+        block=block, context=context
     )
     comptrollers = [pool[2] for pool in all_pools]
     coroutines = [
         _async_get_pool_summary_or_error(
-            comptroller, block=block, provider=provider
+            comptroller, block=block, context=context
         )
         for comptroller in comptrollers
     ]
     results = await asyncio.gather(*coroutines)
 
     filtered_pools = []
     filtered_results = []
@@ -114,26 +115,26 @@
     }
 
 
 async def async_get_pools_by_account_with_data(
     account: spec.Address,
     *,
     lens_address: spec.Address | None = None,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     block: typing.Optional[spec.BlockNumberReference] = None,
 ) -> lens_spec.ReturnPoolsBySupplierWithData:
     if lens_address is None:
-        lens_address = lens_spec.get_lens_address('primary', provider=provider)
+        lens_address = lens_spec.get_lens_address('primary', context=context)
     function_abi = lens_abis.get_function_abi('getPoolsByAccountWithData')
     result = await rpc.async_eth_call(
         to_address=lens_address,
         function_abi=function_abi,
         function_parameters=[account],
         block_number=block,
-        provider=provider,
+        context=context,
     )
     return {
         'indices': result[0],
         'account_pools': [
             lens_spec.fuse_pool_to_dict(pool) for pool in result[1]
         ],
         'data': [lens_spec.fuse_pool_data_to_dict(pool) for pool in result[2]],
@@ -141,75 +142,74 @@
     }
 
 
 async def async_get_pool_summary(
     comptroller: spec.Address,
     *,
     lens_address: spec.Address | None = None,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     block: typing.Optional[spec.BlockNumberReference] = None,
 ) -> lens_spec.ReturnPoolSummary:
     if lens_address is None:
-        lens_address = lens_spec.get_lens_address('primary', provider=provider)
+        lens_address = lens_spec.get_lens_address('primary', context=context)
     function_abi = lens_abis.get_function_abi('getPoolSummary')
     result = await rpc.async_eth_call(
         to_address=lens_address,
         function_abi=function_abi,
         function_parameters=[comptroller],
         block_number=block,
-        provider=provider,
+        context=context,
     )
     return lens_spec.return_pool_summary_to_dict(result)
 
 
 async def async_get_pool_assets_with_data(
     comptroller: spec.Address,
     *,
     lens_address: spec.Address | None = None,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     block: typing.Optional[spec.BlockNumberReference] = None,
 ) -> list[lens_spec.FusePoolAsset]:
     if lens_address is None:
-        lens_address = lens_spec.get_lens_address('primary', provider=provider)
+        lens_address = lens_spec.get_lens_address('primary', context=context)
     function_abi = lens_abis.get_function_abi('getPoolAssetsWithData')
     result = await rpc.async_eth_call(
         to_address=lens_address,
         function_abi=function_abi,
         function_parameters=[comptroller],
         block_number=block,
-        provider=provider,
+        context=context,
     )
     return [lens_spec.fuse_pool_asset_to_dict(item) for item in result]
 
 
 async def async_get_public_pool_users_with_data(
     *,
     max_health: int = int(1e36),
     lens_address: spec.Address | None = None,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     block: typing.Optional[spec.BlockNumberReference] = None,
 ) -> lens_spec.ReturnPublicPoolUsersWithData:
-
     if lens_address is None:
-        lens_address = lens_spec.get_lens_address('primary', provider=provider)
+        lens_address = lens_spec.get_lens_address('primary', context=context)
 
     # on-chain implementation reverts, python implementation instead
     # kwargs = {'block': block, 'provider': provider}
     max_health = int(1e36)
 
     all_pools = await fuse_queries.async_get_all_pools(
-        block=block, provider=provider
+        block=block, context=context
     )
     comptrollers = [pool[2] for pool in all_pools]
     coroutines = [
         _async_get_pool_users_with_data_or_error(
             comptroller=comptroller,
             max_health=max_health,
             block=block,
-            provider=provider,
+            context=context,
         )
         for comptroller in comptrollers
     ]
     result = await asyncio.gather(*coroutines)
 
     users = []
     close_factors = []
@@ -249,56 +249,56 @@
 
 
 async def async_get_pool_users_with_data(
     comptroller: spec.Address,
     *,
     max_health: int = int(1e36),
     lens_address: spec.Address | None = None,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     block: typing.Optional[spec.BlockNumberReference] = None,
 ) -> lens_spec.ReturnPoolUsersWithData:
     if lens_address is None:
-        lens_address = lens_spec.get_lens_address('primary', provider=provider)
+        lens_address = lens_spec.get_lens_address('primary', context=context)
     function_abi = lens_abis.get_function_abi(
         'getPoolUsersWithData',
         parameter_types=('address', 'uint256'),
     )
     result = await rpc.async_eth_call(
         to_address=lens_address,
         function_abi=function_abi,
         function_parameters=[comptroller, max_health],
         block_number=block,
-        provider=provider,
+        context=context,
     )
 
     return lens_spec.return_pool_users_with_data_to_dict(result)
 
 
 async def async_get_pools_users_with_data(
     comptrollers: spec.Address,
     *,
     max_health: int = int(1e36),
     lens_address: spec.Address | None = None,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     block: typing.Optional[spec.BlockNumberReference] = None,
 ) -> lens_spec.ReturnPoolsUsersWithData:
     """renamed to prevent name collision with async_get_pool_users_with_data"""
 
     if lens_address is None:
-        lens_address = lens_spec.get_lens_address('primary', provider=provider)
+        lens_address = lens_spec.get_lens_address('primary', context=context)
     function_abi = lens_abis.get_function_abi(
         'getPoolUsersWithData',
         parameter_types=('address[]', 'uint256'),
     )
     result = await rpc.async_eth_call(
         to_address=lens_address,
         function_abi=function_abi,
         function_parameters=[comptrollers, max_health],
         block_number=block,
-        provider=provider,
+        context=context,
     )
 
     return {
         'users': [
             [lens_spec.fuse_pool_user_to_dict(user) for user in pool_users]
             for pool_users in result[0]
         ],
@@ -308,49 +308,49 @@
     }
 
 
 async def async_get_pools_by_supplier(
     account: spec.Address,
     *,
     lens_address: spec.Address | None = None,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     block: typing.Optional[spec.BlockNumberReference] = None,
 ) -> lens_spec.ReturnPoolsBySupplier:
     if lens_address is None:
-        lens_address = lens_spec.get_lens_address('primary', provider=provider)
+        lens_address = lens_spec.get_lens_address('primary', context=context)
     function_abi = lens_abis.get_function_abi('getPoolsBySupplier')
     result = await rpc.async_eth_call(
         to_address=lens_address,
         function_abi=function_abi,
         function_parameters=[account],
         block_number=block,
-        provider=provider,
+        context=context,
     )
     return {
         'indices': result[0],
         'account_pools': result[1],
     }
 
 
 async def async_get_pools_by_supplier_with_data(
     account: spec.Address,
     *,
     lens_address: spec.Address | None = None,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     block: typing.Optional[spec.BlockNumberReference] = None,
 ) -> lens_spec.ReturnPoolsBySupplierWithData:
     if lens_address is None:
-        lens_address = lens_spec.get_lens_address('primary', provider=provider)
+        lens_address = lens_spec.get_lens_address('primary', context=context)
     function_abi = lens_abis.get_function_abi('getPoolsBySupplierWithData')
     result = await rpc.async_eth_call(
         to_address=lens_address,
         function_abi=function_abi,
         function_parameters=[account],
         block_number=block,
-        provider=provider,
+        context=context,
     )
     return {
         'indices': result[0],
         'account_pools': [
             lens_spec.fuse_pool_to_dict(pool) for pool in result[1]
         ],
         'data': [lens_spec.fuse_pool_data_to_dict(pool) for pool in result[2]],
@@ -358,98 +358,98 @@
     }
 
 
 async def async_get_user_summary(
     account: spec.Address,
     *,
     lens_address: spec.Address | None = None,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     block: typing.Optional[spec.BlockNumberReference] = None,
 ) -> lens_spec.UserSummary:
     if lens_address is None:
-        lens_address = lens_spec.get_lens_address('primary', provider=provider)
+        lens_address = lens_spec.get_lens_address('primary', context=context)
     function_abi = lens_abis.get_function_abi('getUserSummary')
     result = await rpc.async_eth_call(
         to_address=lens_address,
         function_abi=function_abi,
         function_parameters=[account],
         block_number=block,
-        provider=provider,
+        context=context,
     )
 
     return {
         'supply_balance': result[0],
         'borrow_balance': result[1],
         'error': result[2],
     }
 
 
 async def async_get_pool_user_summary(
     comptroller: spec.Address,
     account: spec.Address,
     *,
     lens_address: spec.Address | None = None,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     block: typing.Optional[spec.BlockNumberReference] = None,
 ) -> lens_spec.PoolUserSummary:
     if lens_address is None:
-        lens_address = lens_spec.get_lens_address('primary', provider=provider)
+        lens_address = lens_spec.get_lens_address('primary', context=context)
     function_abi = lens_abis.get_function_abi('getPoolUserSummary')
     result = await rpc.async_eth_call(
         to_address=lens_address,
         function_abi=function_abi,
         function_parameters=[comptroller, account],
         block_number=block,
-        provider=provider,
+        context=context,
     )
     return {
         'supply_balance': result[0],
         'borrow_balance': result[1],
     }
 
 
 async def async_get_whitelisted_pools_by_account(
     account: spec.Address,
     *,
     lens_address: spec.Address | None = None,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     block: typing.Optional[spec.BlockNumberReference] = None,
 ) -> typing.Sequence[lens_spec.FusePool]:
     if lens_address is None:
-        lens_address = lens_spec.get_lens_address('primary', provider=provider)
+        lens_address = lens_spec.get_lens_address('primary', context=context)
     function_abi = lens_abis.get_function_abi('getWhitelistedPoolsByAccount')
     result = await rpc.async_eth_call(
         to_address=lens_address,
         function_abi=function_abi,
         function_parameters=[account],
         block_number=block,
-        provider=provider,
+        context=context,
     )
     output = result[1]
     return typing.cast(typing.Sequence[lens_spec.FusePool], output)
 
 
 async def async_get_whitelisted_pools_by_account_with_data(
     account: spec.Address,
     *,
     lens_address: spec.Address | None = None,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     block: typing.Optional[spec.BlockNumberReference] = None,
 ) -> lens_spec.ReturnWhitelistedPoolsByAccountWithData:
     if lens_address is None:
-        lens_address = lens_spec.get_lens_address('primary', provider=provider)
+        lens_address = lens_spec.get_lens_address('primary', context=context)
     function_abi = lens_abis.get_function_abi(
         'getWhitelistedPoolsByAccountWithData'
     )
     result = await rpc.async_eth_call(
         to_address=lens_address,
         function_abi=function_abi,
         function_parameters=[account],
         block_number=block,
-        provider=provider,
+        context=context,
     )
 
     output: lens_spec.ReturnWhitelistedPoolsByAccountWithData = {
         'indices': result[0],
         'account_pools': result[1],
         'data': result[2],
         'errored': result[3],
@@ -464,7 +464,8 @@
 
     output['data'] = [
         lens_spec.fuse_pool_data_to_dict(item)
         for item in typing.cast(typing.List[typing.Any], output['data'])
     ]
 
     return output
+
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/rari_utils/fuse_queries/irm_metadata.py` & `checkthechain-0.3.4/src/ctc/protocols/rari_utils/fuse_queries/irm_metadata.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/protocols/rari_utils/fuse_queries/pool_metadata.py` & `checkthechain-0.3.4/src/ctc/protocols/rari_utils/fuse_queries/pool_metadata.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/protocols/rari_utils/fuse_queries/pool_state.py` & `checkthechain-0.3.4/src/ctc/protocols/rari_utils/fuse_queries/pool_state.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/protocols/rari_utils/fuse_queries/pool_summary.py` & `checkthechain-0.3.4/src/ctc/protocols/rari_utils/fuse_queries/pool_summary.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/protocols/rari_utils/fuse_queries/token_state/token_interest.py` & `checkthechain-0.3.4/src/ctc/protocols/rari_utils/fuse_queries/token_state/token_interest.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/protocols/rari_utils/fuse_queries/token_state/token_usage.py` & `checkthechain-0.3.4/src/ctc/protocols/rari_utils/fuse_queries/token_state/token_usage.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/protocols/rari_utils/fuse_queries/token_summary.py` & `checkthechain-0.3.4/src/ctc/protocols/rari_utils/fuse_queries/token_summary.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,40 +1,38 @@
 from __future__ import annotations
 
 import typing
 
-from typing_extensions import TypedDict
-
 from ctc import spec
 from ctc.toolbox import nested_utils
 from . import directory_metadata
 from . import pool_metadata
 from . import token_metadata
 from . import token_state
 
+if typing.TYPE_CHECKING:
+    from typing_extensions import TypedDict
 
-class CTokenMetricSpec(TypedDict, total=False):
-    tvl: bool
-    tvb: bool
-    supply_apy: bool
-    borrow_apy: bool
-
-
-class CTokenMetrics(TypedDict, total=False):
-    tvl: spec.Number
-    tvb: spec.Number
-    supply_apy: spec.Number | None
-    borrow_apy: spec.Number | None
-
-
-class CTokenMetricsByBlock(TypedDict, total=False):
-    tvl: typing.Sequence[spec.Number]
-    tvb: typing.Sequence[spec.Number]
-    supply_apy: typing.Sequence[spec.Number | None]
-    borrow_apy: typing.Sequence[spec.Number | None]
+    class CTokenMetricSpec(TypedDict, total=False):
+        tvl: bool
+        tvb: bool
+        supply_apy: bool
+        borrow_apy: bool
+
+    class CTokenMetrics(TypedDict, total=False):
+        tvl: spec.Number
+        tvb: spec.Number
+        supply_apy: spec.Number | None
+        borrow_apy: spec.Number | None
+
+    class CTokenMetricsByBlock(TypedDict, total=False):
+        tvl: typing.Sequence[spec.Number]
+        tvb: typing.Sequence[spec.Number]
+        supply_apy: typing.Sequence[spec.Number | None]
+        borrow_apy: typing.Sequence[spec.Number | None]
 
 
 async def async_get_token_multipool_history(
     token: spec.Address,
     blocks: typing.Sequence[spec.BlockNumberReference],
     *,
     metrics: CTokenMetricSpec | None = None,
@@ -194,7 +192,8 @@
             output['tvb'] = tv_result['tvb']
     if metrics.get('supply_apy'):
         output['supply_apy'] = await supply_task
     if metrics.get('borrow_apy'):
         output['borrow_apy'] = await borrow_task
 
     return output
+
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/rari_utils/rari_abis.py` & `checkthechain-0.3.4/src/ctc/protocols/rari_utils/rari_abis.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/protocols/rari_utils/summary_utils.py` & `checkthechain-0.3.4/src/ctc/protocols/rari_utils/summary_utils.py`

 * *Files 0% similar despite different names*

```diff
@@ -33,15 +33,15 @@
         key=lambda pair: typing.cast(typing.Union[int, float], pair[1][key]),
         reverse=reverse,
     )
     return dict(sorted_pairs)
 
 
 def print_fuse_pool_summary(
-    block: spec.Block,
+    block: spec.DBBlock,
     *,
     tokens_data: typing.Mapping[str, typing.Any],
     pool_name: str,
     comptroller: spec.Address,
 ) -> None:
 
     tvl = sum(token_data['supplied_tvl'] for token_data in tokens_data.values())
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/sushi_utils/sushiswap_crud.py` & `checkthechain-0.3.4/src/ctc/protocols/sushi_utils/sushiswap_crud.py`

 * *Files 22% similar despite different names*

```diff
@@ -16,18 +16,20 @@
     *,
     start_block: spec.BlockNumberReference | None = None,
     end_block: spec.BlockNumberReference | None = None,
     start_time: tooltime.Timestamp | None = None,
     end_time: tooltime.Timestamp | None = None,
     label: Literal['index', 'symbol', 'address'] = 'index',
     normalize: bool = True,
+    context: spec.Context = None,
 ) -> spec.DataFrame:
 
     return await uniswap_v2_utils.async_get_pool_swaps(
         pool=pool_address,
         start_block=start_block,
         end_block=end_block,
         start_time=start_time,
         end_time=end_time,
         label=label,
         normalize=normalize,
+        context=context,
     )
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/uniswap_v2_utils/cli/burns_command.py` & `checkthechain-0.3.4/src/ctc/protocols/uniswap_v2_utils/cli/burns_command.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/protocols/uniswap_v2_utils/cli/chart_command.py` & `checkthechain-0.3.4/src/ctc/defi/dex_utils/dexes/dex_implementations/balancer_dex.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,212 +1,194 @@
 from __future__ import annotations
 
-import functools
-import math
+import typing
 
-import rich.console
-import toolcli
-import toolstr
-import tooltime
-
-from ctc import cli
 from ctc import evm
 from ctc import spec
-from ctc.toolbox.defi_utils import ohlc_utils
-from ctc.protocols import uniswap_v2_utils
+from ctc.protocols import balancer_utils
+from .. import dex_class
 
+if typing.TYPE_CHECKING:
+    import tooltime
 
-def get_command_spec() -> toolcli.CommandSpec:
-    return {
-        'f': async_chart_command,
-        'help': 'chart price action of uniswap pools',
-        'args': [
-            {
-                'name': 'pool',
-                'help': 'Uniswap pool address',
-            },
-            {
-                'name': '--timescale',
-                'help': 'size of candlesticks, e.g. 1h, 1d, or 1w',
-            },
-            {
-                'name': '--invert',
-                'action': 'store_true',
-                'help': 'use inverse of price',
-            },
-            {
-                'name': '--no-volume',
-                'action': 'store_true',
-                'help': 'hide volume data',
-            },
-        ],
-        'examples': ['0x9928e4046d7c6513326ccea028cd3e7a91c7590a'],
-    }
-
-
-async def async_chart_command(
-    *,
-    pool: spec.Address,
-    invert: bool,
-    timescale: str,
-    no_volume: bool,
-) -> None:
-    import asyncio
-
-    metadata_task = asyncio.create_task(
-        uniswap_v2_utils.async_get_pool_tokens_metadata(pool)
-    )
-
-    columns = toolcli.get_n_terminal_cols()
-    n_candles = math.floor((columns - 10) / 2)
-    if timescale is None:
-        candle_timescale = '1d'
-    else:
-        candle_timescale = timescale
-    candle_seconds = tooltime.timelength_to_seconds(candle_timescale)
-    window_seconds = candle_seconds * n_candles
-
-    window_end = tooltime.create_timestamp_seconds()
-    window_start = (
-        math.floor((window_end - window_seconds) / candle_seconds)
-        * candle_seconds
-    )
-    start_block = await evm.async_get_block_of_timestamp(window_start) - 1
-    end_block = await evm.async_get_latest_block_number()
-
-    # get data
-    swaps = await uniswap_v2_utils.async_get_pool_swaps(
-        pool,
-        start_block=start_block,
-        end_block=end_block,
-        normalize=True,
-        include_volumes=True,
-        include_prices=True,
-    )
-
-    # compute candlesticks
-    prices = swaps['price__0__per__1'].values
-    x_volumes = swaps['volume__0'].values
-    if invert:
-        prices = 1 / prices
-    block_timestamps = await evm.async_get_block_timestamps(
-        swaps.index.get_level_values('block_number')
-    )
-    ohlc = ohlc_utils.compute_ohlc(
-        values=prices,  # type: ignore
-        indices=block_timestamps,
-        bin_size=candle_seconds,
-        volumes=x_volumes,  # type: ignore
-    )
-    ohlc = ohlc.iloc[-n_candles:]
-
-    min_price = min(prices)
-    max_price = max(prices)
-    min_time = ohlc.index[0]
-    max_time = ohlc.index[-1] + candle_seconds
-    render_grid = toolstr.create_grid(
-        n_rows=20,
-        n_columns=n_candles * 2,
-        xmin=min_time - 0.05 * (max_time - min_time),
-        xmax=max_time + 0.05 * (max_time - min_time),
-        ymin=min_price - 0.05 * (max_price - min_price),
-        ymax=max_price + 0.05 * (max_price - min_price),
-    )
-    sample_grid = toolstr.create_grid(sample_mode='quadrants', **render_grid)
-    result = toolstr.raster_candlesticks(ohlc.values, sample_grid, render_grid)
-    raster = result['raster']
-    color_grid = result['color_grid']
-
-    as_str = toolstr.render_supergrid(
-        raster,
-        char_dict='quadrants',
-        color_grid=color_grid,
-        color_map=toolstr.candlestick_color_map,
-    )
-
-    console = rich.console.Console(theme=rich.theme.Theme(inherit=False))
-
-    styles = cli.get_cli_styles()
-    plot_styles = {
-        'tick_label_style': 'bold',
-        'chrome_style': '#888888',
-    }
-
-    y_axis = toolstr.render_y_axis(
-        grid=render_grid,
-        **plot_styles,  # type: ignore
-    )
-    y_axis_width = rich.text.Text.from_markup(y_axis.split('\n')[0]).cell_len
-    graph = toolstr.concatenate_blocks([y_axis, as_str])
-
-    formatter = functools.partial(
-        toolstr.format_timestamp,
-        representation='TimestampDate',
-    )
-    x_axis = toolstr.render_x_axis(
-        grid=render_grid,
-        formatter=formatter,
-        **plot_styles,  # type: ignore
-    )
-    x_axis = toolstr.indent_block(x_axis, indent=y_axis_width)
-
-    # compute volume
-    if not no_volume:
-        ymax = ohlc['volume'].max() * 1.1
-        volume_render_grid = toolstr.create_grid(
-            n_rows=5,
-            n_columns=n_candles * 2,
-            xmin=render_grid['xmin'],
-            xmax=render_grid['xmax'],
-            ymin=0 - ymax / 9,
-            ymax=ymax,
-        )
-        volume_sample_grid = toolstr.create_grid(
-            sample_mode='quadrants',
-            **volume_render_grid,
-        )
-        volume_raster = toolstr.raster_bar_chart(
-            values=ohlc['volume'],  # type: ignore
-            grid=volume_sample_grid,
-            bar_width=1,
-            bar_gap=3,
-            start_gap=1,
-        )
-        volume_y_axis = toolstr.render_y_axis(
-            grid=volume_render_grid,
-            n_ticks=1,
-            **plot_styles,  # type: ignore
-        )
-
-    # wait for metadata
-    metadata = await metadata_task
-
-    # print output
-    token0 = metadata['x_symbol']
-    token1 = metadata['y_symbol']
-    toolstr.print_text_box(
-        metadata['x_symbol'] + '-' + metadata['y_symbol'] + ' Uniswap V2 Pool',
-        style=styles['title'],
-    )
-    cli.print_bullet(key='pool address', value=pool)
-    cli.print_bullet(key='each candle', value=candle_timescale)
-    cli.print_bullet(key='n_candles', value=n_candles)
-    if invert:
-        cli.print_bullet(key='price units', value=str(token1) + ' per ' + str(token0))
-    else:
-        cli.print_bullet(key='price units', value=str(token0) + ' per ' + str(token1))
-    if not no_volume:
-        cli.print_bullet(key='volume units', value=token0)
-    print()
-    console.print(graph)
-
-    if not no_volume:
-        volume_bars_str = toolstr.render_supergrid(
-            volume_raster, char_dict='quadrants'
-        )
-        volume_graph = toolstr.concatenate_blocks(
-            [volume_y_axis, volume_bars_str]
+
+class BalancerDEX(dex_class.DEX):
+    """Balancer DEX"""
+
+    _pool_factories = {1: ['0xba12222222228d8ba445958a75a0704d566bf2c8']}
+
+    @classmethod
+    async def async_get_new_pools(
+        cls,
+        *,
+        factory: spec.Address,
+        start_block: spec.BlockNumberReference | None = None,
+        end_block: spec.BlockNumberReference | None = None,
+        start_time: tooltime.Timestamp | None = None,
+        end_time: tooltime.Timestamp | None = None,
+        context: spec.Context = None,
+    ) -> typing.Sequence[spec.DexPool]:
+
+        balancer_pools = await evm.async_get_events(
+            factory,
+            event_abi=balancer_utils.vault_event_abis['PoolRegistered'],
+            verbose=False,
+            start_block=start_block,
+            end_block=end_block,
+            start_time=start_time,
+            end_time=end_time,
+            context=context,
+        )
+        token_registrations = (
+            await balancer_utils.async_get_token_registrations(
+                factory=factory,
+                start_block=start_block,
+                end_block=end_block,
+                context=context,
+            )
+        )
+
+        dex_pools = []
+        for row in balancer_pools.iter_rows(named=True):
+
+            block = int(row['block_number'])
+
+            assets: typing.Sequence[str | None] = token_registrations.get(
+                row['arg__poolId'], []
+            )
+            if len(assets) < 4:
+                assets = list(assets) + [None] * (4 - len(assets))
+            if len(assets) > 4:
+                additional_data = {'additional_assets': assets[4:]}
+                assets = assets[:4]
+            else:
+                additional_data = {}
+            asset0 = assets[0]
+            asset1 = assets[1]
+            asset2 = assets[2]
+            asset3 = assets[3]
+
+            dex_pool: spec.DexPool = {
+                'address': row['arg__poolAddress'],
+                'factory': factory,
+                'asset0': asset0,
+                'asset1': asset1,
+                'asset2': asset2,
+                'asset3': asset3,
+                'creation_block': block,
+                'fee': None,
+                'additional_data': additional_data,
+            }
+            dex_pools.append(dex_pool)
+
+        return dex_pools
+
+    @classmethod
+    async def _async_get_pool_assets_from_node(
+        cls,
+        pool: spec.Address,
+        *,
+        block: spec.BlockNumberReference | None = None,
+        context: spec.Context = None,
+    ) -> typing.Sequence[spec.Address]:
+
+        result = await balancer_utils.async_get_pool_balances(
+            pool_address=pool, context=context, block=block
+        )
+
+        return list(result.keys())
+
+    @classmethod
+    async def _async_get_pool_raw_trades(
+        cls,
+        pool: spec.Address,
+        *,
+        start_block: spec.BlockNumberReference | None = None,
+        end_block: spec.BlockNumberReference | None = None,
+        start_time: tooltime.Timestamp | None = None,
+        end_time: tooltime.Timestamp | None = None,
+        include_timestamps: bool = False,
+        verbose: bool = False,
+        context: spec.Context = None,
+    ) -> spec.RawDexTrades:
+
+        from ctc import config
+
+        network = config.get_context_chain_id(context)
+        vault = cls._pool_factories[network][0]
+        if start_block is None:
+            start_block = await evm.async_get_contract_creation_block(
+                pool,
+                context=context,
+            )
+
+        trades = await evm.async_get_events(
+            vault,
+            event_abi=balancer_utils.vault_event_abis['Swap'],
+            start_block=start_block,
+            end_block=end_block,
+            start_time=start_time,
+            end_time=end_time,
+            verbose=verbose,
+        )
+
+        assets = await cls.async_get_pool_assets(pool)
+
+        # filter by pool
+        pool_id = await balancer_utils.async_get_pool_id(
+            pool_address=pool, context=context
+        )
+        mask = trades['arg__poolId'] == pool_id
+        trades = trades[mask]
+
+        import polars as pl
+
+        output: spec.RawDexTrades = {
+            'block_number': trades['block_number'],
+            'transaction_hash': trades['transaction_hash'],
+            'recipient': None,
+            'sold_id': pl.Series(
+                [
+                    assets.index(address)
+                    for address in trades['arg__tokenIn'].to_list()
+                ],
+            ),
+            'bought_id': pl.Series(
+                [
+                    assets.index(address)
+                    for address in trades['arg__tokenOut'].to_list()
+                ],
+            ),
+            'sold_amount': trades['arg__amountIn'].apply(int),
+            'bought_amount': trades['arg__amountOut'].apply(int),
+        }
+
+        if include_timestamps:
+            output['timestamp'] = await evm.async_get_block_timestamps(
+                blocks=trades['block_number'].to_list(),
+                context=context,
+            )
+
+        return output
+
+    @classmethod
+    async def async_get_pool_balance(
+        cls,
+        pool: spec.Address,
+        asset: spec.Address,
+        *,
+        factory: spec.Address | None = None,
+        normalize: bool = True,
+        block: spec.BlockNumberReference | None = None,
+        context: spec.Context = None,
+    ) -> int | float:
+
+        from ctc.protocols import balancer_utils
+
+        pool_balances = await balancer_utils.async_get_pool_balances(
+            pool_address=pool,
+            block=block,
+            normalize=normalize,
+            context=context,
         )
-        toolstr.print(volume_graph)
+        return pool_balances[asset]
 
-    # print x axis
-    console.print(x_axis)
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/uniswap_v2_utils/cli/mints_command.py` & `checkthechain-0.3.4/src/ctc/protocols/uniswap_v2_utils/cli/swaps_command.py`

 * *Files 7% similar despite different names*

```diff
@@ -5,16 +5,16 @@
 from ctc.protocols import uniswap_v2_utils
 from ctc.cli import cli_utils
 from ctc import spec
 
 
 def get_command_spec() -> toolcli.CommandSpec:
     return {
-        'f': async_burns_command,
-        'help': 'output information about pool mints',
+        'f': async_swaps_command,
+        'help': 'output information about pool swaps',
         'args': [
             {'name': 'pool', 'help': 'pool address'},
             {'name': '--blocks', 'help': 'block number range'},
             {
                 'name': '--export',
                 'default': 'stdout',
                 'help': 'file path for output (.json or .csv)',
@@ -27,27 +27,28 @@
         ],
         'examples': [
             '0xae461ca67b15dc8dc81ce7615e0320da1a9ab8d5 --blocks 14000000:14001000',
         ],
     }
 
 
-async def async_burns_command(
+async def async_swaps_command(
     *,
     pool: spec.Address,
-    blocks: str | None,
+    blocks: str,
     export: str,
     overwrite: bool,
 ) -> None:
 
     if blocks is not None:
         start_block, end_block = await cli_utils.async_parse_block_range(blocks)
     else:
         start_block = None
         end_block = None
 
-    burns = await uniswap_v2_utils.async_get_pool_burns(
+    swaps = await uniswap_v2_utils.async_get_pool_swaps(
         pool,
+        label='symbol',
         start_block=start_block,
         end_block=end_block,
     )
-    cli_utils.output_data(burns, export, overwrite=overwrite)
+    cli_utils.output_data(swaps, export, overwrite=overwrite)
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/uniswap_v2_utils/uniswap_v2_deltas.py` & `checkthechain-0.3.4/src/ctc/protocols/uniswap_v2_utils/uniswap_v2_deltas.py`

 * *Files 19% similar despite different names*

```diff
@@ -16,214 +16,261 @@
     *,
     start_block: typing.Optional[spec.BlockNumberReference] = None,
     end_block: typing.Optional[spec.BlockNumberReference] = None,
     start_time: tooltime.Timestamp | None = None,
     end_time: tooltime.Timestamp | None = None,
     normalize: bool = True,
     include_initial_state: bool = True,
+    context: spec.Context = None,
 ) -> spec.DataFrame:
     import asyncio
-    import pandas as pd
+    import polars as pl
 
     # get start_block and initial conditions
     start_block, end_block = await evm.async_resolve_block_range(
         start_block=start_block,
         end_block=end_block,
         start_time=start_time,
         end_time=end_time,
         allow_none=True,
+        context=context,
     )
     if start_block is None:
-        start_block = await evm.async_get_contract_creation_block(pool)
+        start_block = await evm.async_get_contract_creation_block(
+            pool, context=context
+        )
         initial_point_task = None
     else:
         if include_initial_state:
             coroutine = uniswap_v2_state.async_get_pool_state(
                 pool,
                 block=start_block,
                 normalize=normalize,
+                context=context,
             )
             initial_point_task = asyncio.create_task(coroutine)
         else:
             initial_point_task = None
 
     # get mints, burns, and swaps
     mints_task = uniswap_v2_events.async_get_pool_mints(
         pool,
         start_block=start_block,
         end_block=end_block,
         normalize=normalize,
+        context=context,
     )
     burns_task = uniswap_v2_events.async_get_pool_burns(
         pool,
         start_block=start_block,
         end_block=end_block,
         normalize=normalize,
+        context=context,
     )
     swaps_task = uniswap_v2_events.async_get_pool_swaps(
         pool,
         start_block=start_block,
         end_block=end_block,
         normalize=normalize,
+        context=context,
     )
     mints, burns, swaps = await asyncio.gather(
         mints_task, burns_task, swaps_task
     )
 
     # gather as DataFrames
     dfs = [
-        pd.DataFrame(
+        pl.DataFrame(
             {
+                'block_number': mints['block_number'],
+                'transaction_index': mints['transaction_index'],
+                'log_index': mints['log_index'],
                 'event': 'Mint',
                 'delta_token0': mints['arg__amount0'],
                 'delta_token1': mints['arg__amount1'],
             }
         ),
-        pd.DataFrame(
+        pl.DataFrame(
             {
+                'block_number': mints['block_number'],
+                'transaction_index': mints['transaction_index'],
+                'log_index': mints['log_index'],
                 'event': 'Burn',
                 'delta_token0': -burns['arg__amount0'],
                 'delta_token1': -burns['arg__amount1'],
             }
         ),
-        pd.DataFrame(
+        pl.DataFrame(
             {
+                'block_number': mints['block_number'],
+                'transaction_index': mints['transaction_index'],
+                'log_index': mints['log_index'],
                 'event': 'Swap',
                 'delta_token0': swaps['x_sold'] - swaps['x_bought'],
                 'delta_token1': swaps['y_sold'] - swaps['y_bought'],
             },
         ),
     ]
 
     # add initial point
     if initial_point_task is not None:
         initial_point = await initial_point_task
-        initial_point_df = pd.DataFrame(
+        initial_point_df = pl.DataFrame(
             {
+                'block_number': start_block,
+                'transaction_index': 0,
+                'log_index': 0,
                 'event': 'Initial',
                 'delta_token0': initial_point['x_reserves'],
                 'delta_token1': initial_point['y_reserves'],
             }
         )
         dfs.append(initial_point_df)
 
-    df = pd.concat(dfs)
-    df = df.sort_index()
+    df = pl.concat(dfs)
+    df = df.sort('block_number', 'log_index')
 
     return df
 
 
 async def async_get_pool_transaction_deltas(
     pool: typing.Optional[spec.Address] = None,
     log_deltas: typing.Optional[spec.DataFrame] = None,
+    *,
+    context: spec.Context = None,
     **log_delta_kwargs: typing.Any,
 ) -> spec.DataFrame:
 
     if log_deltas is None:
         if pool is None:
             raise Exception('must specify pool or log_deltas')
-        log_deltas = await async_get_pool_log_deltas(pool, **log_delta_kwargs)
+        log_deltas = await async_get_pool_log_deltas(
+            pool, context=context, **log_delta_kwargs
+        )
 
     transaction_deltas: spec.DataFrame = log_deltas.groupby(
         ['block_number', 'transaction_index']
     ).sum()
 
     return transaction_deltas
 
 
 async def async_get_pool_block_deltas(
     pool: typing.Optional[spec.Address] = None,
     log_deltas: typing.Optional[spec.DataFrame] = None,
+    *,
+    context: spec.Context = None,
     **log_delta_kwargs: typing.Any,
 ) -> spec.DataFrame:
 
     if log_deltas is None:
         if pool is None:
             raise Exception('must specify pool or log_deltas')
-        log_deltas = await async_get_pool_log_deltas(pool, **log_delta_kwargs)
+        log_deltas = await async_get_pool_log_deltas(
+            pool, context=context, **log_delta_kwargs
+        )
 
     block_deltas: spec.DataFrame = log_deltas.groupby(['block_number']).sum()
 
     return block_deltas
 
 
 async def async_get_pool_state_per_log(
     pool: typing.Optional[spec.Address] = None,
     log_deltas: typing.Optional[spec.DataFrame] = None,
+    *,
+    context: spec.Context = None,
     **log_delta_kwargs: typing.Any,
 ) -> spec.DataFrame:
 
+    import polars as pl
+
     if log_deltas is None:
         if pool is None:
             raise Exception('must specify pool or log_deltas')
-        log_deltas = await async_get_pool_log_deltas(pool, **log_delta_kwargs)
+        log_deltas = await async_get_pool_log_deltas(
+            pool, context=context, **log_delta_kwargs
+        )
 
-    state_per_log: spec.DataFrame = log_deltas[
-        ['delta_token0', 'delta_token1']
-    ].cumsum()
-    state_per_log.columns = ['token0_reserves', 'token1_reserves']
+    state_per_log = log_deltas.select(
+        pl.col('delta_token0').cumsum().alias('token0_reserves'),
+        pl.col('delta_token1').cumsum().alias('token1_reserves'),
+    )
 
     _put_price_in_state(state_per_log)
 
     return state_per_log
 
 
 async def async_get_pool_state_per_transaction(
     pool: typing.Optional[spec.Address] = None,
     log_deltas: typing.Optional[spec.DataFrame] = None,
+    *,
+    context: spec.Context = None,
     **log_delta_kwargs: typing.Any,
 ) -> spec.DataFrame:
 
+    import polars as pl
+
     if log_deltas is None:
         if pool is None:
             raise Exception('must specify pool or log_deltas')
-        log_deltas = await async_get_pool_log_deltas(pool, **log_delta_kwargs)
+        log_deltas = await async_get_pool_log_deltas(
+            pool, context=context, **log_delta_kwargs
+        )
 
     transaction_deltas = await async_get_pool_transaction_deltas(
-        log_deltas=log_deltas, **log_delta_kwargs
+        log_deltas=log_deltas, context=context, **log_delta_kwargs
     )
 
-    state_per_transaction: spec.DataFrame = transaction_deltas[
-        ['delta_token0', 'delta_token1']
-    ].cumsum()
-    state_per_transaction.columns = ['token0_reserves', 'token1_reserves']
+    state_per_transaction = transaction_deltas.select(
+        pl.col('delta_token0').cumsum().alias('token0_reserves'),
+        pl.col('delta_token1').cumsum().alias('token1_reserves'),
+    )
 
     _put_price_in_state(state_per_transaction)
 
     return state_per_transaction
 
 
 async def async_integrate_pool_deltas(
     pool: typing.Optional[spec.Address] = None,
     *,
     interpolate: bool = False,
     log_deltas: typing.Optional[spec.DataFrame] = None,
+    context: spec.Context = None,
     **log_delta_kwargs: typing.Any,
 ) -> spec.DataFrame:
 
+    import polars as pl
+    from ctc.toolbox import pl_utils
+
     if log_deltas is None:
         if pool is None:
             raise Exception('must specify pool or log_deltas')
-        log_deltas = await async_get_pool_log_deltas(pool, **log_delta_kwargs)
+        log_deltas = await async_get_pool_log_deltas(
+            pool, context=context, **log_delta_kwargs
+        )
 
     block_deltas = await async_get_pool_block_deltas(
-        log_deltas=log_deltas, **log_delta_kwargs
+        log_deltas=log_deltas, context=context, **log_delta_kwargs
     )
 
-    state_per_block: spec.DataFrame = block_deltas[
-        ['delta_token0', 'delta_token1']
-    ].cumsum()
-    state_per_block.columns = ['token0_reserves', 'token1_reserves']
+    state_per_block: spec.DataFrame = block_deltas.select(
+        pl.col('delta_token0').cumsum().alias('token0_reserves'),
+        pl.col('delta_token1').cumsum().alias('token1_reserves'),
+    )
 
     _put_price_in_state(state_per_block)
 
     if interpolate:
-        from ctc.toolbox import pd_utils
-
-        state_per_block = pd_utils.interpolate_dataframe(state_per_block)
+        state_per_block = pl_utils.interpolate(
+            state_per_block, index_column='block_number'
+        )
 
     return state_per_block
 
 
 def _put_price_in_state(state: spec.DataFrame) -> None:
     state['price_0_per_1'] = state['token0_reserves'] / state['token1_reserves']
     state['price_1_per_0'] = state['token1_reserves'] / state['token0_reserves']
+
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/uniswap_v2_utils/uniswap_v2_events.py` & `checkthechain-0.3.4/src/ctc/protocols/uniswap_v2_utils/uniswap_v2_events.py`

 * *Files 19% similar despite different names*

```diff
@@ -22,159 +22,167 @@
     start_time: tooltime.Timestamp | None = None,
     end_time: tooltime.Timestamp | None = None,
     include_timestamps: bool = False,
     include_prices: bool = False,
     include_volumes: bool = False,
     label: Literal['index', 'symbol', 'address'] = 'index',
     normalize: bool = True,
-    provider: spec.ProviderReference = None,
     verbose: bool = False,
+    context: spec.Context = None,
 ) -> spec.DataFrame:
-
-    from ctc.toolbox.defi_utils import dex_utils
+    from ctc.defi import dex_utils
 
     return await dex_utils.UniswapV2DEX.async_get_pool_trades(
         pool=pool,
         start_block=start_block,
         end_block=end_block,
         start_time=start_time,
         end_time=end_time,
         include_timestamps=include_timestamps,
         include_prices=include_prices,
         include_volumes=include_volumes,
         label=label,
         normalize=normalize,
-        provider=provider,
         verbose=verbose,
+        context=context,
     )
 
 
 async def async_get_pool_mints(
     pool_address: spec.Address,
     *,
     start_block: typing.Optional[spec.BlockNumberReference] = None,
     end_block: typing.Optional[spec.BlockNumberReference] = None,
     start_time: tooltime.Timestamp | None = None,
     end_time: tooltime.Timestamp | None = None,
     include_timestamps: bool = False,
     replace_symbols: bool = False,
     normalize: bool = True,
-    provider: spec.ProviderReference = None,
     verbose: bool = False,
+    context: spec.Context = None,
 ) -> spec.DataFrame:
     import asyncio
 
     if normalize:
         decimals_task = asyncio.create_task(
             uniswap_v2_metadata.async_get_pool_decimals(
-                pool_address, provider=provider
+                pool_address, context=context
             )
         )
     if replace_symbols:
         symbols_task = asyncio.create_task(
             uniswap_v2_metadata.async_get_pool_symbols(
-                pool_address, provider=provider
+                pool_address, context=context
             )
         )
 
     mints = await evm.async_get_events(
         event_abi=uniswap_v2_spec.pool_event_abis['Mint'],
         contract_address=pool_address,
         start_block=start_block,
         end_block=end_block,
         start_time=start_time,
         end_time=end_time,
         include_timestamps=include_timestamps,
-        provider=provider,
         verbose=verbose,
+        context=context,
     )
-    mints['arg__amount0'] = mints['arg__amount0'].map(int)
-    mints['arg__amount1'] = mints['arg__amount1'].map(int)
+    mints['arg__amount0'] = mints['arg__amount0'].apply(int)
+    mints['arg__amount1'] = mints['arg__amount1'].apply(int)
 
     if normalize:
         decimals0, decimals1 = await decimals_task
         mints['arg__amount0'] = await evm.async_normalize_erc20_quantities(
-            quantities=mints['arg__amount0'].astype(float),
+            quantities=mints['arg__amount0'].apply(float),
             decimals=decimals0,
-            provider=provider,
+            context=context,
         )
         mints['arg__amount1'] = await evm.async_normalize_erc20_quantities(
-            quantities=mints['arg__amount1'].astype(float),
+            quantities=mints['arg__amount1'].apply(float),
             decimals=decimals1,
-            provider=provider,
+            context=context,
         )
 
     if replace_symbols:
         symbol0, symbol1 = await symbols_task
         new_names = {
             'arg__amount0': symbol0 + '_amount',
             'arg__amount1': symbol1 + '_amount',
         }
-        mints = mints.rename(columns=new_names)
+        mints = mints.rename(new_names)
 
     return mints
 
 
 async def async_get_pool_burns(
     pool_address: spec.Address,
     *,
     start_block: typing.Optional[spec.BlockNumberReference] = None,
     end_block: typing.Optional[spec.BlockNumberReference] = None,
     start_time: tooltime.Timestamp | None = None,
     end_time: tooltime.Timestamp | None = None,
     include_timestamps: bool = False,
     replace_symbols: bool = False,
     normalize: bool = True,
-    provider: spec.ProviderReference = None,
     verbose: bool = False,
+    context: spec.Context = None,
 ) -> spec.DataFrame:
     import asyncio
+    import polars as pl
 
     if normalize:
         decimals_task = asyncio.create_task(
             uniswap_v2_metadata.async_get_pool_decimals(
-                pool_address, provider=provider
+                pool_address, context=context
             )
         )
     if replace_symbols:
         symbols_task = asyncio.create_task(
             uniswap_v2_metadata.async_get_pool_symbols(
-                pool_address, provider=provider
+                pool_address, context=context
             )
         )
 
+    if normalize:
+        integer_output_format: spec.IntegerOutputFormat = float
+    else:
+        integer_output_format = int
     burns = await evm.async_get_events(
         event_abi=uniswap_v2_spec.pool_event_abis['Burn'],
         contract_address=pool_address,
         start_block=start_block,
         end_block=end_block,
         start_time=start_time,
         end_time=end_time,
         include_timestamps=include_timestamps,
-        provider=provider,
+        context=context,
         verbose=verbose,
+        integer_output_format=integer_output_format,
     )
-    burns['arg__amount0'] = burns['arg__amount0'].map(int)
-    burns['arg__amount1'] = burns['arg__amount1'].map(int)
 
     if normalize:
         decimals0, decimals1 = await decimals_task
-        burns['arg__amount0'] = await evm.async_normalize_erc20_quantities(
-            quantities=burns['arg__amount0'].astype(float),
+        arg__amount0 = await evm.async_normalize_erc20_quantities(
+            quantities=burns['arg__amount0'],
             decimals=decimals0,
-            provider=provider,
+            context=context,
         )
-        burns['arg__amount1'] = await evm.async_normalize_erc20_quantities(
-            quantities=burns['arg__amount1'].astype(float),
+        arg__amount1 = await evm.async_normalize_erc20_quantities(
+            quantities=burns['arg__amount1'],
             decimals=decimals1,
-            provider=provider,
+            context=context,
+        )
+        burns = burns.with_columns(
+            pl.Series('arg__amount0', arg__amount0),
+            pl.Series('arg__amount1', arg__amount1),
         )
 
     if replace_symbols:
         symbol0, symbol1 = await symbols_task
         new_names = {
             'arg__amount0': symbol0 + '_amount',
             'arg__amount1': symbol1 + '_amount',
         }
-        burns = burns.rename(columns=new_names)
+        burns = burns.rename(new_names)
 
     return burns
+
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/uniswap_v2_utils/uniswap_v2_metadata.py` & `checkthechain-0.3.4/src/ctc/protocols/uniswap_v2_utils/uniswap_v2_metadata.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,99 +1,103 @@
 from __future__ import annotations
 
+import typing
+
 from ctc import evm
 from ctc import rpc
 from ctc import spec
 
 from . import uniswap_v2_spec
 
 
 async def async_get_pool_tokens(
     pool: spec.Address,
-    provider: spec.ProviderReference = None,
+    *,
+    context: spec.Context = None,
 ) -> tuple[spec.Address, spec.Address]:
     import asyncio
 
     token0 = rpc.async_eth_call(
         function_abi=uniswap_v2_spec.pool_function_abis['token0'],
         to_address=pool,
-        provider=provider,
+        context=context,
     )
     token1 = rpc.async_eth_call(
         function_abi=uniswap_v2_spec.pool_function_abis['token1'],
         to_address=pool,
-        provider=provider,
+        context=context,
     )
 
     return await asyncio.gather(token0, token1)
 
 
 async def async_get_pool_symbols(
     pool: spec.Address | None = None,
     *,
     x_address: spec.Address | None = None,
     y_address: spec.Address | None = None,
-    provider: spec.ProviderReference = None,
-) -> list[str]:
+    context: spec.Context = None,
+) -> typing.Sequence[str]:
 
     if x_address is None or y_address is None:
         if pool is None:
             raise Exception('must specify pool or tokens')
         x_address, y_address = await async_get_pool_tokens(
-            pool=pool, provider=provider
+            pool=pool, context=context
         )
 
     return await evm.async_get_erc20s_symbols(
         tokens=[x_address, y_address],
-        provider=provider,
+        context=context,
     )
 
 
 async def async_get_pool_decimals(
     pool: spec.Address | None = None,
     *,
     x_address: spec.Address | None = None,
     y_address: spec.Address | None = None,
-    provider: spec.ProviderReference = None,
-) -> list[int]:
+    context: spec.Context = None,
+) -> typing.Sequence[int]:
 
     if x_address is None or y_address is None:
         if pool is None:
             raise Exception('must specify pool or tokens')
         x_address, y_address = await async_get_pool_tokens(
-            pool=pool, provider=provider
+            pool=pool, context=context
         )
 
     return await evm.async_get_erc20s_decimals(
         tokens=[x_address, y_address],
-        provider=provider,
+        context=context,
     )
 
 
 async def async_get_pool_tokens_metadata(
     pool: spec.Address,
-    provider: spec.ProviderReference = None,
+    *,
+    context: spec.Context = None,
 ) -> uniswap_v2_spec.PoolTokensMetadata:
     import asyncio
 
     x_address, y_address = await async_get_pool_tokens(
         pool=pool,
-        provider=provider,
+        context=context,
     )
 
     symbols_coroutine = async_get_pool_symbols(
         x_address=x_address,
         y_address=y_address,
-        provider=provider,
+        context=context,
     )
 
     decimals_coroutine = async_get_pool_decimals(
         x_address=x_address,
         y_address=y_address,
-        provider=provider,
+        context=context,
     )
 
     symbols, decimals = await asyncio.gather(
         symbols_coroutine, decimals_coroutine
     )
     x_symbol, y_symbol = symbols
     x_decimals, y_decimals = decimals
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/uniswap_v2_utils/uniswap_v2_spec.py` & `checkthechain-0.3.4/src/ctc/protocols/uniswap_v2_utils/uniswap_v2_spec.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,40 +1,38 @@
 from __future__ import annotations
 
 import typing
-from typing_extensions import TypedDict
 
 from ctc import spec
 
+if typing.TYPE_CHECKING:
+    from typing_extensions import TypedDict
 
-uniswap_v2_factory = '0x5c69bee701ef814a2b6a3edd4b1652cb9cc5aa6f'
-
-trade_fee = 0.003
+    class PoolTokensMetadata(TypedDict):
+        x_address: spec.Address
+        y_address: spec.Address
+        x_symbol: str
+        y_symbol: str
+        x_decimals: int
+        y_decimals: int
+
+    class PoolState(TypedDict):
+        x_reserves: typing.Union[int, float]
+        y_reserves: typing.Union[int, float]
+        lp_total_supply: typing.Union[int, float]
+
+    class PoolStateByBlock(TypedDict):
+        x_reserves: list[typing.Union[int, float]]
+        y_reserves: list[typing.Union[int, float]]
+        lp_total_supply: list[typing.Union[int, float]]
 
 
-class PoolTokensMetadata(TypedDict):
-    x_address: spec.Address
-    y_address: spec.Address
-    x_symbol: str
-    y_symbol: str
-    x_decimals: int
-    y_decimals: int
-
-
-class PoolState(TypedDict):
-    x_reserves: typing.Union[int, float]
-    y_reserves: typing.Union[int, float]
-    lp_total_supply: typing.Union[int, float]
-
-
-class PoolStateByBlock(TypedDict):
-    x_reserves: list[typing.Union[int, float]]
-    y_reserves: list[typing.Union[int, float]]
-    lp_total_supply: list[typing.Union[int, float]]
+uniswap_v2_factory = '0x5c69bee701ef814a2b6a3edd4b1652cb9cc5aa6f'
 
+trade_fee = 0.003
 
 factory_event_abis: typing.Mapping[str, spec.EventABI] = {
     'PairCreated': {
         'anonymous': False,
         'inputs': [
             {
                 'indexed': True,
@@ -194,7 +192,8 @@
                 'type': 'address',
             },
         ],
         'name': 'Swap',
         'type': 'event',
     },
 }
+
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/uniswap_v2_utils/uniswap_v2_state.py` & `checkthechain-0.3.4/src/ctc/protocols/uniswap_v2_utils/uniswap_v2_state.py`

 * *Files 22% similar despite different names*

```diff
@@ -11,22 +11,22 @@
 
 
 async def async_replace_pool_state_symbols(
     pool_state: typing.Mapping[str, typing.Any],
     *,
     pool: spec.Address | None = None,
     symbols: typing.Optional[typing.Sequence[str]] = None,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
 ) -> typing.Mapping[str, typing.Any]:
 
     if symbols is None:
         if pool is None:
             raise Exception('must specify pool or symbols')
         symbols = await uniswap_v2_metadata.async_get_pool_symbols(
-            pool=pool, provider=provider
+            pool=pool, context=context
         )
 
     x_symbol, y_symbol = symbols
 
     return {
         x_symbol + '_reserves': pool_state['x_reserves'],
         y_symbol + '_reserves': pool_state['y_reserves'],
@@ -34,90 +34,92 @@
     }
 
 
 async def async_get_pool_state(
     pool: spec.Address,
     *,
     block: spec.BlockNumberReference | None = None,
-    provider: spec.ProviderReference = None,
     normalize: bool = True,
     fill_empty: bool = True,
+    context: spec.Context = None,
 ) -> uniswap_v2_spec.PoolState:
     import asyncio
 
     if block is None:
         block = 'latest'
 
-    block = await evm.async_block_number_to_int(block, provider=provider)
+    block = await evm.async_block_number_to_int(block, context=context)
 
     if fill_empty:
         empty_token = 0
     else:
         empty_token = None
 
     # reserves
     token_x, token_y = await uniswap_v2_metadata.async_get_pool_tokens(
-        pool=pool, provider=provider
+        pool=pool, context=context
     )
     reserves_coroutine = evm.async_get_erc20s_balances(
         wallet=pool,
         tokens=[token_x, token_y],
         block=block,
-        provider=provider,
+        context=context,
         normalize=normalize,
         fill_empty=fill_empty,
         empty_token=empty_token,
     )
     reserves_task = asyncio.create_task(reserves_coroutine)
 
     # total supply
     lp_total_supply_coroutine = evm.async_get_erc20_total_supply(
         token=pool,
         block=block,
-        provider=provider,
+        context=context,
         normalize=normalize,
         fill_empty=fill_empty,
         empty_token=empty_token,
     )
     lp_total_supply_task = asyncio.create_task(lp_total_supply_coroutine)
 
     # await results
     token_x_reserves, token_y_reserves = await reserves_task
     lp_total_supply = await lp_total_supply_task
+    if lp_total_supply is None:
+        raise Exception('invalid value for lp_total_supply')
 
     output: uniswap_v2_spec.PoolState = {
         'x_reserves': token_x_reserves,
         'y_reserves': token_y_reserves,
         'lp_total_supply': lp_total_supply,
     }
     return output
 
 
 async def async_get_pool_state_by_block(
     pool: spec.Address,
     *,
     blocks: typing.Sequence[spec.BlockNumberReference],
-    provider: spec.ProviderReference = None,
     normalize: bool = True,
+    context: spec.Context = None,
 ) -> uniswap_v2_spec.PoolStateByBlock:
     import asyncio
 
     if normalize:
         decimals_coroutine = uniswap_v2_metadata.async_get_pool_decimals(
             pool=pool,
-            provider=provider,
+            context=context,
         )
         decimals_task = asyncio.create_task(decimals_coroutine)
 
     coroutines = [
         async_get_pool_state(
             pool=pool,
             block=block,
-            provider=provider,
             normalize=False,
+            context=context,
         )
         for block in blocks
     ]
     results: list[uniswap_v2_spec.PoolState] = await asyncio.gather(*coroutines)
 
     output: uniswap_v2_spec.PoolStateByBlock = (
         nested_utils.list_of_dicts_to_dict_of_lists(results)  # type: ignore
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/uniswap_v3_utils/contracts/pool_derived_state.py` & `checkthechain-0.3.4/src/ctc/protocols/uniswap_v3_utils/contracts/pool_derived_state.py`

 * *Files 13% similar despite different names*

```diff
@@ -6,50 +6,50 @@
 from .. import uniswap_v3_spec
 
 
 async def async_pool_observe(
     seconds_agos: list[int],
     pool: spec.Address,
     *,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     block: spec.BlockNumberReference | None = None,
 ) -> dict[str, int]:
     function_abi = await uniswap_v3_spec.async_get_function_abi(
         'observe', 'pool'
     )
     result = await rpc.async_eth_call(
         to_address=pool,
         function_abi=function_abi,
         function_parameters=[seconds_agos],
-        provider=provider,
+        context=context,
         block_number=block,
     )
     return {
         'tick_cumulatives': result[0],
         'seconds_per_liquidity_cumulative_x128': result[1],
     }
 
 
 async def async_pool_snapshot_cumulatives_inside(
     *,
     tick_lower: int,
     tick_upper: int,
     pool: spec.Address,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     block: spec.BlockNumberReference | None = None,
 ) -> dict[str, int]:
     function_abi = await uniswap_v3_spec.async_get_function_abi(
         'snapshotCumulativesInside',
         'pool',
     )
     result = await rpc.async_eth_call(
         to_address=pool,
         function_abi=function_abi,
         function_parameters=[tick_lower, tick_upper],
-        provider=provider,
+        context=context,
         block_number=block,
     )
     return {
         'tick_cumulative_inside': result[0],
         'seconds_per_liquidity_x128': result[1],
         'seconds_inside': result[2],
     }
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/uniswap_v3_utils/contracts/pool_immutables.py` & `checkthechain-0.3.4/src/ctc/protocols/uniswap_v3_utils/contracts/pool_immutables.py`

 * *Files 20% similar despite different names*

```diff
@@ -5,121 +5,122 @@
 
 from .. import uniswap_v3_spec
 
 
 async def async_pool_factory(
     pool: spec.Address,
     *,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     block: spec.BlockNumberReference | None = None,
 ) -> spec.Address:
     function_abi = await uniswap_v3_spec.async_get_function_abi(
         'factory', 'pool'
     )
     result = await rpc.async_eth_call(
         to_address=pool,
         function_abi=function_abi,
-        provider=provider,
+        context=context,
         block_number=block,
     )
     if not isinstance(result, str):
         raise Exception('invalid rpc result')
     return result
 
 
 async def async_pool_token0(
     pool: spec.Address,
     *,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     block: spec.BlockNumberReference | None = None,
 ) -> spec.Address:
     function_abi = await uniswap_v3_spec.async_get_function_abi(
         'token0', 'pool'
     )
     result = await rpc.async_eth_call(
         to_address=pool,
         function_abi=function_abi,
-        provider=provider,
+        context=context,
         block_number=block,
     )
     if not isinstance(result, str):
         raise Exception('invalid rpc result')
     return result
 
 
 async def async_pool_token1(
     pool: spec.Address,
     *,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     block: spec.BlockNumberReference | None = None,
 ) -> spec.Address:
     function_abi = await uniswap_v3_spec.async_get_function_abi(
         'token1', 'pool'
     )
     result = await rpc.async_eth_call(
         to_address=pool,
         function_abi=function_abi,
-        provider=provider,
+        context=context,
         block_number=block,
     )
     if not isinstance(result, str):
         raise Exception('invalid rpc result')
     return result
 
 
 async def async_pool_fee(
     pool: spec.Address,
     *,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     block: spec.BlockNumberReference | None = None,
 ) -> int:
     function_abi = await uniswap_v3_spec.async_get_function_abi('fee', 'pool')
     result = await rpc.async_eth_call(
         to_address=pool,
         function_abi=function_abi,
-        provider=provider,
+        context=context,
         block_number=block,
     )
     if not isinstance(result, int):
         raise Exception('invalid rpc result')
     return result
 
 
 async def async_pool_tick_spacing(
     pool: spec.Address,
     *,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     block: spec.BlockNumberReference | None = None,
 ) -> int:
     function_abi = await uniswap_v3_spec.async_get_function_abi(
         'tickSpacing', 'pool'
     )
     result = await rpc.async_eth_call(
         to_address=pool,
         function_abi=function_abi,
-        provider=provider,
+        context=context,
         block_number=block,
     )
     if not isinstance(result, int):
         raise Exception('invalid rpc result')
     return result
 
 
 async def async_pool_max_liquidity_per_tick(
     pool: spec.Address,
     *,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     block: spec.BlockNumberReference | None = None,
 ) -> int:
     function_abi = await uniswap_v3_spec.async_get_function_abi(
         'maxLiquidityPerTick',
         'pool',
     )
     result = await rpc.async_eth_call(
         to_address=pool,
         function_abi=function_abi,
-        provider=provider,
+        context=context,
         block_number=block,
     )
     if not isinstance(result, int):
         raise Exception('invalid rpc result')
     return result
+
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/uniswap_v3_utils/contracts/pool_state.py` & `checkthechain-0.3.4/src/ctc/protocols/uniswap_v3_utils/contracts/pool_state.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,29 +1,47 @@
 from __future__ import annotations
 
 import typing
-from typing_extensions import TypedDict
 
 from ctc import rpc
 from ctc import spec
 
 from .. import uniswap_v3_spec
 
+if typing.TYPE_CHECKING:
+    from typing_extensions import TypedDict
+
+    class UniswapV3Ticks(TypedDict):
+        liquidity_gross: int
+        liquidity_net: int
+        fee_growth_outside_0_x128: int
+        fee_growth_outside_1_x128: int
+        tick_cummulative_outside: int
+        seconds_per_liquidity_outside_x128: int
+        seconds_outside: int
+        initialized: bool
+
+    class UniswapV3Observations(TypedDict):
+        block_timestamp: int
+        tick_cummulative: int
+        seconds_per_liquidity_cummulative_x128: int
+        initialized: bool
+
 
 async def async_pool_slot0(
     pool: spec.Address,
     *,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     block: spec.BlockNumberReference | None = None,
 ) -> dict[str, int]:
     function_abi = await uniswap_v3_spec.async_get_function_abi('slot0', 'pool')
     result = await rpc.async_eth_call(
         to_address=pool,
         function_abi=function_abi,
-        provider=provider,
+        context=context,
         block_number=block,
     )
     return {
         'sqrt_price_x96': result[0],
         'tick': result[1],
         'observation_index': result[2],
         'observation_cardinality': result[3],
@@ -32,67 +50,67 @@
         'unlocked': result[6],
     }
 
 
 async def async_pool_fee_growth_global_0_x128(
     pool: spec.Address,
     *,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     block: spec.BlockNumberReference | None = None,
 ) -> int:
     function_abi = await uniswap_v3_spec.async_get_function_abi(
         'feeGrowthGlobal0X128',
         'pool',
     )
     result = await rpc.async_eth_call(
         to_address=pool,
         function_abi=function_abi,
-        provider=provider,
+        context=context,
         block_number=block,
     )
     if not isinstance(result, int):
         raise Exception('invalid rpc result')
     return result
 
 
 async def async_pool_fee_growth_global_1_x128(
     pool: spec.Address,
     *,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     block: spec.BlockNumberReference | None = None,
 ) -> int:
     function_abi = await uniswap_v3_spec.async_get_function_abi(
         'feeGrowthGlobal1X128',
         'pool',
     )
     result = await rpc.async_eth_call(
         to_address=pool,
         function_abi=function_abi,
-        provider=provider,
+        context=context,
         block_number=block,
     )
     if not isinstance(result, int):
         raise Exception('invalid rpc result')
     return result
 
 
 async def async_pool_protocol_fees(
     pool: spec.Address,
     *,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     block: spec.BlockNumberReference | None = None,
 ) -> tuple[int, int]:
     function_abi = await uniswap_v3_spec.async_get_function_abi(
         'protocolFees',
         'pool',
     )
     result = await rpc.async_eth_call(
         to_address=pool,
         function_abi=function_abi,
-        provider=provider,
+        context=context,
         block_number=block,
     )
     if (
         not isinstance(result, tuple)
         or len(result) != 2
         or not isinstance(result[0], int)
         or not isinstance(result[1], int)
@@ -100,56 +118,45 @@
         raise Exception('invalid rpc result')
     return typing.cast(typing.Tuple[int, int], result)
 
 
 async def async_pool_liquidity(
     pool: spec.Address,
     *,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     block: spec.BlockNumberReference | None = None,
 ) -> int:
     function_abi = await uniswap_v3_spec.async_get_function_abi(
         'liquidity',
         'pool',
     )
     result = await rpc.async_eth_call(
         to_address=pool,
         function_abi=function_abi,
-        provider=provider,
+        context=context,
         block_number=block,
     )
     if not isinstance(result, int):
         raise Exception('invalid rpc result')
     return result
 
 
-class UniswapV3Ticks(TypedDict):
-    liquidity_gross: int
-    liquidity_net: int
-    fee_growth_outside_0_x128: int
-    fee_growth_outside_1_x128: int
-    tick_cummulative_outside: int
-    seconds_per_liquidity_outside_x128: int
-    seconds_outside: int
-    initialized: bool
-
-
 async def async_pool_ticks(
     tick: int,
     pool: spec.Address,
     *,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     block: spec.BlockNumberReference | None = None,
 ) -> UniswapV3Ticks:
     function_abi = await uniswap_v3_spec.async_get_function_abi('ticks', 'pool')
     result = await rpc.async_eth_call(
         to_address=pool,
         function_abi=function_abi,
         function_parameters=[tick],
-        provider=provider,
+        context=context,
         block_number=block,
     )
     return {
         'liquidity_gross': result[0],
         'liquidity_net': result[1],
         'fee_growth_outside_0_x128': result[2],
         'fee_growth_outside_1_x128': result[3],
@@ -160,84 +167,78 @@
     }
 
 
 async def async_pool_tick_bitmap(
     word_position: int,
     pool: spec.Address,
     *,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     block: spec.BlockNumberReference | None = None,
 ) -> int:
     function_abi = await uniswap_v3_spec.async_get_function_abi(
         'tickBitmap',
         'pool',
     )
     result = await rpc.async_eth_call(
         to_address=pool,
         function_abi=function_abi,
-        provider=provider,
+        context=context,
         block_number=block,
         function_parameters=[word_position],
     )
     if not isinstance(result, int):
         raise Exception('invalid rpc result')
     return result
 
 
 async def async_pool_positions(
     key: str,
     pool: spec.Address,
     *,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     block: spec.BlockNumberReference | None = None,
 ) -> dict[str, int]:
     function_abi = await uniswap_v3_spec.async_get_function_abi(
         'positions',
         'pool',
     )
     result = await rpc.async_eth_call(
         to_address=pool,
         function_abi=function_abi,
         function_parameters=[key],
-        provider=provider,
+        context=context,
         block_number=block,
     )
     return {
         'liquidity': result[0],
         'fee_growth_inside_0_last_x128': result[1],
         'fee_growth_inside_1_last_x128': result[2],
         'tokens_owed_0': result[3],
         'tokens_owed_1': result[4],
     }
 
 
-class UniswapV3Observations(TypedDict):
-    block_timestamp: int
-    tick_cummulative: int
-    seconds_per_liquidity_cummulative_x128: int
-    initialized: bool
-
-
 async def async_pool_observations(
     index: int,
     pool: spec.Address,
     *,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     block: spec.BlockNumberReference | None = None,
 ) -> UniswapV3Observations:
     function_abi = await uniswap_v3_spec.async_get_function_abi(
         'observations',
         'pool',
     )
     result = await rpc.async_eth_call(
         to_address=pool,
         function_abi=function_abi,
         function_parameters=[index],
-        provider=provider,
+        context=context,
         block_number=block,
     )
     return {
         'block_timestamp': result[0],
         'tick_cummulative': result[1],
         'seconds_per_liquidity_cummulative_x128': result[2],
         'initialized': result[3],
     }
+
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/uniswap_v3_utils/contracts/quoter.py` & `checkthechain-0.3.4/src/ctc/protocols/uniswap_v3_utils/contracts/quoter.py`

 * *Files 12% similar despite different names*

```diff
@@ -9,15 +9,15 @@
 async def async_quote_exact_input_single(
     token_in: spec.Address,
     token_out: spec.Address,
     *,
     fee: int,
     amount_in: int,
     sqrt_price_limit_x96: int = 0,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     block: spec.BlockNumberReference | None = None,
 ) -> int:
     function_abi = await uniswap_v3_spec.async_get_function_abi(
         'quoteExactInputSingle',
         'quoter',
     )
     result = await rpc.async_eth_call(
@@ -26,53 +26,53 @@
         function_parameters=[
             token_in,
             token_out,
             fee,
             amount_in,
             sqrt_price_limit_x96,
         ],
-        provider=provider,
+        context=context,
         block_number=block,
     )
     if not isinstance(result, int):
         raise Exception('invalid rpc result')
     return result
 
 
 async def async_quote_exact_input(
     path: str,
     amount_in: int,
     *,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     block: spec.BlockNumberReference | None = None,
 ) -> int:
     function_abi = await uniswap_v3_spec.async_get_function_abi(
         'quoteExactInput',
         'quoter',
     )
     result = await rpc.async_eth_call(
         to_address=uniswap_v3_spec.quoter,
         function_abi=function_abi,
         function_parameters=[path, amount_in],
-        provider=provider,
+        context=context,
         block_number=block,
     )
     if not isinstance(result, int):
         raise Exception('invalid rpc result')
     return result
 
 
 async def async_quote_exact_output_single(
     token_in: spec.Address,
     token_out: spec.Address,
     *,
     fee: int,
     amount_out: int,
     sqrt_price_limit_x96: int = 0,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     block: spec.BlockNumberReference | None = None,
 ) -> int:
     function_abi = await uniswap_v3_spec.async_get_function_abi(
         'quoteExactOutputSingle',
         'quoter',
     )
     result = await rpc.async_eth_call(
@@ -81,36 +81,37 @@
         function_parameters=[
             token_in,
             token_out,
             fee,
             amount_out,
             sqrt_price_limit_x96,
         ],
-        provider=provider,
+        context=context,
         block_number=block,
     )
     if not isinstance(result, int):
         raise Exception('invalid rpc result')
     return result
 
 
 async def async_quote_exact_output(
     path: str,
     amount_in: int,
     *,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     block: spec.BlockNumberReference | None = None,
 ) -> int:
     function_abi = await uniswap_v3_spec.async_get_function_abi(
         'quoteExactOutput',
         'quoter',
     )
     result = await rpc.async_eth_call(
         to_address=uniswap_v3_spec.quoter,
         function_abi=function_abi,
         function_parameters=[path, amount_in],
-        provider=provider,
+        context=context,
         block_number=block,
     )
     if not isinstance(result, int):
         raise Exception('invalid rpc result')
     return result
+
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/uniswap_v3_utils/contracts/tick_lens.py` & `checkthechain-0.3.4/src/ctc/protocols/uniswap_v3_utils/contracts/tick_lens.py`

 * *Files 24% similar despite different names*

```diff
@@ -7,22 +7,25 @@
 
 from .. import uniswap_v3_spec
 
 
 async def async_get_populated_ticks(
     pool: spec.Address,
     tick_bitmap_index: int,
+    *,
+    context: spec.Context = None,
 ) -> tuple[typing.Mapping[str, int], ...]:
     function_abi = await uniswap_v3_spec.async_get_function_abi(
         'getPopulatedTicksInWord',
         'tick_lens',
     )
     result = await rpc.async_eth_call(
         to_address=uniswap_v3_spec.tick_lens,
         function_abi=function_abi,
         function_parameters=[pool, tick_bitmap_index],
+        context=context,
     )
     if not isinstance(result, tuple) or not all(
         isinstance(item, dict) for item in result
     ):
         raise Exception('invalid rpc result')
     return typing.cast(typing.Tuple[typing.Mapping[str, int], ...], result)
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/uniswap_v3_utils/uniswap_v3_crud.py` & `checkthechain-0.3.4/src/ctc/protocols/uniswap_v3_utils/uniswap_v3_crud.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,62 +1,66 @@
 from __future__ import annotations
 
 import typing
-from typing_extensions import TypedDict
 
 from ctc import evm
 from ctc import rpc
 from ctc import spec
 
 from . import contracts
 from . import uniswap_v3_spec
 
 if typing.TYPE_CHECKING:
-    import tooltime
+    from typing_extensions import TypedDict
 
+    import tooltime
 
-class UniswapV3PoolMetadata(TypedDict):
-    x_symbol: str
-    y_symbol: str
-    x_address: str
-    y_address: str
-    fee: int
+    class UniswapV3PoolMetadata(TypedDict):
+        x_symbol: str
+        y_symbol: str
+        x_address: str
+        y_address: str
+        fee: int
 
 
 #
 # # metadata
 #
 
 
 async def async_get_pool_tokens(
     pool_address: spec.Address,
+    *,
+    context: spec.Context = None,
     **rpc_kwargs: typing.Any,
 ) -> tuple[spec.Address, spec.Address]:
     import asyncio
 
     token0_abi = await uniswap_v3_spec.async_get_function_abi('token0', 'pool')
     token1_abi = await uniswap_v3_spec.async_get_function_abi('token1', 'pool')
-    kwargs = dict(rpc_kwargs, to_address=pool_address)
+    kwargs = dict(rpc_kwargs, to_address=pool_address, context=context)
     return await asyncio.gather(
         rpc.async_eth_call(function_abi=token0_abi, **kwargs),
         rpc.async_eth_call(function_abi=token1_abi, **kwargs),
     )
 
 
 async def async_get_pool_metadata(
     pool_address: spec.Address,
+    *,
+    context: spec.Context = None,
     **rpc_kwargs: typing.Any,
 ) -> UniswapV3PoolMetadata:
     x_address, y_address = await async_get_pool_tokens(
-        pool_address=pool_address
+        pool_address=pool_address, context=context
     )
     x_symbol, y_symbol = await evm.async_get_erc20s_symbols(
-        tokens=[x_address, y_address], **rpc_kwargs
+        tokens=[x_address, y_address], context=context, **rpc_kwargs
     )
-    fee = await contracts.async_pool_fee(pool_address)
+    fee = await contracts.async_pool_fee(pool_address, context=context)
     return {
         'x_symbol': x_symbol,
         'y_symbol': y_symbol,
         'x_address': x_address,
         'y_address': y_address,
         'fee': fee,
     }
@@ -73,33 +77,35 @@
     start_block: spec.BlockNumberReference | None = None,
     end_block: spec.BlockNumberReference | None = None,
     start_time: tooltime.Timestamp | None = None,
     end_time: tooltime.Timestamp | None = None,
     include_timestamps: bool = False,
     replace_symbols: bool = False,
     normalize: bool = True,
+    context: spec.Context = None,
 ) -> spec.DataFrame:
-
     import asyncio
+    import polars as pl
 
     if normalize or replace_symbols:
         metadata_task = asyncio.create_task(
-            async_get_pool_metadata(pool_address)
+            async_get_pool_metadata(pool_address, context=context)
         )
 
     event_abi = await uniswap_v3_spec.async_get_event_abi('Swap', 'pool')
 
     swaps = await evm.async_get_events(
         event_abi=event_abi,
         contract_address=pool_address,
         start_block=start_block,
         end_block=end_block,
         start_time=start_time,
         end_time=end_time,
         include_timestamps=include_timestamps,
+        context=context,
     )
 
     if normalize or replace_symbols:
         metadata = await metadata_task
 
     # rename columns
     if replace_symbols:
@@ -108,22 +114,22 @@
     else:
         x_symbol = 'x'
         y_symbol = 'y'
     columns = {
         'arg__amount0': x_symbol + '_amount',
         'arg__amount1': y_symbol + '_amount',
     }
-    swaps = swaps.rename(columns=columns)
+    swaps = swaps.rename(columns)
 
     # normalize columns
     if normalize:
         x_decimals, y_decimals = await evm.async_get_erc20s_decimals(
             tokens=[metadata['x_address'], metadata['y_address']],
+            context=context,
+        )
+        swaps = swaps.with_columns(
+            pl.col(columns['arg__amount0']).cast(float) / (10**x_decimals),
+            pl.col(columns['arg__amount1']).cast(float) / (10**y_decimals),
         )
-        swaps[columns['arg__amount0']] = swaps[columns['arg__amount0']].astype(
-            float
-        ) / (10**x_decimals)
-        swaps[columns['arg__amount1']] = swaps[columns['arg__amount1']].astype(
-            float
-        ) / (10**y_decimals)
 
     return swaps
+
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/uniswap_v3_utils/uniswap_v3_depth.py` & `checkthechain-0.3.4/src/ctc/protocols/uniswap_v3_utils/uniswap_v3_depth.py`

 * *Files 17% similar despite different names*

```diff
@@ -4,14 +4,15 @@
 """
 from __future__ import annotations
 
 import typing
 
 from ctc.toolbox import optimize_utils
 from ctc import evm
+from ctc import spec
 
 from . import contracts
 
 
 async def async_get_liquidity_depth(
     *,
     new_price: int | float,
@@ -22,21 +23,26 @@
     max_search_depth: int = int(10e6 * 1e18),
     verbose: bool = False,
     output_tol: int | float | None = None,
     input_tol: int | float | None = None,
     max_iterations: int = 50,
     token_in_decimals: int | None = None,
     token_out_decimals: int | None = None,
+    context: spec.Context = None,
 ) -> float:
     """return amount of token sold needed to reach new price"""
 
     if token_in_decimals is None:
-        token_in_decimals = await evm.async_get_erc20_decimals(token_in)
+        token_in_decimals = await evm.async_get_erc20_decimals(
+            token_in, context=context
+        )
     if token_out_decimals is None:
-        token_out_decimals = await evm.async_get_erc20_decimals(token_out)
+        token_out_decimals = await evm.async_get_erc20_decimals(
+            token_out, context=context
+        )
 
     if input_tol is None:
         input_tol = 10 ** (token_in_decimals - 2)
 
     swap_kwargs = {
         'token_in': token_in,
         'token_out': token_out,
@@ -65,61 +71,66 @@
 
 
 async def _async_new_price_distance(
     amount_sold: int | float,
     *,
     target_new_price: float,
     swap_kwargs: typing.Any,
+    context: spec.Context = None,
 ) -> float:
     actual_new_price = await async_get_new_price(
-        amount_sold=amount_sold, **swap_kwargs
+        amount_sold=amount_sold, context=context, **swap_kwargs
     )
     return actual_new_price - target_new_price
 
 
 async def async_get_new_price(
     *,
     amount_sold: int | float,
     token_in: str,
     token_out: str,
     fee: int,
     token_in_decimals: int,
     token_out_decimals: int,
     probe_amount_sold: int | None = None,
+    context: spec.Context = None,
 ) -> float:
     """return new price in pool after a given amount of a token is sold
 
     - does this by computing a trade and an additional probe trade
     """
     if probe_amount_sold is None:
-        probe_amount_sold = 10 ** token_in_decimals
+        probe_amount_sold = 10**token_in_decimals
 
     out_to_in = typing.cast(int, 10 ** (token_in_decimals - token_out_decimals))
 
     amount_sold = int(amount_sold)
     total_input_probe = int(amount_sold + probe_amount_sold)
 
     bought_amount = await contracts.async_quote_exact_input_single(
         token_in=token_in,
         token_out=token_out,
         fee=fee,
         amount_in=amount_sold,
         sqrt_price_limit_x96=0,
+        context=context,
     )
     probe_amount_bought = await contracts.async_quote_exact_input_single(
         token_in=token_in,
         token_out=token_out,
         fee=fee,
         amount_in=total_input_probe,
         sqrt_price_limit_x96=0,
+        context=context,
     )
 
     if not isinstance(bought_amount, int):
         raise Exception('invalid rpc result')
     if not isinstance(probe_amount_bought, int):
         raise Exception('invalid rpc result')
 
     probe_price = (
         out_to_in * (probe_amount_bought - bought_amount) / probe_amount_sold
     )
 
     return probe_price
+
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/uniswap_v3_utils/uniswap_v3_spec.py` & `checkthechain-0.3.4/src/ctc/protocols/uniswap_v3_utils/uniswap_v3_spec.py`

 * *Files 6% similar despite different names*

```diff
@@ -87,15 +87,15 @@
 
     if typing.TYPE_CHECKING:
         return typing.cast(spec.EventABI, abi_entry[event_name])
     else:
         return abi_entry[event_name]
 
 
-factory_event_abis = {
+factory_event_abis: typing.Mapping[str, spec.EventABI] = {
     'PoolCreated': {
         'anonymous': False,
         'inputs': [
             {
                 'indexed': True,
                 'internalType': 'address',
                 'name': 'token0',
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/yearn_utils/cli/yearn_addresses_command.py` & `checkthechain-0.3.4/src/ctc/protocols/yearn_utils/cli/yearn_addresses_command.py`

 * *Files 8% similar despite different names*

```diff
@@ -25,14 +25,17 @@
     }
 
 
 async def async_yearn_addresses_command(verbose: bool) -> None:
     styles = cli.get_cli_styles()
     toolstr.print_text_box('Yearn Lens Addresses', style=styles['title'])
     print()
-    yearn_utils.print_lens_addresses(network='mainnet')
+    yearn_utils.print_lens_addresses(network='ethereum')
     print()
     print()
     toolstr.print_text_box('Yearn Vault Addresses', style=styles['title'])
     print()
-    api_vaults = await yearn_utils.async_get_yearn_api_vaults(network='mainnet')
+    api_vaults = await yearn_utils.async_get_yearn_api_vaults(
+        network='ethereum'
+    )
     yearn_utils.print_vault_addresses(api_vaults=api_vaults, verbose=verbose)
+
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/yearn_utils/cli/yearn_command.py` & `checkthechain-0.3.4/src/ctc/protocols/yearn_utils/cli/yearn_command.py`

 * *Files 2% similar despite different names*

```diff
@@ -74,21 +74,21 @@
     harvests: bool,
 ) -> None:
 
     if query is not None:
         await yearn_utils.async_print_vault_summary(
             query=query,
             verbose=verbose,
-            network='mainnet',
+            network='ethereum',
             show_harvests=harvests,
         )
 
     else:
         await yearn_utils.async_print_vaults_summary(
             sort_by=sort,
             min_tvl=min_tvl,
             min_apy=min_apy,
             min_apr=min_apr,
             n=n,
             verbose=verbose,
-            network='mainnet',
+            network='ethereum',
         )
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/yearn_utils/yearn_addresses.py` & `checkthechain-0.3.4/src/ctc/protocols/yearn_utils/yearn_addresses.py`

 * *Files 5% similar despite different names*

```diff
@@ -9,16 +9,16 @@
 from . import yearn_spec
 
 
 def get_yearn_addresses(
     network: spec.NetworkReference,
 ) -> typing.Mapping[str, spec.Address]:
 
-    if network not in ('mainnet', 1):
-        raise NotImplementedError('non-mainnet address')
+    if network not in ('ethereum', 1):
+        raise NotImplementedError('non-ethereum address')
 
     mainnnet_addresses = {
         'Oracle': '0x83d95e0d5f402511db06817aff3f9ea88224b030',
         'ManagementList': '0xf64e58ee8c7badc741a7ea98fb65488084385674',
         #
         # registries
         'AdapterV2': '0x240315db938d44bb124ae619f5fd0269a02d1271',
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/yearn_utils/yearn_spec.py` & `checkthechain-0.3.4/src/ctc/protocols/yearn_utils/yearn_spec.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/protocols/yearn_utils/yearn_tvls.py` & `checkthechain-0.3.4/src/ctc/protocols/yearn_utils/yearn_tvls.py`

 * *Files 21% similar despite different names*

```diff
@@ -6,31 +6,37 @@
 from ctc import spec
 
 from . import yearn_spec
 
 
 async def async_get_tvl_adapter_assets(
     adapter: spec.Address,
+    *,
+    context: spec.Context = None
 ) -> typing.Sequence[spec.Address]:
 
     addresses: typing.Sequence[spec.Address] = await rpc.async_eth_call(
         to_address=adapter,
         function_name='assetsAddresses',
         n_parameters=0,
+        context=context,
     )
     return addresses
 
 
 async def async_get_tvl_adapter_assets_data(
     adapter: spec.Address,
+    *,
+    context: spec.Context = None,
 ) -> typing.Sequence[yearn_spec.AssetTvlBreakdown]:
     data = await rpc.async_eth_call(
         to_address=adapter,
         function_name='assetsTvlBreakdown',
         n_parameters=0,
+        context=context,
     )
 
     tvls: typing.Sequence[yearn_spec.AssetTvlBreakdown] = [
         {
             'asset': datum[0],
             'token': datum[1],
             'token_price': datum[2],
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/yearn_utils/yearn_vaults.py` & `checkthechain-0.3.4/src/ctc/protocols/yearn_utils/yearn_vaults.py`

 * *Files 3% similar despite different names*

```diff
@@ -32,14 +32,16 @@
     query: str,
     network: spec.NetworkReference,
     *,
     verbose: bool = False,
     show_harvests: int | bool | None = None,
 ) -> None:
 
+    import polars as pl
+
     obtained = tooltime.create_timestamp_iso_pretty()
     vault = await yearn_web_api.async_get_yearn_api_vault(
         query, network=network
     )
 
     styles = cli.get_cli_styles()
 
@@ -198,28 +200,28 @@
             for strategy in vault['strategies']
         }
         try:
             coroutines = [
                 yearn_strategies.async_get_harvests(strategy=strategy)
                 for strategy in strategies
             ]
-            import pandas as pd
 
-            all_harvests = pd.concat(await asyncio.gather(*coroutines))
-            all_harvests = all_harvests.sort_index()
+            results = await asyncio.gather(*coroutines)
+            all_harvests = pl.concat(results)
+            all_harvests = all_harvests.sort('block_number', 'log_index')
         except Exception:
             print()
             toolstr.print(
                 'could not obtain harvests',
                 style=styles['content'],
                 indent=4,
             )
-            all_harvests = pd.DataFrame()
+            all_harvests = pl.DataFrame()
         rows = []
-        for block, harvest in all_harvests.iloc[-n_harvests:].iterrows():
+        for harvest in all_harvests[-n_harvests:].to_dicts():
             age = tooltime.get_age(harvest['timestamp'], 'TimelengthPhrase')
             age = ', '.join(age.split(', ')[:1])
             row = [
                 age,
                 harvest['apr'],
                 strategy_address_to_name[harvest['contract_address']],
             ]
@@ -276,14 +278,16 @@
     n_all_vaults = len(api_vaults)
 
     # filter data
     n_clipped = 0
     filtered_data = []
     for datum in api_vaults:
         tvl = datum['tvl']['tvl']
+        if tvl is None:
+            tvl = 0
         net_apy = datum['apy']['net_apy']
         gross_apr = datum['apy']['gross_apr']
         if (
             (min_tvl is not None and tvl < min_tvl)
             or (min_apy is not None and net_apy < min_apy)
             or (min_apr is not None and gross_apr < min_apr)
         ):
@@ -306,14 +310,16 @@
     rows = []
     for datum in data:
 
         tvl = datum['tvl']['tvl']
         net_apy = datum['apy']['net_apy']
         gross_apr = datum['apy']['gross_apr']
 
+        if tvl is None:
+            tvl = 0
         if tvl < 0.01:
             tvl = 0
         total_tvl += tvl
 
         row = [
             datum['name'],
             tvl,
```

### Comparing `checkthechain-0.3.0/src/ctc/protocols/yearn_utils/yearn_web_api.py` & `checkthechain-0.3.4/src/ctc/protocols/yearn_utils/yearn_web_api.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/rpc/rpc_batch/rpc_batch_constructors.py` & `checkthechain-0.3.4/src/ctc/rpc/rpc_batch/rpc_batch_constructors.py`

 * *Files 8% similar despite different names*

```diff
@@ -482,7 +482,120 @@
 
 def batch_construct_web3_sha3(
     **constructor_kwargs: typing.Any,
 ) -> spec.RpcPluralRequest:
     return rpc_batch_utils.batch_construct(
         method='web3_sha3', **constructor_kwargs
     )
+
+
+def batch_construct_trace_transaction(
+    **constructor_kwargs: typing.Any,
+) -> spec.RpcPluralRequest:
+    return rpc_batch_utils.batch_construct(
+        method='trace_transaction', **constructor_kwargs
+    )
+
+
+def batch_construct_trace_replay_transaction(
+    **constructor_kwargs: typing.Any,
+) -> spec.RpcPluralRequest:
+    return rpc_batch_utils.batch_construct(
+        method='trace_replay_transaction', **constructor_kwargs
+    )
+
+
+def batch_construct_trace_raw_transaction(
+    **constructor_kwargs: typing.Any,
+) -> spec.RpcPluralRequest:
+    return rpc_batch_utils.batch_construct(
+        method='trace_raw_transaction', **constructor_kwargs
+    )
+
+
+def batch_construct_trace_call(
+    **constructor_kwargs: typing.Any,
+) -> spec.RpcPluralRequest:
+    return rpc_batch_utils.batch_construct(
+        method='trace_call', **constructor_kwargs
+    )
+
+
+def batch_construct_trace_call_many(
+    **constructor_kwargs: typing.Any,
+) -> spec.RpcPluralRequest:
+    return rpc_batch_utils.batch_construct(
+        method='trace_call_many', **constructor_kwargs
+    )
+
+
+def batch_construct_trace_get(
+    **constructor_kwargs: typing.Any,
+) -> spec.RpcPluralRequest:
+    return rpc_batch_utils.batch_construct(
+        method='trace_get', **constructor_kwargs
+    )
+
+
+def batch_construct_trace_filter(
+    **constructor_kwargs: typing.Any,
+) -> spec.RpcPluralRequest:
+    return rpc_batch_utils.batch_construct(
+        method='trace_filter', **constructor_kwargs
+    )
+
+
+def batch_construct_trace_block(
+    **constructor_kwargs: typing.Any,
+) -> spec.RpcPluralRequest:
+    return rpc_batch_utils.batch_construct(
+        method='trace_block', **constructor_kwargs
+    )
+
+
+def batch_construct_trace_replay_block_transactions(
+    **constructor_kwargs: typing.Any,
+) -> spec.RpcPluralRequest:
+    return rpc_batch_utils.batch_construct(
+        method='trace_replay_block_transactions', **constructor_kwargs
+    )
+
+
+def batch_construct_debug_trace_call(
+    **constructor_kwargs: typing.Any,
+) -> spec.RpcPluralRequest:
+    return rpc_batch_utils.batch_construct(
+        method='trace_call', **constructor_kwargs
+    )
+
+
+def batch_construct_debug_trace_call_many(
+    **constructor_kwargs: typing.Any,
+) -> spec.RpcPluralRequest:
+    return rpc_batch_utils.batch_construct(
+        method='trace_call_many', **constructor_kwargs
+    )
+
+
+def batch_construct_debug_trace_transaction(
+    **constructor_kwargs: typing.Any,
+) -> spec.RpcPluralRequest:
+    return rpc_batch_utils.batch_construct(
+        method='trace_transaction', **constructor_kwargs
+    )
+
+
+def batch_construct_debug_trace_block_by_number(
+    **constructor_kwargs: typing.Any,
+) -> spec.RpcPluralRequest:
+    return rpc_batch_utils.batch_construct(
+        method='trace_block_by_number', **constructor_kwargs
+    )
+
+
+def batch_construct_debug_trace_block_by_hash(
+    **constructor_kwargs: typing.Any,
+) -> spec.RpcPluralRequest:
+    return rpc_batch_utils.batch_construct(
+        method='trace_block_by_hash', **constructor_kwargs
+    )
+
```

### Comparing `checkthechain-0.3.0/src/ctc/rpc/rpc_batch/rpc_batch_executors.py` & `checkthechain-0.3.4/src/ctc/rpc/rpc_batch/rpc_batch_executors.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,15 +1,14 @@
 from __future__ import annotations
 
 import typing
 
 from ctc import evm
 from ctc import spec
 
-from .. import rpc_provider
 from . import rpc_batch_utils
 
 
 async def async_batch_eth_accounts(
     **kwargs: typing.Any,
 ) -> spec.RpcPluralResponse:
     return await rpc_batch_utils.async_batch_execute('eth_accounts', **kwargs)
@@ -24,15 +23,15 @@
 
 
 async def async_batch_eth_call(
     *,
     function_abi: spec.FunctionABI | None = None,
     function_name: str | None = None,
     function_selector: spec.FunctionSelector | None = None,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     to_address: spec.Address | None = None,
     to_addresses: typing.Sequence[spec.Address] | None = None,
     **kwargs: typing.Any,
 ) -> spec.RpcPluralResponse:
 
     if function_abi is None:
 
@@ -41,30 +40,25 @@
         elif to_addresses is not None:
             contract_address = to_addresses[0]
         else:
             raise Exception(
                 'must specify to_address or to_addresses'
             )
 
-        provider = rpc_provider.get_provider(provider)
-        network = provider['network']
-        if network is None:
-            raise Exception('could not determine network')
-
         function_abi = await evm.async_get_function_abi(
             contract_address=contract_address,
             function_name=function_name,
             function_selector=function_selector,
-            network=network,
+            context=context,
         )
 
     return await rpc_batch_utils.async_batch_execute(
         'eth_call',
         function_abi=function_abi,
-        provider=provider,
+        context=context,
         to_address=to_address,
         to_addresses=to_addresses,
         **kwargs,
     )
 
 
 async def async_batch_eth_coinbase(
@@ -473,7 +467,16 @@
     return await rpc_batch_utils.async_batch_execute(
         'web3_client_version', **kwargs
     )
 
 
 async def async_batch_web3_sha3(**kwargs: typing.Any) -> spec.RpcPluralResponse:
     return await rpc_batch_utils.async_batch_execute('web3_sha3', **kwargs)
+
+
+async def async_batch_trace_block(
+    **kwargs: typing.Any,
+) -> spec.RpcPluralResponse:
+    return await rpc_batch_utils.async_batch_execute(
+        'trace_block', **kwargs
+    )
+
```

### Comparing `checkthechain-0.3.0/src/ctc/rpc/rpc_batch/rpc_batch_utils.py` & `checkthechain-0.3.4/src/ctc/rpc/rpc_batch/rpc_batch_utils.py`

 * *Files 7% similar despite different names*

```diff
@@ -74,25 +74,32 @@
 # # batch execution
 #
 
 
 async def async_batch_execute(
     method: str,
     *,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
+    convert_reverts_to: typing.Any = None,
+    convert_reverts_to_none: bool = False,
     **kwargs: typing.Any,
 ) -> spec.RpcPluralResponse:
     """execute batch rpc call asynchronously"""
 
     constructor_kwargs, digestor_kwargs = _separate_execution_kwargs(
         method=method,
         kwargs=kwargs,
     )
     request = batch_construct(method=method, **constructor_kwargs)
-    response = await rpc_request.async_send(request=request, provider=provider)
+    response = await rpc_request.async_send(
+        request=request,
+        context=context,
+        convert_reverts_to_none=convert_reverts_to_none,
+        convert_reverts_to=convert_reverts_to,
+    )
     return batch_digest(response=response, method=method, **digestor_kwargs)
 
 
 def _separate_execution_kwargs(
     method: str,
     kwargs: typing.Mapping[str, typing.Any],
 ) -> tuple[typing.Mapping[str, typing.Any], typing.Mapping[str, typing.Any]]:
@@ -128,14 +135,14 @@
 
 
 def batch_digest(
     response: spec.RpcPluralResponse,
     method: str,
     **digestor_kwargs: typing.Any,
 ) -> spec.RpcPluralResponse:
-
     digestor = rpc_registry.get_digestor(method)
     results = []
     for s, subresponse in enumerate(response):
         result = digestor(subresponse, **digestor_kwargs)
         results.append(result)
     return results
+
```

### Comparing `checkthechain-0.3.0/src/ctc/rpc/rpc_constructors/rpc_block_constructors.py` & `checkthechain-0.3.4/src/ctc/rpc/rpc_constructors/rpc_block_constructors.py`

 * *Files 9% similar despite different names*

```diff
@@ -2,84 +2,81 @@
 
 from ctc import evm
 from ctc import spec
 
 from .. import rpc_request
 
 
-def construct_eth_block_number() -> spec.RpcRequest:
+def construct_eth_block_number() -> spec.RpcSingularRequest:
     return rpc_request.create('eth_blockNumber', [])
 
 
 def construct_eth_get_block_by_hash(
     block_hash: spec.BinaryData,
     *,
     include_full_transactions: bool = False,
-) -> spec.RpcRequest:
-    encoded_block_hash = evm.binary_convert(block_hash, 'prefix_hex')
+) -> spec.RpcSingularRequest:
+    encoded_block_hash = evm.to_hex(block_hash)
     parameters = [encoded_block_hash, include_full_transactions]
     return rpc_request.create('eth_getBlockByHash', parameters)
 
 
 def construct_eth_get_block_by_number(
     block_number: spec.BlockNumberReference,
     *,
     include_full_transactions: bool = False,
-) -> spec.RpcRequest:
+) -> spec.RpcSingularRequest:
 
     encoded_block_number = evm.encode_block_number(block_number)
 
     parameters = [encoded_block_number, include_full_transactions]
     return rpc_request.create(
         method='eth_getBlockByNumber',
         parameters=parameters,
     )
 
 
 def construct_eth_get_uncle_count_by_block_hash(
     block_hash: spec.BinaryData,
-) -> spec.RpcRequest:
-    encoded_block_hash = evm.binary_convert(block_hash, 'prefix_hex')
+) -> spec.RpcSingularRequest:
+    encoded_block_hash = evm.to_hex(block_hash)
     return rpc_request.create(
         method='eth_getUncleCountByBlockHash',
         parameters=[encoded_block_hash],
     )
 
 
 def construct_eth_get_uncle_count_by_block_number(
     block_number: spec.BlockNumberReference,
-) -> spec.RpcRequest:
+) -> spec.RpcSingularRequest:
     encoded_block_number = evm.encode_block_number(block_number)
     return rpc_request.create(
         method='eth_getUncleCountByBlockNumber',
         parameters=[encoded_block_number],
     )
 
 
 def construct_eth_get_uncle_by_block_hash_and_index(
     block_hash: spec.BinaryData, uncle_index: spec.BinaryData
-) -> spec.RpcRequest:
+) -> spec.RpcSingularRequest:
 
-    encoded_block_hash = evm.binary_convert(block_hash, 'prefix_hex')
-    encoded_uncle_index = evm.binary_convert(
-        uncle_index, 'prefix_hex', keep_leading_0=False
-    )
+    encoded_block_hash = evm.to_hex(block_hash)
+    encoded_uncle_index = evm.to_hex(uncle_index, keep_leading_0=False)
 
     return rpc_request.create(
         method='eth_getUncleByBlockHashAndIndex',
         parameters=[encoded_block_hash, encoded_uncle_index],
     )
 
 
 def construct_eth_get_uncle_by_block_number_and_index(
     block_number: spec.BlockNumberReference, uncle_index: spec.BinaryData
-) -> spec.RpcRequest:
+) -> spec.RpcSingularRequest:
 
     encoded_block_number = evm.encode_block_number(block_number)
-    encoded_uncle_index = evm.binary_convert(
-        uncle_index, 'prefix_hex', keep_leading_0=False
-    )
+    encoded_uncle_index = evm.to_hex(uncle_index, keep_leading_0=False)
 
     return rpc_request.create(
         method='eth_getUncleByBlockNumberAndIndex',
         parameters=[encoded_block_number, encoded_uncle_index],
     )
+
```

### Comparing `checkthechain-0.3.0/src/ctc/rpc/rpc_constructors/rpc_log_constructors.py` & `checkthechain-0.3.4/src/ctc/rpc/rpc_constructors/rpc_log_constructors.py`

 * *Files 10% similar despite different names*

```diff
@@ -5,19 +5,19 @@
 from ctc import evm
 from ctc import spec
 from .. import rpc_request
 
 
 def construct_eth_new_filter(
     address: spec.BinaryData | None = None,
-    topics: typing.Sequence[spec.BinaryData] | None = None,
+    topics: typing.Sequence[spec.BinaryData | None] | None = None,
     *,
     start_block: spec.BlockNumberReference | None = None,
     end_block: spec.BlockNumberReference | None = None,
-) -> spec.RpcRequest:
+) -> spec.RpcSingularRequest:
 
     if start_block is not None:
         start_block = evm.encode_block_number(start_block)
     if end_block is not None:
         end_block = evm.encode_block_number(end_block)
 
     parameters = {
@@ -27,48 +27,48 @@
         'toBlock': end_block,
     }
     parameters = {k: v for k, v in parameters.items() if v is not None}
 
     return rpc_request.create('eth_newFilter', [parameters])
 
 
-def construct_eth_new_block_filter() -> spec.RpcRequest:
+def construct_eth_new_block_filter() -> spec.RpcSingularRequest:
     return rpc_request.create('eth_newBlockFilter', [])
 
 
-def construct_eth_new_pending_transaction_filter() -> spec.RpcRequest:
+def construct_eth_new_pending_transaction_filter() -> spec.RpcSingularRequest:
     return rpc_request.create('eth_newPendingTransactionFilter', [])
 
 
 def construct_eth_uninstall_filter(
     filter_id: spec.GenericBinaryData,
-) -> spec.RpcRequest:
+) -> spec.RpcSingularRequest:
     return rpc_request.create('eth_uninstallFilter', [filter_id])
 
 
 def construct_eth_get_filter_changes(
     filter_id: spec.GenericBinaryData,
-) -> spec.RpcRequest:
+) -> spec.RpcSingularRequest:
     return rpc_request.create('eth_getFilterChanges', [filter_id])
 
 
 def construct_eth_get_filter_logs(
     filter_id: spec.GenericBinaryData,
-) -> spec.RpcRequest:
+) -> spec.RpcSingularRequest:
     return rpc_request.create('eth_getFilterLogs', [filter_id])
 
 
 def construct_eth_get_logs(
     address: spec.BinaryData | None = None,
-    topics: typing.Sequence[spec.BinaryData] | None = None,
+    topics: typing.Sequence[spec.BinaryData | None] | None = None,
     *,
     start_block: spec.BlockNumberReference | None = None,
     end_block: spec.BlockNumberReference | None = None,
     block_hash: spec.BinaryData | None = None,
-) -> spec.RpcRequest:
+) -> spec.RpcSingularRequest:
 
     if start_block is not None:
         start_block = evm.encode_block_number(start_block)
     if end_block is not None:
         end_block = evm.encode_block_number(end_block)
 
     parameters = {
@@ -77,7 +77,8 @@
         'fromBlock': start_block,
         'toBlock': end_block,
         'blockHash': block_hash,
     }
     parameters = {k: v for k, v in parameters.items() if v is not None}
 
     return rpc_request.create('eth_getLogs', [parameters])
+
```

### Comparing `checkthechain-0.3.0/src/ctc/rpc/rpc_constructors/rpc_mining_constructors.py` & `checkthechain-0.3.4/src/ctc/rpc/rpc_constructors/rpc_mining_constructors.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,36 +1,37 @@
 from __future__ import annotations
 
 from ctc import spec
 from .. import rpc_request
 
 
-def construct_eth_get_work() -> spec.RpcRequest:
+def construct_eth_get_work() -> spec.RpcSingularRequest:
     return rpc_request.create('eth_getWork', [])
 
 
 def construct_eth_submit_work(
     *,
     nonce: spec.BinaryData,
     pow_hash: spec.BinaryData,
     digest: spec.BinaryData,
-) -> spec.RpcRequest:
+) -> spec.RpcSingularRequest:
     parameters = [nonce, pow_hash, digest]
     return rpc_request.create('eth_submitWork', parameters)
 
 
 def construct_eth_submit_hashrate(
     hashrate: spec.BinaryData, id: str
-) -> spec.RpcRequest:
+) -> spec.RpcSingularRequest:
     return rpc_request.create('eth_submitHashrate', [hashrate, id])
 
 
-def construct_eth_coinbase() -> spec.RpcRequest:
+def construct_eth_coinbase() -> spec.RpcSingularRequest:
     return rpc_request.create('eth_coinbase', [])
 
 
-def construct_eth_mining() -> spec.RpcRequest:
+def construct_eth_mining() -> spec.RpcSingularRequest:
     return rpc_request.create('eth_mining', [])
 
 
-def construct_eth_hashrate() -> spec.RpcRequest:
+def construct_eth_hashrate() -> spec.RpcSingularRequest:
     return rpc_request.create('eth_hashrate', [])
+
```

### Comparing `checkthechain-0.3.0/src/ctc/rpc/rpc_constructors/rpc_state_constructors.py` & `checkthechain-0.3.4/src/ctc/rpc/rpc_constructors/rpc_state_constructors.py`

 * *Files 3% similar despite different names*

```diff
@@ -16,15 +16,15 @@
     value_sent: spec.BinaryData | None = None,
     block_number: spec.BlockNumberReference | None = None,
     call_data: spec.BinaryData | None = None,
     function_parameters: typing.Sequence[typing.Any]
     | typing.Mapping[str, typing.Any]
     | None = None,
     function_abi: spec.FunctionABI | None = None,
-) -> spec.RpcRequest:
+) -> spec.RpcSingularRequest:
 
     if block_number is None:
         block_number = 'latest'
     else:
         block_number = evm.encode_block_number(block_number)
 
     # encode call data
@@ -56,15 +56,15 @@
     gas_price: spec.BinaryData | None = None,
     value_sent: spec.BinaryData | None = None,
     call_data: spec.BinaryData | None = None,
     function_parameters: typing.Sequence[typing.Any]
     | typing.Mapping[str, typing.Any]
     | None = None,
     function_abi: spec.FunctionABI | None = None,
-) -> spec.RpcRequest:
+) -> spec.RpcSingularRequest:
 
     # encode call data
     if call_data is None:
         call_data = evm.encode_call_data(
             parameters=function_parameters,
             function_abi=function_abi,
         )
@@ -83,40 +83,39 @@
     return rpc_request.create('eth_estimateGas', [call_object])
 
 
 def construct_eth_get_balance(
     address: spec.Address,
     *,
     block_number: spec.BlockNumberReference | None = None,
-) -> spec.RpcRequest:
+) -> spec.RpcSingularRequest:
 
     if block_number is None:
         block_number = 'latest'
 
     encoded_block_number = evm.encode_block_number(block_number)
     return rpc_request.create('eth_getBalance', [address, encoded_block_number])
 
 
 def construct_eth_get_storage_at(
     address: spec.BinaryData,
     position: spec.BinaryData,
     *,
     block_number: spec.BlockNumberReference = 'latest',
-) -> spec.RpcRequest:
+) -> spec.RpcSingularRequest:
 
-    position = evm.binary_convert(
-        position, 'prefix_hex', keep_leading_0=False
-    )
+    position = evm.to_hex(position, keep_leading_0=False)
     encoded_block_number = evm.encode_block_number(block_number)
     return rpc_request.create(
         'eth_getStorageAt', [address, position, encoded_block_number]
     )
 
 
 def construct_eth_get_code(
     address: spec.BinaryData,
     *,
     block_number: spec.BlockNumberReference = 'latest',
-) -> spec.RpcRequest:
+) -> spec.RpcSingularRequest:
 
     block_number = evm.encode_block_number(block_number)
     return rpc_request.create('eth_getCode', [address, block_number])
+
```

### Comparing `checkthechain-0.3.0/src/ctc/rpc/rpc_constructors/rpc_submission_constructors.py` & `checkthechain-0.3.4/src/ctc/rpc/rpc_constructors/rpc_submission_constructors.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,35 +1,37 @@
 from __future__ import annotations
 
 from ctc import spec
 from .. import rpc_request
 
 
-def construct_eth_gas_price() -> spec.RpcRequest:
+def construct_eth_gas_price() -> spec.RpcSingularRequest:
     return rpc_request.create('eth_gasPrice', [])
 
 
-def construct_eth_accounts() -> spec.RpcRequest:
+def construct_eth_accounts() -> spec.RpcSingularRequest:
     return rpc_request.create('eth_accounts', [])
 
 
-def construct_eth_sign(address: spec.Address, message: str) -> spec.RpcRequest:
+def construct_eth_sign(
+    address: spec.Address, message: str
+) -> spec.RpcSingularRequest:
     return rpc_request.create('eth_sign', [address, message])
 
 
 def construct_eth_sign_transaction(
     from_address: spec.Address,
     data: str,
     *,
     to_address: spec.Address | None = None,
     gas: int | None = None,
     gas_price: int | None = None,
     value: int | None = None,
     nonce: str | None = None,
-) -> spec.RpcRequest:
+) -> spec.RpcSingularRequest:
 
     parameters = {
         'from': from_address,
         'to': to_address,
         'gas': gas,
         'gasPrice': gas_price,
         'value': value,
@@ -46,15 +48,15 @@
     data: spec.BinaryData,
     *,
     to_address: spec.BinaryData | None = None,
     gas: int | None = None,
     gas_price: int | None = None,
     value: int | None = None,
     nonce: spec.BinaryData | None = None,
-) -> spec.RpcRequest:
+) -> spec.RpcSingularRequest:
     parameters = {
         'from': from_address,
         'to': to_address,
         'gas': gas,
         'gasPrice': gas_price,
         'value': value,
         'data': data,
@@ -63,9 +65,10 @@
     parameters = {k: v for k, v in parameters.items() if v is not None}
 
     return rpc_request.create('eth_sendTransaction', [parameters])
 
 
 def construct_eth_send_raw_transaction(
     data: spec.BinaryData,
-) -> spec.RpcRequest:
+) -> spec.RpcSingularRequest:
     return rpc_request.create('eth_sendRawTransaction', [data])
+
```

### Comparing `checkthechain-0.3.0/src/ctc/rpc/rpc_constructors/rpc_transaction_constructors.py` & `checkthechain-0.3.4/src/ctc/rpc/rpc_constructors/rpc_transaction_constructors.py`

 * *Files 8% similar despite different names*

```diff
@@ -4,74 +4,75 @@
 from ctc import spec
 from .. import rpc_request
 
 
 def construct_eth_get_transaction_count(
     from_address: spec.BinaryData,
     block_number: spec.BlockNumberReference = 'latest',
-) -> spec.RpcRequest:
+) -> spec.RpcSingularRequest:
 
     block_number = evm.encode_block_number(block_number)
     return rpc_request.create(
         'eth_getTransactionCount',
         [from_address, block_number],
     )
 
 
 def construct_eth_get_transaction_by_hash(
     transaction_hash: spec.BinaryData,
-) -> spec.RpcRequest:
+) -> spec.RpcSingularRequest:
     return rpc_request.create('eth_getTransactionByHash', [transaction_hash])
 
 
 def construct_eth_get_transaction_by_block_hash_and_index(
     block_hash: spec.BinaryData,
     transaction_index: spec.BinaryData,
-) -> spec.RpcRequest:
-    transaction_index = evm.binary_convert(transaction_index, 'prefix_hex')
+) -> spec.RpcSingularRequest:
+    transaction_index = evm.to_hex(transaction_index)
 
     return rpc_request.create(
         'eth_getTransactionByBlockHashAndIndex',
         [block_hash, transaction_index],
     )
 
 
 def construct_eth_get_transaction_by_block_number_and_index(
     block_number: spec.BlockNumberReference,
     transaction_index: spec.BinaryData,
-) -> spec.RpcRequest:
+) -> spec.RpcSingularRequest:
     block_number = evm.encode_block_number(block_number)
-    transaction_index = evm.binary_convert(transaction_index, 'prefix_hex')
+    transaction_index = evm.to_hex(transaction_index)
 
     return rpc_request.create(
         'eth_getTransactionByBlockNumberAndIndex',
         [block_number, transaction_index],
     )
 
 
 def construct_eth_get_transaction_receipt(
     transaction_hash: spec.BinaryData,
-) -> spec.RpcRequest:
+) -> spec.RpcSingularRequest:
     return rpc_request.create(
         'eth_getTransactionReceipt',
         [transaction_hash],
     )
 
 
 def construct_eth_get_block_transaction_count_by_hash(
     block_hash: spec.BinaryData,
-) -> spec.RpcRequest:
+) -> spec.RpcSingularRequest:
     return rpc_request.create(
         'eth_getBlockTransactionCountByHash',
         [block_hash],
     )
 
 
 def construct_eth_get_block_transaction_count_by_number(
     block_number: spec.BlockNumberReference,
-) -> spec.RpcRequest:
+) -> spec.RpcSingularRequest:
 
     block_number = evm.encode_block_number(block_number)
     return rpc_request.create(
         'eth_getBlockTransactionCountByNumber',
         [block_number],
     )
+
```

### Comparing `checkthechain-0.3.0/src/ctc/rpc/rpc_constructors/rpc_whisper_constructors.py` & `checkthechain-0.3.4/src/ctc/rpc/rpc_constructors/rpc_whisper_constructors.py`

 * *Files 10% similar despite different names*

```diff
@@ -2,72 +2,79 @@
 
 import typing
 
 from ctc import spec
 from .. import rpc_request
 
 
-def construct_shh_version() -> spec.RpcRequest:
+def construct_shh_version() -> spec.RpcSingularRequest:
     return rpc_request.create('shh_version', [])
 
 
 def construct_shh_post(
     from_address: spec.BinaryData,
     to_address: spec.BinaryData,
     *,
     topics: list[spec.BinaryData],
     payload: spec.BinaryData,
     priority: spec.BinaryData,
     ttl: spec.BinaryData,
-) -> spec.RpcRequest:
+) -> spec.RpcSingularRequest:
     data: dict[str, typing.Any] = {
         'from': from_address,
         'to': to_address,
         'topics': topics,
         'payload': payload,
         'priority': priority,
         'ttl': ttl,
     }
     data = {k: v for k, v in data.items() if v is not None}
     return rpc_request.create('shh_new_filter', [data])
 
 
-def construct_shh_new_identity() -> spec.RpcRequest:
+def construct_shh_new_identity() -> spec.RpcSingularRequest:
     return rpc_request.create('ssh_new_version', [])
 
 
-def construct_shh_has_identity(data: spec.BinaryData) -> spec.RpcRequest:
+def construct_shh_has_identity(
+    data: spec.BinaryData,
+) -> spec.RpcSingularRequest:
     return rpc_request.create('shh_has_identity', [data])
 
 
-def construct_shh_new_group() -> spec.RpcRequest:
+def construct_shh_new_group() -> spec.RpcSingularRequest:
     return rpc_request.create('shh_new_group', [])
 
 
-def construct_shh_add_to_group(data: spec.BinaryData) -> spec.RpcRequest:
+def construct_shh_add_to_group(
+    data: spec.BinaryData,
+) -> spec.RpcSingularRequest:
     return rpc_request.create('shh_add_to_group', [data])
 
 
 def construct_shh_new_filter(
     to_address: spec.BinaryData, topics: typing.Sequence[spec.BinaryData]
-) -> spec.RpcRequest:
+) -> spec.RpcSingularRequest:
     payload = {
         'to': to_address,
         'topics': topics,
     }
     return rpc_request.create('shh_new_filter', [payload])
 
 
 def construct_shh_uninstall_filter(
     filter_id: spec.BinaryData,
-) -> spec.RpcRequest:
+) -> spec.RpcSingularRequest:
     return rpc_request.create('shh_uninstall_filter', [filter_id])
 
 
 def construct_shh_get_filter_changes(
     filter_id: spec.BinaryData,
-) -> spec.RpcRequest:
+) -> spec.RpcSingularRequest:
     return rpc_request.create('shh_get_filter_changes', [filter_id])
 
 
-def construct_shh_get_messages(filter_id: spec.BinaryData) -> spec.RpcRequest:
+def construct_shh_get_messages(
+    filter_id: spec.BinaryData,
+) -> spec.RpcSingularRequest:
     return rpc_request.create('shh_get_messages', [filter_id])
+
```

### Comparing `checkthechain-0.3.0/src/ctc/rpc/rpc_digestors/rpc_block_digestors.py` & `checkthechain-0.3.4/src/ctc/rpc/rpc_digestors/rpc_block_digestors.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/rpc/rpc_digestors/rpc_dev_digestors.py` & `checkthechain-0.3.4/src/ctc/rpc/rpc_digestors/rpc_dev_digestors.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/rpc/rpc_digestors/rpc_log_digestors.py` & `checkthechain-0.3.4/src/ctc/rpc/rpc_digestors/rpc_log_digestors.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/rpc/rpc_digestors/rpc_mining_digestors.py` & `checkthechain-0.3.4/src/ctc/rpc/rpc_digestors/rpc_mining_digestors.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/rpc/rpc_digestors/rpc_node_digestors.py` & `checkthechain-0.3.4/src/ctc/rpc/rpc_digestors/rpc_node_digestors.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/rpc/rpc_digestors/rpc_state_digestors.py` & `checkthechain-0.3.4/src/ctc/rpc/rpc_digestors/rpc_state_digestors.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/rpc/rpc_digestors/rpc_submission_digestors.py` & `checkthechain-0.3.4/src/ctc/rpc/rpc_digestors/rpc_submission_digestors.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/rpc/rpc_digestors/rpc_transaction_digestors.py` & `checkthechain-0.3.4/src/ctc/rpc/rpc_digestors/rpc_transaction_digestors.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/rpc/rpc_digestors/rpc_whisper_digestors.py` & `checkthechain-0.3.4/src/ctc/rpc/rpc_digestors/rpc_whisper_digestors.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/rpc/rpc_executors/rpc_dev_executors.py` & `checkthechain-0.3.4/src/ctc/rpc/rpc_executors_async/rpc_dev_executors_async.py`

 * *Files 17% similar despite different names*

```diff
@@ -5,36 +5,37 @@
 from .. import rpc_constructors
 from .. import rpc_request
 from .. import rpc_digestors
 
 
 async def async_eth_get_compilers(
     *,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
 ) -> spec.RpcSingularResponse:
     request = rpc_constructors.construct_eth_get_compilers()
-    response = await rpc_request.async_send(request, provider=provider)
+    response = await rpc_request.async_send(request, context=context)
     return rpc_digestors.digest_eth_get_compilers(response=response)
 
 
 async def async_eth_compile_lll(
-    code: str, *, provider: spec.ProviderReference = None
+    code: str, *, context: spec.Context = None
 ) -> spec.RpcSingularResponse:
     request = rpc_constructors.construct_eth_compile_lll(code=code)
-    response = await rpc_request.async_send(request, provider=provider)
+    response = await rpc_request.async_send(request, context=context)
     return rpc_digestors.digest_eth_compile_lll(response=response)
 
 
 async def async_eth_compile_solidity(
-    code: str, *, provider: spec.ProviderReference = None
+    code: str, *, context: spec.Context = None
 ) -> spec.RpcSingularResponse:
     request = rpc_constructors.construct_eth_compile_solidity(code=code)
-    response = await rpc_request.async_send(request, provider=provider)
+    response = await rpc_request.async_send(request, context=context)
     return rpc_digestors.digest_eth_compile_solidity(response=response)
 
 
 async def async_eth_compile_serpent(
-    code: str, *, provider: spec.ProviderReference = None
+    code: str, *, context: spec.Context = None
 ) -> spec.RpcSingularResponse:
     request = rpc_constructors.construct_eth_compile_serpent(code=code)
-    response = await rpc_request.async_send(request, provider=provider)
+    response = await rpc_request.async_send(request, context=context)
     return rpc_digestors.digest_eth_compile_serpent(response=response)
+
```

### Comparing `checkthechain-0.3.0/src/ctc/rpc/rpc_executors/rpc_log_executors.py` & `checkthechain-0.3.4/src/ctc/rpc/rpc_executors_async/rpc_log_executors_async.py`

 * *Files 17% similar despite different names*

```diff
@@ -8,131 +8,162 @@
 from .. import rpc_digestors
 from .. import rpc_request
 
 
 async def async_eth_new_filter(
     *,
     address: spec.Address | None = None,
-    topics: typing.Sequence[spec.BinaryData] | None = None,
+    topics: typing.Sequence[spec.BinaryData | None] | None = None,
     start_block: spec.BlockNumberReference | None = None,
     end_block: spec.BlockNumberReference | None = None,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     decode_response: bool = False,
 ) -> spec.RpcSingularResponse:
     request = rpc_constructors.construct_eth_new_filter(
         address=address,
         topics=topics,
         start_block=start_block,
         end_block=end_block,
     )
-    response = await rpc_request.async_send(request, provider=provider)
+    response = await rpc_request.async_send(request, context=context)
     return rpc_digestors.digest_eth_new_filter(
         response=response,
         decode_response=decode_response,
     )
 
 
 async def async_eth_new_block_filter(
-    *, provider: spec.ProviderReference = None, decode_response: bool = False
+    *, context: spec.Context = None, decode_response: bool = False
 ) -> spec.RpcSingularResponse:
     request = rpc_constructors.construct_eth_new_block_filter()
-    response = await rpc_request.async_send(request, provider=provider)
+    response = await rpc_request.async_send(request, context=context)
     return rpc_digestors.digest_eth_new_block_filter(
         response=response,
         decode_response=decode_response,
     )
 
 
 async def async_eth_new_pending_transaction_filter(
-    *, provider: spec.ProviderReference = None, decode_response: bool = False
+    *, context: spec.Context = None, decode_response: bool = False
 ) -> spec.RpcSingularResponse:
     request = rpc_constructors.construct_eth_new_pending_transaction_filter()
-    response = await rpc_request.async_send(request, provider=provider)
+    response = await rpc_request.async_send(request, context=context)
     return rpc_digestors.digest_eth_new_pending_transaction_filter(
         response=response,
         decode_response=decode_response,
     )
 
 
 async def async_eth_uninstall_filter(
     filter_id: spec.GenericBinaryData,
     *,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     decode_response: bool = False,
 ) -> spec.RpcSingularResponse:
     request = rpc_constructors.construct_eth_uninstall_filter(
         filter_id=filter_id
     )
-    response = await rpc_request.async_send(request, provider=provider)
+    response = await rpc_request.async_send(request, context=context)
     return rpc_digestors.digest_eth_uninstall_filter(
         response=response,
         decode_response=decode_response,
     )
 
 
 async def async_eth_get_filter_changes(
     filter_id: spec.GenericBinaryData,
     *,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     decode_response: bool = True,
     snake_case_response: bool = True,
     include_removed: bool = False,
 ) -> spec.RpcSingularResponse:
     request = rpc_constructors.construct_eth_get_filter_changes(
         filter_id=filter_id
     )
-    response = await rpc_request.async_send(request, provider=provider)
+    response = await rpc_request.async_send(request, context=context)
     return rpc_digestors.digest_eth_get_filter_changes(
         response=response,
         decode_response=decode_response,
         snake_case_response=snake_case_response,
         include_removed=include_removed,
     )
 
 
 async def async_eth_get_filter_logs(
     filter_id: spec.GenericBinaryData,
     *,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     decode_response: bool = True,
     snake_case_response: bool = True,
     include_removed: bool = False,
 ) -> spec.RpcSingularResponse:
     request = rpc_constructors.construct_eth_get_filter_logs(
         filter_id=filter_id
     )
-    response = await rpc_request.async_send(request, provider=provider)
+    response = await rpc_request.async_send(request, context=context)
     return rpc_digestors.digest_eth_get_filter_logs(
         response=response,
         decode_response=decode_response,
         snake_case_response=snake_case_response,
         include_removed=include_removed,
     )
 
 
 async def async_eth_get_logs(
     *,
     address: spec.BinaryData | None = None,
-    topics: typing.Sequence[spec.BinaryData] | None = None,
+    topics: typing.Sequence[spec.BinaryData | None] | None = None,
     start_block: spec.BlockNumberReference | None = None,
     end_block: spec.BlockNumberReference | None = None,
     block_hash: spec.BinaryData | None = None,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     decode_response: bool = True,
     snake_case_response: bool = True,
     include_removed: bool = False,
 ) -> spec.RpcSingularResponse:
 
     request = rpc_constructors.construct_eth_get_logs(
         address=address,
         topics=topics,
         start_block=start_block,
         end_block=end_block,
         block_hash=block_hash,
     )
-    response = await rpc_request.async_send(request, provider=provider)
-    return rpc_digestors.digest_eth_get_logs(
-        response=response,
-        decode_response=decode_response,
-        snake_case_response=snake_case_response,
-        include_removed=include_removed,
-    )
+
+    import sys
+
+    if (sys.version_info.major, sys.version_info.minor) >= (3, 8):
+        from ctc.rpc.rpc_decoders import log_decoder
+
+        raw_response = await rpc_request.async_send(
+            request,
+            context=context,
+            raw_output=True,
+        )
+        return log_decoder.decode_logs(
+            raw_response,
+            include_removed=include_removed,
+        )
+
+    else:
+        response = await rpc_request.async_send(request, context=context)
+        logs = rpc_digestors.digest_eth_get_logs(
+            response=response,
+            decode_response=decode_response,
+            snake_case_response=snake_case_response,
+            include_removed=include_removed,
+        )
+        return [
+            (
+                log['block_number'],
+                log['transaction_index'],
+                log['log_index'],
+                log['transaction_hash'],
+                log['address'],
+                tuple(log['topics']),
+                log['data'],
+                log['block_hash'],
+            )
+            for log in logs
+        ]
+
```

### Comparing `checkthechain-0.3.0/src/ctc/rpc/rpc_executors/rpc_mining_executors.py` & `checkthechain-0.3.4/src/ctc/rpc/rpc_executors_async/rpc_submission_executors_async.py`

 * *Files 23% similar despite different names*

```diff
@@ -3,71 +3,104 @@
 from ctc import spec
 
 from .. import rpc_constructors
 from .. import rpc_digestors
 from .. import rpc_request
 
 
-async def async_eth_get_work(
-    *,
-    provider: spec.ProviderReference = None,
+async def async_eth_gas_price(
+    *, context: spec.Context = None, decode_response: bool = True
 ) -> spec.RpcSingularResponse:
-    request = rpc_constructors.construct_eth_get_work()
-    response = await rpc_request.async_send(request, provider=provider)
-    return rpc_digestors.digest_eth_get_work(response=response)
+    request = rpc_constructors.construct_eth_gas_price()
+    response = await rpc_request.async_send(request, context=context)
+    return rpc_digestors.digest_eth_gas_price(
+        response=response,
+        decode_response=decode_response,
+    )
 
 
-async def async_eth_submit_work(
+async def async_eth_accounts(
     *,
-    nonce: spec.BinaryData,
-    pow_hash: spec.BinaryData,
-    digest: spec.BinaryData,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
 ) -> spec.RpcSingularResponse:
-    request = rpc_constructors.construct_eth_submit_work(
-        nonce=nonce,
-        pow_hash=pow_hash,
-        digest=digest,
-    )
-    response = await rpc_request.async_send(request, provider=provider)
-    return rpc_digestors.digest_eth_submit_work(response=response)
+    request = rpc_constructors.construct_eth_accounts()
+    response = await rpc_request.async_send(request, context=context)
+    return rpc_digestors.digest_eth_accounts(response=response)
 
 
-async def async_eth_submit_hashrate(
-    hashrate: spec.BinaryData,
-    id: str,
+async def async_eth_sign(
+    address: spec.Address,
+    message: str,
     *,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
 ) -> spec.RpcSingularResponse:
-    request = rpc_constructors.construct_eth_submit_hashrate(
-        hashrate=hashrate,
-        id=id,
+    request = rpc_constructors.construct_eth_sign(
+        address=address,
+        message=message,
     )
-    response = await rpc_request.async_send(request, provider=provider)
-    return rpc_digestors.digest_eth_submit_hashrate(response=response)
+    response = await rpc_request.async_send(request, context=context)
+    return rpc_digestors.digest_eth_sign(response=response)
 
 
-async def async_eth_coinbase(
-    *,
-    provider: spec.ProviderReference = None,
-) -> spec.RpcSingularResponse:
-    request = rpc_constructors.construct_eth_coinbase()
-    response = await rpc_request.async_send(request, provider=provider)
-    return rpc_digestors.digest_eth_coinbase(response=response)
+async def async_eth_sign_transaction(
+    from_address: spec.Address,
+    data: str,
+    *,
+    to_address: spec.Address | None = None,
+    gas: int | None = None,
+    gas_price: int | None = None,
+    value: int | None = None,
+    nonce: str | None = None,
+    context: spec.Context = None,
+    snake_case_response: bool = True,
+) -> spec.RpcSingularResponse:
+    request = rpc_constructors.construct_eth_sign_transaction(
+        from_address=from_address,
+        data=data,
+        to_address=to_address,
+        gas=gas,
+        gas_price=gas_price,
+        value=value,
+        nonce=nonce,
+    )
+    response = await rpc_request.async_send(request, context=context)
+    return rpc_digestors.digest_eth_sign_transaction(
+        response=response,
+        snake_case_response=snake_case_response,
+    )
 
 
-async def async_eth_mining(
-    *,
-    provider: spec.ProviderReference = None,
-) -> spec.RpcSingularResponse:
-    request = rpc_constructors.construct_eth_mining()
-    response = await rpc_request.async_send(request, provider=provider)
-    return rpc_digestors.digest_eth_mining(response=response)
+async def async_eth_send_transaction(
+    from_address: spec.Address,
+    data: str,
+    *,
+    to_address: spec.Address | None = None,
+    gas: int | None = None,
+    gas_price: int | None = None,
+    value: int | None = None,
+    nonce: str | None = None,
+    context: spec.Context = None,
+    snake_case_response: bool = True,
+) -> spec.RpcSingularResponse:
+    request = rpc_constructors.construct_eth_send_transaction(
+        from_address=from_address,
+        data=data,
+        to_address=to_address,
+        gas=gas,
+        gas_price=gas_price,
+        value=value,
+        nonce=nonce,
+    )
+    response = await rpc_request.async_send(request, context=context)
+    return rpc_digestors.digest_eth_send_transaction(
+        response=response,
+        snake_case_response=snake_case_response,
+    )
 
 
-async def async_eth_hashrate(
-    *,
-    provider: spec.ProviderReference = None,
+async def async_eth_send_raw_transaction(
+    data: str, *, context: spec.Context = None
 ) -> spec.RpcSingularResponse:
-    request = rpc_constructors.construct_eth_hashrate()
-    response = await rpc_request.async_send(request, provider=provider)
-    return rpc_digestors.digest_eth_hashrate(response=response)
+    request = rpc_constructors.construct_eth_send_raw_transaction(data=data)
+    response = await rpc_request.async_send(request, context=context)
+    return rpc_digestors.digest_eth_send_raw_transaction(response=response)
+
```

### Comparing `checkthechain-0.3.0/src/ctc/rpc/rpc_executors/rpc_state_executors.py` & `checkthechain-0.3.4/src/ctc/rpc/rpc_executors_async/rpc_state_executors_async.py`

 * *Files 15% similar despite different names*

```diff
@@ -4,53 +4,53 @@
 
 from ctc import evm
 from ctc import spec
 
 from .. import rpc_constructors
 from .. import rpc_digestors
 from .. import rpc_request
-from .. import rpc_provider
 
 
 async def async_eth_call(
     to_address: spec.Address,
     *,
     from_address: spec.BinaryData | None = None,
     gas: spec.BinaryData | None = None,
     gas_price: spec.BinaryData | None = None,
     value_sent: spec.BinaryData | None = None,
     block_number: spec.BlockNumberReference | None = None,
     call_data: spec.BinaryData | None = None,
     function_parameters: typing.Sequence[typing.Any]
     | typing.Mapping[str, typing.Any]
     | None = None,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     decode_response: bool = True,
     delist_single_outputs: bool = True,
     package_named_outputs: bool = False,
     fill_empty: bool = False,
     empty_token: typing.Any = None,
+    convert_reverts_to: typing.Any = None,
+    convert_reverts_to_none: bool = False,
     function_abi: spec.FunctionABI | None = None,
     function_name: typing.Optional[str] = None,
     contract_abi: typing.Optional[spec.ContractABI] = None,
     n_parameters: typing.Optional[int] = None,
     parameter_types: typing.Optional[list[spec.ABIDatumType]] = None,
     function_selector: typing.Optional[spec.FunctionSelector] = None,
 ) -> spec.RpcSingularResponse:
-
     if function_abi is None:
         if call_data is None or decode_response:
             function_abi = await evm.async_get_function_abi(
                 contract_address=to_address,
                 contract_abi=contract_abi,
                 function_name=function_name,
                 n_parameters=n_parameters,
                 parameter_types=parameter_types,
                 function_selector=function_selector,
-                network=rpc_provider.get_provider_network(provider),
+                context=context,
             )
 
     # construct request
     request = rpc_constructors.construct_eth_call(
         to_address=to_address,
         from_address=from_address,
         gas=gas,
@@ -59,15 +59,20 @@
         block_number=block_number,
         call_data=call_data,
         function_parameters=function_parameters,
         function_abi=function_abi,
     )
 
     # make request
-    response = await rpc_request.async_send(request, provider=provider)
+    response = await rpc_request.async_send(
+        request,
+        context=context,
+        convert_reverts_to_none=convert_reverts_to_none,
+        convert_reverts_to=convert_reverts_to,
+    )
 
     # digest response
     return rpc_digestors.digest_eth_call(
         response,
         function_abi=function_abi,
         decode_response=decode_response,
         delist_single_outputs=delist_single_outputs,
@@ -84,97 +89,97 @@
     gas: spec.BinaryData | None = None,
     gas_price: spec.BinaryData | None = None,
     value_sent: spec.BinaryData | None = None,
     call_data: spec.BinaryData | None = None,
     function_parameters: typing.Sequence[typing.Any]
     | typing.Mapping[str, typing.Any]
     | None = None,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     decode_response: bool = True,
     function_abi: spec.FunctionABI | None = None,
     function_name: typing.Optional[str] = None,
     contract_abi: typing.Optional[spec.ContractABI] = None,
     n_parameters: typing.Optional[int] = None,
     parameter_types: typing.Optional[list[spec.ABIDatumType]] = None,
     function_selector: typing.Optional[spec.FunctionSelector] = None,
 ) -> spec.RpcSingularResponse:
-
     if function_abi is None:
         function_abi = await evm.async_get_function_abi(
             contract_address=to_address,
             contract_abi=contract_abi,
             function_name=function_name,
             n_parameters=n_parameters,
             parameter_types=parameter_types,
             function_selector=function_selector,
-            network=rpc_provider.get_provider_network(provider),
+            context=context,
         )
 
     request = rpc_constructors.construct_eth_estimate_gas(
         to_address=to_address,
         from_address=from_address,
         gas=gas,
         gas_price=gas_price,
         value_sent=value_sent,
         call_data=call_data,
         function_parameters=function_parameters,
         function_abi=function_abi,
     )
-    response = await rpc_request.async_send(request, provider=provider)
+    response = await rpc_request.async_send(request, context=context)
     return rpc_digestors.digest_eth_estimate_gas(
         response,
         decode_response=decode_response,
     )
 
 
 async def async_eth_get_balance(
     address: spec.Address,
     *,
     block_number: spec.BlockNumberReference | None = None,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     decode_response: bool = True,
 ) -> spec.RpcSingularResponse:
     if block_number is None:
         block_number = 'latest'
     request = rpc_constructors.construct_eth_get_balance(
         address=address,
         block_number=block_number,
     )
-    response = await rpc_request.async_send(request, provider=provider)
+    response = await rpc_request.async_send(request, context=context)
     return rpc_digestors.digest_eth_get_balance(
         response,
         decode_response=decode_response,
     )
 
 
 async def async_eth_get_storage_at(
     address: spec.Address,
     position: spec.BinaryData,
     *,
     block_number: spec.BlockNumberReference | None = None,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
 ) -> spec.RpcSingularResponse:
     if block_number is None:
         block_number = 'latest'
     request = rpc_constructors.construct_eth_get_storage_at(
         address=address,
         position=position,
         block_number=block_number,
     )
-    response = await rpc_request.async_send(request, provider=provider)
+    response = await rpc_request.async_send(request, context=context)
     return rpc_digestors.digest_eth_get_storage_at(response)
 
 
 async def async_eth_get_code(
     address: spec.Address,
     *,
     block_number: spec.BlockNumberReference | None = None,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
 ) -> spec.RpcSingularResponse:
     if block_number is None:
         block_number = 'latest'
     request = rpc_constructors.construct_eth_get_code(
         address=address,
         block_number=block_number,
     )
-    response = await rpc_request.async_send(request, provider=provider)
+    response = await rpc_request.async_send(request, context=context)
     return rpc_digestors.digest_eth_get_code(response)
+
```

### Comparing `checkthechain-0.3.0/src/ctc/rpc/rpc_executors/rpc_transaction_executors.py` & `checkthechain-0.3.4/src/ctc/rpc/rpc_executors_async/rpc_block_executors_async.py`

 * *Files 14% similar despite different names*

```diff
@@ -3,139 +3,151 @@
 from ctc import spec
 
 from .. import rpc_constructors
 from .. import rpc_digestors
 from .. import rpc_request
 
 
-async def async_eth_get_transaction_count(
-    from_address: spec.Address,
+async def async_eth_block_number(
     *,
-    block_number: spec.BlockNumberReference | None = None,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     decode_response: bool = True,
+    raw_output: bool = False,
 ) -> spec.RpcSingularResponse:
-    if block_number is None:
-        block_number = 'latest'
-    request = rpc_constructors.construct_eth_get_transaction_count(
-        from_address=from_address,
-        block_number=block_number,
-    )
-    response = await rpc_request.async_send(request, provider=provider)
-    return rpc_digestors.digest_eth_get_transaction_count(
-        response=response,
-        decode_response=decode_response,
+    request = rpc_constructors.construct_eth_block_number()
+    response = await rpc_request.async_send(
+        request,
+        context=context,
+        raw_output=raw_output,
     )
 
+    if raw_output:
+        return response
+    else:
+        return rpc_digestors.digest_eth_block_number(
+            response=response,
+            decode_response=decode_response,
+        )
+
 
-async def async_eth_get_transaction_by_hash(
-    transaction_hash: str,
+async def async_eth_get_block_by_hash(
+    block_hash: str,
     *,
-    provider: spec.ProviderReference = None,
+    include_full_transactions: bool = False,
+    context: spec.Context = None,
     decode_response: bool = True,
     snake_case_response: bool = True,
 ) -> spec.RpcSingularResponse:
-    request = rpc_constructors.construct_eth_get_transaction_by_hash(
-        transaction_hash=transaction_hash
+    request = rpc_constructors.construct_eth_get_block_by_hash(
+        block_hash=block_hash,
+        include_full_transactions=include_full_transactions,
     )
-    response = await rpc_request.async_send(request, provider=provider)
-    return rpc_digestors.digest_eth_get_transaction_by_hash(
+    response = await rpc_request.async_send(request, context=context)
+    return rpc_digestors.digest_eth_get_block_by_hash(
         response=response,
         decode_response=decode_response,
         snake_case_response=snake_case_response,
     )
 
 
-async def async_eth_get_transaction_by_block_hash_and_index(
-    block_hash: spec.BinaryData,
-    transaction_index: spec.BinaryData,
+async def async_eth_get_block_by_number(
+    block_number: spec.StandardBlockNumber,
     *,
-    provider: spec.ProviderReference = None,
+    include_full_transactions: bool = False,
     decode_response: bool = True,
+    context: spec.Context = None,
     snake_case_response: bool = True,
+    raw_output: bool = False,
 ) -> spec.RpcSingularResponse:
-    request = (
-        rpc_constructors.construct_eth_get_transaction_by_block_hash_and_index(
-            block_hash=block_hash,
-            transaction_index=transaction_index,
-        )
+    request = rpc_constructors.construct_eth_get_block_by_number(
+        block_number=block_number,
+        include_full_transactions=include_full_transactions,
     )
-    response = await rpc_request.async_send(request, provider=provider)
-    return rpc_digestors.digest_eth_get_transaction_by_block_hash_and_index(
-        response=response,
-        decode_response=decode_response,
-        snake_case_response=snake_case_response,
+    response = await rpc_request.async_send(
+        request,
+        context=context,
+        raw_output=raw_output,
     )
 
+    if raw_output:
+        return response
+    else:
+        return rpc_digestors.digest_eth_get_block_by_number(
+            response=response,
+            decode_response=decode_response,
+            snake_case_response=snake_case_response,
+        )
+
 
-async def async_eth_get_transaction_by_block_number_and_index(
-    block_number: spec.BlockNumberReference,
-    transaction_index: spec.BinaryData,
+async def async_eth_get_uncle_count_by_block_hash(
+    block_hash: str,
     *,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     decode_response: bool = True,
-    snake_case_response: bool = True,
 ) -> spec.RpcSingularResponse:
-    request = rpc_constructors.construct_eth_get_transaction_by_block_number_and_index(
-        block_number=block_number,
-        transaction_index=transaction_index,
+    request = rpc_constructors.construct_eth_get_uncle_count_by_block_hash(
+        block_hash=block_hash,
     )
-    response = await rpc_request.async_send(request, provider=provider)
-    return rpc_digestors.digest_eth_get_transaction_by_block_number_and_index(
+    response = await rpc_request.async_send(request, context=context)
+    return rpc_digestors.digest_eth_get_uncle_count_by_block_hash(
         response=response,
         decode_response=decode_response,
-        snake_case_response=snake_case_response,
     )
 
 
-async def async_eth_get_transaction_receipt(
-    transaction_hash: str,
+async def async_eth_get_uncle_count_by_block_number(
+    block_number: spec.StandardBlockNumber,
     *,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     decode_response: bool = True,
-    snake_case_response: bool = True,
 ) -> spec.RpcSingularResponse:
-    request = rpc_constructors.construct_eth_get_transaction_receipt(
-        transaction_hash=transaction_hash,
+    request = rpc_constructors.construct_eth_get_uncle_count_by_block_number(
+        block_number=block_number,
     )
-    response = await rpc_request.async_send(request, provider=provider)
-    return rpc_digestors.digest_eth_get_transaction_receipt(
+    response = await rpc_request.async_send(request, context=context)
+    return rpc_digestors.digest_eth_get_uncle_count_by_block_number(
         response=response,
         decode_response=decode_response,
-        snake_case_response=snake_case_response,
     )
 
 
-async def async_eth_get_block_transaction_count_by_hash(
+async def async_eth_get_uncle_by_block_hash_and_index(
     block_hash: str,
+    uncle_index: str,
     *,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     decode_response: bool = True,
+    snake_case_response: bool = True,
 ) -> spec.RpcSingularResponse:
-    request = (
-        rpc_constructors.construct_eth_get_block_transaction_count_by_hash(
-            block_hash=block_hash,
-        )
+    request = rpc_constructors.construct_eth_get_uncle_by_block_hash_and_index(
+        block_hash=block_hash,
+        uncle_index=uncle_index,
     )
-    response = await rpc_request.async_send(request, provider=provider)
-    return rpc_digestors.digest_eth_get_block_transaction_count_by_hash(
+    response = await rpc_request.async_send(request, context=context)
+    return rpc_digestors.digest_eth_get_uncle_by_block_hash_and_index(
         response=response,
         decode_response=decode_response,
+        snake_case_response=snake_case_response,
     )
 
 
-async def async_eth_get_block_transaction_count_by_number(
-    block_number: spec.BlockNumberReference,
+async def async_eth_get_uncle_by_block_number_and_index(
+    block_number: spec.StandardBlockNumber,
+    uncle_index: str,
     *,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     decode_response: bool = True,
+    snake_case_response: bool = True,
 ) -> spec.RpcSingularResponse:
     request = (
-        rpc_constructors.construct_eth_get_block_transaction_count_by_number(
+        rpc_constructors.construct_eth_get_uncle_by_block_number_and_index(
             block_number=block_number,
+            uncle_index=uncle_index,
         )
     )
-    response = await rpc_request.async_send(request, provider=provider)
-    return rpc_digestors.digest_eth_get_block_transaction_count_by_number(
+    response = await rpc_request.async_send(request, context=context)
+    return rpc_digestors.digest_eth_get_uncle_by_block_number_and_index(
         response=response,
         decode_response=decode_response,
+        snake_case_response=snake_case_response,
     )
+
```

### Comparing `checkthechain-0.3.0/src/ctc/rpc/rpc_format.py` & `checkthechain-0.3.4/src/ctc/rpc/rpc_format.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/rpc/rpc_lifecycle.py` & `checkthechain-0.3.4/src/ctc/rpc/rpc_lifecycle.py`

 * *Files 5% similar despite different names*

```diff
@@ -58,13 +58,14 @@
         return output
     else:
         raise Exception()
 
 
 async def async_execute(
     request: spec.RpcRequest,
-    provider: spec.ProviderReference = None,
     *,
+    context: spec.Context = None,
     digest_kwargs: typing.Optional[dict[typing.Any, typing.Any]] = None,
 ) -> spec.RpcResponse:
-    response = await rpc_request.async_send(request=request, provider=provider)
+    response = await rpc_request.async_send(request=request, context=context)
     return digest(response, request=request, digest_kwargs=digest_kwargs)
+
```

### Comparing `checkthechain-0.3.0/src/ctc/rpc/rpc_protocols/rpc_http_async.py` & `checkthechain-0.3.4/src/ctc/rpc/rpc_protocols/rpc_http.py`

 * *Files 26% similar despite different names*

```diff
@@ -2,92 +2,157 @@
 
 import typing
 import warnings
 
 if typing.TYPE_CHECKING:
     import aiohttp
 
+from ctc import config
 from ctc import spec
 from .. import rpc_provider
 
 
-_http_sessions: dict[spec.ProviderKey, aiohttp.ClientSession] = {}
+_http_sessions: dict[spec.ProviderId, aiohttp.ClientSession] = {}
+
+
+def sync_send_http(
+    request: spec.RpcRequest,
+    provider: spec.Provider,
+    *,
+    n_attempts: int = 8,
+) -> str:
+    import requests
+    import json
+
+    headers = {'Content-Type': 'application/json', 'User-Agent': 'ctc'}
+    data = json.dumps(request)
+    for attempt in range(n_attempts):
+        try:
+            response = requests.post(
+                provider['url'],
+                data=data,
+                headers=headers,
+            )
+            return response.text
+        except Exception:
+            import time
+
+            time.sleep(0.250)
+    else:
+        if response is None:
+            status = 'None'
+        else:
+            status = str(response.status_code)
+        message = (
+            'http rpc request failed after '
+            + str(n_attempts)
+            + ' retries, status_code = '
+            + str(status)
+        )
+        raise Exception(message)
 
 
 async def async_send_http(
     request: spec.RpcRequest,
-    provider: spec.ProviderReference,
+    provider: spec.Provider,
     *,
     n_attempts: int = 8,
-) -> spec.RpcResponse:
-    provider = rpc_provider.get_provider(provider)
+) -> str:
     session = get_async_http_session(provider=provider)
 
     headers = {'User-Agent': 'ctc'}
+    response = None
     for attempt in range(n_attempts):
+        try:
+            async with session.post(
+                provider['url'], json=request, headers=headers
+            ) as response:
+                if response.status != 200:
+                    import random
+
+                    t_sleep = 2**attempt + random.random()
+                    warnings.warn(
+                        'request failed with code '
+                        + str(response.status)
+                        + ' retrying in '
+                        + str(t_sleep)
+                        + 's'
+                    )
+                    import asyncio
+
+                    await asyncio.sleep(t_sleep)
+                    continue
+                as_text = await response.text()
+                return as_text
+        except Exception:
+            # connection failure
+            import asyncio
 
-        async with session.post(
-            provider['url'], json=request, headers=headers
-        ) as response:
-            if response.status != 200:
-                import random
-
-                t_sleep = 2 ** attempt + random.random()
-                warnings.warn(
-                    'request failed with code '
-                    + str(response.status)
-                    + ' retrying in '
-                    + str(t_sleep)
-                    + 's'
-                )
-                import asyncio
-
-                await asyncio.sleep(t_sleep)
-                continue
-            return await response.json()
+            await asyncio.sleep(0.250)
 
     else:
+        if response is None:
+            status = 'None'
+        else:
+            status = str(response.status)
         message = (
             'http rpc request failed after '
             + str(n_attempts)
             + ' retries, status_code = '
-            + str(response.status)
+            + str(status)
         )
-        # logger = logging.getLogger()
-        # logger.info(message)
         raise Exception(message)
 
 
 def get_async_http_session(
     provider: spec.Provider, create: bool = True
 ) -> aiohttp.ClientSession:
-
-    key = rpc_provider.get_provider_key(provider)
-    if key not in _http_sessions:
+    provider_id = rpc_provider._get_provider_id(provider)
+    if provider_id not in _http_sessions:
         if create:
             import aiohttp
 
             kwargs = provider['session_kwargs']
             if kwargs is None:
                 kwargs = {}
-            _http_sessions[key] = aiohttp.ClientSession(**kwargs)
+            kwargs = dict(kwargs)
+            kwargs.setdefault('timeout', aiohttp.ClientTimeout(300))
+            _http_sessions[provider_id] = aiohttp.ClientSession(
+                trust_env=True, **kwargs
+            )
         else:
             raise Exception('no session, must create')
-    return _http_sessions[key]
+    return _http_sessions[provider_id]
 
 
 async def async_close_http_session(
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
 ) -> None:
+    import asyncio
+
     if len(_http_sessions) == 0:
         return
 
-    if provider is None and len(_http_sessions) == 1:
-        session = list(_http_sessions.values())[0]
+    if context is None:
+        for key, session in list(_http_sessions.items()):
+            await asyncio.sleep(0)
+            await session.close()
+            del _http_sessions[key]
+
     else:
-        provider = rpc_provider.get_provider(provider)
+        provider = config.get_context_provider(context)
+        if provider is None:
+            raise Exception('no provider available')
         session = get_async_http_session(provider=provider)
+        session_keys = [
+            key
+            for key, value in _http_sessions.items()
+            if id(session) == id(value)
+        ]
+        if len(session_keys) != 1:
+            raise Exception('unknown session')
+        else:
+            session_key = session_keys[0]
+        await asyncio.sleep(0)
+        await session.close()
+        del _http_sessions[session_key]
 
-    import asyncio
-
-    await asyncio.sleep(0)
-    await session.close()
```

### Comparing `checkthechain-0.3.0/src/ctc/rpc/rpc_registry.py` & `checkthechain-0.3.4/src/ctc/rpc/rpc_registry.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/rpc/rpc_spec.py` & `checkthechain-0.3.4/src/ctc/rpc/rpc_spec.py`

 * *Files 1% similar despite different names*

```diff
@@ -40,25 +40,27 @@
     'blockNumber',
     'gas',
     'gasPrice',
     'maxFeePerGas',
     'maxPriorityFeePerGas',
     'nonce',
     'transactionIndex',
+    'type',
     'value',
     'v',
 ]
 rpc_transaction_receipt_quantities = [
     'transactionIndex',
     'blockNumber',
     'cumulativeGasUsed',
     'effectiveGasPrice',
     'gasUsed',
     'quantity',
     'status',
+    'type',
 ]
 
 rpc_result_scalar_quantities = [
     'eth_blockNumber',
     'eth_getUncleCountByBlockHash',
     'eth_getUncleCountByBlockNumber',
     'eth_newFilter',
@@ -126,8 +128,11 @@
         'indices': 'index',
     },
     'eth_get_transaction_receipt': {'transaction_hashes': 'transaction_hash'},
     'eth_get_block_transaction_count_by_hash': {'block_hashes': 'block_hash'},
     'eth_get_block_transaction_count_by_number': {
         'block_numbers': 'block_number'
     },
+    'trace_block': {
+        'block_numbers': 'block_number',
+    },
 }
```

### Comparing `checkthechain-0.3.0/src/ctc/spec/typedefs/abi_types.py` & `checkthechain-0.3.4/src/ctc/spec/typedefs/abi_types.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,16 +1,15 @@
 # see https://docs.soliditylang.org/en/latest/abi-spec.html
 
 from __future__ import annotations
 
 import typing
-from typing_extensions import TypedDict
 
-if typing.TYPE_CHECKING:
-    from typing_extensions import NotRequired
+from typing_extensions import NotRequired
+from typing_extensions import TypedDict
 
 
 class FunctionABI(TypedDict, total=False):
     type: typing.Literal['function', 'constructor', 'receive', 'fallback']
     name: NotRequired[str]
     inputs: NotRequired[list['ABIFunctionArg']]
     outputs: NotRequired[list['ABIFunctionArg']]
@@ -37,14 +36,23 @@
     type: 'ABIDatumType'
     internalType: 'ABIDatumType'
     components: 'ABITupleComponents'
     indexed: bool
     anonymous: NotRequired[bool]
 
 
+class EventSchema(TypedDict):
+    indexed_names: typing.Sequence[str]
+    indexed_types: typing.Sequence[ABIDatumType]
+    unindexed_names: typing.Sequence[str]
+    unindexed_types: typing.Sequence[ABIDatumType]
+    names: typing.Sequence[str]
+    types: typing.Sequence[ABIDatumType]
+
+
 class ErrorABI(TypedDict):
     type: typing.Literal['error']
     name: str
     inputs: ABIFunctionArg
 
 
 ContractABIEntry = typing.Union[FunctionABI, EventABI, ErrorABI]
```

### Comparing `checkthechain-0.3.0/src/ctc/spec/typedefs/address_types.py` & `checkthechain-0.3.4/src/ctc/spec/typedefs/address_types.py`

 * *Files 2% similar despite different names*

```diff
@@ -32,9 +32,9 @@
     heartbeat: int  # number of seconds
     decimals: int
 
 
 class ERC20Metadata(TypedDict):
     symbol: str
     decimals: int
-    name: str
+    name: str | None
     address: str
```

### Comparing `checkthechain-0.3.0/src/ctc/spec/typedefs/binary_types.py` & `checkthechain-0.3.4/src/ctc/spec/typedefs/binary_types.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/spec/typedefs/block_types.py` & `checkthechain-0.3.4/src/ctc/spec/typedefs/block_types.py`

 * *Files 9% similar despite different names*

```diff
@@ -4,14 +4,18 @@
 from typing_extensions import TypedDict, Literal, NotRequired
 
 from . import address_types
 from . import binary_types
 from . import transaction_types
 
 
+#
+# # block references
+#
+
 BlockHash = binary_types.PrefixHexData
 
 BlockNumberName = typing.Union[
     Literal['latest'],
     Literal['earliest'],
     Literal['pending'],
 ]
@@ -19,14 +23,15 @@
 # anything that can be converted to an int without node querying
 RawBlockNumber = typing.Union[typing.SupportsRound, binary_types.HexData, str]
 
 
 class RawBlock(TypedDict):
     pass
 
+
 # an int or block number name
 StandardBlockNumber = typing.Union[int, BlockNumberName]
 
 # anything that refers to a block number, raw or standard
 BlockNumberReference = typing.Union[RawBlockNumber, StandardBlockNumber]
 
 # any reference to a block
@@ -44,15 +49,20 @@
     start_block: StandardBlockNumber
     end_block: StandardBlockNumber
     block_interval: typing.Union[int, None]
     open_start: bool
     open_end: bool
 
 
-class Block(TypedDict):
+#
+# # block data
+#
+
+# block returned from RPC request
+class RPCBlock(TypedDict):
     base_fee_per_gas: NotRequired[int | None]
     difficulty: int
     extra_data: binary_types.PrefixHexData
     gas_limit: int
     gas_used: int
     hash: BlockHash
     logs_bloom: binary_types.PrefixHexData
@@ -65,39 +75,23 @@
     sha3_uncles: binary_types.PrefixHexData
     size: int
     state_root: binary_types.PrefixHexData
     timestamp: int
     total_difficulty: str
     transactions: typing.Union[
         typing.List[transaction_types.TransactionHash],
-        typing.List[transaction_types.Transaction],
+        typing.List[transaction_types.RPCTransaction],
     ]
     transactions_root: binary_types.PrefixHexData
     uncles: typing.List[BlockHash]
 
 
-class RawLog(TypedDict):
-    removed: bool
-    logIndex: int
-    transactionIndex: int
-    transactionHash: transaction_types.TransactionHash
-    blockHash: BlockHash
-    blockNumber: int
-    address: address_types.Address
-    data: binary_types.PrefixHexData
-    topics: typing.List[binary_types.PrefixHexData]
-
-
-class PendingRawLog(TypedDict):
-    # many log fields are nullable if a log is pending
-    removed: bool
-    logIndex: typing.Union[None, int]
-    transactionIndex: typing.Union[None, int]
-    transactionHash: typing.Union[None, transaction_types.TransactionHash]
-    blockHash: typing.Union[None, BlockHash]
-    blockNumber: typing.Union[None, int]
-    address: address_types.Address
-    data: binary_types.PrefixHexData
-    topics: typing.List[binary_types.PrefixHexData]
-
+class DBBlock(TypedDict):
+    number: int
+    hash: str
+    timestamp: int
+    miner: str
+    extra_data: str
+    base_fee_per_gas: int | None
+    gas_limit: int
+    gas_used: int
 
-NormalizedLog = typing.Dict[str, typing.Any]
```

### Comparing `checkthechain-0.3.0/src/ctc/spec/typedefs/config_types.py` & `checkthechain-0.3.4/src/ctc/spec/typedefs/config_types.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,59 +1,71 @@
 from __future__ import annotations
 
 import typing
 from typing_extensions import TypedDict
 
+from . import context_types
 from . import network_types
 from . import rpc_types
 
 if typing.TYPE_CHECKING:
     import toolsql
+    import toolcli
+    import toolstr
 
 
 class PartialConfig(TypedDict, total=False):
     config_spec_version: str
     data_dir: str
-    providers: typing.Mapping[rpc_types.ProviderName, rpc_types.Provider]
+    providers: typing.Mapping[str, rpc_types.Provider]
     networks: typing.Mapping[
         network_types.ChainId, network_types.NetworkMetadata
     ]
-    default_network: network_types.ChainId | None
-    default_providers: typing.Mapping[
-        network_types.ChainId, rpc_types.ProviderName
-    ]
+    default_network: network_types.ChainId
+    default_providers: typing.Mapping[network_types.ChainId, str]
     db_configs: typing.Mapping[str, toolsql.DBConfig]
+    context_cache_rules: typing.Sequence[context_types.ContextCacheRule]
 
     log_rpc_calls: bool
     log_sql_queries: bool
 
+    cli_color_theme: toolcli.StyleTheme
+    cli_chart_charset: toolstr.SampleMode
+
 
 class Config(TypedDict):
     config_spec_version: str
     data_dir: str
-    providers: typing.Mapping[rpc_types.ProviderName, rpc_types.Provider]
+    providers: typing.Mapping[str, rpc_types.Provider]
     networks: typing.Mapping[
         network_types.ChainId, network_types.NetworkMetadata
     ]
-    default_network: network_types.ChainId | None
-    default_providers: typing.Mapping[
-        network_types.ChainId, rpc_types.ProviderName
-    ]
+    default_network: network_types.ChainId
+    default_providers: typing.Mapping[network_types.ChainId, str]
 
     db_configs: typing.Mapping[str, toolsql.DBConfig]
+    context_cache_rules: typing.Sequence[context_types.ContextCacheRule]
 
     log_rpc_calls: bool
     log_sql_queries: bool
 
+    cli_color_theme: toolcli.StyleTheme
+    cli_chart_charset: toolstr.SampleMode
+
 
 class JsonConfig(TypedDict):
     config_spec_version: str
     data_dir: str
-    providers: typing.Mapping[rpc_types.ProviderName, rpc_types.Provider]
+    providers: typing.Mapping[str, rpc_types.Provider]
     networks: typing.Mapping[str, network_types.NetworkMetadata]
-    default_network: network_types.ChainId | None
-    default_providers: typing.Mapping[str, rpc_types.ProviderName]
+    default_network: network_types.ChainId
+    default_providers: typing.Mapping[str, str]
 
     db_configs: typing.Mapping[str, toolsql.DBConfig]
+    context_cache_rules: typing.Sequence[context_types.ContextCacheRule]
 
     log_rpc_calls: bool
     log_sql_queries: bool
+
+    cli_color_theme: toolcli.StyleTheme
+    cli_chart_charset: toolstr.SampleMode
+
```

### Comparing `checkthechain-0.3.0/src/ctc/spec/typedefs/defi_types.py` & `checkthechain-0.3.4/src/ctc/spec/typedefs/defi_types.py`

 * *Files 26% similar despite different names*

```diff
@@ -3,15 +3,15 @@
 import typing
 from typing_extensions import TypedDict, NotRequired
 
 from . import external_types
 
 
 class RawDexTrades(TypedDict):
-    # each should be  series indexed by block number
+    block_number: external_types.Series
     timestamp: NotRequired[external_types.Series | typing.Sequence[int] | None]
     transaction_hash: external_types.Series
     recipient: NotRequired[external_types.Series | None]
     bought_id: external_types.Series
     sold_id: external_types.Series
     bought_amount: external_types.Series
     sold_amount: external_types.Series
```

### Comparing `checkthechain-0.3.0/src/ctc/spec/typedefs/external_types.py` & `checkthechain-0.3.4/src/ctc/spec/typedefs/external_types.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,27 +1,36 @@
 from __future__ import annotations
 
 import typing
 
 
 if typing.TYPE_CHECKING:
     import numpy
-    import pandas
+    import polars as pl
 
-    DataFrame = pandas.core.frame.DataFrame
-    Series = pandas.core.series.Series
-    PandasIndex = pandas.core.indexes.base.Index
+    DataFrame = pl.DataFrame
+    Series = pl.Series
     DType = numpy.typing.DTypeLike
     NumpyArray = numpy.typing.NDArray  # type: ignore
 
-else:
+    IntegerOutputFormatScalar = typing.Union[
+        type[pl.datatypes.DataTypeClass],
+        type[object],
+        type[int],
+        type[float],
+        typing.Literal['decimal'],
+    ]
+    IntegerOutputFormat = typing.Union[
+        IntegerOutputFormatScalar,
+        typing.Mapping[str, IntegerOutputFormatScalar],
+    ]
 
+else:
     DataFrame = typing.Any
     Series = typing.Any
-    PandasIndex = typing.Any
     DType = typing.Any
     NumpyArray = typing.Any
 
 
 Integer = typing.Union[
     int,
     'numpy.int8',
@@ -35,7 +44,8 @@
     'numpy.float16',
     'numpy.float32',
     'numpy.float64',
     'numpy.float128',
 ]
 
 Number = typing.Union[Integer, Float]
+
```

### Comparing `checkthechain-0.3.0/src/ctc/spec/typedefs/rpc_types.py` & `checkthechain-0.3.4/src/ctc/spec/typedefs/rpc_types.py`

 * *Files 10% similar despite different names*

```diff
@@ -47,37 +47,41 @@
 RpcDigestor = typing.Callable[..., RpcResponse]
 
 
 #
 # # provider
 #
 
-ProviderName = str
+ProviderShortcut = str
 
 
 class PartialProvider(TypedDict, total=False):
     url: str
-    name: typing.Optional[ProviderName]
-    network: typing.Optional[network_types.NetworkReference]
+    name: str | None
+    network: network_types.NetworkReference | None
     protocol: Literal['http', 'wss', 'ipc']
-    session_kwargs: typing.Optional[dict[str, typing.Any]]
-    chunk_size: typing.Optional[int]
+    #
+    # query behaviors
+    session_kwargs: typing.Mapping[str, typing.Any] | None
+    chunk_size: int | None
     convert_reverts_to_none: bool
+    disable_batch_requests: bool
 
 
 class Provider(TypedDict, total=True):
     url: str
-    name: typing.Optional[ProviderName]
-    network: network_types.NetworkReference
+    name: str | None
+    network: network_types.ChainId
     protocol: Literal['http', 'wss', 'ipc']
-    session_kwargs: typing.Optional[dict[str, typing.Any]]
-    chunk_size: typing.Optional[int]
+    #
+    # query behaviors
+    session_kwargs: typing.Mapping[str, typing.Any] | None
+    chunk_size: int | None
     convert_reverts_to_none: bool
+    disable_batch_requests: bool
 
 
-ProviderShortcut = str
-ProviderReference = typing.Union[
-    ProviderShortcut, PartialProvider, Provider, None
-]
-ProviderKey = typing.Tuple[
+ProviderReference = typing.Union[ProviderShortcut, PartialProvider, Provider]
+ProviderId = typing.Tuple[
     int, str, typing.Tuple[typing.Tuple[typing.Any, typing.Any], ...]
 ]
+
```

### Comparing `checkthechain-0.3.0/src/ctc/spec/typedefs/storage_types.py` & `checkthechain-0.3.4/src/ctc/spec/typedefs/storage_types.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/spec/typeguards/binary_typeguards.py` & `checkthechain-0.3.4/src/ctc/spec/typeguards/binary_typeguards.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/spec/typeguards/block_typeguards.py` & `checkthechain-0.3.4/src/ctc/spec/typeguards/block_typeguards.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/spec/typeguards/external_typeguards.py` & `checkthechain-0.3.4/src/ctc/spec/typeguards/external_typeguards.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,26 +1,34 @@
 from __future__ import annotations
 
 import typing
 
-if typing.TYPE_CHECKING:
-    import pandas
+from ctc import spec
 
+if typing.TYPE_CHECKING:
     from typing_extensions import TypeGuard
 
     from .. import typedefs
 
 
-def is_dataframe(
-    candidate: typing.Any,
-) -> TypeGuard['pandas.core.frame.DataFrame']:
-    """return whether input is a pandas DataFrame"""
-    import pandas as pd
+def is_polars_dataframe(item: typing.Any) -> TypeGuard[spec.DataFrame]:
+    """return whether input is a polars DataFrame"""
+    item_type = type(item)
+    return (
+        item_type.__name__ == 'DataFrame'
+        and item_type.__module__ == 'polars.internals.dataframe.frame'
+    )
+
 
-    return isinstance(candidate, pd.DataFrame)
+def is_polars_series(item: typing.Any) -> TypeGuard[spec.DataFrame]:
+    """return whether input is a polars DataFrame"""
+    item_type = type(item)
+    return item_type.__name__ == 'Series' and item_type.__module__.startswith(
+        'polars'
+    )
 
 
 def is_int(value: typing.Any) -> TypeGuard['typedefs.Integer']:
     """return whether input is a python int or numpy int"""
     return isinstance(value, int) or type(value).__name__ in (
         'int8',
         'int16',
@@ -38,7 +46,8 @@
         'float128',
     )
 
 
 def is_number(value: typing.Any) -> TypeGuard['typedefs.Number']:
     """return whether input is any type of int or float"""
     return is_int(value) or is_float(value)
+
```

### Comparing `checkthechain-0.3.0/src/ctc/toolbox/defi_utils/dex_utils/amm_utils/amm_spec.py` & `checkthechain-0.3.4/src/ctc/defi/dex_utils/amm_utils/amm_spec.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/toolbox/defi_utils/dex_utils/amm_utils/cpmm/cpmm_liquidity.py` & `checkthechain-0.3.4/src/ctc/defi/dex_utils/amm_utils/cpmm/cpmm_liquidity.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,28 +1,34 @@
 from __future__ import annotations
 
 import decimal
 import math
 
-from ctc.toolbox import validate_utils
 from . import cpmm_spec
 
 
 def mint_liquidity(
     x_reserves: int | float,
     y_reserves: int | float,
     *,
     lp_total_supply: int | float,
     x_deposited: int | float | None = None,
     y_deposited: int | float | None = None,
     lp_minted: int | float | None = None,
 ) -> cpmm_spec.Mint:
-
     # validate inputs
-    validate_utils._ensure_exactly_one(x_deposited, y_deposited, lp_minted)
+    non_none_inputs = [
+        x_deposited is not None,
+        y_deposited is not None,
+        lp_minted is not None,
+    ]
+    if sum(non_none_inputs) != 1:
+        raise Exception(
+            'must specify one of x_deposited, y_deposited, lp_minted'
+        )
 
     # compute alpha
     if x_deposited is not None:
         alpha = x_deposited / x_reserves
     elif y_deposited is not None:
         alpha = y_deposited / y_reserves
     elif lp_minted is not None:
@@ -56,17 +62,24 @@
     y_reserves: int | float,
     *,
     lp_total_supply: int | float,
     x_withdrawn: int | float | None = None,
     y_withdrawn: int | float | None = None,
     lp_burned: int | float | None = None,
 ) -> cpmm_spec.Burn:
-
     # validate inputs
-    validate_utils._ensure_exactly_one(x_withdrawn, y_withdrawn, lp_burned)
+    non_none_inputs = [
+        x_withdrawn is not None,
+        y_withdrawn is not None,
+        lp_burned is not None,
+    ]
+    if sum(non_none_inputs) != 1:
+        raise Exception(
+            'must specify one of x_withdrawn, y_withdrawn, lp_burned'
+        )
 
     # compute alpha
     if x_withdrawn is not None:
         alpha = x_withdrawn / x_reserves
     elif y_withdrawn is not None:
         alpha = y_withdrawn / y_reserves
     elif lp_burned is not None:
@@ -89,7 +102,8 @@
         'lp_burned': lp_total_supply - lp_total_supply_new,
         'new_pool': {
             'x_reserves': x_reserves_new,
             'y_reserves': y_reserves_new,
             'lp_total_supply': lp_total_supply_new,
         },
     }
+
```

### Comparing `checkthechain-0.3.0/src/ctc/toolbox/defi_utils/dex_utils/amm_utils/cpmm/cpmm_spec.py` & `checkthechain-0.3.4/src/ctc/defi/dex_utils/amm_utils/cpmm/cpmm_spec.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,48 +1,48 @@
 from __future__ import annotations
 
-from typing_extensions import TypedDict, NotRequired
+import typing
 
 
-class Trade(TypedDict):
-    x_bought: int | float
-    x_sold: int | float
-    y_bought: int | float
-    y_sold: int | float
-    fee_rate: float
-    new_pool: NewPoolState
-
-
-class Mint(TypedDict):
-    x_deposited: int | float
-    y_deposited: int | float
-    lp_minted: int | float
-    new_pool: NewPoolState
-
-
-class Burn(TypedDict):
-    x_withdrawn: int | float
-    y_withdrawn: int | float
-    lp_burned: int | float
-    new_pool: NewPoolState
-
-
-class NewPoolState(TypedDict):
-    x_reserves: int | float
-    y_reserves: int | float
-    lp_total_supply: NotRequired[int | float]
-
-
-class TradeSummary(TypedDict):
-    end_slippage_x_per_y: int | float
-    end_slippage_y_per_x: int | float
-    mean_slippage_x_per_y: int | float
-    mean_slippage_y_per_x: int | float
-    mean_x_per_y: int | float
-    mean_y_per_x: int | float
-    x_per_y_start: int | float
-    y_per_x_start: int | float
-    x_per_y_end: int | float
-    y_per_x_end: int | float
-    x_fees: int | float
-    y_fees: int | float
-    trade_results: Trade
+if typing.TYPE_CHECKING:
+    from typing_extensions import TypedDict, NotRequired
+
+    class Trade(TypedDict):
+        x_bought: int | float
+        x_sold: int | float
+        y_bought: int | float
+        y_sold: int | float
+        fee_rate: float
+        new_pool: NewPoolState
+
+    class Mint(TypedDict):
+        x_deposited: int | float
+        y_deposited: int | float
+        lp_minted: int | float
+        new_pool: NewPoolState
+
+    class Burn(TypedDict):
+        x_withdrawn: int | float
+        y_withdrawn: int | float
+        lp_burned: int | float
+        new_pool: NewPoolState
+
+    class NewPoolState(TypedDict):
+        x_reserves: int | float
+        y_reserves: int | float
+        lp_total_supply: NotRequired[int | float]
+
+    class TradeSummary(TypedDict):
+        end_slippage_x_per_y: int | float
+        end_slippage_y_per_x: int | float
+        mean_slippage_x_per_y: int | float
+        mean_slippage_y_per_x: int | float
+        mean_x_per_y: int | float
+        mean_y_per_x: int | float
+        x_per_y_start: int | float
+        y_per_x_start: int | float
+        x_per_y_end: int | float
+        y_per_x_end: int | float
+        x_fees: int | float
+        y_fees: int | float
+        trade_results: Trade
+
```

### Comparing `checkthechain-0.3.0/src/ctc/toolbox/defi_utils/dex_utils/amm_utils/cpmm/cpmm_summary.py` & `checkthechain-0.3.4/src/ctc/defi/dex_utils/amm_utils/cpmm/cpmm_summary.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/toolbox/defi_utils/dex_utils/dexes/dex_class.py` & `checkthechain-0.3.4/src/ctc/defi/dex_utils/dexes/dex_class.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,20 +1,20 @@
 from __future__ import annotations
 
 import asyncio
 import typing
 
+from ctc import evm
+from ctc import spec
+
 if typing.TYPE_CHECKING:
     from typing_extensions import Literal
 
     import tooltime
 
-from ctc import evm
-from ctc import spec
-
 
 class DEX:
     """Standardized interface for DEXes
 
     - All methods should be classmethods or staticmethods
     - The class should never be instantiated
     - Users do not need to use DEX classes directly
@@ -48,60 +48,59 @@
         cls,
         *,
         factory: spec.Address,
         start_block: spec.BlockNumberReference | None = None,
         end_block: spec.BlockNumberReference | None = None,
         start_time: tooltime.Timestamp | None = None,
         end_time: tooltime.Timestamp | None = None,
-        network: spec.NetworkReference | None = None,
-        provider: spec.ProviderReference | None = None,
+        context: spec.Context = None,
     ) -> typing.Sequence[spec.DexPool]:
         raise NotImplementedError(cls.__name__ + '.async_get_new_pools')
 
     @classmethod
     async def _async_get_pool_assets_from_node(
         cls,
         pool: spec.Address,
         *,
-        network: spec.NetworkReference | None = None,
-        provider: spec.ProviderReference | None = None,
         block: spec.BlockNumberReference | None = None,
+        context: spec.Context = None,
     ) -> typing.Sequence[spec.Address]:
         raise NotImplementedError(cls.__name__ + '.async_get_pool_assets')
 
     @classmethod
     async def _async_get_pool_raw_trades(
         cls,
         pool: spec.Address,
         *,
         start_block: spec.BlockNumberReference | None = None,
         end_block: spec.BlockNumberReference | None = None,
         start_time: tooltime.Timestamp | None = None,
         end_time: tooltime.Timestamp | None = None,
         include_timestamps: bool = False,
-        network: spec.NetworkReference | None = None,
-        provider: spec.ProviderReference | None = None,
         verbose: bool = False,
+        context: spec.Context = None,
     ) -> spec.RawDexTrades:
         raise NotImplementedError(cls.__name__ + '.async_get_pool_trades')
 
     #
     # # dex metadata
     #
 
     @classmethod
     def get_dex_name(cls) -> str:
         return cls.__name__.rstrip('DEX')
 
     @classmethod
     def get_pool_factories(
         cls,
-        network: spec.NetworkReference,
+        context: spec.Context = None,
     ) -> typing.Sequence[spec.Address]:
-        chain_id = evm.get_network_chain_id(network)
+        from ctc import config
+
+        chain_id = config.get_context_chain_id(context)
         if cls._pool_factories is None:
             raise NotImplementedError(cls.__name__ + '._pool_factories')
         if chain_id not in cls._pool_factories:
             raise Exception('unknown network: ' + str(chain_id))
         return cls._pool_factories[chain_id]
 
     #
@@ -116,24 +115,21 @@
         all_dex_factories: bool = False,
         assets: typing.Sequence[spec.Address] | None = None,
         start_block: spec.BlockNumberReference | None = None,
         end_block: spec.BlockNumberReference | None = None,
         start_time: tooltime.Timestamp | None = None,
         end_time: tooltime.Timestamp | None = None,
         update: bool = False,
-        network: spec.NetworkReference | None = None,
-        provider: spec.ProviderReference | None = None,
+        context: spec.Context = None,
     ) -> typing.Sequence[spec.DexPool]:
         """return pools"""
 
-        network, provider = evm.get_network_and_provider(network, provider)
-
         factories: typing.Sequence[spec.Address] | None = None
         if all_dex_factories:
-            pool_factories = cls.get_pool_factories(network=network)
+            pool_factories = cls.get_pool_factories(context=context)
             if len(pool_factories) == 1:
                 factory = pool_factories[0]
                 factories = None
             elif len(pool_factories) > 1:
                 factory = None
                 factories = pool_factories
             else:
@@ -145,43 +141,42 @@
 
         start_block, end_block = await evm.async_resolve_block_range(
             start_block=start_block,
             end_block=end_block,
             start_time=start_time,
             end_time=end_time,
             allow_none=True,
-            provider=provider,
+            context=context,
         )
 
         if start_block is not None:
             start_block = await evm.async_block_number_to_int(
                 start_block,
-                provider=provider,
+                context=context,
             )
         if end_block is not None:
             end_block = await evm.async_block_number_to_int(
                 end_block,
-                provider=provider,
+                context=context,
             )
 
         pools = await cls.async_get_stored_dex_pools(
             factory=factory,
             factories=factories,
             assets=assets,
             start_block=start_block,
             end_block=end_block,
-            network=network,
+            context=context,
         )
 
         if update:
             new_pools = await cls.async_update_pools(
                 factory=factory,
                 factories=factories,
-                network=network,
-                provider=provider,
+                context=context,
             )
 
             # filter pools according to function inputs
             new_pools = _filter_pools(
                 pools=new_pools,
                 assets=assets,
                 start_block=start_block,
@@ -194,30 +189,30 @@
 
     @classmethod
     async def async_get_stored_dex_pools(
         cls,
         *,
         factory: spec.Address | None = None,
         factories: typing.Sequence[spec.Address] | None = None,
-        network: spec.NetworkReference,
         assets: typing.Sequence[spec.Address] | None = None,
         start_block: spec.BlockNumberReference | None = None,
         end_block: spec.BlockNumberReference | None = None,
+        context: spec.Context = None,
     ) -> typing.Sequence[spec.DexPool]:
         """return pools"""
 
         from ctc import db
 
         pools = await db.async_query_dex_pools(
             factory=factory,
             factories=factories,
             assets=assets,
-            network=network,
             start_block=start_block,
             end_block=end_block,
+            context=context,
         )
         if pools is None:
             pools = []
 
         return pools
 
     #
@@ -226,79 +221,76 @@
 
     @classmethod
     async def async_update_pools(
         cls,
         *,
         factory: spec.Address | None = None,
         factories: typing.Sequence[spec.Address] | None = None,
-        network: spec.NetworkReference | None = None,
-        provider: spec.ProviderReference = None,
+        context: spec.Context = None,
     ) -> typing.Sequence[spec.DexPool]:
         """update latest pools of factory"""
 
         from ctc import db
 
-        network, provider = evm.get_network_and_provider(network, provider)
-
         # if not factory or factories specified, use all
         if factories is None and factory is None:
-            factories = cls.get_pool_factories(network=network)
+            factories = cls.get_pool_factories(context=context)
 
         # if using multiple factories, call function separately for each
         if factories is not None:
             coroutines = []
             for factory in factories:
                 coroutine = cls.async_update_pools(
                     factory=factory,
-                    network=network,
-                    provider=provider,
+                    context=context,
                 )
                 coroutines.append(coroutine)
             results = await asyncio.gather(*coroutines)
             return [dex_pool for result in results for dex_pool in result]
 
         if factory is None:
             raise Exception('factory should be specified')
 
         # get new pools
         last_scanned_block = (
             await db.async_query_dex_pool_factory_last_scanned_block(
                 factory=factory,
-                network=network,
+                context=context,
             )
         )
         if last_scanned_block is None:
             from ctc.toolbox import search_utils
 
             try:
                 creation_block = await evm.async_get_contract_creation_block(
-                    factory
+                    factory,
+                    context=context,
                 )
                 if creation_block is None:
                     raise Exception(
                         'could not determine factory creation block'
                     )
                 last_scanned_block = creation_block - 1
             except search_utils.NoMatchFound:
                 last_scanned_block = -1
 
-        latest_block = await evm.async_get_latest_block_number()
+        latest_block = await evm.async_get_latest_block_number(context=context)
 
         if last_scanned_block + 1 <= latest_block:
-
             new_pools = await cls.async_get_new_pools(
                 factory=factory,
                 start_block=last_scanned_block + 1,
                 end_block=latest_block,
+                context=context,
             )
             await db.async_intake_dex_pools(
                 factory=factory,
                 dex_pools=new_pools,
-                network=network,
                 last_scanned_block=latest_block,
+                context=context,
             )
 
         else:
             new_pools = []
 
         return new_pools
 
@@ -307,143 +299,135 @@
     #
 
     @classmethod
     async def async_get_pool_assets(
         cls,
         pool: spec.Address,
         *,
-        network: spec.NetworkReference | None = None,
-        provider: spec.ProviderReference | None = None,
         block: spec.BlockNumberReference | None = None,
-        use_db: bool = True,
+        context: spec.Context = None,
     ) -> typing.Sequence[spec.Address]:
-
-        use_db = False
-        if use_db:
-            raise NotImplementedError()
-
-        else:
-            return await cls._async_get_pool_assets_from_node(
-                pool=pool,
-                network=network,
-                provider=provider,
-                block=block,
-            )
+        return await cls._async_get_pool_assets_from_node(
+            pool=pool,
+            block=block,
+            context=context,
+        )
 
     @classmethod
     async def async_get_pool_asset_symbols(
         cls,
         pool: spec.Address,
         *,
-        provider: spec.ProviderReference = None,
-        network: spec.NetworkReference | None = None,
+        context: spec.Context = None,
     ) -> typing.Sequence[str]:
-        network, provider = evm.get_network_and_provider(network, provider)
-        assets = await cls.async_get_pool_assets(
-            pool=pool,
-            network=network,
-            provider=provider,
-        )
-        return await evm.async_get_erc20s_symbols(assets, provider=provider)
+        assets = await cls.async_get_pool_assets(pool=pool, context=context)
+        return await evm.async_get_erc20s_symbols(assets, context=context)
 
     #
     # # single pool balances
     #
 
     @classmethod
     async def async_get_pool_balance(
         cls,
         pool: spec.Address,
         asset: spec.Address,
         *,
         factory: spec.Address | None = None,
         normalize: bool = True,
         block: spec.BlockNumberReference | None = None,
-        network: spec.NetworkReference | None = None,
-        provider: spec.ProviderReference | None = None,
+        context: spec.Context = None,
     ) -> int | float:
-
-        network, provider = evm.get_network_and_provider(network, provider)
-
-        return await evm.async_get_erc20_balance(
+        result = await evm.async_get_erc20_balance(
             wallet=pool,
             token=asset,
             normalize=normalize,
             block=block,
+            context=context,
         )
+        if result is None:
+            raise Exception('invalid result for pool balance')
+        return result
 
     @classmethod
     async def async_get_pool_balances(
         cls,
         pool: spec.Address,
         *,
         factory: spec.Address | None = None,
         normalize: bool = True,
         block: spec.BlockNumberReference | None = None,
-        network: spec.NetworkReference | None = None,
-        provider: spec.ProviderReference | None = None,
+        context: spec.Context = None,
     ) -> typing.Mapping[spec.Address, int | float]:
-
-        network, provider = evm.get_network_and_provider(network, provider)
-
-        pool_tokens = await cls.async_get_pool_assets(pool=pool)
-        balances = await evm.async_get_erc20s_balances(
-            wallet=pool,
-            tokens=pool_tokens,
-            normalize=normalize,
-            block=block,
-            provider=provider,
+        pool_tokens = await cls.async_get_pool_assets(
+            pool=pool, context=context
         )
-        return dict(zip(pool_tokens, balances))
+
+        if cls.async_get_pool_balance == DEX.async_get_pool_balance:
+            balances = await evm.async_get_erc20s_balances(
+                wallet=pool,
+                tokens=pool_tokens,
+                normalize=normalize,
+                block=block,
+                context=context,
+            )
+            return dict(zip(pool_tokens, balances))
+        else:
+            coroutines = []
+            for token in pool_tokens:
+                coroutine = cls.async_get_pool_balance(
+                    pool=pool,
+                    asset=token,
+                    normalize=normalize,
+                    block=block,
+                    context=context,
+                )
+                coroutines.append(coroutine)
+            results = await asyncio.gather(*coroutines)
+            return dict(zip(pool_tokens, results))
 
     @classmethod
     async def async_get_pool_balance_by_block(
         cls,
         pool: spec.Address,
         asset: spec.Address,
         *,
         blocks: typing.Sequence[spec.BlockNumberReference],
         factory: spec.Address | None = None,
         normalize: bool = True,
-        network: spec.NetworkReference | None = None,
-        provider: spec.ProviderReference | None = None,
+        context: spec.Context = None,
     ) -> typing.Sequence[int | float]:
-
-        network, provider = evm.get_network_and_provider(network, provider)
-
         return await evm.async_get_erc20_balance_by_block(
             wallet=pool,
             token=asset,
             normalize=normalize,
             blocks=blocks,
+            context=context,
         )
 
     @classmethod
     async def async_get_pool_balances_by_block(
         cls,
         pool: spec.Address,
         *,
         blocks: typing.Sequence[spec.BlockNumberReference],
         factory: spec.Address | None = None,
         normalize: bool = True,
-        network: spec.NetworkReference | None = None,
-        provider: spec.ProviderReference | None = None,
+        context: spec.Context = None,
     ) -> typing.Mapping[str, typing.Sequence[int | float]]:
-
         if len(blocks) == 0:
             raise NotImplementedError('must specify blocks')
 
         coroutines = [
             cls.async_get_pool_balances(
                 pool=pool,
                 factory=factory,
                 normalize=normalize,
                 block=block,
-                network=network,
-                provider=provider,
+                context=context,
             )
             for block in blocks
         ]
         results = await asyncio.gather(*coroutines)
         balances_by_block: typing.MutableMapping[
             str, typing.MutableSequence[int | float]
         ] = {}
@@ -466,118 +450,111 @@
         start_block: spec.BlockNumberReference | None = None,
         end_block: spec.BlockNumberReference | None = None,
         start_time: tooltime.Timestamp | None = None,
         end_time: tooltime.Timestamp | None = None,
         label: Literal['index', 'symbol', 'address'] = 'index',
         include_timestamps: bool = False,
         normalize: bool = True,
-        network: spec.NetworkReference | None = None,
-        provider: spec.ProviderReference | None = None,
         verbose: bool = False,
         remove_missing_fields: bool = True,
         include_prices: bool = False,
         include_volumes: bool = False,
+        context: spec.Context = None,
     ) -> spec.DataFrame:
-
-        import pandas as pd
-
-        network, provider = evm.get_network_and_provider(network, provider)
+        import polars as pl
 
         # queue relevant label data
         if label == 'symbol':
             symbols_coroutine = cls.async_get_pool_asset_symbols(
                 pool=pool,
-                provider=provider,
-                network=network,
+                context=context,
             )
             symbols_task = asyncio.create_task(symbols_coroutine)
         if normalize or label == 'address':
             assets_coroutine = cls.async_get_pool_assets(
                 pool=pool,
-                provider=provider,
-                network=network,
+                context=context,
             )
             assets_task = asyncio.create_task(assets_coroutine)
 
         output = await cls._async_get_pool_raw_trades(
             pool=pool,
             start_block=start_block,
             end_block=end_block,
             start_time=start_time,
             end_time=end_time,
             include_timestamps=include_timestamps,
-            network=network,
-            provider=provider,
             verbose=verbose,
+            context=context,
         )
 
         if remove_missing_fields:
             if 'timestamp' in output and output['timestamp'] is None:
                 del output['timestamp']
             if 'recipient' in output and output['recipient'] is None:
                 del output['recipient']
 
         if normalize or label == 'address':
             assets = await assets_task
 
         # normalize
         if normalize:
-
             # test for metapools
             if max(output['sold_id']) >= len(assets) or max(
                 output['bought_id']
             ) >= len(assets):
                 raise NotImplementedError(
                     'normalize not implemented for metapools'
                 )
 
             decimals = await evm.async_get_erc20s_decimals(
-                assets, provider=provider
+                assets,
+                context=context,
             )
 
-            sold_decimals = output['sold_id'].map(lambda i: decimals[i])
-            bought_decimals = output['bought_id'].map(lambda i: decimals[i])
-            output['sold_amount'] /= 10**sold_decimals  # type: ignore
-            output['bought_amount'] /= 10**bought_decimals  # type: ignore
+            sold_decimals = output['sold_id'].apply(lambda i: decimals[i])
+            bought_decimals = output['bought_id'].apply(lambda i: decimals[i])
+            output['sold_amount'] /= 10**sold_decimals
+            output['bought_amount'] /= 10**bought_decimals
 
         # replace labels
         if label in ['symbol', 'address']:
             if label == 'symbol':
                 new_ids = await symbols_task
             elif label == 'address':
                 new_ids = assets
             else:
                 raise Exception('unknown label format: ' + str(label))
 
-            output['bought_id'] = output['bought_id'].map(lambda i: new_ids[i])
-            output['sold_id'] = output['sold_id'].map(lambda i: new_ids[i])
+            output['bought_id'] = output['bought_id'].apply(
+                lambda i: new_ids[i]
+            )
+            output['sold_id'] = output['sold_id'].apply(lambda i: new_ids[i])
 
-        df = pd.DataFrame(output)
+        df = pl.DataFrame(output)
 
         if include_prices:
             prices = cls.compute_trade_prices(df, normalized=normalize)
             for key, value in prices.items():
-                df[key] = value
+                df = df.with_columns(pl.Series(key, value))
         if include_volumes:
             volumes = cls.compute_trade_volumes(df)
             for key, value in volumes.items():
-                df[key] = value
+                df = df.with_columns(pl.Series(key, value))
 
         return df
 
     @classmethod
     def compute_trade_volumes(
         cls, df: spec.DataFrame
     ) -> typing.Mapping[str, spec.Series]:
-
         df['sold_amount']
 
         all_ids = sorted(
-            set(df['sold_id'].value_counts().index)
-            | set(df['bought_id'].value_counts().index)
+            set(df['sold_id'].unique()) | set(df['bought_id'].unique())
         )
 
         volumes = {}
         for asset_id in all_ids:
             volumes['volume__' + str(asset_id)] = (
                 df['sold_id'] == asset_id
             ) * df['sold_amount'] + (df['bought_id'] == asset_id) * df[
@@ -588,60 +565,68 @@
 
     @classmethod
     def compute_trade_prices(
         cls,
         df: spec.DataFrame,
         normalized: bool,
     ) -> typing.Mapping[str, spec.Series]:
+        import polars as pl
 
         if not normalized:
             raise Exception('including prices requires normalize=True')
 
         all_ids = sorted(
-            set(df['sold_id'].value_counts().index)
-            | set(df['bought_id'].value_counts().index)
+            set(df['sold_id'].unique()) | set(df['bought_id'].unique())
         )
-        prices: typing.Mapping[str, spec.Series] = {}
+        prices: typing.MutableMapping[str, spec.Series] = {}
 
         # pre-compute quantities
-        sold_amount = df['sold_amount'].map(float)
-        bought_amount = df['bought_amount'].map(float)
+        sold_amount = df['sold_amount'].apply(float)
+        bought_amount = df['bought_amount'].apply(float)
         sold_per_bought = sold_amount / bought_amount
         bought_per_sold = bought_amount / sold_amount
         sold_masks = {}
         bought_masks = {}
         for asset_id in all_ids:
             sold_masks[asset_id] = df['sold_id'] == asset_id
             bought_masks[asset_id] = df['bought_id'] == asset_id
 
         # compute combinations
         for lhs_id in all_ids:
             for rhs_id in all_ids:
-
                 if lhs_id == rhs_id:
                     continue
 
                 key = 'price__' + str(lhs_id) + '__per__' + str(rhs_id)
 
                 sold_lhs_mask = sold_masks[lhs_id]
                 sold_rhs_mask = sold_masks[rhs_id]
                 bought_lhs_mask = bought_masks[lhs_id]
                 bought_rhs_mask = bought_masks[rhs_id]
 
-                df[key] = (
-                    sold_lhs_mask * bought_rhs_mask * sold_per_bought
-                    + bought_lhs_mask * sold_rhs_mask * bought_per_sold
+                values = (
+                    sold_lhs_mask.cast(int)
+                    * bought_rhs_mask.cast(int)
+                    * sold_per_bought
+                    + bought_lhs_mask.cast(int)
+                    * sold_rhs_mask.cast(int)
+                    * bought_per_sold
+                )
+                df = df.with_columns(
+                    pl.Series(key, values)
                 )
                 if len(all_ids) > 2:
                     combined_mask = (
                         sold_lhs_mask * bought_rhs_mask
                         + bought_lhs_mask * sold_rhs_mask
                     )
                     df[key][~combined_mask] = float('nan')
 
+                prices[key] = values
+
         return prices
 
     # should combine adds and removes into single function?
     # @classmethod
     # async def async_get_pool_liquidity_adds(
     #     cls,
     #     pool: spec.Address,
@@ -681,20 +666,18 @@
 def _filter_pools(
     *,
     pools: typing.Sequence[spec.DexPool],
     assets: typing.Sequence[str] | None = None,
     start_block: int | None = None,
     end_block: int | None = None,
 ) -> typing.Sequence[spec.DexPool]:
-
     filtered = []
 
     # filter the new pools according to input arguments
     for pool in pools:
-
         # check asset filter
         include = True
         if assets is not None:
             keys = ['asset0', 'asset1', 'asset2', 'asset3']
             for asset in assets:
                 asset = asset.lower()
                 include = any(pool[key] == asset for key in keys)  # type: ignore
@@ -713,7 +696,8 @@
             pool['creation_block'] is None or pool['creation_block'] > end_block
         ):
             continue
 
         filtered.append(pool)
 
     return filtered
+
```

### Comparing `checkthechain-0.3.0/src/ctc/toolbox/defi_utils/dex_utils/dexes/dex_class_utils.py` & `checkthechain-0.3.4/src/ctc/defi/dex_utils/dexes/dex_class_utils.py`

 * *Files 26% similar despite different names*

```diff
@@ -22,65 +22,60 @@
     return {dex_name: get_dex_class(dex_name) for dex_name in dex_names}
 
 
 def get_dex_class(
     dex: typing.Type[dex_class.DEX] | str | None = None,
     *,
     factory: spec.Address | None = None,
-    network: spec.NetworkReference | None = None,
+    context: spec.Context = None,
 ) -> typing.Type[dex_class.DEX]:
     """return DEX object corresponding to dex name or dex factory"""
 
     if dex is not None:
         if isinstance(dex, str):
             return _get_dex_class_from_name(dex)
         elif issubclass(dex, dex_class.DEX):
             return dex
         else:
             raise Exception('unknown dex type: ' + str(type(dex)))
     elif factory is not None:
-        return _get_dex_class_from_factory(factory=factory, network=network)
+        return _get_dex_class_from_factory(factory=factory, context=context)
     else:
         raise Exception('not enough inputs specified')
 
 
 async def async_get_dex_class(
     dex: typing.Type[dex_class.DEX] | str | None = None,
     *,
     factory: spec.Address | None = None,
     pool: spec.Address | None = None,
-    network: spec.NetworkReference | None = None,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
 ) -> typing.Type[dex_class.DEX]:
     """get DEX class matching given inputs"""
 
-    network, provider = evm.get_network_and_provider(network, provider)
     if factory is not None or dex is not None:
         return get_dex_class(
             dex=dex,
             factory=factory,
-            network=network,
+            context=context,
         )
     else:
         if pool is None:
             raise Exception(
                 'must specify dex, factory or pool to get dex class'
             )
-        return await _async_get_dex_class_of_pool(pool, network=network)
+        return await _async_get_dex_class_of_pool(pool, context=context)
 
 
 def _get_dex_class_from_factory(
     factory: spec.Address,
-    network: spec.NetworkReference | None,
+    context: spec.Context = None,
 ) -> typing.Type[dex_class.DEX]:
     """return DEX class using given DEX factory"""
-
-    if network is None:
-        raise Exception('must specify network of factory')
-    dex_name = dex_directory.get_dex_name_of_factory(factory, network=network)
+    dex_name = dex_directory.get_dex_name_of_factory(factory, context=context)
     return _get_dex_class_from_name(dex_name)
 
 
 def _get_dex_class_from_name(dex: str) -> typing.Type[dex_class.DEX]:
     """return DEX class using given DEX name"""
 
     dex = dex.lower().replace(' ', '').replace('-', '').replace('_', '')
@@ -107,17 +102,18 @@
         return uniswap_v3_dex.UniswapV3DEX
     else:
         raise Exception('unknown DEX: ' + str(dex))
 
 
 async def _async_get_dex_class_of_pool(
     pool: spec.Address,
-    network: spec.NetworkReference | None,
+    context: spec.Context = None,
 ) -> typing.Type[dex_class.DEX]:
     """get DEX class for given pool"""
 
     from ctc import db
 
-    dex_pool = await db.async_query_dex_pool(address=pool, network=network)
+    dex_pool = await db.async_query_dex_pool(address=pool, context=context)
     if dex_pool is None:
         raise Exception('could not determine dex class of pool')
-    return _get_dex_class_from_factory(dex_pool['factory'], network=network)
+    return _get_dex_class_from_factory(dex_pool['factory'], context=context)
+
```

### Comparing `checkthechain-0.3.0/src/ctc/toolbox/defi_utils/dex_utils/dexes/dex_directory.py` & `checkthechain-0.3.4/src/ctc/defi/dex_utils/dexes/dex_directory.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,20 +1,26 @@
 from __future__ import annotations
 
 import typing
 
+from ctc import config
 from ctc import spec
 
 
 def get_dex_names_of_factories(
-    network: spec.NetworkReference,
+    *,
+    network: spec.NetworkReference | None = None,
+    context: spec.Context = None,
 ) -> typing.Mapping[spec.Address, str]:
     """get mapping of factory_address -> dex_name"""
 
-    if network in (1, 'mainnet'):
+    if network is None:
+        network = config.get_context_chain_id(context)
+
+    if network in (1, 'ethereum'):
         return {
             '0x5c69bee701ef814a2b6a3edd4b1652cb9cc5aa6f': 'Uniswap V2',
             '0x1f98431c8ad98523631ae4a59f267346ea31f984': 'Uniswap V3',
             '0xba12222222228d8ba445958a75a0704d566bf2c8': 'Balancer',
             '0xb9fc157394af804a3578134a6585c0dc9cc990d4': 'Curve',
             '0x0959158b6040d32d04c301a72cbfd6b39e21c9ae': 'Curve',
             '0xf18056bbd320e96a48e3fbf8bc061322531aac99': 'Curve',
@@ -27,13 +33,15 @@
         raise Exception(
             'dex pool factory map not available for network: ' + str(network)
         )
 
 
 def get_dex_name_of_factory(
     factory: spec.Address,
-    network: spec.NetworkReference,
+    *,
+    context: spec.Context = None,
 ) -> str:
     """get dex_name of factory address"""
 
-    names_of_factories = get_dex_names_of_factories(network=network)
+    names_of_factories = get_dex_names_of_factories(context=context)
     return names_of_factories[factory]
+
```

### Comparing `checkthechain-0.3.0/src/ctc/toolbox/defi_utils/dex_utils/dexes/dex_functions/dex_metadata_functions.py` & `checkthechain-0.3.4/src/ctc/defi/dex_utils/dexes/dex_functions/dex_metadata_functions.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,35 +1,36 @@
 from __future__ import annotations
 
 import typing
 
-from ctc import evm
 from ctc import spec
 
 from .. import dex_class_utils
 from .. import dex_directory
 
 
 async def async_get_pool_assets(
     pool: spec.Address,
-    network: spec.NetworkReference | None = None,
     *,
-    provider: spec.ProviderReference | None = None,
-    use_db: bool = True,
+    context: spec.Context = None,
     factory: spec.Address | None = None,
 ) -> typing.Sequence[spec.Address]:
     """get assets of a given DEX pool"""
 
-    network, provider = evm.get_network_and_provider(network, provider)
+    from ctc import config
+
+    read_cache, write_cache = config.get_context_cache_read_write(
+        schema_name='dex_pools', context=context
+    )
 
     # try obtaining pool from db
-    if use_db:
+    if read_cache:
         from ctc import db
 
-        pool_data = await db.async_query_dex_pool(address=pool, network=network)
+        pool_data = await db.async_query_dex_pool(address=pool, context=context)
         if pool_data is not None:
             assets: typing.MutableSequence[spec.Address] = []
             asset0 = pool_data['asset0']
             if asset0 is not None:
                 assets.append(asset0)
             asset1 = pool_data['asset1']
             if asset1 is not None:
@@ -43,11 +44,12 @@
             return assets
 
     # if not in db, acquire using RPC
     if factory is None:
         raise Exception('must specify factory if pool not in db')
     dex_name = dex_directory.get_dex_name_of_factory(
         factory=factory,
-        network=network,
+        context=context,
     )
     dex = dex_class_utils.get_dex_class(dex_name)
-    return await dex.async_get_pool_assets(pool=pool, provider=provider)
+    return await dex.async_get_pool_assets(pool=pool, context=context)
+
```

### Comparing `checkthechain-0.3.0/src/ctc/toolbox/defi_utils/dex_utils/dexes/dex_functions/dex_pools_functions.py` & `checkthechain-0.3.4/src/ctc/defi/dex_utils/dexes/dex_functions/dex_pools_functions.py`

 * *Files 12% similar despite different names*

```diff
@@ -11,70 +11,65 @@
     import tooltime
 
 
 async def async_get_pools(
     *,
     dex: typing.Type[dex_class.DEX] | str | None = None,
     factory: spec.Address | None = None,
-    network: spec.NetworkReference | None = None,
     assets: typing.Sequence[spec.Address] | None = None,
     start_block: spec.BlockNumberReference | None = None,
     end_block: spec.BlockNumberReference | None = None,
     start_time: tooltime.Timestamp | None = None,
     end_time: tooltime.Timestamp | None = None,
     update: bool = False,
-    provider: spec.ProviderReference | None = None,
+    context: spec.Context = None,
 ) -> typing.Sequence[spec.DexPool]:
     """get DEX pools matching given inputs"""
 
     # get dex
     all_dex_factories = dex is not None and factory is None
     if factory is None and dex is None:
         dex = dex_class.DEX
 
         if update:
-            await async_update_all_dexes(
-                network=network,
-                provider=provider,
-            )
+            await async_update_all_dexes(context=context)
             update = False
 
     else:
         dex = dex_class_utils.get_dex_class(
             dex=dex,
             factory=factory,
-            network=network,
+            context=context,
         )
 
     return await dex.async_get_pools(
         factory=factory,
         all_dex_factories=all_dex_factories,
         assets=assets,
         start_block=start_block,
         end_block=end_block,
         start_time=start_time,
         end_time=end_time,
         update=update,
-        provider=provider,
+        context=context,
     )
 
 
 async def async_update_all_dexes(
-    network: spec.NetworkReference | None = None,
-    provider: spec.ProviderReference | None = None,
+    context: spec.Context = None,
 ) -> typing.Mapping[str, typing.Mapping[str, typing.Any]]:
     """update local DEX database with latest on-chain entries"""
 
     import asyncio
 
     all_dexes = dex_class_utils.get_all_dex_classes()
 
     coroutines = []
     for dex in all_dexes.values():
-        coroutine = dex.async_update_pools(network=network, provider=provider)
+        coroutine = dex.async_update_pools(context=context)
         coroutines.append(coroutine)
 
     results = await asyncio.gather(*coroutines)
 
     updates = {}
     for dex_name, result in zip(all_dexes.keys(), results):
         updates[dex_name] = {'new_pools': result}
```

### Comparing `checkthechain-0.3.0/src/ctc/toolbox/defi_utils/dex_utils/dexes/dex_functions/dex_trade_functions.py` & `checkthechain-0.3.4/src/ctc/defi/dex_utils/dexes/dex_functions/dex_trade_functions.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,56 +1,54 @@
 from __future__ import annotations
 
 import typing
-if typing.TYPE_CHECKING:
-    from typing_extensions import Literal
-
-    import tooltime
 
 from ctc import spec
 from .. import dex_class
 from .. import dex_class_utils
 
+if typing.TYPE_CHECKING:
+    from typing_extensions import Literal
+
+    import tooltime
+
 
 async def async_get_pool_trades(
     pool: spec.Address,
     *,
     dex: typing.Type[dex_class.DEX] | str | None = None,
     factory: spec.Address | None = None,
     normalize: bool = False,
     start_block: spec.BlockNumberReference | None = None,
     end_block: spec.BlockNumberReference | None = None,
     start_time: tooltime.Timestamp | None = None,
     end_time: tooltime.Timestamp | None = None,
-    network: spec.NetworkReference | None = None,
     label: Literal['index', 'symbol', 'address'] = 'index',
-    provider: spec.ProviderReference = None,
     include_timestamps: bool = False,
     remove_missing_fields: bool = True,
     include_prices: bool = False,
     include_volumes: bool = False,
+    context: spec.Context = None,
 ) -> spec.DataFrame:
     """get trades of a DEX pool"""
 
     dex = await dex_class_utils.async_get_dex_class(
         dex=dex,
         factory=factory,
         pool=pool,
-        network=network,
-        provider=provider,
+        context=context,
     )
 
     return await dex.async_get_pool_trades(
         pool=pool,
         normalize=normalize,
         start_block=start_block,
         end_block=end_block,
         start_time=start_time,
         end_time=end_time,
         label=label,
-        network=network,
-        provider=provider,
+        context=context,
         include_timestamps=include_timestamps,
         remove_missing_fields=remove_missing_fields,
         include_prices=include_prices,
         include_volumes=include_volumes,
     )
```

### Comparing `checkthechain-0.3.0/src/ctc/toolbox/defi_utils/dex_utils/dexes/dex_implementations/balancer_dex.py` & `checkthechain-0.3.4/src/ctc/rpc/rpc_executors_sync/rpc_state_executors_sync.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,205 +1,185 @@
 from __future__ import annotations
 
 import typing
 
 from ctc import evm
 from ctc import spec
-from ctc.protocols import balancer_utils
-from .. import dex_class
 
-if typing.TYPE_CHECKING:
-    import tooltime
-
-
-class BalancerDEX(dex_class.DEX):
-    """Balancer DEX"""
-
-    _pool_factories = {1: ['0xba12222222228d8ba445958a75a0704d566bf2c8']}
-
-    @classmethod
-    async def async_get_new_pools(
-        cls,
-        *,
-        factory: spec.Address,
-        start_block: spec.BlockNumberReference | None = None,
-        end_block: spec.BlockNumberReference | None = None,
-        start_time: tooltime.Timestamp | None = None,
-        end_time: tooltime.Timestamp | None = None,
-        network: spec.NetworkReference | None = None,
-        provider: spec.ProviderReference | None = None,
-    ) -> typing.Sequence[spec.DexPool]:
-
-        network, provider = evm.get_network_and_provider(network, provider)
-
-        balancer_pools = await evm.async_get_events(
-            factory,
-            event_abi=balancer_utils.vault_event_abis['PoolRegistered'],
-            verbose=False,
-            start_block=start_block,
-            end_block=end_block,
-            start_time=start_time,
-            end_time=end_time,
-            keep_multiindex=False,
-        )
-        token_registrations = (
-            await balancer_utils.async_get_token_registrations(
-                factory=factory,
-                start_block=start_block,
-                end_block=end_block,
-                provider=provider,
-            )
-        )
-
-        dex_pools = []
-        for index, row in balancer_pools.iterrows():
-
-            block = typing.cast(int, index)
-
-            assets: typing.Sequence[str | None] = token_registrations.get(
-                row['arg__poolId'], []
+from .. import rpc_constructors
+from .. import rpc_digestors
+from .. import rpc_request
+
+
+def sync_eth_call(
+    to_address: spec.Address,
+    *,
+    from_address: spec.BinaryData | None = None,
+    gas: spec.BinaryData | None = None,
+    gas_price: spec.BinaryData | None = None,
+    value_sent: spec.BinaryData | None = None,
+    block_number: spec.BlockNumberReference | None = None,
+    call_data: spec.BinaryData | None = None,
+    function_parameters: typing.Sequence[typing.Any]
+    | typing.Mapping[str, typing.Any]
+    | None = None,
+    context: spec.Context = None,
+    decode_response: bool = True,
+    delist_single_outputs: bool = True,
+    package_named_outputs: bool = False,
+    fill_empty: bool = False,
+    empty_token: typing.Any = None,
+    convert_reverts_to: typing.Any = None,
+    convert_reverts_to_none: bool = False,
+    function_abi: spec.FunctionABI | None = None,
+    function_name: typing.Optional[str] = None,
+    contract_abi: typing.Optional[spec.ContractABI] = None,
+    n_parameters: typing.Optional[int] = None,
+    parameter_types: typing.Optional[list[spec.ABIDatumType]] = None,
+    function_selector: typing.Optional[spec.FunctionSelector] = None,
+) -> spec.RpcSingularResponse:
+    if function_abi is None:
+        if call_data is None or decode_response:
+            function_abi = evm.sync_get_function_abi(
+                contract_address=to_address,
+                contract_abi=contract_abi,
+                function_name=function_name,
+                n_parameters=n_parameters,
+                parameter_types=parameter_types,
+                function_selector=function_selector,
+                context=context,
             )
-            if len(assets) < 4:
-                assets = list(assets) + [None] * (4 - len(assets))
-            if len(assets) > 4:
-                additional_data = {'additional_assets': assets[4:]}
-                assets = assets[:4]
-            else:
-                additional_data = {}
-            asset0 = assets[0]
-            asset1 = assets[1]
-            asset2 = assets[2]
-            asset3 = assets[3]
-
-            dex_pool: spec.DexPool = {
-                'address': row['arg__poolAddress'],
-                'factory': factory,
-                'asset0': asset0,
-                'asset1': asset1,
-                'asset2': asset2,
-                'asset3': asset3,
-                'creation_block': block,
-                'fee': None,
-                'additional_data': additional_data,
-            }
-            dex_pools.append(dex_pool)
-
-        return dex_pools
-
-    @classmethod
-    async def _async_get_pool_assets_from_node(
-        cls,
-        pool: spec.Address,
-        *,
-        network: spec.NetworkReference | None = None,
-        provider: spec.ProviderReference | None = None,
-        block: spec.BlockNumberReference | None = None,
-    ) -> typing.Sequence[spec.Address]:
-
-        network, provider = evm.get_network_and_provider(network, provider)
 
-        result = await balancer_utils.async_get_pool_balances(
-            pool_address=pool, provider=provider, block=block
-        )
-
-        return list(result.keys())
+    # construct request
+    request = rpc_constructors.construct_eth_call(
+        to_address=to_address,
+        from_address=from_address,
+        gas=gas,
+        gas_price=gas_price,
+        value_sent=value_sent,
+        block_number=block_number,
+        call_data=call_data,
+        function_parameters=function_parameters,
+        function_abi=function_abi,
+    )
+
+    # make request
+    response = rpc_request.sync_send(
+        request,
+        context=context,
+        convert_reverts_to_none=convert_reverts_to_none,
+        convert_reverts_to=convert_reverts_to,
+    )
+
+    # digest response
+    return rpc_digestors.digest_eth_call(
+        response,
+        function_abi=function_abi,
+        decode_response=decode_response,
+        delist_single_outputs=delist_single_outputs,
+        package_named_outputs=package_named_outputs,
+        fill_empty=fill_empty,
+        empty_token=empty_token,
+    )
+
+
+def sync_eth_estimate_gas(
+    to_address: spec.Address,
+    *,
+    from_address: spec.BinaryData | None = None,
+    gas: spec.BinaryData | None = None,
+    gas_price: spec.BinaryData | None = None,
+    value_sent: spec.BinaryData | None = None,
+    call_data: spec.BinaryData | None = None,
+    function_parameters: typing.Sequence[typing.Any]
+    | typing.Mapping[str, typing.Any]
+    | None = None,
+    context: spec.Context = None,
+    decode_response: bool = True,
+    function_abi: spec.FunctionABI | None = None,
+    function_name: typing.Optional[str] = None,
+    contract_abi: typing.Optional[spec.ContractABI] = None,
+    n_parameters: typing.Optional[int] = None,
+    parameter_types: typing.Optional[list[spec.ABIDatumType]] = None,
+    function_selector: typing.Optional[spec.FunctionSelector] = None,
+) -> spec.RpcSingularResponse:
+    if function_abi is None:
+        function_abi = evm.sync_get_function_abi(
+            contract_address=to_address,
+            contract_abi=contract_abi,
+            function_name=function_name,
+            n_parameters=n_parameters,
+            parameter_types=parameter_types,
+            function_selector=function_selector,
+            context=context,
+        )
+
+    request = rpc_constructors.construct_eth_estimate_gas(
+        to_address=to_address,
+        from_address=from_address,
+        gas=gas,
+        gas_price=gas_price,
+        value_sent=value_sent,
+        call_data=call_data,
+        function_parameters=function_parameters,
+        function_abi=function_abi,
+    )
+    response = rpc_request.sync_send(request, context=context)
+    return rpc_digestors.digest_eth_estimate_gas(
+        response,
+        decode_response=decode_response,
+    )
+
+
+def sync_eth_get_balance(
+    address: spec.Address,
+    *,
+    block_number: spec.BlockNumberReference | None = None,
+    context: spec.Context = None,
+    decode_response: bool = True,
+) -> spec.RpcSingularResponse:
+    if block_number is None:
+        block_number = 'latest'
+    request = rpc_constructors.construct_eth_get_balance(
+        address=address,
+        block_number=block_number,
+    )
+    response = rpc_request.sync_send(request, context=context)
+    return rpc_digestors.digest_eth_get_balance(
+        response,
+        decode_response=decode_response,
+    )
+
+
+def sync_eth_get_storage_at(
+    address: spec.Address,
+    position: spec.BinaryData,
+    *,
+    block_number: spec.BlockNumberReference | None = None,
+    context: spec.Context = None,
+) -> spec.RpcSingularResponse:
+    if block_number is None:
+        block_number = 'latest'
+    request = rpc_constructors.construct_eth_get_storage_at(
+        address=address,
+        position=position,
+        block_number=block_number,
+    )
+    response = rpc_request.sync_send(request, context=context)
+    return rpc_digestors.digest_eth_get_storage_at(response)
+
+
+def sync_eth_get_code(
+    address: spec.Address,
+    *,
+    block_number: spec.BlockNumberReference | None = None,
+    context: spec.Context = None,
+) -> spec.RpcSingularResponse:
+    if block_number is None:
+        block_number = 'latest'
+    request = rpc_constructors.construct_eth_get_code(
+        address=address,
+        block_number=block_number,
+    )
+    response = rpc_request.sync_send(request, context=context)
+    return rpc_digestors.digest_eth_get_code(response)
 
-    @classmethod
-    async def _async_get_pool_raw_trades(
-        cls,
-        pool: spec.Address,
-        *,
-        start_block: spec.BlockNumberReference | None = None,
-        end_block: spec.BlockNumberReference | None = None,
-        start_time: tooltime.Timestamp | None = None,
-        end_time: tooltime.Timestamp | None = None,
-        include_timestamps: bool = False,
-        network: spec.NetworkReference | None = None,
-        provider: spec.ProviderReference | None = None,
-        verbose: bool = False,
-    ) -> spec.RawDexTrades:
-
-        network, provider = evm.get_network_and_provider(network, provider)
-
-        network = evm.get_network_chain_id(network)
-        vault = cls._pool_factories[network][0]
-        if start_block is None:
-            start_block = await evm.async_get_contract_creation_block(
-                pool,
-                provider=provider,
-            )
-
-        trades = await evm.async_get_events(
-            vault,
-            event_abi=balancer_utils.vault_event_abis['Swap'],
-            start_block=start_block,
-            end_block=end_block,
-            start_time=start_time,
-            end_time=end_time,
-            verbose=verbose,
-            keep_multiindex=False,
-        )
-
-        assets = await cls.async_get_pool_assets(pool)
-
-        # filter by pool
-        pool_id = await balancer_utils.async_get_pool_id(
-            pool_address=pool, provider=provider
-        )
-        mask = trades['arg__poolId'] == pool_id
-        trades = trades[mask]
-
-        import pandas as pd
-
-        output: spec.RawDexTrades = {
-            'transaction_hash': trades['transaction_hash'],
-            'recipient': None,
-            'sold_id': pd.Series(
-                [
-                    assets.index(address)
-                    for address in trades['arg__tokenIn'].values
-                ],
-                index=trades.index,
-            ),
-            'bought_id': pd.Series(
-                [
-                    assets.index(address)
-                    for address in trades['arg__tokenOut'].values
-                ],
-                index=trades.index,
-            ),
-            'sold_amount': trades['arg__amountIn'].map(int),
-            'bought_amount': trades['arg__amountOut'].map(int),
-        }
-
-        if include_timestamps:
-            output['timestamp'] = await evm.async_get_block_timestamps(
-                blocks=trades.index.values,
-                provider=provider,
-            )
-
-        return output
-
-    @classmethod
-    async def async_get_pool_balance(
-        cls,
-        pool: spec.Address,
-        asset: spec.Address,
-        *,
-        factory: spec.Address | None = None,
-        normalize: bool = True,
-        block: spec.BlockNumberReference | None = None,
-        network: spec.NetworkReference | None = None,
-        provider: spec.ProviderReference | None = None,
-    ) -> int | float:
-
-        from ctc.protocols import balancer_utils
-
-        network, provider = evm.get_network_and_provider(network, provider)
-
-        pool_balances = await balancer_utils.async_get_pool_balances(
-            pool_address=pool,
-            block=block,
-            normalize=normalize,
-            provider=provider,
-        )
-        return pool_balances[asset]
```

### Comparing `checkthechain-0.3.0/src/ctc/toolbox/defi_utils/dex_utils/dexes/dex_implementations/curve_dex.py` & `checkthechain-0.3.4/src/ctc/defi/dex_utils/dexes/dex_implementations/curve_dex.py`

 * *Files 12% similar despite different names*

```diff
@@ -32,31 +32,28 @@
         cls,
         *,
         factory: spec.Address,
         start_block: spec.BlockNumberReference | None = None,
         end_block: spec.BlockNumberReference | None = None,
         start_time: tooltime.Timestamp | None = None,
         end_time: tooltime.Timestamp | None = None,
-        network: spec.NetworkReference | None = None,
-        provider: spec.ProviderReference | None = None,
+        context: spec.Context = None,
     ) -> typing.Sequence[spec.DexPool]:
 
-        network, provider = evm.get_network_and_provider(network, provider)
-
         start_block, end_block = await evm.async_resolve_block_range(
             start_block=start_block,
             end_block=end_block,
             start_time=start_time,
             end_time=end_time,
             allow_none=False,
-            provider=provider,
+            context=context,
         )
 
         start_block, end_block = await evm.async_block_numbers_to_int(
-            [start_block, end_block]
+            [start_block, end_block], context=context
         )
 
         if factory == curve_utils.curve_deployer_eoa:
             unfiltered_pools = curve_utils.get_non_factory_pools()
             pools = []
             for pool, creation_block in unfiltered_pools.items():
                 if start_block is not None and creation_block < start_block:
@@ -66,34 +63,34 @@
                 pools.append(pool)
 
         else:
             start_pool_count, end_pool_count = await rpc.async_batch_eth_call(
                 to_address=factory,
                 function_abi=curve_utils.function_abis['pool_count'],
                 block_numbers=[start_block, end_block],
-                provider=provider,
+                context=context,
             )
 
             pools = await rpc.async_batch_eth_call(
                 to_address=factory,
                 function_abi=curve_utils.function_abis['pool_list'],
                 function_parameter_list=[
                     [index] for index in range(start_pool_count, end_pool_count)
                 ],
-                provider=provider,
+                context=context,
             )
 
             creation_blocks_coroutine = asyncio.create_task(
                 evm.async_get_contracts_creation_blocks(
-                    pools, provider=provider
+                    pools, context=context
                 )
             )
 
         coroutines = [
-            curve_utils.async_get_pool_tokens(pool, provider=provider)
+            curve_utils.async_get_pool_tokens(pool, context=context)
             for pool in pools
         ]
         pools_tokens = await asyncio.gather(*coroutines)
 
         if factory == curve_utils.curve_deployer_eoa:
             creation_blocks = [unfiltered_pools[pool] for pool in pools]
         else:
@@ -136,61 +133,58 @@
         return dex_pools
 
     @classmethod
     async def _async_get_pool_assets_from_node(
         cls,
         pool: spec.Address,
         *,
-        network: spec.NetworkReference | None = None,
-        provider: spec.ProviderReference | None = None,
         block: spec.BlockNumberReference | None = None,
+        context: spec.Context = None,
     ) -> typing.Sequence[spec.Address]:
-        network, provider = evm.get_network_and_provider(network, provider)
         return await curve_utils.async_get_pool_tokens(
             pool=pool,
-            provider=provider,
+            context=context,
         )
 
     @classmethod
     async def _async_get_pool_raw_trades(
         cls,
         pool: spec.Address,
         *,
         start_block: spec.BlockNumberReference | None = None,
         end_block: spec.BlockNumberReference | None = None,
         start_time: tooltime.Timestamp | None = None,
         end_time: tooltime.Timestamp | None = None,
         include_timestamps: bool = False,
-        network: spec.NetworkReference | None = None,
-        provider: spec.ProviderReference | None = None,
         verbose: bool = False,
+        context: spec.Context = None,
     ) -> spec.RawDexTrades:
 
-        import pandas as pd
-
-        network, provider = evm.get_network_and_provider(network, provider)
+        import polars as pl
 
         # get data
         trades = await evm.async_get_events(
             contract_address=pool,
             event_abi=curve_utils.pool_event_abis['TokenExchange'],
             start_block=start_block,
             end_block=end_block,
             start_time=start_time,
             end_time=end_time,
             verbose=verbose,
             include_timestamps=include_timestamps,
+            context=context,
         )
 
         # check factory for whether TokenExchangeUnderlying is present
-        contract_abi = await evm.async_get_contract_abi(pool, network=network)
+        contract_abi = await evm.async_get_contract_abi(pool, context=context)
         try:
             await evm.async_get_event_abi(
                 contract_abi=contract_abi,
                 event_name='TokenExchangeUnderlying',
+                context=context,
             )
             has_token_exchange_underlying = True
         except LookupError:
             has_token_exchange_underlying = False
 
         if has_token_exchange_underlying:
             token_exchange_underlyings = await evm.async_get_events(
@@ -200,25 +194,27 @@
                 ],
                 start_block=start_block,
                 end_block=end_block,
                 start_time=start_time,
                 end_time=end_time,
                 verbose=verbose,
                 include_timestamps=include_timestamps,
+                context=context,
             )
-            trades = pd.concat([trades, token_exchange_underlyings])
-            trades = trades.sort_index()
+            trades = pl.concat([trades, token_exchange_underlyings])
+            trades = trades.sort(['block_number', 'log_index'])
 
         # gather relevatn subset of data
         output: spec.RawDexTrades = {
+            'block_number': trades['block_number'],
             'transaction_hash': trades['transaction_hash'],
             'recipient': trades['arg__buyer'],
             'sold_id': trades['arg__sold_id'],
             'bought_id': trades['arg__bought_id'],
-            'sold_amount': trades['arg__tokens_sold'].map(int),
-            'bought_amount': trades['arg__tokens_bought'].map(int),
+            'sold_amount': trades['arg__tokens_sold'],
+            'bought_amount': trades['arg__tokens_bought'],
         }
 
         if include_timestamps:
             output['timestamp'] = trades['timestamp']
 
         return output
```

### Comparing `checkthechain-0.3.0/src/ctc/toolbox/defi_utils/dex_utils/dexes/dex_implementations/uniswap_v2_dex.py` & `checkthechain-0.3.4/src/ctc/defi/dex_utils/dexes/dex_implementations/uniswap_v2_dex.py`

 * *Files 15% similar despite different names*

```diff
@@ -22,124 +22,118 @@
         cls,
         *,
         factory: spec.Address,
         start_block: spec.BlockNumberReference | None = None,
         end_block: spec.BlockNumberReference | None = None,
         start_time: tooltime.Timestamp | None = None,
         end_time: tooltime.Timestamp | None = None,
-        network: spec.NetworkReference | None = None,
-        provider: spec.ProviderReference | None = None,
+        context: spec.Context = None,
     ) -> typing.Sequence[spec.DexPool]:
-
-        network, provider = evm.get_network_and_provider(network, provider)
-
         df = await evm.async_get_events(
             factory,
             event_abi=uniswap_v2_utils.factory_event_abis['PairCreated'],
             verbose=False,
             start_block=start_block,
             end_block=end_block,
             start_time=start_time,
             end_time=end_time,
-            keep_multiindex=False,
-            provider=provider,
+            context=context,
         )
 
         dex_pools = []
-        for index, row in df.iterrows():
-            block = typing.cast(int, index)
+        for row in df.to_dicts():
             dex_pool: spec.DexPool = {
                 'address': row['arg__pair'],
                 'factory': factory,
                 'asset0': row['arg__token0'],
                 'asset1': row['arg__token1'],
                 'asset2': None,
                 'asset3': None,
                 'fee': int(0.003 * 1e8),
-                'creation_block': block,
+                'creation_block': row['block_number'],
                 'additional_data': {},
             }
             dex_pools.append(dex_pool)
         return dex_pools
 
     @classmethod
     async def _async_get_pool_assets_from_node(
         cls,
         pool: spec.Address,
         *,
-        network: spec.NetworkReference | None = None,
-        provider: spec.ProviderReference | None = None,
         block: spec.BlockNumberReference | None = None,
+        context: spec.Context = None,
     ) -> tuple[str, str]:
-
         import asyncio
         from ctc.protocols import uniswap_v2_utils
 
-        network, provider = evm.get_network_and_provider(network, provider)
-
         token0 = rpc.async_eth_call(
             function_abi=uniswap_v2_utils.pool_function_abis['token0'],
             to_address=pool,
-            provider=provider,
             block_number=block,
+            context=context,
         )
         token1 = rpc.async_eth_call(
             function_abi=uniswap_v2_utils.pool_function_abis['token1'],
             to_address=pool,
-            provider=provider,
             block_number=block,
+            context=context,
         )
 
         return await asyncio.gather(token0, token1)
 
     @classmethod
     async def _async_get_pool_raw_trades(
         cls,
         pool: spec.Address,
         *,
         start_block: spec.BlockNumberReference | None = None,
         end_block: spec.BlockNumberReference | None = None,
         start_time: tooltime.Timestamp | None = None,
         end_time: tooltime.Timestamp | None = None,
         include_timestamps: bool = False,
-        network: spec.NetworkReference | None = None,
-        provider: spec.ProviderReference | None = None,
+        context: spec.Context = None,
         verbose: bool = False,
     ) -> spec.RawDexTrades:
-
-        network, provider = evm.get_network_and_provider(network, provider)
+        import polars as pl
 
         trades = await evm.async_get_events(
             event_abi=uniswap_v2_utils.pool_event_abis['Swap'],
             contract_address=pool,
             start_block=start_block,
             end_block=end_block,
             start_time=start_time,
             end_time=end_time,
             include_timestamps=include_timestamps,
-            provider=provider,
             verbose=verbose,
-            keep_multiindex=False,
+            context=context,
+            integer_output_format=float,
         )
 
-        sold_id = (trades['arg__amount0Out'].map(int) > 0).astype(int)
-        bought_id = (sold_id == 0).astype(int)
-        sold_amount = trades['arg__amount0In'].map(int) + trades[
-            'arg__amount1In'
-        ].map(int)
-        bought_amount = trades['arg__amount0Out'].map(int) + trades[
-            'arg__amount1Out'
-        ].map(int)
+        df = trades.select(
+            (pl.when(pl.col('arg__amount0Out') > 0).then(1).otherwise(0)).alias(
+                'sold_id'
+            ),
+            (pl.col('arg__amount0In') + pl.col('arg__amount1In')).alias(
+                'sold_amount'
+            ),
+            (pl.col('arg__amount0Out') + pl.col('arg__amount1Out')).alias(
+                'bought_amount'
+            ),
+        )
+        df = df.with_columns((1 - pl.col('sold_id')).alias('bought_id'))
 
         output: spec.RawDexTrades = {
+            'block_number': trades['block_number'],
             'transaction_hash': trades['transaction_hash'],
             'recipient': trades['arg__to'],
-            'sold_id': sold_id,
-            'bought_id': bought_id,
-            'sold_amount': sold_amount,
-            'bought_amount': bought_amount,
+            'sold_id': df['sold_id'],
+            'bought_id': df['bought_id'],
+            'sold_amount': df['sold_amount'],
+            'bought_amount': df['bought_amount'],
         }
 
         if include_timestamps:
             output['timestamp'] = trades['timestamp']
 
         return output
+
```

### Comparing `checkthechain-0.3.0/src/ctc/toolbox/defi_utils/dex_utils/dexes/dex_implementations/uniswap_v3_dex.py` & `checkthechain-0.3.4/src/ctc/defi/dex_utils/dexes/dex_implementations/uniswap_v3_dex.py`

 * *Files 13% similar despite different names*

```diff
@@ -22,114 +22,105 @@
         cls,
         *,
         factory: spec.Address,
         start_block: spec.BlockNumberReference | None = None,
         end_block: spec.BlockNumberReference | None = None,
         start_time: tooltime.Timestamp | None = None,
         end_time: tooltime.Timestamp | None = None,
-        network: spec.NetworkReference | None = None,
-        provider: spec.ProviderReference | None = None,
+        context: spec.Context = None,
     ) -> typing.Sequence[spec.DexPool]:
 
         from ctc.protocols import uniswap_v3_utils
 
-        network, provider = evm.get_network_and_provider(network, provider)
-
         df = await evm.async_get_events(
             factory,
             event_abi=uniswap_v3_utils.factory_event_abis['PoolCreated'],
             verbose=False,
             start_block=start_block,
             end_block=end_block,
             start_time=start_time,
             end_time=end_time,
-            keep_multiindex=False,
-            provider=provider,
+            context=context,
         )
 
         dex_pools = []
-        for index, row in df.iterrows():
-            block = typing.cast(int, index)
+        for row in df.to_dicts():
             dex_pool: spec.DexPool = {
                 'address': row['arg__pool'],
                 'factory': factory,
                 'asset0': row['arg__token0'],
                 'asset1': row['arg__token1'],
                 'asset2': None,
                 'asset3': None,
                 'fee': row['arg__fee'] * 100,
-                'creation_block': block,
+                'creation_block': row['block_number'],
                 'additional_data': {},
             }
             dex_pools.append(dex_pool)
 
         return dex_pools
 
     @classmethod
     async def _async_get_pool_assets_from_node(
         cls,
         pool: spec.Address,
         *,
-        network: spec.NetworkReference | None = None,
-        provider: spec.ProviderReference | None = None,
         block: spec.BlockNumberReference | None = None,
+        context: spec.Context = None,
     ) -> tuple[str, str]:
         output = uniswap_v2_dex.UniswapV2DEX._async_get_pool_assets_from_node(
             pool=pool,
-            network=network,
-            provider=provider,
             block=block,
+            context=context,
         )
         return await output
 
     @classmethod
     async def _async_get_pool_raw_trades(
         cls,
         pool: spec.Address,
         *,
         start_block: spec.BlockNumberReference | None = None,
         end_block: spec.BlockNumberReference | None = None,
         start_time: tooltime.Timestamp | None = None,
         end_time: tooltime.Timestamp | None = None,
         include_timestamps: bool = False,
-        network: spec.NetworkReference | None = None,
-        provider: spec.ProviderReference | None = None,
         verbose: bool = False,
+        context: spec.Context = None,
     ) -> spec.RawDexTrades:
 
         from ctc.protocols import uniswap_v3_utils
 
-        network, provider = evm.get_network_and_provider(network, provider)
-
         event_abi = await uniswap_v3_utils.async_get_event_abi('Swap', 'pool')
 
         trades = await evm.async_get_events(
             event_abi=event_abi,
             contract_address=pool,
             start_block=start_block,
             end_block=end_block,
             start_time=start_time,
             end_time=end_time,
             include_timestamps=include_timestamps,
             verbose=verbose,
-            keep_multiindex=False,
+            context=context,
         )
 
-        bool_bought_id = trades['arg__amount0'].map(int) > 0
-        bought_id = bool_bought_id.map(int)
-        sold_id = (bought_id == 0).map(int)
-        sold_amount = sold_id * trades['arg__amount1'].map(
+        bool_bought_id = trades['arg__amount0'].apply(int) > 0
+        bought_id = bool_bought_id.apply(int)
+        sold_id = (bought_id == 0).apply(int)
+        sold_amount = sold_id * trades['arg__amount1'].apply(
             int
-        ) + bought_id * trades['arg__amount0'].map(int)
+        ) + bought_id * trades['arg__amount0'].apply(int)
         bought_amount = -(
-            bought_id * trades['arg__amount1'].map(int)
-            + sold_id * trades['arg__amount0'].map(int)
+            bought_id * trades['arg__amount1'].apply(int)
+            + sold_id * trades['arg__amount0'].apply(int)
         )
 
         output: spec.RawDexTrades = {
+            'block_number': trades['block_number'],
             'transaction_hash': trades['transaction_hash'],
             'recipient': trades['arg__recipient'],
             'sold_id': sold_id,
             'bought_id': bought_id,
             'sold_amount': sold_amount,
             'bought_amount': bought_amount,
         }
```

### Comparing `checkthechain-0.3.0/src/ctc/toolbox/defi_utils/lending_utils/lending_summary.py` & `checkthechain-0.3.4/src/ctc/defi/lending_utils/lending_summary.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 from __future__ import annotations
 
 import asyncio
 import typing
 import types
 
-import pandas as pd
 import tooltime
+import polars as pl
 
 from ctc import evm
 from ctc import spec
 
 
 async def async_get_lending_flows(
     wallet: spec.Address,
@@ -17,15 +17,15 @@
     *,
     protocol: typing.Literal['aave', 'compound', 'rari'],
     wallet_deposits: spec.DataFrame | None = None,
     deposits: spec.DataFrame | None = None,
     wallet_withdrawals: spec.DataFrame | None = None,
     withdrawals: spec.DataFrame | None = None,
     include_latest: bool = True,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     replace_symbols: bool = True,
     normalize: bool = True,
     include_rewards: bool = True,
 ) -> spec.DataFrame:
 
     if protocol == 'aave':
         from ctc.protocols import aave_v2_utils
@@ -45,103 +45,99 @@
     df = await _async_create_raw_wallet_flows_df(
         wallet=wallet,
         wallet_deposits=wallet_deposits,
         deposits=deposits,
         wallet_withdrawals=wallet_withdrawals,
         withdrawals=withdrawals,
         include_latest=include_latest,
-        provider=provider,
+        context=context,
     )
 
     underlying = await protocol_module.async_get_underlying_asset(
         pool_token=pool_token,
-        provider=provider,
+        context=context,
     )
 
     # add time data
-    blocks = df.index.values
-    blocks_before = blocks - 1
+    blocks = df['block_number'].to_numpy()
+    blocks_before = list(blocks - 1)
+    blocks_list = list(blocks)
 
     # queue tasks
     timestamps_coroutine = evm.async_get_block_timestamps(
-        blocks=blocks,
-        provider=provider,
+        blocks=blocks_list,
+        context=context,
     )
     timestamps_task = asyncio.create_task(timestamps_coroutine)
-    pool_token_balances_before_coroutine = (
-        evm.async_get_erc20_balance_by_block(
-            token=pool_token,
-            wallet=wallet,
-            blocks=blocks_before,
-            provider=provider,
-        )
+    pool_token_balances_before_coroutine = evm.async_get_erc20_balance_by_block(
+        token=pool_token,
+        wallet=wallet,
+        blocks=blocks_before,
+        context=context,
     )
     pool_token_balances_before_task = asyncio.create_task(
         pool_token_balances_before_coroutine
     )
-    pool_token_balances_after_coroutine = (
-        evm.async_get_erc20_balance_by_block(
-            token=pool_token,
-            wallet=wallet,
-            blocks=blocks,
-            provider=provider,
-        )
+    pool_token_balances_after_coroutine = evm.async_get_erc20_balance_by_block(
+        token=pool_token,
+        wallet=wallet,
+        blocks=blocks_list,
+        context=context,
     )
     pool_token_balances_after_task = asyncio.create_task(
         pool_token_balances_after_coroutine
     )
     asset_prices_coroutine = protocol_module.async_get_asset_price_by_block(
         asset=underlying,
-        blocks=blocks,
-        provider=provider,
+        blocks=blocks_list,
+        context=context,
     )
     asset_prices_task = asyncio.create_task(asset_prices_coroutine)
 
     # queue optional tasks
     if include_rewards:
         reward_coroutine = protocol_module.async_compute_wallet_rewards(
             wallet=wallet,
             blocks=blocks,
-            provider=provider,
+            context=context,
             replace_symbol=replace_symbols,
         )
         reward_task = asyncio.create_task(reward_coroutine)
     if normalize:
         decimals_coroutine = evm.async_get_erc20_decimals(
             underlying,
-            provider=provider,
+            context=context,
         )
         decimals_task = asyncio.create_task(decimals_coroutine)
     if replace_symbols:
         underlying_symbol_coroutine = evm.async_get_erc20_symbol(
             underlying,
-            provider=provider,
+            context=context,
         )
         underlying_symbol_task = asyncio.create_task(
             underlying_symbol_coroutine
         )
         pool_token_coroutine = evm.async_get_erc20_symbol(
             pool_token,
-            provider=provider,
+            context=context,
         )
         pool_token_symbol_task = asyncio.create_task(pool_token_coroutine)
 
     # normalize deposits and withdrawals
     if normalize:
         decimals = await decimals_task
-        df['asset_deposit'] /= 10 ** decimals
-        df['asset_withdrawal'] /= 10 ** decimals
+        df['asset_deposit'] /= 10**decimals
+        df['asset_withdrawal'] /= 10**decimals
 
     # compute time columns
     timestamps = await timestamps_task
-    df.insert(loc=0, column='timestamp', value=timestamps)  # type: ignore
-    df.insert(
-        loc=1,
-        column='time',
-        value=df['timestamp'].map(tooltime.timestamp_to_iso),
+    df = df.insert_at_idx(0, pl.Series('timestamp', timestamps))
+    df = df.insert_at_idx(
+        1,
+        pl.Series('time', df['timestamp'].apply(tooltime.timestamp_to_iso)),
     )
 
     # add pool token balances
     df['pool_token_balance_before'] = await pool_token_balances_before_task
     df['pool_token_balance_after'] = await pool_token_balances_after_task
 
     # add underlying balances
@@ -167,69 +163,69 @@
                 rename_columns[column] = column.replace(
                     'asset', underlying_symbol
                 )
             if 'pool_token' in column:
                 rename_columns[column] = column.replace(
                     'pool_token', pool_token_symbol
                 )
-        df = df.rename(columns=rename_columns)
+        df = df.rename(rename_columns)
 
     return df
 
 
 async def _async_create_raw_wallet_flows_df(
     *,
     wallet: spec.Address,
     wallet_deposits: spec.DataFrame | None = None,
     deposits: spec.DataFrame | None = None,
     wallet_withdrawals: spec.DataFrame | None = None,
     withdrawals: spec.DataFrame | None = None,
     include_latest: bool = True,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
 ) -> spec.DataFrame:
 
     from ctc.protocols import aave_v2_utils
 
     no_deposits = wallet_deposits is None and deposits is None
     no_withdrawals = wallet_withdrawals is None and withdrawals is None
     if no_deposits and not no_withdrawals:
         deposits = await aave_v2_utils.async_get_deposits()
     elif not no_deposits and no_withdrawals:
         withdrawals = await aave_v2_utils.async_get_withdrawals()
     elif no_deposits and no_withdrawals:
         deposits, withdrawals = await asyncio.gather(
-            aave_v2_utils.async_get_deposits(provider=provider),
-            aave_v2_utils.async_get_withdrawals(provider=provider),
+            aave_v2_utils.async_get_deposits(context=context),
+            aave_v2_utils.async_get_withdrawals(context=context),
         )
 
     wallet = wallet.lower()
     if wallet_deposits is None:
         if deposits is None:
             raise Exception('could not determine deposits')
         wallet_deposits = deposits[deposits['arg__user'] == wallet]
-    if isinstance(wallet_deposits.index, pd.MultiIndex):
-        wallet_deposits = wallet_deposits.groupby(level='block_number').sum()
-    if isinstance(wallet_deposits, pd.DataFrame):
+    wallet_deposits = wallet_deposits.groupby('block_number').agg(pl.sum('*'))
+    if spec.is_polars_dataframe(wallet_deposits):
         wallet_deposits_series = wallet_deposits['arg__amount']
     if wallet_withdrawals is None:
         if withdrawals is None:
             raise Exception('could not determine withdrawals')
-        wallet_withdrawals = withdrawals[withdrawals['arg__user'] == wallet]
-    if isinstance(wallet_withdrawals.index, pd.MultiIndex):
-        wallet_withdrawals = wallet_withdrawals.groupby(
-            level='block_number'
-        ).sum()
-    if isinstance(wallet_withdrawals, pd.DataFrame):
+        wallet_withdrawals = withdrawals.filter(withdrawals['arg__user'] == wallet)
+    wallet_withdrawals = wallet_withdrawals.groupby('block_number').agg(pl.sum('*'))
+    if spec.is_polars_dataframe(wallet_withdrawals):
         wallet_withdrawals_series = wallet_withdrawals['arg__amount']
 
     raw_data = {
+        'block_number': wallet_withdrawals['block_number'],
         'asset_deposit': wallet_deposits_series,
         'asset_withdrawal': wallet_withdrawals_series,
     }
-    raw_df = pd.DataFrame(raw_data)
-    raw_df = raw_df.fillna(0)
-
     if include_latest:
-        block = await evm.async_get_latest_block_number(provider=provider)
-        raw_df.loc[block] = [0, 0]
+        raise NotImplementedError()
+        # block = await evm.async_get_latest_block_number(context=context)
+        # raw_data['block_number'].insert(0, block)
+        # raw_data['asset_deposit'].insert(0, 0)
+        # raw_data['asset_withdrawal'].insert(0, 0)
+    raw_df = pl.DataFrame(raw_data)
+    raw_df = raw_df.fill_null(0)
 
     return raw_df
+
```

### Comparing `checkthechain-0.3.0/src/ctc/toolbox/defi_utils/twap_utils/feed_utils.py` & `checkthechain-0.3.4/src/ctc/defi/metric_utils/twap_utils/feed_utils.py`

 * *Files 14% similar despite different names*

```diff
@@ -19,20 +19,20 @@
         'sushi_pool': async_is_sushi_pool,
         'balancer_v2_pool': async_is_balancer_v2_pool,
     }
 
 
 async def async_get_contract_type(
     address: spec.Address,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
 ) -> str:
 
     contract_guards = get_contract_type_guards()
     coroutines = [
-        contract_guard(address=address, provider=provider)
+        contract_guard(address=address, context=context)
         for contract_guard in contract_guards.values()
     ]
     tasks = [asyncio.create_task(coroutine) for coroutine in coroutines]
     contract_guard_names = list(contract_guards.keys())
     while True:
         done, pending = await asyncio.wait(
             tasks,
@@ -48,101 +48,102 @@
 
 #
 # # specific guard
 #
 
 
 async def async_is_chainlink_feed(
-    address: spec.Address, provider: spec.ProviderReference = None
+    address: spec.Address, context: spec.Context = None
 ) -> bool:
     try:
         await rpc.async_eth_call(
             to_address=address,
             function_abi={'name': 'aggregator', 'inputs': [], 'outputs': []},
-            provider=provider,
+            context=context,
         )
         return True
     except spec.RpcException:
         return False
 
 
 async def async_is_uniswap_v2_pool(
-    address: spec.Address, provider: spec.ProviderReference = None
+    address: spec.Address, context: spec.Context = None
 ) -> bool:
     try:
         factory = await rpc.async_eth_call(
             to_address=address,
             function_abi={
                 'name': 'factory',
                 'inputs': [],
                 'outputs': [{'type': 'address'}],
             },
-            provider=provider,
+            context=context,
         )
         return bool(factory == '0x5c69bee701ef814a2b6a3edd4b1652cb9cc5aa6f')
     except spec.RpcException:
         return False
 
 
 async def async_is_uniswap_v3_pool(
-    address: spec.Address, provider: spec.ProviderReference = None
+    address: spec.Address, context: spec.Context = None
 ) -> bool:
     try:
         factory = await rpc.async_eth_call(
             to_address=address,
             function_abi={
                 'name': 'factory',
                 'inputs': [],
                 'outputs': [{'type': 'address'}],
             },
-            provider=provider,
+            context=context,
         )
         return bool(factory == '0x1f98431c8ad98523631ae4a59f267346ea31f984')
     except spec.RpcException:
         return False
 
 
 async def async_is_curve_pool(
-    address: spec.Address, provider: spec.ProviderReference = None
+    address: spec.Address, context: spec.Context = None
 ) -> bool:
     # doesn't work for early pools
     try:
         await rpc.async_eth_call(
             to_address=address,
             function_abi={'name': 'A', 'inputs': [], 'outputs': []},
-            provider=provider,
+            context=context,
         )
         return True
     except spec.RpcException:
         return False
 
 
 async def async_is_sushi_pool(
-    address: spec.Address, provider: spec.ProviderReference = None
+    address: spec.Address, context: spec.Context = None
 ) -> bool:
     try:
         factory = await rpc.async_eth_call(
             to_address=address,
             function_abi={
                 'name': 'factory',
                 'inputs': [],
                 'outputs': [{'type': 'address'}],
             },
-            provider=provider,
+            context=context,
         )
         return bool(factory == '0xc0aee478e3658e2610c5f7a4a2e1777ce9e4f2ac')
     except spec.RpcException:
         return False
 
 
 async def async_is_balancer_v2_pool(
-    address: spec.Address, provider: spec.ProviderReference = None
+    address: spec.Address, context: spec.Context = None
 ) -> bool:
     try:
         await rpc.async_eth_call(
             to_address=address,
             function_abi={'name': 'getPoolId', 'inputs': [], 'outputs': []},
-            provider=provider,
+            context=context,
         )
         return True
     except spec.RpcException:
         return False
+
```

### Comparing `checkthechain-0.3.0/src/ctc/toolbox/defi_utils/twap_utils/twap_crud.py` & `checkthechain-0.3.4/src/ctc/defi/metric_utils/twap_utils/twap_crud.py`

 * *Files 18% similar despite different names*

```diff
@@ -22,37 +22,37 @@
     # # output samples
     output_start_block: typing.Optional[spec.BlockNumberReference] = None,
     output_end_block: typing.Optional[spec.BlockNumberReference] = None,
     output_start_time: typing.Optional[tooltime.Timestamp] = None,
     output_end_time: typing.Optional[tooltime.Timestamp] = None,
     #
     # # other
-    provider: spec.ProviderReference = None,
-) -> spec.Series:
+    context: spec.Context = None,
+) -> spec.DataFrame:
 
     # get block numbers and timestamps
     start_coroutine = evm.async_get_block_number_and_time(
         block_number=output_start_block,
         block_timestamp=output_start_time,
-        provider=provider,
+        context=context,
     )
     start_task = asyncio.create_task(start_coroutine)
     end_coroutine = evm.async_get_block_number_and_time(
         block_number=output_end_block,
         block_timestamp=output_end_time,
-        provider=provider,
+        context=context,
     )
     end_task = asyncio.create_task(end_coroutine)
     start_block, start_time = await start_task
     end_block, end_time = await end_task
 
     # start block timestamp acquisition task
     blocks = list(range(start_block, end_block + 1))
     block_timestamps_task = asyncio.create_task(
-        evm.async_get_block_timestamps(blocks=blocks, provider=provider)
+        evm.async_get_block_timestamps(blocks=blocks, context=context)
     )
 
     # get data
     data = await twap_data.async_get_data_feed(
         data_source=data_source,
         start_block=start_block,
         end_block=end_block,
@@ -60,15 +60,15 @@
 
     # filter data if necessary
     mode = data_source.get('mode')
     if mode == 'native':
         twap = data
     elif mode == 'raw':
         twap = twap_filter.filter_twap(
-            raw_values=typing.cast(typing.Sequence[typing.Any], data.values),
+            raw_values=data.rows(),
             timestamps=(await block_timestamps_task),
             filter_duration=filter_duration,
         )
     else:
         raise Exception('unknown mode: ' + str(mode))
 
     return twap
@@ -76,26 +76,26 @@
 
 async def async_get_twap_single_sample(
     data_source: twap_spec.DataSource,
     filter_duration: tooltime.Timestamp,
     *,
     block: typing.Optional[spec.BlockNumberReference] = None,
     timestamp: typing.Optional[tooltime.Timestamp] = None,
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
 ) -> float:
 
     series = await async_get_twap(
         data_source=data_source,
         filter_duration=filter_duration,
         output_start_block=block,
         output_end_block=block,
         output_start_time=timestamp,
         output_end_time=timestamp,
-        provider=provider,
+        context=context,
     )
 
     if len(series) == 0:
         raise Exception()
     elif len(series) > 1:
         raise Exception()
     else:
-        return typing.cast(float, series.values[0])
+        return typing.cast(float, series[0])
```

### Comparing `checkthechain-0.3.0/src/ctc/toolbox/defi_utils/twap_utils/twap_data.py` & `checkthechain-0.3.4/src/ctc/defi/metric_utils/twap_utils/twap_data.py`

 * *Files 5% similar despite different names*

```diff
@@ -6,24 +6,24 @@
 
 
 async def async_get_data_feed(
     data_source: twap_spec.DataSource,
     *,
     start_block: int,
     end_block: int,
-    provider: spec.ProviderReference = None,
-) -> spec.Series:
+    context: spec.Context = None,
+) -> spec.DataFrame:
     # acquire data
     protocol = data_source['protocol']
     if protocol == 'Chainlink':
         return await twap_data_sources.async_get_chainlink_data(
             start_block=start_block,
             end_block=end_block,
             data_source=data_source,
-            provider=provider,
+            context=context,
         )
     # elif protocol == 'UniswapV2':
     #     return await twap_data_sources.async_get_uniswap_v2_data(
     #         start_block=start_block,
     #         end_block=end_block,
     #         data_source=data_source,
     #         provider=provider,
```

### Comparing `checkthechain-0.3.0/src/ctc/toolbox/defi_utils/twap_utils/twap_data_sources.py` & `checkthechain-0.3.4/src/ctc/defi/metric_utils/twap_utils/twap_data_sources.py`

 * *Files 10% similar despite different names*

```diff
@@ -7,16 +7,16 @@
 
 
 async def async_get_chainlink_data(
     data_source: twap_spec.DataSource,
     *,
     start_block: typing.Optional[spec.BlockNumberReference] = None,
     end_block: typing.Optional[spec.BlockNumberReference] = None,
-    provider: spec.ProviderReference = None,
-) -> spec.Series:
+    context: spec.Context = None,
+) -> spec.DataFrame:
 
     from ctc.protocols import chainlink_utils
 
     feed = data_source.get('feed')
     composite_feed = data_source.get('composite_feed')
     invert = data_source.get('invert')
     if invert is None:
@@ -30,33 +30,33 @@
             feed=feed,
             invert=invert,
             normalize=normalize,
             start_block=start_block,
             end_block=end_block,
             interpolate=True,
             fields='answer',
-            provider=provider,
+            context=context,
         )
     elif composite_feed is not None:
         return await chainlink_utils.async_get_composite_feed_data(
             composite_feed=composite_feed,
             invert=invert,
             start_block=start_block,
             end_block=end_block,
-            provider=provider,
+            context=context,
         )
     else:
         raise Exception('must specify feed or composite_feed')
 
 
 # async def async_get_uniswap_v2_data(
 #     data_source: twap_spec.DataSource,
 #     start_block: typing.Optional[spec.BlockNumberReference] = None,
 #     end_block: typing.Optional[spec.BlockNumberReference] = None,
-#     provider: spec.ProviderReference = None,
+#     context: spec.Context = None,
 # ) -> spec.Series:
 
 #     from ctc.protocols import uniswap_v2_utils
 
 #     feed = data_source.get('feed')
 #     composite_feed = data_source.get('composite_feed')
 #     invert = data_source.get('invert')
@@ -66,20 +66,20 @@
 #         return await uniswap_v2_utils.async_get_feed_data(
 #             feed=feed,
 #             invert=invert,
 #             normalize=normalize,
 #             start_block=start_block,
 #             end_block=end_block,
 #             interpolate=True,
-#             provider=provider,
+#             context=context,
 #         )
 #     elif composite_feed is not None:
 #         return await uniswap_v2_utils.async_get_composite_feed_data(
 #             composite_feed=composite_feed,
 #             invert=invert,
 #             normalize=normalize,
 #             start_block=start_block,
 #             end_block=end_block,
-#             provider=provider,
+#             context=context,
 #         )
 #     else:
 #         raise Exception('must specify feed or composite_feed')
```

### Comparing `checkthechain-0.3.0/src/ctc/toolbox/defi_utils/twap_utils/twap_filter.py` & `checkthechain-0.3.4/src/ctc/defi/metric_utils/twap_utils/twap_filter.py`

 * *Files 12% similar despite different names*

```diff
@@ -8,19 +8,19 @@
 
 
 def filter_twap(
     *,
     raw_values: typing.Sequence[typing.Any],
     timestamps: typing.Sequence[typing.Any],
     filter_duration: tooltime.Timestamp,
-) -> spec.Series:
+) -> spec.DataFrame:
     """convert raw value of a TWAP"""
 
     import numpy as np
-    import pandas as pd
+    import polars as pl
 
     # compute twap times
     timestamps_array: spec.NumpyArray = np.array(timestamps)
     filter_seconds = tooltime.timestamp_to_seconds(filter_duration)
     first_input_timestamp = timestamps[0]
     output_mask = timestamps_array > first_input_timestamp + filter_seconds
     twap_times = timestamps_array[output_mask]
@@ -34,8 +34,9 @@
         lower_bound = twap_time - filter_seconds < timestamps_array
         upper_bound = timestamps_array <= twap_time
         block_mask = lower_bound * upper_bound
         twap_value = raw_values_array[block_mask].mean()
         twap_values.append(twap_value)
 
     # format as Series
-    return pd.Series(twap_values, index=twap_times)
+    return pl.DataFrame({'timestamp': twap_times, 'value': twap_values})
+
```

### Comparing `checkthechain-0.3.0/src/ctc/toolbox/nested_utils.py` & `checkthechain-0.3.4/src/ctc/toolbox/nested_utils.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/src/ctc/toolbox/optimize_utils/async_search.py` & `checkthechain-0.3.4/src/ctc/toolbox/optimize_utils.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,12 +1,14 @@
 from __future__ import annotations
 
 import typing
 
-from . import optimize_exceptions
+
+class BadSearchDomain(Exception):
+    pass
 
 
 async def async_bisect(
     async_f: typing.Callable[
         ...,
         typing.Coroutine[typing.Any, typing.Any, float],
     ],
@@ -20,15 +22,15 @@
     f_kwargs: typing.Mapping[str, typing.Any] | None = None,
     verbose: bool = False,
 ) -> float:
     import asyncio
 
     # ensure that bounds are valid
     if a > b:
-        raise optimize_exceptions.BadSearchDomain(
+        raise BadSearchDomain(
             'a must be less than b (' + str(a) + ' >= ' + str(b) + ')'
         )
 
     # set defaults
     if f_args is None:
         f_args = []
     if f_kwargs is None:
@@ -48,15 +50,15 @@
     if f_a == 0:
         return a
     if f_b == 0:
         return b
 
     # check that function has opposite signs at bounds
     if (f_a < 0 and f_b < 0) or (f_a > 0 and f_b > 0):
-        raise optimize_exceptions.BadSearchDomain(
+        raise BadSearchDomain(
             'function must have opposite signs at bounds, have:\n    f(a) = '
             + str(f_a)
             + '\n    f(b) = '
             + str(f_b)
         )
 
     iteration = 0
```

### Comparing `checkthechain-0.3.0/src/ctc/toolbox/pd_utils/pandas_interpolate_utils.py` & `checkthechain-0.3.4/src/ctc/toolbox/pl_utils/interpolate_utils.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,114 +1,104 @@
 from __future__ import annotations
 
 import typing
 
-import numpy as np
-import pandas as pd
+import polars as pl
 
 from ctc import spec
+from ctc.toolbox import pl_utils
 
 
-def keep_level(index: pd.MultiIndex, level: str) -> pd.Index:
-    """drop all levels in a multiindex except for one"""
-    for other_level in list(index.names):
-        if other_level != level:
-            index = index.droplevel(other_level)
-    return index
-
-
-def interpolate_series(
-    series: spec.Series,
-    *,
-    start_index: typing.Optional[int] = None,
-    end_index: typing.Optional[int] = None,
-    pre_fill_value: typing.Any = None,
-    level: typing.Optional[str] = None,
-) -> spec.Series:
-
-    # drop extra levels
-    old_index = series.index
-    if isinstance(old_index, pd.MultiIndex):
-        if level is None:
-            raise Exception('must specify which index level to use')
-        series = series.copy()
-        series.index = keep_level(old_index, level)
-
-    # remove duplicate index values, keeping last value of each duplicate
-    series = series[~series.index.duplicated(keep='last')]
-
-    # build new index
-    if start_index is None:
-        start_index = series.index.values[0]
-    if end_index is None:
-        end_index = series.index.values[-1]
-    new_index: spec.NumpyArray = np.arange(
-        start_index, end_index + 1, 1, dtype=int
-    )
-
-    # create new series
-    new_series = typing.cast(
-        pd.Series, series.reindex(new_index, fill_value=pd.NA)
-    )
-
-    # insert pre fill value
-    if len(series) > 0:
-        if start_index < series.index.values[0]:
-            if pre_fill_value is None:
-                raise Exception('for early start must specify pre_fill_value')
-            new_series.iloc[0] = pre_fill_value
-        elif start_index > series.index.values[-1]:
-            # case: indicies start after the series ends
-            new_series.iloc[0] = series.values[-1]
-        elif start_index > series.index.values[0]:
-            # fill in any initial values that were cut off
-            fill_index = np.nonzero(series.index > start_index)[0][0] - 1  # type: ignore
-            new_series.iloc[0] = series.iloc[fill_index]
-
-    # interpolate values
-    if len(series) == 0 and len(new_series) > 0 and pre_fill_value is not None:
-        new_series.iloc[0] = pre_fill_value
-    new_series = new_series.fillna(method='ffill')
-
-    return new_series
-
-
-def interpolate_dataframe(
+def interpolate(
     df: spec.DataFrame,
     *,
-    start_index: typing.Optional[int] = None,
-    end_index: typing.Optional[int] = None,
-    level: typing.Optional[str] = None,
+    index_column: str,
+    start_index: int | None = None,
+    end_index: int | None = None,
+    pre_fill_values: typing.Mapping[str, typing.Any] | None = None,
 ) -> spec.DataFrame:
+    """interpolate values in dataframe according to index column"""
+
+    if len(df) == 0:
+        return df
 
-    # drop extra levels
-    old_index = df.index
-    if isinstance(old_index, pd.MultiIndex):
-        if level is None:
-            raise Exception('must specify which index level to use')
-        df = df.copy()
-        df.index = keep_level(old_index, level)
-
-    # remove duplicate index values, keeping last value of each duplicate
-    df = df[~df.index.duplicated(keep='last')]
-
-    # build new index
-    if start_index is None:
-        start_index = df.index.values[0]
-    if end_index is None:
-        end_index = df.index.values[-1]
-    new_index: spec.NumpyArray = np.arange(
-        start_index, end_index + 1, 1, dtype=int
-    )
-
-    # create new series
-    new_df = df.reindex(new_index, fill_value=pd.NA)
-
-    # fill in cut off values
-    if start_index > df.index.values[0]:
-        fill_index = np.nonzero(df.index > start_index)[0][0] - 1
-        new_df.iloc[0] = df.iloc[fill_index]
+    index = df[index_column]
 
-    # interpolate values
-    new_df = new_df.fillna(method='ffill')
+    # remove redundant rows wrt index_column
+    df = df.filter(pl.col(index_column).cumcount().over(index_column) == 0)
+
+    # validate index
+    if index.dtype not in [pl.Int8, pl.Int16, pl.Int32, pl.Int64]:
+        raise Exception('index must be an integer column')
+    if not index.series_equal(index.sort()):
+        raise Exception('index must be a sorted column')
+    if start_index is not None:
+        if start_index > index[0]:
+            raise Exception('start_index is larger than first index in df')
+    else:
+        start_index = index[0]
+    if end_index is not None:
+        if end_index < index[-1]:
+            raise Exception('end_index is smaller than last index in df')
+    else:
+        end_index = index[-1]
+
+    # build new index and initial values
+    if start_index < index[0]:
+        if pre_fill_values is None:
+            raise Exception(
+                'must specify pre_fill_values if start_index < index[0]'
+            )
+        initial_values: typing.MutableMapping[
+            str, None | typing.Sequence[typing.Any]
+        ] = {k: [v] for k, v in pre_fill_values.items()}
+        initial_values[index_column] = [start_index]
+        for column in df.columns:
+            if column not in initial_values and column != index_column:
+                if df[column].dtype == pl.Object:
+                    initial_values[column] = [None for i in range(len(df))]
+                else:
+                    initial_values[column] = None
+        initial_df = pl.DataFrame(initial_values, schema=df.schema)
+        new_index = range(start_index + 1, end_index + 1)
+    else:
+        initial_df = None
+        new_index = range(start_index, end_index + 1)
+
+    # create interpolation rows
+    new_data: typing.MutableMapping[str, typing.Any] = {
+        column: None for column in df.columns if column != index_column
+    }
+    new_data[index_column] = pl.DataFrame(
+        pl.Series(index_column, new_index)
+    ).filter(~pl.col(index_column).is_in(df[index_column]))[index_column]
+    for column in df.columns:
+        if (pre_fill_values is None or column not in pre_fill_values) and df[
+            column
+        ].dtype == pl.Object:
+            new_data[column] = [
+                None for i in range(len(new_data[index_column]))
+            ]
+    new_df = pl.DataFrame(new_data, schema=df.schema)
+
+    # concat, sort, and fill
+    if initial_df is not None:
+        dfs = [initial_df, df, new_df]
+    else:
+        dfs = [df, new_df]
+    concated = pl_utils.concat(dfs).sort(index_column)
+
+    # handle pl.Object columns separately
+    filled = {}
+    for column in concated.columns:
+        if concated[column].dtype == pl.Object:
+            new = []
+            current = None
+            for item in concated[column].to_list():
+                if item is not None:
+                    current = item
+                new.append(current)
+            filled[column] = pl.Series(new, dtype=pl.Object)
+        else:
+            filled[column] = concated[column].fill_null(strategy='forward')
 
-    return new_df
+    return pl.DataFrame(filled)
```

### Comparing `checkthechain-0.3.0/src/ctc/toolbox/plot_utils/plot_format_utils.py` & `checkthechain-0.3.4/src/ctc/toolbox/plot_utils.py`

 * *Files 18% similar despite different names*

```diff
@@ -13,21 +13,21 @@
 
 
 if typing.TYPE_CHECKING:
     T = typing.TypeVar('T')
 
 
 async def async_xtick_block_dates(
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
 ) -> None:
     import tooltime
 
     start_block, end_block = plt.xlim()
     start_time, end_time = await evm.async_predict_block_timestamps(
-        [round(start_block), round(end_block)], provider=provider
+        [round(start_block), round(end_block)], context=context
     )
     date_timestamps = tooltime.get_standard_intervals(
         interval_size='1d',
         start_time=start_time,
         end_time=end_time,
     )
     date_timestamps = [
@@ -59,27 +59,27 @@
         return items
     else:
         indices = np.linspace(0, len(items) - 1, number).round().astype(int)
         return [items[index] for index in indices]
 
 
 async def async_block_timestamp_xticks(
-    provider: spec.ProviderReference = None,
+    context: spec.Context = None,
     representation: tooltime.TimestampExtendedRepresentation | None = None,
     *,
     omit: str | None = 'year',
 ) -> None:
     """
     matplotlib.FuncFormatter not used, because it cannot use async
     """
 
     raw_blocks, labels = plt.xticks()
     blocks = [int(block) for block in raw_blocks]
     block_timestamps = await evm.async_predict_block_timestamps(
-        blocks, provider=provider
+        blocks, context=context
     )
 
     if representation is None:
         if len(block_timestamps) < 2:
             representation = 'TimestampDate'
         else:
             interval = block_timestamps[1] - block_timestamps[0]
```

### Comparing `checkthechain-0.3.0/src/ctc/toolbox/search_utils.py` & `checkthechain-0.3.4/src/ctc/toolbox/search_utils.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/tests/ctc/binary/.hypothesis/unicode_data/13.0.0/charmap.json.gz` & `checkthechain-0.3.4/tests/ctc/binary/.hypothesis/unicode_data/13.0.0/charmap.json.gz`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/tests/ctc/binary/test_eip712.py` & `checkthechain-0.3.4/tests/ctc/binary/test_eip712.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/tests/ctc/binary/test_format_utils.py` & `checkthechain-0.3.4/tests/ctc/binary/test_format_utils.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/tests/ctc/binary/test_hash_utils.py` & `checkthechain-0.3.4/tests/ctc/binary/test_hash_utils.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/tests/ctc/binary/test_rlp_encoding.py` & `checkthechain-0.3.4/tests/ctc/binary/test_rlp_encoding.py`

 * *Files 2% similar despite different names*

```diff
@@ -7,24 +7,23 @@
     [0, '0x80'],
     [15, '0x0f'],
     [1024, '0x820400'],
     #
     # str
     [
         'dog',
-        evm.binary_convert(bytes.fromhex('83') + 'dog'.encode(), 'prefix_hex'),
+        evm.to_hex(bytes.fromhex('83') + 'dog'.encode()),
     ],
     [
         ['cat', 'dog'],
-        evm.binary_convert(
+        evm.to_hex(
             bytes.fromhex('c883')
             + 'cat'.encode()
             + bytes.fromhex('83')
-            + 'dog'.encode(),
-            'prefix_hex',
+            + 'dog'.encode()
         ),
     ],
     #
     # lists
     [[], '0xc0'],
     [
         [[], [[]], [[], [[]]]],
@@ -174,7 +173,8 @@
 
 
 @pytest.mark.parametrize('test', zip(nonces, encoded_address_nonce_tuples))
 def test_rlp_encode_address_integer_tuples(test):
     nonce, target_encoding = test
 
     assert evm.rlp_encode([address, nonce], str_mode='hex') == target_encoding
+
```

### Comparing `checkthechain-0.3.0/tests/ctc/binary/test_signatures.py` & `checkthechain-0.3.4/tests/ctc/binary/test_signatures.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/tests/ctc/cli/test_cli_args.py` & `checkthechain-0.3.4/tests/ctc/cli/test_cli_args.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/tests/ctc/cli/test_cli_subcommands.py` & `checkthechain-0.3.4/tests/ctc/cli/test_cli_subcommands.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/tests/ctc/config/test_config_defaults.py` & `checkthechain-0.3.4/tests/ctc/config/test_config_defaults.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/tests/ctc/config/test_config_validators.py` & `checkthechain-0.3.4/tests/ctc/config/test_config_validators.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,19 +1,21 @@
 import pytest
 
 from ctc import spec
-from ctc.spec import typedefs
+from ctc.spec.typedefs import config_types
 from ctc.config import config_defaults
 from ctc.config import config_validate
 
 
-default_db_configs = config_defaults.get_default_db_configs('/path/to/data')
+default_db_configs = config_defaults.get_default_db_configs(
+    data_dir='/path/to/data'
+)
 
 valid_values = {
-    'config_spec_version': ['0.3.0'],
+    'config_spec_version': ['0.3.1'],
     'data_dir': ['/path/to/data'],
     'networks': [
         {
             1: {
                 'name': 'mainnet',
                 'chain_id': 1,
                 'block_explorer': 'etherscan.io',
@@ -34,37 +36,39 @@
                 'name': 'test_provider',
                 'url': 'http://some_url.com',
                 'network': 1,
                 'protocol': 'http',
                 'session_kwargs': {},
                 'chunk_size': None,
                 'convert_reverts_to_none': False,
+                'disable_batch_requests': True,
             },
         },
         {
             'test_provider': {
                 'name': 'test_provider',
                 'url': 'https://some_url.com',
                 'network': 1,
                 'protocol': 'http',
                 'session_kwargs': {},
                 'chunk_size': None,
                 'convert_reverts_to_none': False,
+                'disable_batch_requests': True,
             },
         },
     ],
     'default_network': [1],
     'default_providers': [{}],
     'db_configs': [default_db_configs],
     'log_rpc_calls': [True, False],
     'log_sql_queries': [True, False],
 }
 
 invalid_values = {
-    'config_spec_version': ['0.3.0b', '0.2.10', None],
+    'config_spec_version': ['0.2.10', None],
     'data_dir': ['relpath/to/data'],
     'networks': [
         {
             'mainnet': {
                 'name': 'mainnet',
                 'chain_id': 1,
                 'block_explorer': 'etherscan.io',
@@ -85,51 +89,51 @@
                 'name': 'test_provider',
                 'url': 'some_url.com',
                 'network': 1,
                 'protocol': 'http',
                 'session_kwargs': {},
                 'chunk_size': None,
                 'convert_reverts_to_none': False,
+                'disable_batch_requests': True,
             },
         },
         {
             'test_provider': {
                 'name': 'test_provider_different_name',
                 'url': 'some_url.com',
                 'network': 1,
                 'protocol': 'http',
                 'session_kwargs': {},
                 'chunk_size': None,
                 'convert_reverts_to_none': False,
+                'disable_batch_requests': True,
             },
         },
     ],
     'default_network': [888, 'mainnet'],
     'default_providers': [{888: None}, {'mainnet': None}],
     'db_configs': [
         {},
-        dict(default_db_configs, main2=default_db_configs['main']),
     ],
     'log_rpc_calls': [None, 'a', 2],
     'log_sql_queries': [None, 'a', 2],
 }
 
 
 def test_every_config_key_has_validator_entry():
-    config_spec = list(typedefs.Config.__annotations__.keys())
+    config_spec = list(config_types.Config.__annotations__.keys())
     config_validators = config_validate.get_config_validators()
     for key in config_spec:
         assert key in config_validators
     for key in config_validators:
         assert key in config_spec
 
 
 @pytest.mark.parametrize('item', list(valid_values.items()))
 def test_validate_valid_config_values(item):
-
     key, values = item
 
     base_type = config_validate.get_config_base_types()[key]
     validator = config_validate.get_config_validators()[key]
     default_config = config_defaults.get_default_config()
 
     for value in values:
@@ -148,7 +152,8 @@
 
     for value in values:
         if not isinstance(value, base_type):
             continue
         if validator is not None:
             with pytest.raises(spec.ConfigInvalid):
                 validator(value, default_config)
+
```

### Comparing `checkthechain-0.3.0/tests/ctc/config/test_setup.py` & `checkthechain-0.3.4/tests/ctc/config/test_setup.py`

 * *Files 1% similar despite different names*

```diff
@@ -221,15 +221,15 @@
         rpc_chain_id=1,
     )
     assert os.path.isfile(db_path)
 
 
 old_config__0_2_10 = {
     'config_spec_version': '0.2.10',
-    'data_dir': '/home/storm/ctc_data',
+    'data_dir': os.path.expanduser('~/ctc_data'),
     'providers': {
         'example_provider_1': {
             'url': 'https://example_provider.com',
             'name': 'example_provider_1',
             'network': 1,
             'protocol': 'http',
             'session_kwargs': {},
@@ -263,34 +263,35 @@
         'default_providers': {
             'mainnet': 'example_provider_1',
             'arbitrum': 'example_provider_2',
         },
     },
 }
 
+old_config__0_3_0 = upgrade_utils.upgrade__0_2_0__to__0_3_0(old_config__0_2_10)
 
 default_config = config_defaults.get_default_config()
 
 old_config_examples = [
     #
     # 0.2.10 style config
     old_config__0_2_10,
     #
     # blank old config
     {},
     #
-    # 0.3.0 style default config
+    # current style default config
     default_config,
     #
     # default config with small changes
     dict(
         default_config,
         data_dir=tempfile.mkdtemp(),
         providers={},
-        default_provider=None,
+        default_providers={},
     ),
 ]
 
 
 @pytest.mark.parametrize('old_config', old_config_examples)
 def test_ctc_setup__use_old_config(monkeypatch, old_config):
     # test that
@@ -315,15 +316,18 @@
 
     old_config_upgraded = upgrade_utils.upgrade_config(old_config)
 
     # now, check that old_config values are preserved if they were valid
     new_config = get_ctc_config()
 
     # check that current ctc value is used
-    assert new_config['config_spec_version'] == ctc.__version__
+    assert new_config['config_spec_version'] in [
+        ctc.__version__,
+        upgrade_utils.get_stable_version(ctc.__version__),
+    ]
 
     # check that providers are preserved
     assert len(old_config_upgraded['providers']) == len(new_config['providers'])
 
     # check that default network is preserved
     assert (
         old_config_upgraded.get('default_network')
```

### Comparing `checkthechain-0.3.0/tests/ctc/db/db_crud/test_db_block_timestamps.py` & `checkthechain-0.3.4/tests/ctc/db/db_crud/test_db_block_timestamps.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,14 +1,13 @@
-import os
-import tempfile
-
 import toolsql
 
 from ctc import db
 
+import conftest
+
 
 example_data = [
     {
         'block_number': 14000000,
         'timestamp': 1642114795,
     },
     {
@@ -46,101 +45,79 @@
     {
         'block_number': 14000009,
         'timestamp': 1642114917,
     },
 ]
 
 
-def get_test_db_config():
-    tempdir = tempfile.mkdtemp()
-    return {
-        'dbms': 'sqlite',
-        'path': os.path.join(tempdir, 'example.db'),
-    }
-
-
 async def test_block_timestamps_db():
-    db_config = get_test_db_config()
+    db_config = conftest.get_test_db_config()
     db_schema = db.get_prepared_schema(
         schema_name='block_timestamps',
-        network='mainnet',
+        context=dict(network='ethereum'),
     )
-    toolsql.create_tables(
+    toolsql.create_db(
         db_config=db_config,
         db_schema=db_schema,
+        if_not_exists=True,
+        confirm=True,
     )
 
-    engine = toolsql.create_engine(**db_config)
-
-    # insert data
-    with engine.connect() as conn:
-
-        #         # insert data in bulk
-        #         with conn.begin():
-        #             data = {
-        #                 datum['block_number']: datum['timestamp']
-        #                 for datum in example_data
-        #             }
-        #             db.set_blocks_timestamps(
-        #                 conn=conn,
-        #                 blocks_timestamps=data,
-        #             )
-
-        # insert data one-by-one
-        with conn.begin():
-            for datum in example_data:
-                await db.async_upsert_block_timestamp(conn=conn, **datum)
-
-        # get data individually
-        with conn.begin():
-            for datum in example_data:
-                timestamp = await db.async_select_block_timestamp(
-                    conn=conn,
-                    block_number=datum['block_number'],
-                )
-                assert timestamp == datum['timestamp']
-
-        # get data collectively
-        all_blocks = [datum['block_number'] for datum in example_data]
-        all_timestamps = [datum['timestamp'] for datum in example_data]
-        with conn.begin():
-            stored_timestamps = await db.async_select_block_timestamps(
+    # insert data one-by-one
+    async with toolsql.async_connect(db_config) as conn:
+        for datum in example_data:
+            await db.async_upsert_block_timestamp(conn=conn, **datum)
+
+    # get data individually
+    async with toolsql.async_connect(db_config) as conn:
+        for datum in example_data:
+            timestamp = await db.async_select_block_timestamp(
                 conn=conn,
-                block_numbers=all_blocks,
+                block_number=datum['block_number'],
             )
-            assert set(stored_timestamps) == set(all_timestamps)
+            assert timestamp == datum['timestamp']
 
-        # delete entries one by one
-        with conn.begin():
-            for datum in example_data:
-                await db.async_delete_block_timestamp(
-                    conn=conn,
-                    block_number=datum['block_number'],
-                )
-
-        # ensure all entries deleted
-        with conn.begin():
-            stored_timestamps = await db.async_select_block_timestamps(
+    # get data collectively
+    all_blocks = [datum['block_number'] for datum in example_data]
+    all_timestamps = [datum['timestamp'] for datum in example_data]
+    async with toolsql.async_connect(db_config) as conn:
+        stored_timestamps = await db.async_select_block_timestamps(
+            conn=conn,
+            block_numbers=all_blocks,
+        )
+        assert set(stored_timestamps) == set(all_timestamps)
+
+    # delete entries one by one
+    async with toolsql.async_connect(db_config) as conn:
+        for datum in example_data:
+            await db.async_delete_block_timestamp(
                 conn=conn,
-                block_numbers=all_blocks,
+                block_number=datum['block_number'],
             )
-            assert set(stored_timestamps) == {None}
 
-        # insert data again
-        with conn.begin():
-            for datum in example_data:
-                await db.async_upsert_block_timestamp(conn=conn, **datum)
-
-        # delete entries all at once
-        with conn.begin():
-            await db.async_delete_block_timestamps(
-                conn=conn,
-                block_numbers=all_blocks,
-            )
-
-        # ensure all entries deleted
-        with conn.begin():
-            stored_timestamps = await db.async_select_block_timestamps(
-                conn=conn,
-                block_numbers=all_blocks,
-            )
-            assert set(stored_timestamps) == {None}
+    # ensure all entries deleted
+    async with toolsql.async_connect(db_config) as conn:
+        stored_timestamps = await db.async_select_block_timestamps(
+            conn=conn,
+            block_numbers=all_blocks,
+        )
+        assert set(stored_timestamps) == {None}
+
+    # insert data again
+    async with toolsql.async_connect(db_config) as conn:
+        for datum in example_data:
+            await db.async_upsert_block_timestamp(conn=conn, **datum)
+
+    # delete entries all at once
+    async with toolsql.async_connect(db_config) as conn:
+        await db.async_delete_block_timestamps(
+            conn=conn,
+            block_numbers=all_blocks,
+        )
+
+    # ensure all entries deleted
+    async with toolsql.async_connect(db_config) as conn:
+        stored_timestamps = await db.async_select_block_timestamps(
+            conn=conn,
+            block_numbers=all_blocks,
+        )
+        assert set(stored_timestamps) == {None}
```

### Comparing `checkthechain-0.3.0/tests/ctc/db/db_crud/test_db_blocks.py` & `checkthechain-0.3.4/tests/ctc/db/db_crud/test_db_blocks.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,13 +1,14 @@
-import os
-import tempfile
 import toolsql
 
+import ctc
 from ctc import db
 
+import conftest
+
 
 example_data = [
     {
         'number': 100,
         'difficulty': 17916437174,
         'extra_data': '0x476574682f4c5649562f76312e302e302f6c696e75782f676f312e342e32',
         'gas_limit': 5000,
@@ -70,81 +71,75 @@
         'total_difficulty': '1802617262413',
         'transactions': [],
         'transactions_root': '0x56e81f171bcc55a6ff8345e692c0f86e5b48e01b996cadc001622fb5e363b421',
         'uncles': [],
     },
 ]
 
-
-def get_test_db_config():
-    tempdir = tempfile.mkdtemp()
-    return {
-        'dbms': 'sqlite',
-        'path': os.path.join(tempdir, 'example.db'),
-    }
+example_data = [
+    ctc.convert_rpc_block_to_db_block(block) for block in example_data
+]
 
 
 async def test_blocks_crud():
 
-    db_config = get_test_db_config()
+    db_config = conftest.get_test_db_config()
     db_schema = db.get_prepared_schema(
         schema_name='blocks',
-        network='mainnet',
+        context=dict(network='ethereum'),
     )
-    toolsql.create_tables(
+    toolsql.create_db(
         db_config=db_config,
         db_schema=db_schema,
+        if_not_exists=True,
+        confirm=True,
     )
 
-    engine = toolsql.create_engine(**db_config)
-
     network = 1
 
     # insert data
-    with engine.connect() as conn:
+    async with toolsql.async_connect(db_config) as conn:
+        for block in example_data:
+            await db.async_upsert_block(
+                conn=conn, block=block, context=dict(network=network)
+            )
 
-        # insert data
-        with conn.begin():
-            for block in example_data:
-                await db.async_upsert_block(
-                    conn=conn, block=block, network=network
-                )
-
-        # get data individually
-        with conn.begin():
-            for block in example_data:
-                db_block = await db.async_select_block(
-                    conn=conn,
-                    block_number=block['number'],
-                    network=network,
-                )
-                for key, target_value in block.items():
-                    assert target_value == db_block[key]
-
-        # get data collectively
-        with conn.begin():
-            block_numbers = [block['number'] for block in example_data]
-            db_blocks = await db.async_select_blocks(
+    # get data individually
+    async with toolsql.async_connect(db_config) as conn:
+        for block in example_data:
+            db_block = await db.async_select_block(
                 conn=conn,
-                block_numbers=block_numbers,
-                network=network,
+                block_number=block['number'],
+                context=dict(network=network),
             )
-            db_blocks = sorted(db_blocks, key=lambda block: block['number'])
-            assert db_blocks == example_data
+            for key, target_value in block.items():
+                assert target_value == db_block[key]
 
-        # delete entries one by one
-        with conn.begin():
-            for block in example_data:
-                await db.async_delete_block(
-                    conn=conn,
-                    block_number=block['number'],
-                    network=network,
-                )
-
-        # ensure all entries deleted
-        with conn.begin():
-            db_blocks = await db.async_select_blocks(
+    # get data collectively
+    async with toolsql.async_connect(db_config) as conn:
+        block_numbers = [block['number'] for block in example_data]
+        db_blocks = await db.async_select_blocks(
+            conn=conn,
+            block_numbers=block_numbers,
+            context=dict(network=network),
+        )
+        db_blocks = sorted(db_blocks, key=lambda block: block['number'])
+        assert db_blocks == example_data
+
+    # delete entries one by one
+    async with toolsql.async_connect(db_config) as conn:
+        for block in example_data:
+            await db.async_delete_block(
                 conn=conn,
-                block_numbers=block_numbers,
-                network=network,
+                block_number=block['number'],
+                context=dict(network=network),
             )
-            assert all(item is None for item in db_blocks)
+
+    # ensure all entries deleted
+    async with toolsql.async_connect(db_config) as conn:
+        db_blocks = await db.async_select_blocks(
+            conn=conn,
+            block_numbers=block_numbers,
+            context=dict(network=network),
+        )
+        assert all(item is None for item in db_blocks)
+
```

### Comparing `checkthechain-0.3.0/tests/ctc/db/db_crud/test_db_contract_abis.py` & `checkthechain-0.3.4/tests/ctc/db/db_crud/test_db_contract_creation.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,97 +1,69 @@
-import os
-import tempfile
 import toolsql
 
 from ctc import db
 
+import conftest
+
 
 example_data = [
     {
         'address': '0x956f47f50a910163d8bf957cf5846d573e7f87ca',
-        'abi': {'fake': 'abi', 'nested': {'attribute': 'value'}},
-        'includes_proxy': False,
+        'block_number': 12125705,
+    },
+    {
+        'address': '0xc7283b66eb1eb5fb86327f08e1b5816b0720212b',
+        'block_number': 12125705,
     },
     {
-        'address': '0x9928e4046d7c6513326ccea028cd3e7a91c7590a',
-        'abi': {
-            'another_fake': 'abi',
-            'another_nested': {'attribute': 'value'},
-        },
-        'includes_proxy': False,
+        'address': '0xa0b86991c6218b36c1d19d4a2e9eb0ce3606eb48',
+        'block_number': 6082465,
     },
 ]
 
 
-def get_test_db_config():
-    tempdir = tempfile.mkdtemp()
-    return {
-        'dbms': 'sqlite',
-        'path': os.path.join(tempdir, 'example.db'),
-    }
-
-
-async def test_contract_abis_crud():
-
-    db_config = get_test_db_config()
+async def test_create_creation_blocks_crud():
+    db_config = conftest.get_test_db_config()
     db_schema = db.get_prepared_schema(
-        schema_name='contract_abis',
-        network='mainnet',
+        schema_name='contract_creation_blocks',
+        context=dict(network='ethereum'),
     )
-    toolsql.create_tables(
+    toolsql.create_db(
         db_config=db_config,
         db_schema=db_schema,
+        if_not_exists=True,
+        confirm=True,
     )
 
-    engine = toolsql.create_engine(**db_config)
-
     # insert data
-    with engine.connect() as conn:
+    async with toolsql.async_connect(db_config) as conn:
+        for datum in example_data:
+            await db.async_upsert_contract_creation_block(
+                conn=conn, **datum
+            )
+
+    # get data individually
+    async with toolsql.async_connect(db_config) as conn:
+        for datum in example_data:
+            stored_block = await db.async_select_contract_creation_block(
+                conn=conn,
+                address=datum['address'],
+            )
+            assert stored_block == datum['block_number']
 
-        # insert data
-        with conn.begin():
-            for datum in example_data:
-                await db.async_upsert_contract_abi(conn=conn, **datum)
-
-        # get data individually
-        with conn.begin():
-            for datum in example_data:
-                db_contract_abi = await db.async_select_contract_abi(
-                    conn=conn,
-                    address=datum['address'],
-                )
-                assert datum['abi'] == db_contract_abi
-                # for key, target_value in datum.items():
-                #     assert target_value == db_contract_abi[key]
-
-        # get data collectively
-        all_addresses = [datum['address'] for datum in example_data]
-        with conn.begin():
-            db_contract_abis = await db.async_select_contract_abis(
+    # delete entries one by one
+    async with toolsql.async_connect(db_config) as conn:
+        for datum in example_data:
+            await db.async_delete_contract_creation_block(
                 conn=conn,
-                addresses=all_addresses,
+                address=datum['address'],
             )
-            packaged_example_data = {
-                datum['address']: datum['abi'] for datum in example_data
-            }
-            assert db_contract_abis == packaged_example_data
-
-        # delete entries one by one
-        with conn.begin():
-            for datum in example_data:
-                await db.async_delete_contract_abi(
-                    conn=conn,
-                    address=datum['address'],
-                )
-
-        # ensure all entries deleted
-        with conn.begin():
-            db_contract_abis = await db.async_select_contract_abis(
+
+    # ensure all entries deleted
+    async with toolsql.async_connect(db_config) as conn:
+        for datum in example_data:
+            block = await db.async_select_contract_creation_block(
                 conn=conn,
-                addresses=all_addresses,
+                address=datum['address'],
             )
-            assert all(item is None for item in db_contract_abis)
+            assert block is None
 
-        # insert data again
-        with conn.begin():
-            for datum in example_data:
-                await db.async_upsert_contract_abi(conn=conn, **datum)
```

### Comparing `checkthechain-0.3.0/tests/ctc/db/db_crud/test_db_contract_creation.py` & `checkthechain-0.3.4/tests/ctc/db/db_crud/test_db_contract_abis.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,79 +1,87 @@
-import os
-import tempfile
 import toolsql
 
 from ctc import db
 
+import conftest
+
 
 example_data = [
     {
         'address': '0x956f47f50a910163d8bf957cf5846d573e7f87ca',
-        'block_number': 12125705,
-    },
-    {
-        'address': '0xc7283b66eb1eb5fb86327f08e1b5816b0720212b',
-        'block_number': 12125705,
+        'abi': {'fake': 'abi', 'nested': {'attribute': 'value'}},
+        'includes_proxy': False,
     },
     {
-        'address': '0xa0b86991c6218b36c1d19d4a2e9eb0ce3606eb48',
-        'block_number': 6082465,
+        'address': '0x9928e4046d7c6513326ccea028cd3e7a91c7590a',
+        'abi': {
+            'another_fake': 'abi',
+            'another_nested': {'attribute': 'value'},
+        },
+        'includes_proxy': False,
     },
 ]
 
 
-def get_test_db_config():
-    tempdir = tempfile.mkdtemp()
-    return {
-        'dbms': 'sqlite',
-        'path': os.path.join(tempdir, 'example.db'),
-    }
+async def test_contract_abis_crud():
 
-
-async def test_create_creation_blocks_crud():
-    db_config = get_test_db_config()
+    db_config = conftest.get_test_db_config()
     db_schema = db.get_prepared_schema(
-        schema_name='contract_creation_blocks',
-        network='mainnet',
+        schema_name='contract_abis',
+        context=dict(network='ethereum'),
     )
-    toolsql.create_tables(
+    toolsql.create_db(
         db_config=db_config,
         db_schema=db_schema,
+        if_not_exists=True,
+        confirm=True,
     )
 
-    engine = toolsql.create_engine(**db_config)
-
     # insert data
-    with engine.connect() as conn:
+    async with toolsql.async_connect(db_config) as conn:
+        for datum in example_data:
+            await db.async_upsert_contract_abi(conn=conn, **datum)
+
+    # get data individually
+    async with toolsql.async_connect(db_config) as conn:
+        for datum in example_data:
+            db_contract_abi = await db.async_select_contract_abi(
+                conn=conn,
+                address=datum['address'],
+            )
+            assert datum['abi'] == db_contract_abi
+            # for key, target_value in datum.items():
+            #     assert target_value == db_contract_abi[key]
+
+    # get data collectively
+    all_addresses = [datum['address'] for datum in example_data]
+    async with toolsql.async_connect(db_config) as conn:
+        db_contract_abis = await db.async_select_contract_abis(
+            conn=conn,
+            addresses=all_addresses,
+        )
+        packaged_example_data = {
+            datum['address']: datum['abi'] for datum in example_data
+        }
+        assert db_contract_abis == packaged_example_data
+
+    # delete entries one by one
+    async with toolsql.async_connect(db_config) as conn:
+        for datum in example_data:
+            await db.async_delete_contract_abi(
+                conn=conn,
+                address=datum['address'],
+            )
+
+    # ensure all entries deleted
+    async with toolsql.async_connect(db_config) as conn:
+        db_contract_abis = await db.async_select_contract_abis(
+            conn=conn,
+            addresses=all_addresses,
+        )
+        assert all(item is None for item in db_contract_abis)
+
+    # insert data again
+    async with toolsql.async_connect(db_config) as conn:
+        for datum in example_data:
+            await db.async_upsert_contract_abi(conn=conn, **datum)
 
-        # insert data
-        with conn.begin():
-            for datum in example_data:
-                await db.async_upsert_contract_creation_block(
-                    conn=conn, **datum
-                )
-
-        # get data individually
-        with conn.begin():
-            for datum in example_data:
-                stored_block = await db.async_select_contract_creation_block(
-                    conn=conn,
-                    address=datum['address'],
-                )
-                assert stored_block == datum['block_number']
-
-        # delete entries one by one
-        with conn.begin():
-            for datum in example_data:
-                await db.async_delete_contract_creation_block(
-                    conn=conn,
-                    address=datum['address'],
-                )
-
-        # ensure all entries deleted
-        with conn.begin():
-            for datum in example_data:
-                block = await db.async_select_contract_creation_block(
-                    conn=conn,
-                    address=datum['address'],
-                )
-                assert block is None
```

### Comparing `checkthechain-0.3.0/tests/ctc/db/db_crud/test_db_erc20_metadata.py` & `checkthechain-0.3.4/tests/ctc/db/db_crud/test_db_erc20_metadata.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,13 +1,13 @@
-import os
-import tempfile
 import toolsql
 
 from ctc import db
 
+import conftest
+
 
 example_data = [
     {
         'address': '0x956f47f50a910163d8bf957cf5846d573e7f87ca',
         'symbol': 'FEI',
         'decimals': 18,
         'name': 'Fei USD',
@@ -17,104 +17,92 @@
         'symbol': 'TRIBE',
         'decimals': 18,
         'name': 'Tribe',
     },
 ]
 
 
-def get_test_db_config():
-    tempdir = tempfile.mkdtemp()
-    return {
-        'dbms': 'sqlite',
-        'path': os.path.join(tempdir, 'example.db'),
-    }
-
-
 async def test_erc20_metadata_crud():
-    db_config = get_test_db_config()
+    db_config = conftest.get_test_db_config()
     db_schema = db.get_prepared_schema(
         schema_name='erc20_metadata',
-        network='mainnet',
+        context=dict(network='ethereum'),
     )
-    toolsql.create_tables(
+    toolsql.create_db(
         db_config=db_config,
         db_schema=db_schema,
+        if_not_exists=True,
+        confirm=True,
     )
 
-    engine = toolsql.create_engine(**db_config)
-
     # insert data
-    with engine.connect() as conn:
-
-        # insert data
-        with conn.begin():
-            await db.async_upsert_erc20s_metadata(
-                conn=conn,
-                erc20s_metadata=example_data,
-                network=1,
-            )
-
-        # get data individually
-        with conn.begin():
-            for datum in example_data:
-                actual_metadata = await db.async_select_erc20_metadata(
-                    conn=conn,
-                    address=datum['address'],
-                )
-                for key, target_value in datum.items():
-                    assert target_value == actual_metadata[key]
-
-        # get data collectively
-        all_addresses = [datum['address'] for datum in example_data]
-        with conn.begin():
-            actual_metadatas = await db.async_select_erc20s_metadata(
+    async with toolsql.async_connect(db_config) as conn:
+        await db.async_upsert_erc20s_metadata(
+            conn=conn,
+            erc20s_metadata=example_data,
+            context=dict(network=1),
+        )
+
+    # get data individually
+    async with toolsql.async_connect(db_config) as conn:
+        for datum in example_data:
+            actual_metadata = await db.async_select_erc20_metadata(
                 conn=conn,
-                addresses=all_addresses,
-            )
-            sorted_example_data = sorted(
-                example_data, key=lambda x: x['address']
+                address=datum['address'],
             )
-            sorted_actual_data = sorted(
-                actual_metadatas, key=lambda x: x['address']
-            )
-            for target, actual in zip(sorted_example_data, sorted_actual_data):
-                assert target == actual
+            for key, target_value in datum.items():
+                assert target_value == actual_metadata[key]
 
-        # delete entries one by one
-        with conn.begin():
-            for datum in example_data:
-                await db.async_delete_erc20_metadata(
-                    conn=conn,
-                    address=datum['address'],
-                    network=1,
-                )
-
-        # ensure all entries deleted
-        with conn.begin():
-            actual_metadatas = await db.async_select_erc20s_metadata(
+    # get data collectively
+    all_addresses = [datum['address'] for datum in example_data]
+    async with toolsql.async_connect(db_config) as conn:
+        actual_metadatas = await db.async_select_erc20s_metadata(
+            conn=conn,
+            addresses=all_addresses,
+        )
+        sorted_example_data = sorted(example_data, key=lambda x: x['address'])
+        sorted_actual_data = sorted(
+            actual_metadatas, key=lambda x: x['address']
+        )
+        for target, actual in zip(sorted_example_data, sorted_actual_data):
+            assert target == actual
+
+    # delete entries one by one
+    async with toolsql.async_connect(db_config) as conn:
+        for datum in example_data:
+            await db.async_delete_erc20_metadata(
                 conn=conn,
-                addresses=all_addresses,
+                address=datum['address'],
+                context=dict(network=1),
             )
-            assert all(item is None for item in actual_metadatas)
 
-        # insert data again
-        with conn.begin():
-            for datum in example_data:
-                await db.async_upsert_erc20_metadata(
-                    conn=conn, network=1, **datum
-                )
-
-        # delete entries all at once
-        with conn.begin():
-            await db.async_delete_erc20s_metadata(
-                conn=conn,
-                addresses=all_addresses,
-                network=1,
-            )
+    # ensure all entries deleted
+    async with toolsql.async_connect(db_config) as conn:
+        actual_metadatas = await db.async_select_erc20s_metadata(
+            conn=conn,
+            addresses=all_addresses,
+        )
+        assert all(item is None for item in actual_metadatas)
+
+    # insert data again
+    async with toolsql.async_connect(db_config) as conn:
+        for datum in example_data:
+            await db.async_upsert_erc20_metadata(
+                conn=conn, context=dict(network=1), **datum
+            )
+
+    # delete entries all at once
+    async with toolsql.async_connect(db_config) as conn:
+        await db.async_delete_erc20s_metadata(
+            conn=conn,
+            addresses=all_addresses,
+            context=dict(network=1),
+        )
+
+    # ensure all entries deleted
+    async with toolsql.async_connect(db_config) as conn:
+        actual_metadatas = await db.async_select_erc20s_metadata(
+            conn=conn,
+            addresses=all_addresses,
+        )
+        assert all(item is None for item in actual_metadatas)
 
-        # ensure all entries deleted
-        with conn.begin():
-            actual_metadatas = await db.async_select_erc20s_metadata(
-                conn=conn,
-                addresses=all_addresses,
-            )
-            assert all(item is None for item in actual_metadatas)
```

### Comparing `checkthechain-0.3.0/tests/ctc/db/test_crud_problems.py` & `checkthechain-0.3.4/tests/ctc/db/test_crud_problems.py`

 * *Files 7% similar despite different names*

```diff
@@ -5,14 +5,16 @@
 import toolsql
 
 from ctc import db
 from ctc.protocols.chainlink_utils import chainlink_db
 from ctc.protocols import fourbyte_utils
 from ctc.protocols.coingecko_utils import coingecko_db
 
+import conftest
+
 
 schema_datas = [
     {
         'schema_name': 'block_timestamps',
         'selector': db.schemas.block_timestamps.async_select_block_timestamp,
         'queryer': db.schemas.block_timestamps.async_query_block_timestamp,
         'query': {'block_number': 100},
@@ -105,199 +107,216 @@
         # 'query': {'address': '0x31e0a88fecb6ec0a411dbe0e9e76391498296ee9'},
         'plural_selector': fourbyte_utils.async_select_function_signatures,
         'plural_queryer': fourbyte_utils.async_query_function_signatures,
         'plural_query': {
             'text_signature': 'transfer(address,uint256)',
         },
     },
-    {
-        'schema_name': 'coingecko',
-        'selector': coingecko_db.async_select_token,
-        'queryer': coingecko_db.async_query_token,
-        'query': {'id': '1244-s-avers'},
-        'plural_selector': coingecko_db.async_select_tokens,
-        'plural_queryer': coingecko_db.async_query_tokens,
-        'plural_query': {
-            'symbol_query': 'eth',
-        },
-    },
+    # {
+    #     'schema_name': 'coingecko',
+    #     'selector': coingecko_db.async_select_token,
+    #     'queryer': coingecko_db.async_query_token,
+    #     'query': {'id': '1244-s-avers'},
+    #     'plural_selector': coingecko_db.async_select_tokens,
+    #     'plural_queryer': coingecko_db.async_query_tokens,
+    #     'plural_query': {
+    #         'symbol_query': 'eth',
+    #     },
+    # },
     {
         'schema_name': 'block_gas',
         'selector': db.async_select_median_block_gas_fee,
         'queryer': db.async_query_median_block_gas_fee,
         'query': {'block_number': 14000000},
         'plural_selector': db.async_select_median_blocks_gas_fees,
         'plural_queryer': db.async_query_median_blocks_gas_fees,
         'plural_query': {'block_numbers': [14000000, 14000001, 14000002]},
     },
+    {
+        'schema_name': 'events',
+        'plural_selector': db.async_select_event_queries,
+        'plural_queryer': db.async_query_event_queries,
+        'plural_query': {
+            'query_type': 3,
+            'contract_address': '0x6b175474e89094c44da98b954eedeac495271d0f',
+            'start_block': 14000000,
+            'end_block': 14000000,
+        },
+    },
+    {
+        'schema_name': 'transactions',
+        'selector': db.async_select_transaction,
+        'queryer': db.async_query_transaction,
+        'query': {
+            'hash': '0xaef402056d26796c49a7cdc0be9fa09f193e48458a1829dd788c38a8ae143683'
+        },
+        'plural_selector': db.async_select_transactions,
+        'plural_queryer': db.async_query_transactions,
+        'plural_query': {
+            'hashes': [
+                '0xaef402056d26796c49a7cdc0be9fa09f193e48458a1829dd788c38a8ae143683',
+                '0xb451a6aa6a5a0f30b62ea616f581b8f4c9a2e52091a6787591c5941be9995f75',
+                '0x3ccc6a654fd68a2a2303c9ef2a54512890c96376016a50c83f227ef705d27a05',
+            ]
+        },
+    },
 ]
 
 non_network_schemas = (
     db.get_generic_schema_names() + db.get_admin_schema_names()
 )
 
 
-def get_test_db_config():
-    tempdir = tempfile.mkdtemp()
-    return {
-        'dbms': 'sqlite',
-        'path': os.path.join(tempdir, 'example.db'),
-    }
-
-
 def test_all_evm_schemas_tested_for_problems():
     tested = {schema_datum['schema_name'] for schema_datum in schema_datas}
+    tested |= {'coingecko'}
     assert tested == set(
         db.get_network_schema_names() + db.get_generic_schema_names()
     ), 'not all EVM schema types being tested for common db problems'
 
 
 @pytest.mark.parametrize('schema_data', schema_datas)
 async def test_select_when_db_folder_does_not_exist(schema_data):
 
     dne_dir = os.path.join(tempfile.mkdtemp(), 'does', 'not', 'exist')
     assert not os.path.isdir(dne_dir)
+    dne_path = os.path.join(dne_dir, 'ctc.db')
 
-    db_config = {
-        'dbms': 'sqlite',
-        'path': dne_dir,
-    }
-    engine = toolsql.create_engine(**db_config)
+    db_config = {'dbms': 'sqlite', 'path': dne_path}
 
     if schema_data.get('queryer') is not None:
-        result = await schema_data['queryer'](network=1, engine=engine)
+        result = await schema_data['queryer'](
+            context=dict(network=1),
+            db_config=db_config,
+            **schema_data['query'],
+        )
 
         assert result is None
 
 
 @pytest.mark.parametrize('schema_data', schema_datas)
 async def test_select_when_db_file_does_not_exist(schema_data):
-
-    db_config = get_test_db_config()
-    engine = toolsql.create_engine(**db_config)
-
+    db_config = conftest.get_test_db_config()
     if schema_data.get('queryer') is not None:
         result = await schema_data['queryer'](
-            network=1, engine=engine, **schema_data['query']
+            context=dict(network=1), db_config=db_config, **schema_data['query']
         )
 
         assert result is None
 
 
 @pytest.mark.parametrize('schema_data', schema_datas)
 async def test_select_when_schema_not_initialized(schema_data):
 
-    db_config = get_test_db_config()
-    engine = toolsql.create_engine(**db_config)
-    with engine.begin() as conn:
+    db_config = conftest.get_test_db_config()
+    with toolsql.connect(db_config) as conn:
         db.initialize_schema_versions(conn=conn)
 
     if schema_data['schema_name'] not in non_network_schemas:
-        network_kwargs = {'network': 1}
+        network_kwargs = {'context': {'network': 1}}
     else:
         network_kwargs = {}
 
     if schema_data.get('selector') is not None:
-        with engine.begin() as conn:
-            result = await schema_data['selector'](
-                conn=conn, **schema_data['query'], **network_kwargs
-            )
-
-        assert result is None
+        with pytest.raises(toolsql.TableDoesNotExist):
+            async with toolsql.async_connect(db_config) as conn:
+                await schema_data['selector'](
+                    conn=conn, **schema_data['query'], **network_kwargs
+                )
 
     if 'plural_selector' in schema_data:
-        with engine.begin() as conn:
-            result = await schema_data['plural_selector'](
-                conn=conn,
-                **schema_data['plural_query'],
-                **network_kwargs,
-            )
-
-        assert result is None
+        with pytest.raises(toolsql.TableDoesNotExist):
+            async with toolsql.async_connect(db_config) as conn:
+                await schema_data['plural_selector'](
+                    conn=conn,
+                    **schema_data['plural_query'],
+                    **network_kwargs,
+                )
 
 
 @pytest.mark.parametrize('schema_data', schema_datas)
 async def test_query_when_schema_not_initialized(schema_data):
-
-    db_config = get_test_db_config()
-    engine = toolsql.create_engine(**db_config)
-    with engine.begin() as conn:
+    db_config = conftest.get_test_db_config()
+    with toolsql.connect(db_config) as conn:
         db.initialize_schema_versions(conn=conn)
 
     if schema_data['schema_name'] not in non_network_schemas:
-        network_kwargs = {'network': 1}
+        network_kwargs = {'context': {'network': 1}}
     else:
-        network_kwargs = {}
+        network_kwargs = {'context': None}
 
     if schema_data.get('queryer') is not None:
         result = await schema_data['queryer'](
-            engine=engine, **schema_data['query'], **network_kwargs
+            db_config=db_config,
+            **schema_data['query'],
+            **network_kwargs,
         )
 
         assert result is None
 
 
-@pytest.mark.parametrize('schema_data', schema_datas)
-async def test_select_when_row_does_not_exist(schema_data):
-
-    db_config = get_test_db_config()
-    engine = toolsql.create_engine(**db_config)
-    with engine.begin() as conn:
-        if schema_data['schema_name'] not in non_network_schemas:
-            network_kwargs = {'network': 1}
-        else:
-            network_kwargs = {'network': None}
-
-        db.initialize_schema(
-            schema_name=schema_data['schema_name'], conn=conn, **network_kwargs
-        )
-
-    if schema_data['schema_name'] not in non_network_schemas:
-        network_kwargs = {'network': 1}
-    else:
-        network_kwargs = {}
-
-    if schema_data.get('selector') is not None:
-        with engine.begin() as conn:
-            result = await schema_data['selector'](
-                conn=conn, **schema_data['query'], **network_kwargs
-            )
+# @pytest.mark.parametrize('schema_data', schema_datas)
+# async def test_select_when_row_does_not_exist(schema_data):
+#     db_config = conftest.get_test_db_config()
+#     with toolsql.connect(db_config) as conn:
+#         if schema_data['schema_name'] not in non_network_schemas:
+#             network_kwargs = {'context': {'network': 1}}
+#         else:
+#             network_kwargs = {'context': {'network': None}}
+
+#         db.initialize_schema(
+#             schema_name=schema_data['schema_name'], conn=conn, **network_kwargs
+#         )
+
+#     if schema_data['schema_name'] not in non_network_schemas:
+#         network_kwargs = {'context': {'network': 1}}
+#     else:
+#         network_kwargs = {}
+
+#     if schema_data.get('selector') is not None:
+#         async with toolsql.async_connect(db_config) as conn:
+#             result = await schema_data['selector'](
+#                 conn=conn, **schema_data['query'], **network_kwargs
+#             )
+
+#         assert result is None
+
+#     if 'plural_selector' in schema_data:
+#         async with toolsql.async_connect(db_config) as conn:
+#             result = await schema_data['plural_selector'](
+#                 conn=conn,
+#                 **schema_data['plural_query'],
+#                 **network_kwargs,
+#             )
 
-        assert result is None
-
-    if 'plural_selector' in schema_data:
-        with engine.begin() as conn:
-            result = await schema_data['plural_selector'](
-                conn=conn,
-                **schema_data['plural_query'],
-                **network_kwargs,
-            )
-
-        assert result is None or all(item is None for item in result)
+#         assert result is None or all(item is None for item in result)
 
 
 @pytest.mark.parametrize('schema_data', schema_datas)
 async def test_query_when_row_does_not_exist(schema_data):
-
-    db_config = get_test_db_config()
-    engine = toolsql.create_engine(**db_config)
-    with engine.begin() as conn:
+    db_config = conftest.get_test_db_config()
+    with toolsql.connect(db_config) as conn:
         if schema_data['schema_name'] not in non_network_schemas:
-            network_kwargs = {'network': 1}
+            network_kwargs = {'context': {'network': 1}}
         else:
-            network_kwargs = {'network': None}
+            network_kwargs = {'context': {'network': None}}
 
         db.initialize_schema(
-            schema_name=schema_data['schema_name'], conn=conn, **network_kwargs
+            schema_name=schema_data['schema_name'],
+            conn=conn,
+            **network_kwargs,
         )
 
     if schema_data.get('queryer') is not None:
         if schema_data['schema_name'] not in non_network_schemas:
-            network_kwargs = {'network': 1}
+            network_kwargs = {'context': {'network': 1}}
         else:
-            network_kwargs = {}
+            network_kwargs = {'context': None}
 
         result = await schema_data['queryer'](
-            engine=engine, **schema_data['query'], **network_kwargs
+            db_config=db_config,
+            **schema_data['query'],
+            **network_kwargs,
         )
 
         assert result is None
+
```

### Comparing `checkthechain-0.3.0/tests/ctc/directory/.hypothesis/unicode_data/13.0.0/charmap.json.gz` & `checkthechain-0.3.4/tests/ctc/directory/.hypothesis/unicode_data/13.0.0/charmap.json.gz`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/tests/ctc/directory/test_directory_networks.py` & `checkthechain-0.3.4/tests/ctc/directory/test_directory_networks.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,54 +1,50 @@
 
 import pytest
-import toolconfig
 
 from ctc import evm
-from ctc.spec import typedefs
+from ctc.spec.typedefs import network_types
 from ctc.config import config_defaults
 
 
 @pytest.mark.parametrize(
     'test',
     [
-        [1, 'mainnet'],
-        ['mainnet', 'mainnet'],
+        [1, 'ethereum'],
+        ['ethereum', 'ethereum'],
         [3, 'ropsten'],
     ],
 )
 def test_get_network_name(test):
     network_reference, network_name = test
 
     actual_network_name = evm.get_network_name(network=network_reference)
     assert actual_network_name == network_name
 
 
 @pytest.mark.parametrize(
     'test',
     [
         [1, 1],
-        ['mainnet', 1],
+        ['ethereum', 1],
         ['ropsten', 3],
     ],
 )
 def test_get_chain_id(test):
     network_reference, network_chain_id = test
 
     actual_network_chain_id = evm.get_network_chain_id(
         network=network_reference
     )
     assert actual_network_chain_id == network_chain_id
 
 
 def test_get_network_metadata():
     metadata = evm.get_network_metadata(network=1)
-    assert metadata['name'] == 'mainnet'
+    assert metadata['name'] == 'ethereum'
     assert metadata['chain_id'] == 1
     assert metadata['block_explorer'] == 'etherscan.io'
 
 
 def test_get_networks():
-    networks = config_defaults.get_default_networks_metadata()
-    for network_metadata in networks.values():
-        toolconfig.conforms_to_spec(
-            data=network_metadata, spec=typedefs.NetworkMetadata
-        )
+    config_defaults.get_default_networks_metadata()
+
```

### Comparing `checkthechain-0.3.0/tests/ctc/directory/test_directory_tokens.py` & `checkthechain-0.3.4/tests/ctc/directory/test_directory_tokens.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/tests/ctc/docs/test_readme_examples.py` & `checkthechain-0.3.4/tests/ctc/docs/test_readme_examples.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/tests/ctc/evm/.hypothesis/unicode_data/13.0.0/charmap.json.gz` & `checkthechain-0.3.4/tests/ctc/evm/.hypothesis/unicode_data/13.0.0/charmap.json.gz`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/tests/ctc/evm/test_address_utils.py` & `checkthechain-0.3.4/tests/ctc/evm/test_address_utils.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/tests/ctc/evm/test_block_utils.py` & `checkthechain-0.3.4/tests/ctc/evm/test_block_utils.py`

 * *Files 24% similar despite different names*

```diff
@@ -30,71 +30,68 @@
 
 
 @pytest.mark.asyncio
 @pytest.mark.parametrize('block_timestamp', block_timestamps.items())
 async def test_get_block_of_timestamp(block_timestamp):
     block, timestamp = block_timestamp
     obtained_block = await evm.async_get_block_of_timestamp(
-        timestamp, use_db=False, use_db_assist=False
+        timestamp,
+        context={'cache': True},
     )
     assert block == obtained_block
 
     obtained_block = await evm.async_get_block_of_timestamp(
-        timestamp, use_db=False, use_db_assist=True
-    )
-    assert block == obtained_block
-
-    obtained_block = await evm.async_get_block_of_timestamp(
-        timestamp, use_db=True
+        timestamp,
+        context={'cache': False},
     )
     assert block == obtained_block
 
 
 @pytest.mark.asyncio
 @pytest.mark.parametrize('block_timestamp', block_timestamps.items())
 @pytest.mark.parametrize(
     'db_settings', [[False, False], [False, True], [True, True]]
 )
 async def test_block_of_timestamp_modes(block_timestamp, db_settings):
     block, _ = block_timestamp
     use_db, use_db_assist = db_settings
+    context = {'cache': use_db}
 
     block_data = await evm.async_get_block(block)
 
     timestamp = block_data['timestamp']
     timestamp_after = timestamp + 1
 
     # test using exact timestamp
 
     obtained_block = await evm.async_get_block_of_timestamp(
-        timestamp, mode='==', use_db=use_db, use_db_assist=use_db_assist
+        timestamp, mode='==', context=context
     )
     assert obtained_block == block
 
     obtained_block = await evm.async_get_block_of_timestamp(
-        timestamp, mode='<=', use_db=use_db, use_db_assist=use_db_assist
+        timestamp, mode='<=', context=context
     )
     assert obtained_block == block
 
     obtained_block = await evm.async_get_block_of_timestamp(
-        timestamp, mode='>=', use_db=use_db, use_db_assist=use_db_assist
+        timestamp, mode='>=', context=context
     )
     assert obtained_block == block
 
     # test using offset timestamp
     with pytest.raises(Exception):
         obtained_block = await evm.async_get_block_of_timestamp(
             timestamp_after,
             mode='==',
-            use_db=use_db,
-            use_db_assist=use_db_assist,
+            context=context
         )
 
     obtained_block = await evm.async_get_block_of_timestamp(
-        timestamp_after, mode='<=', use_db=use_db, use_db_assist=use_db_assist
+        timestamp_after, mode='<=', context=context
     )
     assert obtained_block == block
 
     obtained_block = await evm.async_get_block_of_timestamp(
-        timestamp_after, mode='>=', use_db=use_db, use_db_assist=use_db_assist
+        timestamp_after, mode='>=', context=context
     )
     assert obtained_block == block + 1
```

### Comparing `checkthechain-0.3.0/tests/ctc/evm/test_erc20_utils/test_erc20_metadata.py` & `checkthechain-0.3.4/tests/ctc/evm/test_erc20_utils/test_erc20_metadata.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/tests/ctc/evm/test_erc20_utils/test_erc20_state.py` & `checkthechain-0.3.4/tests/ctc/evm/test_erc20_utils/test_erc20_state.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/tests/ctc/evm/test_event_utils.py` & `checkthechain-0.3.4/tests/ctc/evm/test_event_utils.py`

 * *Files 12% similar despite different names*

```diff
@@ -16,12 +16,11 @@
         contract_address=DAI_CONTRACT,
         event_abi=erc20_spec.erc20_event_abis['Transfer'],
         start_block=START_BLOCK,
         end_block=END_BLOCK,
         include_timestamps=True,
         event_name="Transfer",
     )
-    df = df.reset_index()
     assert len(df) == 6
-    assert df.iloc[0]["contract_address"] == DAI_CONTRACT
-    assert df.iloc[0]["block_number"] == START_BLOCK
-    assert df.iloc[0]["timestamp"] == START_TIMESTAMP
+    assert df["contract_address"][0] == DAI_CONTRACT
+    assert df["block_number"][0] == START_BLOCK
+    assert df["timestamp"][0] == START_TIMESTAMP
```

### Comparing `checkthechain-0.3.0/tests/ctc/evm/test_rpc_utils/.hypothesis/unicode_data/13.0.0/charmap.json.gz` & `checkthechain-0.3.4/tests/ctc/evm/test_rpc_utils/.hypothesis/unicode_data/13.0.0/charmap.json.gz`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/tests/ctc/evm/test_rpc_utils/test_rpc_blocks.py` & `checkthechain-0.3.4/tests/ctc/evm/test_rpc_utils/test_rpc_blocks.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/tests/ctc/evm/test_rpc_utils/test_rpc_logs.py` & `checkthechain-0.3.4/tests/ctc/evm/test_rpc_utils/test_rpc_logs.py`

 * *Files 10% similar despite different names*

```diff
@@ -27,38 +27,38 @@
 
 @pytest.mark.asyncio
 async def test_eth_uninstall_filter():
     new_filter = await rpc.async_eth_new_filter()
     await rpc.async_eth_uninstall_filter(new_filter)
 
 
-@pytest.mark.asyncio
-async def test_eth_get_filter_changes():
-    new_filter = await rpc.async_eth_new_pending_transaction_filter()
-    time.sleep(3)
-    pending_transactions = await rpc.async_eth_get_filter_changes(new_filter)
-    assert len(pending_transactions) > 0
-
-
-@pytest.mark.asyncio
-async def test_eth_get_filter_logs():
-    new_filter = await rpc.async_eth_new_filter(
-        topics=None,
-        start_block=None,
-        end_block=None,
-    )
-    new_filter = await rpc.async_eth_new_filter(
-        topics=[
-            '0xddf252ad1be2c89b69c2b068fc378daa952ba7f163c4a11628f55a4df523b3ef'
-        ],
-        start_block=12345677,
-        end_block=12345679,
-    )
-    logs = await rpc.async_eth_get_filter_logs(new_filter)
-    assert len(logs) == 375
+# @pytest.mark.asyncio
+# async def test_eth_get_filter_changes():
+#     new_filter = await rpc.async_eth_new_pending_transaction_filter()
+#     time.sleep(3)
+#     pending_transactions = await rpc.async_eth_get_filter_changes(new_filter)
+#     assert len(pending_transactions) > 0
+
+
+# @pytest.mark.asyncio
+# async def test_eth_get_filter_logs():
+#     new_filter = await rpc.async_eth_new_filter(
+#         topics=None,
+#         start_block=None,
+#         end_block=None,
+#     )
+#     new_filter = await rpc.async_eth_new_filter(
+#         topics=[
+#             '0xddf252ad1be2c89b69c2b068fc378daa952ba7f163c4a11628f55a4df523b3ef'
+#         ],
+#         start_block=12345677,
+#         end_block=12345679,
+#     )
+#     logs = await rpc.async_eth_get_filter_logs(new_filter)
+#     assert len(logs) == 375
 
 
 @pytest.mark.asyncio
 async def test_eth_get_logs():
     logs = await rpc.async_eth_get_logs(
         topics=[
             '0xddf252ad1be2c89b69c2b068fc378daa952ba7f163c4a11628f55a4df523b3ef'
```

### Comparing `checkthechain-0.3.0/tests/ctc/evm/test_rpc_utils/test_rpc_node.py` & `checkthechain-0.3.4/tests/ctc/evm/test_rpc_utils/test_rpc_node.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/tests/ctc/evm/test_rpc_utils/test_rpc_state.py` & `checkthechain-0.3.4/tests/ctc/evm/test_rpc_utils/test_rpc_state.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/tests/ctc/evm/test_rpc_utils/test_rpc_transactions.py` & `checkthechain-0.3.4/tests/ctc/evm/test_rpc_utils/test_rpc_transactions.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/tests/ctc/evm/test_transaction_utils/test_transaction_utils.py` & `checkthechain-0.3.4/tests/ctc/evm/test_transaction_utils/test_transaction_utils.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,33 +1,34 @@
 import pytest
 
 from ctc import evm
+from ctc import rpc
 
 
 example_txs = [
     '0xccb0a942a36db42ccc5ee226e4f0599c761d4c0a884f3ac2f7a56fef7aef85df',
     '0xfd74b4443e147687326e76886417a5a81c07ba26568c87e928546ef5b8dacd0d',
     '0x0bf99b11e4f4963d34b5b9d24a542ff045d8e436740dcda698ec29deff84c959',
 ]
 
 
 @pytest.mark.parametrize('test', example_txs)
 async def test_get_tx_hash(test):
 
     target_hash = test
-    transaction = await evm.async_get_transaction(target_hash)
+    transaction = await rpc.async_eth_get_transaction_by_hash(target_hash)
     actual_hash = evm.hash_signed_transaction(transaction)
     assert actual_hash == target_hash
 
 
 @pytest.mark.parametrize('test', example_txs)
 async def test_verify_transaction_signature(test):
 
     tx_hash = test
-    transaction = await evm.async_get_transaction(tx_hash)
+    transaction = await rpc.async_eth_get_transaction_by_hash(tx_hash)
     signature = (
         transaction['v'],
         transaction['r'],
         transaction['s'],
     )
     assert evm.verify_transaction_signature(
         signature=signature,
@@ -78,32 +79,33 @@
             93522894155654168208483453926995743737629589441154283159505514235904280342434,
             48417310681110102814014302147799665717176259465062324746227758019974374282313,
         ),
         'transaction': {
             'value': 0,
             'chainId': 1,
             'gas': 70000,
-            'maxFeePerGas': 2000000000,
-            'maxPriorityFeePerGas': 1000000000,
+            'max_fee_per_gas': 2000000000,
+            'max_priority_fee_per_gas': 1000000000,
             'nonce': 0,
             'to': '0xfB6916095ca1df60bB79Ce92cE3Ea74c37c5d359',
-            'data': '0xa9059cbb000000000000000000000000fb6916095ca1df60bb79ce92ce3ea74c37c5d3590000000000000000000000000000000000000000000000000000000000000001',
+            'input': '0xa9059cbb000000000000000000000000fb6916095ca1df60bb79ce92ce3ea74c37c5d3590000000000000000000000000000000000000000000000000000000000000001',
+            'access_list': [],
         },
     },
 ]
 
 
 @pytest.mark.parametrize('test', example_transactions)
 def test_sign_transaction(test):
 
     private_key = test['private_key']
     transaction = test['transaction']
     target_signature = test['signature']
 
-    transaction = evm.standardize_transaction(transaction)
+    # transaction = evm.standardize_transaction(transaction)
 
     actual_signature = evm.sign_transaction(
         transaction=transaction,
         private_key=private_key,
     )
 
     assert actual_signature == target_signature
```

### Comparing `checkthechain-0.3.0/tests/ctc/protocols/balancer_utils/test_balancer_utils.py` & `checkthechain-0.3.4/tests/ctc/protocols/balancer_utils/test_balancer_utils.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/tests/ctc/protocols/chainlink_utils/test_chainlink_db.py` & `checkthechain-0.3.4/tests/ctc/protocols/chainlink_utils/test_chainlink_db.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,38 +1,33 @@
-import os
-import tempfile
 
 import toolsql
 
 from ctc import db
 from ctc.protocols.chainlink_utils import chainlink_db
 
-
-def get_test_db_config():
-    tempdir = tempfile.mkdtemp()
-    return {
-        'dbms': 'sqlite',
-        'path': os.path.join(tempdir, 'example.db'),
-    }
+import conftest
 
 
 async def test_get_chainlink_feed_payload():
     await chainlink_db.async_get_complete_feed_payload()
 
 
 async def test_populate_feeds():
-    db_config = get_test_db_config()
-    engine = toolsql.create_engine(db_config=db_config)
-    with engine.begin() as conn:
+    db_config = conftest.get_test_db_config()
+    with toolsql.connect(db_config) as conn:
         db.initialize_schema(
-            schema_name='chainlink', network='mainnet', conn=conn
+            schema_name='chainlink',
+            context=dict(network='ethereum'),
+            conn=conn,
+        )
+    async with toolsql.async_connect(db_config) as conn:
+        await chainlink_db.async_import_network_to_db(
+            network='ethereum',
+            conn=conn,
         )
-    await chainlink_db.async_import_network_to_db(
-        network='mainnet', engine=engine
-    )
 
 
 example_data = [
     {
         'address': '0x31e0a88fecb6ec0a411dbe0e9e76391498296ee9',
         'name': 'FEI / USD',
         'deviation': '1',
@@ -53,70 +48,70 @@
         'status': 'verified',
     },
 ]
 
 
 async def test_chainlink_crud():
 
-    db_config = get_test_db_config()
+    db_config = conftest.get_test_db_config()
     db_schema = db.get_prepared_schema(
         schema_name='chainlink',
-        network='mainnet',
+        context=dict(network='ethereum'),
     )
-    toolsql.create_tables(
+    toolsql.create_db(
         db_config=db_config,
         db_schema=db_schema,
+        if_not_exists=True,
+        confirm=True,
     )
 
-    engine = toolsql.create_engine(**db_config)
-
     network = 1
 
     # insert data
-    with engine.connect() as conn:
+    async with toolsql.async_connect(db_config) as conn:
+        for feed_data in example_data:
+            await chainlink_db.async_upsert_feed(
+                conn=conn,
+                feed=feed_data,
+                context=dict(network=network),
+            )
 
-        # insert data
-        with conn.begin():
-            for feed_data in example_data:
-                await chainlink_db.async_upsert_feed(
-                    conn=conn, feed=feed_data, network=network
-                )
-
-        # get data individually
-        with conn.begin():
-            for feed_data in example_data:
-                db_feed = await chainlink_db.async_select_feed(
-                    conn=conn,
-                    address=feed_data['address'],
-                    network=network,
-                )
-                for key, target_value in feed_data.items():
-                    assert target_value == db_feed[key]
-
-        # get data collectively
-        with conn.begin():
-            addresses = [feed_data['address'] for feed_data in example_data]
-            db_feeds = await chainlink_db.async_select_feeds(
+    # get data individually
+    async with toolsql.async_connect(db_config) as conn:
+        for feed_data in example_data:
+            db_feed = await chainlink_db.async_select_feed(
                 conn=conn,
-                addresses=addresses,
-                network=network,
+                address=feed_data['address'],
+                context=dict(network=network),
             )
-            db_feeds = sorted(db_feeds, key=lambda feed: feed['address'])
-            assert db_feeds == example_data
+            for key, target_value in feed_data.items():
+                assert target_value == db_feed[key]
 
-        # delete entries one by one
-        with conn.begin():
-            for feed_data in example_data:
-                await chainlink_db.async_delete_feed(
-                    conn=conn,
-                    address=feed_data['address'],
-                    network=network,
-                )
-
-        # ensure all entries deleted
-        with conn.begin():
-            db_feeds = await chainlink_db.async_select_feeds(
+    # get data collectively
+    async with toolsql.async_connect(db_config) as conn:
+        addresses = [feed_data['address'] for feed_data in example_data]
+        db_feeds = await chainlink_db.async_select_feeds(
+            conn=conn,
+            addresses=addresses,
+            context=dict(network=network),
+        )
+        db_feeds = sorted(db_feeds, key=lambda feed: feed['address'])
+        assert db_feeds == example_data
+
+    # delete entries one by one
+    async with toolsql.async_connect(db_config) as conn:
+        for feed_data in example_data:
+            await chainlink_db.async_delete_feed(
                 conn=conn,
-                addresses=addresses,
-                network=network,
+                address=feed_data['address'],
+                context=dict(network=network),
             )
-            assert all(item is None for item in db_feeds)
+
+    # ensure all entries deleted
+    async with toolsql.async_connect(db_config) as conn:
+        db_feeds = await chainlink_db.async_select_feeds(
+            conn=conn,
+            addresses=addresses,
+            context=dict(network=network),
+        )
+        assert all(item is None for item in db_feeds)
+
```

### Comparing `checkthechain-0.3.0/tests/ctc/protocols/fourbyte_utils/test_fourbyte_db.py` & `checkthechain-0.3.4/tests/ctc/protocols/fourbyte_utils/test_fourbyte_db.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,114 +1,98 @@
-import os
-import tempfile
 
 import toolsql
 
 from ctc import db
 from ctc.protocols import fourbyte_utils
 
+import conftest
+
 
 example_data = [
     {
         'id': 145,
         'created_at': '2016-07-09T03:58:28.234977Z',
         'text_signature': 'transfer(address,uint256)',
         'hex_signature': '0xa9059cbb',
-        'bytes_signature': '©\x05\x9c»',
     },
     {
         'id': 179,
         'created_at': '2016-07-09T03:58:45.230129Z',
         'hex_signature': '0x18160ddd',
         'text_signature': 'totalSupply()',
-        'bytes_signature': '\x18\x16\rÝ',
     },
     {
         'id': 31780,
         'created_at': '2018-05-11T08:39:29.708250Z',
         'text_signature': 'many_msg_babbage(bytes1)',
         'hex_signature': '0xa9059cbb',
-        'bytes_signature': '©\x05\x9c»',
     },
     {
         'id': 161159,
         'created_at': '2019-03-22T19:13:17.314877Z',
         'text_signature': 'transfer(bytes4[9],bytes5[6],int48[11])',
         'hex_signature': '0xa9059cbb',
-        'bytes_signature': '©\x05\x9c»',
     },
     {
         'id': 313067,
         'created_at': '2021-10-20T05:29:13.555535Z',
         'text_signature': 'func_2093253501(bytes)',
         'hex_signature': '0xa9059cbb',
-        'bytes_signature': '©\x05\x9c»',
     },
 ]
 
 
-def get_test_db_config():
-    tempdir = tempfile.mkdtemp()
-    return {
-        'dbms': 'sqlite',
-        'path': os.path.join(tempdir, 'example.db'),
-    }
-
-
 async def test_fourbyte_crud():
 
-    db_config = get_test_db_config()
+    db_config = conftest.get_test_db_config()
     db_schema = db.get_raw_schema(schema_name='4byte')
-    toolsql.create_tables(
+    toolsql.create_db(
         db_config=db_config,
         db_schema=db_schema,
+        if_not_exists=True,
+        confirm=True,
     )
 
-    engine = toolsql.create_engine(**db_config)
-
     # insert data
-    with engine.connect() as conn:
-
-        # insert data
-        with conn.begin():
-            for datum in example_data:
-                await fourbyte_utils.async_upsert_function_signature(
-                    conn=conn,
-                    function_signature=datum,
-                )
-
-        # get data individually
-        with conn.begin():
-            for datum in example_data:
-                db_data = await fourbyte_utils.async_select_function_signatures(
-                    conn=conn,
-                    id=datum['id'],
-                )
-                db_datum = db_data[0]
-                for key, target_value in datum.items():
-                    assert target_value == db_datum[key]
-
-        # get data collectively
-        with conn.begin():
-            for datum in example_data:
-                db_datas = (
-                    await fourbyte_utils.async_select_function_signatures(
-                        conn=conn,
-                        hex_signature=datum['hex_signature'],
-                    )
-                )
-                assert len(db_datas) > 0
+    async with toolsql.async_connect(db_config) as conn:
+        for datum in example_data:
+            await fourbyte_utils.async_upsert_function_signature(
+                conn=conn,
+                function_signature=datum,
+            )
 
-        # delete entries one by one
-        with conn.begin():
-            for datum in example_data:
-                await fourbyte_utils.async_delete_function_signatures(
+    # get data individually
+    async with toolsql.async_connect(db_config) as conn:
+        for datum in example_data:
+            db_data = await fourbyte_utils.async_select_function_signatures(
+                conn=conn,
+                id=datum['id'],
+            )
+            db_datum = db_data[0]
+            for key, target_value in datum.items():
+                assert target_value == db_datum[key]
+
+    # get data collectively
+    async with toolsql.async_connect(db_config) as conn:
+        for datum in example_data:
+            db_datas = (
+                await fourbyte_utils.async_select_function_signatures(
                     conn=conn,
-                    text_signature=datum['text_signature'],
+                    hex_signature=datum['hex_signature'],
                 )
+            )
+            assert len(db_datas) > 0
 
-        # ensure all entries deleted
-        with conn.begin():
-            db_datas = await fourbyte_utils.async_select_function_signatures(
+    # delete entries one by one
+    async with toolsql.async_connect(db_config) as conn:
+        for datum in example_data:
+            await fourbyte_utils.async_delete_function_signatures(
                 conn=conn,
+                text_signature=datum['text_signature'],
             )
-            assert len(db_datas) == 0
+
+    # ensure all entries deleted
+    async with toolsql.async_connect(db_config) as conn:
+        db_datas = await fourbyte_utils.async_select_function_signatures(
+            conn=conn,
+        )
+        assert len(db_datas) == 0
```

#### encoding

```diff
@@ -1 +1 @@
-utf-8
+us-ascii
```

### Comparing `checkthechain-0.3.0/tests/ctc/protocols/uniswap_v2_utils/test_uniswap_queries.py` & `checkthechain-0.3.4/tests/ctc/protocols/uniswap_v2_utils/test_uniswap_queries.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/tests/ctc/test_code.py` & `checkthechain-0.3.4/tests/ctc/test_code.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,36 +1,45 @@
+import inspect
 import os
+import sys
 import types
 
 import ctc
+import ctc.db
+import ctc.rpc
 
 
 def test_ctc_functions_have_docstrings():
     functiontype = type(test_ctc_functions_have_docstrings)
 
     functions_without_docstrings = []
     for key, value in vars(ctc).items():
         if isinstance(value, functiontype):
             docstring = value.__doc__
+            missing = False
             if docstring is None or docstring == '':
-                functions_without_docstrings.append(value.__name__)
-                continue
-            lines = docstring.split('\n')
-            if lines[0] == '':
-                functions_without_docstrings.append(value.__name__)
+                missing = True
+            else:
+                lines = docstring.split('\n')
+                if lines[0] == '':
+                    missing = True
+
+            if missing:
+                name = value.__name__
+                file = sys.modules[value.__module__].__file__
+                functions_without_docstrings.append((name, file))
 
     if len(functions_without_docstrings) > 0:
-        raise Exception(
-            'some functions do not have docstrings:\n    '
-            + '\n    '.join(functions_without_docstrings)
-        )
+        message = 'some functions do not have docstrings:\n'
+        for name, file in functions_without_docstrings:
+            message += '    - ' + name + ': ' + file + '\n\n'
+        raise Exception(message)
 
 
 def test_code_imports_future_annotations():
-
     phrase = 'from __future__ import annotations'
     root_path = ctc.__path__[0]
 
     missing = []
     for root, dirnames, filenames in os.walk(root_path):
         for filename in filenames:
             if not filename.startswith('__') and filename.endswith('.py'):
@@ -77,27 +86,27 @@
     import pkgutil
 
     should_have_async_in_name = []
     should_not_have_async_in_name = []
     async_exceptions = [
         '__aenter__',
         '__aexit__',
+        'async_connect',
     ]
 
     should_use_by_block = []
     by_block_exceptions = [
         'bin_by_blocks',
     ]
 
     for importer, modname, ispkg in pkgutil.walk_packages(
         path=ctc.__path__,
         prefix="ctc.",
         onerror=lambda x: None,
     ):
-
         # skip files that run a lot of code
         if modname.endswith('__main__'):
             continue
 
         module = importlib.import_module(modname)
         for attr_name in dir(module):
             module_attr = getattr(module, attr_name)
@@ -189,24 +198,22 @@
     function_to_name = {}
 
     for importer, modname, ispkg in pkgutil.walk_packages(
         path=ctc.__path__,
         prefix=prefix,
         onerror=lambda x: None,
     ):
-
         # skip files that run a lot of code
         if modname.endswith('__main__'):
             continue
 
         module = importlib.import_module(modname)
         for attr_name in dir(module):
             module_attr = getattr(module, attr_name)
             if isinstance(module_attr, types.FunctionType):
-
                 function_data = {
                     'module_name': modname,
                     'function_name': attr_name,
                     'function': module_attr,
                     'module': module,
                 }
                 name = modname + '.' + attr_name
@@ -225,28 +232,34 @@
     return functions
 
 
 def test_max_positional_args():
     import inspect
 
     max_positional_args = 2
+    allowed_exceptions = [
+        'ctc.toolbox.chunk_utils.range_to_chunks',
+    ]
 
     too_many = []
     for function_name, function_data in iterate_package_functions(
         'ctc.'
     ).items():
         argspec = inspect.getfullargspec(function_data['function'])
         if len(argspec.args) > max_positional_args:
-            too_many.append(function_name)
+            if function_name not in allowed_exceptions:
+                too_many.append(function_name)
 
     for class_name, class_data in iterate_package_classes('ctc.').items():
         for method_name, method in class_data['methods']:
             argspec = inspect.getfullargspec(method)
             if len(argspec.args) > max_positional_args + 1:
-                too_many.append(class_name + '.' + method_name)
+                name = class_name + '.' + method_name
+                if name not in allowed_exceptions:
+                    too_many.append(name)
 
     if len(too_many) > 0:
         message = (
             'functions should take no more than '
             + str(max_positional_args)
             + ' positional args, use `*` to convert to keyword-only arguments'
         )
@@ -266,27 +279,25 @@
     classes_to_name = {}
 
     for importer, modname, ispkg in pkgutil.walk_packages(
         path=ctc.__path__,
         prefix=prefix,
         onerror=lambda x: None,
     ):
-
         # skip files that run a lot of code
         if modname.endswith('__main__'):
             continue
 
         module = importlib.import_module(modname)
         for attr_name in dir(module):
             module_attr = getattr(module, attr_name)
             if (
                 isinstance(module_attr, type)
                 and module_attr.__module__ == module.__name__
             ):
-
                 class_data = {
                     'module_name': modname,
                     'class_name': attr_name,
                     'class': module_attr,
                     'module': module,
                 }
 
@@ -305,7 +316,157 @@
                     other_name = classes_to_name[module_attr]
                     if len(name) > len(other_name):
                         del classes[other_name]
                         classes[name] = class_data
                         classes_to_name[module_attr] = name
 
     return classes
+
+
+def _get_tested_modules():
+    from ctc.protocols import (
+        aave_v2_utils,
+        balancer_utils,
+        chainlink_utils,
+        coingecko_utils,
+        compound_utils,
+        curve_utils,
+        ens_utils,
+        etherscan_utils,
+        fourbyte_utils,
+        g_uni_utils,
+        gnosis_utils,
+        llama_utils,
+        multicall_utils,
+        rari_utils,
+        sushi_utils,
+        uniswap_v2_utils,
+        uniswap_v3_utils,
+        yearn_utils,
+    )
+
+    return [
+        ctc,
+        ctc.db,
+        ctc.rpc,
+        aave_v2_utils,
+        balancer_utils,
+        chainlink_utils,
+        coingecko_utils,
+        compound_utils,
+        curve_utils,
+        ens_utils,
+        etherscan_utils,
+        fourbyte_utils,
+        g_uni_utils,
+        gnosis_utils,
+        llama_utils,
+        multicall_utils,
+        rari_utils,
+        sushi_utils,
+        uniswap_v2_utils,
+        uniswap_v3_utils,
+        yearn_utils,
+    ]
+
+
+def _get_take_context_exceptions():
+    from ctc.protocols import uniswap_v3_utils
+
+    return [
+        (ctc.rpc, 'async_send_raw'),
+        (ctc.rpc, 'async_close_http_session'),
+        (uniswap_v3_utils, 'async_get_function_abi'),
+        (uniswap_v3_utils, 'async_get_event_abi'),
+    ]
+
+
+def test_async_functions_take_context():
+    modules = _get_tested_modules()
+    exceptions = _get_take_context_exceptions()
+
+    failures = []
+    for module in modules:
+        for name, value in vars(module).items():
+            if name.startswith('async_') and isinstance(
+                value, types.FunctionType
+            ):
+                # try exception list first
+                if module == ctc.rpc and name.startswith('async_batch_'):
+                    continue
+                elif module.__name__ in (
+                    'ctc.protocols.coingecko_utils',
+                    'ctc.protocols.fourbyte_utils',
+                    'ctc.protocols.llama_utils',
+                    'ctc.protocols.rari_utils',
+                    'ctc.protocols.yearn_utils',
+                ):
+                    continue
+                elif (module, name) in exceptions:
+                    continue
+
+                argspec = inspect.getfullargspec(value)
+                if (
+                    'context' not in argspec.args
+                    and 'context' not in argspec.kwonlyargs
+                ):
+                    failures.append(value.__module__ + '.' + name)
+    if len(failures) > 0:
+        raise Exception(
+            str(len(failures))
+            + ' functions missing context argument:\n- '
+            + '\n- '.join(failures)
+        )
+
+
+def _get_take_kw_only_context_exceptions():
+    return [
+        (ctc.rpc, 'async_send_raw'),
+        (ctc.rpc, 'async_close_http_session'),
+        (ctc, 'async_get_latest_block_number'),
+        (ctc, 'async_get_default_erc20_tokens'),
+    ]
+
+
+def test_async_functions_take_kw_only_context():
+    modules = _get_tested_modules()
+    exceptions = _get_take_kw_only_context_exceptions()
+
+    failures = []
+    for module in modules:
+        for name, value in vars(module).items():
+
+            if name.startswith('async_') and isinstance(
+                value, types.FunctionType
+            ):
+                # try exception list first
+                if module == ctc.rpc and name.startswith('async_batch_'):
+                    continue
+                elif module.__name__ in (
+                    'ctc.protocols.coingecko_utils',
+                    'ctc.protocols.fourbyte_utils',
+                    'ctc.protocols.llama_utils',
+                    'ctc.protocols.rari_utils',
+                ):
+                    continue
+                elif (module, name) in exceptions:
+                    continue
+
+                argspec = inspect.getfullargspec(value)
+                if 'context' in argspec.args:
+
+                    # skip ctc.db.connect_utils.async_connect()
+                    if (
+                        value.__module__ == 'ctc.db.connect_utils'
+                        and name == 'async_connect'
+                    ):
+                        continue
+
+                    failures.append(value.__module__ + '.' + name)
+
+    if len(failures) > 0:
+        raise Exception(
+            str(len(failures))
+            + ' functions that use context as a positional argument:\n- '
+            + '\n- '.join(failures)
+        )
+
```

### Comparing `checkthechain-0.3.0/tests/ctc/test_config.py` & `checkthechain-0.3.4/tests/ctc/test_config.py`

 * *Files 6% similar despite different names*

```diff
@@ -15,15 +15,15 @@
     current_deps = {}
     for dep_str in config['project']['dependencies']:
         if '>=' not in dep_str:
             raise Exception('need min version for dependency: ' + str(dep_str))
         dep_name, version_tail = dep_str.split(' >=')
         min_version, max_version = version_tail.split(', <')
         current_deps[dep_name] = tuple(
-            int(number) for number in min_version.split('.')
+            number for number in min_version.split('.')
         )
 
     # load legacy deps
     legacy_parser = configparser.ConfigParser()
     legacy_parser.read_string(config['tool']['tox']['legacy_tox_ini'])
     legacy_deps_str = legacy_parser.get("testenv:py37-legacy", "deps")
     legacy_deps_strs = legacy_deps_str.split('\n')
@@ -33,15 +33,15 @@
             continue
 
         if '==' not in legacy_dep_str:
             continue
 
         dep_name, version = legacy_dep_str.split('==')
         legacy_deps[dep_name] = tuple(
-            int(number) for number in version.split('.')
+            number for number in version.split('.')
         )
 
     # assert that legacy uses the min version number of each dependency
     for dep_name in legacy_deps.keys():
         if dep_name not in current_deps:
             raise Exception(
                 dep_name
```

### Comparing `checkthechain-0.3.0/tests/ctc/toolbox/defi_utils/defi_directory.py` & `checkthechain-0.3.4/tests/ctc/toolbox/defi_utils/defi_directory.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 import pytest
 
-from ctc.toolbox.defi_utils import dex_utils
+from ctc.defi import dex_utils
 
 
 dexes = [
     'Balancer',
     'Curve',
     'Sushi',
     'Uniswap V2',
```

### Comparing `checkthechain-0.3.0/tests/ctc/toolbox/defi_utils/dex_utils.py` & `checkthechain-0.3.4/tests/ctc/toolbox/defi_utils/dex_utils.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 import pytest
 
-from ctc.toolbox.defi_utils import dex_utils
+from ctc.defi import dex_utils
 
 
 #
 # # test get dex pools
 #
 
 example_pool_queries = [
```

### Comparing `checkthechain-0.3.0/tests/ctc/toolbox/test_amm_utils.py` & `checkthechain-0.3.4/tests/ctc/toolbox/test_amm_utils.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,21 +1,31 @@
+import typing
 import pytest
+import math
+
 import numpy as np
 
-from ctc.toolbox.defi_utils.dex_utils.amm_utils import cpmm
-from ctc.toolbox import validate_utils
+from ctc.defi.dex_utils.amm_utils import cpmm
 
 
 x_reserves = 1e6
 y_reserves = 1e3
 
 
+def _ensure_values_equal(lhs: typing.Any, rhs: typing.Any) -> None:
+    if isinstance(lhs, dict):
+        assert set(lhs.keys()) == set(rhs.keys())
+        for key in lhs.keys():
+            _ensure_values_equal(lhs[key], rhs[key])
+    else:
+        assert math.isclose(lhs, rhs)
+
+
 @pytest.mark.parametrize('x_sold', [1e1, 1e6, 1e10])
 def test_trade_x_sold(x_sold):
-
     result = cpmm.trade(
         x_reserves=x_reserves,
         y_reserves=y_reserves,
         x_sold=x_sold,
     )
 
     assert result['new_pool']['x_reserves'] == x_reserves + x_sold
@@ -25,15 +35,14 @@
         x_reserves=x_reserves,
         y_reserves=y_reserves,
     )
 
 
 @pytest.mark.parametrize('y_sold', [1e1, 1e6, 1e10])
 def test_trade_y_sold(y_sold):
-
     result = cpmm.trade(
         x_reserves=x_reserves,
         y_reserves=y_reserves,
         y_sold=y_sold,
     )
 
     assert result['new_pool']['x_reserves'] == x_reserves - result['x_bought']
@@ -43,55 +52,52 @@
         x_reserves=y_reserves,
         y_reserves=x_reserves,
     )
 
 
 @pytest.mark.parametrize('x_bought', [1e1, 1e3, 1e5])
 def test_trade_x_bought(x_bought):
-
     result = cpmm.trade(
         x_reserves=x_reserves,
         y_reserves=y_reserves,
         x_bought=x_bought,
     )
     assert result['new_pool']['x_reserves'] == x_reserves - x_bought
     assert result['new_pool']['y_reserves'] == y_reserves + result['y_sold']
 
     # ensure that the reserve specification gives the same result
     reverse_result = cpmm.trade(
         x_reserves=x_reserves,
         y_reserves=y_reserves,
         y_sold=result['y_sold'],
     )
-    validate_utils._ensure_values_equal(result, reverse_result)
+    _ensure_values_equal(result, reverse_result)
 
 
 @pytest.mark.parametrize('y_bought', [1e0, 1e1, 1e2])
 def test_trade_y_bought(y_bought):
-
     result = cpmm.trade(
         x_reserves=x_reserves,
         y_reserves=y_reserves,
         y_bought=y_bought,
     )
     assert result['new_pool']['x_reserves'] == x_reserves - result['x_bought']
     assert result['new_pool']['y_reserves'] == y_reserves - y_bought
 
     # ensure that the reserve specification gives the same result
     reverse_result = cpmm.trade(
         x_reserves=x_reserves,
         y_reserves=y_reserves,
         x_sold=result['x_sold'],
     )
-    validate_utils._ensure_values_equal(result, reverse_result)
+    _ensure_values_equal(result, reverse_result)
 
 
 @pytest.mark.parametrize('new_x_reserves', [1e1, 1e6, 1e9])
 def test_trade_new_x_reserves(new_x_reserves):
-
     result = cpmm.trade_to_target_reserves(
         x_reserves=x_reserves,
         y_reserves=y_reserves,
         new_x_reserves=new_x_reserves,
     )
     assert result['new_pool']['x_reserves'] == new_x_reserves
 
@@ -100,23 +106,22 @@
     for name in ['x_sold', 'y_sold', 'y_bought', 'x_bought']:
         if result[name] >= 0:
             reverse_result = cpmm.trade(
                 x_reserves=x_reserves,
                 y_reserves=y_reserves,
                 **{name: result[name]},
             )
-            validate_utils._ensure_values_equal(result, reverse_result)
+            _ensure_values_equal(result, reverse_result)
             count += 1
     if count < 2:
         raise Exception('could not detect enough suitable reverse trades')
 
 
 @pytest.mark.parametrize('new_y_reserves', [1e1, 1e3, 1e6])
 def test_trade_y_reserves_new(new_y_reserves):
-
     result = cpmm.trade_to_target_reserves(
         x_reserves=x_reserves,
         y_reserves=y_reserves,
         new_y_reserves=new_y_reserves,
     )
     assert result['new_pool']['y_reserves'] == new_y_reserves
 
@@ -125,23 +130,22 @@
     for name in ['x_sold', 'y_sold', 'y_bought', 'x_bought']:
         if result[name] >= 0:
             reverse_result = cpmm.trade(
                 x_reserves=x_reserves,
                 y_reserves=y_reserves,
                 **{name: result[name]},
             )
-            validate_utils._ensure_values_equal(result, reverse_result)
+            _ensure_values_equal(result, reverse_result)
             count += 1
     if count < 2:
         raise Exception('could not detect enough suitable reverse trades')
 
 
 @pytest.mark.parametrize('new_price', [1e-8, 1e-2, 1e2, 1e8])
 def test_trade_to_price(new_price):
-
     # modify x per y
     result = cpmm.trade_to_price(
         x_reserves=x_reserves,
         y_reserves=y_reserves,
         new_x_per_y=new_price,
     )
     result_price = (
@@ -168,7 +172,8 @@
         'x_bought',
         'y_bought',
     ]:
         with pytest.raises(Exception):
             cpmm.trade(
                 x_reserves=x_reserves, y_reserves=y_reserves, **{arg: -1}
             )
+
```

### Comparing `checkthechain-0.3.0/tests/ctc/toolbox/test_feed_utils.py` & `checkthechain-0.3.4/tests/ctc/toolbox/test_feed_utils.py`

 * *Files identical despite different names*

### Comparing `checkthechain-0.3.0/PKG-INFO` & `checkthechain-0.3.4/PKG-INFO`

 * *Files 4% similar despite different names*

```diff
@@ -1,60 +1,59 @@
 Metadata-Version: 2.1
 Name: checkthechain
-Version: 0.3.0
+Version: 0.3.4
 Summary: ctc is a tool for collecting and processing historical EVM data
 Requires-Python: >=3.7
 Description-Content-Type: text/markdown
 Classifier: Development Status :: 4 - Beta
 Classifier: Intended Audience :: Developers
 Classifier: Intended Audience :: Financial and Insurance Industry
 Classifier: Intended Audience :: Science/Research
+Classifier: License :: OSI Approved :: Apache Software License
 Classifier: License :: OSI Approved :: MIT License
 Classifier: Natural Language :: English
 Classifier: Operating System :: MacOS
 Classifier: Operating System :: Microsoft :: Windows
 Classifier: Operating System :: POSIX :: Linux
 Classifier: Programming Language :: Python :: 3.7
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
 Classifier: Programming Language :: Python :: 3.10
+Classifier: Programming Language :: Python :: 3.11
 Classifier: Typing :: Typed
 Requires-Dist: typing-extensions >=4.2.0, <5
 Requires-Dist: numpy >=1.19.0, <1.24
-Requires-Dist: pandas >=1.2.0, <1.5
+Requires-Dist: polars >=0.17.3, <0.18
+Requires-Dist: pyarrow >=12.0.0, <13
 Requires-Dist: aiohttp >=3.7.4, <4
+Requires-Dist: connectorx==0.3.2a5
 Requires-Dist: loguru >=0.5.3, <0.7
+Requires-Dist: msgspec >=0.14.1, <0.15
+Requires-Dist: orjson >=3.7.9, <4
+Requires-Dist: requests >=2.20.0, <3
 Requires-Dist: toml >=0.10.2, <0.11
-Requires-Dist: toolcli >=0.6.8, <0.7
+Requires-Dist: toolcli >=0.6.13, <0.7
 Requires-Dist: toolconf >=0.1.2, <0.2
-Requires-Dist: toolsql >=0.3.11, <0.4
-Requires-Dist: toolstr >=0.8.2, <0.9
-Requires-Dist: tooltime >=0.2.7, <0.3
+Requires-Dist: toolsql >=0.6.0, <0.7
+Requires-Dist: toolstr >=0.9.3, <0.10
+Requires-Dist: tooltime >=0.2.10, <0.3
 Requires-Dist: pycryptodome >=3.9.1, <4
-Requires-Dist: eth_abi_lite >=3.0.3, <4
-Requires-Dist: idna >=3.3, <4
-Requires-Dist: rlp >=3.0.0 ; extra == "full"
-Requires-Dist: pysha3 ==1.0.2 ; extra == "performance"
-Requires-Dist: scikit-image >=0.19.2 ; extra == "performance"
-Requires-Dist: orjson >=3.6.8 ; extra == "performance"
-Requires-Dist: matplotlib >=3.1.3 ; extra == "plots"
-Requires-Dist: toolplot >=0.1.0 ; extra == "plots"
-Requires-Dist: mypy ==0.960 ; extra == "test"
-Requires-Dist: mypy_extensions >= 0.4.3, <0.5.0 ; extra == "test"
-Requires-Dist: pandas-stubs >=1.2.0.1 ; extra == "test"
+Requires-Dist: eth_abi_lite >=3.2.0, <4
+Requires-Dist: idna >=2.10, <4
+Requires-Dist: mypy ==1.2.0 ; extra == "test"
+Requires-Dist: mypy_extensions >= 1.0.0, <1.1.0 ; extra == "test"
 Requires-Dist: pytest-asyncio ==0.18.0 ; extra == "test"
+Requires-Dist: pytest-xdist ==3.1.0 ; extra == "test"
 Requires-Dist: pytest >=6 ; extra == "test"
 Requires-Dist: tox-asdf ==0.1.0 ; extra == "test"
 Requires-Dist: tox ==3.8.0 ; extra == "test"
 Requires-Dist: virtualenv >=20.6.0 ; extra == "test"
+Requires-Dist: types-requests >= 2.28.11.17 ; extra == "test"
 Project-URL: Documentation, https://ctc.readthedocs.io/en/latest/
 Project-URL: Source, https://github.com/fei-protocol/checkthechain
-Provides-Extra: full
-Provides-Extra: performance
-Provides-Extra: plots
 Provides-Extra: test
 
 # ⛓🔍 Check the Chain (`ctc`) 🔎⛓
 
 `ctc` is a tool for collecting and analyzing data from Ethereum and other EVM chains
 
 It can be used as either 1) a python package or 2) a cli tool
@@ -84,15 +83,15 @@
 3. [**FAQ**](#faq)
 4. [**Similar Projects**](#similar-projects)
 
 <table>
   <tbody>
     <tr>
       <td>
-        <b>📜 Legal Disclaimer 📜</b> As stated in the MIT license, <code>ctc</code> comes with no warranty of any kind. The authors of <code>ctc</code> accept no responsibility for any damages or negative outcomes that result from using <code>ctc</code> or <code>ctc</code>-derived data. <code>ctc</code> is not audited and using it as a basis for making financial decisions is not recommended.
+        <b>📜 Legal Disclaimer 📜</b> <code>ctc</code> is available under either the MIT license or the Apache license at your option. As stated in both licenses, <code>ctc</code> comes with no warranty of any kind. The authors of <code>ctc</code> accept no responsibility for any damages or negative outcomes that result from using <code>ctc</code> or <code>ctc</code>-derived data. <code>ctc</code> is not audited and using it as a basis for making financial decisions is not recommended.
       </td>
     </tr>
   </tbody>
 </table>
 
 ## Example Usage
 
@@ -205,15 +204,15 @@
 1. `pip install checkthechain`
 2. run `ctc setup` in terminal to specify data provider and data storage path
 
 If your shell's `PATH` does not include python scripts you may need to do something like `python3 -m pip ...` and `python3 -m ctc ...`
 
 Detailed instructions can be found in the [installation documentation](https://ctc.readthedocs.io/en/latest/overview/installation.html).
 
-`ctc` requires python >= 3.7. 
+`ctc` requires python >= 3.7 (supports `3.7`, `3.8`, `3.9`, `3.10`, and `3.11`). 
 
 ## FAQ
 - What are the goals of `ctc`?
     1. **Treat historical data as a first-class feature**: This means having historical data functionality well-integrated into each part of the of the API. It also means optimizing the codebase with historical data workloads in mind.
     2. **Protocol-specific functionality**: This means having built-in support for popular on-chain protocols.
     3. **Terminal-based block explorer**: This means supporting as many block explorer tasks as possible from the terminal. And doing so in a way that is faster than can be done with a web browser.
     4. **Clean API emphasizing UX**: With `ctc` most data queries can be obtained with a single function call. No need to instantiate objects. RPC inputs/outputs are automatically encoded/decoded by default.
```

