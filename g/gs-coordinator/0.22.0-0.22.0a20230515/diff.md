# Comparing `tmp/gs_coordinator-0.22.0-py2.py3-none-macosx_12_0_arm64.whl.zip` & `tmp/gs_coordinator-0.22.0a20230515-py2.py3-none-macosx_11_0_x86_64.whl.zip`

## zipinfo {}

```diff
@@ -1,34 +1,34 @@
-Zip file size: 93699 bytes, number of entries: 32
--rw-r--r--  2.0 unx      694 b- defN 23-Jun-06 08:10 graphscope_runtime/__init__.py
--rw-rw-r--  2.0 unx     2829 b- defN 23-Jun-06 01:44 gs_coordinator-0.22.0.dist-info/RECORD
--rw-r--r--  2.0 unx      138 b- defN 23-Jun-06 08:40 gs_coordinator-0.22.0.dist-info/WHEEL
--rw-r--r--  2.0 unx       33 b- defN 23-Jun-06 08:40 gs_coordinator-0.22.0.dist-info/top_level.txt
--rw-r--r--  2.0 unx    22312 b- defN 23-Jun-06 08:40 gs_coordinator-0.22.0.dist-info/METADATA
--rw-r--r--  2.0 unx    58206 b- defN 23-Jun-06 08:10 gscoordinator/kubernetes_launcher.py
--rw-r--r--  2.0 unx    37570 b- defN 23-Jun-06 08:10 gscoordinator/coordinator.py
--rw-r--r--  2.0 unx     5537 b- defN 23-Jun-06 08:10 gscoordinator/dag_manager.py
--rw-r--r--  2.0 unx     1045 b- defN 23-Jun-06 08:10 gscoordinator/version.py
--rw-r--r--  2.0 unx     7006 b- defN 23-Jun-06 08:10 gscoordinator/monitor.py
--rw-r--r--  2.0 unx    38436 b- defN 23-Jun-06 08:10 gscoordinator/op_executor.py
--rw-r--r--  2.0 unx     2957 b- defN 23-Jun-06 08:10 gscoordinator/object_manager.py
--rw-r--r--  2.0 unx      990 b- defN 23-Jun-06 08:10 gscoordinator/__init__.py
--rw-r--r--  2.0 unx    22541 b- defN 23-Jun-06 08:10 gscoordinator/cluster_builder.py
--rw-r--r--  2.0 unx    19978 b- defN 23-Jun-06 08:10 gscoordinator/local_launcher.py
--rw-r--r--  2.0 unx        7 b- defN 23-Jun-06 08:10 gscoordinator/VERSION
--rw-r--r--  2.0 unx    77420 b- defN 23-Jun-06 08:10 gscoordinator/utils.py
--rw-r--r--  2.0 unx     4091 b- defN 23-Jun-06 08:10 gscoordinator/io_utils.py
--rw-r--r--  2.0 unx     5062 b- defN 23-Jun-06 08:10 gscoordinator/launcher.py
--rw-r--r--  2.0 unx     2450 b- defN 23-Jun-06 08:10 gscoordinator/learning.py
--rw-r--r--  2.0 unx       77 b- defN 23-Jun-06 08:10 gscoordinator/__main__.py
--rw-r--r--  2.0 unx      646 b- defN 23-Jun-06 08:10 gscoordinator/template/__init__.py
--rw-r--r--  2.0 unx     4340 b- defN 23-Jun-06 08:10 gscoordinator/template/pregel.pxd.template
--rw-r--r--  2.0 unx     4957 b- defN 23-Jun-06 08:10 gscoordinator/template/pie.pxd.template
--rw-r--r--  2.0 unx    19957 b- defN 23-Jun-06 08:10 gscoordinator/template/CMakeLists.template
--rw-r--r--  2.0 unx      646 b- defN 23-Jun-06 08:10 gscoordinator/builtin/__init__.py
--rw-r--r--  2.0 unx    23996 b- defN 23-Jun-06 08:10 gscoordinator/builtin/app/.gs_conf.yaml
--rw-r--r--  2.0 unx     5601 b- defN 23-Jun-06 08:40 gscoordinator/builtin/app/builtin_app.gar
--rw-r--r--  2.0 unx      646 b- defN 23-Jun-06 08:10 gscoordinator/builtin/app/__init__.py
--rw-r--r--  2.0 unx      646 b- defN 23-Jun-06 08:10 gscoordinator/hook/__init__.py
--rw-r--r--  2.0 unx      646 b- defN 23-Jun-06 08:10 gscoordinator/hook/prestop/__init__.py
--rw-r--r--  2.0 unx     1560 b- defN 23-Jun-06 08:10 gscoordinator/hook/prestop/__main__.py
-32 files, 373020 bytes uncompressed, 89179 bytes compressed:  76.1%
+Zip file size: 89340 bytes, number of entries: 32
+-rw-rw-r--  2.0 unx     2866 b- defN 23-May-15 21:26 gs_coordinator-0.22.0a20230515.dist-info/RECORD
+-rw-r--r--  2.0 unx      140 b- defN 23-May-15 21:14 gs_coordinator-0.22.0a20230515.dist-info/WHEEL
+-rw-r--r--  2.0 unx       33 b- defN 23-May-15 21:14 gs_coordinator-0.22.0a20230515.dist-info/top_level.txt
+-rw-r--r--  2.0 unx    22321 b- defN 23-May-15 21:14 gs_coordinator-0.22.0a20230515.dist-info/METADATA
+-rw-r--r--  2.0 unx      694 b- defN 23-May-15 19:08 graphscope_runtime/__init__.py
+-rw-r--r--  2.0 unx    36024 b- defN 23-May-15 19:08 gscoordinator/kubernetes_launcher.py
+-rw-r--r--  2.0 unx    37321 b- defN 23-May-15 19:08 gscoordinator/coordinator.py
+-rw-r--r--  2.0 unx     5537 b- defN 23-May-15 19:08 gscoordinator/dag_manager.py
+-rw-r--r--  2.0 unx     1045 b- defN 23-May-15 19:08 gscoordinator/version.py
+-rw-r--r--  2.0 unx     7006 b- defN 23-May-15 19:08 gscoordinator/monitor.py
+-rw-r--r--  2.0 unx    38246 b- defN 23-May-15 19:08 gscoordinator/op_executor.py
+-rw-r--r--  2.0 unx     2957 b- defN 23-May-15 19:08 gscoordinator/object_manager.py
+-rw-r--r--  2.0 unx      990 b- defN 23-May-15 19:08 gscoordinator/__init__.py
+-rw-r--r--  2.0 unx    24417 b- defN 23-May-15 19:08 gscoordinator/cluster_builder.py
+-rw-r--r--  2.0 unx    19314 b- defN 23-May-15 19:08 gscoordinator/local_launcher.py
+-rw-r--r--  2.0 unx       16 b- defN 23-May-15 19:20 gscoordinator/VERSION
+-rw-r--r--  2.0 unx    76887 b- defN 23-May-15 19:08 gscoordinator/utils.py
+-rw-r--r--  2.0 unx     4091 b- defN 23-May-15 19:08 gscoordinator/io_utils.py
+-rw-r--r--  2.0 unx     5062 b- defN 23-May-15 19:08 gscoordinator/launcher.py
+-rw-r--r--  2.0 unx     2450 b- defN 23-May-15 19:08 gscoordinator/learning.py
+-rw-r--r--  2.0 unx       77 b- defN 23-May-15 19:08 gscoordinator/__main__.py
+-rw-r--r--  2.0 unx      646 b- defN 23-May-15 19:08 gscoordinator/template/__init__.py
+-rw-r--r--  2.0 unx     4340 b- defN 23-May-15 19:08 gscoordinator/template/pregel.pxd.template
+-rw-r--r--  2.0 unx     4957 b- defN 23-May-15 19:08 gscoordinator/template/pie.pxd.template
+-rw-r--r--  2.0 unx    19853 b- defN 23-May-15 19:08 gscoordinator/template/CMakeLists.template
+-rw-r--r--  2.0 unx      646 b- defN 23-May-15 19:08 gscoordinator/builtin/__init__.py
+-rw-r--r--  2.0 unx    23996 b- defN 23-May-15 19:08 gscoordinator/builtin/app/.gs_conf.yaml
+-rw-r--r--  2.0 unx     5601 b- defN 23-May-15 21:14 gscoordinator/builtin/app/builtin_app.gar
+-rw-r--r--  2.0 unx      646 b- defN 23-May-15 19:08 gscoordinator/builtin/app/__init__.py
+-rw-r--r--  2.0 unx      646 b- defN 23-May-15 19:08 gscoordinator/hook/__init__.py
+-rw-r--r--  2.0 unx      646 b- defN 23-May-15 19:08 gscoordinator/hook/prestop/__init__.py
+-rw-r--r--  2.0 unx     1560 b- defN 23-May-15 19:08 gscoordinator/hook/prestop/__main__.py
+32 files, 351031 bytes uncompressed, 84748 bytes compressed:  75.9%
```

## zipnote {}

```diff
@@ -1,20 +1,20 @@
-Filename: graphscope_runtime/__init__.py
+Filename: gs_coordinator-0.22.0a20230515.dist-info/RECORD
 Comment: 
 
-Filename: gs_coordinator-0.22.0.dist-info/RECORD
+Filename: gs_coordinator-0.22.0a20230515.dist-info/WHEEL
 Comment: 
 
-Filename: gs_coordinator-0.22.0.dist-info/WHEEL
+Filename: gs_coordinator-0.22.0a20230515.dist-info/top_level.txt
 Comment: 
 
-Filename: gs_coordinator-0.22.0.dist-info/top_level.txt
+Filename: gs_coordinator-0.22.0a20230515.dist-info/METADATA
 Comment: 
 
-Filename: gs_coordinator-0.22.0.dist-info/METADATA
+Filename: graphscope_runtime/__init__.py
 Comment: 
 
 Filename: gscoordinator/kubernetes_launcher.py
 Comment: 
 
 Filename: gscoordinator/coordinator.py
 Comment:
```

## gscoordinator/kubernetes_launcher.py

```diff
@@ -58,15 +58,15 @@
 from gscoordinator.utils import ANALYTICAL_ENGINE_PATH
 from gscoordinator.utils import GRAPHSCOPE_HOME
 from gscoordinator.utils import INTERACTIVE_ENGINE_SCRIPT
 from gscoordinator.utils import WORKSPACE
 from gscoordinator.utils import ResolveMPICmdPrefix
 from gscoordinator.utils import delegate_command_to_pod
 from gscoordinator.utils import parse_as_glog_level
-from gscoordinator.utils import run_kube_cp_command
+from gscoordinator.utils import run_command
 from gscoordinator.version import __version__
 
 logger = logging.getLogger("graphscope")
 
 
 class FakeKubeResponse:
     def __init__(self, obj):
@@ -105,15 +105,14 @@
         vineyard_mem=None,
         vineyard_shared_mem=None,
         volumes=None,
         waiting_for_delete=None,
         with_mars=False,
         enabled_engines="",
         dataset_proxy=None,
-        deploy_mode="eager",
         **kwargs,
     ):
         super().__init__()
         self._api_client = resolve_api_client()
         self._core_api = kube_client.CoreV1Api(self._api_client)
         self._apps_api = kube_client.AppsV1Api(self._api_client)
         self._resource_object = ResourceManager(self._api_client)
@@ -125,41 +124,38 @@
         self._coordinator_name = coordinator_name
         self._coordinator_service_name = coordinator_service_name
 
         self._owner_references = self.get_coordinator_owner_references()
         self._image_registry = image_registry
         self._image_repository = image_repository
         self._image_tag = image_tag
-        self._image_pull_policy = image_pull_policy
 
-        self._image_pull_secrets = (
-            image_pull_secrets.split(",") if image_pull_secrets else []
-        )
+        image_pull_secrets = image_pull_secrets.split(",") if image_pull_secrets else []
 
         self._glog_level = parse_as_glog_level(log_level)
 
-        self._engine_pod_prefix = "gs-engine-"
-
         self._num_workers = num_workers
 
-        self._vineyard_image = vineyard_image
-        self._vineyard_mem = vineyard_mem
-        self._vineyard_cpu = vineyard_cpu
-        self._vineyard_size = vineyard_shared_mem
-
         self._vineyard_deployment = vineyard_deployment
 
+        if self.vineyard_deployment_exists():
+            try:
+                self._apps_api.read_namespaced_deployment(
+                    vineyard_deployment, self._namespace
+                )
+            except K8SApiException:
+                logger.exception(
+                    f"Vineyard deployment {self._namespace}/{vineyard_deployment} not found"
+                )
+                self._vineyard_deployment = None
+
         self._engine_cpu = engine_cpu
         self._engine_mem = engine_mem
-        self._engine_pod_node_selector = engine_pod_node_selector
         self._vineyard_shared_mem = vineyard_shared_mem
 
-        self._volumes = volumes
-        self._dataset_proxy = dataset_proxy
-
         self._with_dataset = with_dataset
         self._preemptive = preemptive
         self._service_type = service_type
 
         assert timeout_seconds is not None
         self._timeout_seconds = timeout_seconds
 
@@ -173,15 +169,15 @@
         valid_engines = set(
             "analytical,analytical-java,interactive,learning,gae,gae-java,gie,gle".split(
                 ","
             )
         )
 
         for item in engines:
-            if item not in valid_engines and item != "":
+            if item not in valid_engines:
                 raise ValueError(
                     f"Not a valid engine name: {item}, valid engines are {valid_engines}"
                 )
             if item == "analytical" or item == "gae":
                 self._with_analytical = True
             if item == "interactive" or item == "gie":
                 self._with_interactive = True
@@ -192,78 +188,17 @@
 
         self._with_mars = with_mars
         self._mars_scheduler_cpu = mars_scheduler_cpu
         self._mars_scheduler_mem = mars_scheduler_mem
         self._mars_worker_cpu = mars_worker_cpu
         self._mars_worker_mem = mars_worker_mem
 
-        # check the validity of deploy mode
-        self._deploy_mode = deploy_mode
-        if self._deploy_mode not in ["eager", "lazy"]:
-            logger.error(
-                "Invalid mode %s, choose from 'eager' or 'lazy'. Proceeding with default mode: 'eager'",
-                self._deploy_mode,
-            )
-            self._deploy_mode = "eager"
-
-        self._vineyard_pod_name_list = []
-
-        # set the kube config file
-        self._k8s_config_file = self.get_current_kubeconfig()
-        config = kwargs.pop("k8s_client_config", {})
-        if "config_file" in config:
-            self._k8s_config_file = config["config_file"]
-
-        if self._vineyard_deployment is not None:
-            self._deploy_vineyard_deployment_if_not_exist()
-            # check the if the vineyard deployment is ready again
-            if not self._check_if_vineyard_deployment_exist():
-                # if not ready, then set the vineyard deployment to None
-                logger.error(
-                    "Vineyard deployment %s is not ready, please check the deployment status."
-                    "Proceeding with none vineyard deployment mode.",
-                    self._vineyard_deployment,
-                )
-                self._vineyard_deployment = None
-
-        # if the vineyard deployment is not set and use the eager mode,
-        # which means deploy the engine as a single pod and there is no
-        # external vineyard deployment. The vineyard objects are not
-        # shared between the engine pods, so report an error here and set
-        # the mode to eager.
-        if self._deploy_mode == "lazy" and self._vineyard_deployment is None:
-            logger.error(
-                "Lazy mode is only possible with a vineyard deployment, "
-                "please add a vineyard deployment name by k8s_vineyard_deployment='vineyardd-sample'. "
-                "Proceeding with default mode: 'eager'"
-            )
-            self._deploy_mode = "eager"
-
         self._pod_name_list = []
-        self._pod_ip_list = []
-        self._pod_host_ip_list = []
-
-        # analytical engine
-        self._analytical_pod_name = []
-        self._analytical_pod_ip = []
-        self._analytical_pod_host_ip = []
-        # analytical java engine
-        self._analytical_java_pod_name = []
-        self._analytical_java_pod_ip = []
-        self._analytical_java_pod_host_ip = []
-        # interactive engine
-        self._interactive_resource_object = {}
-        self._interactive_pod_name = {}
-        self._interactive_pod_ip = {}
-        self._interactive_pod_host_ip = {}
-        # learning engine
-        self._learning_resource_object = {}
-        self._learning_pod_name = {}
-        self._learning_pod_ip = {}
-        self._learning_pod_host_ip = {}
+        self._pod_ip_list = None
+        self._pod_host_ip_list = None
 
         self._analytical_engine_endpoint = None
         self._mars_service_endpoint = None
 
         self._serving = False
 
         self._analytical_engine_process = None
@@ -280,19 +215,43 @@
         self._learning_instance_processes = {}
 
         # workspace
         self._instance_workspace = os.path.join(WORKSPACE, instance_id)
         os.makedirs(self._instance_workspace, exist_ok=True)
         self._session_workspace = None
 
-        self._engine_cluster = self._build_engine_cluster(
-            with_analytical_container=self._with_analytical,
-            with_analytical_java_container=self._with_analytical_java,
-            with_interactive_container=self._with_interactive,
-            with_learning_container=self._with_learning,
+        self._engine_cluster = EngineCluster(
+            engine_cpu=engine_cpu,
+            engine_mem=engine_mem,
+            engine_pod_node_selector=engine_pod_node_selector,
+            glog_level=self._glog_level,
+            image_pull_policy=image_pull_policy,
+            image_pull_secrets=image_pull_secrets,
+            image_registry=image_registry,
+            image_repository=image_repository,
+            image_tag=image_tag,
+            instance_id=instance_id,
+            learning_start_port=self._learning_start_port,
+            with_dataset=with_dataset,
+            namespace=namespace,
+            num_workers=num_workers,
+            preemptive=preemptive,
+            service_type=service_type,
+            vineyard_cpu=vineyard_cpu,
+            vineyard_deployment=vineyard_deployment,
+            vineyard_image=vineyard_image,
+            vineyard_mem=vineyard_mem,
+            vineyard_shared_mem=vineyard_shared_mem,
+            volumes=volumes,
+            with_mars=with_mars,
+            with_analytical=self._with_analytical,
+            with_analytical_java=self._with_analytical_java,
+            with_interactive=self._with_interactive,
+            with_learning=self._with_learning,
+            dataset_proxy=dataset_proxy,
         )
 
         self._vineyard_service_endpoint = None
         self._vineyard_internal_service_endpoint = None
         self._mars_service_endpoint = None
         if self._with_mars:
             self._mars_cluster = MarsCluster(
@@ -304,68 +263,14 @@
 
     def type(self):
         return types_pb2.K8S
 
     def vineyard_deployment_exists(self):
         return self._vineyard_deployment is not None
 
-    def get_current_kubeconfig(self):
-        """Gets the current kubeconfig file path.
-
-        Returns:
-            str: The path to the current kubeconfig file.
-        """
-
-        kubeconfig_path = os.environ.get("KUBECONFIG")
-        if kubeconfig_path is None:
-            kubeconfig_path = "~/.kube/config"
-
-        return kubeconfig_path
-
-    # the argument `with_analytical_` means whether to add the analytical engine
-    # container to the engine statefulset, and the other three arguments are similar.
-    def _build_engine_cluster(
-        self,
-        with_analytical_container: bool,
-        with_analytical_java_container: bool,
-        with_interactive_container: bool,
-        with_learning_container: bool,
-    ):
-        return EngineCluster(
-            engine_cpu=self._engine_cpu,
-            engine_mem=self._engine_mem,
-            engine_pod_node_selector=self._engine_pod_node_selector,
-            engine_pod_prefix=self._engine_pod_prefix,
-            glog_level=self._glog_level,
-            image_pull_policy=self._image_pull_policy,
-            image_pull_secrets=self._image_pull_secrets,
-            image_registry=self._image_registry,
-            image_repository=self._image_repository,
-            image_tag=self._image_tag,
-            instance_id=self._instance_id,
-            learning_start_port=self._learning_start_port,
-            with_dataset=self._with_dataset,
-            namespace=self._namespace,
-            num_workers=self._num_workers,
-            preemptive=self._preemptive,
-            service_type=self._service_type,
-            vineyard_cpu=self._vineyard_cpu,
-            vineyard_deployment=self._vineyard_deployment,
-            vineyard_image=self._vineyard_image,
-            vineyard_mem=self._vineyard_mem,
-            vineyard_shared_mem=self._vineyard_shared_mem,
-            volumes=self._volumes,
-            with_mars=self._with_mars,
-            with_analytical=with_analytical_container,
-            with_analytical_java=with_analytical_java_container,
-            with_interactive=with_interactive_container,
-            with_learning=with_learning_container,
-            dataset_proxy=self._dataset_proxy,
-        )
-
     def get_coordinator_owner_references(self):
         owner_references = []
         if self._coordinator_name:
             try:
                 deployment = self._apps_api.read_namespaced_deployment(
                     self._coordinator_name, self._namespace
                 )
@@ -374,30 +279,26 @@
                         api_version="apps/v1",
                         kind="Deployment",
                         name=self._coordinator_name,
                         uid=deployment.metadata.uid,
                     )
                 )
             except K8SApiException:
-                logger.error("Coordinator %s not found", self._coordinator_name)
+                logger.error(f"Coordinator {self._coordinator_name} not found")
 
         return owner_references
 
     def waiting_for_delete(self):
         return self._waiting_for_delete
 
     def get_namespace(self):
         return self._namespace
 
     def get_vineyard_stream_info(self):
         hosts = [f"{self._namespace}:{host}" for host in self._pod_name_list]
-        if self._vineyard_deployment is not None:
-            hosts = [
-                f"{self._namespace}:{host}" for host in self._vineyard_pod_name_list
-            ]
         return "kubernetes", hosts
 
     def set_session_workspace(self, session_id):
         self._session_workspace = os.path.join(self._instance_workspace, session_id)
         os.makedirs(self._session_workspace, exist_ok=True)
 
     def launch_etcd(self):
@@ -413,29 +314,29 @@
     @property
     def hosts(self):
         """String of a list of pod name, comma separated."""
         return ",".join(self._pod_name_list)
 
     @property
     def hosts_list(self):
-        return self._get_analytical_hosts()
+        return self._pod_name_list
 
     def distribute_file(self, path):
-        pod_name_list, _, _ = self._allocate_analytical_engine()
-        for pod in pod_name_list:
+        for pod in self._pod_name_list:
             container = self._engine_cluster.analytical_container_name
             try:
                 # The library may exists in the analytical pod.
                 test_cmd = f"test -f {path}"
                 logger.debug(delegate_command_to_pod(test_cmd, pod, container))
                 logger.info("Library exists, skip distribute")
             except RuntimeError:
                 cmd = f"mkdir -p {os.path.dirname(path)}"
                 logger.debug(delegate_command_to_pod(cmd, pod, container))
-                logger.debug(run_kube_cp_command(path, path, pod, container, True))
+                cmd = f"kubectl cp {path} {pod}:{path} -c {container}"
+                logger.debug(run_command(cmd))
 
     def close_analytical_instance(self):
         pass
 
     def launch_vineyard(self):
         """Launch vineyardd in k8s cluster."""
         # vineyardd is auto launched in vineyardd container
@@ -448,192 +349,37 @@
         pass
 
     def close_vineyard(self):
         # No need to close vineyardd
         # Use delete deployment instead
         pass
 
-    def check_if_engine_exist(self, engine_type, object_id=None):
-        """Checks if the engine with the given type exists.
-
-        Args:
-            engine_type: The type of engine to check for.
-            object_id: The object id of the engine to check for.
-
-        Returns:
-            True if the engine exists, False otherwise.
-        """
-
-        if object_id:
-            engine_pod_name_dict = getattr(self, f"_{engine_type}_pod_name")
-            engine_pod_name_list = engine_pod_name_dict.get(object_id, [])
-            engine_pod_ip_dict = getattr(self, f"_{engine_type}_pod_ip")
-            engine_pod_ip_list = engine_pod_ip_dict.get(object_id, [])
-            engine_pod_host_ip_dict = getattr(self, f"_{engine_type}_pod_host_ip")
-            engine_pod_host_ip_list = engine_pod_host_ip_dict.get(object_id, [])
-        else:
-            engine_pod_name_list = getattr(self, f"_{engine_type}_pod_name")
-            engine_pod_ip_list = getattr(self, f"_{engine_type}_pod_ip")
-            engine_pod_host_ip_list = getattr(self, f"_{engine_type}_pod_host_ip")
-
-        return engine_pod_name_list and engine_pod_ip_list and engine_pod_host_ip_list
-
-    def deploy_engine(self, engine_type, object_id=None):
-        """Deploys the engine with the given type.
-
-        Args:
-            engine_type: The type of engine to deploy.
-            object_id: The object ID to deploy the engine with.
-
-        Returns:
-            A tuple of the pod names, IP addresses, and host IP addresses of the
-            deployed engine and the response of the engine and service.
-        """
-
-        if not self.check_if_engine_exist(engine_type, object_id):
-            self._engine_pod_prefix = f"gs-{engine_type}-" + (
-                f"{object_id}-" if object_id else ""
-            ).replace("_", "-")
-            self._engine_cluster = self._build_engine_cluster(
-                with_analytical_container=engine_type == "analytical",
-                with_analytical_java_container=engine_type == "analytical-java",
-                with_interactive_container=engine_type == "interactive",
-                with_learning_container=engine_type == "learning",
-            )
-            response = self._create_engine_stateful_set()
-            self._waiting_for_services_ready()
-
-            if object_id:
-                resource_object = getattr(self, f"_{engine_type}_resource_object")
-                pod_name = getattr(self, f"_{engine_type}_pod_name")
-                pod_ip = getattr(self, f"_{engine_type}_pod_ip")
-                pod_host_ip = getattr(self, f"_{engine_type}_pod_host_ip")
-                resource_object[object_id] = response
-                pod_name[object_id] = self._pod_name_list
-                pod_ip[object_id] = self._pod_ip_list
-                pod_host_ip[object_id] = self._pod_host_ip_list
-            else:
-                # Set the engine pod info
-                setattr(self, f"_{engine_type}_pod_name", self._pod_name_list)
-                setattr(self, f"_{engine_type}_pod_ip", self._pod_ip_list)
-                setattr(self, f"_{engine_type}_pod_host_ip", self._pod_host_ip_list)
-
-        return (
-            getattr(self, f"_{engine_type}_pod_name")
-            if object_id is None
-            else getattr(self, f"_{engine_type}_pod_name")[object_id],
-            getattr(self, f"_{engine_type}_pod_ip")
-            if object_id is None
-            else getattr(self, f"_{engine_type}_pod_ip")[object_id],
-            getattr(self, f"_{engine_type}_pod_host_ip")
-            if object_id is None
-            else getattr(self, f"_{engine_type}_pod_host_ip")[object_id],
-        )
-
-    def delete_engine_stateful_set_with_object_id(self, engine_type, object_id):
-        """delete the engine stateful set with the given object id.
-
-        Args:
-            object_id (int): The object id of the engine to delete.
-        """
-        resource_object = getattr(self, f"_{engine_type}_resource_object")
-        obj = resource_object.get(object_id, {})
-        if obj:
-            delete_kubernetes_object(
-                api_client=self._api_client,
-                target=obj,
-                wait=self._waiting_for_delete,
-                timeout_seconds=self._timeout_seconds,
-            )
-
-            pod_name = getattr(self, f"_{engine_type}_pod_name")
-            pod_ip = getattr(self, f"_{engine_type}_pod_ip")
-            pod_host_ip = getattr(self, f"_{engine_type}_pod_host_ip")
-            del resource_object[object_id]
-            del pod_name[object_id]
-            del pod_ip[object_id]
-            del pod_host_ip[object_id]
-
-    def deploy_analytical_engine(self):
-        return self.deploy_engine("analytical")
-
-    def deploy_analytical_java_engine(self):
-        return self.deploy_engine("analytical-java")
-
-    def deploy_interactive_engine(self, object_id):
-        pod_name_list, pod_ip_list, pod_host_ip_list = self.deploy_engine(
-            "interactive", object_id
-        )
-        try:
-            response = self._core_api.read_namespaced_pod(
-                pod_name_list[0], self._namespace
-            )
-        except K8SApiException:
-            logger.exception(
-                "Get pod %s error, please check if the pod is ready",
-                pod_name_list[0],
-            )
-        owner_references = [
-            kube_client.V1OwnerReference(
-                api_version=response.metadata.owner_references[0].api_version,
-                kind=response.metadata.owner_references[0].kind,
-                name=response.metadata.owner_references[0].name,
-                uid=response.metadata.owner_references[0].uid,
-            )
-        ]
-        name = f"gs-interactive-frontend-{object_id}-{self._instance_id}"
-        self._create_frontend_deployment(name, owner_references)
-
-        return pod_name_list, pod_ip_list, pod_host_ip_list
-
-    def deploy_learning_engine(self, object_id):
-        return self.deploy_engine("learning", object_id)
-
-    def delete_interactive_engine(self, object_id):
-        self.delete_engine_stateful_set_with_object_id("interactive", object_id)
-
-    def delete_learning_engine(self, object_id):
-        self.delete_engine_stateful_set_with_object_id("learning", object_id)
-
-    def _allocate_interactive_engine(self, object_id):
-        # check the interactive engine flag
+    def create_interactive_instance(self, object_id: int, schema_path: str):
         if not self._with_interactive:
             raise NotImplementedError("Interactive engine not enabled")
-
-        # allocate analytical engine based on the mode
-        if self._deploy_mode == "eager":
-            return self._pod_name_list, self._pod_ip_list, self._pod_host_ip_list
-        return self.deploy_interactive_engine(object_id)
-
-    def _distribute_interactive_process(
-        self, hosts, object_id: int, schema_path: str, engine_selector: str
-    ):
         """
         Args:
-            hosts (str): hosts of the graph.
             object_id (int): object id of the graph.
             schema_path (str): path of the schema file.
-            engine_selector(str): the label selector of the engine.
         """
         env = os.environ.copy()
         env["GRAPHSCOPE_HOME"] = GRAPHSCOPE_HOME
         container = self._engine_cluster.interactive_executor_container_name
         cmd = [
             INTERACTIVE_ENGINE_SCRIPT,
             "create_gremlin_instance_on_k8s",
             self._session_workspace,
             str(object_id),
             schema_path,
-            hosts,
+            self.hosts,
             container,
             str(self._interactive_port),  # executor port
             str(self._interactive_port + 1),  # executor rpc port
             str(self._interactive_port + 2),  # frontend port
             self._coordinator_name,
-            engine_selector,
         ]
         self._interactive_port += 3
         logger.info("Create GIE instance with command: %s", " ".join(cmd))
         process = subprocess.Popen(
             cmd,
             start_new_session=True,
             cwd=os.getcwd(),
@@ -644,46 +390,24 @@
             stdout=subprocess.PIPE,
             stderr=subprocess.STDOUT,
             bufsize=1,
             universal_newlines=True,
         )
         return process
 
-    def create_interactive_instance(self, object_id: int, schema_path: str):
-        pod_name_list, _, _ = self._allocate_interactive_engine(object_id)
-        if not pod_name_list:
-            raise RuntimeError("Failed to allocate interactive engine")
-        hosts = ",".join(pod_name_list)
-
-        engine_selector = "gs-engine-" + self._instance_id
-        if self._deploy_mode == "lazy":
-            engine_selector = (
-                "gs-interactive-" + str(object_id) + "-" + self._instance_id
-            )
-
-        return self._distribute_interactive_process(
-            hosts, object_id, schema_path, engine_selector
-        )
-
     def close_interactive_instance(self, object_id):
-        if self._deploy_mode == "lazy":
-            logger.info("Close interactive instance with object id: %d", object_id)
-            self.delete_interactive_engine(object_id)
-            return None
-        pod_name_list, _, _ = self._allocate_interactive_engine(object_id)
-        hosts = ",".join(pod_name_list)
         env = os.environ.copy()
         env["GRAPHSCOPE_HOME"] = GRAPHSCOPE_HOME
         container = self._engine_cluster.interactive_executor_container_name
         cmd = [
             INTERACTIVE_ENGINE_SCRIPT,
             "close_gremlin_instance_on_k8s",
             self._session_workspace,
             str(object_id),
-            hosts,
+            self.hosts,
             container,
             self._instance_id,
         ]
         logger.info("Close GIE instance with command: %s", " ".join(cmd))
         process = subprocess.Popen(
             cmd,
             start_new_session=True,
@@ -704,246 +428,58 @@
         deployment = self._mars_cluster.get_mars_deployment()
         deployment.metadata.owner_references = self._owner_references
         response = self._apps_api.create_namespaced_deployment(
             self._namespace, deployment
         )
         self._resource_object.append(response)
 
-    # The function is used to inject vineyard as a sidecar container into the workload
-    # and return the json string of new workload which is injected with vineyard sidecar
-    #
-    # Assume we have a workload json as below:
-    #
-    # {
-    #  "apiVersion": "apps/v1",
-    #  "kind": "Deployment",
-    #  "metadata": {
-    #    "name": "nginx-deployment",
-    #    "namespace": "vineyard-job"
-    #  },
-    #  "spec": {
-    #    "selector": {
-    #      "matchLabels": {
-    #        "app": "nginx"
-    #      }
-    #    },
-    #    "template": {
-    #      "metadata": {
-    #        "labels": {
-    #          "app": "nginx"
-    #        }
-    #      },
-    #      "spec": {
-    #        "containers": [
-    #          {
-    #            "name": "nginx",
-    #            "image": "nginx:1.14.2",
-    #            "ports": [
-    #              {
-    #                "containerPort": 80
-    #              }
-    #            ]
-    #          }
-    #        ]
-    #      }
-    #    }
-    #  }
-    # }
-    #
-    # The function will return a new workload json as below:
-    #
-    # {
-    #  "apiVersion": "apps/v1",
-    #  "kind": "Deployment",
-    #  "metadata": {
-    #    "creationTimestamp": null,
-    #    "name": "nginx-deployment",
-    #    "namespace": "vineyard-job"
-    #  },
-    #  "spec": {
-    #    "selector": {
-    #      "matchLabels": {
-    #        "app": "nginx"
-    #      }
-    #    }
-    #  },
-    #  "template": {
-    #    "metadata": null,
-    #    "labels": {
-    #      "app": "nginx",
-    #      "app.vineyard.io/name": "vineyard-sidecar"
-    #    },
-    #    "spec": {
-    #      "containers": [
-    #        {
-    #          "command": null,
-    #          "image": "nginx:1.14.2",
-    #          "name": "nginx",
-    #          "ports": [
-    #            {
-    #              "containerPort": 80
-    #            }
-    #          ],
-    #          "volumeMounts": [
-    #            {
-    #              "mountPath": "/var/run",
-    #              "name": "vineyard-socket"
-    #            }
-    #          ]
-    #        },
-    #        {
-    #          "command": [
-    #            "/bin/bash",
-    #            "-c",
-    #            "/usr/bin/wait-for-it.sh -t 60 vineyard-sidecar-etcd-service.vineyard-job.svc.cluster.local:2379; \\\n
-    #             sleep 1; /usr/local/bin/vineyardd --sync_crds true --socket /var/run/vineyard.sock --size 256Mi \\\n
-    #             --stream_threshold 80 --etcd_cmd etcd --etcd_prefix /vineyard \\\n
-    #             --etcd_endpoint http://vineyard-sidecar-etcd-service:2379\n"
-    #          ],
-    #          "env": [
-    #            {
-    #              "name": "VINEYARDD_UID",
-    #              "value": null
-    #            },
-    #            {
-    #              "name": "VINEYARDD_NAME",
-    #              "value": "vineyard-sidecar"
-    #            },
-    #            {
-    #              "name": "VINEYARDD_NAMESPACE",
-    #              "value": "vineyard-job"
-    #            }
-    #          ],
-    #          "image": "vineyardcloudnative/vineyardd:latest",
-    #          "imagePullPolicy": "IfNotPresent",
-    #          "name": "vineyard-sidecar",
-    #          "ports": [
-    #            {
-    #              "containerPort": 9600,
-    #              "name": "vineyard-rpc",
-    #              "protocol": "TCP"
-    #            }
-    #          ],
-    #          "volumeMounts": [
-    #            {
-    #              "mountPath": "/var/run",
-    #              "name": "vineyard-socket"
-    #            }
-    #          ]
-    #        }
-    #      ],
-    #      "volumes": [
-    #        {
-    #          "emptyDir": {},
-    #          "name": "vineyard-socket"
-    #        }
-    #      ]
-    #    }
-    #  }
-    # }
-
-    def _inject_vineyard_as_sidecar(self, workload):
-        import vineyard
-
-        # create the annotations for the workload's template if not exists
-        if workload.spec.template.metadata.annotations is None:
-            workload.spec.template.metadata.annotations = {}
-
-        # create the labels for the workload's template if not exists
-        if workload.spec.template.metadata.labels is None:
-            workload.spec.template.metadata.labels = {}
-
-        workload_json = json.dumps(
-            self._api_client.sanitize_for_serialization(workload)
-        )
-
-        sts_name = (
-            f"{self._engine_cluster.engine_stateful_set_name}-{self._instance_id}"
-        )
-        owner_reference = [
-            {
-                "apiVersion": self._owner_references[0].api_version,
-                "kind": self._owner_references[0].kind,
-                "name": self._owner_references[0].name,
-                "uid": self._owner_references[0].uid,
-            }
-        ]
-
-        owner_reference_json = json.dumps(owner_reference)
-        # inject vineyard sidecar into the workload
-        #
-        # the name is used to specify the name of the sidecar container, which is also the
-        # labelSelector of the rpc service and the etcd service.
-        #
-        # the apply_resources is used to apply resources to the kubernetes cluster during
-        # the injection.
-        #
-        # for more details about vineyardctl inject, please refer to the link below:
-        # https://github.com/v6d-io/v6d/tree/main/k8s/cmd#vineyardctl-inject
-
-        new_workload_json = vineyard.deploy.vineyardctl.inject(
-            kubeconfig=self._k8s_config_file,
-            resource=workload_json,
-            sidecar_volume_mountpath="/tmp/vineyard_workspace",
-            name=sts_name + "-vineyard",
-            apply_resources=True,
-            owner_references=owner_reference_json,
-            sidecar_image=self._vineyard_image,
-            sidecar_size=self._vineyard_shared_mem,
-            sidecar_cpu=self._vineyard_cpu,
-            sidecar_memory=self._vineyard_mem,
-            sidecar_service_type=self._service_type,
-            output="json",
-            capture=True,
-        )
-
-        normalized_workload_json = json.loads(new_workload_json)
-        final_workload_json = json.loads(normalized_workload_json["workload"])
-
-        fake_kube_response = FakeKubeResponse(final_workload_json)
-
-        new_workload = self._api_client.deserialize(fake_kube_response, type(workload))
-        return new_workload
-
     def _create_engine_stateful_set(self):
+        logger.info("Create engine headless services...")
+        service = self._engine_cluster.get_engine_headless_service()
+        service.metadata.owner_references = self._owner_references
+        response = self._core_api.create_namespaced_service(self._namespace, service)
+        self._resource_object.append(response)
         logger.info("Creating engine pods...")
 
         stateful_set = self._engine_cluster.get_engine_stateful_set()
-        if self._vineyard_deployment is not None:
+        if self.vineyard_deployment_exists():
             # schedule engine statefulset to the same node with vineyard deployment
             stateful_set = self._add_pod_affinity_for_vineyard_deployment(
                 workload=stateful_set
             )
-        else:
-            stateful_set = self._inject_vineyard_as_sidecar(stateful_set)
 
+        stateful_set.metadata.owner_references = self._owner_references
         response = self._apps_api.create_namespaced_stateful_set(
             self._namespace, stateful_set
         )
         self._resource_object.append(response)
-        return response
 
-    def _create_frontend_deployment(self, name=None, owner_references=None):
+    def _create_frontend_deployment(self):
         logger.info("Creating frontend pods...")
         deployment = self._engine_cluster.get_interactive_frontend_deployment()
-        if name is not None:
-            deployment.metadata.name = name
-        deployment.metadata.owner_references = owner_references
+        deployment.metadata.owner_references = self._owner_references
         response = self._apps_api.create_namespaced_deployment(
             self._namespace, deployment
         )
         self._resource_object.append(response)
 
     def _create_frontend_service(self):
         logger.info("Creating frontend service...")
         service = self._engine_cluster.get_interactive_frontend_service(8233)
         service.metadata.owner_references = self._owner_references
         response = self._core_api.create_namespaced_service(self._namespace, service)
         self._resource_object.append(response)
 
+    def _create_vineyard_service(self):
+        logger.info("Creating vineyard service...")
+        service = self._engine_cluster.get_vineyard_service()
+        service.metadata.owner_references = self._owner_references
+        response = self._core_api.create_namespaced_service(self._namespace, service)
+        self._resource_object.append(response)
+
     def _create_learning_service(self, object_id):
         logger.info("Creating learning service...")
         service = self._engine_cluster.get_learning_service(
             object_id, self._learning_start_port
         )
         service.metadata.owner_references = self._owner_references
         response = self._core_api.create_namespaced_service(self._namespace, service)
@@ -963,14 +499,16 @@
         self._create_engine_stateful_set()
         if self._with_interactive:
             self._create_frontend_deployment()
             # self._create_frontend_service()
         if self._with_mars:
             # scheduler used by Mars
             self._create_mars_scheduler()
+        if self._vineyard_deployment is None:
+            self._create_vineyard_service()
 
     def _waiting_for_services_ready(self):
         logger.info("Waiting for services ready...")
         selector = ""
         namespace = self._namespace
         start_time = time.time()
         event_messages = []
@@ -1031,14 +569,15 @@
             self._pod_name_list.append(pod.metadata.name)
             self._pod_ip_list.append(pod.status.pod_ip)
             self._pod_host_ip_list.append(pod.status.host_ip)
         assert len(self._pod_ip_list) > 0
         self._analytical_engine_endpoint = (
             f"{self._pod_ip_list[0]}:{self._random_analytical_engine_rpc_port}"
         )
+
         self._vineyard_service_endpoint = (
             self._engine_cluster.get_vineyard_service_endpoint(self._api_client)
         )
         self._vineyard_internal_endpoint = (
             f"{self._pod_ip_list[0]}:{self._engine_cluster._vineyard_service_port}"
         )
 
@@ -1071,15 +610,14 @@
     def _add_pod_affinity_for_vineyard_deployment(self, workload):
         import vineyard
 
         workload_json = json.dumps(
             self._api_client.sanitize_for_serialization(workload)
         )
         new_workload_json = vineyard.deploy.vineyardctl.schedule.workload(
-            kubeconfig=self._k8s_config_file,
             resource=workload_json,
             vineyardd_name=self._vineyard_deployment,
             vineyardd_namespace=self._namespace,
             capture=True,
         )
 
         normalized_workload_json = json.loads(new_workload_json)
@@ -1093,58 +631,36 @@
             resource[self._namespace] = "Namespace"
         else:
             # coordinator info
             resource[self._coordinator_name] = "Deployment"
             resource[self._coordinator_service_name] = "Service"
         self._resource_object.dump(extra_resource=resource)
 
-    def _get_analytical_hosts(self):
-        pod_name_list = self._pod_name_list
-        if self._analytical_pod_name:
-            pod_name_list = self._analytical_pod_name
-        return pod_name_list
-
-    def _allocate_analytical_engine(self):
-        # check the engine flag
-        if self._with_analytical and self._with_analytical_java:
-            logger.info(
-                "Analytical engine and analytical engine(java) cannot be enabled at the same time. "
-                "Proceeding to only enable analytical_java."
-            )
-            self._with_analytical = False
-        elif not (self._with_analytical or self._with_analytical_java):
-            raise NotImplementedError(
-                "Neither analytical engine nor analytical engine(java) is enabled."
-            )
-
-        # allocate analytical engine based on the mode
-        if self._deploy_mode == "eager":
-            return self._pod_name_list, self._pod_ip_list, self._pod_host_ip_list
-        else:
-            if self._with_analytical:
-                return self.deploy_analytical_engine()
-            else:
-                return self.deploy_analytical_java_engine()
+    def create_analytical_instance(self):
+        if not (self._with_analytical or self._with_analytical_java):
+            raise NotImplementedError("Analytical engine not enabled")
+        logger.info(
+            "Starting GAE rpc service on %s ...", self._analytical_engine_endpoint
+        )
 
-    def _distribute_analytical_process(self, pod_name_list, pod_ip_list):
         # generate and distribute hostfile
-        hosts = os.path.join(get_tempdir(), "kube_hosts")
-        with open(hosts, "w") as f:
-            for i, pod_ip in enumerate(pod_ip_list):
-                f.write(f"{pod_ip} {pod_name_list[i]}\n")
-
-        container = self._engine_cluster.analytical_container_name
-        for pod in pod_name_list:
-            logger.debug(
-                run_kube_cp_command(hosts, "/tmp/hosts_of_nodes", pod, container, True)
-            )
+        kube_hosts_path = os.path.join(get_tempdir(), "kube_hosts")
+        with open(kube_hosts_path, "w") as f:
+            for i, pod_ip in enumerate(self._pod_ip_list):
+                f.write(f"{pod_ip} {self._pod_name_list[i]}\n")
+
+        for pod in self._pod_name_list:
+            container = self._engine_cluster.analytical_container_name
+            cmd = f"kubectl -n {self._namespace} cp {kube_hosts_path} {pod}:/tmp/hosts_of_nodes -c {container}"
+            cmd = shlex.split(cmd)
+            subprocess.check_call(cmd)
 
         # launch engine
         rmcp = ResolveMPICmdPrefix(rsh_agent=True)
-        cmd, mpi_env = rmcp.resolve(self._num_workers, ",".join(pod_name_list))
+        cmd, mpi_env = rmcp.resolve(self._num_workers, ",".join(self._pod_name_list))
 
         cmd.append(ANALYTICAL_ENGINE_PATH)
         cmd.extend(["--host", "0.0.0.0"])
         cmd.extend(["--port", str(self._random_analytical_engine_rpc_port)])
 
         cmd.extend(["-v", str(self._glog_level)])
         mpi_env["GLOG_v"] = str(self._glog_level)
@@ -1172,24 +688,14 @@
         )
         stderr_watcher = PipeWatcher(
             self._analytical_engine_process.stderr, sys.stderr, drop=True
         )
         setattr(self._analytical_engine_process, "stdout_watcher", stdout_watcher)
         setattr(self._analytical_engine_process, "stderr_watcher", stderr_watcher)
 
-    def create_analytical_instance(self):
-        pod_name_list, pod_ip_list, _ = self._allocate_analytical_engine()
-        if not pod_name_list or not pod_ip_list:
-            raise RuntimeError("Failed to allocate analytical engine.")
-        logger.info(
-            "Starting GAE rpc service on %s ...", self._analytical_engine_endpoint
-        )
-
-        self._distribute_analytical_process(pod_name_list, pod_ip_list)
-
     def _delete_dangling_coordinator(self):
         # delete service
         try:
             self._core_api.delete_namespaced_service(
                 self._coordinator_service_name, self._namespace
             )
         except K8SApiException as ex:
@@ -1234,87 +740,22 @@
                     time.sleep(1)
                     if time.time() - start_time > self._timeout_seconds:
                         logger.error(
                             "Deleting dangling coordinator %s timeout",
                             self._coordinator_name,
                         )
 
-    def _get_owner_reference_as_json(self):
-        owner_reference = [
-            {
-                "apiVersion": self._owner_references[0].api_version,
-                "kind": self._owner_references[0].kind,
-                "name": self._owner_references[0].name,
-                "uid": self._owner_references[0].uid,
-            }
-        ]
-        owner_reference_json = json.dumps(owner_reference)
-        return owner_reference_json
-
-    def _check_if_vineyard_deployment_exist(self):
-        try:
-            self._apps_api.read_namespaced_deployment(
-                self._vineyard_deployment, self._namespace
-            )
-        except K8SApiException:
-            logger.info(
-                "Vineyard deployment %s/%s not exist",
-                self._namespace,
-                self._vineyard_deployment,
-            )
-            return False
-        return True
-
-    def _deploy_vineyard_deployment_if_not_exist(self):
-        if not self._check_if_vineyard_deployment_exist():
-            self._deploy_vineyard_deployment()
-        else:
-            logger.info(
-                "The external vineyard deployment %s is ready."
-                "Please make sure the type of the vineyard rpc service is the same as %s.",
-                self._vineyard_deployment,
-                self._service_type,
-            )
-
-    def _deploy_vineyard_deployment(self):
-        import vineyard
-
-        owner_reference_json = self._get_owner_reference_as_json()
-        vineyard.deploy.vineyardctl.deploy.vineyard_deployment(
-            kubeconfig=self._k8s_config_file,
-            name=self._vineyard_deployment,
-            namespace=self._namespace,
-            vineyard_replicas=self._num_workers,
-            vineyard_etcd_replicas=self._num_workers,
-            vineyardd_image=self._vineyard_image,
-            vineyardd_memory=self._vineyard_mem,
-            vineyardd_cpu=self._vineyard_cpu,
-            vineyardd_size=self._vineyard_shared_mem,
-            vineyardd_service_type=self._service_type,
-            owner_references=owner_reference_json,
-        )
-        vineyard_pods = self._core_api.list_namespaced_pod(
-            self._namespace,
-            label_selector="app.kubernetes.io/instance="
-            + self._namespace
-            + "-"
-            + self._vineyard_deployment,
-        )
-        for pod in vineyard_pods.items:
-            self._vineyard_pod_name_list.append(pod.metadata.name)
-
     def start(self):
         if self._serving:
             return True
         try:
-            if self._deploy_mode == "eager":
-                self._create_services()
-                self._waiting_for_services_ready()
-                self._dump_resource_object()
-                self._serving = True
+            self._create_services()
+            self._waiting_for_services_ready()
+            self._dump_resource_object()
+            self._serving = True
         except Exception:  # pylint: disable=broad-except
             time.sleep(1)
             logger.exception("Error when launching GraphScope on kubernetes cluster")
             self.stop()
             return False
         return True
 
@@ -1356,39 +797,29 @@
                                     )
                 else:
                     # delete coordinator deployment and service
                     self._delete_dangling_coordinator()
             self._serving = False
             logger.info("Kubernetes launcher stopped")
 
-    def _allocate_learining_engine(self, object_id):
-        # check the learning engine flag
+    def create_learning_instance(self, object_id, handle, config):
         if not self._with_learning:
             raise NotImplementedError("Learning engine not enabled")
-
-        # allocate learning engine based on the mode
-        if self._deploy_mode == "eager":
-            return self._pod_name_list, self._pod_ip_list, self._pod_host_ip_list
-        return self.deploy_learning_engine(object_id)
-
-    def _distribute_learning_process(
-        self, pod_name_list, pod_host_ip_list, object_id, handle, config
-    ):
         # allocate service for ports
         # prepare arguments
         handle = json.loads(
             base64.b64decode(handle.encode("utf-8", errors="ignore")).decode(
                 "utf-8", errors="ignore"
             )
         )
         hosts = ",".join(
             [
                 f"{pod_name}:{port}"
                 for pod_name, port in zip(
-                    pod_name_list,
+                    self._pod_name_list,
                     self._engine_cluster.get_learning_ports(self._learning_start_port),
                 )
             ]
         )
         handle["server"] = hosts
         handle = base64.b64encode(
             json.dumps(handle).encode("utf-8", errors="ignore")
@@ -1396,17 +827,18 @@
 
         # launch the server
         self._learning_instance_processes[object_id] = []
         for pod_index, pod in enumerate(self._pod_name_list):
             container = self._engine_cluster.learning_container_name
             sub_cmd = f"python3 -m gscoordinator.learning {handle} {config} {pod_index}"
             cmd = f"kubectl -n {self._namespace} exec -it -c {container} {pod} -- {sub_cmd}"
-            logger.debug("launching learning server: %s", " ".join(cmd))
+            logging.debug("launching learning server: %s", " ".join(cmd))
+            cmd = shlex.split(cmd)
             proc = subprocess.Popen(
-                shlex.split(cmd),
+                cmd,
                 stdout=subprocess.PIPE,
                 stderr=subprocess.STDOUT,
                 encoding="utf-8",
                 errors="replace",
                 universal_newlines=True,
                 bufsize=1,
             )
@@ -1418,32 +850,21 @@
             )
             setattr(proc, "stdout_watcher", stdout_watcher)
             self._learning_instance_processes[object_id].append(proc)
 
         # Create Service
         self._create_learning_service(object_id)
         # update the port usage record
-        self._learning_start_port += len(pod_name_list)
+        self._learning_start_port += len(self._pod_name_list)
         # parse the service hosts and ports
         return self._engine_cluster.get_graphlearn_service_endpoint(
-            self._api_client, object_id, pod_host_ip_list
-        )
-
-    def create_learning_instance(self, object_id, handle, config):
-        pod_name_list, _, pod_host_ip_list = self._allocate_learining_engine(object_id)
-        if not pod_name_list or not pod_host_ip_list:
-            raise RuntimeError("Failed to allocate learning engine")
-        return self._distribute_learning_process(
-            pod_name_list, pod_host_ip_list, object_id, handle, config
+            self._api_client, object_id, self._pod_host_ip_list
         )
 
     def close_learning_instance(self, object_id):
-        if self._deploy_mode == "lazy":
-            self.delete_learning_engine(object_id)
-            return
         if object_id not in self._learning_instance_processes:
             return
         # delete the services
         target = self._graphlearn_services[object_id]
         try:
             delete_kubernetes_object(
                 api_client=self._api_client,
```

## gscoordinator/coordinator.py

```diff
@@ -862,20 +862,14 @@
         type=str2bool,
         nargs="?",
         const=False,
         default=False,
         help="Mount the aliyun dataset bucket as a volume by ossfs.",
     )
     parser.add_argument(
-        "--k8s_deploy_mode",
-        type=str,
-        default="eager",
-        help="The deploying mode of graphscope, eager or lazy.",
-    )
-    parser.add_argument(
         "--monitor",
         type=str2bool,
         nargs="?",
         const=False,
         default=False,
         help="Enable or disable prometheus exporter.",
     )
@@ -935,15 +929,14 @@
             vineyard_mem=args.k8s_vineyard_mem,
             vineyard_shared_mem=args.vineyard_shared_mem,
             volumes=args.k8s_volumes,
             waiting_for_delete=args.waiting_for_delete,
             with_mars=args.k8s_with_mars,
             enabled_engines=args.k8s_enabled_engines,
             dataset_proxy=args.dataset_proxy,
-            deploy_mode=args.k8s_deploy_mode,
         )
     elif args.cluster_type == "hosts":
         launcher = LocalLauncher(
             num_workers=args.num_workers,
             hosts=args.hosts,
             etcd_addrs=args.etcd_addrs,
             etcd_listening_client_port=args.etcd_listening_client_port,
@@ -988,17 +981,17 @@
 
     if args.monitor:
         try:
             Monitor.startServer(args.monitor_port, "0.0.0.0")
             logger.info(
                 "Coordinator monitor server listen at 0.0.0.0:%d", args.monitor_port
             )
-        except Exception:  # noqa: E722, pylint: disable=broad-except
-            logger.exception(
-                "Failed to start monitor server 0.0.0.0:%d", args.monitor_port
+        except Exception as e:
+            logger.error(
+                "Failed to start monitor server 0.0.0.0:%d : %s", args.monitor_port, e
             )
 
     # handle SIGTERM signal
     def terminate(signum, frame):
         server.stop(True)
         coordinator_service_servicer.cleanup()
```

## gscoordinator/op_executor.py

```diff
@@ -13,15 +13,15 @@
 from graphscope.framework import utils
 from graphscope.framework.dag_utils import create_graph
 from graphscope.framework.dag_utils import create_loader
 from graphscope.framework.errors import AnalyticalEngineInternalError
 from graphscope.framework.graph_utils import normalize_parameter_edges
 from graphscope.framework.graph_utils import normalize_parameter_vertices
 from graphscope.framework.loader import Loader
-from graphscope.framework.utils import find_java_exe
+from graphscope.framework.utils import find_java
 from graphscope.framework.utils import get_tempdir
 from graphscope.framework.utils import normalize_data_type_str
 from graphscope.proto import attr_value_pb2
 from graphscope.proto import engine_service_pb2_grpc
 from graphscope.proto import graph_def_pb2
 from graphscope.proto import message_pb2
 from graphscope.proto import op_def_pb2
@@ -333,32 +333,30 @@
     def _create_analytical_grpc_stub(self):
         options = [
             ("grpc.max_send_message_length", GS_GRPC_MAX_MESSAGE_LENGTH),
             ("grpc.max_receive_message_length", GS_GRPC_MAX_MESSAGE_LENGTH),
             ("grpc.max_metadata_size", GS_GRPC_MAX_MESSAGE_LENGTH),
         ]
         # Check connectivity, otherwise the stub is useless
-        delay = 2
-        for retry in range(8):  # approximated 255s
+        retry = 0
+        while retry < 20:
             try:
                 channel = grpc.insecure_channel(
                     self._launcher.analytical_engine_endpoint, options=options
                 )
                 stub = engine_service_pb2_grpc.EngineServiceStub(channel)
                 stub.HeartBeat(message_pb2.HeartBeatRequest())
                 return stub
             except grpc.RpcError as e:
                 logger.warning(
-                    "Connecting to analytical engine... tried %d time, will retry in %d seconds",
-                    retry + 1,
-                    delay,
+                    "Connecting to analytical engine... retrying %d time", retry
                 )
                 logger.warning("Error code: %s, details %s", e.code(), e.details())
-                time.sleep(delay)
-                delay *= 2  # back off
+                retry += 1
+                time.sleep(3)
         raise RuntimeError(
             "Failed to connect to engine in 60s, deployment may failed. Please check coordinator log for details"
         )
 
     @property
     def analytical_grpc_stub(self):
         if self._launcher.analytical_engine_endpoint is None:
@@ -373,15 +371,15 @@
         config = json.loads(
             response_head.head.results[0].result.decode("utf-8", errors="ignore")
         )
         config["engine_hosts"] = self._launcher.hosts
         # Disable ENABLE_JAVA_SDK when java is not installed on coordinator
         if config["enable_java_sdk"] == "ON":
             try:
-                find_java_exe()
+                find_java()
             except RuntimeError:
                 logger.warning(
                     "Disable java sdk support since java is not installed on coordinator"
                 )
                 config["enable_java_sdk"] = "OFF"
         return config
 
@@ -634,15 +632,14 @@
                 types_pb2.DIRECTED: utils.b_to_attr(True),
                 types_pb2.OID_TYPE: utils.s_to_attr(oid_type),
                 types_pb2.GENERATE_EID: utils.b_to_attr(False),
                 # otherwise the new graph cannot be used for GIE
                 types_pb2.RETAIN_OID: utils.b_to_attr(True),
                 types_pb2.VID_TYPE: utils.s_to_attr("uint64_t"),
                 types_pb2.IS_FROM_VINEYARD_ID: utils.b_to_attr(False),
-                types_pb2.COMPACT_EDGES: utils.b_to_attr(False),
             }
             new_op = create_graph(
                 self._session_id,
                 graph_def_pb2.ARROW_PROPERTY,
                 inputs=[loader_op],
                 attrs=config,
             )
```

## gscoordinator/cluster_builder.py

```diff
@@ -50,15 +50,14 @@
 
 class EngineCluster:
     def __init__(
         self,
         engine_cpu,
         engine_mem,
         engine_pod_node_selector,
-        engine_pod_prefix,
         glog_level,
         image_pull_policy,
         image_pull_secrets,
         image_registry,
         image_repository,
         image_tag,
         instance_id,
@@ -77,15 +76,15 @@
         with_analytical_java,
         with_dataset,
         with_interactive,
         with_learning,
         with_mars,
         dataset_proxy,
     ):
-        self._gs_prefix = engine_pod_prefix
+        self._gs_prefix = "gs-engine-"
         self._analytical_prefix = "gs-analytical-"
         self._interactive_frontend_prefix = "gs-interactive-frontend-"
 
         self._learning_prefix = "gs-learning-"
 
         self._vineyard_prefix = "vineyard-"
 
@@ -98,17 +97,15 @@
 
         self._namespace = namespace
         self._engine_labels = {
             "app.kubernetes.io/name": "graphscope",
             "app.kubernetes.io/instance": self._instance_id,
             "app.kubernetes.io/version": __version__,
             "app.kubernetes.io/component": "engine",
-            "app.kubernetes.io/engine_selector": self.engine_stateful_set_name,
         }
-
         self._frontend_labels = self._engine_labels.copy()
         self._frontend_labels["app.kubernetes.io/component"] = "frontend"
 
         self._with_dataset = with_dataset
         if not image_registry:
             image_prefix = image_repository
         else:
@@ -215,14 +212,33 @@
     def get_base_machine_env(self):
         env = [
             ResourceBuilder.get_value_from_field_ref(key, value)
             for key, value in BASE_MACHINE_ENVS.items()
         ]
         return env
 
+    def get_vineyard_socket_volume(self):
+        name = "vineyard-ipc-socket"
+        volume = kube_client.V1Volume(name=name)
+        if self._vineyard_deployment is None:
+            empty_dir = kube_client.V1EmptyDirVolumeSource()
+            volume.empty_dir = empty_dir
+        else:
+            path = f"/var/run/vineyard-kubernetes/{self._namespace}/{self._vineyard_deployment}"
+            host_path = kube_client.V1HostPathVolumeSource(path=path)
+            host_path.type = "Directory"
+            volume.host_path = host_path
+
+        source_volume_mount = kube_client.V1VolumeMount(
+            name=name, mount_path="/tmp/vineyard_workspace"
+        )
+        destination_volume_mount = source_volume_mount
+
+        return volume, source_volume_mount, destination_volume_mount
+
     def get_shm_volume(self):
         name = "host-shm"
         volume = kube_client.V1Volume(name=name)
         volume.empty_dir = kube_client.V1EmptyDirVolumeSource()
         volume.empty_dir.medium = "Memory"
 
         source_volume_mount = kube_client.V1VolumeMount(
@@ -317,14 +333,48 @@
         )
         container.ports = [
             kube_client.V1ContainerPort(container_port=p)
             for p in range(self._learning_start_port, self._learning_start_port + 1000)
         ]
         return container
 
+    def get_vineyard_container(self, volume_mounts):
+        name = self.vineyard_container_name
+        image = self._vineyard_image
+        sts_name = self.engine_stateful_set_name
+        svc_name = sts_name + "-headless"
+        pod0_dns = f"{sts_name}-0.{svc_name}.{self._namespace}.svc.cluster.local"
+        vineyard_cmd = (
+            f"vineyardd -size {self._vineyard_shared_mem} -socket {self._sock}"
+        )
+        args = f"""
+            [[ `hostname` =~ -([0-9]+)$ ]] || exit 1;
+            ordinal=${{BASH_REMATCH[1]}};
+            if (( $ordinal == 0 )); then
+                {vineyard_cmd} -etcd_endpoint http://0.0.0.0:{self._etcd_port}
+            else
+                until nslookup {pod0_dns}; do sleep 1; done;
+                {vineyard_cmd} -etcd_endpoint http://{pod0_dns}:{self._etcd_port}
+            fi;
+            """
+        args = ["bash", "-c", args]
+        container = self.get_engine_container_helper(
+            name,
+            image,
+            args,
+            volume_mounts,
+            self._vineyard_requests,
+            self._vineyard_requests,
+        )
+        container.ports = [
+            kube_client.V1ContainerPort(container_port=self._vineyard_service_port),
+            kube_client.V1ContainerPort(container_port=self._etcd_port),
+        ]
+        return container
+
     def get_mars_container(self):
         _ = self.mars_container_name
         return
 
     def get_dataset_container(self, volume_mounts):
         name = self.dataset_container_name
         container = kube_client.V1Container(name=name)
@@ -338,43 +388,23 @@
         container.volume_mounts = volume_mounts
         if self._dataset_proxy and self._dataset_proxy is not None:
             container.env = self.get_dataset_proxy_env()
 
         container.security_context = kube_client.V1SecurityContext(privileged=True)
         return container
 
-    def get_vineyard_socket_volume_from_vineyard_deployment(self):
-        name = "vineyard-ipc-socket"
-
-        # Notice, the path must be same as the one in vineyardd_types.go
-        # https://github.com/v6d-io/v6d/blob/main/k8s/apis/k8s/v1alpha1/vineyardd_types.go#L125
-        path = f"/var/run/vineyard-kubernetes/{self._namespace}/{self._vineyard_deployment}"
-        host_path = kube_client.V1HostPathVolumeSource(path=path)
-        host_path.type = "Directory"
-        volume = kube_client.V1Volume(name=name, host_path=host_path)
-        volume_mount = kube_client.V1VolumeMount(
-            name=name, mount_path="/tmp/vineyard_workspace"
-        )
-        return volume, volume_mount
-
     def get_engine_pod_spec(self):
         containers = []
         volumes = []
 
+        socket_volume = self.get_vineyard_socket_volume()
         shm_volume = self.get_shm_volume()
-        volumes = [shm_volume[0]]
-        engine_volume_mounts = [shm_volume[2]]
+        volumes.extend([socket_volume[0], shm_volume[0]])
 
-        if self.vineyard_deployment_exists():
-            (
-                volume,
-                volume_mount,
-            ) = self.get_vineyard_socket_volume_from_vineyard_deployment()
-            volumes.append(volume)
-            engine_volume_mounts.append(volume_mount)
+        engine_volume_mounts = [socket_volume[2], shm_volume[2]]
 
         if self._volumes and self._volumes is not None:
             udf_volumes = ResourceBuilder.get_user_defined_volumes(self._volumes)
             volumes.extend(udf_volumes[0])
             engine_volume_mounts.extend(udf_volumes[2])
 
         if self._with_analytical:
@@ -394,14 +424,21 @@
                 )
             )
         if self._with_learning:
             containers.append(
                 self.get_learning_container(volume_mounts=engine_volume_mounts)
             )
 
+        if self._vineyard_deployment is None:
+            containers.append(
+                self.get_vineyard_container(
+                    volume_mounts=[socket_volume[1], shm_volume[1]]
+                )
+            )
+
         if self._with_dataset:
             dataset_volume = self.get_dataset_volume()
             volumes.append(dataset_volume[0])
             containers.append(
                 self.get_dataset_container(volume_mounts=[dataset_volume[1]])
             )
             engine_volume_mounts.append(dataset_volume[2])
@@ -440,22 +477,33 @@
 
     def get_engine_headless_service(self):
         name = self.engine_stateful_set_name + "-headless"
         ports = [kube_client.V1ServicePort(name="etcd", port=self._etcd_port)]
         service_spec = ResourceBuilder.get_service_spec(
             "ClusterIP", ports, self._engine_labels, None
         )
-
         # Necessary, create a headless service for statefulset
         service_spec.cluster_ip = "None"
         service = ResourceBuilder.get_service(
             self._namespace, name, service_spec, self._engine_labels
         )
         return service
 
+    def get_vineyard_service(self):
+        service_type = self._service_type
+        name = f"{self._vineyard_prefix}{self._instance_id}"
+        ports = [kube_client.V1ServicePort(name=name, port=self._vineyard_service_port)]
+        service_spec = ResourceBuilder.get_service_spec(
+            service_type, ports, self._engine_labels, None
+        )
+        service = ResourceBuilder.get_service(
+            self._namespace, name, service_spec, self._engine_labels
+        )
+        return service
+
     def get_learning_service(self, object_id, start_port):
         service_type = self._service_type
         num_workers = self._num_workers
         name = self.get_learning_service_name(object_id)
         ports = []
         for i in range(start_port, start_port + num_workers):
             port = kube_client.V1ServicePort(name=f"{name}-{i}", port=i, protocol="TCP")
@@ -478,22 +526,23 @@
 
     @property
     def frontend_deployment_name(self):
         return f"{self._interactive_frontend_prefix}{self._instance_id}"
 
     @property
     def vineyard_service_name(self):
-        return f"{self.engine_stateful_set_name}-{self._instance_id}-vineyard-rpc"
+        return f"{self._vineyard_prefix}{self._instance_id}"
 
     def get_vineyard_service_endpoint(self, api_client):
         # return f"{self.vineyard_service_name}:{self._vineyard_service_port}"
         service_name = self.vineyard_service_name
         service_type = self._service_type
         if self.vineyard_deployment_exists():
             service_name = self._vineyard_deployment + "-rpc"
+            service_type = "ClusterIP"
         endpoints = get_service_endpoints(
             api_client=api_client,
             namespace=self._namespace,
             name=service_name,
             service_type=service_type,
         )
         assert len(endpoints) > 0
```

## gscoordinator/local_launcher.py

```diff
@@ -1,35 +1,16 @@
-#!/usr/bin/env python3
-# -*- coding: utf-8 -*-
-#
-# Copyright 2020-2023 Alibaba Group Holding Limited. All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-#
-
 import base64
 import json
 import logging
 import os
 import shutil
 import socket
 import subprocess
 import sys
 import time
-from typing import List
 
 from graphscope.framework.utils import PipeWatcher
 from graphscope.framework.utils import get_free_port
 from graphscope.framework.utils import get_java_version
 from graphscope.framework.utils import get_tempdir
 from graphscope.framework.utils import is_free_port
 from graphscope.proto import types_pb2
@@ -189,16 +170,18 @@
                 self._analytical_engine_process.kill()
                 raise RuntimeError("Launch analytical engine failed due to timeout.")
         logger.info(
             "Analytical engine is listening on %s", self._analytical_engine_endpoint
         )
 
     def create_interactive_instance(self, object_id: int, schema_path: str):
+        # check java version
         try:
-            logger.info("Java version: %s", get_java_version())
+            java_version = get_java_version()
+            logger.info("Java version: %s", java_version)
         except:  # noqa: E722
             logger.exception("Cannot get version of java")
 
         env = os.environ.copy()
         env["GRAPHSCOPE_HOME"] = GRAPHSCOPE_HOME
         if ".install_prefix" in INTERACTIVE_ENGINE_SCRIPT:
             env["GRAPHSCOPE_HOME"] = os.path.dirname(
@@ -494,16 +477,15 @@
                     self._vineyardd_process.kill()
                     # outs, _ = self._vineyardd_process.communicate()
                     # logger.error("Start vineyardd timeout, %s", outs)
                     raise RuntimeError("Launch vineyardd failed due to timeout.")
         stdout_watcher.drop(True)
         stdout_watcher.suppress(not logger.isEnabledFor(logging.DEBUG))
         logger.info(
-            "Vineyardd is ready, ipc socket is %s",
-            self._vineyard_socket,
+            "Vineyardd is ready, ipc socket is {0}".format(self._vineyard_socket)
         )
 
     def close_etcd(self):
         self._stop_subprocess(self._etcd_process)
 
     def close_vineyard(self):
         self._stop_subprocess(self._vineyardd_process, kill=True)
@@ -516,19 +498,19 @@
             else:
                 proc.terminate()
 
     def distribute_file(self, path) -> None:
         dir = os.path.dirname(path)
         for host in self.hosts.split(","):
             if host not in ("localhost", "127.0.0.1"):
-                logger.debug(run_command(f"ssh {host} mkdir -p {dir}"))  # noqa: G004
-                logger.debug(run_command(f"scp -r {path} {host}:{path}"))  # noqa: G004
+                logger.debug(run_command(f"ssh {host} mkdir -p {dir}"))
+                logger.debug(run_command(f"scp -r {path} {host}:{path}"))
 
     @staticmethod
-    def find_etcd() -> List[str]:
+    def find_etcd() -> [str]:
         etcd = shutil.which("etcd")
         if etcd is None:
             etcd = [sys.executable, "-m", "etcd_distro.etcd"]
         else:
             etcd = [etcd]
         return etcd
```

## gscoordinator/VERSION

```diff
@@ -1 +1 @@
-0.22.0
+0.22.0a20230515
```

## gscoordinator/utils.py

```diff
@@ -39,15 +39,15 @@
 
 import yaml
 from google.protobuf.any_pb2 import Any
 from graphscope.framework import utils
 from graphscope.framework.errors import CompilationError
 from graphscope.framework.graph_schema import GraphSchema
 from graphscope.framework.utils import PipeWatcher
-from graphscope.framework.utils import find_java_exe
+from graphscope.framework.utils import find_java
 from graphscope.framework.utils import get_platform_info
 from graphscope.framework.utils import get_tempdir
 from graphscope.proto import attr_value_pb2
 from graphscope.proto import data_types_pb2
 from graphscope.proto import graph_def_pb2
 from graphscope.proto import op_def_pb2
 from graphscope.proto import types_pb2
@@ -219,19 +219,17 @@
             f"{app_type}.{app_class}.{graph_type}".encode("utf-8", errors="ignore")
         ).hexdigest()
     elif app_type == "java_pie":
         s = hashlib.sha256()
         s.update(f"{graph_type}.{vd_type}".encode("utf-8", errors="ignore"))
         app_sha256 = s.hexdigest()
         logger.info(
-            "app sha256 for app %s with graph %s:%s, is %s",
-            java_app_class,
-            app_type,
-            java_app_class,
-            app_sha256,
+            "app sha256 for app {} with graph {}:{}, is {}".format(
+                java_app_class, app_type, java_app_class, app_sha256
+            )
         )
     else:
         s = hashlib.sha256()
         s.update(
             f"{app_type}.{app_class}.{graph_type}".encode("utf-8", errors="ignore")
         )
         if types_pb2.GAR in attr:
@@ -297,37 +295,26 @@
     return cp.stdout.decode("utf-8", errors="ignore")
 
 
 def delegate_command_to_pod(args: str, pod: str, container: str):
     """Delegate a command to a pod.
 
     Args:
-         command (str): Command to be delegated.
-         pod_name (str): Pod name.
-         namespace (str): Namespace of the pod.
+        command (str): Command to be delegated.
+        pod_name (str): Pod name.
+        namespace (str): Namespace of the pod.
 
-     Returns:
-         str: Output of the command.
+    Returns:
+        str: Output of the command.
     """
     # logger.info("Delegate command to pod: %s, %s, %s", args, pod, container)
     args = f'kubectl exec -c {container} {pod} -- bash -c "{args}"'
     return run_command(args)
 
 
-def run_kube_cp_command(src, dst, pod, container=None, host_to_pod=True):
-    if host_to_pod:
-        cmd = f"kubectl cp {src} {pod}:{dst}"
-    else:
-        cmd = f"kubectl cp {pod}:{src} {dst}"
-    if container is not None:
-        cmd = f"{cmd} -c {container}"
-    cmd = f"{cmd} --retries=5"
-    return run_command(cmd)
-
-
 def compile_library(commands, workdir, output_name, launcher):
     if launcher.type() == types_pb2.K8S:
         return _compile_on_kubernetes(
             commands,
             workdir,
             output_name,
             launcher.hosts_list[0],
@@ -345,56 +332,59 @@
         commands,
         workdir,
         output_name,
         pod,
         container,
     )
     try:
-        lib_path = get_lib_path(workdir, output_name)
+        full_path = get_lib_path(workdir, output_name)
         try:
             # The library may exists in the analytical pod.
-            test_cmd = f"test -f {lib_path}"
+            test_cmd = f"test -f {full_path}"
             logger.debug(delegate_command_to_pod(test_cmd, pod, container))
             logger.info("Library exists, skip compilation")
-            logger.debug(run_kube_cp_command(lib_path, lib_path, pod, container, False))
-            return lib_path
+            cp = f"kubectl cp {pod}:{full_path} {full_path} -c {container}"
+            logger.debug(run_command(cp))
+            return full_path
         except RuntimeError:
             pass
         parent_dir = os.path.dirname(workdir)
         mkdir = f"mkdir -p {parent_dir}"
         logger.debug(delegate_command_to_pod(mkdir, pod, container))
-        logger.debug(run_kube_cp_command(workdir, workdir, pod, container, True))
+        cp = f"kubectl cp {workdir} {pod}:{workdir} -c {container}"
+        logger.debug(run_command(cp))
         for command in commands:
             command = f"cd {workdir} && {command}"
             logger.debug(delegate_command_to_pod(command, pod, container))
-        logger.debug(run_kube_cp_command(lib_path, lib_path, pod, container, False))
-        if not os.path.isfile(lib_path):
+        cp = f"kubectl cp {pod}:{full_path} {full_path} -c {container}"
+        logger.debug(run_command(cp))
+        if not os.path.isfile(full_path):
             logger.error("Could not find desired library, found files are:")
             logger.error(os.listdir(workdir))
-            raise FileNotFoundError(lib_path)
+            raise FileNotFoundError(full_path)
     except Exception as e:
         raise CompilationError(f"Failed to compile {output_name} on kubernetes") from e
-    return lib_path
+    return full_path
 
 
 def _compile_on_local(commands, workdir, output_name):
     logger.info("compile on local, %s, %s, %s", commands, workdir, output_name)
     try:
         for command in commands:
             logger.debug(run_command(command, cwd=workdir))
-        lib_path = get_lib_path(workdir, output_name)
-        if not os.path.isfile(lib_path):
+        full_path = get_lib_path(workdir, output_name)
+        if not os.path.isfile(full_path):
             logger.error("Could not find desired library")
             logger.info(os.listdir(workdir))
-            raise FileNotFoundError(lib_path)
+            raise FileNotFoundError(full_path)
     except Exception as e:
         raise CompilationError(
             f"Failed to compile {output_name} on platform {get_platform_info()}"
         ) from e
-    return lib_path
+    return full_path
 
 
 def compile_app(
     workspace: str,
     library_name: str,
     attr: dict,
     engine_config: dict,
@@ -829,26 +819,26 @@
     if "engine_jvm_opts" in kwargs:
         engine_jvm_opts = kwargs.pop("engine_jvm_opts")
         op.attr[types_pb2.JVM_OPTS].CopyFrom(utils.s_to_attr(engine_jvm_opts))
 
     app_type = parent_op.attr[types_pb2.APP_ALGO].s.decode("utf-8", errors="ignore")
 
     if app_type.startswith("java_pie:") or app_type.startswith("giraph:"):
-        logger.debug("args length: %s", len(op.query_args.args))
+        logger.debug("args len: {}".format(len(op.query_args.args)))
         if len(op.query_args.args) == 1:
             original_json_param = data_types_pb2.StringValue()
             op.query_args.args[0].Unpack(original_json_param)
-            logger.debug("original user params: %s", original_json_param)
+            logger.debug("original user param {}".format(original_json_param))
             user_params = json.loads(original_json_param.value)
             del op.query_args.args[0]
         elif len(op.query_args.args) == 0:
             user_params = {}
         else:
             raise RuntimeError(
-                "Unexpected num of params: {}".format(len(op.query_args.args))
+                "Unexpected num of params{}".format(len(op.query_args.args))
             )
         # we need extra param in first arg.
         user_params["jar_name"] = engine_java_class_path
         user_params["frag_name"] = "gs::ArrowProjectedFragment<{},{},{},{}>".format(
             parent_op.attr[types_pb2.OID_TYPE].s.decode("utf-8", errors="ignore"),
             parent_op.attr[types_pb2.VID_TYPE].s.decode("utf-8", errors="ignore"),
             parent_op.attr[types_pb2.V_DATA_TYPE].s.decode("utf-8", errors="ignore"),
@@ -858,25 +848,25 @@
         # for giraph app, we need to add args into orginal query_args, which is a json string
         # first one should be user params, second should be lib_path
         if app_type.startswith("giraph:"):
             user_params["app_class"] = GIRAPH_DRIVER_CLASS
             user_params["user_app_class"] = app_type[7:]
         else:
             user_params["app_class"] = app_type.split(":")[-1]
-        logger.debug("user params: %s", json.dumps(user_params))
+        logger.debug("user params {}".format(json.dumps(user_params)))
         new_user_param = Any()
         new_user_param.Pack(data_types_pb2.StringValue(value=json.dumps(user_params)))
         op.query_args.args.extend([new_user_param])
 
         # For java app, we need lib path as an explicit arg.
         lib_param = Any()
         lib_path = parent_op.attr[types_pb2.APP_LIBRARY_PATH].s.decode(
             "utf-8", errors="ignore"
         )
-        logger.info("Java app: Lib path: %s", lib_path)
+        logger.info("Java app: Lib path {}".format(lib_path))
         lib_param.Pack(data_types_pb2.StringValue(value=lib_path))
         op.query_args.args.extend([lib_param])
 
 
 def _pre_process_for_unload_graph_op(op, op_result_pool, key_to_op, **kwargs):
     assert len(op.parents) == 1
     key_of_parent_op = op.parents[0]
@@ -1449,16 +1439,15 @@
         zip_ref.extractall(app_dir)
 
 
 def _parse_java_app_type(java_class_path, real_algo):
     _java_app_type = ""
     _frag_param_str = ""
     _java_inner_context_type = ""
-    _vd_type = ""
-    _java_executable = find_java_exe()
+    _java_executable = find_java()
     parse_user_app_cmd = [
         _java_executable,
         "-cp",
         "{}".format(java_class_path),
         "com.alibaba.graphscope.utils.AppBaseParser",
         real_algo,
     ]
@@ -1495,19 +1484,17 @@
             _frag_param_str = line.split(":")[-1].strip()
         elif line.find("ContextType") != -1:
             _java_inner_context_type = line.split(":")[-1].strip()
         elif line.find("VertexData") != -1:
             _vd_type = line.split(":")[-1].strip()
     # for giraph app, we manually set java inner ctx type
     logger.info(
-        "Java app type: %s, frag type str: %s, ctx type: %s, vd type %s",
-        _java_app_type,
-        _frag_param_str,
-        _java_inner_context_type,
-        _vd_type,
+        "Java app type: {}, frag type str: {}, ctx type: {}, vd type {}".format(
+            _java_app_type, _frag_param_str, _java_inner_context_type, _vd_type
+        )
     )
     if (
         not _java_app_type
         or not _frag_param_str
         or not _java_inner_context_type
         or not _vd_type
     ):
@@ -1567,15 +1554,15 @@
         with zip_ref.open(meta_file, "r") as f:
             config_yaml = yaml.safe_load(f)
 
     algo = attr[types_pb2.APP_ALGO].s.decode("utf-8", errors="ignore")
     # for algo start with giraph:, we don't find info in meta
     if algo.startswith("giraph:") or algo.startswith("java_pie:"):
         real_algo = algo.split(":")[1]
-        logger.info("codegen app info for java app: %s", real_algo)
+        logger.info("codegen app info for java app : {}".format(real_algo))
         src_header, app_class, vd_type, java_app_template_str = _probe_for_java_app(
             attr, java_class_path, real_algo
         )
         return (
             "java_pie",
             src_header,
             "{}<_GRAPH_TYPE>".format(app_class),
@@ -1684,31 +1671,25 @@
                 return "vineyard::arrow_string_view"
             return t
 
         return VERETX_MAP_CLASS_MAP[vm_type_enum].format(
             internal_type(oid_type()), vid_type()
         )
 
-    def compact_edges():
-        compact_edges = False
-        if types_pb2.COMPACT_EDGES in attr:
-            compact_edges = attr[types_pb2.COMPACT_EDGES].b
-        return "true" if compact_edges else "false"
-
     graph_type = attr[types_pb2.GRAPH_TYPE].i
     graph_class, graph_header = GRAPH_HEADER_MAP[graph_type]
 
     # graph_type is a literal of graph template in c++ side
     if graph_type == graph_def_pb2.ARROW_PROPERTY:
         # in a format of full qualified name, e.g.
-        # vineyard::ArrowFragment<int64_t, uin64_t, vineyard::ArrowLocalVertexMap<int64_t, uint64_t>, false>
-        graph_fqn = f"{graph_class}<{oid_type()},{vid_type()},{vertex_map_type()},{compact_edges()}>"
+        # vineyard::ArrowFragment<int64_t, uin64_t, vineyard::ArrowLocalVertexMap<int64_t, uint64_t>>
+        graph_fqn = f"{graph_class}<{oid_type()},{vid_type()},{vertex_map_type()}>"
     elif graph_type == graph_def_pb2.ARROW_PROJECTED:
-        # gs::ArrowProjectedFragment<int64_t, uint64_t, double, double,vineyard::ArrowLocalVertexMap<int64_t, uint64_t>, false>
-        graph_fqn = f"{graph_class}<{oid_type()},{vid_type()},{vdata_type()},{edata_type()},{vertex_map_type()},{compact_edges()}>"  # noqa: E501
+        # gs::ArrowProjectedFragment<int64_t, uint64_t, double, double,vineyard::ArrowLocalVertexMap<int64_t, uint64_t>>
+        graph_fqn = f"{graph_class}<{oid_type()},{vid_type()},{vdata_type()},{edata_type()},{vertex_map_type()}>"
     elif graph_type == graph_def_pb2.IMMUTABLE_EDGECUT:
         # grape::ImmutableEdgecutFragment<int64_t, uint32_t, double, double>
         graph_fqn = (
             f"{graph_class}<{oid_type()},{vid_type()},{vdata_type()},{edata_type()}>"
         )
     elif graph_type == graph_def_pb2.ARROW_FLATTENED:
         # grape::ArrowFlattenFragment<int64_t, uint32_t, double, double>
```

## gscoordinator/template/CMakeLists.template

```diff
@@ -285,18 +285,14 @@
 endif()
 
 if (APPLE AND "${CMAKE_CXX_COMPILER_ID}" STREQUAL "Clang")
     set(CMAKE_SHARED_LIBRARY_CREATE_CXX_FLAGS "${CMAKE_SHARED_LIBRARY_CREATE_CXX_FLAGS} -undefined dynamic_lookup")
 endif()
 
 set(GRAPH_TYPE "$_graph_type")
-# message("GRAPH_TYPE = ${GRAPH_TYPE}")
-
-set(APP_TYPE "$_app_type")
-# message("APP_TYPE = ${APP_TYPE}")
 
 if (CYTHON_PREGEL_APP)
     file(GLOB_RECURSE FILES_NEED_COMPILE "*.cc")
     add_library(${FRAME_NAME} SHARED ${FILES_NEED_COMPILE}
                                      ${ANALYTICAL_ENGINE_FRAME_DIR}/cython_app_frame.cc)
     target_compile_definitions(${FRAME_NAME} PRIVATE _OID_TYPE=$_oid_type
                                                      _VD_TYPE=$_vd_type
```

## gscoordinator/builtin/app/builtin_app.gar

### zipinfo {}

```diff
@@ -1,5 +1,5 @@
 Zip file size: 5601 bytes, number of entries: 3
--rw-r--r--  2.0 unx    23996 b- defN 23-Jun-06 01:10 .gs_conf.yaml
--rw-r--r--  2.0 unx      646 b- defN 23-Jun-06 01:10 __init__.py
--rw-r--r--  2.0 unx     2676 b- defN 23-Jun-06 01:40 builtin_app.zip
+-rw-r--r--  2.0 unx    23996 b- defN 23-May-15 19:08 .gs_conf.yaml
+-rw-r--r--  2.0 unx      646 b- defN 23-May-15 19:08 __init__.py
+-rw-r--r--  2.0 unx     2676 b- defN 23-May-15 21:14 builtin_app.zip
 3 files, 27318 bytes uncompressed, 5273 bytes compressed:  80.7%
```

### builtin_app.zip

 * *Command `'zipinfo {}'` failed with exit code 9. Standard output:*

 * *    Archive:  /tmp/diffoscope_qvsva96x_/tmpj2t0jp59_ZipContainer/builtin_app.zip*

 * *    […]*

 * *Archive contents identical but files differ, possibly due to different compression levels. Falling back to binary comparison.*

```diff
@@ -1,8 +1,8 @@
-00000000: 504b 0304 1400 0000 0800 4809 c656 c5fe  PK........H..V..
+00000000: 504b 0304 1400 0000 0800 1c99 af56 c5fe  PK...........V..
 00000010: c588 8608 0000 bc5d 0000 0d00 0000 2e67  .......].......g
 00000020: 735f 636f 6e66 2e79 616d 6ccd 9c5b 739b  s_conf.yaml..[s.
 00000030: 3814 80df f757 e40f b0cc a46f 7973 48b3  8....W.....oysH.
 00000040: cd34 693d 71ba bbb3 2f8c 8c15 ac8d 0cac  .4i=q.../.......
 00000050: 046e dd5f bf47 0299 8b01 1fd9 a9c5 431c  .n._.G........C.
 00000060: 0fe8 5c3e 1d5d 8e84 30c9 b29b dfae aebc  ..\>.]..0.......
 00000070: 2bc2 e3f4 e62a 2331 1524 7983 4b57 57f9  +....*#1.$y.KWW.
@@ -133,15 +133,15 @@
 00000840: 6fc7 5e60 68a3 69f5 6eb6 d06d f6d0 b163  o.^`h.i.n..m...c
 00000850: fbd2 cde0 0e66 2d9e ea00 cee8 1b4f 6d1e  .....f-......Om.
 00000860: 370f 74a4 4578 16e8 f048 37e1 9156 e159  7.t.Ex...H7..V.Y
 00000870: e0c3 235d 8567 2918 28c1 b738 5d1c dbe6  ..#].g).(..8]...
 00000880: 7461 7754 363d 490b a03b 932e ed26 6020  tawT6=I..;...&` 
 00000890: 1e66 294b 2c32 8a22 9f2b 01ec 585e e49e  .f)K,2.".+..X^..
 000008a0: 36e0 94ce e6c5 cf8a 0f1b bd3d e045 02f8  6..........=.E..
-000008b0: 3f50 4b03 0414 0000 0008 0048 09c6 567c  ?PK........H..V|
+000008b0: 3f50 4b03 0414 0000 0008 001c 99af 567c  ?PK...........V|
 000008c0: bd2d f09a 0100 0086 0200 000b 0000 005f  .-............._
 000008d0: 5f69 6e69 745f 5f2e 7079 6592 416f db30  _init__.pye.Ao.0
 000008e0: 0c85 effd 156f c965 1b92 38c8 2e43 77f2  .....o.e..8..Cw.
 000008f0: d26c 3516 3840 9cae e851 b669 9b80 2369  .l5.8@...Q.i..#i
 00000900: 925c 37ff 7e94 9b01 2da6 8b20 f1f1 e923  .\7.~...-.. ...#
 00000910: a9f9 0724 8377 49c9 3a21 fd0c 7b09 9dd1  ...$.wI.:!..{...
 00000920: 5f6e e658 7e5e a232 35eb f616 4368 965f  _n.X~^.25...Ch._
```

#### builtin_app.zip

```diff
@@ -1,8 +1,8 @@
-00000000: 504b 0304 1400 0000 0800 4809 c656 c5fe  PK........H..V..
+00000000: 504b 0304 1400 0000 0800 1c99 af56 c5fe  PK...........V..
 00000010: c588 8608 0000 bc5d 0000 0d00 0000 2e67  .......].......g
 00000020: 735f 636f 6e66 2e79 616d 6ccd 9c5b 739b  s_conf.yaml..[s.
 00000030: 3814 80df f757 e40f b0cc a46f 7973 48b3  8....W.....oysH.
 00000040: cd34 693d 71ba bbb3 2f8c 8c15 ac8d 0cac  .4i=q.../.......
 00000050: 046e dd5f bf47 0299 8b01 1fd9 a9c5 431c  .n._.G........C.
 00000060: 0fe8 5c3e 1d5d 8e84 30c9 b29b dfae aebc  ..\>.]..0.......
 00000070: 2bc2 e3f4 e62a 2331 1524 7983 4b57 57f9  +....*#1.$y.KWW.
@@ -133,15 +133,15 @@
 00000840: 6fc7 5e60 68a3 69f5 6eb6 d06d f6d0 b163  o.^`h.i.n..m...c
 00000850: fbd2 cde0 0e66 2d9e ea00 cee8 1b4f 6d1e  .....f-......Om.
 00000860: 370f 74a4 4578 16e8 f048 37e1 9156 e159  7.t.Ex...H7..V.Y
 00000870: e0c3 235d 8567 2918 28c1 b738 5d1c dbe6  ..#].g).(..8]...
 00000880: 7461 7754 363d 490b a03b 932e ed26 6020  tawT6=I..;...&` 
 00000890: 1e66 294b 2c32 8a22 9f2b 01ec 585e e49e  .f)K,2.".+..X^..
 000008a0: 36e0 94ce e6c5 cf8a 0f1b bd3d e045 02f8  6..........=.E..
-000008b0: 3f50 4b03 0414 0000 0008 0048 09c6 567c  ?PK........H..V|
+000008b0: 3f50 4b03 0414 0000 0008 001c 99af 567c  ?PK...........V|
 000008c0: bd2d f09a 0100 0086 0200 000b 0000 005f  .-............._
 000008d0: 5f69 6e69 745f 5f2e 7079 6592 416f db30  _init__.pye.Ao.0
 000008e0: 0c85 effd 156f c965 1b92 38c8 2e43 77f2  .....o.e..8..Cw.
 000008f0: d26c 3516 3840 9cae e851 b669 9b80 2369  .l5.8@...Q.i..#i
 00000900: 925c 37ff 7e94 9b01 2da6 8b20 f1f1 e923  .\7.~...-.. ...#
 00000910: a9f9 0724 8377 49c9 3a21 fd0c 7b09 9dd1  ...$.wI.:!..{...
 00000920: 5f6e e658 7e5e a232 35eb f616 4368 965f  _n.X~^.25...Ch._
```

## Comparing `gs_coordinator-0.22.0.dist-info/RECORD` & `gs_coordinator-0.22.0a20230515.dist-info/RECORD`

 * *Files 8% similar despite different names*

```diff
@@ -1,32 +1,32 @@
+gs_coordinator-0.22.0a20230515.dist-info/RECORD,,
+gs_coordinator-0.22.0a20230515.dist-info/WHEEL,sha256=fw_hGi-Yx84a3ggAIzpSq5odRE77o5K1cXAmZvJuyLk,140
+gs_coordinator-0.22.0a20230515.dist-info/top_level.txt,sha256=GiJfpWt7WpC-H1BxUy5V39G7WAtPut6eqH3yAciJhqQ,33
+gs_coordinator-0.22.0a20230515.dist-info/METADATA,sha256=SLHLGCyhkv2hhhnTVm_KX4QgJSXM7fQuXhhpF0GU8vI,22321
 graphscope_runtime/__init__.py,sha256=w_Me0NHI5zy8GitMCD7mzOi0Qz7ZfeE2zUI5wGfZIyM,694
-gs_coordinator-0.22.0.dist-info/RECORD,,
-gs_coordinator-0.22.0.dist-info/WHEEL,sha256=HKte8F_3_5BhqubTWOSqDKg3FZYIY1VaDasAQmf0R1I,138
-gs_coordinator-0.22.0.dist-info/top_level.txt,sha256=GiJfpWt7WpC-H1BxUy5V39G7WAtPut6eqH3yAciJhqQ,33
-gs_coordinator-0.22.0.dist-info/METADATA,sha256=wTi7R4iWPVHz7ykwI78mo6Q04rCKjfB9e6ijfBv3K10,22312
-gscoordinator/kubernetes_launcher.py,sha256=rDDRJU6Py9ucic7pFE5FD7wTmV1fGuwsUXaQGLKw9d0,58206
-gscoordinator/coordinator.py,sha256=uvCxBHcnwZHaVGcVvGxRafHs7j-s-pPbn9iQcC97yZ0,37570
+gscoordinator/kubernetes_launcher.py,sha256=Mf3xJddi_2dQOPglhM4wksQWc77WDqEPSG4yZxX32tU,36024
+gscoordinator/coordinator.py,sha256=m32CaDozoiIObS3lLa-JuqfS5p91HY4bkN4u3n0oSrU,37321
 gscoordinator/dag_manager.py,sha256=GJBIzr3BNs2_1a2rbTwkBw7H8SwiTFbrzhotdiMjDCY,5537
 gscoordinator/version.py,sha256=bS71qRjwM-xk4LAFTExdiWJOaJEXaeNdlJYCAqtD98U,1045
 gscoordinator/monitor.py,sha256=7-barfbJ0LefMG3bQvkuG0qy5pKTTfeWD4T4zImB81A,7006
-gscoordinator/op_executor.py,sha256=Otx9T3y2qkFxkBUPj8tShJD0TsSW3E-7LuFsYjbEiTo,38436
+gscoordinator/op_executor.py,sha256=f21lQ5NIQ28nG1m4j_RzJpu4xBrNOIWMSNsJhvMt4rU,38246
 gscoordinator/object_manager.py,sha256=_mWIHV4E4UHhdbdXU23juWPDhA4EgDY4XIhHb-z0aiI,2957
 gscoordinator/__init__.py,sha256=nUqENyB6dtqMgYfbJjblAdV2nemmlsaTMp_yTteBnOw,990
-gscoordinator/cluster_builder.py,sha256=h3Q61iS_F11Id497WI2Cn2eyEFO7_uaC5vyhrJau5-U,22541
-gscoordinator/local_launcher.py,sha256=s3RAAeXhbMrKpw5TEu8nIjxOcMXuVwU9djigUeSarjk,19978
-gscoordinator/VERSION,sha256=Rkhj7mlsqGL2riv-6XKOu9hEY1l4JUQu_GKDjZRbAPs,7
-gscoordinator/utils.py,sha256=outYdoGzVv1oOE8S-LJ3pkAHpYIf8GQGOJ9BS2sc9TM,77420
+gscoordinator/cluster_builder.py,sha256=nEjGzaoahhmr8CZvb16OjFDn48A04P3CyELInho4AP4,24417
+gscoordinator/local_launcher.py,sha256=SZaP7BdJLsYOnvBJWMT1hRK153QEWugRmLcOcdUs-wQ,19314
+gscoordinator/VERSION,sha256=KQJZBG-Mxkijark9CBH9Oczy7Hti0axQ2uqhEXerj5Q,16
+gscoordinator/utils.py,sha256=zvhTbhL19l8pZKdtSByG7mf3IttuOTjFJU82OjVKScg,76887
 gscoordinator/io_utils.py,sha256=8lxUPh-DfBj4yPIAPY9ovv2Iweg7MG8V77LscRlPM8o,4091
 gscoordinator/launcher.py,sha256=uxi4zSyr11csGtQLihzmzR4S07ZI9sYjkd1FEJxOnLk,5062
 gscoordinator/learning.py,sha256=M9MOv4ywKjZVYv1o1SB0fXN0ToTLD1EhfPiiBU1ic94,2450
 gscoordinator/__main__.py,sha256=pfC-UJ0gz8i-p1lGAs2jBB8zALAz6PaBokLa9v6AYQ4,77
 gscoordinator/template/__init__.py,sha256=TsAsMQRDcEJ9nRXDAeF-pJPapJrZPwVeb-TxxVp42aY,646
 gscoordinator/template/pregel.pxd.template,sha256=Eh4tESR8KlmM30Mcw-eIUfiQNeadDj3WWGCUzkIsT2M,4340
 gscoordinator/template/pie.pxd.template,sha256=-hYphyhUzTnyQELecGEsCK_S-fEXLWGiTV91-gDqAU8,4957
-gscoordinator/template/CMakeLists.template,sha256=HTO9-vFKVWwT3OJn8YcmciJ2Hh8Ox4IqyNfcD85jcwg,19957
+gscoordinator/template/CMakeLists.template,sha256=JVAD0zemkedKacJbyJDEmLzzoUgRhEvXHu3AGcl6O5k,19853
 gscoordinator/builtin/__init__.py,sha256=TsAsMQRDcEJ9nRXDAeF-pJPapJrZPwVeb-TxxVp42aY,646
 gscoordinator/builtin/app/.gs_conf.yaml,sha256=S15xBlunwTgfjtjjsIGreWXv8OkWwtAlNANO84u08YE,23996
-gscoordinator/builtin/app/builtin_app.gar,sha256=wFNCtj7hSLnKJfRP75EZZ2wWKItykZ8IUjutlzNkDnQ,5601
+gscoordinator/builtin/app/builtin_app.gar,sha256=Z-PgxO2UKY1FqOPnhuhFp6zrwA-T-itwgv-_HKxyuYU,5601
 gscoordinator/builtin/app/__init__.py,sha256=TsAsMQRDcEJ9nRXDAeF-pJPapJrZPwVeb-TxxVp42aY,646
 gscoordinator/hook/__init__.py,sha256=jzzLJxC1gBgRLMb4xzX6vucYuNdosuWOtZKRj7Cal_o,646
 gscoordinator/hook/prestop/__init__.py,sha256=jzzLJxC1gBgRLMb4xzX6vucYuNdosuWOtZKRj7Cal_o,646
 gscoordinator/hook/prestop/__main__.py,sha256=1FmS0g2hwl85NPMOtbAvW_IGn4GFnldmjbSSwaj9GrE,1560
```

## Comparing `gs_coordinator-0.22.0.dist-info/METADATA` & `gs_coordinator-0.22.0a20230515.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: gs-coordinator
-Version: 0.22.0
+Version: 0.22.0a20230515
 Home-page: https://github.com/alibaba/GraphScope
 Author: GraphScope Team, Damo Academy
 Author-email: graphscope@alibaba-inc.com
 License: Apache License 2.0
 Keywords: GraphScope,Graph Computations
 Classifier: Development Status :: 5 - Production/Stable
 Classifier: Intended Audience :: Developers
@@ -18,24 +18,24 @@
 Classifier: Programming Language :: Python :: 3.7
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
 Classifier: Programming Language :: Python :: 3.10
 Classifier: Programming Language :: Python :: 3.11
 Description-Content-Type: text/markdown
 Requires-Dist: etcd-distro (>=3.5.1)
+Requires-Dist: graphscope-client (>=0.20.0)
 Requires-Dist: grpcio (>=1.49)
 Requires-Dist: grpcio-tools (>=1.49)
 Requires-Dist: kubernetes (>=24.2.0)
 Requires-Dist: protobuf (>=4)
 Requires-Dist: PyYAML
 Requires-Dist: prometheus-client (>=0.14.1)
 Requires-Dist: setuptools (==65.7.0)
 Requires-Dist: packaging
 Requires-Dist: tqdm
-Requires-Dist: graphscope-client (==0.22.0)
 Requires-Dist: vineyard (>=0.14) ; sys_platform != "win32"
 Requires-Dist: vineyard-io (>=0.14) ; sys_platform != "win32"
 Provides-Extra: dev
 Requires-Dist: black (>=23.3.0) ; extra == 'dev'
 Requires-Dist: flake8 (==4.0.1) ; extra == 'dev'
 Requires-Dist: isort (==5.10.1) ; extra == 'dev'
 
@@ -353,15 +353,15 @@
 
 ```python
 sess.close()
 ```
 
 This operation will notify the backend engines and vineyard
 to safely unload graphs and their applications,
-Then, the coordinator will release all the applied resources in the k8s cluster.
+Then, the coordinator will dealloc all the applied resources in the k8s cluster.
 
 Please note that we have not hardened this release for production use and it lacks important security features such as authentication and encryption, and therefore **it is NOT recommended for production use (yet)!**
 
 ## Development
 
 ### Building on local
```

